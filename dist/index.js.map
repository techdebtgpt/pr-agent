{"version":3,"file":"index.js","mappings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v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vCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3oBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxDA;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5iBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACRA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACPA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACXA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9NA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxGA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACr0BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/IA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1uEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClf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zgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChlBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnmEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACj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jBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACroBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACv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vYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrRA;;;;;;;;ACAA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9VA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChoBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChCA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACnMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AChCA;AACA;AACA;AACA;AACA;;;;ACJA;AACA;;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACx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pEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1XA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3QA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC/GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACx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lJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACvHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC1IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACvRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC7v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n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bA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AEjNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AE3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACh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gBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACjJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpGA;AACA;AACA;AACA;AACA;AACA;;ACLA;AACA;AACA;AACA;AACA;AACA;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACh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eA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AClMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACpjBA;AACA;AACA;AACA;AACA;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACprDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACz4BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACpIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACpIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACRA;AACA;AACA;AACA;AACA;AACA;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5mHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACh1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACtCA;AACA;AACA;AACA;AACA;AACA;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC3GA;AACA;AACA;AACA;AACA;AACA;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACjyBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/uDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA;AACA;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC3RA;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5aA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3QA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC3vBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACp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hBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvCA;AACA;AACA;AACA;AACA;AACA;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrDA;AACA;AACA;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5QA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACliBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/oCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACxCA;AACA;AACA;AACA;AACA;AACA;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC7+BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1GA;AACA;AACA;AACA;AACA;AACA;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjJA;AACA;AACA;AACA;AACA;AACA;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7FA;AACA;AACA;;ACFA;AACA;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5FA;AACA;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClCA;AACA;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACv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kBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtkBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7h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vyBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;;;ACFA;;;AAGA;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;;AAGA;;;;AAIA;;;;;;;;;;;;AAYA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACl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uBA;;;AAGA;AAEA;AAEA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AAKA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;;;AChIA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA","sources":[".././node_modules/@actions/core/lib/command.js",".././node_modules/@actions/core/lib/core.js",".././node_modules/@actions/core/lib/file-command.js",".././node_modules/@actions/core/lib/oidc-utils.js",".././node_modules/@actions/core/lib/path-utils.js",".././node_modules/@actions/core/lib/platform.js",".././node_modules/@actions/core/lib/summary.js",".././node_modules/@actions/core/lib/utils.js",".././node_modules/@actions/exec/lib/exec.js",".././node_modules/@actions/exec/lib/toolrunner.js",".././node_modules/@actions/github/lib/context.js",".././node_modules/@actions/github/lib/github.js",".././node_modules/@actions/github/lib/internal/utils.js",".././node_modules/@actions/github/lib/utils.js",".././node_modules/@actions/http-client/lib/auth.js",".././node_modules/@actions/http-client/lib/index.js",".././node_modules/@actions/http-client/lib/proxy.js",".././node_modules/@actions/io/lib/io-util.js",".././node_modules/@actions/io/lib/io.js",".././node_modules/@langchain/core/node_modules/ansi-styles/index.js",".././node_modules/@langchain/core/node_modules/camelcase/index.js",".././node_modules/@langchain/core/node_modules/uuid/dist/index.js",".././node_modules/@langchain/core/node_modules/uuid/dist/max.js",".././node_modules/@langchain/core/node_modules/uuid/dist/md5.js",".././node_modules/@langchain/core/node_modules/uuid/dist/native.js",".././node_modules/@langchain/core/node_modules/uuid/dist/nil.js",".././node_modules/@langchain/core/node_modules/uuid/dist/parse.js",".././node_modules/@langchain/core/node_modules/uuid/dist/regex.js",".././node_modules/@langchain/core/node_modules/uuid/dist/rng.js",".././node_modules/@langchain/core/node_modules/uuid/dist/sha1.js",".././node_modules/@langchain/core/node_modules/uuid/dist/stringify.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v1.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v1ToV6.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v3.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v35.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v4.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v5.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v6.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v6ToV1.js",".././node_modules/@langchain/core/node_modules/uuid/dist/v7.js",".././node_modules/@langchain/core/node_modules/uuid/dist/validate.js",".././node_modules/@langchain/core/node_modules/uuid/dist/version.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/index.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/max.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/md5.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/native.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/nil.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/parse.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/regex.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/rng.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/sha1.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/stringify.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v1.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v1ToV6.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v3.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v35.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v4.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v5.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v6.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v6ToV1.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/v7.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/validate.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/dist/version.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/index.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/max.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/md5.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/native.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/nil.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/parse.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/regex.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/rng.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/sha1.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/stringify.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v1.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v1ToV6.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v3.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v35.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v4.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v5.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v6.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v6ToV1.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/v7.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/validate.js",".././node_modules/@langchain/langgraph/node_modules/uuid/dist/version.js",".././node_modules/@octokit/auth-token/dist-node/index.js",".././node_modules/@octokit/core/dist-node/index.js",".././node_modules/@octokit/endpoint/dist-node/index.js",".././node_modules/@octokit/graphql/dist-node/index.js",".././node_modules/@octokit/plugin-paginate-rest/dist-node/index.js",".././node_modules/@octokit/plugin-rest-endpoint-methods/dist-node/index.js",".././node_modules/@octokit/request-error/dist-node/index.js",".././node_modules/@octokit/request/dist-node/index.js",".././node_modules/base64-js/index.js",".././node_modules/before-after-hook/index.js",".././node_modules/before-after-hook/lib/add.js",".././node_modules/before-after-hook/lib/register.js",".././node_modules/before-after-hook/lib/remove.js",".././node_modules/decamelize/index.js",".././node_modules/deprecation/dist-node/index.js",".././node_modules/eventemitter3/index.js",".././node_modules/langsmith/node_modules/uuid/dist/index.js",".././node_modules/langsmith/node_modules/uuid/dist/max.js",".././node_modules/langsmith/node_modules/uuid/dist/md5.js",".././node_modules/langsmith/node_modules/uuid/dist/native.js",".././node_modules/langsmith/node_modules/uuid/dist/nil.js",".././node_modules/langsmith/node_modules/uuid/dist/parse.js",".././node_modules/langsmith/node_modules/uuid/dist/regex.js",".././node_modules/langsmith/node_modules/uuid/dist/rng.js",".././node_modules/langsmith/node_modules/uuid/dist/sha1.js",".././node_modules/langsmith/node_modules/uuid/dist/stringify.js",".././node_modules/langsmith/node_modules/uuid/dist/v1.js",".././node_modules/langsmith/node_modules/uuid/dist/v1ToV6.js",".././node_modules/langsmith/node_modules/uuid/dist/v3.js",".././node_modules/langsmith/node_modules/uuid/dist/v35.js",".././node_modules/langsmith/node_modules/uuid/dist/v4.js",".././node_modules/langsmith/node_modules/uuid/dist/v5.js",".././node_modules/langsmith/node_modules/uuid/dist/v6.js",".././node_modules/langsmith/node_modules/uuid/dist/v6ToV1.js",".././node_modules/langsmith/node_modules/uuid/dist/v7.js",".././node_modules/langsmith/node_modules/uuid/dist/validate.js",".././node_modules/langsmith/node_modules/uuid/dist/version.js",".././node_modules/once/once.js",".././node_modules/p-finally/index.js",".././node_modules/p-queue/dist/index.js",".././node_modules/p-queue/dist/lower-bound.js",".././node_modules/p-queue/dist/priority-queue.js",".././node_modules/p-retry/index.js",".././node_modules/p-timeout/index.js",".././node_modules/retry/index.js",".././node_modules/retry/lib/retry.js",".././node_modules/retry/lib/retry_operation.js",".././node_modules/semver/classes/comparator.js",".././node_modules/semver/classes/range.js",".././node_modules/semver/classes/semver.js",".././node_modules/semver/functions/clean.js",".././node_modules/semver/functions/cmp.js",".././node_modules/semver/functions/coerce.js",".././node_modules/semver/functions/compare-build.js",".././node_modules/semver/functions/compare-loose.js",".././node_modules/semver/functions/compare.js",".././node_modules/semver/functions/diff.js",".././node_modules/semver/functions/eq.js",".././node_modules/semver/functions/gt.js",".././node_modules/semver/functions/gte.js",".././node_modules/semver/functions/inc.js",".././node_modules/semver/functions/lt.js",".././node_modules/semver/functions/lte.js",".././node_modules/semver/functions/major.js",".././node_modules/semver/functions/minor.js",".././node_modules/semver/functions/neq.js",".././node_modules/semver/functions/parse.js",".././node_modules/semver/functions/patch.js",".././node_modules/semver/functions/prerelease.js",".././node_modules/semver/functions/rcompare.js",".././node_modules/semver/functions/rsort.js",".././node_modules/semver/functions/satisfies.js",".././node_modules/semver/functions/sort.js",".././node_modules/semver/functions/valid.js",".././node_modules/semver/index.js",".././node_modules/semver/internal/constants.js",".././node_modules/semver/internal/debug.js",".././node_modules/semver/internal/identifiers.js",".././node_modules/semver/internal/lrucache.js",".././node_modules/semver/internal/parse-options.js",".././node_modules/semver/internal/re.js",".././node_modules/semver/ranges/gtr.js",".././node_modules/semver/ranges/intersects.js",".././node_modules/semver/ranges/ltr.js",".././node_modules/semver/ranges/max-satisfying.js",".././node_modules/semver/ranges/min-satisfying.js",".././node_modules/semver/ranges/min-version.js",".././node_modules/semver/ranges/outside.js",".././node_modules/semver/ranges/simplify.js",".././node_modules/semver/ranges/subset.js",".././node_modules/semver/ranges/to-comparators.js",".././node_modules/semver/ranges/valid.js",".././node_modules/tunnel/index.js",".././node_modules/tunnel/lib/tunnel.js",".././node_modules/undici/index.js",".././node_modules/undici/lib/agent.js",".././node_modules/undici/lib/api/abort-signal.js",".././node_modules/undici/lib/api/api-connect.js",".././node_modules/undici/lib/api/api-pipeline.js",".././node_modules/undici/lib/api/api-request.js",".././node_modules/undici/lib/api/api-stream.js",".././node_modules/undici/lib/api/api-upgrade.js",".././node_modules/undici/lib/api/index.js",".././node_modules/undici/lib/api/readable.js",".././node_modules/undici/lib/api/util.js",".././node_modules/undici/lib/balanced-pool.js",".././node_modules/undici/lib/cache/cache.js",".././node_modules/undici/lib/cache/cachestorage.js",".././node_modules/undici/lib/cache/symbols.js",".././node_modules/undici/lib/cache/util.js",".././node_modules/undici/lib/client.js",".././node_modules/undici/lib/compat/dispatcher-weakref.js",".././node_modules/undici/lib/cookies/constants.js",".././node_modules/undici/lib/cookies/index.js",".././node_modules/undici/lib/cookies/parse.js",".././node_modules/undici/lib/cookies/util.js",".././node_modules/undici/lib/core/connect.js",".././node_modules/undici/lib/core/constants.js",".././node_modules/undici/lib/core/errors.js",".././node_modules/undici/lib/core/request.js",".././node_modules/undici/lib/core/symbols.js",".././node_modules/undici/lib/core/util.js",".././node_modules/undici/lib/dispatcher-base.js",".././node_modules/undici/lib/dispatcher.js",".././node_modules/undici/lib/fetch/body.js",".././node_modules/undici/lib/fetch/constants.js",".././node_modules/undici/lib/fetch/dataURL.js",".././node_modules/undici/lib/fetch/file.js",".././node_modules/undici/lib/fetch/formdata.js",".././node_modules/undici/lib/fetch/global.js",".././node_modules/undici/lib/fetch/headers.js",".././node_modules/undici/lib/fetch/index.js",".././node_modules/undici/lib/fetch/request.js",".././node_modules/undici/lib/fetch/response.js",".././node_modules/undici/lib/fetch/symbols.js",".././node_modules/undici/lib/fetch/util.js",".././node_modules/undici/lib/fetch/webidl.js",".././node_modules/undici/lib/fileapi/encoding.js",".././node_modules/undici/lib/fileapi/filereader.js",".././node_modules/undici/lib/fileapi/progressevent.js",".././node_modules/undici/lib/fileapi/symbols.js",".././node_modules/undici/lib/fileapi/util.js",".././node_modules/undici/lib/global.js",".././node_modules/undici/lib/handler/DecoratorHandler.js",".././node_modules/undici/lib/handler/RedirectHandler.js",".././node_modules/undici/lib/handler/RetryHandler.js",".././node_modules/undici/lib/interceptor/redirectInterceptor.js",".././node_modules/undici/lib/llhttp/constants.js",".././node_modules/undici/lib/llhttp/llhttp-wasm.js",".././node_modules/undici/lib/llhttp/llhttp_simd-wasm.js",".././node_modules/undici/lib/llhttp/utils.js",".././node_modules/undici/lib/mock/mock-agent.js",".././node_modules/undici/lib/mock/mock-client.js",".././node_modules/undici/lib/mock/mock-errors.js",".././node_modules/undici/lib/mock/mock-interceptor.js",".././node_modules/undici/lib/mock/mock-pool.js",".././node_modules/undici/lib/mock/mock-symbols.js",".././node_modules/undici/lib/mock/mock-utils.js",".././node_modules/undici/lib/mock/pending-interceptors-formatter.js",".././node_modules/undici/lib/mock/pluralizer.js",".././node_modules/undici/lib/node/fixed-queue.js",".././node_modules/undici/lib/pool-base.js",".././node_modules/undici/lib/pool-stats.js",".././node_modules/undici/lib/pool.js",".././node_modules/undici/lib/proxy-agent.js",".././node_modules/undici/lib/timers.js",".././node_modules/undici/lib/websocket/connection.js",".././node_modules/undici/lib/websocket/constants.js",".././node_modules/undici/lib/websocket/events.js",".././node_modules/undici/lib/websocket/frame.js",".././node_modules/undici/lib/websocket/receiver.js",".././node_modules/undici/lib/websocket/symbols.js",".././node_modules/undici/lib/websocket/util.js",".././node_modules/undici/lib/websocket/websocket.js",".././node_modules/universal-user-agent/dist-node/index.js",".././node_modules/wrappy/wrappy.js","../external node-commonjs \"assert\"","../external node-commonjs \"async_hooks\"","../external node-commonjs \"buffer\"","../external node-commonjs \"child_process\"","../external node-commonjs \"console\"","../external node-commonjs \"crypto\"","../external node-commonjs \"diagnostics_channel\"","../external node-commonjs \"events\"","../external node-commonjs \"fs\"","../external node-commonjs \"http\"","../external node-commonjs \"http2\"","../external node-commonjs \"https\"","../external node-commonjs \"net\"","../external node-commonjs \"node:crypto\"","../external node-commonjs \"node:events\"","../external node-commonjs \"node:stream\"","../external node-commonjs \"node:util\"","../external node-commonjs \"os\"","../external node-commonjs \"path\"","../external node-commonjs \"perf_hooks\"","../external node-commonjs \"querystring\"","../external node-commonjs \"stream\"","../external node-commonjs \"stream/web\"","../external node-commonjs \"string_decoder\"","../external node-commonjs \"timers\"","../external node-commonjs \"tls\"","../external node-commonjs \"url\"","../external node-commonjs \"util\"","../external node-commonjs \"util/types\"","../external node-commonjs \"worker_threads\"","../external node-commonjs \"zlib\"",".././node_modules/@fastify/busboy/deps/dicer/lib/Dicer.js",".././node_modules/@fastify/busboy/deps/dicer/lib/HeaderParser.js",".././node_modules/@fastify/busboy/deps/dicer/lib/PartStream.js",".././node_modules/@fastify/busboy/deps/streamsearch/sbmh.js",".././node_modules/@fastify/busboy/lib/main.js",".././node_modules/@fastify/busboy/lib/types/multipart.js",".././node_modules/@fastify/busboy/lib/types/urlencoded.js",".././node_modules/@fastify/busboy/lib/utils/Decoder.js",".././node_modules/@fastify/busboy/lib/utils/basename.js",".././node_modules/@fastify/busboy/lib/utils/decodeText.js",".././node_modules/@fastify/busboy/lib/utils/getLimit.js",".././node_modules/@fastify/busboy/lib/utils/parseParams.js","../webpack/bootstrap","../webpack/runtime/node module decorator","../webpack/runtime/compat",".././node_modules/@langchain/core/dist/_virtual/rolldown_runtime.js",".././node_modules/@langchain/core/dist/singletons/async_local_storage/globals.js",".././node_modules/@langchain/core/dist/load/map_keys.js",".././node_modules/@langchain/core/dist/load/serializable.js",".././node_modules/@langchain/core/dist/messages/content/data.js",".././node_modules/@langchain/core/dist/messages/block_translators/utils.js",".././node_modules/@langchain/core/dist/messages/block_translators/anthropic.js",".././node_modules/@langchain/core/dist/messages/block_translators/data.js",".././node_modules/@langchain/core/dist/messages/block_translators/openai.js",".././node_modules/@langchain/core/dist/messages/message.js",".././node_modules/@langchain/core/dist/messages/format.js",".././node_modules/@langchain/core/dist/messages/base.js",".././node_modules/@langchain/core/dist/messages/tool.js",".././node_modules/@langchain/core/dist/utils/json.js",".././node_modules/@langchain/core/dist/messages/block_translators/bedrock_converse.js",".././node_modules/@langchain/core/dist/messages/block_translators/google_genai.js",".././node_modules/@langchain/core/dist/messages/block_translators/google_vertexai.js",".././node_modules/@langchain/core/dist/messages/block_translators/index.js",".././node_modules/@langchain/core/dist/messages/metadata.js",".././node_modules/@langchain/core/dist/messages/ai.js",".././node_modules/@langchain/core/dist/messages/chat.js",".././node_modules/@langchain/core/dist/messages/function.js",".././node_modules/@langchain/core/dist/messages/human.js",".././node_modules/@langchain/core/dist/messages/system.js",".././node_modules/@langchain/core/dist/errors/index.js",".././node_modules/@langchain/core/dist/tools/utils.js",".././node_modules/@langchain/core/dist/messages/modifier.js",".././node_modules/@langchain/core/dist/messages/utils.js",".././node_modules/@langchain/core/dist/utils/env.js",".././node_modules/@langchain/core/node_modules/uuid/wrapper.mjs",".././node_modules/@langchain/core/dist/callbacks/base.js",".././node_modules/langsmith/node_modules/uuid/wrapper.mjs",".././node_modules/langsmith/dist/experimental/otel/constants.js",".././node_modules/langsmith/dist/singletons/fetch.js",".././node_modules/langsmith/dist/utils/project.js",".././node_modules/langsmith/dist/index.js",".././node_modules/langsmith/dist/utils/env.js",".././node_modules/langsmith/dist/singletons/otel.js",".././node_modules/langsmith/dist/experimental/otel/translator.js",".././node_modules/langsmith/dist/utils/async_caller.js",".././node_modules/langsmith/dist/utils/messages.js",".././node_modules/langsmith/dist/utils/_uuid.js",".././node_modules/langsmith/dist/utils/warn.js",".././node_modules/langsmith/dist/utils/prompts.js",".././node_modules/langsmith/dist/utils/error.js",".././node_modules/langsmith/dist/utils/fast-safe-stringify/index.js",".././node_modules/langsmith/dist/client.js",".././node_modules/langsmith/dist/env.js",".././node_modules/langsmith/dist/singletons/constants.js",".././node_modules/langsmith/dist/run_trees.js",".././node_modules/langsmith/run_trees.js",".././node_modules/@langchain/core/dist/tracers/base.js",".././node_modules/@langchain/core/dist/tracers/console.js",".././node_modules/langsmith/index.js",".././node_modules/@langchain/core/dist/singletons/tracer.js",".././node_modules/langsmith/dist/singletons/traceable.js",".././node_modules/langsmith/singletons/traceable.js",".././node_modules/@langchain/core/dist/tracers/tracer_langchain.js",".././node_modules/@langchain/core/dist/singletons/callbacks.js",".././node_modules/@langchain/core/dist/callbacks/promises.js",".././node_modules/@langchain/core/dist/utils/callbacks.js",".././node_modules/@langchain/core/dist/singletons/async_local_storage/context.js",".././node_modules/@langchain/core/dist/callbacks/manager.js",".././node_modules/@langchain/core/dist/singletons/async_local_storage/index.js",".././node_modules/@langchain/core/dist/singletons/index.js","../external node-commonjs \"node:async_hooks\"",".././node_modules/@langchain/langgraph/dist/setup/async_local_storage.js",".././node_modules/@langchain/langgraph/dist/errors.js",".././node_modules/@langchain/langgraph-checkpoint/node_modules/uuid/wrapper.mjs",".././node_modules/@langchain/langgraph-checkpoint/dist/id.js",".././node_modules/@langchain/langgraph-checkpoint/dist/serde/types.js",".././node_modules/@langchain/langgraph-checkpoint/dist/serde/utils/fast-safe-stringify/index.js",".././node_modules/@langchain/core/dist/load/import_constants.js",".././node_modules/@langchain/core/dist/agents.js",".././node_modules/@langchain/core/dist/runnables/config.js",".././node_modules/@langchain/core/dist/utils/signal.js",".././node_modules/@langchain/core/dist/utils/stream.js",".././node_modules/@langchain/core/dist/utils/fast-json-patch/src/helpers.js",".././node_modules/@langchain/core/dist/utils/fast-json-patch/src/core.js",".././node_modules/@langchain/core/dist/utils/fast-json-patch/src/duplex.js",".././node_modules/@langchain/core/dist/utils/fast-json-patch/index.js",".././node_modules/@langchain/core/dist/tracers/log_stream.js",".././node_modules/@langchain/core/dist/outputs.js",".././node_modules/@langchain/core/dist/utils/async_caller.js",".././node_modules/zod/v4/core/core.js",".././node_modules/zod/v4/core/util.js",".././node_modules/zod/v4/core/errors.js",".././node_modules/zod/v4/core/parse.js",".././node_modules/zod/v4/core/registries.js",".././node_modules/zod/v4/core/checks.js",".././node_modules/zod/v4/core/versions.js",".././node_modules/zod/v4/core/schemas.js",".././node_modules/zod/v4/core/api.js",".././node_modules/@langchain/core/dist/utils/types/zod.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/Options.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/Refs.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/getRelativePath.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/any.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/errorMessages.js",".././node_modules/zod/v3/helpers/util.js",".././node_modules/zod/v3/ZodError.js",".././node_modules/zod/v3/locales/en.js",".././node_modules/zod/v3/errors.js",".././node_modules/zod/v3/helpers/errorUtil.js",".././node_modules/zod/v3/helpers/parseUtil.js",".././node_modules/zod/v3/types.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/array.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/bigint.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/boolean.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/branded.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/catch.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/date.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/default.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/effects.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/enum.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/intersection.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/literal.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/string.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/record.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/map.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/nativeEnum.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/never.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/null.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/union.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/nullable.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/number.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/object.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/optional.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/pipeline.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/promise.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/set.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/tuple.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/undefined.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/unknown.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parsers/readonly.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/selectParser.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/parseDef.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/zodToJsonSchema.js",".././node_modules/@langchain/core/dist/utils/zod-to-json-schema/index.js",".././node_modules/zod/v4/core/to-json-schema.js",".././node_modules/@cfworker/json-schema/dist/esm/deep-compare-strict.js",".././node_modules/@cfworker/json-schema/dist/esm/pointer.js",".././node_modules/@cfworker/json-schema/dist/esm/dereference.js",".././node_modules/@cfworker/json-schema/dist/esm/format.js",".././node_modules/@cfworker/json-schema/dist/esm/types.js",".././node_modules/@cfworker/json-schema/dist/esm/ucs2-length.js",".././node_modules/@cfworker/json-schema/dist/esm/validate.js",".././node_modules/@cfworker/json-schema/dist/esm/validator.js",".././node_modules/@cfworker/json-schema/dist/esm/index.js",".././node_modules/@langchain/core/dist/utils/json_schema.js",".././node_modules/@langchain/core/dist/runnables/utils.js",".././node_modules/@langchain/core/dist/runnables/graph_mermaid.js",".././node_modules/@langchain/core/dist/runnables/graph.js",".././node_modules/@langchain/core/dist/tracers/event_stream.js",".././node_modules/@langchain/core/dist/tracers/root_listener.js",".././node_modules/@langchain/core/dist/runnables/wrappers.js",".././node_modules/@langchain/core/dist/runnables/iter.js",".././node_modules/@langchain/core/dist/runnables/base.js",".././node_modules/@langchain/core/dist/messages/transformers.js",".././node_modules/@langchain/core/dist/messages/content/tools.js",".././node_modules/@langchain/core/dist/messages/content/multimodal.js",".././node_modules/@langchain/core/dist/messages/content/index.js",".././node_modules/@langchain/core/dist/messages/index.js",".././node_modules/@langchain/core/dist/chat_history.js",".././node_modules/@langchain/core/dist/embeddings.js",".././node_modules/@langchain/core/dist/index.js",".././node_modules/@langchain/core/dist/memory.js",".././node_modules/@langchain/core/dist/prompt_values.js",".././node_modules/@langchain/core/dist/stores.js",".././node_modules/@langchain/core/dist/retrievers/index.js",".././node_modules/@langchain/core/dist/vectorstores.js",".././node_modules/@langchain/core/dist/utils/js-sha256/hash.js",".././node_modules/@langchain/core/dist/utils/hash.js",".././node_modules/@langchain/core/dist/caches/base.js",".././node_modules/@langchain/core/dist/document_loaders/base.js",".././node_modules/@langchain/core/dist/document_loaders/langsmith.js",".././node_modules/@langchain/core/dist/documents/document.js",".././node_modules/@langchain/core/dist/documents/transformers.js",".././node_modules/@langchain/core/dist/documents/index.js",".././node_modules/@langchain/core/dist/example_selectors/base.js",".././node_modules/@langchain/core/dist/example_selectors/conditional.js",".././node_modules/@langchain/core/dist/example_selectors/length_based.js",".././node_modules/@langchain/core/dist/example_selectors/semantic_similarity.js",".././node_modules/@langchain/core/dist/example_selectors/index.js",".././node_modules/@langchain/core/dist/indexing/record_manager.js",".././node_modules/@langchain/core/dist/indexing/base.js",".././node_modules/@langchain/core/dist/indexing/index.js",".././node_modules/js-tiktoken/dist/chunk-VL2OQCWN.js",".././node_modules/js-tiktoken/dist/lite.js",".././node_modules/@langchain/core/dist/utils/tiktoken.js",".././node_modules/@langchain/core/dist/language_models/base.js",".././node_modules/@langchain/core/dist/runnables/passthrough.js",".././node_modules/@langchain/core/dist/language_models/utils.js",".././node_modules/@langchain/core/dist/language_models/chat_models.js",".././node_modules/@langchain/core/dist/language_models/llms.js",".././node_modules/@langchain/core/dist/runnables/router.js",".././node_modules/@langchain/core/dist/runnables/branch.js",".././node_modules/@langchain/core/dist/runnables/history.js",".././node_modules/@langchain/core/dist/runnables/index.js",".././node_modules/@langchain/core/dist/utils/json_patch.js",".././node_modules/@langchain/core/dist/output_parsers/base.js",".././node_modules/@langchain/core/dist/output_parsers/transform.js",".././node_modules/@langchain/core/dist/output_parsers/bytes.js",".././node_modules/@langchain/core/dist/output_parsers/list.js",".././node_modules/@langchain/core/dist/output_parsers/string.js",".././node_modules/@langchain/core/dist/output_parsers/structured.js",".././node_modules/@langchain/core/dist/output_parsers/json.js",".././node_modules/@langchain/core/dist/utils/sax-js/sax.js",".././node_modules/@langchain/core/dist/output_parsers/xml.js",".././node_modules/@langchain/core/dist/output_parsers/index.js",".././node_modules/@langchain/core/dist/output_parsers/openai_tools/json_output_tools_parsers.js",".././node_modules/@langchain/core/dist/output_parsers/openai_tools/index.js",".././node_modules/@langchain/core/dist/output_parsers/openai_functions/json_output_functions_parsers.js",".././node_modules/@langchain/core/dist/output_parsers/openai_functions/index.js",".././node_modules/@langchain/core/dist/prompts/base.js",".././node_modules/@langchain/core/dist/prompts/string.js",".././node_modules/mustache/mustache.mjs",".././node_modules/@langchain/core/dist/prompts/template.js",".././node_modules/@langchain/core/dist/prompts/prompt.js",".././node_modules/@langchain/core/dist/prompts/image.js",".././node_modules/@langchain/core/dist/prompts/dict.js",".././node_modules/@langchain/core/dist/prompts/chat.js",".././node_modules/@langchain/core/dist/prompts/few_shot.js",".././node_modules/@langchain/core/dist/prompts/pipeline.js",".././node_modules/@langchain/core/dist/prompts/structured.js",".././node_modules/@langchain/core/dist/prompts/index.js",".././node_modules/@langchain/core/dist/retrievers/document_compressors/base.js",".././node_modules/@langchain/core/dist/structured_query/ir.js",".././node_modules/@langchain/core/dist/structured_query/utils.js",".././node_modules/@langchain/core/dist/structured_query/base.js",".././node_modules/@langchain/core/dist/structured_query/functional.js",".././node_modules/@langchain/core/dist/structured_query/index.js",".././node_modules/@langchain/core/dist/tools/types.js",".././node_modules/@langchain/core/dist/tools/index.js",".././node_modules/@langchain/core/dist/tracers/run_collector.js",".././node_modules/@langchain/core/dist/types/stream.js",".././node_modules/@langchain/core/dist/utils/chunk_array.js",".././node_modules/@langchain/core/dist/utils/event_source_parse.js",".././node_modules/@langchain/core/dist/utils/function_calling.js",".././node_modules/@langchain/core/dist/utils/ml-distance/similarities.js",".././node_modules/@langchain/core/dist/utils/ml-distance/distances.js",".././node_modules/@langchain/core/dist/utils/ml-distance-euclidean/euclidean.js",".././node_modules/@langchain/core/dist/utils/math.js",".././node_modules/@langchain/core/dist/utils/testing/chat_models.js",".././node_modules/@langchain/core/dist/utils/testing/embeddings.js",".././node_modules/@langchain/core/dist/utils/testing/llms.js",".././node_modules/@langchain/core/dist/utils/testing/message_history.js",".././node_modules/@langchain/core/dist/utils/testing/output_parsers.js",".././node_modules/@langchain/core/dist/utils/testing/retrievers.js",".././node_modules/@langchain/core/dist/utils/testing/runnables.js",".././node_modules/@langchain/core/dist/utils/testing/tools.js",".././node_modules/@langchain/core/dist/utils/testing/tracers.js",".././node_modules/@langchain/core/dist/utils/testing/vectorstores.js",".././node_modules/@langchain/core/dist/utils/testing/index.js",".././node_modules/@langchain/core/dist/utils/types/index.js",".././node_modules/@langchain/core/dist/load/import_map.js",".././node_modules/@langchain/core/dist/load/index.js",".././node_modules/@langchain/langgraph-checkpoint/dist/serde/jsonplus.js",".././node_modules/@langchain/langgraph-checkpoint/dist/base.js",".././node_modules/@langchain/langgraph-checkpoint/dist/memory.js",".././node_modules/@langchain/langgraph-checkpoint/dist/store/base.js",".././node_modules/@langchain/langgraph-checkpoint/dist/store/batch.js",".././node_modules/@langchain/langgraph-checkpoint/dist/store/utils.js",".././node_modules/@langchain/langgraph-checkpoint/dist/store/memory.js",".././node_modules/@langchain/langgraph-checkpoint/dist/cache/base.js",".././node_modules/@langchain/langgraph-checkpoint/dist/cache/memory.js",".././node_modules/@langchain/langgraph-checkpoint/dist/cache/index.js",".././node_modules/@langchain/langgraph-checkpoint/dist/index.js",".././node_modules/@langchain/langgraph/dist/channels/base.js",".././node_modules/@langchain/langgraph/dist/channels/binop.js",".././node_modules/@langchain/langgraph/dist/channels/last_value.js",".././node_modules/@langchain/langgraph/dist/graph/annotation.js",".././node_modules/@langchain/langgraph/dist/constants.js",".././node_modules/@langchain/langgraph/dist/pregel/utils/config.js",".././node_modules/@langchain/langgraph/dist/hash.js",".././node_modules/@langchain/langgraph/dist/interrupt.js",".././node_modules/@langchain/langgraph/dist/utils.js",".././node_modules/@langchain/langgraph/dist/pregel/write.js",".././node_modules/@langchain/langgraph/dist/pregel/read.js",".././node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.js",".././node_modules/@langchain/langgraph/dist/pregel/io.js",".././node_modules/@langchain/langgraph/dist/pregel/utils/index.js",".././node_modules/@langchain/langgraph/dist/pregel/types.js",".././node_modules/@langchain/langgraph/dist/pregel/call.js",".././node_modules/@langchain/langgraph/dist/pregel/algo.js",".././node_modules/@langchain/langgraph/dist/pregel/debug.js",".././node_modules/@langchain/langgraph/dist/pregel/stream.js",".././node_modules/@langchain/langgraph/dist/pregel/loop.js",".././node_modules/@langchain/langgraph/dist/pregel/messages.js",".././node_modules/@langchain/langgraph/dist/pregel/retry.js",".././node_modules/@langchain/langgraph/dist/pregel/runner.js",".././node_modules/@langchain/langgraph/dist/pregel/validate.js",".././node_modules/@langchain/langgraph/dist/channels/topic.js",".././node_modules/@langchain/langgraph/dist/pregel/index.js",".././node_modules/@langchain/langgraph/dist/channels/ephemeral_value.js",".././node_modules/zod/v4/classic/errors.js",".././node_modules/zod/v4/classic/parse.js",".././node_modules/zod/v4/classic/schemas.js",".././node_modules/@langchain/langgraph/node_modules/uuid/wrapper.mjs",".././node_modules/@langchain/langgraph/dist/graph/graph.js",".././node_modules/@langchain/langgraph/dist/channels/named_barrier_value.js",".././node_modules/@langchain/langgraph/dist/graph/zod/meta.js",".././node_modules/@langchain/langgraph/dist/graph/state.js",".././node_modules/@langchain/langgraph/dist/graph/message.js",".././node_modules/@langchain/langgraph/dist/func/index.js",".././node_modules/@langchain/langgraph/dist/graph/messages_annotation.js",".././node_modules/@langchain/langgraph/dist/graph/index.js",".././node_modules/@langchain/langgraph/dist/channels/any_value.js",".././node_modules/@langchain/langgraph/dist/channels/dynamic_barrier_value.js",".././node_modules/@langchain/langgraph/dist/channels/index.js",".././node_modules/@langchain/langgraph/dist/web.js",".././node_modules/@langchain/langgraph/dist/writer.js",".././node_modules/@langchain/langgraph/dist/index.js",".././node_modules/@langchain/anthropic/dist/output_parsers.js",".././node_modules/@langchain/anthropic/dist/utils/tools.js",".././node_modules/@langchain/anthropic/dist/utils/content.js",".././node_modules/@langchain/anthropic/dist/utils/index.js",".././node_modules/@langchain/anthropic/dist/utils/standard.js",".././node_modules/@langchain/anthropic/dist/utils/message_inputs.js",".././node_modules/@langchain/anthropic/dist/utils/message_outputs.js",".././node_modules/@langchain/anthropic/dist/utils/errors.js",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/tslib.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/utils/uuid.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/errors.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/core/error.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/utils/values.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/utils/sleep.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/version.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/detect-platform.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/shims.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/request-options.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/utils/bytes.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/decoders/line.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/utils/log.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/core/streaming.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/parse.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/core/api-promise.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/core/pagination.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/uploads.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/to-file.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/core/uploads.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/core/resource.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/headers.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/utils/path.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/beta/files.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/beta/models.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/decoders/jsonl.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/error.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/beta/messages/batches.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/streaming.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/_vendor/partial-json-parser/parser.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/lib/BetaMessageStream.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/constants.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/lib/tools/BetaToolRunner.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/beta/messages/messages.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/beta/beta.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/completions.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/lib/MessageStream.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/messages/batches.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/messages/messages.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/models.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/resources/index.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/internal/utils/env.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/client.mjs",".././node_modules/@langchain/anthropic/node_modules/@anthropic-ai/sdk/index.mjs",".././node_modules/@langchain/anthropic/dist/chat_models.js",".././node_modules/@langchain/anthropic/dist/utils/prompts.js",".././node_modules/@langchain/anthropic/dist/index.js",".././src/tools/pr-analysis-tools.ts",".././src/agents/base-pr-agent-workflow.ts",".././src/agents/pr-analyzer-agent.ts",".././src/action.ts"],"sourcesContent":["\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return (0, utils_1.toCommandValue)(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return (0, utils_1.toCommandValue)(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.platform = exports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = exports.markdownSummary = exports.summary = exports.getIDToken = exports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.notice = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\nconst oidc_utils_1 = require(\"./oidc-utils\");\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode || (exports.ExitCode = ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = (0, utils_1.toCommandValue)(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        return (0, file_command_1.issueFileCommand)('ENV', (0, file_command_1.prepareKeyValueMessage)(name, val));\n    }\n    (0, command_1.issueCommand)('set-env', { name }, convertedVal);\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    (0, command_1.issueCommand)('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        (0, file_command_1.issueFileCommand)('PATH', inputPath);\n    }\n    else {\n        (0, command_1.issueCommand)('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    if (options && options.trimWhitespace === false) {\n        return inputs;\n    }\n    return inputs.map(input => input.trim());\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    const filePath = process.env['GITHUB_OUTPUT'] || '';\n    if (filePath) {\n        return (0, file_command_1.issueFileCommand)('OUTPUT', (0, file_command_1.prepareKeyValueMessage)(name, value));\n    }\n    process.stdout.write(os.EOL);\n    (0, command_1.issueCommand)('set-output', { name }, (0, utils_1.toCommandValue)(value));\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    (0, command_1.issue)('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    (0, command_1.issueCommand)('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction error(message, properties = {}) {\n    (0, command_1.issueCommand)('error', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds a warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction warning(message, properties = {}) {\n    (0, command_1.issueCommand)('warning', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Adds a notice issue\n * @param message notice issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction notice(message, properties = {}) {\n    (0, command_1.issueCommand)('notice', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);\n}\nexports.notice = notice;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    (0, command_1.issue)('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    (0, command_1.issue)('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    const filePath = process.env['GITHUB_STATE'] || '';\n    if (filePath) {\n        return (0, file_command_1.issueFileCommand)('STATE', (0, file_command_1.prepareKeyValueMessage)(name, value));\n    }\n    (0, command_1.issueCommand)('save-state', { name }, (0, utils_1.toCommandValue)(value));\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\nfunction getIDToken(aud) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return yield oidc_utils_1.OidcClient.getIDToken(aud);\n    });\n}\nexports.getIDToken = getIDToken;\n/**\n * Summary exports\n */\nvar summary_1 = require(\"./summary\");\nObject.defineProperty(exports, \"summary\", { enumerable: true, get: function () { return summary_1.summary; } });\n/**\n * @deprecated use core.summary\n */\nvar summary_2 = require(\"./summary\");\nObject.defineProperty(exports, \"markdownSummary\", { enumerable: true, get: function () { return summary_2.markdownSummary; } });\n/**\n * Path exports\n */\nvar path_utils_1 = require(\"./path-utils\");\nObject.defineProperty(exports, \"toPosixPath\", { enumerable: true, get: function () { return path_utils_1.toPosixPath; } });\nObject.defineProperty(exports, \"toWin32Path\", { enumerable: true, get: function () { return path_utils_1.toWin32Path; } });\nObject.defineProperty(exports, \"toPlatformPath\", { enumerable: true, get: function () { return path_utils_1.toPlatformPath; } });\n/**\n * Platform utilities exports\n */\nexports.platform = __importStar(require(\"./platform\"));\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.prepareKeyValueMessage = exports.issueFileCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst crypto = __importStar(require(\"crypto\"));\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\nfunction issueFileCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${(0, utils_1.toCommandValue)(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueFileCommand = issueFileCommand;\nfunction prepareKeyValueMessage(key, value) {\n    const delimiter = `ghadelimiter_${crypto.randomUUID()}`;\n    const convertedValue = (0, utils_1.toCommandValue)(value);\n    // These should realistically never happen, but just in case someone finds a\n    // way to exploit uuid generation let's not allow keys or values that contain\n    // the delimiter.\n    if (key.includes(delimiter)) {\n        throw new Error(`Unexpected input: name should not contain the delimiter \"${delimiter}\"`);\n    }\n    if (convertedValue.includes(delimiter)) {\n        throw new Error(`Unexpected input: value should not contain the delimiter \"${delimiter}\"`);\n    }\n    return `${key}<<${delimiter}${os.EOL}${convertedValue}${os.EOL}${delimiter}`;\n}\nexports.prepareKeyValueMessage = prepareKeyValueMessage;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.OidcClient = void 0;\nconst http_client_1 = require(\"@actions/http-client\");\nconst auth_1 = require(\"@actions/http-client/lib/auth\");\nconst core_1 = require(\"./core\");\nclass OidcClient {\n    static createHttpClient(allowRetry = true, maxRetry = 10) {\n        const requestOptions = {\n            allowRetries: allowRetry,\n            maxRetries: maxRetry\n        };\n        return new http_client_1.HttpClient('actions/oidc-client', [new auth_1.BearerCredentialHandler(OidcClient.getRequestToken())], requestOptions);\n    }\n    static getRequestToken() {\n        const token = process.env['ACTIONS_ID_TOKEN_REQUEST_TOKEN'];\n        if (!token) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_TOKEN env variable');\n        }\n        return token;\n    }\n    static getIDTokenUrl() {\n        const runtimeUrl = process.env['ACTIONS_ID_TOKEN_REQUEST_URL'];\n        if (!runtimeUrl) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable');\n        }\n        return runtimeUrl;\n    }\n    static getCall(id_token_url) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            const httpclient = OidcClient.createHttpClient();\n            const res = yield httpclient\n                .getJson(id_token_url)\n                .catch(error => {\n                throw new Error(`Failed to get ID Token. \\n \n        Error Code : ${error.statusCode}\\n \n        Error Message: ${error.message}`);\n            });\n            const id_token = (_a = res.result) === null || _a === void 0 ? void 0 : _a.value;\n            if (!id_token) {\n                throw new Error('Response json body do not have ID Token field');\n            }\n            return id_token;\n        });\n    }\n    static getIDToken(audience) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // New ID Token is requested from action service\n                let id_token_url = OidcClient.getIDTokenUrl();\n                if (audience) {\n                    const encodedAudience = encodeURIComponent(audience);\n                    id_token_url = `${id_token_url}&audience=${encodedAudience}`;\n                }\n                (0, core_1.debug)(`ID token url is ${id_token_url}`);\n                const id_token = yield OidcClient.getCall(id_token_url);\n                (0, core_1.setSecret)(id_token);\n                return id_token;\n            }\n            catch (error) {\n                throw new Error(`Error message: ${error.message}`);\n            }\n        });\n    }\n}\nexports.OidcClient = OidcClient;\n//# sourceMappingURL=oidc-utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = void 0;\nconst path = __importStar(require(\"path\"));\n/**\n * toPosixPath converts the given path to the posix form. On Windows, \\\\ will be\n * replaced with /.\n *\n * @param pth. Path to transform.\n * @return string Posix path.\n */\nfunction toPosixPath(pth) {\n    return pth.replace(/[\\\\]/g, '/');\n}\nexports.toPosixPath = toPosixPath;\n/**\n * toWin32Path converts the given path to the win32 form. On Linux, / will be\n * replaced with \\\\.\n *\n * @param pth. Path to transform.\n * @return string Win32 path.\n */\nfunction toWin32Path(pth) {\n    return pth.replace(/[/]/g, '\\\\');\n}\nexports.toWin32Path = toWin32Path;\n/**\n * toPlatformPath converts the given path to a platform-specific path. It does\n * this by replacing instances of / and \\ with the platform-specific path\n * separator.\n *\n * @param pth The path to platformize.\n * @return string The platform-specific path.\n */\nfunction toPlatformPath(pth) {\n    return pth.replace(/[/\\\\]/g, path.sep);\n}\nexports.toPlatformPath = toPlatformPath;\n//# sourceMappingURL=path-utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getDetails = exports.isLinux = exports.isMacOS = exports.isWindows = exports.arch = exports.platform = void 0;\nconst os_1 = __importDefault(require(\"os\"));\nconst exec = __importStar(require(\"@actions/exec\"));\nconst getWindowsInfo = () => __awaiter(void 0, void 0, void 0, function* () {\n    const { stdout: version } = yield exec.getExecOutput('powershell -command \"(Get-CimInstance -ClassName Win32_OperatingSystem).Version\"', undefined, {\n        silent: true\n    });\n    const { stdout: name } = yield exec.getExecOutput('powershell -command \"(Get-CimInstance -ClassName Win32_OperatingSystem).Caption\"', undefined, {\n        silent: true\n    });\n    return {\n        name: name.trim(),\n        version: version.trim()\n    };\n});\nconst getMacOsInfo = () => __awaiter(void 0, void 0, void 0, function* () {\n    var _a, _b, _c, _d;\n    const { stdout } = yield exec.getExecOutput('sw_vers', undefined, {\n        silent: true\n    });\n    const version = (_b = (_a = stdout.match(/ProductVersion:\\s*(.+)/)) === null || _a === void 0 ? void 0 : _a[1]) !== null && _b !== void 0 ? _b : '';\n    const name = (_d = (_c = stdout.match(/ProductName:\\s*(.+)/)) === null || _c === void 0 ? void 0 : _c[1]) !== null && _d !== void 0 ? _d : '';\n    return {\n        name,\n        version\n    };\n});\nconst getLinuxInfo = () => __awaiter(void 0, void 0, void 0, function* () {\n    const { stdout } = yield exec.getExecOutput('lsb_release', ['-i', '-r', '-s'], {\n        silent: true\n    });\n    const [name, version] = stdout.trim().split('\\n');\n    return {\n        name,\n        version\n    };\n});\nexports.platform = os_1.default.platform();\nexports.arch = os_1.default.arch();\nexports.isWindows = exports.platform === 'win32';\nexports.isMacOS = exports.platform === 'darwin';\nexports.isLinux = exports.platform === 'linux';\nfunction getDetails() {\n    return __awaiter(this, void 0, void 0, function* () {\n        return Object.assign(Object.assign({}, (yield (exports.isWindows\n            ? getWindowsInfo()\n            : exports.isMacOS\n                ? getMacOsInfo()\n                : getLinuxInfo()))), { platform: exports.platform,\n            arch: exports.arch,\n            isWindows: exports.isWindows,\n            isMacOS: exports.isMacOS,\n            isLinux: exports.isLinux });\n    });\n}\nexports.getDetails = getDetails;\n//# sourceMappingURL=platform.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.summary = exports.markdownSummary = exports.SUMMARY_DOCS_URL = exports.SUMMARY_ENV_VAR = void 0;\nconst os_1 = require(\"os\");\nconst fs_1 = require(\"fs\");\nconst { access, appendFile, writeFile } = fs_1.promises;\nexports.SUMMARY_ENV_VAR = 'GITHUB_STEP_SUMMARY';\nexports.SUMMARY_DOCS_URL = 'https://docs.github.com/actions/using-workflows/workflow-commands-for-github-actions#adding-a-job-summary';\nclass Summary {\n    constructor() {\n        this._buffer = '';\n    }\n    /**\n     * Finds the summary file path from the environment, rejects if env var is not found or file does not exist\n     * Also checks r/w permissions.\n     *\n     * @returns step summary file path\n     */\n    filePath() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._filePath) {\n                return this._filePath;\n            }\n            const pathFromEnv = process.env[exports.SUMMARY_ENV_VAR];\n            if (!pathFromEnv) {\n                throw new Error(`Unable to find environment variable for $${exports.SUMMARY_ENV_VAR}. Check if your runtime environment supports job summaries.`);\n            }\n            try {\n                yield access(pathFromEnv, fs_1.constants.R_OK | fs_1.constants.W_OK);\n            }\n            catch (_a) {\n                throw new Error(`Unable to access summary file: '${pathFromEnv}'. Check if the file has correct read/write permissions.`);\n            }\n            this._filePath = pathFromEnv;\n            return this._filePath;\n        });\n    }\n    /**\n     * Wraps content in an HTML tag, adding any HTML attributes\n     *\n     * @param {string} tag HTML tag to wrap\n     * @param {string | null} content content within the tag\n     * @param {[attribute: string]: string} attrs key-value list of HTML attributes to add\n     *\n     * @returns {string} content wrapped in HTML element\n     */\n    wrap(tag, content, attrs = {}) {\n        const htmlAttrs = Object.entries(attrs)\n            .map(([key, value]) => ` ${key}=\"${value}\"`)\n            .join('');\n        if (!content) {\n            return `<${tag}${htmlAttrs}>`;\n        }\n        return `<${tag}${htmlAttrs}>${content}</${tag}>`;\n    }\n    /**\n     * Writes text in the buffer to the summary buffer file and empties buffer. Will append by default.\n     *\n     * @param {SummaryWriteOptions} [options] (optional) options for write operation\n     *\n     * @returns {Promise<Summary>} summary instance\n     */\n    write(options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const overwrite = !!(options === null || options === void 0 ? void 0 : options.overwrite);\n            const filePath = yield this.filePath();\n            const writeFunc = overwrite ? writeFile : appendFile;\n            yield writeFunc(filePath, this._buffer, { encoding: 'utf8' });\n            return this.emptyBuffer();\n        });\n    }\n    /**\n     * Clears the summary buffer and wipes the summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    clear() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.emptyBuffer().write({ overwrite: true });\n        });\n    }\n    /**\n     * Returns the current summary buffer as a string\n     *\n     * @returns {string} string of summary buffer\n     */\n    stringify() {\n        return this._buffer;\n    }\n    /**\n     * If the summary buffer is empty\n     *\n     * @returns {boolen} true if the buffer is empty\n     */\n    isEmptyBuffer() {\n        return this._buffer.length === 0;\n    }\n    /**\n     * Resets the summary buffer without writing to summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    emptyBuffer() {\n        this._buffer = '';\n        return this;\n    }\n    /**\n     * Adds raw text to the summary buffer\n     *\n     * @param {string} text content to add\n     * @param {boolean} [addEOL=false] (optional) append an EOL to the raw text (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addRaw(text, addEOL = false) {\n        this._buffer += text;\n        return addEOL ? this.addEOL() : this;\n    }\n    /**\n     * Adds the operating system-specific end-of-line marker to the buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addEOL() {\n        return this.addRaw(os_1.EOL);\n    }\n    /**\n     * Adds an HTML codeblock to the summary buffer\n     *\n     * @param {string} code content to render within fenced code block\n     * @param {string} lang (optional) language to syntax highlight code\n     *\n     * @returns {Summary} summary instance\n     */\n    addCodeBlock(code, lang) {\n        const attrs = Object.assign({}, (lang && { lang }));\n        const element = this.wrap('pre', this.wrap('code', code), attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML list to the summary buffer\n     *\n     * @param {string[]} items list of items to render\n     * @param {boolean} [ordered=false] (optional) if the rendered list should be ordered or not (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addList(items, ordered = false) {\n        const tag = ordered ? 'ol' : 'ul';\n        const listItems = items.map(item => this.wrap('li', item)).join('');\n        const element = this.wrap(tag, listItems);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML table to the summary buffer\n     *\n     * @param {SummaryTableCell[]} rows table rows\n     *\n     * @returns {Summary} summary instance\n     */\n    addTable(rows) {\n        const tableBody = rows\n            .map(row => {\n            const cells = row\n                .map(cell => {\n                if (typeof cell === 'string') {\n                    return this.wrap('td', cell);\n                }\n                const { header, data, colspan, rowspan } = cell;\n                const tag = header ? 'th' : 'td';\n                const attrs = Object.assign(Object.assign({}, (colspan && { colspan })), (rowspan && { rowspan }));\n                return this.wrap(tag, data, attrs);\n            })\n                .join('');\n            return this.wrap('tr', cells);\n        })\n            .join('');\n        const element = this.wrap('table', tableBody);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds a collapsable HTML details element to the summary buffer\n     *\n     * @param {string} label text for the closed state\n     * @param {string} content collapsable content\n     *\n     * @returns {Summary} summary instance\n     */\n    addDetails(label, content) {\n        const element = this.wrap('details', this.wrap('summary', label) + content);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML image tag to the summary buffer\n     *\n     * @param {string} src path to the image you to embed\n     * @param {string} alt text description of the image\n     * @param {SummaryImageOptions} options (optional) addition image attributes\n     *\n     * @returns {Summary} summary instance\n     */\n    addImage(src, alt, options) {\n        const { width, height } = options || {};\n        const attrs = Object.assign(Object.assign({}, (width && { width })), (height && { height }));\n        const element = this.wrap('img', null, Object.assign({ src, alt }, attrs));\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML section heading element\n     *\n     * @param {string} text heading text\n     * @param {number | string} [level=1] (optional) the heading level, default: 1\n     *\n     * @returns {Summary} summary instance\n     */\n    addHeading(text, level) {\n        const tag = `h${level}`;\n        const allowedTag = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6'].includes(tag)\n            ? tag\n            : 'h1';\n        const element = this.wrap(allowedTag, text);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML thematic break (<hr>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addSeparator() {\n        const element = this.wrap('hr', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML line break (<br>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addBreak() {\n        const element = this.wrap('br', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML blockquote to the summary buffer\n     *\n     * @param {string} text quote text\n     * @param {string} cite (optional) citation url\n     *\n     * @returns {Summary} summary instance\n     */\n    addQuote(text, cite) {\n        const attrs = Object.assign({}, (cite && { cite }));\n        const element = this.wrap('blockquote', text, attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML anchor tag to the summary buffer\n     *\n     * @param {string} text link text/content\n     * @param {string} href hyperlink\n     *\n     * @returns {Summary} summary instance\n     */\n    addLink(text, href) {\n        const element = this.wrap('a', text, { href });\n        return this.addRaw(element).addEOL();\n    }\n}\nconst _summary = new Summary();\n/**\n * @deprecated use `core.summary`\n */\nexports.markdownSummary = _summary;\nexports.summary = _summary;\n//# sourceMappingURL=summary.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandProperties = exports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n/**\n *\n * @param annotationProperties\n * @returns The command properties to send with the actual annotation command\n * See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646\n */\nfunction toCommandProperties(annotationProperties) {\n    if (!Object.keys(annotationProperties).length) {\n        return {};\n    }\n    return {\n        title: annotationProperties.title,\n        file: annotationProperties.file,\n        line: annotationProperties.startLine,\n        endLine: annotationProperties.endLine,\n        col: annotationProperties.startColumn,\n        endColumn: annotationProperties.endColumn\n    };\n}\nexports.toCommandProperties = toCommandProperties;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getExecOutput = exports.exec = void 0;\nconst string_decoder_1 = require(\"string_decoder\");\nconst tr = __importStar(require(\"./toolrunner\"));\n/**\n * Exec a command.\n * Output will be streamed to the live console.\n * Returns promise with return code\n *\n * @param     commandLine        command to execute (can include additional args). Must be correctly escaped.\n * @param     args               optional arguments for tool. Escaping is handled by the lib.\n * @param     options            optional exec options.  See ExecOptions\n * @returns   Promise<number>    exit code\n */\nfunction exec(commandLine, args, options) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const commandArgs = tr.argStringToArray(commandLine);\n        if (commandArgs.length === 0) {\n            throw new Error(`Parameter 'commandLine' cannot be null or empty.`);\n        }\n        // Path to tool to execute should be first arg\n        const toolPath = commandArgs[0];\n        args = commandArgs.slice(1).concat(args || []);\n        const runner = new tr.ToolRunner(toolPath, args, options);\n        return runner.exec();\n    });\n}\nexports.exec = exec;\n/**\n * Exec a command and get the output.\n * Output will be streamed to the live console.\n * Returns promise with the exit code and collected stdout and stderr\n *\n * @param     commandLine           command to execute (can include additional args). Must be correctly escaped.\n * @param     args                  optional arguments for tool. Escaping is handled by the lib.\n * @param     options               optional exec options.  See ExecOptions\n * @returns   Promise<ExecOutput>   exit code, stdout, and stderr\n */\nfunction getExecOutput(commandLine, args, options) {\n    var _a, _b;\n    return __awaiter(this, void 0, void 0, function* () {\n        let stdout = '';\n        let stderr = '';\n        //Using string decoder covers the case where a mult-byte character is split\n        const stdoutDecoder = new string_decoder_1.StringDecoder('utf8');\n        const stderrDecoder = new string_decoder_1.StringDecoder('utf8');\n        const originalStdoutListener = (_a = options === null || options === void 0 ? void 0 : options.listeners) === null || _a === void 0 ? void 0 : _a.stdout;\n        const originalStdErrListener = (_b = options === null || options === void 0 ? void 0 : options.listeners) === null || _b === void 0 ? void 0 : _b.stderr;\n        const stdErrListener = (data) => {\n            stderr += stderrDecoder.write(data);\n            if (originalStdErrListener) {\n                originalStdErrListener(data);\n            }\n        };\n        const stdOutListener = (data) => {\n            stdout += stdoutDecoder.write(data);\n            if (originalStdoutListener) {\n                originalStdoutListener(data);\n            }\n        };\n        const listeners = Object.assign(Object.assign({}, options === null || options === void 0 ? void 0 : options.listeners), { stdout: stdOutListener, stderr: stdErrListener });\n        const exitCode = yield exec(commandLine, args, Object.assign(Object.assign({}, options), { listeners }));\n        //flush any remaining characters\n        stdout += stdoutDecoder.end();\n        stderr += stderrDecoder.end();\n        return {\n            exitCode,\n            stdout,\n            stderr\n        };\n    });\n}\nexports.getExecOutput = getExecOutput;\n//# sourceMappingURL=exec.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.argStringToArray = exports.ToolRunner = void 0;\nconst os = __importStar(require(\"os\"));\nconst events = __importStar(require(\"events\"));\nconst child = __importStar(require(\"child_process\"));\nconst path = __importStar(require(\"path\"));\nconst io = __importStar(require(\"@actions/io\"));\nconst ioUtil = __importStar(require(\"@actions/io/lib/io-util\"));\nconst timers_1 = require(\"timers\");\n/* eslint-disable @typescript-eslint/unbound-method */\nconst IS_WINDOWS = process.platform === 'win32';\n/*\n * Class for running command line tools. Handles quoting and arg parsing in a platform agnostic way.\n */\nclass ToolRunner extends events.EventEmitter {\n    constructor(toolPath, args, options) {\n        super();\n        if (!toolPath) {\n            throw new Error(\"Parameter 'toolPath' cannot be null or empty.\");\n        }\n        this.toolPath = toolPath;\n        this.args = args || [];\n        this.options = options || {};\n    }\n    _debug(message) {\n        if (this.options.listeners && this.options.listeners.debug) {\n            this.options.listeners.debug(message);\n        }\n    }\n    _getCommandString(options, noPrefix) {\n        const toolPath = this._getSpawnFileName();\n        const args = this._getSpawnArgs(options);\n        let cmd = noPrefix ? '' : '[command]'; // omit prefix when piped to a second tool\n        if (IS_WINDOWS) {\n            // Windows + cmd file\n            if (this._isCmdFile()) {\n                cmd += toolPath;\n                for (const a of args) {\n                    cmd += ` ${a}`;\n                }\n            }\n            // Windows + verbatim\n            else if (options.windowsVerbatimArguments) {\n                cmd += `\"${toolPath}\"`;\n                for (const a of args) {\n                    cmd += ` ${a}`;\n                }\n            }\n            // Windows (regular)\n            else {\n                cmd += this._windowsQuoteCmdArg(toolPath);\n                for (const a of args) {\n                    cmd += ` ${this._windowsQuoteCmdArg(a)}`;\n                }\n            }\n        }\n        else {\n            // OSX/Linux - this can likely be improved with some form of quoting.\n            // creating processes on Unix is fundamentally different than Windows.\n            // on Unix, execvp() takes an arg array.\n            cmd += toolPath;\n            for (const a of args) {\n                cmd += ` ${a}`;\n            }\n        }\n        return cmd;\n    }\n    _processLineBuffer(data, strBuffer, onLine) {\n        try {\n            let s = strBuffer + data.toString();\n            let n = s.indexOf(os.EOL);\n            while (n > -1) {\n                const line = s.substring(0, n);\n                onLine(line);\n                // the rest of the string ...\n                s = s.substring(n + os.EOL.length);\n                n = s.indexOf(os.EOL);\n            }\n            return s;\n        }\n        catch (err) {\n            // streaming lines to console is best effort.  Don't fail a build.\n            this._debug(`error processing line. Failed with error ${err}`);\n            return '';\n        }\n    }\n    _getSpawnFileName() {\n        if (IS_WINDOWS) {\n            if (this._isCmdFile()) {\n                return process.env['COMSPEC'] || 'cmd.exe';\n            }\n        }\n        return this.toolPath;\n    }\n    _getSpawnArgs(options) {\n        if (IS_WINDOWS) {\n            if (this._isCmdFile()) {\n                let argline = `/D /S /C \"${this._windowsQuoteCmdArg(this.toolPath)}`;\n                for (const a of this.args) {\n                    argline += ' ';\n                    argline += options.windowsVerbatimArguments\n                        ? a\n                        : this._windowsQuoteCmdArg(a);\n                }\n                argline += '\"';\n                return [argline];\n            }\n        }\n        return this.args;\n    }\n    _endsWith(str, end) {\n        return str.endsWith(end);\n    }\n    _isCmdFile() {\n        const upperToolPath = this.toolPath.toUpperCase();\n        return (this._endsWith(upperToolPath, '.CMD') ||\n            this._endsWith(upperToolPath, '.BAT'));\n    }\n    _windowsQuoteCmdArg(arg) {\n        // for .exe, apply the normal quoting rules that libuv applies\n        if (!this._isCmdFile()) {\n            return this._uvQuoteCmdArg(arg);\n        }\n        // otherwise apply quoting rules specific to the cmd.exe command line parser.\n        // the libuv rules are generic and are not designed specifically for cmd.exe\n        // command line parser.\n        //\n        // for a detailed description of the cmd.exe command line parser, refer to\n        // http://stackoverflow.com/questions/4094699/how-does-the-windows-command-interpreter-cmd-exe-parse-scripts/7970912#7970912\n        // need quotes for empty arg\n        if (!arg) {\n            return '\"\"';\n        }\n        // determine whether the arg needs to be quoted\n        const cmdSpecialChars = [\n            ' ',\n            '\\t',\n            '&',\n            '(',\n            ')',\n            '[',\n            ']',\n            '{',\n            '}',\n            '^',\n            '=',\n            ';',\n            '!',\n            \"'\",\n            '+',\n            ',',\n            '`',\n            '~',\n            '|',\n            '<',\n            '>',\n            '\"'\n        ];\n        let needsQuotes = false;\n        for (const char of arg) {\n            if (cmdSpecialChars.some(x => x === char)) {\n                needsQuotes = true;\n                break;\n            }\n        }\n        // short-circuit if quotes not needed\n        if (!needsQuotes) {\n            return arg;\n        }\n        // the following quoting rules are very similar to the rules that by libuv applies.\n        //\n        // 1) wrap the string in quotes\n        //\n        // 2) double-up quotes - i.e. \" => \"\"\n        //\n        //    this is different from the libuv quoting rules. libuv replaces \" with \\\", which unfortunately\n        //    doesn't work well with a cmd.exe command line.\n        //\n        //    note, replacing \" with \"\" also works well if the arg is passed to a downstream .NET console app.\n        //    for example, the command line:\n        //          foo.exe \"myarg:\"\"my val\"\"\"\n        //    is parsed by a .NET console app into an arg array:\n        //          [ \"myarg:\\\"my val\\\"\" ]\n        //    which is the same end result when applying libuv quoting rules. although the actual\n        //    command line from libuv quoting rules would look like:\n        //          foo.exe \"myarg:\\\"my val\\\"\"\n        //\n        // 3) double-up slashes that precede a quote,\n        //    e.g.  hello \\world    => \"hello \\world\"\n        //          hello\\\"world    => \"hello\\\\\"\"world\"\n        //          hello\\\\\"world   => \"hello\\\\\\\\\"\"world\"\n        //          hello world\\    => \"hello world\\\\\"\n        //\n        //    technically this is not required for a cmd.exe command line, or the batch argument parser.\n        //    the reasons for including this as a .cmd quoting rule are:\n        //\n        //    a) this is optimized for the scenario where the argument is passed from the .cmd file to an\n        //       external program. many programs (e.g. .NET console apps) rely on the slash-doubling rule.\n        //\n        //    b) it's what we've been doing previously (by deferring to node default behavior) and we\n        //       haven't heard any complaints about that aspect.\n        //\n        // note, a weakness of the quoting rules chosen here, is that % is not escaped. in fact, % cannot be\n        // escaped when used on the command line directly - even though within a .cmd file % can be escaped\n        // by using %%.\n        //\n        // the saving grace is, on the command line, %var% is left as-is if var is not defined. this contrasts\n        // the line parsing rules within a .cmd file, where if var is not defined it is replaced with nothing.\n        //\n        // one option that was explored was replacing % with ^% - i.e. %var% => ^%var^%. this hack would\n        // often work, since it is unlikely that var^ would exist, and the ^ character is removed when the\n        // variable is used. the problem, however, is that ^ is not removed when %* is used to pass the args\n        // to an external program.\n        //\n        // an unexplored potential solution for the % escaping problem, is to create a wrapper .cmd file.\n        // % can be escaped within a .cmd file.\n        let reverse = '\"';\n        let quoteHit = true;\n        for (let i = arg.length; i > 0; i--) {\n            // walk the string in reverse\n            reverse += arg[i - 1];\n            if (quoteHit && arg[i - 1] === '\\\\') {\n                reverse += '\\\\'; // double the slash\n            }\n            else if (arg[i - 1] === '\"') {\n                quoteHit = true;\n                reverse += '\"'; // double the quote\n            }\n            else {\n                quoteHit = false;\n            }\n        }\n        reverse += '\"';\n        return reverse\n            .split('')\n            .reverse()\n            .join('');\n    }\n    _uvQuoteCmdArg(arg) {\n        // Tool runner wraps child_process.spawn() and needs to apply the same quoting as\n        // Node in certain cases where the undocumented spawn option windowsVerbatimArguments\n        // is used.\n        //\n        // Since this function is a port of quote_cmd_arg from Node 4.x (technically, lib UV,\n        // see https://github.com/nodejs/node/blob/v4.x/deps/uv/src/win/process.c for details),\n        // pasting copyright notice from Node within this function:\n        //\n        //      Copyright Joyent, Inc. and other Node contributors. All rights reserved.\n        //\n        //      Permission is hereby granted, free of charge, to any person obtaining a copy\n        //      of this software and associated documentation files (the \"Software\"), to\n        //      deal in the Software without restriction, including without limitation the\n        //      rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n        //      sell copies of the Software, and to permit persons to whom the Software is\n        //      furnished to do so, subject to the following conditions:\n        //\n        //      The above copyright notice and this permission notice shall be included in\n        //      all copies or substantial portions of the Software.\n        //\n        //      THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n        //      IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n        //      FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n        //      AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n        //      LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n        //      FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n        //      IN THE SOFTWARE.\n        if (!arg) {\n            // Need double quotation for empty argument\n            return '\"\"';\n        }\n        if (!arg.includes(' ') && !arg.includes('\\t') && !arg.includes('\"')) {\n            // No quotation needed\n            return arg;\n        }\n        if (!arg.includes('\"') && !arg.includes('\\\\')) {\n            // No embedded double quotes or backslashes, so I can just wrap\n            // quote marks around the whole thing.\n            return `\"${arg}\"`;\n        }\n        // Expected input/output:\n        //   input : hello\"world\n        //   output: \"hello\\\"world\"\n        //   input : hello\"\"world\n        //   output: \"hello\\\"\\\"world\"\n        //   input : hello\\world\n        //   output: hello\\world\n        //   input : hello\\\\world\n        //   output: hello\\\\world\n        //   input : hello\\\"world\n        //   output: \"hello\\\\\\\"world\"\n        //   input : hello\\\\\"world\n        //   output: \"hello\\\\\\\\\\\"world\"\n        //   input : hello world\\\n        //   output: \"hello world\\\\\" - note the comment in libuv actually reads \"hello world\\\"\n        //                             but it appears the comment is wrong, it should be \"hello world\\\\\"\n        let reverse = '\"';\n        let quoteHit = true;\n        for (let i = arg.length; i > 0; i--) {\n            // walk the string in reverse\n            reverse += arg[i - 1];\n            if (quoteHit && arg[i - 1] === '\\\\') {\n                reverse += '\\\\';\n            }\n            else if (arg[i - 1] === '\"') {\n                quoteHit = true;\n                reverse += '\\\\';\n            }\n            else {\n                quoteHit = false;\n            }\n        }\n        reverse += '\"';\n        return reverse\n            .split('')\n            .reverse()\n            .join('');\n    }\n    _cloneExecOptions(options) {\n        options = options || {};\n        const result = {\n            cwd: options.cwd || process.cwd(),\n            env: options.env || process.env,\n            silent: options.silent || false,\n            windowsVerbatimArguments: options.windowsVerbatimArguments || false,\n            failOnStdErr: options.failOnStdErr || false,\n            ignoreReturnCode: options.ignoreReturnCode || false,\n            delay: options.delay || 10000\n        };\n        result.outStream = options.outStream || process.stdout;\n        result.errStream = options.errStream || process.stderr;\n        return result;\n    }\n    _getSpawnOptions(options, toolPath) {\n        options = options || {};\n        const result = {};\n        result.cwd = options.cwd;\n        result.env = options.env;\n        result['windowsVerbatimArguments'] =\n            options.windowsVerbatimArguments || this._isCmdFile();\n        if (options.windowsVerbatimArguments) {\n            result.argv0 = `\"${toolPath}\"`;\n        }\n        return result;\n    }\n    /**\n     * Exec a tool.\n     * Output will be streamed to the live console.\n     * Returns promise with return code\n     *\n     * @param     tool     path to tool to exec\n     * @param     options  optional exec options.  See ExecOptions\n     * @returns   number\n     */\n    exec() {\n        return __awaiter(this, void 0, void 0, function* () {\n            // root the tool path if it is unrooted and contains relative pathing\n            if (!ioUtil.isRooted(this.toolPath) &&\n                (this.toolPath.includes('/') ||\n                    (IS_WINDOWS && this.toolPath.includes('\\\\')))) {\n                // prefer options.cwd if it is specified, however options.cwd may also need to be rooted\n                this.toolPath = path.resolve(process.cwd(), this.options.cwd || process.cwd(), this.toolPath);\n            }\n            // if the tool is only a file name, then resolve it from the PATH\n            // otherwise verify it exists (add extension on Windows if necessary)\n            this.toolPath = yield io.which(this.toolPath, true);\n            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {\n                this._debug(`exec tool: ${this.toolPath}`);\n                this._debug('arguments:');\n                for (const arg of this.args) {\n                    this._debug(`   ${arg}`);\n                }\n                const optionsNonNull = this._cloneExecOptions(this.options);\n                if (!optionsNonNull.silent && optionsNonNull.outStream) {\n                    optionsNonNull.outStream.write(this._getCommandString(optionsNonNull) + os.EOL);\n                }\n                const state = new ExecState(optionsNonNull, this.toolPath);\n                state.on('debug', (message) => {\n                    this._debug(message);\n                });\n                if (this.options.cwd && !(yield ioUtil.exists(this.options.cwd))) {\n                    return reject(new Error(`The cwd: ${this.options.cwd} does not exist!`));\n                }\n                const fileName = this._getSpawnFileName();\n                const cp = child.spawn(fileName, this._getSpawnArgs(optionsNonNull), this._getSpawnOptions(this.options, fileName));\n                let stdbuffer = '';\n                if (cp.stdout) {\n                    cp.stdout.on('data', (data) => {\n                        if (this.options.listeners && this.options.listeners.stdout) {\n                            this.options.listeners.stdout(data);\n                        }\n                        if (!optionsNonNull.silent && optionsNonNull.outStream) {\n                            optionsNonNull.outStream.write(data);\n                        }\n                        stdbuffer = this._processLineBuffer(data, stdbuffer, (line) => {\n                            if (this.options.listeners && this.options.listeners.stdline) {\n                                this.options.listeners.stdline(line);\n                            }\n                        });\n                    });\n                }\n                let errbuffer = '';\n                if (cp.stderr) {\n                    cp.stderr.on('data', (data) => {\n                        state.processStderr = true;\n                        if (this.options.listeners && this.options.listeners.stderr) {\n                            this.options.listeners.stderr(data);\n                        }\n                        if (!optionsNonNull.silent &&\n                            optionsNonNull.errStream &&\n                            optionsNonNull.outStream) {\n                            const s = optionsNonNull.failOnStdErr\n                                ? optionsNonNull.errStream\n                                : optionsNonNull.outStream;\n                            s.write(data);\n                        }\n                        errbuffer = this._processLineBuffer(data, errbuffer, (line) => {\n                            if (this.options.listeners && this.options.listeners.errline) {\n                                this.options.listeners.errline(line);\n                            }\n                        });\n                    });\n                }\n                cp.on('error', (err) => {\n                    state.processError = err.message;\n                    state.processExited = true;\n                    state.processClosed = true;\n                    state.CheckComplete();\n                });\n                cp.on('exit', (code) => {\n                    state.processExitCode = code;\n                    state.processExited = true;\n                    this._debug(`Exit code ${code} received from tool '${this.toolPath}'`);\n                    state.CheckComplete();\n                });\n                cp.on('close', (code) => {\n                    state.processExitCode = code;\n                    state.processExited = true;\n                    state.processClosed = true;\n                    this._debug(`STDIO streams have closed for tool '${this.toolPath}'`);\n                    state.CheckComplete();\n                });\n                state.on('done', (error, exitCode) => {\n                    if (stdbuffer.length > 0) {\n                        this.emit('stdline', stdbuffer);\n                    }\n                    if (errbuffer.length > 0) {\n                        this.emit('errline', errbuffer);\n                    }\n                    cp.removeAllListeners();\n                    if (error) {\n                        reject(error);\n                    }\n                    else {\n                        resolve(exitCode);\n                    }\n                });\n                if (this.options.input) {\n                    if (!cp.stdin) {\n                        throw new Error('child process missing stdin');\n                    }\n                    cp.stdin.end(this.options.input);\n                }\n            }));\n        });\n    }\n}\nexports.ToolRunner = ToolRunner;\n/**\n * Convert an arg string to an array of args. Handles escaping\n *\n * @param    argString   string of arguments\n * @returns  string[]    array of arguments\n */\nfunction argStringToArray(argString) {\n    const args = [];\n    let inQuotes = false;\n    let escaped = false;\n    let arg = '';\n    function append(c) {\n        // we only escape double quotes.\n        if (escaped && c !== '\"') {\n            arg += '\\\\';\n        }\n        arg += c;\n        escaped = false;\n    }\n    for (let i = 0; i < argString.length; i++) {\n        const c = argString.charAt(i);\n        if (c === '\"') {\n            if (!escaped) {\n                inQuotes = !inQuotes;\n            }\n            else {\n                append(c);\n            }\n            continue;\n        }\n        if (c === '\\\\' && escaped) {\n            append(c);\n            continue;\n        }\n        if (c === '\\\\' && inQuotes) {\n            escaped = true;\n            continue;\n        }\n        if (c === ' ' && !inQuotes) {\n            if (arg.length > 0) {\n                args.push(arg);\n                arg = '';\n            }\n            continue;\n        }\n        append(c);\n    }\n    if (arg.length > 0) {\n        args.push(arg.trim());\n    }\n    return args;\n}\nexports.argStringToArray = argStringToArray;\nclass ExecState extends events.EventEmitter {\n    constructor(options, toolPath) {\n        super();\n        this.processClosed = false; // tracks whether the process has exited and stdio is closed\n        this.processError = '';\n        this.processExitCode = 0;\n        this.processExited = false; // tracks whether the process has exited\n        this.processStderr = false; // tracks whether stderr was written to\n        this.delay = 10000; // 10 seconds\n        this.done = false;\n        this.timeout = null;\n        if (!toolPath) {\n            throw new Error('toolPath must not be empty');\n        }\n        this.options = options;\n        this.toolPath = toolPath;\n        if (options.delay) {\n            this.delay = options.delay;\n        }\n    }\n    CheckComplete() {\n        if (this.done) {\n            return;\n        }\n        if (this.processClosed) {\n            this._setResult();\n        }\n        else if (this.processExited) {\n            this.timeout = timers_1.setTimeout(ExecState.HandleTimeout, this.delay, this);\n        }\n    }\n    _debug(message) {\n        this.emit('debug', message);\n    }\n    _setResult() {\n        // determine whether there is an error\n        let error;\n        if (this.processExited) {\n            if (this.processError) {\n                error = new Error(`There was an error when attempting to execute the process '${this.toolPath}'. This may indicate the process failed to start. Error: ${this.processError}`);\n            }\n            else if (this.processExitCode !== 0 && !this.options.ignoreReturnCode) {\n                error = new Error(`The process '${this.toolPath}' failed with exit code ${this.processExitCode}`);\n            }\n            else if (this.processStderr && this.options.failOnStdErr) {\n                error = new Error(`The process '${this.toolPath}' failed because one or more lines were written to the STDERR stream`);\n            }\n        }\n        // clear the timeout\n        if (this.timeout) {\n            clearTimeout(this.timeout);\n            this.timeout = null;\n        }\n        this.done = true;\n        this.emit('done', error, this.processExitCode);\n    }\n    static HandleTimeout(state) {\n        if (state.done) {\n            return;\n        }\n        if (!state.processClosed && state.processExited) {\n            const message = `The STDIO streams did not close within ${state.delay /\n                1000} seconds of the exit event from process '${state.toolPath}'. This may indicate a child process inherited the STDIO streams and has not yet exited.`;\n            state._debug(message);\n        }\n        state._setResult();\n    }\n}\n//# sourceMappingURL=toolrunner.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Context = void 0;\nconst fs_1 = require(\"fs\");\nconst os_1 = require(\"os\");\nclass Context {\n    /**\n     * Hydrate the context from the environment\n     */\n    constructor() {\n        var _a, _b, _c;\n        this.payload = {};\n        if (process.env.GITHUB_EVENT_PATH) {\n            if ((0, fs_1.existsSync)(process.env.GITHUB_EVENT_PATH)) {\n                this.payload = JSON.parse((0, fs_1.readFileSync)(process.env.GITHUB_EVENT_PATH, { encoding: 'utf8' }));\n            }\n            else {\n                const path = process.env.GITHUB_EVENT_PATH;\n                process.stdout.write(`GITHUB_EVENT_PATH ${path} does not exist${os_1.EOL}`);\n            }\n        }\n        this.eventName = process.env.GITHUB_EVENT_NAME;\n        this.sha = process.env.GITHUB_SHA;\n        this.ref = process.env.GITHUB_REF;\n        this.workflow = process.env.GITHUB_WORKFLOW;\n        this.action = process.env.GITHUB_ACTION;\n        this.actor = process.env.GITHUB_ACTOR;\n        this.job = process.env.GITHUB_JOB;\n        this.runAttempt = parseInt(process.env.GITHUB_RUN_ATTEMPT, 10);\n        this.runNumber = parseInt(process.env.GITHUB_RUN_NUMBER, 10);\n        this.runId = parseInt(process.env.GITHUB_RUN_ID, 10);\n        this.apiUrl = (_a = process.env.GITHUB_API_URL) !== null && _a !== void 0 ? _a : `https://api.github.com`;\n        this.serverUrl = (_b = process.env.GITHUB_SERVER_URL) !== null && _b !== void 0 ? _b : `https://github.com`;\n        this.graphqlUrl =\n            (_c = process.env.GITHUB_GRAPHQL_URL) !== null && _c !== void 0 ? _c : `https://api.github.com/graphql`;\n    }\n    get issue() {\n        const payload = this.payload;\n        return Object.assign(Object.assign({}, this.repo), { number: (payload.issue || payload.pull_request || payload).number });\n    }\n    get repo() {\n        if (process.env.GITHUB_REPOSITORY) {\n            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');\n            return { owner, repo };\n        }\n        if (this.payload.repository) {\n            return {\n                owner: this.payload.repository.owner.login,\n                repo: this.payload.repository.name\n            };\n        }\n        throw new Error(\"context.repo requires a GITHUB_REPOSITORY environment variable like 'owner/repo'\");\n    }\n}\nexports.Context = Context;\n//# sourceMappingURL=context.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getOctokit = exports.context = void 0;\nconst Context = __importStar(require(\"./context\"));\nconst utils_1 = require(\"./utils\");\nexports.context = new Context.Context();\n/**\n * Returns a hydrated octokit ready to use for GitHub Actions\n *\n * @param     token    the repo PAT or GITHUB_TOKEN\n * @param     options  other options to set\n */\nfunction getOctokit(token, options, ...additionalPlugins) {\n    const GitHubWithPlugins = utils_1.GitHub.plugin(...additionalPlugins);\n    return new GitHubWithPlugins((0, utils_1.getOctokitOptions)(token, options));\n}\nexports.getOctokit = getOctokit;\n//# sourceMappingURL=github.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getApiBaseUrl = exports.getProxyFetch = exports.getProxyAgentDispatcher = exports.getProxyAgent = exports.getAuthString = void 0;\nconst httpClient = __importStar(require(\"@actions/http-client\"));\nconst undici_1 = require(\"undici\");\nfunction getAuthString(token, options) {\n    if (!token && !options.auth) {\n        throw new Error('Parameter token or opts.auth is required');\n    }\n    else if (token && options.auth) {\n        throw new Error('Parameters token and opts.auth may not both be specified');\n    }\n    return typeof options.auth === 'string' ? options.auth : `token ${token}`;\n}\nexports.getAuthString = getAuthString;\nfunction getProxyAgent(destinationUrl) {\n    const hc = new httpClient.HttpClient();\n    return hc.getAgent(destinationUrl);\n}\nexports.getProxyAgent = getProxyAgent;\nfunction getProxyAgentDispatcher(destinationUrl) {\n    const hc = new httpClient.HttpClient();\n    return hc.getAgentDispatcher(destinationUrl);\n}\nexports.getProxyAgentDispatcher = getProxyAgentDispatcher;\nfunction getProxyFetch(destinationUrl) {\n    const httpDispatcher = getProxyAgentDispatcher(destinationUrl);\n    const proxyFetch = (url, opts) => __awaiter(this, void 0, void 0, function* () {\n        return (0, undici_1.fetch)(url, Object.assign(Object.assign({}, opts), { dispatcher: httpDispatcher }));\n    });\n    return proxyFetch;\n}\nexports.getProxyFetch = getProxyFetch;\nfunction getApiBaseUrl() {\n    return process.env['GITHUB_API_URL'] || 'https://api.github.com';\n}\nexports.getApiBaseUrl = getApiBaseUrl;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getOctokitOptions = exports.GitHub = exports.defaults = exports.context = void 0;\nconst Context = __importStar(require(\"./context\"));\nconst Utils = __importStar(require(\"./internal/utils\"));\n// octokit + plugins\nconst core_1 = require(\"@octokit/core\");\nconst plugin_rest_endpoint_methods_1 = require(\"@octokit/plugin-rest-endpoint-methods\");\nconst plugin_paginate_rest_1 = require(\"@octokit/plugin-paginate-rest\");\nexports.context = new Context.Context();\nconst baseUrl = Utils.getApiBaseUrl();\nexports.defaults = {\n    baseUrl,\n    request: {\n        agent: Utils.getProxyAgent(baseUrl),\n        fetch: Utils.getProxyFetch(baseUrl)\n    }\n};\nexports.GitHub = core_1.Octokit.plugin(plugin_rest_endpoint_methods_1.restEndpointMethods, plugin_paginate_rest_1.paginateRest).defaults(exports.defaults);\n/**\n * Convience function to correctly format Octokit Options to pass into the constructor.\n *\n * @param     token    the repo PAT or GITHUB_TOKEN\n * @param     options  other options to set\n */\nfunction getOctokitOptions(token, options) {\n    const opts = Object.assign({}, options || {}); // Shallow clone - don't mutate the object provided by the caller\n    // Auth\n    const auth = Utils.getAuthString(token, opts);\n    if (auth) {\n        opts.auth = auth;\n    }\n    return opts;\n}\nexports.getOctokitOptions = getOctokitOptions;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.PersonalAccessTokenCredentialHandler = exports.BearerCredentialHandler = exports.BasicCredentialHandler = void 0;\nclass BasicCredentialHandler {\n    constructor(username, password) {\n        this.username = username;\n        this.password = password;\n    }\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`${this.username}:${this.password}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BasicCredentialHandler = BasicCredentialHandler;\nclass BearerCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Bearer ${this.token}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BearerCredentialHandler = BearerCredentialHandler;\nclass PersonalAccessTokenCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`PAT:${this.token}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.PersonalAccessTokenCredentialHandler = PersonalAccessTokenCredentialHandler;\n//# sourceMappingURL=auth.js.map","\"use strict\";\n/* eslint-disable @typescript-eslint/no-explicit-any */\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.HttpClient = exports.isHttps = exports.HttpClientResponse = exports.HttpClientError = exports.getProxyUrl = exports.MediaTypes = exports.Headers = exports.HttpCodes = void 0;\nconst http = __importStar(require(\"http\"));\nconst https = __importStar(require(\"https\"));\nconst pm = __importStar(require(\"./proxy\"));\nconst tunnel = __importStar(require(\"tunnel\"));\nconst undici_1 = require(\"undici\");\nvar HttpCodes;\n(function (HttpCodes) {\n    HttpCodes[HttpCodes[\"OK\"] = 200] = \"OK\";\n    HttpCodes[HttpCodes[\"MultipleChoices\"] = 300] = \"MultipleChoices\";\n    HttpCodes[HttpCodes[\"MovedPermanently\"] = 301] = \"MovedPermanently\";\n    HttpCodes[HttpCodes[\"ResourceMoved\"] = 302] = \"ResourceMoved\";\n    HttpCodes[HttpCodes[\"SeeOther\"] = 303] = \"SeeOther\";\n    HttpCodes[HttpCodes[\"NotModified\"] = 304] = \"NotModified\";\n    HttpCodes[HttpCodes[\"UseProxy\"] = 305] = \"UseProxy\";\n    HttpCodes[HttpCodes[\"SwitchProxy\"] = 306] = \"SwitchProxy\";\n    HttpCodes[HttpCodes[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    HttpCodes[HttpCodes[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    HttpCodes[HttpCodes[\"BadRequest\"] = 400] = \"BadRequest\";\n    HttpCodes[HttpCodes[\"Unauthorized\"] = 401] = \"Unauthorized\";\n    HttpCodes[HttpCodes[\"PaymentRequired\"] = 402] = \"PaymentRequired\";\n    HttpCodes[HttpCodes[\"Forbidden\"] = 403] = \"Forbidden\";\n    HttpCodes[HttpCodes[\"NotFound\"] = 404] = \"NotFound\";\n    HttpCodes[HttpCodes[\"MethodNotAllowed\"] = 405] = \"MethodNotAllowed\";\n    HttpCodes[HttpCodes[\"NotAcceptable\"] = 406] = \"NotAcceptable\";\n    HttpCodes[HttpCodes[\"ProxyAuthenticationRequired\"] = 407] = \"ProxyAuthenticationRequired\";\n    HttpCodes[HttpCodes[\"RequestTimeout\"] = 408] = \"RequestTimeout\";\n    HttpCodes[HttpCodes[\"Conflict\"] = 409] = \"Conflict\";\n    HttpCodes[HttpCodes[\"Gone\"] = 410] = \"Gone\";\n    HttpCodes[HttpCodes[\"TooManyRequests\"] = 429] = \"TooManyRequests\";\n    HttpCodes[HttpCodes[\"InternalServerError\"] = 500] = \"InternalServerError\";\n    HttpCodes[HttpCodes[\"NotImplemented\"] = 501] = \"NotImplemented\";\n    HttpCodes[HttpCodes[\"BadGateway\"] = 502] = \"BadGateway\";\n    HttpCodes[HttpCodes[\"ServiceUnavailable\"] = 503] = \"ServiceUnavailable\";\n    HttpCodes[HttpCodes[\"GatewayTimeout\"] = 504] = \"GatewayTimeout\";\n})(HttpCodes || (exports.HttpCodes = HttpCodes = {}));\nvar Headers;\n(function (Headers) {\n    Headers[\"Accept\"] = \"accept\";\n    Headers[\"ContentType\"] = \"content-type\";\n})(Headers || (exports.Headers = Headers = {}));\nvar MediaTypes;\n(function (MediaTypes) {\n    MediaTypes[\"ApplicationJson\"] = \"application/json\";\n})(MediaTypes || (exports.MediaTypes = MediaTypes = {}));\n/**\n * Returns the proxy URL, depending upon the supplied url and proxy environment variables.\n * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n */\nfunction getProxyUrl(serverUrl) {\n    const proxyUrl = pm.getProxyUrl(new URL(serverUrl));\n    return proxyUrl ? proxyUrl.href : '';\n}\nexports.getProxyUrl = getProxyUrl;\nconst HttpRedirectCodes = [\n    HttpCodes.MovedPermanently,\n    HttpCodes.ResourceMoved,\n    HttpCodes.SeeOther,\n    HttpCodes.TemporaryRedirect,\n    HttpCodes.PermanentRedirect\n];\nconst HttpResponseRetryCodes = [\n    HttpCodes.BadGateway,\n    HttpCodes.ServiceUnavailable,\n    HttpCodes.GatewayTimeout\n];\nconst RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];\nconst ExponentialBackoffCeiling = 10;\nconst ExponentialBackoffTimeSlice = 5;\nclass HttpClientError extends Error {\n    constructor(message, statusCode) {\n        super(message);\n        this.name = 'HttpClientError';\n        this.statusCode = statusCode;\n        Object.setPrototypeOf(this, HttpClientError.prototype);\n    }\n}\nexports.HttpClientError = HttpClientError;\nclass HttpClientResponse {\n    constructor(message) {\n        this.message = message;\n    }\n    readBody() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n                let output = Buffer.alloc(0);\n                this.message.on('data', (chunk) => {\n                    output = Buffer.concat([output, chunk]);\n                });\n                this.message.on('end', () => {\n                    resolve(output.toString());\n                });\n            }));\n        });\n    }\n    readBodyBuffer() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n                const chunks = [];\n                this.message.on('data', (chunk) => {\n                    chunks.push(chunk);\n                });\n                this.message.on('end', () => {\n                    resolve(Buffer.concat(chunks));\n                });\n            }));\n        });\n    }\n}\nexports.HttpClientResponse = HttpClientResponse;\nfunction isHttps(requestUrl) {\n    const parsedUrl = new URL(requestUrl);\n    return parsedUrl.protocol === 'https:';\n}\nexports.isHttps = isHttps;\nclass HttpClient {\n    constructor(userAgent, handlers, requestOptions) {\n        this._ignoreSslError = false;\n        this._allowRedirects = true;\n        this._allowRedirectDowngrade = false;\n        this._maxRedirects = 50;\n        this._allowRetries = false;\n        this._maxRetries = 1;\n        this._keepAlive = false;\n        this._disposed = false;\n        this.userAgent = userAgent;\n        this.handlers = handlers || [];\n        this.requestOptions = requestOptions;\n        if (requestOptions) {\n            if (requestOptions.ignoreSslError != null) {\n                this._ignoreSslError = requestOptions.ignoreSslError;\n            }\n            this._socketTimeout = requestOptions.socketTimeout;\n            if (requestOptions.allowRedirects != null) {\n                this._allowRedirects = requestOptions.allowRedirects;\n            }\n            if (requestOptions.allowRedirectDowngrade != null) {\n                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;\n            }\n            if (requestOptions.maxRedirects != null) {\n                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);\n            }\n            if (requestOptions.keepAlive != null) {\n                this._keepAlive = requestOptions.keepAlive;\n            }\n            if (requestOptions.allowRetries != null) {\n                this._allowRetries = requestOptions.allowRetries;\n            }\n            if (requestOptions.maxRetries != null) {\n                this._maxRetries = requestOptions.maxRetries;\n            }\n        }\n    }\n    options(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    get(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('GET', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    del(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('DELETE', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    post(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('POST', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    patch(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PATCH', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    put(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PUT', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    head(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('HEAD', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    sendStream(verb, requestUrl, stream, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request(verb, requestUrl, stream, additionalHeaders);\n        });\n    }\n    /**\n     * Gets a typed object from an endpoint\n     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise\n     */\n    getJson(requestUrl, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            const res = yield this.get(requestUrl, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    postJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.post(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    putJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.put(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    patchJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.patch(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    /**\n     * Makes a raw http request.\n     * All other methods such as get, post, patch, and request ultimately call this.\n     * Prefer get, del, post and patch\n     */\n    request(verb, requestUrl, data, headers) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._disposed) {\n                throw new Error('Client has already been disposed.');\n            }\n            const parsedUrl = new URL(requestUrl);\n            let info = this._prepareRequest(verb, parsedUrl, headers);\n            // Only perform retries on reads since writes may not be idempotent.\n            const maxTries = this._allowRetries && RetryableHttpVerbs.includes(verb)\n                ? this._maxRetries + 1\n                : 1;\n            let numTries = 0;\n            let response;\n            do {\n                response = yield this.requestRaw(info, data);\n                // Check if it's an authentication challenge\n                if (response &&\n                    response.message &&\n                    response.message.statusCode === HttpCodes.Unauthorized) {\n                    let authenticationHandler;\n                    for (const handler of this.handlers) {\n                        if (handler.canHandleAuthentication(response)) {\n                            authenticationHandler = handler;\n                            break;\n                        }\n                    }\n                    if (authenticationHandler) {\n                        return authenticationHandler.handleAuthentication(this, info, data);\n                    }\n                    else {\n                        // We have received an unauthorized response but have no handlers to handle it.\n                        // Let the response return to the caller.\n                        return response;\n                    }\n                }\n                let redirectsRemaining = this._maxRedirects;\n                while (response.message.statusCode &&\n                    HttpRedirectCodes.includes(response.message.statusCode) &&\n                    this._allowRedirects &&\n                    redirectsRemaining > 0) {\n                    const redirectUrl = response.message.headers['location'];\n                    if (!redirectUrl) {\n                        // if there's no location to redirect to, we won't\n                        break;\n                    }\n                    const parsedRedirectUrl = new URL(redirectUrl);\n                    if (parsedUrl.protocol === 'https:' &&\n                        parsedUrl.protocol !== parsedRedirectUrl.protocol &&\n                        !this._allowRedirectDowngrade) {\n                        throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');\n                    }\n                    // we need to finish reading the response before reassigning response\n                    // which will leak the open socket.\n                    yield response.readBody();\n                    // strip authorization header if redirected to a different hostname\n                    if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {\n                        for (const header in headers) {\n                            // header names are case insensitive\n                            if (header.toLowerCase() === 'authorization') {\n                                delete headers[header];\n                            }\n                        }\n                    }\n                    // let's make the request with the new redirectUrl\n                    info = this._prepareRequest(verb, parsedRedirectUrl, headers);\n                    response = yield this.requestRaw(info, data);\n                    redirectsRemaining--;\n                }\n                if (!response.message.statusCode ||\n                    !HttpResponseRetryCodes.includes(response.message.statusCode)) {\n                    // If not a retry code, return immediately instead of retrying\n                    return response;\n                }\n                numTries += 1;\n                if (numTries < maxTries) {\n                    yield response.readBody();\n                    yield this._performExponentialBackoff(numTries);\n                }\n            } while (numTries < maxTries);\n            return response;\n        });\n    }\n    /**\n     * Needs to be called if keepAlive is set to true in request options.\n     */\n    dispose() {\n        if (this._agent) {\n            this._agent.destroy();\n        }\n        this._disposed = true;\n    }\n    /**\n     * Raw request.\n     * @param info\n     * @param data\n     */\n    requestRaw(info, data) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => {\n                function callbackForResult(err, res) {\n                    if (err) {\n                        reject(err);\n                    }\n                    else if (!res) {\n                        // If `err` is not passed, then `res` must be passed.\n                        reject(new Error('Unknown error'));\n                    }\n                    else {\n                        resolve(res);\n                    }\n                }\n                this.requestRawWithCallback(info, data, callbackForResult);\n            });\n        });\n    }\n    /**\n     * Raw request with callback.\n     * @param info\n     * @param data\n     * @param onResult\n     */\n    requestRawWithCallback(info, data, onResult) {\n        if (typeof data === 'string') {\n            if (!info.options.headers) {\n                info.options.headers = {};\n            }\n            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');\n        }\n        let callbackCalled = false;\n        function handleResult(err, res) {\n            if (!callbackCalled) {\n                callbackCalled = true;\n                onResult(err, res);\n            }\n        }\n        const req = info.httpModule.request(info.options, (msg) => {\n            const res = new HttpClientResponse(msg);\n            handleResult(undefined, res);\n        });\n        let socket;\n        req.on('socket', sock => {\n            socket = sock;\n        });\n        // If we ever get disconnected, we want the socket to timeout eventually\n        req.setTimeout(this._socketTimeout || 3 * 60000, () => {\n            if (socket) {\n                socket.end();\n            }\n            handleResult(new Error(`Request timeout: ${info.options.path}`));\n        });\n        req.on('error', function (err) {\n            // err has statusCode property\n            // res should have headers\n            handleResult(err);\n        });\n        if (data && typeof data === 'string') {\n            req.write(data, 'utf8');\n        }\n        if (data && typeof data !== 'string') {\n            data.on('close', function () {\n                req.end();\n            });\n            data.pipe(req);\n        }\n        else {\n            req.end();\n        }\n    }\n    /**\n     * Gets an http agent. This function is useful when you need an http agent that handles\n     * routing through a proxy server - depending upon the url and proxy environment variables.\n     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n     */\n    getAgent(serverUrl) {\n        const parsedUrl = new URL(serverUrl);\n        return this._getAgent(parsedUrl);\n    }\n    getAgentDispatcher(serverUrl) {\n        const parsedUrl = new URL(serverUrl);\n        const proxyUrl = pm.getProxyUrl(parsedUrl);\n        const useProxy = proxyUrl && proxyUrl.hostname;\n        if (!useProxy) {\n            return;\n        }\n        return this._getProxyAgentDispatcher(parsedUrl, proxyUrl);\n    }\n    _prepareRequest(method, requestUrl, headers) {\n        const info = {};\n        info.parsedUrl = requestUrl;\n        const usingSsl = info.parsedUrl.protocol === 'https:';\n        info.httpModule = usingSsl ? https : http;\n        const defaultPort = usingSsl ? 443 : 80;\n        info.options = {};\n        info.options.host = info.parsedUrl.hostname;\n        info.options.port = info.parsedUrl.port\n            ? parseInt(info.parsedUrl.port)\n            : defaultPort;\n        info.options.path =\n            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');\n        info.options.method = method;\n        info.options.headers = this._mergeHeaders(headers);\n        if (this.userAgent != null) {\n            info.options.headers['user-agent'] = this.userAgent;\n        }\n        info.options.agent = this._getAgent(info.parsedUrl);\n        // gives handlers an opportunity to participate\n        if (this.handlers) {\n            for (const handler of this.handlers) {\n                handler.prepareRequest(info.options);\n            }\n        }\n        return info;\n    }\n    _mergeHeaders(headers) {\n        if (this.requestOptions && this.requestOptions.headers) {\n            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers || {}));\n        }\n        return lowercaseKeys(headers || {});\n    }\n    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {\n        let clientHeader;\n        if (this.requestOptions && this.requestOptions.headers) {\n            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];\n        }\n        return additionalHeaders[header] || clientHeader || _default;\n    }\n    _getAgent(parsedUrl) {\n        let agent;\n        const proxyUrl = pm.getProxyUrl(parsedUrl);\n        const useProxy = proxyUrl && proxyUrl.hostname;\n        if (this._keepAlive && useProxy) {\n            agent = this._proxyAgent;\n        }\n        if (!useProxy) {\n            agent = this._agent;\n        }\n        // if agent is already assigned use that agent.\n        if (agent) {\n            return agent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        let maxSockets = 100;\n        if (this.requestOptions) {\n            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;\n        }\n        // This is `useProxy` again, but we need to check `proxyURl` directly for TypeScripts's flow analysis.\n        if (proxyUrl && proxyUrl.hostname) {\n            const agentOptions = {\n                maxSockets,\n                keepAlive: this._keepAlive,\n                proxy: Object.assign(Object.assign({}, ((proxyUrl.username || proxyUrl.password) && {\n                    proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`\n                })), { host: proxyUrl.hostname, port: proxyUrl.port })\n            };\n            let tunnelAgent;\n            const overHttps = proxyUrl.protocol === 'https:';\n            if (usingSsl) {\n                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;\n            }\n            else {\n                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;\n            }\n            agent = tunnelAgent(agentOptions);\n            this._proxyAgent = agent;\n        }\n        // if tunneling agent isn't assigned create a new agent\n        if (!agent) {\n            const options = { keepAlive: this._keepAlive, maxSockets };\n            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);\n            this._agent = agent;\n        }\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            agent.options = Object.assign(agent.options || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return agent;\n    }\n    _getProxyAgentDispatcher(parsedUrl, proxyUrl) {\n        let proxyAgent;\n        if (this._keepAlive) {\n            proxyAgent = this._proxyAgentDispatcher;\n        }\n        // if agent is already assigned use that agent.\n        if (proxyAgent) {\n            return proxyAgent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        proxyAgent = new undici_1.ProxyAgent(Object.assign({ uri: proxyUrl.href, pipelining: !this._keepAlive ? 0 : 1 }, ((proxyUrl.username || proxyUrl.password) && {\n            token: `Basic ${Buffer.from(`${proxyUrl.username}:${proxyUrl.password}`).toString('base64')}`\n        })));\n        this._proxyAgentDispatcher = proxyAgent;\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            proxyAgent.options = Object.assign(proxyAgent.options.requestTls || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return proxyAgent;\n    }\n    _performExponentialBackoff(retryNumber) {\n        return __awaiter(this, void 0, void 0, function* () {\n            retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);\n            const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);\n            return new Promise(resolve => setTimeout(() => resolve(), ms));\n        });\n    }\n    _processResponse(res, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {\n                const statusCode = res.message.statusCode || 0;\n                const response = {\n                    statusCode,\n                    result: null,\n                    headers: {}\n                };\n                // not found leads to null obj returned\n                if (statusCode === HttpCodes.NotFound) {\n                    resolve(response);\n                }\n                // get the result from the body\n                function dateTimeDeserializer(key, value) {\n                    if (typeof value === 'string') {\n                        const a = new Date(value);\n                        if (!isNaN(a.valueOf())) {\n                            return a;\n                        }\n                    }\n                    return value;\n                }\n                let obj;\n                let contents;\n                try {\n                    contents = yield res.readBody();\n                    if (contents && contents.length > 0) {\n                        if (options && options.deserializeDates) {\n                            obj = JSON.parse(contents, dateTimeDeserializer);\n                        }\n                        else {\n                            obj = JSON.parse(contents);\n                        }\n                        response.result = obj;\n                    }\n                    response.headers = res.message.headers;\n                }\n                catch (err) {\n                    // Invalid resource (contents not json);  leaving result obj null\n                }\n                // note that 3xx redirects are handled by the http layer.\n                if (statusCode > 299) {\n                    let msg;\n                    // if exception/error in body, attempt to get better error\n                    if (obj && obj.message) {\n                        msg = obj.message;\n                    }\n                    else if (contents && contents.length > 0) {\n                        // it may be the case that the exception is in the body message as string\n                        msg = contents;\n                    }\n                    else {\n                        msg = `Failed request: (${statusCode})`;\n                    }\n                    const err = new HttpClientError(msg, statusCode);\n                    err.result = response.result;\n                    reject(err);\n                }\n                else {\n                    resolve(response);\n                }\n            }));\n        });\n    }\n}\nexports.HttpClient = HttpClient;\nconst lowercaseKeys = (obj) => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.checkBypass = exports.getProxyUrl = void 0;\nfunction getProxyUrl(reqUrl) {\n    const usingSsl = reqUrl.protocol === 'https:';\n    if (checkBypass(reqUrl)) {\n        return undefined;\n    }\n    const proxyVar = (() => {\n        if (usingSsl) {\n            return process.env['https_proxy'] || process.env['HTTPS_PROXY'];\n        }\n        else {\n            return process.env['http_proxy'] || process.env['HTTP_PROXY'];\n        }\n    })();\n    if (proxyVar) {\n        try {\n            return new DecodedURL(proxyVar);\n        }\n        catch (_a) {\n            if (!proxyVar.startsWith('http://') && !proxyVar.startsWith('https://'))\n                return new DecodedURL(`http://${proxyVar}`);\n        }\n    }\n    else {\n        return undefined;\n    }\n}\nexports.getProxyUrl = getProxyUrl;\nfunction checkBypass(reqUrl) {\n    if (!reqUrl.hostname) {\n        return false;\n    }\n    const reqHost = reqUrl.hostname;\n    if (isLoopbackAddress(reqHost)) {\n        return true;\n    }\n    const noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';\n    if (!noProxy) {\n        return false;\n    }\n    // Determine the request port\n    let reqPort;\n    if (reqUrl.port) {\n        reqPort = Number(reqUrl.port);\n    }\n    else if (reqUrl.protocol === 'http:') {\n        reqPort = 80;\n    }\n    else if (reqUrl.protocol === 'https:') {\n        reqPort = 443;\n    }\n    // Format the request hostname and hostname with port\n    const upperReqHosts = [reqUrl.hostname.toUpperCase()];\n    if (typeof reqPort === 'number') {\n        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);\n    }\n    // Compare request host against noproxy\n    for (const upperNoProxyItem of noProxy\n        .split(',')\n        .map(x => x.trim().toUpperCase())\n        .filter(x => x)) {\n        if (upperNoProxyItem === '*' ||\n            upperReqHosts.some(x => x === upperNoProxyItem ||\n                x.endsWith(`.${upperNoProxyItem}`) ||\n                (upperNoProxyItem.startsWith('.') &&\n                    x.endsWith(`${upperNoProxyItem}`)))) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkBypass = checkBypass;\nfunction isLoopbackAddress(host) {\n    const hostLower = host.toLowerCase();\n    return (hostLower === 'localhost' ||\n        hostLower.startsWith('127.') ||\n        hostLower.startsWith('[::1]') ||\n        hostLower.startsWith('[0:0:0:0:0:0:0:1]'));\n}\nclass DecodedURL extends URL {\n    constructor(url, base) {\n        super(url, base);\n        this._decodedUsername = decodeURIComponent(super.username);\n        this._decodedPassword = decodeURIComponent(super.password);\n    }\n    get username() {\n        return this._decodedUsername;\n    }\n    get password() {\n        return this._decodedPassword;\n    }\n}\n//# sourceMappingURL=proxy.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar _a;\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getCmdPath = exports.tryGetExecutablePath = exports.isRooted = exports.isDirectory = exports.exists = exports.READONLY = exports.UV_FS_O_EXLOCK = exports.IS_WINDOWS = exports.unlink = exports.symlink = exports.stat = exports.rmdir = exports.rm = exports.rename = exports.readlink = exports.readdir = exports.open = exports.mkdir = exports.lstat = exports.copyFile = exports.chmod = void 0;\nconst fs = __importStar(require(\"fs\"));\nconst path = __importStar(require(\"path\"));\n_a = fs.promises\n// export const {open} = 'fs'\n, exports.chmod = _a.chmod, exports.copyFile = _a.copyFile, exports.lstat = _a.lstat, exports.mkdir = _a.mkdir, exports.open = _a.open, exports.readdir = _a.readdir, exports.readlink = _a.readlink, exports.rename = _a.rename, exports.rm = _a.rm, exports.rmdir = _a.rmdir, exports.stat = _a.stat, exports.symlink = _a.symlink, exports.unlink = _a.unlink;\n// export const {open} = 'fs'\nexports.IS_WINDOWS = process.platform === 'win32';\n// See https://github.com/nodejs/node/blob/d0153aee367422d0858105abec186da4dff0a0c5/deps/uv/include/uv/win.h#L691\nexports.UV_FS_O_EXLOCK = 0x10000000;\nexports.READONLY = fs.constants.O_RDONLY;\nfunction exists(fsPath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        try {\n            yield exports.stat(fsPath);\n        }\n        catch (err) {\n            if (err.code === 'ENOENT') {\n                return false;\n            }\n            throw err;\n        }\n        return true;\n    });\n}\nexports.exists = exists;\nfunction isDirectory(fsPath, useStat = false) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const stats = useStat ? yield exports.stat(fsPath) : yield exports.lstat(fsPath);\n        return stats.isDirectory();\n    });\n}\nexports.isDirectory = isDirectory;\n/**\n * On OSX/Linux, true if path starts with '/'. On Windows, true for paths like:\n * \\, \\hello, \\\\hello\\share, C:, and C:\\hello (and corresponding alternate separator cases).\n */\nfunction isRooted(p) {\n    p = normalizeSeparators(p);\n    if (!p) {\n        throw new Error('isRooted() parameter \"p\" cannot be empty');\n    }\n    if (exports.IS_WINDOWS) {\n        return (p.startsWith('\\\\') || /^[A-Z]:/i.test(p) // e.g. \\ or \\hello or \\\\hello\n        ); // e.g. C: or C:\\hello\n    }\n    return p.startsWith('/');\n}\nexports.isRooted = isRooted;\n/**\n * Best effort attempt to determine whether a file exists and is executable.\n * @param filePath    file path to check\n * @param extensions  additional file extensions to try\n * @return if file exists and is executable, returns the file path. otherwise empty string.\n */\nfunction tryGetExecutablePath(filePath, extensions) {\n    return __awaiter(this, void 0, void 0, function* () {\n        let stats = undefined;\n        try {\n            // test file exists\n            stats = yield exports.stat(filePath);\n        }\n        catch (err) {\n            if (err.code !== 'ENOENT') {\n                // eslint-disable-next-line no-console\n                console.log(`Unexpected error attempting to determine if executable file exists '${filePath}': ${err}`);\n            }\n        }\n        if (stats && stats.isFile()) {\n            if (exports.IS_WINDOWS) {\n                // on Windows, test for valid extension\n                const upperExt = path.extname(filePath).toUpperCase();\n                if (extensions.some(validExt => validExt.toUpperCase() === upperExt)) {\n                    return filePath;\n                }\n            }\n            else {\n                if (isUnixExecutable(stats)) {\n                    return filePath;\n                }\n            }\n        }\n        // try each extension\n        const originalFilePath = filePath;\n        for (const extension of extensions) {\n            filePath = originalFilePath + extension;\n            stats = undefined;\n            try {\n                stats = yield exports.stat(filePath);\n            }\n            catch (err) {\n                if (err.code !== 'ENOENT') {\n                    // eslint-disable-next-line no-console\n                    console.log(`Unexpected error attempting to determine if executable file exists '${filePath}': ${err}`);\n                }\n            }\n            if (stats && stats.isFile()) {\n                if (exports.IS_WINDOWS) {\n                    // preserve the case of the actual file (since an extension was appended)\n                    try {\n                        const directory = path.dirname(filePath);\n                        const upperName = path.basename(filePath).toUpperCase();\n                        for (const actualName of yield exports.readdir(directory)) {\n                            if (upperName === actualName.toUpperCase()) {\n                                filePath = path.join(directory, actualName);\n                                break;\n                            }\n                        }\n                    }\n                    catch (err) {\n                        // eslint-disable-next-line no-console\n                        console.log(`Unexpected error attempting to determine the actual case of the file '${filePath}': ${err}`);\n                    }\n                    return filePath;\n                }\n                else {\n                    if (isUnixExecutable(stats)) {\n                        return filePath;\n                    }\n                }\n            }\n        }\n        return '';\n    });\n}\nexports.tryGetExecutablePath = tryGetExecutablePath;\nfunction normalizeSeparators(p) {\n    p = p || '';\n    if (exports.IS_WINDOWS) {\n        // convert slashes on Windows\n        p = p.replace(/\\//g, '\\\\');\n        // remove redundant slashes\n        return p.replace(/\\\\\\\\+/g, '\\\\');\n    }\n    // remove redundant slashes\n    return p.replace(/\\/\\/+/g, '/');\n}\n// on Mac/Linux, test the execute bit\n//     R   W  X  R  W X R W X\n//   256 128 64 32 16 8 4 2 1\nfunction isUnixExecutable(stats) {\n    return ((stats.mode & 1) > 0 ||\n        ((stats.mode & 8) > 0 && stats.gid === process.getgid()) ||\n        ((stats.mode & 64) > 0 && stats.uid === process.getuid()));\n}\n// Get the path of cmd.exe in windows\nfunction getCmdPath() {\n    var _a;\n    return (_a = process.env['COMSPEC']) !== null && _a !== void 0 ? _a : `cmd.exe`;\n}\nexports.getCmdPath = getCmdPath;\n//# sourceMappingURL=io-util.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.findInPath = exports.which = exports.mkdirP = exports.rmRF = exports.mv = exports.cp = void 0;\nconst assert_1 = require(\"assert\");\nconst path = __importStar(require(\"path\"));\nconst ioUtil = __importStar(require(\"./io-util\"));\n/**\n * Copies a file or folder.\n * Based off of shelljs - https://github.com/shelljs/shelljs/blob/9237f66c52e5daa40458f94f9565e18e8132f5a6/src/cp.js\n *\n * @param     source    source path\n * @param     dest      destination path\n * @param     options   optional. See CopyOptions.\n */\nfunction cp(source, dest, options = {}) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const { force, recursive, copySourceDirectory } = readCopyOptions(options);\n        const destStat = (yield ioUtil.exists(dest)) ? yield ioUtil.stat(dest) : null;\n        // Dest is an existing file, but not forcing\n        if (destStat && destStat.isFile() && !force) {\n            return;\n        }\n        // If dest is an existing directory, should copy inside.\n        const newDest = destStat && destStat.isDirectory() && copySourceDirectory\n            ? path.join(dest, path.basename(source))\n            : dest;\n        if (!(yield ioUtil.exists(source))) {\n            throw new Error(`no such file or directory: ${source}`);\n        }\n        const sourceStat = yield ioUtil.stat(source);\n        if (sourceStat.isDirectory()) {\n            if (!recursive) {\n                throw new Error(`Failed to copy. ${source} is a directory, but tried to copy without recursive flag.`);\n            }\n            else {\n                yield cpDirRecursive(source, newDest, 0, force);\n            }\n        }\n        else {\n            if (path.relative(source, newDest) === '') {\n                // a file cannot be copied to itself\n                throw new Error(`'${newDest}' and '${source}' are the same file`);\n            }\n            yield copyFile(source, newDest, force);\n        }\n    });\n}\nexports.cp = cp;\n/**\n * Moves a path.\n *\n * @param     source    source path\n * @param     dest      destination path\n * @param     options   optional. See MoveOptions.\n */\nfunction mv(source, dest, options = {}) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (yield ioUtil.exists(dest)) {\n            let destExists = true;\n            if (yield ioUtil.isDirectory(dest)) {\n                // If dest is directory copy src into dest\n                dest = path.join(dest, path.basename(source));\n                destExists = yield ioUtil.exists(dest);\n            }\n            if (destExists) {\n                if (options.force == null || options.force) {\n                    yield rmRF(dest);\n                }\n                else {\n                    throw new Error('Destination already exists');\n                }\n            }\n        }\n        yield mkdirP(path.dirname(dest));\n        yield ioUtil.rename(source, dest);\n    });\n}\nexports.mv = mv;\n/**\n * Remove a path recursively with force\n *\n * @param inputPath path to remove\n */\nfunction rmRF(inputPath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (ioUtil.IS_WINDOWS) {\n            // Check for invalid characters\n            // https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file\n            if (/[*\"<>|]/.test(inputPath)) {\n                throw new Error('File path must not contain `*`, `\"`, `<`, `>` or `|` on Windows');\n            }\n        }\n        try {\n            // note if path does not exist, error is silent\n            yield ioUtil.rm(inputPath, {\n                force: true,\n                maxRetries: 3,\n                recursive: true,\n                retryDelay: 300\n            });\n        }\n        catch (err) {\n            throw new Error(`File was unable to be removed ${err}`);\n        }\n    });\n}\nexports.rmRF = rmRF;\n/**\n * Make a directory.  Creates the full path with folders in between\n * Will throw if it fails\n *\n * @param   fsPath        path to create\n * @returns Promise<void>\n */\nfunction mkdirP(fsPath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        assert_1.ok(fsPath, 'a path argument must be provided');\n        yield ioUtil.mkdir(fsPath, { recursive: true });\n    });\n}\nexports.mkdirP = mkdirP;\n/**\n * Returns path of a tool had the tool actually been invoked.  Resolves via paths.\n * If you check and the tool does not exist, it will throw.\n *\n * @param     tool              name of the tool\n * @param     check             whether to check if tool exists\n * @returns   Promise<string>   path to tool\n */\nfunction which(tool, check) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (!tool) {\n            throw new Error(\"parameter 'tool' is required\");\n        }\n        // recursive when check=true\n        if (check) {\n            const result = yield which(tool, false);\n            if (!result) {\n                if (ioUtil.IS_WINDOWS) {\n                    throw new Error(`Unable to locate executable file: ${tool}. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also verify the file has a valid extension for an executable file.`);\n                }\n                else {\n                    throw new Error(`Unable to locate executable file: ${tool}. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also check the file mode to verify the file is executable.`);\n                }\n            }\n            return result;\n        }\n        const matches = yield findInPath(tool);\n        if (matches && matches.length > 0) {\n            return matches[0];\n        }\n        return '';\n    });\n}\nexports.which = which;\n/**\n * Returns a list of all occurrences of the given tool on the system path.\n *\n * @returns   Promise<string[]>  the paths of the tool\n */\nfunction findInPath(tool) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (!tool) {\n            throw new Error(\"parameter 'tool' is required\");\n        }\n        // build the list of extensions to try\n        const extensions = [];\n        if (ioUtil.IS_WINDOWS && process.env['PATHEXT']) {\n            for (const extension of process.env['PATHEXT'].split(path.delimiter)) {\n                if (extension) {\n                    extensions.push(extension);\n                }\n            }\n        }\n        // if it's rooted, return it if exists. otherwise return empty.\n        if (ioUtil.isRooted(tool)) {\n            const filePath = yield ioUtil.tryGetExecutablePath(tool, extensions);\n            if (filePath) {\n                return [filePath];\n            }\n            return [];\n        }\n        // if any path separators, return empty\n        if (tool.includes(path.sep)) {\n            return [];\n        }\n        // build the list of directories\n        //\n        // Note, technically \"where\" checks the current directory on Windows. From a toolkit perspective,\n        // it feels like we should not do this. Checking the current directory seems like more of a use\n        // case of a shell, and the which() function exposed by the toolkit should strive for consistency\n        // across platforms.\n        const directories = [];\n        if (process.env.PATH) {\n            for (const p of process.env.PATH.split(path.delimiter)) {\n                if (p) {\n                    directories.push(p);\n                }\n            }\n        }\n        // find all matches\n        const matches = [];\n        for (const directory of directories) {\n            const filePath = yield ioUtil.tryGetExecutablePath(path.join(directory, tool), extensions);\n            if (filePath) {\n                matches.push(filePath);\n            }\n        }\n        return matches;\n    });\n}\nexports.findInPath = findInPath;\nfunction readCopyOptions(options) {\n    const force = options.force == null ? true : options.force;\n    const recursive = Boolean(options.recursive);\n    const copySourceDirectory = options.copySourceDirectory == null\n        ? true\n        : Boolean(options.copySourceDirectory);\n    return { force, recursive, copySourceDirectory };\n}\nfunction cpDirRecursive(sourceDir, destDir, currentDepth, force) {\n    return __awaiter(this, void 0, void 0, function* () {\n        // Ensure there is not a run away recursive copy\n        if (currentDepth >= 255)\n            return;\n        currentDepth++;\n        yield mkdirP(destDir);\n        const files = yield ioUtil.readdir(sourceDir);\n        for (const fileName of files) {\n            const srcFile = `${sourceDir}/${fileName}`;\n            const destFile = `${destDir}/${fileName}`;\n            const srcFileStat = yield ioUtil.lstat(srcFile);\n            if (srcFileStat.isDirectory()) {\n                // Recurse\n                yield cpDirRecursive(srcFile, destFile, currentDepth, force);\n            }\n            else {\n                yield copyFile(srcFile, destFile, force);\n            }\n        }\n        // Change the mode for the newly created directory\n        yield ioUtil.chmod(destDir, (yield ioUtil.stat(sourceDir)).mode);\n    });\n}\n// Buffered file copy\nfunction copyFile(srcFile, destFile, force) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if ((yield ioUtil.lstat(srcFile)).isSymbolicLink()) {\n            // unlink/re-link it\n            try {\n                yield ioUtil.lstat(destFile);\n                yield ioUtil.unlink(destFile);\n            }\n            catch (e) {\n                // Try to override file permission\n                if (e.code === 'EPERM') {\n                    yield ioUtil.chmod(destFile, '0666');\n                    yield ioUtil.unlink(destFile);\n                }\n                // other errors = it doesn't exist, no work to do\n            }\n            // Copy over symlink\n            const symlinkFull = yield ioUtil.readlink(srcFile);\n            yield ioUtil.symlink(symlinkFull, destFile, ioUtil.IS_WINDOWS ? 'junction' : null);\n        }\n        else if (!(yield ioUtil.exists(destFile)) || force) {\n            yield ioUtil.copyFile(srcFile, destFile);\n        }\n    });\n}\n//# sourceMappingURL=io.js.map","'use strict';\n\nconst ANSI_BACKGROUND_OFFSET = 10;\n\nconst wrapAnsi256 = (offset = 0) => code => `\\u001B[${38 + offset};5;${code}m`;\n\nconst wrapAnsi16m = (offset = 0) => (red, green, blue) => `\\u001B[${38 + offset};2;${red};${green};${blue}m`;\n\nfunction assembleStyles() {\n\tconst codes = new Map();\n\tconst styles = {\n\t\tmodifier: {\n\t\t\treset: [0, 0],\n\t\t\t// 21 isn't widely supported and 22 does the same thing\n\t\t\tbold: [1, 22],\n\t\t\tdim: [2, 22],\n\t\t\titalic: [3, 23],\n\t\t\tunderline: [4, 24],\n\t\t\toverline: [53, 55],\n\t\t\tinverse: [7, 27],\n\t\t\thidden: [8, 28],\n\t\t\tstrikethrough: [9, 29]\n\t\t},\n\t\tcolor: {\n\t\t\tblack: [30, 39],\n\t\t\tred: [31, 39],\n\t\t\tgreen: [32, 39],\n\t\t\tyellow: [33, 39],\n\t\t\tblue: [34, 39],\n\t\t\tmagenta: [35, 39],\n\t\t\tcyan: [36, 39],\n\t\t\twhite: [37, 39],\n\n\t\t\t// Bright color\n\t\t\tblackBright: [90, 39],\n\t\t\tredBright: [91, 39],\n\t\t\tgreenBright: [92, 39],\n\t\t\tyellowBright: [93, 39],\n\t\t\tblueBright: [94, 39],\n\t\t\tmagentaBright: [95, 39],\n\t\t\tcyanBright: [96, 39],\n\t\t\twhiteBright: [97, 39]\n\t\t},\n\t\tbgColor: {\n\t\t\tbgBlack: [40, 49],\n\t\t\tbgRed: [41, 49],\n\t\t\tbgGreen: [42, 49],\n\t\t\tbgYellow: [43, 49],\n\t\t\tbgBlue: [44, 49],\n\t\t\tbgMagenta: [45, 49],\n\t\t\tbgCyan: [46, 49],\n\t\t\tbgWhite: [47, 49],\n\n\t\t\t// Bright color\n\t\t\tbgBlackBright: [100, 49],\n\t\t\tbgRedBright: [101, 49],\n\t\t\tbgGreenBright: [102, 49],\n\t\t\tbgYellowBright: [103, 49],\n\t\t\tbgBlueBright: [104, 49],\n\t\t\tbgMagentaBright: [105, 49],\n\t\t\tbgCyanBright: [106, 49],\n\t\t\tbgWhiteBright: [107, 49]\n\t\t}\n\t};\n\n\t// Alias bright black as gray (and grey)\n\tstyles.color.gray = styles.color.blackBright;\n\tstyles.bgColor.bgGray = styles.bgColor.bgBlackBright;\n\tstyles.color.grey = styles.color.blackBright;\n\tstyles.bgColor.bgGrey = styles.bgColor.bgBlackBright;\n\n\tfor (const [groupName, group] of Object.entries(styles)) {\n\t\tfor (const [styleName, style] of Object.entries(group)) {\n\t\t\tstyles[styleName] = {\n\t\t\t\topen: `\\u001B[${style[0]}m`,\n\t\t\t\tclose: `\\u001B[${style[1]}m`\n\t\t\t};\n\n\t\t\tgroup[styleName] = styles[styleName];\n\n\t\t\tcodes.set(style[0], style[1]);\n\t\t}\n\n\t\tObject.defineProperty(styles, groupName, {\n\t\t\tvalue: group,\n\t\t\tenumerable: false\n\t\t});\n\t}\n\n\tObject.defineProperty(styles, 'codes', {\n\t\tvalue: codes,\n\t\tenumerable: false\n\t});\n\n\tstyles.color.close = '\\u001B[39m';\n\tstyles.bgColor.close = '\\u001B[49m';\n\n\tstyles.color.ansi256 = wrapAnsi256();\n\tstyles.color.ansi16m = wrapAnsi16m();\n\tstyles.bgColor.ansi256 = wrapAnsi256(ANSI_BACKGROUND_OFFSET);\n\tstyles.bgColor.ansi16m = wrapAnsi16m(ANSI_BACKGROUND_OFFSET);\n\n\t// From https://github.com/Qix-/color-convert/blob/3f0e0d4e92e235796ccb17f6e85c72094a651f49/conversions.js\n\tObject.defineProperties(styles, {\n\t\trgbToAnsi256: {\n\t\t\tvalue: (red, green, blue) => {\n\t\t\t\t// We use the extended greyscale palette here, with the exception of\n\t\t\t\t// black and white. normal palette only has 4 greyscale shades.\n\t\t\t\tif (red === green && green === blue) {\n\t\t\t\t\tif (red < 8) {\n\t\t\t\t\t\treturn 16;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (red > 248) {\n\t\t\t\t\t\treturn 231;\n\t\t\t\t\t}\n\n\t\t\t\t\treturn Math.round(((red - 8) / 247) * 24) + 232;\n\t\t\t\t}\n\n\t\t\t\treturn 16 +\n\t\t\t\t\t(36 * Math.round(red / 255 * 5)) +\n\t\t\t\t\t(6 * Math.round(green / 255 * 5)) +\n\t\t\t\t\tMath.round(blue / 255 * 5);\n\t\t\t},\n\t\t\tenumerable: false\n\t\t},\n\t\thexToRgb: {\n\t\t\tvalue: hex => {\n\t\t\t\tconst matches = /(?<colorString>[a-f\\d]{6}|[a-f\\d]{3})/i.exec(hex.toString(16));\n\t\t\t\tif (!matches) {\n\t\t\t\t\treturn [0, 0, 0];\n\t\t\t\t}\n\n\t\t\t\tlet {colorString} = matches.groups;\n\n\t\t\t\tif (colorString.length === 3) {\n\t\t\t\t\tcolorString = colorString.split('').map(character => character + character).join('');\n\t\t\t\t}\n\n\t\t\t\tconst integer = Number.parseInt(colorString, 16);\n\n\t\t\t\treturn [\n\t\t\t\t\t(integer >> 16) & 0xFF,\n\t\t\t\t\t(integer >> 8) & 0xFF,\n\t\t\t\t\tinteger & 0xFF\n\t\t\t\t];\n\t\t\t},\n\t\t\tenumerable: false\n\t\t},\n\t\thexToAnsi256: {\n\t\t\tvalue: hex => styles.rgbToAnsi256(...styles.hexToRgb(hex)),\n\t\t\tenumerable: false\n\t\t}\n\t});\n\n\treturn styles;\n}\n\n// Make the export immutable\nObject.defineProperty(module, 'exports', {\n\tenumerable: true,\n\tget: assembleStyles\n});\n","'use strict';\n\nconst UPPERCASE = /[\\p{Lu}]/u;\nconst LOWERCASE = /[\\p{Ll}]/u;\nconst LEADING_CAPITAL = /^[\\p{Lu}](?![\\p{Lu}])/gu;\nconst IDENTIFIER = /([\\p{Alpha}\\p{N}_]|$)/u;\nconst SEPARATORS = /[_.\\- ]+/;\n\nconst LEADING_SEPARATORS = new RegExp('^' + SEPARATORS.source);\nconst SEPARATORS_AND_IDENTIFIER = new RegExp(SEPARATORS.source + IDENTIFIER.source, 'gu');\nconst NUMBERS_AND_IDENTIFIER = new RegExp('\\\\d+' + IDENTIFIER.source, 'gu');\n\nconst preserveCamelCase = (string, toLowerCase, toUpperCase) => {\n\tlet isLastCharLower = false;\n\tlet isLastCharUpper = false;\n\tlet isLastLastCharUpper = false;\n\n\tfor (let i = 0; i < string.length; i++) {\n\t\tconst character = string[i];\n\n\t\tif (isLastCharLower && UPPERCASE.test(character)) {\n\t\t\tstring = string.slice(0, i) + '-' + string.slice(i);\n\t\t\tisLastCharLower = false;\n\t\t\tisLastLastCharUpper = isLastCharUpper;\n\t\t\tisLastCharUpper = true;\n\t\t\ti++;\n\t\t} else if (isLastCharUpper && isLastLastCharUpper && LOWERCASE.test(character)) {\n\t\t\tstring = string.slice(0, i - 1) + '-' + string.slice(i - 1);\n\t\t\tisLastLastCharUpper = isLastCharUpper;\n\t\t\tisLastCharUpper = false;\n\t\t\tisLastCharLower = true;\n\t\t} else {\n\t\t\tisLastCharLower = toLowerCase(character) === character && toUpperCase(character) !== character;\n\t\t\tisLastLastCharUpper = isLastCharUpper;\n\t\t\tisLastCharUpper = toUpperCase(character) === character && toLowerCase(character) !== character;\n\t\t}\n\t}\n\n\treturn string;\n};\n\nconst preserveConsecutiveUppercase = (input, toLowerCase) => {\n\tLEADING_CAPITAL.lastIndex = 0;\n\n\treturn input.replace(LEADING_CAPITAL, m1 => toLowerCase(m1));\n};\n\nconst postProcess = (input, toUpperCase) => {\n\tSEPARATORS_AND_IDENTIFIER.lastIndex = 0;\n\tNUMBERS_AND_IDENTIFIER.lastIndex = 0;\n\n\treturn input.replace(SEPARATORS_AND_IDENTIFIER, (_, identifier) => toUpperCase(identifier))\n\t\t.replace(NUMBERS_AND_IDENTIFIER, m => toUpperCase(m));\n};\n\nconst camelCase = (input, options) => {\n\tif (!(typeof input === 'string' || Array.isArray(input))) {\n\t\tthrow new TypeError('Expected the input to be `string | string[]`');\n\t}\n\n\toptions = {\n\t\tpascalCase: false,\n\t\tpreserveConsecutiveUppercase: false,\n\t\t...options\n\t};\n\n\tif (Array.isArray(input)) {\n\t\tinput = input.map(x => x.trim())\n\t\t\t.filter(x => x.length)\n\t\t\t.join('-');\n\t} else {\n\t\tinput = input.trim();\n\t}\n\n\tif (input.length === 0) {\n\t\treturn '';\n\t}\n\n\tconst toLowerCase = options.locale === false ?\n\t\tstring => string.toLowerCase() :\n\t\tstring => string.toLocaleLowerCase(options.locale);\n\tconst toUpperCase = options.locale === false ?\n\t\tstring => string.toUpperCase() :\n\t\tstring => string.toLocaleUpperCase(options.locale);\n\n\tif (input.length === 1) {\n\t\treturn options.pascalCase ? toUpperCase(input) : toLowerCase(input);\n\t}\n\n\tconst hasUpperCase = input !== toLowerCase(input);\n\n\tif (hasUpperCase) {\n\t\tinput = preserveCamelCase(input, toLowerCase, toUpperCase);\n\t}\n\n\tinput = input.replace(LEADING_SEPARATORS, '');\n\n\tif (options.preserveConsecutiveUppercase) {\n\t\tinput = preserveConsecutiveUppercase(input, toLowerCase);\n\t} else {\n\t\tinput = toLowerCase(input);\n\t}\n\n\tif (options.pascalCase) {\n\t\tinput = toUpperCase(input.charAt(0)) + input.slice(1);\n\t}\n\n\treturn postProcess(input, toUpperCase);\n};\n\nmodule.exports = camelCase;\n// TODO: Remove this for the next major release\nmodule.exports.default = camelCase;\n","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nObject.defineProperty(exports, \"MAX\", {\n  enumerable: true,\n  get: function () {\n    return _max.default;\n  }\n});\nObject.defineProperty(exports, \"NIL\", {\n  enumerable: true,\n  get: function () {\n    return _nil.default;\n  }\n});\nObject.defineProperty(exports, \"parse\", {\n  enumerable: true,\n  get: function () {\n    return _parse.default;\n  }\n});\nObject.defineProperty(exports, \"stringify\", {\n  enumerable: true,\n  get: function () {\n    return _stringify.default;\n  }\n});\nObject.defineProperty(exports, \"v1\", {\n  enumerable: true,\n  get: function () {\n    return _v.default;\n  }\n});\nObject.defineProperty(exports, \"v1ToV6\", {\n  enumerable: true,\n  get: function () {\n    return _v1ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v3\", {\n  enumerable: true,\n  get: function () {\n    return _v2.default;\n  }\n});\nObject.defineProperty(exports, \"v4\", {\n  enumerable: true,\n  get: function () {\n    return _v3.default;\n  }\n});\nObject.defineProperty(exports, \"v5\", {\n  enumerable: true,\n  get: function () {\n    return _v4.default;\n  }\n});\nObject.defineProperty(exports, \"v6\", {\n  enumerable: true,\n  get: function () {\n    return _v5.default;\n  }\n});\nObject.defineProperty(exports, \"v6ToV1\", {\n  enumerable: true,\n  get: function () {\n    return _v6ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v7\", {\n  enumerable: true,\n  get: function () {\n    return _v6.default;\n  }\n});\nObject.defineProperty(exports, \"validate\", {\n  enumerable: true,\n  get: function () {\n    return _validate.default;\n  }\n});\nObject.defineProperty(exports, \"version\", {\n  enumerable: true,\n  get: function () {\n    return _version.default;\n  }\n});\nvar _max = _interopRequireDefault(require(\"./max.js\"));\nvar _nil = _interopRequireDefault(require(\"./nil.js\"));\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nvar _v2 = _interopRequireDefault(require(\"./v3.js\"));\nvar _v3 = _interopRequireDefault(require(\"./v4.js\"));\nvar _v4 = _interopRequireDefault(require(\"./v5.js\"));\nvar _v5 = _interopRequireDefault(require(\"./v6.js\"));\nvar _v6ToV = _interopRequireDefault(require(\"./v6ToV1.js\"));\nvar _v6 = _interopRequireDefault(require(\"./v7.js\"));\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nvar _version = _interopRequireDefault(require(\"./version.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = 'ffffffff-ffff-ffff-ffff-ffffffffffff';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction md5(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('md5').update(bytes).digest();\n}\nvar _default = exports.default = md5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nvar _default = exports.default = {\n  randomUUID: _nodeCrypto.default.randomUUID\n};","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = '00000000-0000-0000-0000-000000000000';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction parse(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  let v;\n  const arr = new Uint8Array(16);\n\n  // Parse ########-....-....-....-............\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff;\n\n  // Parse ........-####-....-....-............\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff;\n\n  // Parse ........-....-####-....-............\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff;\n\n  // Parse ........-....-....-####-............\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff;\n\n  // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\nvar _default = exports.default = parse;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = rng;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst rnds8Pool = new Uint8Array(256); // # of random values to pre-allocate\nlet poolPtr = rnds8Pool.length;\nfunction rng() {\n  if (poolPtr > rnds8Pool.length - 16) {\n    _nodeCrypto.default.randomFillSync(rnds8Pool);\n    poolPtr = 0;\n  }\n  return rnds8Pool.slice(poolPtr, poolPtr += 16);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction sha1(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('sha1').update(bytes).digest();\n}\nvar _default = exports.default = sha1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nexports.unsafeStringify = unsafeStringify;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nconst byteToHex = [];\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  //\n  // Note to future-self: No, you can't remove the `toLowerCase()` call.\n  // REF: https://github.com/uuidjs/uuid/pull/677#issuecomment-1757351351\n  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();\n}\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset);\n  // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n  return uuid;\n}\nvar _default = exports.default = stringify;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nlet _nodeId;\nlet _clockseq;\n\n// Previous uuid creation time\nlet _lastMSecs = 0;\nlet _lastNSecs = 0;\n\n// See https://github.com/uuidjs/uuid for API details\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node;\n  let clockseq = options.clockseq;\n\n  // v1 only: Use cached `node` and `clockseq` values\n  if (!options._v6) {\n    if (!node) {\n      node = _nodeId;\n    }\n    if (clockseq == null) {\n      clockseq = _clockseq;\n    }\n  }\n\n  // Handle cases where we need entropy.  We do this lazily to minimize issues\n  // related to insufficient system entropy.  See #189\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng.default)();\n\n    // Randomize node\n    if (node == null) {\n      node = [seedBytes[0], seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n\n      // v1 only: cache node value for reuse\n      if (!_nodeId && !options._v6) {\n        // per RFC4122 4.5: Set MAC multicast bit (v1 only)\n        node[0] |= 0x01; // Set multicast bit\n\n        _nodeId = node;\n      }\n    }\n\n    // Randomize clockseq\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n      if (_clockseq === undefined && !options._v6) {\n        _clockseq = clockseq;\n      }\n    }\n  }\n\n  // v1 & v6 timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so time is\n  // handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v1ToV6;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v1 UUID to a v6 UUID\n *\n * @param {string|Uint8Array} uuid - The v1 UUID to convert to v6\n * @returns {string|Uint8Array} The v6 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v1ToV6(uuid) {\n  const v1Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v6Bytes = _v1ToV6(v1Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v6Bytes) : v6Bytes;\n}\n\n// Do the field transformation needed for v1 -> v6\nfunction _v1ToV6(v1Bytes, randomize = false) {\n  return Uint8Array.of((v1Bytes[6] & 0x0f) << 4 | v1Bytes[7] >> 4 & 0x0f, (v1Bytes[7] & 0x0f) << 4 | (v1Bytes[4] & 0xf0) >> 4, (v1Bytes[4] & 0x0f) << 4 | (v1Bytes[5] & 0xf0) >> 4, (v1Bytes[5] & 0x0f) << 4 | (v1Bytes[0] & 0xf0) >> 4, (v1Bytes[0] & 0x0f) << 4 | (v1Bytes[1] & 0xf0) >> 4, (v1Bytes[1] & 0x0f) << 4 | (v1Bytes[2] & 0xf0) >> 4, 0x60 | v1Bytes[2] & 0x0f, v1Bytes[3], v1Bytes[8], v1Bytes[9], v1Bytes[10], v1Bytes[11], v1Bytes[12], v1Bytes[13], v1Bytes[14], v1Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _md = _interopRequireDefault(require(\"./md5.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v3 = (0, _v.default)('v3', 0x30, _md.default);\nvar _default = exports.default = v3;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.URL = exports.DNS = void 0;\nexports.default = v35;\nvar _stringify = require(\"./stringify.js\");\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n  return bytes;\n}\nconst DNS = exports.DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nconst URL = exports.URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nfunction v35(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    var _namespace;\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n    if (typeof namespace === 'string') {\n      namespace = (0, _parse.default)(namespace);\n    }\n    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    }\n\n    // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n    if (buf) {\n      offset = offset || 0;\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n      return buf;\n    }\n    return (0, _stringify.unsafeStringify)(bytes);\n  }\n\n  // Function#name is not settable on some platforms (#270)\n  try {\n    generateUUID.name = name;\n  } catch (err) {}\n\n  // For CommonJS default export support\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _native = _interopRequireDefault(require(\"./native.js\"));\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction v4(options, buf, offset) {\n  if (_native.default.randomUUID && !buf && !options) {\n    return _native.default.randomUUID();\n  }\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    offset = offset || 0;\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(rnds);\n}\nvar _default = exports.default = v4;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _sha = _interopRequireDefault(require(\"./sha1.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v5 = (0, _v.default)('v5', 0x50, _sha.default);\nvar _default = exports.default = v5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6;\nvar _stringify = require(\"./stringify.js\");\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n *\n * @param {object} options\n * @param {Uint8Array=} buf\n * @param {number=} offset\n * @returns\n */\nfunction v6(options = {}, buf, offset = 0) {\n  // v6 is v1 with different field layout, so we start with a v1 UUID, albeit\n  // with slightly different behavior around how the clock_seq and node fields\n  // are randomized, which is why we call v1 with _v6: true.\n  let bytes = (0, _v.default)({\n    ...options,\n    _v6: true\n  }, new Uint8Array(16));\n\n  // Reorder the fields to v6 layout.\n  bytes = (0, _v1ToV.default)(bytes);\n\n  // Return as a byte array if requested\n  if (buf) {\n    for (let i = 0; i < 16; i++) {\n      buf[offset + i] = bytes[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(bytes);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6ToV1;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v6 UUID to a v1 UUID\n *\n * @param {string|Uint8Array} uuid - The v6 UUID to convert to v6\n * @returns {string|Uint8Array} The v1 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v6ToV1(uuid) {\n  const v6Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v1Bytes = _v6ToV1(v6Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v1Bytes) : v1Bytes;\n}\n\n// Do the field transformation needed for v6 -> v1\nfunction _v6ToV1(v6Bytes) {\n  return Uint8Array.of((v6Bytes[3] & 0x0f) << 4 | v6Bytes[4] >> 4 & 0x0f, (v6Bytes[4] & 0x0f) << 4 | (v6Bytes[5] & 0xf0) >> 4, (v6Bytes[5] & 0x0f) << 4 | v6Bytes[6] & 0x0f, v6Bytes[7], (v6Bytes[1] & 0x0f) << 4 | (v6Bytes[2] & 0xf0) >> 4, (v6Bytes[2] & 0x0f) << 4 | (v6Bytes[3] & 0xf0) >> 4, 0x10 | (v6Bytes[0] & 0xf0) >> 4, (v6Bytes[0] & 0x0f) << 4 | (v6Bytes[1] & 0xf0) >> 4, v6Bytes[8], v6Bytes[9], v6Bytes[10], v6Bytes[11], v6Bytes[12], v6Bytes[13], v6Bytes[14], v6Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * UUID V7 - Unix Epoch time-based UUID\n *\n * The IETF has published RFC9562, introducing 3 new UUID versions (6,7,8). This\n * implementation of V7 is based on the accepted, though not yet approved,\n * revisions.\n *\n * RFC 9562:https://www.rfc-editor.org/rfc/rfc9562.html Universally Unique\n * IDentifiers (UUIDs)\n\n *\n * Sample V7 value:\n * https://www.rfc-editor.org/rfc/rfc9562.html#name-example-of-a-uuidv7-value\n *\n * Monotonic Bit Layout: RFC rfc9562.6.2 Method 1, Dedicated Counter Bits ref:\n *     https://www.rfc-editor.org/rfc/rfc9562.html#section-6.2-5.1\n *\n *   0                   1                   2                   3 0 1 2 3 4 5 6\n *   7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                          unix_ts_ms                           |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |          unix_ts_ms           |  ver  |        seq_hi         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |var|               seq_low               |        rand         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                             rand                              |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *\n * seq is a 31 bit serialized counter; comprised of 12 bit seq_hi and 19 bit\n * seq_low, and randomly initialized upon timestamp change. 31 bit counter size\n * was selected as any bitwise operations in node are done as _signed_ 32 bit\n * ints. we exclude the sign bit.\n */\n\nlet _seqLow = null;\nlet _seqHigh = null;\nlet _msecs = 0;\nfunction v7(options, buf, offset) {\n  options = options || {};\n\n  // initialize buffer and pointer\n  let i = buf && offset || 0;\n  const b = buf || new Uint8Array(16);\n\n  // rnds is Uint8Array(16) filled with random bytes\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // milliseconds since unix epoch, 1970-01-01 00:00\n  const msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // seq is user provided 31 bit counter\n  let seq = options.seq !== undefined ? options.seq : null;\n\n  // initialize local seq high/low parts\n  let seqHigh = _seqHigh;\n  let seqLow = _seqLow;\n\n  // check if clock has advanced and user has not provided msecs\n  if (msecs > _msecs && options.msecs === undefined) {\n    _msecs = msecs;\n\n    // unless user provided seq, reset seq parts\n    if (seq !== null) {\n      seqHigh = null;\n      seqLow = null;\n    }\n  }\n\n  // if we have a user provided seq\n  if (seq !== null) {\n    // trim provided seq to 31 bits of value, avoiding overflow\n    if (seq > 0x7fffffff) {\n      seq = 0x7fffffff;\n    }\n\n    // split provided seq into high/low parts\n    seqHigh = seq >>> 19 & 0xfff;\n    seqLow = seq & 0x7ffff;\n  }\n\n  // randomly initialize seq\n  if (seqHigh === null || seqLow === null) {\n    seqHigh = rnds[6] & 0x7f;\n    seqHigh = seqHigh << 8 | rnds[7];\n    seqLow = rnds[8] & 0x3f; // pad for var\n    seqLow = seqLow << 8 | rnds[9];\n    seqLow = seqLow << 5 | rnds[10] >>> 3;\n  }\n\n  // increment seq if within msecs window\n  if (msecs + 10000 > _msecs && seq === null) {\n    if (++seqLow > 0x7ffff) {\n      seqLow = 0;\n      if (++seqHigh > 0xfff) {\n        seqHigh = 0;\n\n        // increment internal _msecs. this allows us to continue incrementing\n        // while staying monotonic. Note, once we hit 10k milliseconds beyond system\n        // clock, we will reset breaking monotonicity (after (2^31)*10000 generations)\n        _msecs++;\n      }\n    }\n  } else {\n    // resetting; we have advanced more than\n    // 10k milliseconds beyond system clock\n    _msecs = msecs;\n  }\n  _seqHigh = seqHigh;\n  _seqLow = seqLow;\n\n  // [bytes 0-5] 48 bits of local timestamp\n  b[i++] = _msecs / 0x10000000000 & 0xff;\n  b[i++] = _msecs / 0x100000000 & 0xff;\n  b[i++] = _msecs / 0x1000000 & 0xff;\n  b[i++] = _msecs / 0x10000 & 0xff;\n  b[i++] = _msecs / 0x100 & 0xff;\n  b[i++] = _msecs & 0xff;\n\n  // [byte 6] - set 4 bits of version (7) with first 4 bits seq_hi\n  b[i++] = seqHigh >>> 4 & 0x0f | 0x70;\n\n  // [byte 7] remaining 8 bits of seq_hi\n  b[i++] = seqHigh & 0xff;\n\n  // [byte 8] - variant (2 bits), first 6 bits seq_low\n  b[i++] = seqLow >>> 13 & 0x3f | 0x80;\n\n  // [byte 9] 8 bits seq_low\n  b[i++] = seqLow >>> 5 & 0xff;\n\n  // [byte 10] remaining 5 bits seq_low, 3 bits random\n  b[i++] = seqLow << 3 & 0xff | rnds[10] & 0x07;\n\n  // [bytes 11-15] always random\n  b[i++] = rnds[11];\n  b[i++] = rnds[12];\n  b[i++] = rnds[13];\n  b[i++] = rnds[14];\n  b[i++] = rnds[15];\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v7;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _regex = _interopRequireDefault(require(\"./regex.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex.default.test(uuid);\n}\nvar _default = exports.default = validate;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction version(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  return parseInt(uuid.slice(14, 15), 16);\n}\nvar _default = exports.default = version;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nObject.defineProperty(exports, \"MAX\", {\n  enumerable: true,\n  get: function () {\n    return _max.default;\n  }\n});\nObject.defineProperty(exports, \"NIL\", {\n  enumerable: true,\n  get: function () {\n    return _nil.default;\n  }\n});\nObject.defineProperty(exports, \"parse\", {\n  enumerable: true,\n  get: function () {\n    return _parse.default;\n  }\n});\nObject.defineProperty(exports, \"stringify\", {\n  enumerable: true,\n  get: function () {\n    return _stringify.default;\n  }\n});\nObject.defineProperty(exports, \"v1\", {\n  enumerable: true,\n  get: function () {\n    return _v.default;\n  }\n});\nObject.defineProperty(exports, \"v1ToV6\", {\n  enumerable: true,\n  get: function () {\n    return _v1ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v3\", {\n  enumerable: true,\n  get: function () {\n    return _v2.default;\n  }\n});\nObject.defineProperty(exports, \"v4\", {\n  enumerable: true,\n  get: function () {\n    return _v3.default;\n  }\n});\nObject.defineProperty(exports, \"v5\", {\n  enumerable: true,\n  get: function () {\n    return _v4.default;\n  }\n});\nObject.defineProperty(exports, \"v6\", {\n  enumerable: true,\n  get: function () {\n    return _v5.default;\n  }\n});\nObject.defineProperty(exports, \"v6ToV1\", {\n  enumerable: true,\n  get: function () {\n    return _v6ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v7\", {\n  enumerable: true,\n  get: function () {\n    return _v6.default;\n  }\n});\nObject.defineProperty(exports, \"validate\", {\n  enumerable: true,\n  get: function () {\n    return _validate.default;\n  }\n});\nObject.defineProperty(exports, \"version\", {\n  enumerable: true,\n  get: function () {\n    return _version.default;\n  }\n});\nvar _max = _interopRequireDefault(require(\"./max.js\"));\nvar _nil = _interopRequireDefault(require(\"./nil.js\"));\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nvar _v2 = _interopRequireDefault(require(\"./v3.js\"));\nvar _v3 = _interopRequireDefault(require(\"./v4.js\"));\nvar _v4 = _interopRequireDefault(require(\"./v5.js\"));\nvar _v5 = _interopRequireDefault(require(\"./v6.js\"));\nvar _v6ToV = _interopRequireDefault(require(\"./v6ToV1.js\"));\nvar _v6 = _interopRequireDefault(require(\"./v7.js\"));\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nvar _version = _interopRequireDefault(require(\"./version.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = 'ffffffff-ffff-ffff-ffff-ffffffffffff';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction md5(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('md5').update(bytes).digest();\n}\nvar _default = exports.default = md5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nvar _default = exports.default = {\n  randomUUID: _nodeCrypto.default.randomUUID\n};","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = '00000000-0000-0000-0000-000000000000';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction parse(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  let v;\n  const arr = new Uint8Array(16);\n\n  // Parse ########-....-....-....-............\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff;\n\n  // Parse ........-####-....-....-............\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff;\n\n  // Parse ........-....-####-....-............\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff;\n\n  // Parse ........-....-....-####-............\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff;\n\n  // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\nvar _default = exports.default = parse;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = rng;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst rnds8Pool = new Uint8Array(256); // # of random values to pre-allocate\nlet poolPtr = rnds8Pool.length;\nfunction rng() {\n  if (poolPtr > rnds8Pool.length - 16) {\n    _nodeCrypto.default.randomFillSync(rnds8Pool);\n    poolPtr = 0;\n  }\n  return rnds8Pool.slice(poolPtr, poolPtr += 16);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction sha1(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('sha1').update(bytes).digest();\n}\nvar _default = exports.default = sha1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nexports.unsafeStringify = unsafeStringify;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nconst byteToHex = [];\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  //\n  // Note to future-self: No, you can't remove the `toLowerCase()` call.\n  // REF: https://github.com/uuidjs/uuid/pull/677#issuecomment-1757351351\n  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();\n}\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset);\n  // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n  return uuid;\n}\nvar _default = exports.default = stringify;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nlet _nodeId;\nlet _clockseq;\n\n// Previous uuid creation time\nlet _lastMSecs = 0;\nlet _lastNSecs = 0;\n\n// See https://github.com/uuidjs/uuid for API details\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node;\n  let clockseq = options.clockseq;\n\n  // v1 only: Use cached `node` and `clockseq` values\n  if (!options._v6) {\n    if (!node) {\n      node = _nodeId;\n    }\n    if (clockseq == null) {\n      clockseq = _clockseq;\n    }\n  }\n\n  // Handle cases where we need entropy.  We do this lazily to minimize issues\n  // related to insufficient system entropy.  See #189\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng.default)();\n\n    // Randomize node\n    if (node == null) {\n      node = [seedBytes[0], seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n\n      // v1 only: cache node value for reuse\n      if (!_nodeId && !options._v6) {\n        // per RFC4122 4.5: Set MAC multicast bit (v1 only)\n        node[0] |= 0x01; // Set multicast bit\n\n        _nodeId = node;\n      }\n    }\n\n    // Randomize clockseq\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n      if (_clockseq === undefined && !options._v6) {\n        _clockseq = clockseq;\n      }\n    }\n  }\n\n  // v1 & v6 timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so time is\n  // handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v1ToV6;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v1 UUID to a v6 UUID\n *\n * @param {string|Uint8Array} uuid - The v1 UUID to convert to v6\n * @returns {string|Uint8Array} The v6 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v1ToV6(uuid) {\n  const v1Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v6Bytes = _v1ToV6(v1Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v6Bytes) : v6Bytes;\n}\n\n// Do the field transformation needed for v1 -> v6\nfunction _v1ToV6(v1Bytes, randomize = false) {\n  return Uint8Array.of((v1Bytes[6] & 0x0f) << 4 | v1Bytes[7] >> 4 & 0x0f, (v1Bytes[7] & 0x0f) << 4 | (v1Bytes[4] & 0xf0) >> 4, (v1Bytes[4] & 0x0f) << 4 | (v1Bytes[5] & 0xf0) >> 4, (v1Bytes[5] & 0x0f) << 4 | (v1Bytes[0] & 0xf0) >> 4, (v1Bytes[0] & 0x0f) << 4 | (v1Bytes[1] & 0xf0) >> 4, (v1Bytes[1] & 0x0f) << 4 | (v1Bytes[2] & 0xf0) >> 4, 0x60 | v1Bytes[2] & 0x0f, v1Bytes[3], v1Bytes[8], v1Bytes[9], v1Bytes[10], v1Bytes[11], v1Bytes[12], v1Bytes[13], v1Bytes[14], v1Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _md = _interopRequireDefault(require(\"./md5.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v3 = (0, _v.default)('v3', 0x30, _md.default);\nvar _default = exports.default = v3;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.URL = exports.DNS = void 0;\nexports.default = v35;\nvar _stringify = require(\"./stringify.js\");\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n  return bytes;\n}\nconst DNS = exports.DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nconst URL = exports.URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nfunction v35(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    var _namespace;\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n    if (typeof namespace === 'string') {\n      namespace = (0, _parse.default)(namespace);\n    }\n    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    }\n\n    // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n    if (buf) {\n      offset = offset || 0;\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n      return buf;\n    }\n    return (0, _stringify.unsafeStringify)(bytes);\n  }\n\n  // Function#name is not settable on some platforms (#270)\n  try {\n    generateUUID.name = name;\n  } catch (err) {}\n\n  // For CommonJS default export support\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _native = _interopRequireDefault(require(\"./native.js\"));\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction v4(options, buf, offset) {\n  if (_native.default.randomUUID && !buf && !options) {\n    return _native.default.randomUUID();\n  }\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    offset = offset || 0;\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(rnds);\n}\nvar _default = exports.default = v4;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _sha = _interopRequireDefault(require(\"./sha1.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v5 = (0, _v.default)('v5', 0x50, _sha.default);\nvar _default = exports.default = v5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6;\nvar _stringify = require(\"./stringify.js\");\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n *\n * @param {object} options\n * @param {Uint8Array=} buf\n * @param {number=} offset\n * @returns\n */\nfunction v6(options = {}, buf, offset = 0) {\n  // v6 is v1 with different field layout, so we start with a v1 UUID, albeit\n  // with slightly different behavior around how the clock_seq and node fields\n  // are randomized, which is why we call v1 with _v6: true.\n  let bytes = (0, _v.default)({\n    ...options,\n    _v6: true\n  }, new Uint8Array(16));\n\n  // Reorder the fields to v6 layout.\n  bytes = (0, _v1ToV.default)(bytes);\n\n  // Return as a byte array if requested\n  if (buf) {\n    for (let i = 0; i < 16; i++) {\n      buf[offset + i] = bytes[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(bytes);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6ToV1;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v6 UUID to a v1 UUID\n *\n * @param {string|Uint8Array} uuid - The v6 UUID to convert to v6\n * @returns {string|Uint8Array} The v1 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v6ToV1(uuid) {\n  const v6Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v1Bytes = _v6ToV1(v6Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v1Bytes) : v1Bytes;\n}\n\n// Do the field transformation needed for v6 -> v1\nfunction _v6ToV1(v6Bytes) {\n  return Uint8Array.of((v6Bytes[3] & 0x0f) << 4 | v6Bytes[4] >> 4 & 0x0f, (v6Bytes[4] & 0x0f) << 4 | (v6Bytes[5] & 0xf0) >> 4, (v6Bytes[5] & 0x0f) << 4 | v6Bytes[6] & 0x0f, v6Bytes[7], (v6Bytes[1] & 0x0f) << 4 | (v6Bytes[2] & 0xf0) >> 4, (v6Bytes[2] & 0x0f) << 4 | (v6Bytes[3] & 0xf0) >> 4, 0x10 | (v6Bytes[0] & 0xf0) >> 4, (v6Bytes[0] & 0x0f) << 4 | (v6Bytes[1] & 0xf0) >> 4, v6Bytes[8], v6Bytes[9], v6Bytes[10], v6Bytes[11], v6Bytes[12], v6Bytes[13], v6Bytes[14], v6Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * UUID V7 - Unix Epoch time-based UUID\n *\n * The IETF has published RFC9562, introducing 3 new UUID versions (6,7,8). This\n * implementation of V7 is based on the accepted, though not yet approved,\n * revisions.\n *\n * RFC 9562:https://www.rfc-editor.org/rfc/rfc9562.html Universally Unique\n * IDentifiers (UUIDs)\n\n *\n * Sample V7 value:\n * https://www.rfc-editor.org/rfc/rfc9562.html#name-example-of-a-uuidv7-value\n *\n * Monotonic Bit Layout: RFC rfc9562.6.2 Method 1, Dedicated Counter Bits ref:\n *     https://www.rfc-editor.org/rfc/rfc9562.html#section-6.2-5.1\n *\n *   0                   1                   2                   3 0 1 2 3 4 5 6\n *   7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                          unix_ts_ms                           |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |          unix_ts_ms           |  ver  |        seq_hi         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |var|               seq_low               |        rand         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                             rand                              |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *\n * seq is a 31 bit serialized counter; comprised of 12 bit seq_hi and 19 bit\n * seq_low, and randomly initialized upon timestamp change. 31 bit counter size\n * was selected as any bitwise operations in node are done as _signed_ 32 bit\n * ints. we exclude the sign bit.\n */\n\nlet _seqLow = null;\nlet _seqHigh = null;\nlet _msecs = 0;\nfunction v7(options, buf, offset) {\n  options = options || {};\n\n  // initialize buffer and pointer\n  let i = buf && offset || 0;\n  const b = buf || new Uint8Array(16);\n\n  // rnds is Uint8Array(16) filled with random bytes\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // milliseconds since unix epoch, 1970-01-01 00:00\n  const msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // seq is user provided 31 bit counter\n  let seq = options.seq !== undefined ? options.seq : null;\n\n  // initialize local seq high/low parts\n  let seqHigh = _seqHigh;\n  let seqLow = _seqLow;\n\n  // check if clock has advanced and user has not provided msecs\n  if (msecs > _msecs && options.msecs === undefined) {\n    _msecs = msecs;\n\n    // unless user provided seq, reset seq parts\n    if (seq !== null) {\n      seqHigh = null;\n      seqLow = null;\n    }\n  }\n\n  // if we have a user provided seq\n  if (seq !== null) {\n    // trim provided seq to 31 bits of value, avoiding overflow\n    if (seq > 0x7fffffff) {\n      seq = 0x7fffffff;\n    }\n\n    // split provided seq into high/low parts\n    seqHigh = seq >>> 19 & 0xfff;\n    seqLow = seq & 0x7ffff;\n  }\n\n  // randomly initialize seq\n  if (seqHigh === null || seqLow === null) {\n    seqHigh = rnds[6] & 0x7f;\n    seqHigh = seqHigh << 8 | rnds[7];\n    seqLow = rnds[8] & 0x3f; // pad for var\n    seqLow = seqLow << 8 | rnds[9];\n    seqLow = seqLow << 5 | rnds[10] >>> 3;\n  }\n\n  // increment seq if within msecs window\n  if (msecs + 10000 > _msecs && seq === null) {\n    if (++seqLow > 0x7ffff) {\n      seqLow = 0;\n      if (++seqHigh > 0xfff) {\n        seqHigh = 0;\n\n        // increment internal _msecs. this allows us to continue incrementing\n        // while staying monotonic. Note, once we hit 10k milliseconds beyond system\n        // clock, we will reset breaking monotonicity (after (2^31)*10000 generations)\n        _msecs++;\n      }\n    }\n  } else {\n    // resetting; we have advanced more than\n    // 10k milliseconds beyond system clock\n    _msecs = msecs;\n  }\n  _seqHigh = seqHigh;\n  _seqLow = seqLow;\n\n  // [bytes 0-5] 48 bits of local timestamp\n  b[i++] = _msecs / 0x10000000000 & 0xff;\n  b[i++] = _msecs / 0x100000000 & 0xff;\n  b[i++] = _msecs / 0x1000000 & 0xff;\n  b[i++] = _msecs / 0x10000 & 0xff;\n  b[i++] = _msecs / 0x100 & 0xff;\n  b[i++] = _msecs & 0xff;\n\n  // [byte 6] - set 4 bits of version (7) with first 4 bits seq_hi\n  b[i++] = seqHigh >>> 4 & 0x0f | 0x70;\n\n  // [byte 7] remaining 8 bits of seq_hi\n  b[i++] = seqHigh & 0xff;\n\n  // [byte 8] - variant (2 bits), first 6 bits seq_low\n  b[i++] = seqLow >>> 13 & 0x3f | 0x80;\n\n  // [byte 9] 8 bits seq_low\n  b[i++] = seqLow >>> 5 & 0xff;\n\n  // [byte 10] remaining 5 bits seq_low, 3 bits random\n  b[i++] = seqLow << 3 & 0xff | rnds[10] & 0x07;\n\n  // [bytes 11-15] always random\n  b[i++] = rnds[11];\n  b[i++] = rnds[12];\n  b[i++] = rnds[13];\n  b[i++] = rnds[14];\n  b[i++] = rnds[15];\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v7;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _regex = _interopRequireDefault(require(\"./regex.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex.default.test(uuid);\n}\nvar _default = exports.default = validate;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction version(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  return parseInt(uuid.slice(14, 15), 16);\n}\nvar _default = exports.default = version;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nObject.defineProperty(exports, \"MAX\", {\n  enumerable: true,\n  get: function () {\n    return _max.default;\n  }\n});\nObject.defineProperty(exports, \"NIL\", {\n  enumerable: true,\n  get: function () {\n    return _nil.default;\n  }\n});\nObject.defineProperty(exports, \"parse\", {\n  enumerable: true,\n  get: function () {\n    return _parse.default;\n  }\n});\nObject.defineProperty(exports, \"stringify\", {\n  enumerable: true,\n  get: function () {\n    return _stringify.default;\n  }\n});\nObject.defineProperty(exports, \"v1\", {\n  enumerable: true,\n  get: function () {\n    return _v.default;\n  }\n});\nObject.defineProperty(exports, \"v1ToV6\", {\n  enumerable: true,\n  get: function () {\n    return _v1ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v3\", {\n  enumerable: true,\n  get: function () {\n    return _v2.default;\n  }\n});\nObject.defineProperty(exports, \"v4\", {\n  enumerable: true,\n  get: function () {\n    return _v3.default;\n  }\n});\nObject.defineProperty(exports, \"v5\", {\n  enumerable: true,\n  get: function () {\n    return _v4.default;\n  }\n});\nObject.defineProperty(exports, \"v6\", {\n  enumerable: true,\n  get: function () {\n    return _v5.default;\n  }\n});\nObject.defineProperty(exports, \"v6ToV1\", {\n  enumerable: true,\n  get: function () {\n    return _v6ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v7\", {\n  enumerable: true,\n  get: function () {\n    return _v6.default;\n  }\n});\nObject.defineProperty(exports, \"validate\", {\n  enumerable: true,\n  get: function () {\n    return _validate.default;\n  }\n});\nObject.defineProperty(exports, \"version\", {\n  enumerable: true,\n  get: function () {\n    return _version.default;\n  }\n});\nvar _max = _interopRequireDefault(require(\"./max.js\"));\nvar _nil = _interopRequireDefault(require(\"./nil.js\"));\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nvar _v2 = _interopRequireDefault(require(\"./v3.js\"));\nvar _v3 = _interopRequireDefault(require(\"./v4.js\"));\nvar _v4 = _interopRequireDefault(require(\"./v5.js\"));\nvar _v5 = _interopRequireDefault(require(\"./v6.js\"));\nvar _v6ToV = _interopRequireDefault(require(\"./v6ToV1.js\"));\nvar _v6 = _interopRequireDefault(require(\"./v7.js\"));\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nvar _version = _interopRequireDefault(require(\"./version.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = 'ffffffff-ffff-ffff-ffff-ffffffffffff';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction md5(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('md5').update(bytes).digest();\n}\nvar _default = exports.default = md5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nvar _default = exports.default = {\n  randomUUID: _nodeCrypto.default.randomUUID\n};","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = '00000000-0000-0000-0000-000000000000';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction parse(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  let v;\n  const arr = new Uint8Array(16);\n\n  // Parse ########-....-....-....-............\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff;\n\n  // Parse ........-####-....-....-............\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff;\n\n  // Parse ........-....-####-....-............\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff;\n\n  // Parse ........-....-....-####-............\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff;\n\n  // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\nvar _default = exports.default = parse;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = rng;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst rnds8Pool = new Uint8Array(256); // # of random values to pre-allocate\nlet poolPtr = rnds8Pool.length;\nfunction rng() {\n  if (poolPtr > rnds8Pool.length - 16) {\n    _nodeCrypto.default.randomFillSync(rnds8Pool);\n    poolPtr = 0;\n  }\n  return rnds8Pool.slice(poolPtr, poolPtr += 16);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction sha1(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('sha1').update(bytes).digest();\n}\nvar _default = exports.default = sha1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nexports.unsafeStringify = unsafeStringify;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nconst byteToHex = [];\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  //\n  // Note to future-self: No, you can't remove the `toLowerCase()` call.\n  // REF: https://github.com/uuidjs/uuid/pull/677#issuecomment-1757351351\n  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();\n}\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset);\n  // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n  return uuid;\n}\nvar _default = exports.default = stringify;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nlet _nodeId;\nlet _clockseq;\n\n// Previous uuid creation time\nlet _lastMSecs = 0;\nlet _lastNSecs = 0;\n\n// See https://github.com/uuidjs/uuid for API details\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node;\n  let clockseq = options.clockseq;\n\n  // v1 only: Use cached `node` and `clockseq` values\n  if (!options._v6) {\n    if (!node) {\n      node = _nodeId;\n    }\n    if (clockseq == null) {\n      clockseq = _clockseq;\n    }\n  }\n\n  // Handle cases where we need entropy.  We do this lazily to minimize issues\n  // related to insufficient system entropy.  See #189\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng.default)();\n\n    // Randomize node\n    if (node == null) {\n      node = [seedBytes[0], seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n\n      // v1 only: cache node value for reuse\n      if (!_nodeId && !options._v6) {\n        // per RFC4122 4.5: Set MAC multicast bit (v1 only)\n        node[0] |= 0x01; // Set multicast bit\n\n        _nodeId = node;\n      }\n    }\n\n    // Randomize clockseq\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n      if (_clockseq === undefined && !options._v6) {\n        _clockseq = clockseq;\n      }\n    }\n  }\n\n  // v1 & v6 timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so time is\n  // handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v1ToV6;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v1 UUID to a v6 UUID\n *\n * @param {string|Uint8Array} uuid - The v1 UUID to convert to v6\n * @returns {string|Uint8Array} The v6 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v1ToV6(uuid) {\n  const v1Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v6Bytes = _v1ToV6(v1Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v6Bytes) : v6Bytes;\n}\n\n// Do the field transformation needed for v1 -> v6\nfunction _v1ToV6(v1Bytes, randomize = false) {\n  return Uint8Array.of((v1Bytes[6] & 0x0f) << 4 | v1Bytes[7] >> 4 & 0x0f, (v1Bytes[7] & 0x0f) << 4 | (v1Bytes[4] & 0xf0) >> 4, (v1Bytes[4] & 0x0f) << 4 | (v1Bytes[5] & 0xf0) >> 4, (v1Bytes[5] & 0x0f) << 4 | (v1Bytes[0] & 0xf0) >> 4, (v1Bytes[0] & 0x0f) << 4 | (v1Bytes[1] & 0xf0) >> 4, (v1Bytes[1] & 0x0f) << 4 | (v1Bytes[2] & 0xf0) >> 4, 0x60 | v1Bytes[2] & 0x0f, v1Bytes[3], v1Bytes[8], v1Bytes[9], v1Bytes[10], v1Bytes[11], v1Bytes[12], v1Bytes[13], v1Bytes[14], v1Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _md = _interopRequireDefault(require(\"./md5.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v3 = (0, _v.default)('v3', 0x30, _md.default);\nvar _default = exports.default = v3;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.URL = exports.DNS = void 0;\nexports.default = v35;\nvar _stringify = require(\"./stringify.js\");\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n  return bytes;\n}\nconst DNS = exports.DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nconst URL = exports.URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nfunction v35(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    var _namespace;\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n    if (typeof namespace === 'string') {\n      namespace = (0, _parse.default)(namespace);\n    }\n    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    }\n\n    // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n    if (buf) {\n      offset = offset || 0;\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n      return buf;\n    }\n    return (0, _stringify.unsafeStringify)(bytes);\n  }\n\n  // Function#name is not settable on some platforms (#270)\n  try {\n    generateUUID.name = name;\n  } catch (err) {}\n\n  // For CommonJS default export support\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _native = _interopRequireDefault(require(\"./native.js\"));\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction v4(options, buf, offset) {\n  if (_native.default.randomUUID && !buf && !options) {\n    return _native.default.randomUUID();\n  }\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    offset = offset || 0;\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(rnds);\n}\nvar _default = exports.default = v4;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _sha = _interopRequireDefault(require(\"./sha1.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v5 = (0, _v.default)('v5', 0x50, _sha.default);\nvar _default = exports.default = v5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6;\nvar _stringify = require(\"./stringify.js\");\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n *\n * @param {object} options\n * @param {Uint8Array=} buf\n * @param {number=} offset\n * @returns\n */\nfunction v6(options = {}, buf, offset = 0) {\n  // v6 is v1 with different field layout, so we start with a v1 UUID, albeit\n  // with slightly different behavior around how the clock_seq and node fields\n  // are randomized, which is why we call v1 with _v6: true.\n  let bytes = (0, _v.default)({\n    ...options,\n    _v6: true\n  }, new Uint8Array(16));\n\n  // Reorder the fields to v6 layout.\n  bytes = (0, _v1ToV.default)(bytes);\n\n  // Return as a byte array if requested\n  if (buf) {\n    for (let i = 0; i < 16; i++) {\n      buf[offset + i] = bytes[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(bytes);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6ToV1;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v6 UUID to a v1 UUID\n *\n * @param {string|Uint8Array} uuid - The v6 UUID to convert to v6\n * @returns {string|Uint8Array} The v1 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v6ToV1(uuid) {\n  const v6Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v1Bytes = _v6ToV1(v6Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v1Bytes) : v1Bytes;\n}\n\n// Do the field transformation needed for v6 -> v1\nfunction _v6ToV1(v6Bytes) {\n  return Uint8Array.of((v6Bytes[3] & 0x0f) << 4 | v6Bytes[4] >> 4 & 0x0f, (v6Bytes[4] & 0x0f) << 4 | (v6Bytes[5] & 0xf0) >> 4, (v6Bytes[5] & 0x0f) << 4 | v6Bytes[6] & 0x0f, v6Bytes[7], (v6Bytes[1] & 0x0f) << 4 | (v6Bytes[2] & 0xf0) >> 4, (v6Bytes[2] & 0x0f) << 4 | (v6Bytes[3] & 0xf0) >> 4, 0x10 | (v6Bytes[0] & 0xf0) >> 4, (v6Bytes[0] & 0x0f) << 4 | (v6Bytes[1] & 0xf0) >> 4, v6Bytes[8], v6Bytes[9], v6Bytes[10], v6Bytes[11], v6Bytes[12], v6Bytes[13], v6Bytes[14], v6Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * UUID V7 - Unix Epoch time-based UUID\n *\n * The IETF has published RFC9562, introducing 3 new UUID versions (6,7,8). This\n * implementation of V7 is based on the accepted, though not yet approved,\n * revisions.\n *\n * RFC 9562:https://www.rfc-editor.org/rfc/rfc9562.html Universally Unique\n * IDentifiers (UUIDs)\n\n *\n * Sample V7 value:\n * https://www.rfc-editor.org/rfc/rfc9562.html#name-example-of-a-uuidv7-value\n *\n * Monotonic Bit Layout: RFC rfc9562.6.2 Method 1, Dedicated Counter Bits ref:\n *     https://www.rfc-editor.org/rfc/rfc9562.html#section-6.2-5.1\n *\n *   0                   1                   2                   3 0 1 2 3 4 5 6\n *   7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                          unix_ts_ms                           |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |          unix_ts_ms           |  ver  |        seq_hi         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |var|               seq_low               |        rand         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                             rand                              |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *\n * seq is a 31 bit serialized counter; comprised of 12 bit seq_hi and 19 bit\n * seq_low, and randomly initialized upon timestamp change. 31 bit counter size\n * was selected as any bitwise operations in node are done as _signed_ 32 bit\n * ints. we exclude the sign bit.\n */\n\nlet _seqLow = null;\nlet _seqHigh = null;\nlet _msecs = 0;\nfunction v7(options, buf, offset) {\n  options = options || {};\n\n  // initialize buffer and pointer\n  let i = buf && offset || 0;\n  const b = buf || new Uint8Array(16);\n\n  // rnds is Uint8Array(16) filled with random bytes\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // milliseconds since unix epoch, 1970-01-01 00:00\n  const msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // seq is user provided 31 bit counter\n  let seq = options.seq !== undefined ? options.seq : null;\n\n  // initialize local seq high/low parts\n  let seqHigh = _seqHigh;\n  let seqLow = _seqLow;\n\n  // check if clock has advanced and user has not provided msecs\n  if (msecs > _msecs && options.msecs === undefined) {\n    _msecs = msecs;\n\n    // unless user provided seq, reset seq parts\n    if (seq !== null) {\n      seqHigh = null;\n      seqLow = null;\n    }\n  }\n\n  // if we have a user provided seq\n  if (seq !== null) {\n    // trim provided seq to 31 bits of value, avoiding overflow\n    if (seq > 0x7fffffff) {\n      seq = 0x7fffffff;\n    }\n\n    // split provided seq into high/low parts\n    seqHigh = seq >>> 19 & 0xfff;\n    seqLow = seq & 0x7ffff;\n  }\n\n  // randomly initialize seq\n  if (seqHigh === null || seqLow === null) {\n    seqHigh = rnds[6] & 0x7f;\n    seqHigh = seqHigh << 8 | rnds[7];\n    seqLow = rnds[8] & 0x3f; // pad for var\n    seqLow = seqLow << 8 | rnds[9];\n    seqLow = seqLow << 5 | rnds[10] >>> 3;\n  }\n\n  // increment seq if within msecs window\n  if (msecs + 10000 > _msecs && seq === null) {\n    if (++seqLow > 0x7ffff) {\n      seqLow = 0;\n      if (++seqHigh > 0xfff) {\n        seqHigh = 0;\n\n        // increment internal _msecs. this allows us to continue incrementing\n        // while staying monotonic. Note, once we hit 10k milliseconds beyond system\n        // clock, we will reset breaking monotonicity (after (2^31)*10000 generations)\n        _msecs++;\n      }\n    }\n  } else {\n    // resetting; we have advanced more than\n    // 10k milliseconds beyond system clock\n    _msecs = msecs;\n  }\n  _seqHigh = seqHigh;\n  _seqLow = seqLow;\n\n  // [bytes 0-5] 48 bits of local timestamp\n  b[i++] = _msecs / 0x10000000000 & 0xff;\n  b[i++] = _msecs / 0x100000000 & 0xff;\n  b[i++] = _msecs / 0x1000000 & 0xff;\n  b[i++] = _msecs / 0x10000 & 0xff;\n  b[i++] = _msecs / 0x100 & 0xff;\n  b[i++] = _msecs & 0xff;\n\n  // [byte 6] - set 4 bits of version (7) with first 4 bits seq_hi\n  b[i++] = seqHigh >>> 4 & 0x0f | 0x70;\n\n  // [byte 7] remaining 8 bits of seq_hi\n  b[i++] = seqHigh & 0xff;\n\n  // [byte 8] - variant (2 bits), first 6 bits seq_low\n  b[i++] = seqLow >>> 13 & 0x3f | 0x80;\n\n  // [byte 9] 8 bits seq_low\n  b[i++] = seqLow >>> 5 & 0xff;\n\n  // [byte 10] remaining 5 bits seq_low, 3 bits random\n  b[i++] = seqLow << 3 & 0xff | rnds[10] & 0x07;\n\n  // [bytes 11-15] always random\n  b[i++] = rnds[11];\n  b[i++] = rnds[12];\n  b[i++] = rnds[13];\n  b[i++] = rnds[14];\n  b[i++] = rnds[15];\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v7;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _regex = _interopRequireDefault(require(\"./regex.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex.default.test(uuid);\n}\nvar _default = exports.default = validate;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction version(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  return parseInt(uuid.slice(14, 15), 16);\n}\nvar _default = exports.default = version;","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  createTokenAuth: () => createTokenAuth\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/auth.js\nvar REGEX_IS_INSTALLATION_LEGACY = /^v1\\./;\nvar REGEX_IS_INSTALLATION = /^ghs_/;\nvar REGEX_IS_USER_TO_SERVER = /^ghu_/;\nasync function auth(token) {\n  const isApp = token.split(/\\./).length === 3;\n  const isInstallation = REGEX_IS_INSTALLATION_LEGACY.test(token) || REGEX_IS_INSTALLATION.test(token);\n  const isUserToServer = REGEX_IS_USER_TO_SERVER.test(token);\n  const tokenType = isApp ? \"app\" : isInstallation ? \"installation\" : isUserToServer ? \"user-to-server\" : \"oauth\";\n  return {\n    type: \"token\",\n    token,\n    tokenType\n  };\n}\n\n// pkg/dist-src/with-authorization-prefix.js\nfunction withAuthorizationPrefix(token) {\n  if (token.split(/\\./).length === 3) {\n    return `bearer ${token}`;\n  }\n  return `token ${token}`;\n}\n\n// pkg/dist-src/hook.js\nasync function hook(token, request, route, parameters) {\n  const endpoint = request.endpoint.merge(\n    route,\n    parameters\n  );\n  endpoint.headers.authorization = withAuthorizationPrefix(token);\n  return request(endpoint);\n}\n\n// pkg/dist-src/index.js\nvar createTokenAuth = function createTokenAuth2(token) {\n  if (!token) {\n    throw new Error(\"[@octokit/auth-token] No token passed to createTokenAuth\");\n  }\n  if (typeof token !== \"string\") {\n    throw new Error(\n      \"[@octokit/auth-token] Token passed to createTokenAuth is not a string\"\n    );\n  }\n  token = token.replace(/^(token|bearer) +/i, \"\");\n  return Object.assign(auth.bind(null, token), {\n    hook: hook.bind(null, token)\n  });\n};\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  createTokenAuth\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar index_exports = {};\n__export(index_exports, {\n  Octokit: () => Octokit\n});\nmodule.exports = __toCommonJS(index_exports);\nvar import_universal_user_agent = require(\"universal-user-agent\");\nvar import_before_after_hook = require(\"before-after-hook\");\nvar import_request = require(\"@octokit/request\");\nvar import_graphql = require(\"@octokit/graphql\");\nvar import_auth_token = require(\"@octokit/auth-token\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"5.2.2\";\n\n// pkg/dist-src/index.js\nvar noop = () => {\n};\nvar consoleWarn = console.warn.bind(console);\nvar consoleError = console.error.bind(console);\nfunction createLogger(logger = {}) {\n  if (typeof logger.debug !== \"function\") {\n    logger.debug = noop;\n  }\n  if (typeof logger.info !== \"function\") {\n    logger.info = noop;\n  }\n  if (typeof logger.warn !== \"function\") {\n    logger.warn = consoleWarn;\n  }\n  if (typeof logger.error !== \"function\") {\n    logger.error = consoleError;\n  }\n  return logger;\n}\nvar userAgentTrail = `octokit-core.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`;\nvar Octokit = class {\n  static {\n    this.VERSION = VERSION;\n  }\n  static defaults(defaults) {\n    const OctokitWithDefaults = class extends this {\n      constructor(...args) {\n        const options = args[0] || {};\n        if (typeof defaults === \"function\") {\n          super(defaults(options));\n          return;\n        }\n        super(\n          Object.assign(\n            {},\n            defaults,\n            options,\n            options.userAgent && defaults.userAgent ? {\n              userAgent: `${options.userAgent} ${defaults.userAgent}`\n            } : null\n          )\n        );\n      }\n    };\n    return OctokitWithDefaults;\n  }\n  static {\n    this.plugins = [];\n  }\n  /**\n   * Attach a plugin (or many) to your Octokit instance.\n   *\n   * @example\n   * const API = Octokit.plugin(plugin1, plugin2, plugin3, ...)\n   */\n  static plugin(...newPlugins) {\n    const currentPlugins = this.plugins;\n    const NewOctokit = class extends this {\n      static {\n        this.plugins = currentPlugins.concat(\n          newPlugins.filter((plugin) => !currentPlugins.includes(plugin))\n        );\n      }\n    };\n    return NewOctokit;\n  }\n  constructor(options = {}) {\n    const hook = new import_before_after_hook.Collection();\n    const requestDefaults = {\n      baseUrl: import_request.request.endpoint.DEFAULTS.baseUrl,\n      headers: {},\n      request: Object.assign({}, options.request, {\n        // @ts-ignore internal usage only, no need to type\n        hook: hook.bind(null, \"request\")\n      }),\n      mediaType: {\n        previews: [],\n        format: \"\"\n      }\n    };\n    requestDefaults.headers[\"user-agent\"] = options.userAgent ? `${options.userAgent} ${userAgentTrail}` : userAgentTrail;\n    if (options.baseUrl) {\n      requestDefaults.baseUrl = options.baseUrl;\n    }\n    if (options.previews) {\n      requestDefaults.mediaType.previews = options.previews;\n    }\n    if (options.timeZone) {\n      requestDefaults.headers[\"time-zone\"] = options.timeZone;\n    }\n    this.request = import_request.request.defaults(requestDefaults);\n    this.graphql = (0, import_graphql.withCustomRequest)(this.request).defaults(requestDefaults);\n    this.log = createLogger(options.log);\n    this.hook = hook;\n    if (!options.authStrategy) {\n      if (!options.auth) {\n        this.auth = async () => ({\n          type: \"unauthenticated\"\n        });\n      } else {\n        const auth = (0, import_auth_token.createTokenAuth)(options.auth);\n        hook.wrap(\"request\", auth.hook);\n        this.auth = auth;\n      }\n    } else {\n      const { authStrategy, ...otherOptions } = options;\n      const auth = authStrategy(\n        Object.assign(\n          {\n            request: this.request,\n            log: this.log,\n            // we pass the current octokit instance as well as its constructor options\n            // to allow for authentication strategies that return a new octokit instance\n            // that shares the same internal state as the current one. The original\n            // requirement for this was the \"event-octokit\" authentication strategy\n            // of https://github.com/probot/octokit-auth-probot.\n            octokit: this,\n            octokitOptions: otherOptions\n          },\n          options.auth\n        )\n      );\n      hook.wrap(\"request\", auth.hook);\n      this.auth = auth;\n    }\n    const classConstructor = this.constructor;\n    for (let i = 0; i < classConstructor.plugins.length; ++i) {\n      Object.assign(this, classConstructor.plugins[i](this, options));\n    }\n  }\n};\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  Octokit\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  endpoint: () => endpoint\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/defaults.js\nvar import_universal_user_agent = require(\"universal-user-agent\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"9.0.6\";\n\n// pkg/dist-src/defaults.js\nvar userAgent = `octokit-endpoint.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`;\nvar DEFAULTS = {\n  method: \"GET\",\n  baseUrl: \"https://api.github.com\",\n  headers: {\n    accept: \"application/vnd.github.v3+json\",\n    \"user-agent\": userAgent\n  },\n  mediaType: {\n    format: \"\"\n  }\n};\n\n// pkg/dist-src/util/lowercase-keys.js\nfunction lowercaseKeys(object) {\n  if (!object) {\n    return {};\n  }\n  return Object.keys(object).reduce((newObj, key) => {\n    newObj[key.toLowerCase()] = object[key];\n    return newObj;\n  }, {});\n}\n\n// pkg/dist-src/util/is-plain-object.js\nfunction isPlainObject(value) {\n  if (typeof value !== \"object\" || value === null)\n    return false;\n  if (Object.prototype.toString.call(value) !== \"[object Object]\")\n    return false;\n  const proto = Object.getPrototypeOf(value);\n  if (proto === null)\n    return true;\n  const Ctor = Object.prototype.hasOwnProperty.call(proto, \"constructor\") && proto.constructor;\n  return typeof Ctor === \"function\" && Ctor instanceof Ctor && Function.prototype.call(Ctor) === Function.prototype.call(value);\n}\n\n// pkg/dist-src/util/merge-deep.js\nfunction mergeDeep(defaults, options) {\n  const result = Object.assign({}, defaults);\n  Object.keys(options).forEach((key) => {\n    if (isPlainObject(options[key])) {\n      if (!(key in defaults))\n        Object.assign(result, { [key]: options[key] });\n      else\n        result[key] = mergeDeep(defaults[key], options[key]);\n    } else {\n      Object.assign(result, { [key]: options[key] });\n    }\n  });\n  return result;\n}\n\n// pkg/dist-src/util/remove-undefined-properties.js\nfunction removeUndefinedProperties(obj) {\n  for (const key in obj) {\n    if (obj[key] === void 0) {\n      delete obj[key];\n    }\n  }\n  return obj;\n}\n\n// pkg/dist-src/merge.js\nfunction merge(defaults, route, options) {\n  if (typeof route === \"string\") {\n    let [method, url] = route.split(\" \");\n    options = Object.assign(url ? { method, url } : { url: method }, options);\n  } else {\n    options = Object.assign({}, route);\n  }\n  options.headers = lowercaseKeys(options.headers);\n  removeUndefinedProperties(options);\n  removeUndefinedProperties(options.headers);\n  const mergedOptions = mergeDeep(defaults || {}, options);\n  if (options.url === \"/graphql\") {\n    if (defaults && defaults.mediaType.previews?.length) {\n      mergedOptions.mediaType.previews = defaults.mediaType.previews.filter(\n        (preview) => !mergedOptions.mediaType.previews.includes(preview)\n      ).concat(mergedOptions.mediaType.previews);\n    }\n    mergedOptions.mediaType.previews = (mergedOptions.mediaType.previews || []).map((preview) => preview.replace(/-preview/, \"\"));\n  }\n  return mergedOptions;\n}\n\n// pkg/dist-src/util/add-query-parameters.js\nfunction addQueryParameters(url, parameters) {\n  const separator = /\\?/.test(url) ? \"&\" : \"?\";\n  const names = Object.keys(parameters);\n  if (names.length === 0) {\n    return url;\n  }\n  return url + separator + names.map((name) => {\n    if (name === \"q\") {\n      return \"q=\" + parameters.q.split(\"+\").map(encodeURIComponent).join(\"+\");\n    }\n    return `${name}=${encodeURIComponent(parameters[name])}`;\n  }).join(\"&\");\n}\n\n// pkg/dist-src/util/extract-url-variable-names.js\nvar urlVariableRegex = /\\{[^{}}]+\\}/g;\nfunction removeNonChars(variableName) {\n  return variableName.replace(/(?:^\\W+)|(?:(?<!\\W)\\W+$)/g, \"\").split(/,/);\n}\nfunction extractUrlVariableNames(url) {\n  const matches = url.match(urlVariableRegex);\n  if (!matches) {\n    return [];\n  }\n  return matches.map(removeNonChars).reduce((a, b) => a.concat(b), []);\n}\n\n// pkg/dist-src/util/omit.js\nfunction omit(object, keysToOmit) {\n  const result = { __proto__: null };\n  for (const key of Object.keys(object)) {\n    if (keysToOmit.indexOf(key) === -1) {\n      result[key] = object[key];\n    }\n  }\n  return result;\n}\n\n// pkg/dist-src/util/url-template.js\nfunction encodeReserved(str) {\n  return str.split(/(%[0-9A-Fa-f]{2})/g).map(function(part) {\n    if (!/%[0-9A-Fa-f]/.test(part)) {\n      part = encodeURI(part).replace(/%5B/g, \"[\").replace(/%5D/g, \"]\");\n    }\n    return part;\n  }).join(\"\");\n}\nfunction encodeUnreserved(str) {\n  return encodeURIComponent(str).replace(/[!'()*]/g, function(c) {\n    return \"%\" + c.charCodeAt(0).toString(16).toUpperCase();\n  });\n}\nfunction encodeValue(operator, value, key) {\n  value = operator === \"+\" || operator === \"#\" ? encodeReserved(value) : encodeUnreserved(value);\n  if (key) {\n    return encodeUnreserved(key) + \"=\" + value;\n  } else {\n    return value;\n  }\n}\nfunction isDefined(value) {\n  return value !== void 0 && value !== null;\n}\nfunction isKeyOperator(operator) {\n  return operator === \";\" || operator === \"&\" || operator === \"?\";\n}\nfunction getValues(context, operator, key, modifier) {\n  var value = context[key], result = [];\n  if (isDefined(value) && value !== \"\") {\n    if (typeof value === \"string\" || typeof value === \"number\" || typeof value === \"boolean\") {\n      value = value.toString();\n      if (modifier && modifier !== \"*\") {\n        value = value.substring(0, parseInt(modifier, 10));\n      }\n      result.push(\n        encodeValue(operator, value, isKeyOperator(operator) ? key : \"\")\n      );\n    } else {\n      if (modifier === \"*\") {\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function(value2) {\n            result.push(\n              encodeValue(operator, value2, isKeyOperator(operator) ? key : \"\")\n            );\n          });\n        } else {\n          Object.keys(value).forEach(function(k) {\n            if (isDefined(value[k])) {\n              result.push(encodeValue(operator, value[k], k));\n            }\n          });\n        }\n      } else {\n        const tmp = [];\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function(value2) {\n            tmp.push(encodeValue(operator, value2));\n          });\n        } else {\n          Object.keys(value).forEach(function(k) {\n            if (isDefined(value[k])) {\n              tmp.push(encodeUnreserved(k));\n              tmp.push(encodeValue(operator, value[k].toString()));\n            }\n          });\n        }\n        if (isKeyOperator(operator)) {\n          result.push(encodeUnreserved(key) + \"=\" + tmp.join(\",\"));\n        } else if (tmp.length !== 0) {\n          result.push(tmp.join(\",\"));\n        }\n      }\n    }\n  } else {\n    if (operator === \";\") {\n      if (isDefined(value)) {\n        result.push(encodeUnreserved(key));\n      }\n    } else if (value === \"\" && (operator === \"&\" || operator === \"?\")) {\n      result.push(encodeUnreserved(key) + \"=\");\n    } else if (value === \"\") {\n      result.push(\"\");\n    }\n  }\n  return result;\n}\nfunction parseUrl(template) {\n  return {\n    expand: expand.bind(null, template)\n  };\n}\nfunction expand(template, context) {\n  var operators = [\"+\", \"#\", \".\", \"/\", \";\", \"?\", \"&\"];\n  template = template.replace(\n    /\\{([^\\{\\}]+)\\}|([^\\{\\}]+)/g,\n    function(_, expression, literal) {\n      if (expression) {\n        let operator = \"\";\n        const values = [];\n        if (operators.indexOf(expression.charAt(0)) !== -1) {\n          operator = expression.charAt(0);\n          expression = expression.substr(1);\n        }\n        expression.split(/,/g).forEach(function(variable) {\n          var tmp = /([^:\\*]*)(?::(\\d+)|(\\*))?/.exec(variable);\n          values.push(getValues(context, operator, tmp[1], tmp[2] || tmp[3]));\n        });\n        if (operator && operator !== \"+\") {\n          var separator = \",\";\n          if (operator === \"?\") {\n            separator = \"&\";\n          } else if (operator !== \"#\") {\n            separator = operator;\n          }\n          return (values.length !== 0 ? operator : \"\") + values.join(separator);\n        } else {\n          return values.join(\",\");\n        }\n      } else {\n        return encodeReserved(literal);\n      }\n    }\n  );\n  if (template === \"/\") {\n    return template;\n  } else {\n    return template.replace(/\\/$/, \"\");\n  }\n}\n\n// pkg/dist-src/parse.js\nfunction parse(options) {\n  let method = options.method.toUpperCase();\n  let url = (options.url || \"/\").replace(/:([a-z]\\w+)/g, \"{$1}\");\n  let headers = Object.assign({}, options.headers);\n  let body;\n  let parameters = omit(options, [\n    \"method\",\n    \"baseUrl\",\n    \"url\",\n    \"headers\",\n    \"request\",\n    \"mediaType\"\n  ]);\n  const urlVariableNames = extractUrlVariableNames(url);\n  url = parseUrl(url).expand(parameters);\n  if (!/^http/.test(url)) {\n    url = options.baseUrl + url;\n  }\n  const omittedParameters = Object.keys(options).filter((option) => urlVariableNames.includes(option)).concat(\"baseUrl\");\n  const remainingParameters = omit(parameters, omittedParameters);\n  const isBinaryRequest = /application\\/octet-stream/i.test(headers.accept);\n  if (!isBinaryRequest) {\n    if (options.mediaType.format) {\n      headers.accept = headers.accept.split(/,/).map(\n        (format) => format.replace(\n          /application\\/vnd(\\.\\w+)(\\.v3)?(\\.\\w+)?(\\+json)?$/,\n          `application/vnd$1$2.${options.mediaType.format}`\n        )\n      ).join(\",\");\n    }\n    if (url.endsWith(\"/graphql\")) {\n      if (options.mediaType.previews?.length) {\n        const previewsFromAcceptHeader = headers.accept.match(/(?<![\\w-])[\\w-]+(?=-preview)/g) || [];\n        headers.accept = previewsFromAcceptHeader.concat(options.mediaType.previews).map((preview) => {\n          const format = options.mediaType.format ? `.${options.mediaType.format}` : \"+json\";\n          return `application/vnd.github.${preview}-preview${format}`;\n        }).join(\",\");\n      }\n    }\n  }\n  if ([\"GET\", \"HEAD\"].includes(method)) {\n    url = addQueryParameters(url, remainingParameters);\n  } else {\n    if (\"data\" in remainingParameters) {\n      body = remainingParameters.data;\n    } else {\n      if (Object.keys(remainingParameters).length) {\n        body = remainingParameters;\n      }\n    }\n  }\n  if (!headers[\"content-type\"] && typeof body !== \"undefined\") {\n    headers[\"content-type\"] = \"application/json; charset=utf-8\";\n  }\n  if ([\"PATCH\", \"PUT\"].includes(method) && typeof body === \"undefined\") {\n    body = \"\";\n  }\n  return Object.assign(\n    { method, url, headers },\n    typeof body !== \"undefined\" ? { body } : null,\n    options.request ? { request: options.request } : null\n  );\n}\n\n// pkg/dist-src/endpoint-with-defaults.js\nfunction endpointWithDefaults(defaults, route, options) {\n  return parse(merge(defaults, route, options));\n}\n\n// pkg/dist-src/with-defaults.js\nfunction withDefaults(oldDefaults, newDefaults) {\n  const DEFAULTS2 = merge(oldDefaults, newDefaults);\n  const endpoint2 = endpointWithDefaults.bind(null, DEFAULTS2);\n  return Object.assign(endpoint2, {\n    DEFAULTS: DEFAULTS2,\n    defaults: withDefaults.bind(null, DEFAULTS2),\n    merge: merge.bind(null, DEFAULTS2),\n    parse\n  });\n}\n\n// pkg/dist-src/index.js\nvar endpoint = withDefaults(null, DEFAULTS);\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  endpoint\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar index_exports = {};\n__export(index_exports, {\n  GraphqlResponseError: () => GraphqlResponseError,\n  graphql: () => graphql2,\n  withCustomRequest: () => withCustomRequest\n});\nmodule.exports = __toCommonJS(index_exports);\nvar import_request3 = require(\"@octokit/request\");\nvar import_universal_user_agent = require(\"universal-user-agent\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"7.1.1\";\n\n// pkg/dist-src/with-defaults.js\nvar import_request2 = require(\"@octokit/request\");\n\n// pkg/dist-src/graphql.js\nvar import_request = require(\"@octokit/request\");\n\n// pkg/dist-src/error.js\nfunction _buildMessageForResponseErrors(data) {\n  return `Request failed due to following response errors:\n` + data.errors.map((e) => ` - ${e.message}`).join(\"\\n\");\n}\nvar GraphqlResponseError = class extends Error {\n  constructor(request2, headers, response) {\n    super(_buildMessageForResponseErrors(response));\n    this.request = request2;\n    this.headers = headers;\n    this.response = response;\n    this.name = \"GraphqlResponseError\";\n    this.errors = response.errors;\n    this.data = response.data;\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n};\n\n// pkg/dist-src/graphql.js\nvar NON_VARIABLE_OPTIONS = [\n  \"method\",\n  \"baseUrl\",\n  \"url\",\n  \"headers\",\n  \"request\",\n  \"query\",\n  \"mediaType\"\n];\nvar FORBIDDEN_VARIABLE_OPTIONS = [\"query\", \"method\", \"url\"];\nvar GHES_V3_SUFFIX_REGEX = /\\/api\\/v3\\/?$/;\nfunction graphql(request2, query, options) {\n  if (options) {\n    if (typeof query === \"string\" && \"query\" in options) {\n      return Promise.reject(\n        new Error(`[@octokit/graphql] \"query\" cannot be used as variable name`)\n      );\n    }\n    for (const key in options) {\n      if (!FORBIDDEN_VARIABLE_OPTIONS.includes(key)) continue;\n      return Promise.reject(\n        new Error(\n          `[@octokit/graphql] \"${key}\" cannot be used as variable name`\n        )\n      );\n    }\n  }\n  const parsedOptions = typeof query === \"string\" ? Object.assign({ query }, options) : query;\n  const requestOptions = Object.keys(\n    parsedOptions\n  ).reduce((result, key) => {\n    if (NON_VARIABLE_OPTIONS.includes(key)) {\n      result[key] = parsedOptions[key];\n      return result;\n    }\n    if (!result.variables) {\n      result.variables = {};\n    }\n    result.variables[key] = parsedOptions[key];\n    return result;\n  }, {});\n  const baseUrl = parsedOptions.baseUrl || request2.endpoint.DEFAULTS.baseUrl;\n  if (GHES_V3_SUFFIX_REGEX.test(baseUrl)) {\n    requestOptions.url = baseUrl.replace(GHES_V3_SUFFIX_REGEX, \"/api/graphql\");\n  }\n  return request2(requestOptions).then((response) => {\n    if (response.data.errors) {\n      const headers = {};\n      for (const key of Object.keys(response.headers)) {\n        headers[key] = response.headers[key];\n      }\n      throw new GraphqlResponseError(\n        requestOptions,\n        headers,\n        response.data\n      );\n    }\n    return response.data.data;\n  });\n}\n\n// pkg/dist-src/with-defaults.js\nfunction withDefaults(request2, newDefaults) {\n  const newRequest = request2.defaults(newDefaults);\n  const newApi = (query, options) => {\n    return graphql(newRequest, query, options);\n  };\n  return Object.assign(newApi, {\n    defaults: withDefaults.bind(null, newRequest),\n    endpoint: newRequest.endpoint\n  });\n}\n\n// pkg/dist-src/index.js\nvar graphql2 = withDefaults(import_request3.request, {\n  headers: {\n    \"user-agent\": `octokit-graphql.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`\n  },\n  method: \"POST\",\n  url: \"/graphql\"\n});\nfunction withCustomRequest(customRequest) {\n  return withDefaults(customRequest, {\n    method: \"POST\",\n    url: \"/graphql\"\n  });\n}\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  GraphqlResponseError,\n  graphql,\n  withCustomRequest\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  composePaginateRest: () => composePaginateRest,\n  isPaginatingEndpoint: () => isPaginatingEndpoint,\n  paginateRest: () => paginateRest,\n  paginatingEndpoints: () => paginatingEndpoints\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/version.js\nvar VERSION = \"9.2.2\";\n\n// pkg/dist-src/normalize-paginated-list-response.js\nfunction normalizePaginatedListResponse(response) {\n  if (!response.data) {\n    return {\n      ...response,\n      data: []\n    };\n  }\n  const responseNeedsNormalization = \"total_count\" in response.data && !(\"url\" in response.data);\n  if (!responseNeedsNormalization)\n    return response;\n  const incompleteResults = response.data.incomplete_results;\n  const repositorySelection = response.data.repository_selection;\n  const totalCount = response.data.total_count;\n  delete response.data.incomplete_results;\n  delete response.data.repository_selection;\n  delete response.data.total_count;\n  const namespaceKey = Object.keys(response.data)[0];\n  const data = response.data[namespaceKey];\n  response.data = data;\n  if (typeof incompleteResults !== \"undefined\") {\n    response.data.incomplete_results = incompleteResults;\n  }\n  if (typeof repositorySelection !== \"undefined\") {\n    response.data.repository_selection = repositorySelection;\n  }\n  response.data.total_count = totalCount;\n  return response;\n}\n\n// pkg/dist-src/iterator.js\nfunction iterator(octokit, route, parameters) {\n  const options = typeof route === \"function\" ? route.endpoint(parameters) : octokit.request.endpoint(route, parameters);\n  const requestMethod = typeof route === \"function\" ? route : octokit.request;\n  const method = options.method;\n  const headers = options.headers;\n  let url = options.url;\n  return {\n    [Symbol.asyncIterator]: () => ({\n      async next() {\n        if (!url)\n          return { done: true };\n        try {\n          const response = await requestMethod({ method, url, headers });\n          const normalizedResponse = normalizePaginatedListResponse(response);\n          url = ((normalizedResponse.headers.link || \"\").match(\n            /<([^<>]+)>;\\s*rel=\"next\"/\n          ) || [])[1];\n          return { value: normalizedResponse };\n        } catch (error) {\n          if (error.status !== 409)\n            throw error;\n          url = \"\";\n          return {\n            value: {\n              status: 200,\n              headers: {},\n              data: []\n            }\n          };\n        }\n      }\n    })\n  };\n}\n\n// pkg/dist-src/paginate.js\nfunction paginate(octokit, route, parameters, mapFn) {\n  if (typeof parameters === \"function\") {\n    mapFn = parameters;\n    parameters = void 0;\n  }\n  return gather(\n    octokit,\n    [],\n    iterator(octokit, route, parameters)[Symbol.asyncIterator](),\n    mapFn\n  );\n}\nfunction gather(octokit, results, iterator2, mapFn) {\n  return iterator2.next().then((result) => {\n    if (result.done) {\n      return results;\n    }\n    let earlyExit = false;\n    function done() {\n      earlyExit = true;\n    }\n    results = results.concat(\n      mapFn ? mapFn(result.value, done) : result.value.data\n    );\n    if (earlyExit) {\n      return results;\n    }\n    return gather(octokit, results, iterator2, mapFn);\n  });\n}\n\n// pkg/dist-src/compose-paginate.js\nvar composePaginateRest = Object.assign(paginate, {\n  iterator\n});\n\n// pkg/dist-src/generated/paginating-endpoints.js\nvar paginatingEndpoints = [\n  \"GET /advisories\",\n  \"GET /app/hook/deliveries\",\n  \"GET /app/installation-requests\",\n  \"GET /app/installations\",\n  \"GET /assignments/{assignment_id}/accepted_assignments\",\n  \"GET /classrooms\",\n  \"GET /classrooms/{classroom_id}/assignments\",\n  \"GET /enterprises/{enterprise}/dependabot/alerts\",\n  \"GET /enterprises/{enterprise}/secret-scanning/alerts\",\n  \"GET /events\",\n  \"GET /gists\",\n  \"GET /gists/public\",\n  \"GET /gists/starred\",\n  \"GET /gists/{gist_id}/comments\",\n  \"GET /gists/{gist_id}/commits\",\n  \"GET /gists/{gist_id}/forks\",\n  \"GET /installation/repositories\",\n  \"GET /issues\",\n  \"GET /licenses\",\n  \"GET /marketplace_listing/plans\",\n  \"GET /marketplace_listing/plans/{plan_id}/accounts\",\n  \"GET /marketplace_listing/stubbed/plans\",\n  \"GET /marketplace_listing/stubbed/plans/{plan_id}/accounts\",\n  \"GET /networks/{owner}/{repo}/events\",\n  \"GET /notifications\",\n  \"GET /organizations\",\n  \"GET /orgs/{org}/actions/cache/usage-by-repository\",\n  \"GET /orgs/{org}/actions/permissions/repositories\",\n  \"GET /orgs/{org}/actions/runners\",\n  \"GET /orgs/{org}/actions/secrets\",\n  \"GET /orgs/{org}/actions/secrets/{secret_name}/repositories\",\n  \"GET /orgs/{org}/actions/variables\",\n  \"GET /orgs/{org}/actions/variables/{name}/repositories\",\n  \"GET /orgs/{org}/blocks\",\n  \"GET /orgs/{org}/code-scanning/alerts\",\n  \"GET /orgs/{org}/codespaces\",\n  \"GET /orgs/{org}/codespaces/secrets\",\n  \"GET /orgs/{org}/codespaces/secrets/{secret_name}/repositories\",\n  \"GET /orgs/{org}/copilot/billing/seats\",\n  \"GET /orgs/{org}/dependabot/alerts\",\n  \"GET /orgs/{org}/dependabot/secrets\",\n  \"GET /orgs/{org}/dependabot/secrets/{secret_name}/repositories\",\n  \"GET /orgs/{org}/events\",\n  \"GET /orgs/{org}/failed_invitations\",\n  \"GET /orgs/{org}/hooks\",\n  \"GET /orgs/{org}/hooks/{hook_id}/deliveries\",\n  \"GET /orgs/{org}/installations\",\n  \"GET /orgs/{org}/invitations\",\n  \"GET /orgs/{org}/invitations/{invitation_id}/teams\",\n  \"GET /orgs/{org}/issues\",\n  \"GET /orgs/{org}/members\",\n  \"GET /orgs/{org}/members/{username}/codespaces\",\n  \"GET /orgs/{org}/migrations\",\n  \"GET /orgs/{org}/migrations/{migration_id}/repositories\",\n  \"GET /orgs/{org}/organization-roles/{role_id}/teams\",\n  \"GET /orgs/{org}/organization-roles/{role_id}/users\",\n  \"GET /orgs/{org}/outside_collaborators\",\n  \"GET /orgs/{org}/packages\",\n  \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\",\n  \"GET /orgs/{org}/personal-access-token-requests\",\n  \"GET /orgs/{org}/personal-access-token-requests/{pat_request_id}/repositories\",\n  \"GET /orgs/{org}/personal-access-tokens\",\n  \"GET /orgs/{org}/personal-access-tokens/{pat_id}/repositories\",\n  \"GET /orgs/{org}/projects\",\n  \"GET /orgs/{org}/properties/values\",\n  \"GET /orgs/{org}/public_members\",\n  \"GET /orgs/{org}/repos\",\n  \"GET /orgs/{org}/rulesets\",\n  \"GET /orgs/{org}/rulesets/rule-suites\",\n  \"GET /orgs/{org}/secret-scanning/alerts\",\n  \"GET /orgs/{org}/security-advisories\",\n  \"GET /orgs/{org}/teams\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\",\n  \"GET /orgs/{org}/teams/{team_slug}/invitations\",\n  \"GET /orgs/{org}/teams/{team_slug}/members\",\n  \"GET /orgs/{org}/teams/{team_slug}/projects\",\n  \"GET /orgs/{org}/teams/{team_slug}/repos\",\n  \"GET /orgs/{org}/teams/{team_slug}/teams\",\n  \"GET /projects/columns/{column_id}/cards\",\n  \"GET /projects/{project_id}/collaborators\",\n  \"GET /projects/{project_id}/columns\",\n  \"GET /repos/{owner}/{repo}/actions/artifacts\",\n  \"GET /repos/{owner}/{repo}/actions/caches\",\n  \"GET /repos/{owner}/{repo}/actions/organization-secrets\",\n  \"GET /repos/{owner}/{repo}/actions/organization-variables\",\n  \"GET /repos/{owner}/{repo}/actions/runners\",\n  \"GET /repos/{owner}/{repo}/actions/runs\",\n  \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts\",\n  \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/jobs\",\n  \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs\",\n  \"GET /repos/{owner}/{repo}/actions/secrets\",\n  \"GET /repos/{owner}/{repo}/actions/variables\",\n  \"GET /repos/{owner}/{repo}/actions/workflows\",\n  \"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs\",\n  \"GET /repos/{owner}/{repo}/activity\",\n  \"GET /repos/{owner}/{repo}/assignees\",\n  \"GET /repos/{owner}/{repo}/branches\",\n  \"GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations\",\n  \"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs\",\n  \"GET /repos/{owner}/{repo}/code-scanning/alerts\",\n  \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\",\n  \"GET /repos/{owner}/{repo}/code-scanning/analyses\",\n  \"GET /repos/{owner}/{repo}/codespaces\",\n  \"GET /repos/{owner}/{repo}/codespaces/devcontainers\",\n  \"GET /repos/{owner}/{repo}/codespaces/secrets\",\n  \"GET /repos/{owner}/{repo}/collaborators\",\n  \"GET /repos/{owner}/{repo}/comments\",\n  \"GET /repos/{owner}/{repo}/comments/{comment_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/commits\",\n  \"GET /repos/{owner}/{repo}/commits/{commit_sha}/comments\",\n  \"GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/check-runs\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/check-suites\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/status\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/statuses\",\n  \"GET /repos/{owner}/{repo}/contributors\",\n  \"GET /repos/{owner}/{repo}/dependabot/alerts\",\n  \"GET /repos/{owner}/{repo}/dependabot/secrets\",\n  \"GET /repos/{owner}/{repo}/deployments\",\n  \"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\",\n  \"GET /repos/{owner}/{repo}/environments\",\n  \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies\",\n  \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/apps\",\n  \"GET /repos/{owner}/{repo}/events\",\n  \"GET /repos/{owner}/{repo}/forks\",\n  \"GET /repos/{owner}/{repo}/hooks\",\n  \"GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries\",\n  \"GET /repos/{owner}/{repo}/invitations\",\n  \"GET /repos/{owner}/{repo}/issues\",\n  \"GET /repos/{owner}/{repo}/issues/comments\",\n  \"GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/issues/events\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/comments\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/events\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/labels\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/reactions\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/timeline\",\n  \"GET /repos/{owner}/{repo}/keys\",\n  \"GET /repos/{owner}/{repo}/labels\",\n  \"GET /repos/{owner}/{repo}/milestones\",\n  \"GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels\",\n  \"GET /repos/{owner}/{repo}/notifications\",\n  \"GET /repos/{owner}/{repo}/pages/builds\",\n  \"GET /repos/{owner}/{repo}/projects\",\n  \"GET /repos/{owner}/{repo}/pulls\",\n  \"GET /repos/{owner}/{repo}/pulls/comments\",\n  \"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/comments\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/commits\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments\",\n  \"GET /repos/{owner}/{repo}/releases\",\n  \"GET /repos/{owner}/{repo}/releases/{release_id}/assets\",\n  \"GET /repos/{owner}/{repo}/releases/{release_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/rules/branches/{branch}\",\n  \"GET /repos/{owner}/{repo}/rulesets\",\n  \"GET /repos/{owner}/{repo}/rulesets/rule-suites\",\n  \"GET /repos/{owner}/{repo}/secret-scanning/alerts\",\n  \"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}/locations\",\n  \"GET /repos/{owner}/{repo}/security-advisories\",\n  \"GET /repos/{owner}/{repo}/stargazers\",\n  \"GET /repos/{owner}/{repo}/subscribers\",\n  \"GET /repos/{owner}/{repo}/tags\",\n  \"GET /repos/{owner}/{repo}/teams\",\n  \"GET /repos/{owner}/{repo}/topics\",\n  \"GET /repositories\",\n  \"GET /repositories/{repository_id}/environments/{environment_name}/secrets\",\n  \"GET /repositories/{repository_id}/environments/{environment_name}/variables\",\n  \"GET /search/code\",\n  \"GET /search/commits\",\n  \"GET /search/issues\",\n  \"GET /search/labels\",\n  \"GET /search/repositories\",\n  \"GET /search/topics\",\n  \"GET /search/users\",\n  \"GET /teams/{team_id}/discussions\",\n  \"GET /teams/{team_id}/discussions/{discussion_number}/comments\",\n  \"GET /teams/{team_id}/discussions/{discussion_number}/comments/{comment_number}/reactions\",\n  \"GET /teams/{team_id}/discussions/{discussion_number}/reactions\",\n  \"GET /teams/{team_id}/invitations\",\n  \"GET /teams/{team_id}/members\",\n  \"GET /teams/{team_id}/projects\",\n  \"GET /teams/{team_id}/repos\",\n  \"GET /teams/{team_id}/teams\",\n  \"GET /user/blocks\",\n  \"GET /user/codespaces\",\n  \"GET /user/codespaces/secrets\",\n  \"GET /user/emails\",\n  \"GET /user/followers\",\n  \"GET /user/following\",\n  \"GET /user/gpg_keys\",\n  \"GET /user/installations\",\n  \"GET /user/installations/{installation_id}/repositories\",\n  \"GET /user/issues\",\n  \"GET /user/keys\",\n  \"GET /user/marketplace_purchases\",\n  \"GET /user/marketplace_purchases/stubbed\",\n  \"GET /user/memberships/orgs\",\n  \"GET /user/migrations\",\n  \"GET /user/migrations/{migration_id}/repositories\",\n  \"GET /user/orgs\",\n  \"GET /user/packages\",\n  \"GET /user/packages/{package_type}/{package_name}/versions\",\n  \"GET /user/public_emails\",\n  \"GET /user/repos\",\n  \"GET /user/repository_invitations\",\n  \"GET /user/social_accounts\",\n  \"GET /user/ssh_signing_keys\",\n  \"GET /user/starred\",\n  \"GET /user/subscriptions\",\n  \"GET /user/teams\",\n  \"GET /users\",\n  \"GET /users/{username}/events\",\n  \"GET /users/{username}/events/orgs/{org}\",\n  \"GET /users/{username}/events/public\",\n  \"GET /users/{username}/followers\",\n  \"GET /users/{username}/following\",\n  \"GET /users/{username}/gists\",\n  \"GET /users/{username}/gpg_keys\",\n  \"GET /users/{username}/keys\",\n  \"GET /users/{username}/orgs\",\n  \"GET /users/{username}/packages\",\n  \"GET /users/{username}/projects\",\n  \"GET /users/{username}/received_events\",\n  \"GET /users/{username}/received_events/public\",\n  \"GET /users/{username}/repos\",\n  \"GET /users/{username}/social_accounts\",\n  \"GET /users/{username}/ssh_signing_keys\",\n  \"GET /users/{username}/starred\",\n  \"GET /users/{username}/subscriptions\"\n];\n\n// pkg/dist-src/paginating-endpoints.js\nfunction isPaginatingEndpoint(arg) {\n  if (typeof arg === \"string\") {\n    return paginatingEndpoints.includes(arg);\n  } else {\n    return false;\n  }\n}\n\n// pkg/dist-src/index.js\nfunction paginateRest(octokit) {\n  return {\n    paginate: Object.assign(paginate.bind(null, octokit), {\n      iterator: iterator.bind(null, octokit)\n    })\n  };\n}\npaginateRest.VERSION = VERSION;\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  composePaginateRest,\n  isPaginatingEndpoint,\n  paginateRest,\n  paginatingEndpoints\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  legacyRestEndpointMethods: () => legacyRestEndpointMethods,\n  restEndpointMethods: () => restEndpointMethods\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/version.js\nvar VERSION = \"10.4.1\";\n\n// pkg/dist-src/generated/endpoints.js\nvar Endpoints = {\n  actions: {\n    addCustomLabelsToSelfHostedRunnerForOrg: [\n      \"POST /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    addCustomLabelsToSelfHostedRunnerForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    addSelectedRepoToOrgSecret: [\n      \"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    addSelectedRepoToOrgVariable: [\n      \"PUT /orgs/{org}/actions/variables/{name}/repositories/{repository_id}\"\n    ],\n    approveWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/approve\"\n    ],\n    cancelWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/cancel\"\n    ],\n    createEnvironmentVariable: [\n      \"POST /repositories/{repository_id}/environments/{environment_name}/variables\"\n    ],\n    createOrUpdateEnvironmentSecret: [\n      \"PUT /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"\n    ],\n    createOrUpdateOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}\"],\n    createOrUpdateRepoSecret: [\n      \"PUT /repos/{owner}/{repo}/actions/secrets/{secret_name}\"\n    ],\n    createOrgVariable: [\"POST /orgs/{org}/actions/variables\"],\n    createRegistrationTokenForOrg: [\n      \"POST /orgs/{org}/actions/runners/registration-token\"\n    ],\n    createRegistrationTokenForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/registration-token\"\n    ],\n    createRemoveTokenForOrg: [\"POST /orgs/{org}/actions/runners/remove-token\"],\n    createRemoveTokenForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/remove-token\"\n    ],\n    createRepoVariable: [\"POST /repos/{owner}/{repo}/actions/variables\"],\n    createWorkflowDispatch: [\n      \"POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches\"\n    ],\n    deleteActionsCacheById: [\n      \"DELETE /repos/{owner}/{repo}/actions/caches/{cache_id}\"\n    ],\n    deleteActionsCacheByKey: [\n      \"DELETE /repos/{owner}/{repo}/actions/caches{?key,ref}\"\n    ],\n    deleteArtifact: [\n      \"DELETE /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"\n    ],\n    deleteEnvironmentSecret: [\n      \"DELETE /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"\n    ],\n    deleteEnvironmentVariable: [\n      \"DELETE /repositories/{repository_id}/environments/{environment_name}/variables/{name}\"\n    ],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/actions/secrets/{secret_name}\"],\n    deleteOrgVariable: [\"DELETE /orgs/{org}/actions/variables/{name}\"],\n    deleteRepoSecret: [\n      \"DELETE /repos/{owner}/{repo}/actions/secrets/{secret_name}\"\n    ],\n    deleteRepoVariable: [\n      \"DELETE /repos/{owner}/{repo}/actions/variables/{name}\"\n    ],\n    deleteSelfHostedRunnerFromOrg: [\n      \"DELETE /orgs/{org}/actions/runners/{runner_id}\"\n    ],\n    deleteSelfHostedRunnerFromRepo: [\n      \"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}\"\n    ],\n    deleteWorkflowRun: [\"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    deleteWorkflowRunLogs: [\n      \"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"\n    ],\n    disableSelectedRepositoryGithubActionsOrganization: [\n      \"DELETE /orgs/{org}/actions/permissions/repositories/{repository_id}\"\n    ],\n    disableWorkflow: [\n      \"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/disable\"\n    ],\n    downloadArtifact: [\n      \"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}/{archive_format}\"\n    ],\n    downloadJobLogsForWorkflowRun: [\n      \"GET /repos/{owner}/{repo}/actions/jobs/{job_id}/logs\"\n    ],\n    downloadWorkflowRunAttemptLogs: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/logs\"\n    ],\n    downloadWorkflowRunLogs: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"\n    ],\n    enableSelectedRepositoryGithubActionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/repositories/{repository_id}\"\n    ],\n    enableWorkflow: [\n      \"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/enable\"\n    ],\n    forceCancelWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/force-cancel\"\n    ],\n    generateRunnerJitconfigForOrg: [\n      \"POST /orgs/{org}/actions/runners/generate-jitconfig\"\n    ],\n    generateRunnerJitconfigForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/generate-jitconfig\"\n    ],\n    getActionsCacheList: [\"GET /repos/{owner}/{repo}/actions/caches\"],\n    getActionsCacheUsage: [\"GET /repos/{owner}/{repo}/actions/cache/usage\"],\n    getActionsCacheUsageByRepoForOrg: [\n      \"GET /orgs/{org}/actions/cache/usage-by-repository\"\n    ],\n    getActionsCacheUsageForOrg: [\"GET /orgs/{org}/actions/cache/usage\"],\n    getAllowedActionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions/selected-actions\"\n    ],\n    getAllowedActionsRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions/selected-actions\"\n    ],\n    getArtifact: [\"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"],\n    getCustomOidcSubClaimForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/oidc/customization/sub\"\n    ],\n    getEnvironmentPublicKey: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/secrets/public-key\"\n    ],\n    getEnvironmentSecret: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"\n    ],\n    getEnvironmentVariable: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/variables/{name}\"\n    ],\n    getGithubActionsDefaultWorkflowPermissionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions/workflow\"\n    ],\n    getGithubActionsDefaultWorkflowPermissionsRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions/workflow\"\n    ],\n    getGithubActionsPermissionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions\"\n    ],\n    getGithubActionsPermissionsRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions\"\n    ],\n    getJobForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/jobs/{job_id}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/actions/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/actions/secrets/{secret_name}\"],\n    getOrgVariable: [\"GET /orgs/{org}/actions/variables/{name}\"],\n    getPendingDeploymentsForRun: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"\n    ],\n    getRepoPermissions: [\n      \"GET /repos/{owner}/{repo}/actions/permissions\",\n      {},\n      { renamed: [\"actions\", \"getGithubActionsPermissionsRepository\"] }\n    ],\n    getRepoPublicKey: [\"GET /repos/{owner}/{repo}/actions/secrets/public-key\"],\n    getRepoSecret: [\"GET /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    getRepoVariable: [\"GET /repos/{owner}/{repo}/actions/variables/{name}\"],\n    getReviewsForRun: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/approvals\"\n    ],\n    getSelfHostedRunnerForOrg: [\"GET /orgs/{org}/actions/runners/{runner_id}\"],\n    getSelfHostedRunnerForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/runners/{runner_id}\"\n    ],\n    getWorkflow: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}\"],\n    getWorkflowAccessToRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions/access\"\n    ],\n    getWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    getWorkflowRunAttempt: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}\"\n    ],\n    getWorkflowRunUsage: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/timing\"\n    ],\n    getWorkflowUsage: [\n      \"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/timing\"\n    ],\n    listArtifactsForRepo: [\"GET /repos/{owner}/{repo}/actions/artifacts\"],\n    listEnvironmentSecrets: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/secrets\"\n    ],\n    listEnvironmentVariables: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/variables\"\n    ],\n    listJobsForWorkflowRun: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs\"\n    ],\n    listJobsForWorkflowRunAttempt: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/jobs\"\n    ],\n    listLabelsForSelfHostedRunnerForOrg: [\n      \"GET /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    listLabelsForSelfHostedRunnerForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    listOrgSecrets: [\"GET /orgs/{org}/actions/secrets\"],\n    listOrgVariables: [\"GET /orgs/{org}/actions/variables\"],\n    listRepoOrganizationSecrets: [\n      \"GET /repos/{owner}/{repo}/actions/organization-secrets\"\n    ],\n    listRepoOrganizationVariables: [\n      \"GET /repos/{owner}/{repo}/actions/organization-variables\"\n    ],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/actions/secrets\"],\n    listRepoVariables: [\"GET /repos/{owner}/{repo}/actions/variables\"],\n    listRepoWorkflows: [\"GET /repos/{owner}/{repo}/actions/workflows\"],\n    listRunnerApplicationsForOrg: [\"GET /orgs/{org}/actions/runners/downloads\"],\n    listRunnerApplicationsForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/runners/downloads\"\n    ],\n    listSelectedReposForOrgSecret: [\n      \"GET /orgs/{org}/actions/secrets/{secret_name}/repositories\"\n    ],\n    listSelectedReposForOrgVariable: [\n      \"GET /orgs/{org}/actions/variables/{name}/repositories\"\n    ],\n    listSelectedRepositoriesEnabledGithubActionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions/repositories\"\n    ],\n    listSelfHostedRunnersForOrg: [\"GET /orgs/{org}/actions/runners\"],\n    listSelfHostedRunnersForRepo: [\"GET /repos/{owner}/{repo}/actions/runners\"],\n    listWorkflowRunArtifacts: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts\"\n    ],\n    listWorkflowRuns: [\n      \"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs\"\n    ],\n    listWorkflowRunsForRepo: [\"GET /repos/{owner}/{repo}/actions/runs\"],\n    reRunJobForWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/jobs/{job_id}/rerun\"\n    ],\n    reRunWorkflow: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun\"],\n    reRunWorkflowFailedJobs: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun-failed-jobs\"\n    ],\n    removeAllCustomLabelsFromSelfHostedRunnerForOrg: [\n      \"DELETE /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    removeAllCustomLabelsFromSelfHostedRunnerForRepo: [\n      \"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    removeCustomLabelFromSelfHostedRunnerForOrg: [\n      \"DELETE /orgs/{org}/actions/runners/{runner_id}/labels/{name}\"\n    ],\n    removeCustomLabelFromSelfHostedRunnerForRepo: [\n      \"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels/{name}\"\n    ],\n    removeSelectedRepoFromOrgSecret: [\n      \"DELETE /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    removeSelectedRepoFromOrgVariable: [\n      \"DELETE /orgs/{org}/actions/variables/{name}/repositories/{repository_id}\"\n    ],\n    reviewCustomGatesForRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/deployment_protection_rule\"\n    ],\n    reviewPendingDeploymentsForRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"\n    ],\n    setAllowedActionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/selected-actions\"\n    ],\n    setAllowedActionsRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions/selected-actions\"\n    ],\n    setCustomLabelsForSelfHostedRunnerForOrg: [\n      \"PUT /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    setCustomLabelsForSelfHostedRunnerForRepo: [\n      \"PUT /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    setCustomOidcSubClaimForRepo: [\n      \"PUT /repos/{owner}/{repo}/actions/oidc/customization/sub\"\n    ],\n    setGithubActionsDefaultWorkflowPermissionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/workflow\"\n    ],\n    setGithubActionsDefaultWorkflowPermissionsRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions/workflow\"\n    ],\n    setGithubActionsPermissionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions\"\n    ],\n    setGithubActionsPermissionsRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions\"\n    ],\n    setSelectedReposForOrgSecret: [\n      \"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories\"\n    ],\n    setSelectedReposForOrgVariable: [\n      \"PUT /orgs/{org}/actions/variables/{name}/repositories\"\n    ],\n    setSelectedRepositoriesEnabledGithubActionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/repositories\"\n    ],\n    setWorkflowAccessToRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions/access\"\n    ],\n    updateEnvironmentVariable: [\n      \"PATCH /repositories/{repository_id}/environments/{environment_name}/variables/{name}\"\n    ],\n    updateOrgVariable: [\"PATCH /orgs/{org}/actions/variables/{name}\"],\n    updateRepoVariable: [\n      \"PATCH /repos/{owner}/{repo}/actions/variables/{name}\"\n    ]\n  },\n  activity: {\n    checkRepoIsStarredByAuthenticatedUser: [\"GET /user/starred/{owner}/{repo}\"],\n    deleteRepoSubscription: [\"DELETE /repos/{owner}/{repo}/subscription\"],\n    deleteThreadSubscription: [\n      \"DELETE /notifications/threads/{thread_id}/subscription\"\n    ],\n    getFeeds: [\"GET /feeds\"],\n    getRepoSubscription: [\"GET /repos/{owner}/{repo}/subscription\"],\n    getThread: [\"GET /notifications/threads/{thread_id}\"],\n    getThreadSubscriptionForAuthenticatedUser: [\n      \"GET /notifications/threads/{thread_id}/subscription\"\n    ],\n    listEventsForAuthenticatedUser: [\"GET /users/{username}/events\"],\n    listNotificationsForAuthenticatedUser: [\"GET /notifications\"],\n    listOrgEventsForAuthenticatedUser: [\n      \"GET /users/{username}/events/orgs/{org}\"\n    ],\n    listPublicEvents: [\"GET /events\"],\n    listPublicEventsForRepoNetwork: [\"GET /networks/{owner}/{repo}/events\"],\n    listPublicEventsForUser: [\"GET /users/{username}/events/public\"],\n    listPublicOrgEvents: [\"GET /orgs/{org}/events\"],\n    listReceivedEventsForUser: [\"GET /users/{username}/received_events\"],\n    listReceivedPublicEventsForUser: [\n      \"GET /users/{username}/received_events/public\"\n    ],\n    listRepoEvents: [\"GET /repos/{owner}/{repo}/events\"],\n    listRepoNotificationsForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/notifications\"\n    ],\n    listReposStarredByAuthenticatedUser: [\"GET /user/starred\"],\n    listReposStarredByUser: [\"GET /users/{username}/starred\"],\n    listReposWatchedByUser: [\"GET /users/{username}/subscriptions\"],\n    listStargazersForRepo: [\"GET /repos/{owner}/{repo}/stargazers\"],\n    listWatchedReposForAuthenticatedUser: [\"GET /user/subscriptions\"],\n    listWatchersForRepo: [\"GET /repos/{owner}/{repo}/subscribers\"],\n    markNotificationsAsRead: [\"PUT /notifications\"],\n    markRepoNotificationsAsRead: [\"PUT /repos/{owner}/{repo}/notifications\"],\n    markThreadAsDone: [\"DELETE /notifications/threads/{thread_id}\"],\n    markThreadAsRead: [\"PATCH /notifications/threads/{thread_id}\"],\n    setRepoSubscription: [\"PUT /repos/{owner}/{repo}/subscription\"],\n    setThreadSubscription: [\n      \"PUT /notifications/threads/{thread_id}/subscription\"\n    ],\n    starRepoForAuthenticatedUser: [\"PUT /user/starred/{owner}/{repo}\"],\n    unstarRepoForAuthenticatedUser: [\"DELETE /user/starred/{owner}/{repo}\"]\n  },\n  apps: {\n    addRepoToInstallation: [\n      \"PUT /user/installations/{installation_id}/repositories/{repository_id}\",\n      {},\n      { renamed: [\"apps\", \"addRepoToInstallationForAuthenticatedUser\"] }\n    ],\n    addRepoToInstallationForAuthenticatedUser: [\n      \"PUT /user/installations/{installation_id}/repositories/{repository_id}\"\n    ],\n    checkToken: [\"POST /applications/{client_id}/token\"],\n    createFromManifest: [\"POST /app-manifests/{code}/conversions\"],\n    createInstallationAccessToken: [\n      \"POST /app/installations/{installation_id}/access_tokens\"\n    ],\n    deleteAuthorization: [\"DELETE /applications/{client_id}/grant\"],\n    deleteInstallation: [\"DELETE /app/installations/{installation_id}\"],\n    deleteToken: [\"DELETE /applications/{client_id}/token\"],\n    getAuthenticated: [\"GET /app\"],\n    getBySlug: [\"GET /apps/{app_slug}\"],\n    getInstallation: [\"GET /app/installations/{installation_id}\"],\n    getOrgInstallation: [\"GET /orgs/{org}/installation\"],\n    getRepoInstallation: [\"GET /repos/{owner}/{repo}/installation\"],\n    getSubscriptionPlanForAccount: [\n      \"GET /marketplace_listing/accounts/{account_id}\"\n    ],\n    getSubscriptionPlanForAccountStubbed: [\n      \"GET /marketplace_listing/stubbed/accounts/{account_id}\"\n    ],\n    getUserInstallation: [\"GET /users/{username}/installation\"],\n    getWebhookConfigForApp: [\"GET /app/hook/config\"],\n    getWebhookDelivery: [\"GET /app/hook/deliveries/{delivery_id}\"],\n    listAccountsForPlan: [\"GET /marketplace_listing/plans/{plan_id}/accounts\"],\n    listAccountsForPlanStubbed: [\n      \"GET /marketplace_listing/stubbed/plans/{plan_id}/accounts\"\n    ],\n    listInstallationReposForAuthenticatedUser: [\n      \"GET /user/installations/{installation_id}/repositories\"\n    ],\n    listInstallationRequestsForAuthenticatedApp: [\n      \"GET /app/installation-requests\"\n    ],\n    listInstallations: [\"GET /app/installations\"],\n    listInstallationsForAuthenticatedUser: [\"GET /user/installations\"],\n    listPlans: [\"GET /marketplace_listing/plans\"],\n    listPlansStubbed: [\"GET /marketplace_listing/stubbed/plans\"],\n    listReposAccessibleToInstallation: [\"GET /installation/repositories\"],\n    listSubscriptionsForAuthenticatedUser: [\"GET /user/marketplace_purchases\"],\n    listSubscriptionsForAuthenticatedUserStubbed: [\n      \"GET /user/marketplace_purchases/stubbed\"\n    ],\n    listWebhookDeliveries: [\"GET /app/hook/deliveries\"],\n    redeliverWebhookDelivery: [\n      \"POST /app/hook/deliveries/{delivery_id}/attempts\"\n    ],\n    removeRepoFromInstallation: [\n      \"DELETE /user/installations/{installation_id}/repositories/{repository_id}\",\n      {},\n      { renamed: [\"apps\", \"removeRepoFromInstallationForAuthenticatedUser\"] }\n    ],\n    removeRepoFromInstallationForAuthenticatedUser: [\n      \"DELETE /user/installations/{installation_id}/repositories/{repository_id}\"\n    ],\n    resetToken: [\"PATCH /applications/{client_id}/token\"],\n    revokeInstallationAccessToken: [\"DELETE /installation/token\"],\n    scopeToken: [\"POST /applications/{client_id}/token/scoped\"],\n    suspendInstallation: [\"PUT /app/installations/{installation_id}/suspended\"],\n    unsuspendInstallation: [\n      \"DELETE /app/installations/{installation_id}/suspended\"\n    ],\n    updateWebhookConfigForApp: [\"PATCH /app/hook/config\"]\n  },\n  billing: {\n    getGithubActionsBillingOrg: [\"GET /orgs/{org}/settings/billing/actions\"],\n    getGithubActionsBillingUser: [\n      \"GET /users/{username}/settings/billing/actions\"\n    ],\n    getGithubPackagesBillingOrg: [\"GET /orgs/{org}/settings/billing/packages\"],\n    getGithubPackagesBillingUser: [\n      \"GET /users/{username}/settings/billing/packages\"\n    ],\n    getSharedStorageBillingOrg: [\n      \"GET /orgs/{org}/settings/billing/shared-storage\"\n    ],\n    getSharedStorageBillingUser: [\n      \"GET /users/{username}/settings/billing/shared-storage\"\n    ]\n  },\n  checks: {\n    create: [\"POST /repos/{owner}/{repo}/check-runs\"],\n    createSuite: [\"POST /repos/{owner}/{repo}/check-suites\"],\n    get: [\"GET /repos/{owner}/{repo}/check-runs/{check_run_id}\"],\n    getSuite: [\"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}\"],\n    listAnnotations: [\n      \"GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations\"\n    ],\n    listForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-runs\"],\n    listForSuite: [\n      \"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs\"\n    ],\n    listSuitesForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-suites\"],\n    rerequestRun: [\n      \"POST /repos/{owner}/{repo}/check-runs/{check_run_id}/rerequest\"\n    ],\n    rerequestSuite: [\n      \"POST /repos/{owner}/{repo}/check-suites/{check_suite_id}/rerequest\"\n    ],\n    setSuitesPreferences: [\n      \"PATCH /repos/{owner}/{repo}/check-suites/preferences\"\n    ],\n    update: [\"PATCH /repos/{owner}/{repo}/check-runs/{check_run_id}\"]\n  },\n  codeScanning: {\n    deleteAnalysis: [\n      \"DELETE /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}{?confirm_delete}\"\n    ],\n    getAlert: [\n      \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\",\n      {},\n      { renamedParameters: { alert_id: \"alert_number\" } }\n    ],\n    getAnalysis: [\n      \"GET /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}\"\n    ],\n    getCodeqlDatabase: [\n      \"GET /repos/{owner}/{repo}/code-scanning/codeql/databases/{language}\"\n    ],\n    getDefaultSetup: [\"GET /repos/{owner}/{repo}/code-scanning/default-setup\"],\n    getSarif: [\"GET /repos/{owner}/{repo}/code-scanning/sarifs/{sarif_id}\"],\n    listAlertInstances: [\n      \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\"\n    ],\n    listAlertsForOrg: [\"GET /orgs/{org}/code-scanning/alerts\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/code-scanning/alerts\"],\n    listAlertsInstances: [\n      \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\",\n      {},\n      { renamed: [\"codeScanning\", \"listAlertInstances\"] }\n    ],\n    listCodeqlDatabases: [\n      \"GET /repos/{owner}/{repo}/code-scanning/codeql/databases\"\n    ],\n    listRecentAnalyses: [\"GET /repos/{owner}/{repo}/code-scanning/analyses\"],\n    updateAlert: [\n      \"PATCH /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\"\n    ],\n    updateDefaultSetup: [\n      \"PATCH /repos/{owner}/{repo}/code-scanning/default-setup\"\n    ],\n    uploadSarif: [\"POST /repos/{owner}/{repo}/code-scanning/sarifs\"]\n  },\n  codesOfConduct: {\n    getAllCodesOfConduct: [\"GET /codes_of_conduct\"],\n    getConductCode: [\"GET /codes_of_conduct/{key}\"]\n  },\n  codespaces: {\n    addRepositoryForSecretForAuthenticatedUser: [\n      \"PUT /user/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    addSelectedRepoToOrgSecret: [\n      \"PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    checkPermissionsForDevcontainer: [\n      \"GET /repos/{owner}/{repo}/codespaces/permissions_check\"\n    ],\n    codespaceMachinesForAuthenticatedUser: [\n      \"GET /user/codespaces/{codespace_name}/machines\"\n    ],\n    createForAuthenticatedUser: [\"POST /user/codespaces\"],\n    createOrUpdateOrgSecret: [\n      \"PUT /orgs/{org}/codespaces/secrets/{secret_name}\"\n    ],\n    createOrUpdateRepoSecret: [\n      \"PUT /repos/{owner}/{repo}/codespaces/secrets/{secret_name}\"\n    ],\n    createOrUpdateSecretForAuthenticatedUser: [\n      \"PUT /user/codespaces/secrets/{secret_name}\"\n    ],\n    createWithPrForAuthenticatedUser: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/codespaces\"\n    ],\n    createWithRepoForAuthenticatedUser: [\n      \"POST /repos/{owner}/{repo}/codespaces\"\n    ],\n    deleteForAuthenticatedUser: [\"DELETE /user/codespaces/{codespace_name}\"],\n    deleteFromOrganization: [\n      \"DELETE /orgs/{org}/members/{username}/codespaces/{codespace_name}\"\n    ],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/codespaces/secrets/{secret_name}\"],\n    deleteRepoSecret: [\n      \"DELETE /repos/{owner}/{repo}/codespaces/secrets/{secret_name}\"\n    ],\n    deleteSecretForAuthenticatedUser: [\n      \"DELETE /user/codespaces/secrets/{secret_name}\"\n    ],\n    exportForAuthenticatedUser: [\n      \"POST /user/codespaces/{codespace_name}/exports\"\n    ],\n    getCodespacesForUserInOrg: [\n      \"GET /orgs/{org}/members/{username}/codespaces\"\n    ],\n    getExportDetailsForAuthenticatedUser: [\n      \"GET /user/codespaces/{codespace_name}/exports/{export_id}\"\n    ],\n    getForAuthenticatedUser: [\"GET /user/codespaces/{codespace_name}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/codespaces/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/codespaces/secrets/{secret_name}\"],\n    getPublicKeyForAuthenticatedUser: [\n      \"GET /user/codespaces/secrets/public-key\"\n    ],\n    getRepoPublicKey: [\n      \"GET /repos/{owner}/{repo}/codespaces/secrets/public-key\"\n    ],\n    getRepoSecret: [\n      \"GET /repos/{owner}/{repo}/codespaces/secrets/{secret_name}\"\n    ],\n    getSecretForAuthenticatedUser: [\n      \"GET /user/codespaces/secrets/{secret_name}\"\n    ],\n    listDevcontainersInRepositoryForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces/devcontainers\"\n    ],\n    listForAuthenticatedUser: [\"GET /user/codespaces\"],\n    listInOrganization: [\n      \"GET /orgs/{org}/codespaces\",\n      {},\n      { renamedParameters: { org_id: \"org\" } }\n    ],\n    listInRepositoryForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces\"\n    ],\n    listOrgSecrets: [\"GET /orgs/{org}/codespaces/secrets\"],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/codespaces/secrets\"],\n    listRepositoriesForSecretForAuthenticatedUser: [\n      \"GET /user/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    listSecretsForAuthenticatedUser: [\"GET /user/codespaces/secrets\"],\n    listSelectedReposForOrgSecret: [\n      \"GET /orgs/{org}/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    preFlightWithRepoForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces/new\"\n    ],\n    publishForAuthenticatedUser: [\n      \"POST /user/codespaces/{codespace_name}/publish\"\n    ],\n    removeRepositoryForSecretForAuthenticatedUser: [\n      \"DELETE /user/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    removeSelectedRepoFromOrgSecret: [\n      \"DELETE /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    repoMachinesForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces/machines\"\n    ],\n    setRepositoriesForSecretForAuthenticatedUser: [\n      \"PUT /user/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    setSelectedReposForOrgSecret: [\n      \"PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    startForAuthenticatedUser: [\"POST /user/codespaces/{codespace_name}/start\"],\n    stopForAuthenticatedUser: [\"POST /user/codespaces/{codespace_name}/stop\"],\n    stopInOrganization: [\n      \"POST /orgs/{org}/members/{username}/codespaces/{codespace_name}/stop\"\n    ],\n    updateForAuthenticatedUser: [\"PATCH /user/codespaces/{codespace_name}\"]\n  },\n  copilot: {\n    addCopilotSeatsForTeams: [\n      \"POST /orgs/{org}/copilot/billing/selected_teams\"\n    ],\n    addCopilotSeatsForUsers: [\n      \"POST /orgs/{org}/copilot/billing/selected_users\"\n    ],\n    cancelCopilotSeatAssignmentForTeams: [\n      \"DELETE /orgs/{org}/copilot/billing/selected_teams\"\n    ],\n    cancelCopilotSeatAssignmentForUsers: [\n      \"DELETE /orgs/{org}/copilot/billing/selected_users\"\n    ],\n    getCopilotOrganizationDetails: [\"GET /orgs/{org}/copilot/billing\"],\n    getCopilotSeatDetailsForUser: [\n      \"GET /orgs/{org}/members/{username}/copilot\"\n    ],\n    listCopilotSeats: [\"GET /orgs/{org}/copilot/billing/seats\"]\n  },\n  dependabot: {\n    addSelectedRepoToOrgSecret: [\n      \"PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    createOrUpdateOrgSecret: [\n      \"PUT /orgs/{org}/dependabot/secrets/{secret_name}\"\n    ],\n    createOrUpdateRepoSecret: [\n      \"PUT /repos/{owner}/{repo}/dependabot/secrets/{secret_name}\"\n    ],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/dependabot/secrets/{secret_name}\"],\n    deleteRepoSecret: [\n      \"DELETE /repos/{owner}/{repo}/dependabot/secrets/{secret_name}\"\n    ],\n    getAlert: [\"GET /repos/{owner}/{repo}/dependabot/alerts/{alert_number}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/dependabot/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/dependabot/secrets/{secret_name}\"],\n    getRepoPublicKey: [\n      \"GET /repos/{owner}/{repo}/dependabot/secrets/public-key\"\n    ],\n    getRepoSecret: [\n      \"GET /repos/{owner}/{repo}/dependabot/secrets/{secret_name}\"\n    ],\n    listAlertsForEnterprise: [\n      \"GET /enterprises/{enterprise}/dependabot/alerts\"\n    ],\n    listAlertsForOrg: [\"GET /orgs/{org}/dependabot/alerts\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/dependabot/alerts\"],\n    listOrgSecrets: [\"GET /orgs/{org}/dependabot/secrets\"],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/dependabot/secrets\"],\n    listSelectedReposForOrgSecret: [\n      \"GET /orgs/{org}/dependabot/secrets/{secret_name}/repositories\"\n    ],\n    removeSelectedRepoFromOrgSecret: [\n      \"DELETE /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    setSelectedReposForOrgSecret: [\n      \"PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories\"\n    ],\n    updateAlert: [\n      \"PATCH /repos/{owner}/{repo}/dependabot/alerts/{alert_number}\"\n    ]\n  },\n  dependencyGraph: {\n    createRepositorySnapshot: [\n      \"POST /repos/{owner}/{repo}/dependency-graph/snapshots\"\n    ],\n    diffRange: [\n      \"GET /repos/{owner}/{repo}/dependency-graph/compare/{basehead}\"\n    ],\n    exportSbom: [\"GET /repos/{owner}/{repo}/dependency-graph/sbom\"]\n  },\n  emojis: { get: [\"GET /emojis\"] },\n  gists: {\n    checkIsStarred: [\"GET /gists/{gist_id}/star\"],\n    create: [\"POST /gists\"],\n    createComment: [\"POST /gists/{gist_id}/comments\"],\n    delete: [\"DELETE /gists/{gist_id}\"],\n    deleteComment: [\"DELETE /gists/{gist_id}/comments/{comment_id}\"],\n    fork: [\"POST /gists/{gist_id}/forks\"],\n    get: [\"GET /gists/{gist_id}\"],\n    getComment: [\"GET /gists/{gist_id}/comments/{comment_id}\"],\n    getRevision: [\"GET /gists/{gist_id}/{sha}\"],\n    list: [\"GET /gists\"],\n    listComments: [\"GET /gists/{gist_id}/comments\"],\n    listCommits: [\"GET /gists/{gist_id}/commits\"],\n    listForUser: [\"GET /users/{username}/gists\"],\n    listForks: [\"GET /gists/{gist_id}/forks\"],\n    listPublic: [\"GET /gists/public\"],\n    listStarred: [\"GET /gists/starred\"],\n    star: [\"PUT /gists/{gist_id}/star\"],\n    unstar: [\"DELETE /gists/{gist_id}/star\"],\n    update: [\"PATCH /gists/{gist_id}\"],\n    updateComment: [\"PATCH /gists/{gist_id}/comments/{comment_id}\"]\n  },\n  git: {\n    createBlob: [\"POST /repos/{owner}/{repo}/git/blobs\"],\n    createCommit: [\"POST /repos/{owner}/{repo}/git/commits\"],\n    createRef: [\"POST /repos/{owner}/{repo}/git/refs\"],\n    createTag: [\"POST /repos/{owner}/{repo}/git/tags\"],\n    createTree: [\"POST /repos/{owner}/{repo}/git/trees\"],\n    deleteRef: [\"DELETE /repos/{owner}/{repo}/git/refs/{ref}\"],\n    getBlob: [\"GET /repos/{owner}/{repo}/git/blobs/{file_sha}\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/git/commits/{commit_sha}\"],\n    getRef: [\"GET /repos/{owner}/{repo}/git/ref/{ref}\"],\n    getTag: [\"GET /repos/{owner}/{repo}/git/tags/{tag_sha}\"],\n    getTree: [\"GET /repos/{owner}/{repo}/git/trees/{tree_sha}\"],\n    listMatchingRefs: [\"GET /repos/{owner}/{repo}/git/matching-refs/{ref}\"],\n    updateRef: [\"PATCH /repos/{owner}/{repo}/git/refs/{ref}\"]\n  },\n  gitignore: {\n    getAllTemplates: [\"GET /gitignore/templates\"],\n    getTemplate: [\"GET /gitignore/templates/{name}\"]\n  },\n  interactions: {\n    getRestrictionsForAuthenticatedUser: [\"GET /user/interaction-limits\"],\n    getRestrictionsForOrg: [\"GET /orgs/{org}/interaction-limits\"],\n    getRestrictionsForRepo: [\"GET /repos/{owner}/{repo}/interaction-limits\"],\n    getRestrictionsForYourPublicRepos: [\n      \"GET /user/interaction-limits\",\n      {},\n      { renamed: [\"interactions\", \"getRestrictionsForAuthenticatedUser\"] }\n    ],\n    removeRestrictionsForAuthenticatedUser: [\"DELETE /user/interaction-limits\"],\n    removeRestrictionsForOrg: [\"DELETE /orgs/{org}/interaction-limits\"],\n    removeRestrictionsForRepo: [\n      \"DELETE /repos/{owner}/{repo}/interaction-limits\"\n    ],\n    removeRestrictionsForYourPublicRepos: [\n      \"DELETE /user/interaction-limits\",\n      {},\n      { renamed: [\"interactions\", \"removeRestrictionsForAuthenticatedUser\"] }\n    ],\n    setRestrictionsForAuthenticatedUser: [\"PUT /user/interaction-limits\"],\n    setRestrictionsForOrg: [\"PUT /orgs/{org}/interaction-limits\"],\n    setRestrictionsForRepo: [\"PUT /repos/{owner}/{repo}/interaction-limits\"],\n    setRestrictionsForYourPublicRepos: [\n      \"PUT /user/interaction-limits\",\n      {},\n      { renamed: [\"interactions\", \"setRestrictionsForAuthenticatedUser\"] }\n    ]\n  },\n  issues: {\n    addAssignees: [\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/assignees\"\n    ],\n    addLabels: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    checkUserCanBeAssigned: [\"GET /repos/{owner}/{repo}/assignees/{assignee}\"],\n    checkUserCanBeAssignedToIssue: [\n      \"GET /repos/{owner}/{repo}/issues/{issue_number}/assignees/{assignee}\"\n    ],\n    create: [\"POST /repos/{owner}/{repo}/issues\"],\n    createComment: [\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/comments\"\n    ],\n    createLabel: [\"POST /repos/{owner}/{repo}/labels\"],\n    createMilestone: [\"POST /repos/{owner}/{repo}/milestones\"],\n    deleteComment: [\n      \"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}\"\n    ],\n    deleteLabel: [\"DELETE /repos/{owner}/{repo}/labels/{name}\"],\n    deleteMilestone: [\n      \"DELETE /repos/{owner}/{repo}/milestones/{milestone_number}\"\n    ],\n    get: [\"GET /repos/{owner}/{repo}/issues/{issue_number}\"],\n    getComment: [\"GET /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    getEvent: [\"GET /repos/{owner}/{repo}/issues/events/{event_id}\"],\n    getLabel: [\"GET /repos/{owner}/{repo}/labels/{name}\"],\n    getMilestone: [\"GET /repos/{owner}/{repo}/milestones/{milestone_number}\"],\n    list: [\"GET /issues\"],\n    listAssignees: [\"GET /repos/{owner}/{repo}/assignees\"],\n    listComments: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/comments\"],\n    listCommentsForRepo: [\"GET /repos/{owner}/{repo}/issues/comments\"],\n    listEvents: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/events\"],\n    listEventsForRepo: [\"GET /repos/{owner}/{repo}/issues/events\"],\n    listEventsForTimeline: [\n      \"GET /repos/{owner}/{repo}/issues/{issue_number}/timeline\"\n    ],\n    listForAuthenticatedUser: [\"GET /user/issues\"],\n    listForOrg: [\"GET /orgs/{org}/issues\"],\n    listForRepo: [\"GET /repos/{owner}/{repo}/issues\"],\n    listLabelsForMilestone: [\n      \"GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels\"\n    ],\n    listLabelsForRepo: [\"GET /repos/{owner}/{repo}/labels\"],\n    listLabelsOnIssue: [\n      \"GET /repos/{owner}/{repo}/issues/{issue_number}/labels\"\n    ],\n    listMilestones: [\"GET /repos/{owner}/{repo}/milestones\"],\n    lock: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    removeAllLabels: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels\"\n    ],\n    removeAssignees: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/assignees\"\n    ],\n    removeLabel: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels/{name}\"\n    ],\n    setLabels: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    unlock: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    update: [\"PATCH /repos/{owner}/{repo}/issues/{issue_number}\"],\n    updateComment: [\"PATCH /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    updateLabel: [\"PATCH /repos/{owner}/{repo}/labels/{name}\"],\n    updateMilestone: [\n      \"PATCH /repos/{owner}/{repo}/milestones/{milestone_number}\"\n    ]\n  },\n  licenses: {\n    get: [\"GET /licenses/{license}\"],\n    getAllCommonlyUsed: [\"GET /licenses\"],\n    getForRepo: [\"GET /repos/{owner}/{repo}/license\"]\n  },\n  markdown: {\n    render: [\"POST /markdown\"],\n    renderRaw: [\n      \"POST /markdown/raw\",\n      { headers: { \"content-type\": \"text/plain; charset=utf-8\" } }\n    ]\n  },\n  meta: {\n    get: [\"GET /meta\"],\n    getAllVersions: [\"GET /versions\"],\n    getOctocat: [\"GET /octocat\"],\n    getZen: [\"GET /zen\"],\n    root: [\"GET /\"]\n  },\n  migrations: {\n    cancelImport: [\n      \"DELETE /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.cancelImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#cancel-an-import\"\n      }\n    ],\n    deleteArchiveForAuthenticatedUser: [\n      \"DELETE /user/migrations/{migration_id}/archive\"\n    ],\n    deleteArchiveForOrg: [\n      \"DELETE /orgs/{org}/migrations/{migration_id}/archive\"\n    ],\n    downloadArchiveForOrg: [\n      \"GET /orgs/{org}/migrations/{migration_id}/archive\"\n    ],\n    getArchiveForAuthenticatedUser: [\n      \"GET /user/migrations/{migration_id}/archive\"\n    ],\n    getCommitAuthors: [\n      \"GET /repos/{owner}/{repo}/import/authors\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.getCommitAuthors() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-commit-authors\"\n      }\n    ],\n    getImportStatus: [\n      \"GET /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.getImportStatus() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-an-import-status\"\n      }\n    ],\n    getLargeFiles: [\n      \"GET /repos/{owner}/{repo}/import/large_files\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.getLargeFiles() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-large-files\"\n      }\n    ],\n    getStatusForAuthenticatedUser: [\"GET /user/migrations/{migration_id}\"],\n    getStatusForOrg: [\"GET /orgs/{org}/migrations/{migration_id}\"],\n    listForAuthenticatedUser: [\"GET /user/migrations\"],\n    listForOrg: [\"GET /orgs/{org}/migrations\"],\n    listReposForAuthenticatedUser: [\n      \"GET /user/migrations/{migration_id}/repositories\"\n    ],\n    listReposForOrg: [\"GET /orgs/{org}/migrations/{migration_id}/repositories\"],\n    listReposForUser: [\n      \"GET /user/migrations/{migration_id}/repositories\",\n      {},\n      { renamed: [\"migrations\", \"listReposForAuthenticatedUser\"] }\n    ],\n    mapCommitAuthor: [\n      \"PATCH /repos/{owner}/{repo}/import/authors/{author_id}\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.mapCommitAuthor() is deprecated, see https://docs.github.com/rest/migrations/source-imports#map-a-commit-author\"\n      }\n    ],\n    setLfsPreference: [\n      \"PATCH /repos/{owner}/{repo}/import/lfs\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.setLfsPreference() is deprecated, see https://docs.github.com/rest/migrations/source-imports#update-git-lfs-preference\"\n      }\n    ],\n    startForAuthenticatedUser: [\"POST /user/migrations\"],\n    startForOrg: [\"POST /orgs/{org}/migrations\"],\n    startImport: [\n      \"PUT /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.startImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#start-an-import\"\n      }\n    ],\n    unlockRepoForAuthenticatedUser: [\n      \"DELETE /user/migrations/{migration_id}/repos/{repo_name}/lock\"\n    ],\n    unlockRepoForOrg: [\n      \"DELETE /orgs/{org}/migrations/{migration_id}/repos/{repo_name}/lock\"\n    ],\n    updateImport: [\n      \"PATCH /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.updateImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#update-an-import\"\n      }\n    ]\n  },\n  oidc: {\n    getOidcCustomSubTemplateForOrg: [\n      \"GET /orgs/{org}/actions/oidc/customization/sub\"\n    ],\n    updateOidcCustomSubTemplateForOrg: [\n      \"PUT /orgs/{org}/actions/oidc/customization/sub\"\n    ]\n  },\n  orgs: {\n    addSecurityManagerTeam: [\n      \"PUT /orgs/{org}/security-managers/teams/{team_slug}\"\n    ],\n    assignTeamToOrgRole: [\n      \"PUT /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}\"\n    ],\n    assignUserToOrgRole: [\n      \"PUT /orgs/{org}/organization-roles/users/{username}/{role_id}\"\n    ],\n    blockUser: [\"PUT /orgs/{org}/blocks/{username}\"],\n    cancelInvitation: [\"DELETE /orgs/{org}/invitations/{invitation_id}\"],\n    checkBlockedUser: [\"GET /orgs/{org}/blocks/{username}\"],\n    checkMembershipForUser: [\"GET /orgs/{org}/members/{username}\"],\n    checkPublicMembershipForUser: [\"GET /orgs/{org}/public_members/{username}\"],\n    convertMemberToOutsideCollaborator: [\n      \"PUT /orgs/{org}/outside_collaborators/{username}\"\n    ],\n    createCustomOrganizationRole: [\"POST /orgs/{org}/organization-roles\"],\n    createInvitation: [\"POST /orgs/{org}/invitations\"],\n    createOrUpdateCustomProperties: [\"PATCH /orgs/{org}/properties/schema\"],\n    createOrUpdateCustomPropertiesValuesForRepos: [\n      \"PATCH /orgs/{org}/properties/values\"\n    ],\n    createOrUpdateCustomProperty: [\n      \"PUT /orgs/{org}/properties/schema/{custom_property_name}\"\n    ],\n    createWebhook: [\"POST /orgs/{org}/hooks\"],\n    delete: [\"DELETE /orgs/{org}\"],\n    deleteCustomOrganizationRole: [\n      \"DELETE /orgs/{org}/organization-roles/{role_id}\"\n    ],\n    deleteWebhook: [\"DELETE /orgs/{org}/hooks/{hook_id}\"],\n    enableOrDisableSecurityProductOnAllOrgRepos: [\n      \"POST /orgs/{org}/{security_product}/{enablement}\"\n    ],\n    get: [\"GET /orgs/{org}\"],\n    getAllCustomProperties: [\"GET /orgs/{org}/properties/schema\"],\n    getCustomProperty: [\n      \"GET /orgs/{org}/properties/schema/{custom_property_name}\"\n    ],\n    getMembershipForAuthenticatedUser: [\"GET /user/memberships/orgs/{org}\"],\n    getMembershipForUser: [\"GET /orgs/{org}/memberships/{username}\"],\n    getOrgRole: [\"GET /orgs/{org}/organization-roles/{role_id}\"],\n    getWebhook: [\"GET /orgs/{org}/hooks/{hook_id}\"],\n    getWebhookConfigForOrg: [\"GET /orgs/{org}/hooks/{hook_id}/config\"],\n    getWebhookDelivery: [\n      \"GET /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}\"\n    ],\n    list: [\"GET /organizations\"],\n    listAppInstallations: [\"GET /orgs/{org}/installations\"],\n    listBlockedUsers: [\"GET /orgs/{org}/blocks\"],\n    listCustomPropertiesValuesForRepos: [\"GET /orgs/{org}/properties/values\"],\n    listFailedInvitations: [\"GET /orgs/{org}/failed_invitations\"],\n    listForAuthenticatedUser: [\"GET /user/orgs\"],\n    listForUser: [\"GET /users/{username}/orgs\"],\n    listInvitationTeams: [\"GET /orgs/{org}/invitations/{invitation_id}/teams\"],\n    listMembers: [\"GET /orgs/{org}/members\"],\n    listMembershipsForAuthenticatedUser: [\"GET /user/memberships/orgs\"],\n    listOrgRoleTeams: [\"GET /orgs/{org}/organization-roles/{role_id}/teams\"],\n    listOrgRoleUsers: [\"GET /orgs/{org}/organization-roles/{role_id}/users\"],\n    listOrgRoles: [\"GET /orgs/{org}/organization-roles\"],\n    listOrganizationFineGrainedPermissions: [\n      \"GET /orgs/{org}/organization-fine-grained-permissions\"\n    ],\n    listOutsideCollaborators: [\"GET /orgs/{org}/outside_collaborators\"],\n    listPatGrantRepositories: [\n      \"GET /orgs/{org}/personal-access-tokens/{pat_id}/repositories\"\n    ],\n    listPatGrantRequestRepositories: [\n      \"GET /orgs/{org}/personal-access-token-requests/{pat_request_id}/repositories\"\n    ],\n    listPatGrantRequests: [\"GET /orgs/{org}/personal-access-token-requests\"],\n    listPatGrants: [\"GET /orgs/{org}/personal-access-tokens\"],\n    listPendingInvitations: [\"GET /orgs/{org}/invitations\"],\n    listPublicMembers: [\"GET /orgs/{org}/public_members\"],\n    listSecurityManagerTeams: [\"GET /orgs/{org}/security-managers\"],\n    listWebhookDeliveries: [\"GET /orgs/{org}/hooks/{hook_id}/deliveries\"],\n    listWebhooks: [\"GET /orgs/{org}/hooks\"],\n    patchCustomOrganizationRole: [\n      \"PATCH /orgs/{org}/organization-roles/{role_id}\"\n    ],\n    pingWebhook: [\"POST /orgs/{org}/hooks/{hook_id}/pings\"],\n    redeliverWebhookDelivery: [\n      \"POST /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}/attempts\"\n    ],\n    removeCustomProperty: [\n      \"DELETE /orgs/{org}/properties/schema/{custom_property_name}\"\n    ],\n    removeMember: [\"DELETE /orgs/{org}/members/{username}\"],\n    removeMembershipForUser: [\"DELETE /orgs/{org}/memberships/{username}\"],\n    removeOutsideCollaborator: [\n      \"DELETE /orgs/{org}/outside_collaborators/{username}\"\n    ],\n    removePublicMembershipForAuthenticatedUser: [\n      \"DELETE /orgs/{org}/public_members/{username}\"\n    ],\n    removeSecurityManagerTeam: [\n      \"DELETE /orgs/{org}/security-managers/teams/{team_slug}\"\n    ],\n    reviewPatGrantRequest: [\n      \"POST /orgs/{org}/personal-access-token-requests/{pat_request_id}\"\n    ],\n    reviewPatGrantRequestsInBulk: [\n      \"POST /orgs/{org}/personal-access-token-requests\"\n    ],\n    revokeAllOrgRolesTeam: [\n      \"DELETE /orgs/{org}/organization-roles/teams/{team_slug}\"\n    ],\n    revokeAllOrgRolesUser: [\n      \"DELETE /orgs/{org}/organization-roles/users/{username}\"\n    ],\n    revokeOrgRoleTeam: [\n      \"DELETE /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}\"\n    ],\n    revokeOrgRoleUser: [\n      \"DELETE /orgs/{org}/organization-roles/users/{username}/{role_id}\"\n    ],\n    setMembershipForUser: [\"PUT /orgs/{org}/memberships/{username}\"],\n    setPublicMembershipForAuthenticatedUser: [\n      \"PUT /orgs/{org}/public_members/{username}\"\n    ],\n    unblockUser: [\"DELETE /orgs/{org}/blocks/{username}\"],\n    update: [\"PATCH /orgs/{org}\"],\n    updateMembershipForAuthenticatedUser: [\n      \"PATCH /user/memberships/orgs/{org}\"\n    ],\n    updatePatAccess: [\"POST /orgs/{org}/personal-access-tokens/{pat_id}\"],\n    updatePatAccesses: [\"POST /orgs/{org}/personal-access-tokens\"],\n    updateWebhook: [\"PATCH /orgs/{org}/hooks/{hook_id}\"],\n    updateWebhookConfigForOrg: [\"PATCH /orgs/{org}/hooks/{hook_id}/config\"]\n  },\n  packages: {\n    deletePackageForAuthenticatedUser: [\n      \"DELETE /user/packages/{package_type}/{package_name}\"\n    ],\n    deletePackageForOrg: [\n      \"DELETE /orgs/{org}/packages/{package_type}/{package_name}\"\n    ],\n    deletePackageForUser: [\n      \"DELETE /users/{username}/packages/{package_type}/{package_name}\"\n    ],\n    deletePackageVersionForAuthenticatedUser: [\n      \"DELETE /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    deletePackageVersionForOrg: [\n      \"DELETE /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    deletePackageVersionForUser: [\n      \"DELETE /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    getAllPackageVersionsForAPackageOwnedByAnOrg: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\",\n      {},\n      { renamed: [\"packages\", \"getAllPackageVersionsForPackageOwnedByOrg\"] }\n    ],\n    getAllPackageVersionsForAPackageOwnedByTheAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}/versions\",\n      {},\n      {\n        renamed: [\n          \"packages\",\n          \"getAllPackageVersionsForPackageOwnedByAuthenticatedUser\"\n        ]\n      }\n    ],\n    getAllPackageVersionsForPackageOwnedByAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}/versions\"\n    ],\n    getAllPackageVersionsForPackageOwnedByOrg: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\"\n    ],\n    getAllPackageVersionsForPackageOwnedByUser: [\n      \"GET /users/{username}/packages/{package_type}/{package_name}/versions\"\n    ],\n    getPackageForAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}\"\n    ],\n    getPackageForOrganization: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}\"\n    ],\n    getPackageForUser: [\n      \"GET /users/{username}/packages/{package_type}/{package_name}\"\n    ],\n    getPackageVersionForAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    getPackageVersionForOrganization: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    getPackageVersionForUser: [\n      \"GET /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    listDockerMigrationConflictingPackagesForAuthenticatedUser: [\n      \"GET /user/docker/conflicts\"\n    ],\n    listDockerMigrationConflictingPackagesForOrganization: [\n      \"GET /orgs/{org}/docker/conflicts\"\n    ],\n    listDockerMigrationConflictingPackagesForUser: [\n      \"GET /users/{username}/docker/conflicts\"\n    ],\n    listPackagesForAuthenticatedUser: [\"GET /user/packages\"],\n    listPackagesForOrganization: [\"GET /orgs/{org}/packages\"],\n    listPackagesForUser: [\"GET /users/{username}/packages\"],\n    restorePackageForAuthenticatedUser: [\n      \"POST /user/packages/{package_type}/{package_name}/restore{?token}\"\n    ],\n    restorePackageForOrg: [\n      \"POST /orgs/{org}/packages/{package_type}/{package_name}/restore{?token}\"\n    ],\n    restorePackageForUser: [\n      \"POST /users/{username}/packages/{package_type}/{package_name}/restore{?token}\"\n    ],\n    restorePackageVersionForAuthenticatedUser: [\n      \"POST /user/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"\n    ],\n    restorePackageVersionForOrg: [\n      \"POST /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"\n    ],\n    restorePackageVersionForUser: [\n      \"POST /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"\n    ]\n  },\n  projects: {\n    addCollaborator: [\"PUT /projects/{project_id}/collaborators/{username}\"],\n    createCard: [\"POST /projects/columns/{column_id}/cards\"],\n    createColumn: [\"POST /projects/{project_id}/columns\"],\n    createForAuthenticatedUser: [\"POST /user/projects\"],\n    createForOrg: [\"POST /orgs/{org}/projects\"],\n    createForRepo: [\"POST /repos/{owner}/{repo}/projects\"],\n    delete: [\"DELETE /projects/{project_id}\"],\n    deleteCard: [\"DELETE /projects/columns/cards/{card_id}\"],\n    deleteColumn: [\"DELETE /projects/columns/{column_id}\"],\n    get: [\"GET /projects/{project_id}\"],\n    getCard: [\"GET /projects/columns/cards/{card_id}\"],\n    getColumn: [\"GET /projects/columns/{column_id}\"],\n    getPermissionForUser: [\n      \"GET /projects/{project_id}/collaborators/{username}/permission\"\n    ],\n    listCards: [\"GET /projects/columns/{column_id}/cards\"],\n    listCollaborators: [\"GET /projects/{project_id}/collaborators\"],\n    listColumns: [\"GET /projects/{project_id}/columns\"],\n    listForOrg: [\"GET /orgs/{org}/projects\"],\n    listForRepo: [\"GET /repos/{owner}/{repo}/projects\"],\n    listForUser: [\"GET /users/{username}/projects\"],\n    moveCard: [\"POST /projects/columns/cards/{card_id}/moves\"],\n    moveColumn: [\"POST /projects/columns/{column_id}/moves\"],\n    removeCollaborator: [\n      \"DELETE /projects/{project_id}/collaborators/{username}\"\n    ],\n    update: [\"PATCH /projects/{project_id}\"],\n    updateCard: [\"PATCH /projects/columns/cards/{card_id}\"],\n    updateColumn: [\"PATCH /projects/columns/{column_id}\"]\n  },\n  pulls: {\n    checkIfMerged: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    create: [\"POST /repos/{owner}/{repo}/pulls\"],\n    createReplyForReviewComment: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments/{comment_id}/replies\"\n    ],\n    createReview: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    createReviewComment: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments\"\n    ],\n    deletePendingReview: [\n      \"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"\n    ],\n    deleteReviewComment: [\n      \"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}\"\n    ],\n    dismissReview: [\n      \"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/dismissals\"\n    ],\n    get: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    getReview: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"\n    ],\n    getReviewComment: [\"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}\"],\n    list: [\"GET /repos/{owner}/{repo}/pulls\"],\n    listCommentsForReview: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments\"\n    ],\n    listCommits: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/commits\"],\n    listFiles: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\"],\n    listRequestedReviewers: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"\n    ],\n    listReviewComments: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/comments\"\n    ],\n    listReviewCommentsForRepo: [\"GET /repos/{owner}/{repo}/pulls/comments\"],\n    listReviews: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    merge: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    removeRequestedReviewers: [\n      \"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"\n    ],\n    requestReviewers: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"\n    ],\n    submitReview: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/events\"\n    ],\n    update: [\"PATCH /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    updateBranch: [\n      \"PUT /repos/{owner}/{repo}/pulls/{pull_number}/update-branch\"\n    ],\n    updateReview: [\n      \"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"\n    ],\n    updateReviewComment: [\n      \"PATCH /repos/{owner}/{repo}/pulls/comments/{comment_id}\"\n    ]\n  },\n  rateLimit: { get: [\"GET /rate_limit\"] },\n  reactions: {\n    createForCommitComment: [\n      \"POST /repos/{owner}/{repo}/comments/{comment_id}/reactions\"\n    ],\n    createForIssue: [\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/reactions\"\n    ],\n    createForIssueComment: [\n      \"POST /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\"\n    ],\n    createForPullRequestReviewComment: [\n      \"POST /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\"\n    ],\n    createForRelease: [\n      \"POST /repos/{owner}/{repo}/releases/{release_id}/reactions\"\n    ],\n    createForTeamDiscussionCommentInOrg: [\n      \"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\"\n    ],\n    createForTeamDiscussionInOrg: [\n      \"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\"\n    ],\n    deleteForCommitComment: [\n      \"DELETE /repos/{owner}/{repo}/comments/{comment_id}/reactions/{reaction_id}\"\n    ],\n    deleteForIssue: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/reactions/{reaction_id}\"\n    ],\n    deleteForIssueComment: [\n      \"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions/{reaction_id}\"\n    ],\n    deleteForPullRequestComment: [\n      \"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions/{reaction_id}\"\n    ],\n    deleteForRelease: [\n      \"DELETE /repos/{owner}/{repo}/releases/{release_id}/reactions/{reaction_id}\"\n    ],\n    deleteForTeamDiscussion: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions/{reaction_id}\"\n    ],\n    deleteForTeamDiscussionComment: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions/{reaction_id}\"\n    ],\n    listForCommitComment: [\n      \"GET /repos/{owner}/{repo}/comments/{comment_id}/reactions\"\n    ],\n    listForIssue: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/reactions\"],\n    listForIssueComment: [\n      \"GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\"\n    ],\n    listForPullRequestReviewComment: [\n      \"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\"\n    ],\n    listForRelease: [\n      \"GET /repos/{owner}/{repo}/releases/{release_id}/reactions\"\n    ],\n    listForTeamDiscussionCommentInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\"\n    ],\n    listForTeamDiscussionInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\"\n    ]\n  },\n  repos: {\n    acceptInvitation: [\n      \"PATCH /user/repository_invitations/{invitation_id}\",\n      {},\n      { renamed: [\"repos\", \"acceptInvitationForAuthenticatedUser\"] }\n    ],\n    acceptInvitationForAuthenticatedUser: [\n      \"PATCH /user/repository_invitations/{invitation_id}\"\n    ],\n    addAppAccessRestrictions: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\",\n      {},\n      { mapToData: \"apps\" }\n    ],\n    addCollaborator: [\"PUT /repos/{owner}/{repo}/collaborators/{username}\"],\n    addStatusCheckContexts: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\",\n      {},\n      { mapToData: \"contexts\" }\n    ],\n    addTeamAccessRestrictions: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\",\n      {},\n      { mapToData: \"teams\" }\n    ],\n    addUserAccessRestrictions: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\",\n      {},\n      { mapToData: \"users\" }\n    ],\n    cancelPagesDeployment: [\n      \"POST /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}/cancel\"\n    ],\n    checkAutomatedSecurityFixes: [\n      \"GET /repos/{owner}/{repo}/automated-security-fixes\"\n    ],\n    checkCollaborator: [\"GET /repos/{owner}/{repo}/collaborators/{username}\"],\n    checkVulnerabilityAlerts: [\n      \"GET /repos/{owner}/{repo}/vulnerability-alerts\"\n    ],\n    codeownersErrors: [\"GET /repos/{owner}/{repo}/codeowners/errors\"],\n    compareCommits: [\"GET /repos/{owner}/{repo}/compare/{base}...{head}\"],\n    compareCommitsWithBasehead: [\n      \"GET /repos/{owner}/{repo}/compare/{basehead}\"\n    ],\n    createAutolink: [\"POST /repos/{owner}/{repo}/autolinks\"],\n    createCommitComment: [\n      \"POST /repos/{owner}/{repo}/commits/{commit_sha}/comments\"\n    ],\n    createCommitSignatureProtection: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\"\n    ],\n    createCommitStatus: [\"POST /repos/{owner}/{repo}/statuses/{sha}\"],\n    createDeployKey: [\"POST /repos/{owner}/{repo}/keys\"],\n    createDeployment: [\"POST /repos/{owner}/{repo}/deployments\"],\n    createDeploymentBranchPolicy: [\n      \"POST /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies\"\n    ],\n    createDeploymentProtectionRule: [\n      \"POST /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules\"\n    ],\n    createDeploymentStatus: [\n      \"POST /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"\n    ],\n    createDispatchEvent: [\"POST /repos/{owner}/{repo}/dispatches\"],\n    createForAuthenticatedUser: [\"POST /user/repos\"],\n    createFork: [\"POST /repos/{owner}/{repo}/forks\"],\n    createInOrg: [\"POST /orgs/{org}/repos\"],\n    createOrUpdateCustomPropertiesValues: [\n      \"PATCH /repos/{owner}/{repo}/properties/values\"\n    ],\n    createOrUpdateEnvironment: [\n      \"PUT /repos/{owner}/{repo}/environments/{environment_name}\"\n    ],\n    createOrUpdateFileContents: [\"PUT /repos/{owner}/{repo}/contents/{path}\"],\n    createOrgRuleset: [\"POST /orgs/{org}/rulesets\"],\n    createPagesDeployment: [\"POST /repos/{owner}/{repo}/pages/deployments\"],\n    createPagesSite: [\"POST /repos/{owner}/{repo}/pages\"],\n    createRelease: [\"POST /repos/{owner}/{repo}/releases\"],\n    createRepoRuleset: [\"POST /repos/{owner}/{repo}/rulesets\"],\n    createTagProtection: [\"POST /repos/{owner}/{repo}/tags/protection\"],\n    createUsingTemplate: [\n      \"POST /repos/{template_owner}/{template_repo}/generate\"\n    ],\n    createWebhook: [\"POST /repos/{owner}/{repo}/hooks\"],\n    declineInvitation: [\n      \"DELETE /user/repository_invitations/{invitation_id}\",\n      {},\n      { renamed: [\"repos\", \"declineInvitationForAuthenticatedUser\"] }\n    ],\n    declineInvitationForAuthenticatedUser: [\n      \"DELETE /user/repository_invitations/{invitation_id}\"\n    ],\n    delete: [\"DELETE /repos/{owner}/{repo}\"],\n    deleteAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"\n    ],\n    deleteAdminBranchProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"\n    ],\n    deleteAnEnvironment: [\n      \"DELETE /repos/{owner}/{repo}/environments/{environment_name}\"\n    ],\n    deleteAutolink: [\"DELETE /repos/{owner}/{repo}/autolinks/{autolink_id}\"],\n    deleteBranchProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection\"\n    ],\n    deleteCommitComment: [\"DELETE /repos/{owner}/{repo}/comments/{comment_id}\"],\n    deleteCommitSignatureProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\"\n    ],\n    deleteDeployKey: [\"DELETE /repos/{owner}/{repo}/keys/{key_id}\"],\n    deleteDeployment: [\n      \"DELETE /repos/{owner}/{repo}/deployments/{deployment_id}\"\n    ],\n    deleteDeploymentBranchPolicy: [\n      \"DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}\"\n    ],\n    deleteFile: [\"DELETE /repos/{owner}/{repo}/contents/{path}\"],\n    deleteInvitation: [\n      \"DELETE /repos/{owner}/{repo}/invitations/{invitation_id}\"\n    ],\n    deleteOrgRuleset: [\"DELETE /orgs/{org}/rulesets/{ruleset_id}\"],\n    deletePagesSite: [\"DELETE /repos/{owner}/{repo}/pages\"],\n    deletePullRequestReviewProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"\n    ],\n    deleteRelease: [\"DELETE /repos/{owner}/{repo}/releases/{release_id}\"],\n    deleteReleaseAsset: [\n      \"DELETE /repos/{owner}/{repo}/releases/assets/{asset_id}\"\n    ],\n    deleteRepoRuleset: [\"DELETE /repos/{owner}/{repo}/rulesets/{ruleset_id}\"],\n    deleteTagProtection: [\n      \"DELETE /repos/{owner}/{repo}/tags/protection/{tag_protection_id}\"\n    ],\n    deleteWebhook: [\"DELETE /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    disableAutomatedSecurityFixes: [\n      \"DELETE /repos/{owner}/{repo}/automated-security-fixes\"\n    ],\n    disableDeploymentProtectionRule: [\n      \"DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}\"\n    ],\n    disablePrivateVulnerabilityReporting: [\n      \"DELETE /repos/{owner}/{repo}/private-vulnerability-reporting\"\n    ],\n    disableVulnerabilityAlerts: [\n      \"DELETE /repos/{owner}/{repo}/vulnerability-alerts\"\n    ],\n    downloadArchive: [\n      \"GET /repos/{owner}/{repo}/zipball/{ref}\",\n      {},\n      { renamed: [\"repos\", \"downloadZipballArchive\"] }\n    ],\n    downloadTarballArchive: [\"GET /repos/{owner}/{repo}/tarball/{ref}\"],\n    downloadZipballArchive: [\"GET /repos/{owner}/{repo}/zipball/{ref}\"],\n    enableAutomatedSecurityFixes: [\n      \"PUT /repos/{owner}/{repo}/automated-security-fixes\"\n    ],\n    enablePrivateVulnerabilityReporting: [\n      \"PUT /repos/{owner}/{repo}/private-vulnerability-reporting\"\n    ],\n    enableVulnerabilityAlerts: [\n      \"PUT /repos/{owner}/{repo}/vulnerability-alerts\"\n    ],\n    generateReleaseNotes: [\n      \"POST /repos/{owner}/{repo}/releases/generate-notes\"\n    ],\n    get: [\"GET /repos/{owner}/{repo}\"],\n    getAccessRestrictions: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"\n    ],\n    getAdminBranchProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"\n    ],\n    getAllDeploymentProtectionRules: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules\"\n    ],\n    getAllEnvironments: [\"GET /repos/{owner}/{repo}/environments\"],\n    getAllStatusCheckContexts: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\"\n    ],\n    getAllTopics: [\"GET /repos/{owner}/{repo}/topics\"],\n    getAppsWithAccessToProtectedBranch: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\"\n    ],\n    getAutolink: [\"GET /repos/{owner}/{repo}/autolinks/{autolink_id}\"],\n    getBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}\"],\n    getBranchProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection\"\n    ],\n    getBranchRules: [\"GET /repos/{owner}/{repo}/rules/branches/{branch}\"],\n    getClones: [\"GET /repos/{owner}/{repo}/traffic/clones\"],\n    getCodeFrequencyStats: [\"GET /repos/{owner}/{repo}/stats/code_frequency\"],\n    getCollaboratorPermissionLevel: [\n      \"GET /repos/{owner}/{repo}/collaborators/{username}/permission\"\n    ],\n    getCombinedStatusForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/status\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/commits/{ref}\"],\n    getCommitActivityStats: [\"GET /repos/{owner}/{repo}/stats/commit_activity\"],\n    getCommitComment: [\"GET /repos/{owner}/{repo}/comments/{comment_id}\"],\n    getCommitSignatureProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\"\n    ],\n    getCommunityProfileMetrics: [\"GET /repos/{owner}/{repo}/community/profile\"],\n    getContent: [\"GET /repos/{owner}/{repo}/contents/{path}\"],\n    getContributorsStats: [\"GET /repos/{owner}/{repo}/stats/contributors\"],\n    getCustomDeploymentProtectionRule: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}\"\n    ],\n    getCustomPropertiesValues: [\"GET /repos/{owner}/{repo}/properties/values\"],\n    getDeployKey: [\"GET /repos/{owner}/{repo}/keys/{key_id}\"],\n    getDeployment: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}\"],\n    getDeploymentBranchPolicy: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}\"\n    ],\n    getDeploymentStatus: [\n      \"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses/{status_id}\"\n    ],\n    getEnvironment: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}\"\n    ],\n    getLatestPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/latest\"],\n    getLatestRelease: [\"GET /repos/{owner}/{repo}/releases/latest\"],\n    getOrgRuleSuite: [\"GET /orgs/{org}/rulesets/rule-suites/{rule_suite_id}\"],\n    getOrgRuleSuites: [\"GET /orgs/{org}/rulesets/rule-suites\"],\n    getOrgRuleset: [\"GET /orgs/{org}/rulesets/{ruleset_id}\"],\n    getOrgRulesets: [\"GET /orgs/{org}/rulesets\"],\n    getPages: [\"GET /repos/{owner}/{repo}/pages\"],\n    getPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/{build_id}\"],\n    getPagesDeployment: [\n      \"GET /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}\"\n    ],\n    getPagesHealthCheck: [\"GET /repos/{owner}/{repo}/pages/health\"],\n    getParticipationStats: [\"GET /repos/{owner}/{repo}/stats/participation\"],\n    getPullRequestReviewProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"\n    ],\n    getPunchCardStats: [\"GET /repos/{owner}/{repo}/stats/punch_card\"],\n    getReadme: [\"GET /repos/{owner}/{repo}/readme\"],\n    getReadmeInDirectory: [\"GET /repos/{owner}/{repo}/readme/{dir}\"],\n    getRelease: [\"GET /repos/{owner}/{repo}/releases/{release_id}\"],\n    getReleaseAsset: [\"GET /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    getReleaseByTag: [\"GET /repos/{owner}/{repo}/releases/tags/{tag}\"],\n    getRepoRuleSuite: [\n      \"GET /repos/{owner}/{repo}/rulesets/rule-suites/{rule_suite_id}\"\n    ],\n    getRepoRuleSuites: [\"GET /repos/{owner}/{repo}/rulesets/rule-suites\"],\n    getRepoRuleset: [\"GET /repos/{owner}/{repo}/rulesets/{ruleset_id}\"],\n    getRepoRulesets: [\"GET /repos/{owner}/{repo}/rulesets\"],\n    getStatusChecksProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"\n    ],\n    getTeamsWithAccessToProtectedBranch: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\"\n    ],\n    getTopPaths: [\"GET /repos/{owner}/{repo}/traffic/popular/paths\"],\n    getTopReferrers: [\"GET /repos/{owner}/{repo}/traffic/popular/referrers\"],\n    getUsersWithAccessToProtectedBranch: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\"\n    ],\n    getViews: [\"GET /repos/{owner}/{repo}/traffic/views\"],\n    getWebhook: [\"GET /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    getWebhookConfigForRepo: [\n      \"GET /repos/{owner}/{repo}/hooks/{hook_id}/config\"\n    ],\n    getWebhookDelivery: [\n      \"GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}\"\n    ],\n    listActivities: [\"GET /repos/{owner}/{repo}/activity\"],\n    listAutolinks: [\"GET /repos/{owner}/{repo}/autolinks\"],\n    listBranches: [\"GET /repos/{owner}/{repo}/branches\"],\n    listBranchesForHeadCommit: [\n      \"GET /repos/{owner}/{repo}/commits/{commit_sha}/branches-where-head\"\n    ],\n    listCollaborators: [\"GET /repos/{owner}/{repo}/collaborators\"],\n    listCommentsForCommit: [\n      \"GET /repos/{owner}/{repo}/commits/{commit_sha}/comments\"\n    ],\n    listCommitCommentsForRepo: [\"GET /repos/{owner}/{repo}/comments\"],\n    listCommitStatusesForRef: [\n      \"GET /repos/{owner}/{repo}/commits/{ref}/statuses\"\n    ],\n    listCommits: [\"GET /repos/{owner}/{repo}/commits\"],\n    listContributors: [\"GET /repos/{owner}/{repo}/contributors\"],\n    listCustomDeploymentRuleIntegrations: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/apps\"\n    ],\n    listDeployKeys: [\"GET /repos/{owner}/{repo}/keys\"],\n    listDeploymentBranchPolicies: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies\"\n    ],\n    listDeploymentStatuses: [\n      \"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"\n    ],\n    listDeployments: [\"GET /repos/{owner}/{repo}/deployments\"],\n    listForAuthenticatedUser: [\"GET /user/repos\"],\n    listForOrg: [\"GET /orgs/{org}/repos\"],\n    listForUser: [\"GET /users/{username}/repos\"],\n    listForks: [\"GET /repos/{owner}/{repo}/forks\"],\n    listInvitations: [\"GET /repos/{owner}/{repo}/invitations\"],\n    listInvitationsForAuthenticatedUser: [\"GET /user/repository_invitations\"],\n    listLanguages: [\"GET /repos/{owner}/{repo}/languages\"],\n    listPagesBuilds: [\"GET /repos/{owner}/{repo}/pages/builds\"],\n    listPublic: [\"GET /repositories\"],\n    listPullRequestsAssociatedWithCommit: [\n      \"GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls\"\n    ],\n    listReleaseAssets: [\n      \"GET /repos/{owner}/{repo}/releases/{release_id}/assets\"\n    ],\n    listReleases: [\"GET /repos/{owner}/{repo}/releases\"],\n    listTagProtection: [\"GET /repos/{owner}/{repo}/tags/protection\"],\n    listTags: [\"GET /repos/{owner}/{repo}/tags\"],\n    listTeams: [\"GET /repos/{owner}/{repo}/teams\"],\n    listWebhookDeliveries: [\n      \"GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries\"\n    ],\n    listWebhooks: [\"GET /repos/{owner}/{repo}/hooks\"],\n    merge: [\"POST /repos/{owner}/{repo}/merges\"],\n    mergeUpstream: [\"POST /repos/{owner}/{repo}/merge-upstream\"],\n    pingWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/pings\"],\n    redeliverWebhookDelivery: [\n      \"POST /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}/attempts\"\n    ],\n    removeAppAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\",\n      {},\n      { mapToData: \"apps\" }\n    ],\n    removeCollaborator: [\n      \"DELETE /repos/{owner}/{repo}/collaborators/{username}\"\n    ],\n    removeStatusCheckContexts: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\",\n      {},\n      { mapToData: \"contexts\" }\n    ],\n    removeStatusCheckProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"\n    ],\n    removeTeamAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\",\n      {},\n      { mapToData: \"teams\" }\n    ],\n    removeUserAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\",\n      {},\n      { mapToData: \"users\" }\n    ],\n    renameBranch: [\"POST /repos/{owner}/{repo}/branches/{branch}/rename\"],\n    replaceAllTopics: [\"PUT /repos/{owner}/{repo}/topics\"],\n    requestPagesBuild: [\"POST /repos/{owner}/{repo}/pages/builds\"],\n    setAdminBranchProtection: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"\n    ],\n    setAppAccessRestrictions: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\",\n      {},\n      { mapToData: \"apps\" }\n    ],\n    setStatusCheckContexts: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\",\n      {},\n      { mapToData: \"contexts\" }\n    ],\n    setTeamAccessRestrictions: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\",\n      {},\n      { mapToData: \"teams\" }\n    ],\n    setUserAccessRestrictions: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\",\n      {},\n      { mapToData: \"users\" }\n    ],\n    testPushWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/tests\"],\n    transfer: [\"POST /repos/{owner}/{repo}/transfer\"],\n    update: [\"PATCH /repos/{owner}/{repo}\"],\n    updateBranchProtection: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection\"\n    ],\n    updateCommitComment: [\"PATCH /repos/{owner}/{repo}/comments/{comment_id}\"],\n    updateDeploymentBranchPolicy: [\n      \"PUT /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}\"\n    ],\n    updateInformationAboutPagesSite: [\"PUT /repos/{owner}/{repo}/pages\"],\n    updateInvitation: [\n      \"PATCH /repos/{owner}/{repo}/invitations/{invitation_id}\"\n    ],\n    updateOrgRuleset: [\"PUT /orgs/{org}/rulesets/{ruleset_id}\"],\n    updatePullRequestReviewProtection: [\n      \"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"\n    ],\n    updateRelease: [\"PATCH /repos/{owner}/{repo}/releases/{release_id}\"],\n    updateReleaseAsset: [\n      \"PATCH /repos/{owner}/{repo}/releases/assets/{asset_id}\"\n    ],\n    updateRepoRuleset: [\"PUT /repos/{owner}/{repo}/rulesets/{ruleset_id}\"],\n    updateStatusCheckPotection: [\n      \"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\",\n      {},\n      { renamed: [\"repos\", \"updateStatusCheckProtection\"] }\n    ],\n    updateStatusCheckProtection: [\n      \"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"\n    ],\n    updateWebhook: [\"PATCH /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    updateWebhookConfigForRepo: [\n      \"PATCH /repos/{owner}/{repo}/hooks/{hook_id}/config\"\n    ],\n    uploadReleaseAsset: [\n      \"POST /repos/{owner}/{repo}/releases/{release_id}/assets{?name,label}\",\n      { baseUrl: \"https://uploads.github.com\" }\n    ]\n  },\n  search: {\n    code: [\"GET /search/code\"],\n    commits: [\"GET /search/commits\"],\n    issuesAndPullRequests: [\"GET /search/issues\"],\n    labels: [\"GET /search/labels\"],\n    repos: [\"GET /search/repositories\"],\n    topics: [\"GET /search/topics\"],\n    users: [\"GET /search/users\"]\n  },\n  secretScanning: {\n    getAlert: [\n      \"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"\n    ],\n    listAlertsForEnterprise: [\n      \"GET /enterprises/{enterprise}/secret-scanning/alerts\"\n    ],\n    listAlertsForOrg: [\"GET /orgs/{org}/secret-scanning/alerts\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/secret-scanning/alerts\"],\n    listLocationsForAlert: [\n      \"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}/locations\"\n    ],\n    updateAlert: [\n      \"PATCH /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"\n    ]\n  },\n  securityAdvisories: {\n    createFork: [\n      \"POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/forks\"\n    ],\n    createPrivateVulnerabilityReport: [\n      \"POST /repos/{owner}/{repo}/security-advisories/reports\"\n    ],\n    createRepositoryAdvisory: [\n      \"POST /repos/{owner}/{repo}/security-advisories\"\n    ],\n    createRepositoryAdvisoryCveRequest: [\n      \"POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/cve\"\n    ],\n    getGlobalAdvisory: [\"GET /advisories/{ghsa_id}\"],\n    getRepositoryAdvisory: [\n      \"GET /repos/{owner}/{repo}/security-advisories/{ghsa_id}\"\n    ],\n    listGlobalAdvisories: [\"GET /advisories\"],\n    listOrgRepositoryAdvisories: [\"GET /orgs/{org}/security-advisories\"],\n    listRepositoryAdvisories: [\"GET /repos/{owner}/{repo}/security-advisories\"],\n    updateRepositoryAdvisory: [\n      \"PATCH /repos/{owner}/{repo}/security-advisories/{ghsa_id}\"\n    ]\n  },\n  teams: {\n    addOrUpdateMembershipForUserInOrg: [\n      \"PUT /orgs/{org}/teams/{team_slug}/memberships/{username}\"\n    ],\n    addOrUpdateProjectPermissionsInOrg: [\n      \"PUT /orgs/{org}/teams/{team_slug}/projects/{project_id}\"\n    ],\n    addOrUpdateRepoPermissionsInOrg: [\n      \"PUT /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"\n    ],\n    checkPermissionsForProjectInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/projects/{project_id}\"\n    ],\n    checkPermissionsForRepoInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"\n    ],\n    create: [\"POST /orgs/{org}/teams\"],\n    createDiscussionCommentInOrg: [\n      \"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"\n    ],\n    createDiscussionInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions\"],\n    deleteDiscussionCommentInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"\n    ],\n    deleteDiscussionInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"\n    ],\n    deleteInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}\"],\n    getByName: [\"GET /orgs/{org}/teams/{team_slug}\"],\n    getDiscussionCommentInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"\n    ],\n    getDiscussionInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"\n    ],\n    getMembershipForUserInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/memberships/{username}\"\n    ],\n    list: [\"GET /orgs/{org}/teams\"],\n    listChildInOrg: [\"GET /orgs/{org}/teams/{team_slug}/teams\"],\n    listDiscussionCommentsInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"\n    ],\n    listDiscussionsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions\"],\n    listForAuthenticatedUser: [\"GET /user/teams\"],\n    listMembersInOrg: [\"GET /orgs/{org}/teams/{team_slug}/members\"],\n    listPendingInvitationsInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/invitations\"\n    ],\n    listProjectsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/projects\"],\n    listReposInOrg: [\"GET /orgs/{org}/teams/{team_slug}/repos\"],\n    removeMembershipForUserInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/memberships/{username}\"\n    ],\n    removeProjectInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/projects/{project_id}\"\n    ],\n    removeRepoInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"\n    ],\n    updateDiscussionCommentInOrg: [\n      \"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"\n    ],\n    updateDiscussionInOrg: [\n      \"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"\n    ],\n    updateInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}\"]\n  },\n  users: {\n    addEmailForAuthenticated: [\n      \"POST /user/emails\",\n      {},\n      { renamed: [\"users\", \"addEmailForAuthenticatedUser\"] }\n    ],\n    addEmailForAuthenticatedUser: [\"POST /user/emails\"],\n    addSocialAccountForAuthenticatedUser: [\"POST /user/social_accounts\"],\n    block: [\"PUT /user/blocks/{username}\"],\n    checkBlocked: [\"GET /user/blocks/{username}\"],\n    checkFollowingForUser: [\"GET /users/{username}/following/{target_user}\"],\n    checkPersonIsFollowedByAuthenticated: [\"GET /user/following/{username}\"],\n    createGpgKeyForAuthenticated: [\n      \"POST /user/gpg_keys\",\n      {},\n      { renamed: [\"users\", \"createGpgKeyForAuthenticatedUser\"] }\n    ],\n    createGpgKeyForAuthenticatedUser: [\"POST /user/gpg_keys\"],\n    createPublicSshKeyForAuthenticated: [\n      \"POST /user/keys\",\n      {},\n      { renamed: [\"users\", \"createPublicSshKeyForAuthenticatedUser\"] }\n    ],\n    createPublicSshKeyForAuthenticatedUser: [\"POST /user/keys\"],\n    createSshSigningKeyForAuthenticatedUser: [\"POST /user/ssh_signing_keys\"],\n    deleteEmailForAuthenticated: [\n      \"DELETE /user/emails\",\n      {},\n      { renamed: [\"users\", \"deleteEmailForAuthenticatedUser\"] }\n    ],\n    deleteEmailForAuthenticatedUser: [\"DELETE /user/emails\"],\n    deleteGpgKeyForAuthenticated: [\n      \"DELETE /user/gpg_keys/{gpg_key_id}\",\n      {},\n      { renamed: [\"users\", \"deleteGpgKeyForAuthenticatedUser\"] }\n    ],\n    deleteGpgKeyForAuthenticatedUser: [\"DELETE /user/gpg_keys/{gpg_key_id}\"],\n    deletePublicSshKeyForAuthenticated: [\n      \"DELETE /user/keys/{key_id}\",\n      {},\n      { renamed: [\"users\", \"deletePublicSshKeyForAuthenticatedUser\"] }\n    ],\n    deletePublicSshKeyForAuthenticatedUser: [\"DELETE /user/keys/{key_id}\"],\n    deleteSocialAccountForAuthenticatedUser: [\"DELETE /user/social_accounts\"],\n    deleteSshSigningKeyForAuthenticatedUser: [\n      \"DELETE /user/ssh_signing_keys/{ssh_signing_key_id}\"\n    ],\n    follow: [\"PUT /user/following/{username}\"],\n    getAuthenticated: [\"GET /user\"],\n    getByUsername: [\"GET /users/{username}\"],\n    getContextForUser: [\"GET /users/{username}/hovercard\"],\n    getGpgKeyForAuthenticated: [\n      \"GET /user/gpg_keys/{gpg_key_id}\",\n      {},\n      { renamed: [\"users\", \"getGpgKeyForAuthenticatedUser\"] }\n    ],\n    getGpgKeyForAuthenticatedUser: [\"GET /user/gpg_keys/{gpg_key_id}\"],\n    getPublicSshKeyForAuthenticated: [\n      \"GET /user/keys/{key_id}\",\n      {},\n      { renamed: [\"users\", \"getPublicSshKeyForAuthenticatedUser\"] }\n    ],\n    getPublicSshKeyForAuthenticatedUser: [\"GET /user/keys/{key_id}\"],\n    getSshSigningKeyForAuthenticatedUser: [\n      \"GET /user/ssh_signing_keys/{ssh_signing_key_id}\"\n    ],\n    list: [\"GET /users\"],\n    listBlockedByAuthenticated: [\n      \"GET /user/blocks\",\n      {},\n      { renamed: [\"users\", \"listBlockedByAuthenticatedUser\"] }\n    ],\n    listBlockedByAuthenticatedUser: [\"GET /user/blocks\"],\n    listEmailsForAuthenticated: [\n      \"GET /user/emails\",\n      {},\n      { renamed: [\"users\", \"listEmailsForAuthenticatedUser\"] }\n    ],\n    listEmailsForAuthenticatedUser: [\"GET /user/emails\"],\n    listFollowedByAuthenticated: [\n      \"GET /user/following\",\n      {},\n      { renamed: [\"users\", \"listFollowedByAuthenticatedUser\"] }\n    ],\n    listFollowedByAuthenticatedUser: [\"GET /user/following\"],\n    listFollowersForAuthenticatedUser: [\"GET /user/followers\"],\n    listFollowersForUser: [\"GET /users/{username}/followers\"],\n    listFollowingForUser: [\"GET /users/{username}/following\"],\n    listGpgKeysForAuthenticated: [\n      \"GET /user/gpg_keys\",\n      {},\n      { renamed: [\"users\", \"listGpgKeysForAuthenticatedUser\"] }\n    ],\n    listGpgKeysForAuthenticatedUser: [\"GET /user/gpg_keys\"],\n    listGpgKeysForUser: [\"GET /users/{username}/gpg_keys\"],\n    listPublicEmailsForAuthenticated: [\n      \"GET /user/public_emails\",\n      {},\n      { renamed: [\"users\", \"listPublicEmailsForAuthenticatedUser\"] }\n    ],\n    listPublicEmailsForAuthenticatedUser: [\"GET /user/public_emails\"],\n    listPublicKeysForUser: [\"GET /users/{username}/keys\"],\n    listPublicSshKeysForAuthenticated: [\n      \"GET /user/keys\",\n      {},\n      { renamed: [\"users\", \"listPublicSshKeysForAuthenticatedUser\"] }\n    ],\n    listPublicSshKeysForAuthenticatedUser: [\"GET /user/keys\"],\n    listSocialAccountsForAuthenticatedUser: [\"GET /user/social_accounts\"],\n    listSocialAccountsForUser: [\"GET /users/{username}/social_accounts\"],\n    listSshSigningKeysForAuthenticatedUser: [\"GET /user/ssh_signing_keys\"],\n    listSshSigningKeysForUser: [\"GET /users/{username}/ssh_signing_keys\"],\n    setPrimaryEmailVisibilityForAuthenticated: [\n      \"PATCH /user/email/visibility\",\n      {},\n      { renamed: [\"users\", \"setPrimaryEmailVisibilityForAuthenticatedUser\"] }\n    ],\n    setPrimaryEmailVisibilityForAuthenticatedUser: [\n      \"PATCH /user/email/visibility\"\n    ],\n    unblock: [\"DELETE /user/blocks/{username}\"],\n    unfollow: [\"DELETE /user/following/{username}\"],\n    updateAuthenticated: [\"PATCH /user\"]\n  }\n};\nvar endpoints_default = Endpoints;\n\n// pkg/dist-src/endpoints-to-methods.js\nvar endpointMethodsMap = /* @__PURE__ */ new Map();\nfor (const [scope, endpoints] of Object.entries(endpoints_default)) {\n  for (const [methodName, endpoint] of Object.entries(endpoints)) {\n    const [route, defaults, decorations] = endpoint;\n    const [method, url] = route.split(/ /);\n    const endpointDefaults = Object.assign(\n      {\n        method,\n        url\n      },\n      defaults\n    );\n    if (!endpointMethodsMap.has(scope)) {\n      endpointMethodsMap.set(scope, /* @__PURE__ */ new Map());\n    }\n    endpointMethodsMap.get(scope).set(methodName, {\n      scope,\n      methodName,\n      endpointDefaults,\n      decorations\n    });\n  }\n}\nvar handler = {\n  has({ scope }, methodName) {\n    return endpointMethodsMap.get(scope).has(methodName);\n  },\n  getOwnPropertyDescriptor(target, methodName) {\n    return {\n      value: this.get(target, methodName),\n      // ensures method is in the cache\n      configurable: true,\n      writable: true,\n      enumerable: true\n    };\n  },\n  defineProperty(target, methodName, descriptor) {\n    Object.defineProperty(target.cache, methodName, descriptor);\n    return true;\n  },\n  deleteProperty(target, methodName) {\n    delete target.cache[methodName];\n    return true;\n  },\n  ownKeys({ scope }) {\n    return [...endpointMethodsMap.get(scope).keys()];\n  },\n  set(target, methodName, value) {\n    return target.cache[methodName] = value;\n  },\n  get({ octokit, scope, cache }, methodName) {\n    if (cache[methodName]) {\n      return cache[methodName];\n    }\n    const method = endpointMethodsMap.get(scope).get(methodName);\n    if (!method) {\n      return void 0;\n    }\n    const { endpointDefaults, decorations } = method;\n    if (decorations) {\n      cache[methodName] = decorate(\n        octokit,\n        scope,\n        methodName,\n        endpointDefaults,\n        decorations\n      );\n    } else {\n      cache[methodName] = octokit.request.defaults(endpointDefaults);\n    }\n    return cache[methodName];\n  }\n};\nfunction endpointsToMethods(octokit) {\n  const newMethods = {};\n  for (const scope of endpointMethodsMap.keys()) {\n    newMethods[scope] = new Proxy({ octokit, scope, cache: {} }, handler);\n  }\n  return newMethods;\n}\nfunction decorate(octokit, scope, methodName, defaults, decorations) {\n  const requestWithDefaults = octokit.request.defaults(defaults);\n  function withDecorations(...args) {\n    let options = requestWithDefaults.endpoint.merge(...args);\n    if (decorations.mapToData) {\n      options = Object.assign({}, options, {\n        data: options[decorations.mapToData],\n        [decorations.mapToData]: void 0\n      });\n      return requestWithDefaults(options);\n    }\n    if (decorations.renamed) {\n      const [newScope, newMethodName] = decorations.renamed;\n      octokit.log.warn(\n        `octokit.${scope}.${methodName}() has been renamed to octokit.${newScope}.${newMethodName}()`\n      );\n    }\n    if (decorations.deprecated) {\n      octokit.log.warn(decorations.deprecated);\n    }\n    if (decorations.renamedParameters) {\n      const options2 = requestWithDefaults.endpoint.merge(...args);\n      for (const [name, alias] of Object.entries(\n        decorations.renamedParameters\n      )) {\n        if (name in options2) {\n          octokit.log.warn(\n            `\"${name}\" parameter is deprecated for \"octokit.${scope}.${methodName}()\". Use \"${alias}\" instead`\n          );\n          if (!(alias in options2)) {\n            options2[alias] = options2[name];\n          }\n          delete options2[name];\n        }\n      }\n      return requestWithDefaults(options2);\n    }\n    return requestWithDefaults(...args);\n  }\n  return Object.assign(withDecorations, requestWithDefaults);\n}\n\n// pkg/dist-src/index.js\nfunction restEndpointMethods(octokit) {\n  const api = endpointsToMethods(octokit);\n  return {\n    rest: api\n  };\n}\nrestEndpointMethods.VERSION = VERSION;\nfunction legacyRestEndpointMethods(octokit) {\n  const api = endpointsToMethods(octokit);\n  return {\n    ...api,\n    rest: api\n  };\n}\nlegacyRestEndpointMethods.VERSION = VERSION;\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  legacyRestEndpointMethods,\n  restEndpointMethods\n});\n","\"use strict\";\nvar __create = Object.create;\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __getProtoOf = Object.getPrototypeOf;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(\n  // If the importer is in node compatibility mode or this is not an ESM\n  // file that has been converted to a CommonJS file using a Babel-\n  // compatible transform (i.e. \"__esModule\" has not been set), then set\n  // \"default\" to the CommonJS \"module.exports\" for node compatibility.\n  isNodeMode || !mod || !mod.__esModule ? __defProp(target, \"default\", { value: mod, enumerable: true }) : target,\n  mod\n));\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  RequestError: () => RequestError\n});\nmodule.exports = __toCommonJS(dist_src_exports);\nvar import_deprecation = require(\"deprecation\");\nvar import_once = __toESM(require(\"once\"));\nvar logOnceCode = (0, import_once.default)((deprecation) => console.warn(deprecation));\nvar logOnceHeaders = (0, import_once.default)((deprecation) => console.warn(deprecation));\nvar RequestError = class extends Error {\n  constructor(message, statusCode, options) {\n    super(message);\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n    this.name = \"HttpError\";\n    this.status = statusCode;\n    let headers;\n    if (\"headers\" in options && typeof options.headers !== \"undefined\") {\n      headers = options.headers;\n    }\n    if (\"response\" in options) {\n      this.response = options.response;\n      headers = options.response.headers;\n    }\n    const requestCopy = Object.assign({}, options.request);\n    if (options.request.headers.authorization) {\n      requestCopy.headers = Object.assign({}, options.request.headers, {\n        authorization: options.request.headers.authorization.replace(\n          /(?<! ) .*$/,\n          \" [REDACTED]\"\n        )\n      });\n    }\n    requestCopy.url = requestCopy.url.replace(/\\bclient_secret=\\w+/g, \"client_secret=[REDACTED]\").replace(/\\baccess_token=\\w+/g, \"access_token=[REDACTED]\");\n    this.request = requestCopy;\n    Object.defineProperty(this, \"code\", {\n      get() {\n        logOnceCode(\n          new import_deprecation.Deprecation(\n            \"[@octokit/request-error] `error.code` is deprecated, use `error.status`.\"\n          )\n        );\n        return statusCode;\n      }\n    });\n    Object.defineProperty(this, \"headers\", {\n      get() {\n        logOnceHeaders(\n          new import_deprecation.Deprecation(\n            \"[@octokit/request-error] `error.headers` is deprecated, use `error.response.headers`.\"\n          )\n        );\n        return headers || {};\n      }\n    });\n  }\n};\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  RequestError\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  request: () => request\n});\nmodule.exports = __toCommonJS(dist_src_exports);\nvar import_endpoint = require(\"@octokit/endpoint\");\nvar import_universal_user_agent = require(\"universal-user-agent\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"8.4.1\";\n\n// pkg/dist-src/is-plain-object.js\nfunction isPlainObject(value) {\n  if (typeof value !== \"object\" || value === null)\n    return false;\n  if (Object.prototype.toString.call(value) !== \"[object Object]\")\n    return false;\n  const proto = Object.getPrototypeOf(value);\n  if (proto === null)\n    return true;\n  const Ctor = Object.prototype.hasOwnProperty.call(proto, \"constructor\") && proto.constructor;\n  return typeof Ctor === \"function\" && Ctor instanceof Ctor && Function.prototype.call(Ctor) === Function.prototype.call(value);\n}\n\n// pkg/dist-src/fetch-wrapper.js\nvar import_request_error = require(\"@octokit/request-error\");\n\n// pkg/dist-src/get-buffer-response.js\nfunction getBufferResponse(response) {\n  return response.arrayBuffer();\n}\n\n// pkg/dist-src/fetch-wrapper.js\nfunction fetchWrapper(requestOptions) {\n  var _a, _b, _c, _d;\n  const log = requestOptions.request && requestOptions.request.log ? requestOptions.request.log : console;\n  const parseSuccessResponseBody = ((_a = requestOptions.request) == null ? void 0 : _a.parseSuccessResponseBody) !== false;\n  if (isPlainObject(requestOptions.body) || Array.isArray(requestOptions.body)) {\n    requestOptions.body = JSON.stringify(requestOptions.body);\n  }\n  let headers = {};\n  let status;\n  let url;\n  let { fetch } = globalThis;\n  if ((_b = requestOptions.request) == null ? void 0 : _b.fetch) {\n    fetch = requestOptions.request.fetch;\n  }\n  if (!fetch) {\n    throw new Error(\n      \"fetch is not set. Please pass a fetch implementation as new Octokit({ request: { fetch }}). Learn more at https://github.com/octokit/octokit.js/#fetch-missing\"\n    );\n  }\n  return fetch(requestOptions.url, {\n    method: requestOptions.method,\n    body: requestOptions.body,\n    redirect: (_c = requestOptions.request) == null ? void 0 : _c.redirect,\n    headers: requestOptions.headers,\n    signal: (_d = requestOptions.request) == null ? void 0 : _d.signal,\n    // duplex must be set if request.body is ReadableStream or Async Iterables.\n    // See https://fetch.spec.whatwg.org/#dom-requestinit-duplex.\n    ...requestOptions.body && { duplex: \"half\" }\n  }).then(async (response) => {\n    url = response.url;\n    status = response.status;\n    for (const keyAndValue of response.headers) {\n      headers[keyAndValue[0]] = keyAndValue[1];\n    }\n    if (\"deprecation\" in headers) {\n      const matches = headers.link && headers.link.match(/<([^<>]+)>; rel=\"deprecation\"/);\n      const deprecationLink = matches && matches.pop();\n      log.warn(\n        `[@octokit/request] \"${requestOptions.method} ${requestOptions.url}\" is deprecated. It is scheduled to be removed on ${headers.sunset}${deprecationLink ? `. See ${deprecationLink}` : \"\"}`\n      );\n    }\n    if (status === 204 || status === 205) {\n      return;\n    }\n    if (requestOptions.method === \"HEAD\") {\n      if (status < 400) {\n        return;\n      }\n      throw new import_request_error.RequestError(response.statusText, status, {\n        response: {\n          url,\n          status,\n          headers,\n          data: void 0\n        },\n        request: requestOptions\n      });\n    }\n    if (status === 304) {\n      throw new import_request_error.RequestError(\"Not modified\", status, {\n        response: {\n          url,\n          status,\n          headers,\n          data: await getResponseData(response)\n        },\n        request: requestOptions\n      });\n    }\n    if (status >= 400) {\n      const data = await getResponseData(response);\n      const error = new import_request_error.RequestError(toErrorMessage(data), status, {\n        response: {\n          url,\n          status,\n          headers,\n          data\n        },\n        request: requestOptions\n      });\n      throw error;\n    }\n    return parseSuccessResponseBody ? await getResponseData(response) : response.body;\n  }).then((data) => {\n    return {\n      status,\n      url,\n      headers,\n      data\n    };\n  }).catch((error) => {\n    if (error instanceof import_request_error.RequestError)\n      throw error;\n    else if (error.name === \"AbortError\")\n      throw error;\n    let message = error.message;\n    if (error.name === \"TypeError\" && \"cause\" in error) {\n      if (error.cause instanceof Error) {\n        message = error.cause.message;\n      } else if (typeof error.cause === \"string\") {\n        message = error.cause;\n      }\n    }\n    throw new import_request_error.RequestError(message, 500, {\n      request: requestOptions\n    });\n  });\n}\nasync function getResponseData(response) {\n  const contentType = response.headers.get(\"content-type\");\n  if (/application\\/json/.test(contentType)) {\n    return response.json().catch(() => response.text()).catch(() => \"\");\n  }\n  if (!contentType || /^text\\/|charset=utf-8$/.test(contentType)) {\n    return response.text();\n  }\n  return getBufferResponse(response);\n}\nfunction toErrorMessage(data) {\n  if (typeof data === \"string\")\n    return data;\n  let suffix;\n  if (\"documentation_url\" in data) {\n    suffix = ` - ${data.documentation_url}`;\n  } else {\n    suffix = \"\";\n  }\n  if (\"message\" in data) {\n    if (Array.isArray(data.errors)) {\n      return `${data.message}: ${data.errors.map(JSON.stringify).join(\", \")}${suffix}`;\n    }\n    return `${data.message}${suffix}`;\n  }\n  return `Unknown error: ${JSON.stringify(data)}`;\n}\n\n// pkg/dist-src/with-defaults.js\nfunction withDefaults(oldEndpoint, newDefaults) {\n  const endpoint2 = oldEndpoint.defaults(newDefaults);\n  const newApi = function(route, parameters) {\n    const endpointOptions = endpoint2.merge(route, parameters);\n    if (!endpointOptions.request || !endpointOptions.request.hook) {\n      return fetchWrapper(endpoint2.parse(endpointOptions));\n    }\n    const request2 = (route2, parameters2) => {\n      return fetchWrapper(\n        endpoint2.parse(endpoint2.merge(route2, parameters2))\n      );\n    };\n    Object.assign(request2, {\n      endpoint: endpoint2,\n      defaults: withDefaults.bind(null, endpoint2)\n    });\n    return endpointOptions.request.hook(request2, endpointOptions);\n  };\n  return Object.assign(newApi, {\n    endpoint: endpoint2,\n    defaults: withDefaults.bind(null, endpoint2)\n  });\n}\n\n// pkg/dist-src/index.js\nvar request = withDefaults(import_endpoint.endpoint, {\n  headers: {\n    \"user-agent\": `octokit-request.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`\n  }\n});\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  request\n});\n","'use strict'\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  var i\n  for (i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n","var register = require(\"./lib/register\");\nvar addHook = require(\"./lib/add\");\nvar removeHook = require(\"./lib/remove\");\n\n// bind with array of arguments: https://stackoverflow.com/a/21792913\nvar bind = Function.bind;\nvar bindable = bind.bind(bind);\n\nfunction bindApi(hook, state, name) {\n  var removeHookRef = bindable(removeHook, null).apply(\n    null,\n    name ? [state, name] : [state]\n  );\n  hook.api = { remove: removeHookRef };\n  hook.remove = removeHookRef;\n  [\"before\", \"error\", \"after\", \"wrap\"].forEach(function (kind) {\n    var args = name ? [state, kind, name] : [state, kind];\n    hook[kind] = hook.api[kind] = bindable(addHook, null).apply(null, args);\n  });\n}\n\nfunction HookSingular() {\n  var singularHookName = \"h\";\n  var singularHookState = {\n    registry: {},\n  };\n  var singularHook = register.bind(null, singularHookState, singularHookName);\n  bindApi(singularHook, singularHookState, singularHookName);\n  return singularHook;\n}\n\nfunction HookCollection() {\n  var state = {\n    registry: {},\n  };\n\n  var hook = register.bind(null, state);\n  bindApi(hook, state);\n\n  return hook;\n}\n\nvar collectionHookDeprecationMessageDisplayed = false;\nfunction Hook() {\n  if (!collectionHookDeprecationMessageDisplayed) {\n    console.warn(\n      '[before-after-hook]: \"Hook()\" repurposing warning, use \"Hook.Collection()\". Read more: https://git.io/upgrade-before-after-hook-to-1.4'\n    );\n    collectionHookDeprecationMessageDisplayed = true;\n  }\n  return HookCollection();\n}\n\nHook.Singular = HookSingular.bind();\nHook.Collection = HookCollection.bind();\n\nmodule.exports = Hook;\n// expose constructors as a named property for TypeScript\nmodule.exports.Hook = Hook;\nmodule.exports.Singular = Hook.Singular;\nmodule.exports.Collection = Hook.Collection;\n","module.exports = addHook;\n\nfunction addHook(state, kind, name, hook) {\n  var orig = hook;\n  if (!state.registry[name]) {\n    state.registry[name] = [];\n  }\n\n  if (kind === \"before\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(orig.bind(null, options))\n        .then(method.bind(null, options));\n    };\n  }\n\n  if (kind === \"after\") {\n    hook = function (method, options) {\n      var result;\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .then(function (result_) {\n          result = result_;\n          return orig(result, options);\n        })\n        .then(function () {\n          return result;\n        });\n    };\n  }\n\n  if (kind === \"error\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .catch(function (error) {\n          return orig(error, options);\n        });\n    };\n  }\n\n  state.registry[name].push({\n    hook: hook,\n    orig: orig,\n  });\n}\n","module.exports = register;\n\nfunction register(state, name, method, options) {\n  if (typeof method !== \"function\") {\n    throw new Error(\"method for before hook must be a function\");\n  }\n\n  if (!options) {\n    options = {};\n  }\n\n  if (Array.isArray(name)) {\n    return name.reverse().reduce(function (callback, name) {\n      return register.bind(null, state, name, callback, options);\n    }, method)();\n  }\n\n  return Promise.resolve().then(function () {\n    if (!state.registry[name]) {\n      return method(options);\n    }\n\n    return state.registry[name].reduce(function (method, registered) {\n      return registered.hook.bind(null, method, options);\n    }, method)();\n  });\n}\n","module.exports = removeHook;\n\nfunction removeHook(state, name, method) {\n  if (!state.registry[name]) {\n    return;\n  }\n\n  var index = state.registry[name]\n    .map(function (registered) {\n      return registered.orig;\n    })\n    .indexOf(method);\n\n  if (index === -1) {\n    return;\n  }\n\n  state.registry[name].splice(index, 1);\n}\n","'use strict';\nmodule.exports = function (str, sep) {\n\tif (typeof str !== 'string') {\n\t\tthrow new TypeError('Expected a string');\n\t}\n\n\tsep = typeof sep === 'undefined' ? '_' : sep;\n\n\treturn str\n\t\t.replace(/([a-z\\d])([A-Z])/g, '$1' + sep + '$2')\n\t\t.replace(/([A-Z]+)([A-Z][a-z\\d]+)/g, '$1' + sep + '$2')\n\t\t.toLowerCase();\n};\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nclass Deprecation extends Error {\n  constructor(message) {\n    super(message); // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n\n    this.name = 'Deprecation';\n  }\n\n}\n\nexports.Deprecation = Deprecation;\n","'use strict';\n\nvar has = Object.prototype.hasOwnProperty\n  , prefix = '~';\n\n/**\n * Constructor to create a storage for our `EE` objects.\n * An `Events` instance is a plain object whose properties are event names.\n *\n * @constructor\n * @private\n */\nfunction Events() {}\n\n//\n// We try to not inherit from `Object.prototype`. In some engines creating an\n// instance in this way is faster than calling `Object.create(null)` directly.\n// If `Object.create(null)` is not supported we prefix the event names with a\n// character to make sure that the built-in object properties are not\n// overridden or used as an attack vector.\n//\nif (Object.create) {\n  Events.prototype = Object.create(null);\n\n  //\n  // This hack is needed because the `__proto__` property is still inherited in\n  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.\n  //\n  if (!new Events().__proto__) prefix = false;\n}\n\n/**\n * Representation of a single event listener.\n *\n * @param {Function} fn The listener function.\n * @param {*} context The context to invoke the listener with.\n * @param {Boolean} [once=false] Specify if the listener is a one-time listener.\n * @constructor\n * @private\n */\nfunction EE(fn, context, once) {\n  this.fn = fn;\n  this.context = context;\n  this.once = once || false;\n}\n\n/**\n * Add a listener for a given event.\n *\n * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn The listener function.\n * @param {*} context The context to invoke the listener with.\n * @param {Boolean} once Specify if the listener is a one-time listener.\n * @returns {EventEmitter}\n * @private\n */\nfunction addListener(emitter, event, fn, context, once) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('The listener must be a function');\n  }\n\n  var listener = new EE(fn, context || emitter, once)\n    , evt = prefix ? prefix + event : event;\n\n  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;\n  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);\n  else emitter._events[evt] = [emitter._events[evt], listener];\n\n  return emitter;\n}\n\n/**\n * Clear event by name.\n *\n * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n * @param {(String|Symbol)} evt The Event name.\n * @private\n */\nfunction clearEvent(emitter, evt) {\n  if (--emitter._eventsCount === 0) emitter._events = new Events();\n  else delete emitter._events[evt];\n}\n\n/**\n * Minimal `EventEmitter` interface that is molded against the Node.js\n * `EventEmitter` interface.\n *\n * @constructor\n * @public\n */\nfunction EventEmitter() {\n  this._events = new Events();\n  this._eventsCount = 0;\n}\n\n/**\n * Return an array listing the events for which the emitter has registered\n * listeners.\n *\n * @returns {Array}\n * @public\n */\nEventEmitter.prototype.eventNames = function eventNames() {\n  var names = []\n    , events\n    , name;\n\n  if (this._eventsCount === 0) return names;\n\n  for (name in (events = this._events)) {\n    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);\n  }\n\n  if (Object.getOwnPropertySymbols) {\n    return names.concat(Object.getOwnPropertySymbols(events));\n  }\n\n  return names;\n};\n\n/**\n * Return the listeners registered for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @returns {Array} The registered listeners.\n * @public\n */\nEventEmitter.prototype.listeners = function listeners(event) {\n  var evt = prefix ? prefix + event : event\n    , handlers = this._events[evt];\n\n  if (!handlers) return [];\n  if (handlers.fn) return [handlers.fn];\n\n  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {\n    ee[i] = handlers[i].fn;\n  }\n\n  return ee;\n};\n\n/**\n * Return the number of listeners listening to a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @returns {Number} The number of listeners.\n * @public\n */\nEventEmitter.prototype.listenerCount = function listenerCount(event) {\n  var evt = prefix ? prefix + event : event\n    , listeners = this._events[evt];\n\n  if (!listeners) return 0;\n  if (listeners.fn) return 1;\n  return listeners.length;\n};\n\n/**\n * Calls each of the listeners registered for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @returns {Boolean} `true` if the event had listeners, else `false`.\n * @public\n */\nEventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {\n  var evt = prefix ? prefix + event : event;\n\n  if (!this._events[evt]) return false;\n\n  var listeners = this._events[evt]\n    , len = arguments.length\n    , args\n    , i;\n\n  if (listeners.fn) {\n    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);\n\n    switch (len) {\n      case 1: return listeners.fn.call(listeners.context), true;\n      case 2: return listeners.fn.call(listeners.context, a1), true;\n      case 3: return listeners.fn.call(listeners.context, a1, a2), true;\n      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;\n      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;\n      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;\n    }\n\n    for (i = 1, args = new Array(len -1); i < len; i++) {\n      args[i - 1] = arguments[i];\n    }\n\n    listeners.fn.apply(listeners.context, args);\n  } else {\n    var length = listeners.length\n      , j;\n\n    for (i = 0; i < length; i++) {\n      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);\n\n      switch (len) {\n        case 1: listeners[i].fn.call(listeners[i].context); break;\n        case 2: listeners[i].fn.call(listeners[i].context, a1); break;\n        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;\n        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;\n        default:\n          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {\n            args[j - 1] = arguments[j];\n          }\n\n          listeners[i].fn.apply(listeners[i].context, args);\n      }\n    }\n  }\n\n  return true;\n};\n\n/**\n * Add a listener for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn The listener function.\n * @param {*} [context=this] The context to invoke the listener with.\n * @returns {EventEmitter} `this`.\n * @public\n */\nEventEmitter.prototype.on = function on(event, fn, context) {\n  return addListener(this, event, fn, context, false);\n};\n\n/**\n * Add a one-time listener for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn The listener function.\n * @param {*} [context=this] The context to invoke the listener with.\n * @returns {EventEmitter} `this`.\n * @public\n */\nEventEmitter.prototype.once = function once(event, fn, context) {\n  return addListener(this, event, fn, context, true);\n};\n\n/**\n * Remove the listeners of a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn Only remove the listeners that match this function.\n * @param {*} context Only remove the listeners that have this context.\n * @param {Boolean} once Only remove one-time listeners.\n * @returns {EventEmitter} `this`.\n * @public\n */\nEventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {\n  var evt = prefix ? prefix + event : event;\n\n  if (!this._events[evt]) return this;\n  if (!fn) {\n    clearEvent(this, evt);\n    return this;\n  }\n\n  var listeners = this._events[evt];\n\n  if (listeners.fn) {\n    if (\n      listeners.fn === fn &&\n      (!once || listeners.once) &&\n      (!context || listeners.context === context)\n    ) {\n      clearEvent(this, evt);\n    }\n  } else {\n    for (var i = 0, events = [], length = listeners.length; i < length; i++) {\n      if (\n        listeners[i].fn !== fn ||\n        (once && !listeners[i].once) ||\n        (context && listeners[i].context !== context)\n      ) {\n        events.push(listeners[i]);\n      }\n    }\n\n    //\n    // Reset the array, or remove it completely if we have no more listeners.\n    //\n    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;\n    else clearEvent(this, evt);\n  }\n\n  return this;\n};\n\n/**\n * Remove all listeners, or those of the specified event.\n *\n * @param {(String|Symbol)} [event] The event name.\n * @returns {EventEmitter} `this`.\n * @public\n */\nEventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {\n  var evt;\n\n  if (event) {\n    evt = prefix ? prefix + event : event;\n    if (this._events[evt]) clearEvent(this, evt);\n  } else {\n    this._events = new Events();\n    this._eventsCount = 0;\n  }\n\n  return this;\n};\n\n//\n// Alias methods names because people roll like that.\n//\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\nEventEmitter.prototype.addListener = EventEmitter.prototype.on;\n\n//\n// Expose the prefix.\n//\nEventEmitter.prefixed = prefix;\n\n//\n// Allow `EventEmitter` to be imported as module namespace.\n//\nEventEmitter.EventEmitter = EventEmitter;\n\n//\n// Expose the module.\n//\nif ('undefined' !== typeof module) {\n  module.exports = EventEmitter;\n}\n","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nObject.defineProperty(exports, \"MAX\", {\n  enumerable: true,\n  get: function () {\n    return _max.default;\n  }\n});\nObject.defineProperty(exports, \"NIL\", {\n  enumerable: true,\n  get: function () {\n    return _nil.default;\n  }\n});\nObject.defineProperty(exports, \"parse\", {\n  enumerable: true,\n  get: function () {\n    return _parse.default;\n  }\n});\nObject.defineProperty(exports, \"stringify\", {\n  enumerable: true,\n  get: function () {\n    return _stringify.default;\n  }\n});\nObject.defineProperty(exports, \"v1\", {\n  enumerable: true,\n  get: function () {\n    return _v.default;\n  }\n});\nObject.defineProperty(exports, \"v1ToV6\", {\n  enumerable: true,\n  get: function () {\n    return _v1ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v3\", {\n  enumerable: true,\n  get: function () {\n    return _v2.default;\n  }\n});\nObject.defineProperty(exports, \"v4\", {\n  enumerable: true,\n  get: function () {\n    return _v3.default;\n  }\n});\nObject.defineProperty(exports, \"v5\", {\n  enumerable: true,\n  get: function () {\n    return _v4.default;\n  }\n});\nObject.defineProperty(exports, \"v6\", {\n  enumerable: true,\n  get: function () {\n    return _v5.default;\n  }\n});\nObject.defineProperty(exports, \"v6ToV1\", {\n  enumerable: true,\n  get: function () {\n    return _v6ToV.default;\n  }\n});\nObject.defineProperty(exports, \"v7\", {\n  enumerable: true,\n  get: function () {\n    return _v6.default;\n  }\n});\nObject.defineProperty(exports, \"validate\", {\n  enumerable: true,\n  get: function () {\n    return _validate.default;\n  }\n});\nObject.defineProperty(exports, \"version\", {\n  enumerable: true,\n  get: function () {\n    return _version.default;\n  }\n});\nvar _max = _interopRequireDefault(require(\"./max.js\"));\nvar _nil = _interopRequireDefault(require(\"./nil.js\"));\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nvar _v2 = _interopRequireDefault(require(\"./v3.js\"));\nvar _v3 = _interopRequireDefault(require(\"./v4.js\"));\nvar _v4 = _interopRequireDefault(require(\"./v5.js\"));\nvar _v5 = _interopRequireDefault(require(\"./v6.js\"));\nvar _v6ToV = _interopRequireDefault(require(\"./v6ToV1.js\"));\nvar _v6 = _interopRequireDefault(require(\"./v7.js\"));\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nvar _version = _interopRequireDefault(require(\"./version.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = 'ffffffff-ffff-ffff-ffff-ffffffffffff';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction md5(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('md5').update(bytes).digest();\n}\nvar _default = exports.default = md5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nvar _default = exports.default = {\n  randomUUID: _nodeCrypto.default.randomUUID\n};","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = '00000000-0000-0000-0000-000000000000';","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction parse(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  let v;\n  const arr = new Uint8Array(16);\n\n  // Parse ########-....-....-....-............\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff;\n\n  // Parse ........-####-....-....-............\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff;\n\n  // Parse ........-....-####-....-............\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff;\n\n  // Parse ........-....-....-####-............\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff;\n\n  // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\nvar _default = exports.default = parse;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = exports.default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = rng;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst rnds8Pool = new Uint8Array(256); // # of random values to pre-allocate\nlet poolPtr = rnds8Pool.length;\nfunction rng() {\n  if (poolPtr > rnds8Pool.length - 16) {\n    _nodeCrypto.default.randomFillSync(rnds8Pool);\n    poolPtr = 0;\n  }\n  return rnds8Pool.slice(poolPtr, poolPtr += 16);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _nodeCrypto = _interopRequireDefault(require(\"node:crypto\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction sha1(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n  return _nodeCrypto.default.createHash('sha1').update(bytes).digest();\n}\nvar _default = exports.default = sha1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nexports.unsafeStringify = unsafeStringify;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nconst byteToHex = [];\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  //\n  // Note to future-self: No, you can't remove the `toLowerCase()` call.\n  // REF: https://github.com/uuidjs/uuid/pull/677#issuecomment-1757351351\n  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();\n}\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset);\n  // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n  return uuid;\n}\nvar _default = exports.default = stringify;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nlet _nodeId;\nlet _clockseq;\n\n// Previous uuid creation time\nlet _lastMSecs = 0;\nlet _lastNSecs = 0;\n\n// See https://github.com/uuidjs/uuid for API details\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node;\n  let clockseq = options.clockseq;\n\n  // v1 only: Use cached `node` and `clockseq` values\n  if (!options._v6) {\n    if (!node) {\n      node = _nodeId;\n    }\n    if (clockseq == null) {\n      clockseq = _clockseq;\n    }\n  }\n\n  // Handle cases where we need entropy.  We do this lazily to minimize issues\n  // related to insufficient system entropy.  See #189\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng.default)();\n\n    // Randomize node\n    if (node == null) {\n      node = [seedBytes[0], seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n\n      // v1 only: cache node value for reuse\n      if (!_nodeId && !options._v6) {\n        // per RFC4122 4.5: Set MAC multicast bit (v1 only)\n        node[0] |= 0x01; // Set multicast bit\n\n        _nodeId = node;\n      }\n    }\n\n    // Randomize clockseq\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n      if (_clockseq === undefined && !options._v6) {\n        _clockseq = clockseq;\n      }\n    }\n  }\n\n  // v1 & v6 timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so time is\n  // handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v1;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v1ToV6;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v1 UUID to a v6 UUID\n *\n * @param {string|Uint8Array} uuid - The v1 UUID to convert to v6\n * @returns {string|Uint8Array} The v6 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v1ToV6(uuid) {\n  const v1Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v6Bytes = _v1ToV6(v1Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v6Bytes) : v6Bytes;\n}\n\n// Do the field transformation needed for v1 -> v6\nfunction _v1ToV6(v1Bytes, randomize = false) {\n  return Uint8Array.of((v1Bytes[6] & 0x0f) << 4 | v1Bytes[7] >> 4 & 0x0f, (v1Bytes[7] & 0x0f) << 4 | (v1Bytes[4] & 0xf0) >> 4, (v1Bytes[4] & 0x0f) << 4 | (v1Bytes[5] & 0xf0) >> 4, (v1Bytes[5] & 0x0f) << 4 | (v1Bytes[0] & 0xf0) >> 4, (v1Bytes[0] & 0x0f) << 4 | (v1Bytes[1] & 0xf0) >> 4, (v1Bytes[1] & 0x0f) << 4 | (v1Bytes[2] & 0xf0) >> 4, 0x60 | v1Bytes[2] & 0x0f, v1Bytes[3], v1Bytes[8], v1Bytes[9], v1Bytes[10], v1Bytes[11], v1Bytes[12], v1Bytes[13], v1Bytes[14], v1Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _md = _interopRequireDefault(require(\"./md5.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v3 = (0, _v.default)('v3', 0x30, _md.default);\nvar _default = exports.default = v3;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.URL = exports.DNS = void 0;\nexports.default = v35;\nvar _stringify = require(\"./stringify.js\");\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n  return bytes;\n}\nconst DNS = exports.DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nconst URL = exports.URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nfunction v35(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    var _namespace;\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n    if (typeof namespace === 'string') {\n      namespace = (0, _parse.default)(namespace);\n    }\n    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    }\n\n    // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n    if (buf) {\n      offset = offset || 0;\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n      return buf;\n    }\n    return (0, _stringify.unsafeStringify)(bytes);\n  }\n\n  // Function#name is not settable on some platforms (#270)\n  try {\n    generateUUID.name = name;\n  } catch (err) {}\n\n  // For CommonJS default export support\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _native = _interopRequireDefault(require(\"./native.js\"));\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction v4(options, buf, offset) {\n  if (_native.default.randomUUID && !buf && !options) {\n    return _native.default.randomUUID();\n  }\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    offset = offset || 0;\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(rnds);\n}\nvar _default = exports.default = v4;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\nvar _sha = _interopRequireDefault(require(\"./sha1.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nconst v5 = (0, _v.default)('v5', 0x50, _sha.default);\nvar _default = exports.default = v5;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6;\nvar _stringify = require(\"./stringify.js\");\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\nvar _v1ToV = _interopRequireDefault(require(\"./v1ToV6.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n *\n * @param {object} options\n * @param {Uint8Array=} buf\n * @param {number=} offset\n * @returns\n */\nfunction v6(options = {}, buf, offset = 0) {\n  // v6 is v1 with different field layout, so we start with a v1 UUID, albeit\n  // with slightly different behavior around how the clock_seq and node fields\n  // are randomized, which is why we call v1 with _v6: true.\n  let bytes = (0, _v.default)({\n    ...options,\n    _v6: true\n  }, new Uint8Array(16));\n\n  // Reorder the fields to v6 layout.\n  bytes = (0, _v1ToV.default)(bytes);\n\n  // Return as a byte array if requested\n  if (buf) {\n    for (let i = 0; i < 16; i++) {\n      buf[offset + i] = bytes[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(bytes);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = v6ToV1;\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * Convert a v6 UUID to a v1 UUID\n *\n * @param {string|Uint8Array} uuid - The v6 UUID to convert to v6\n * @returns {string|Uint8Array} The v1 UUID as the same type as the `uuid` arg\n * (string or Uint8Array)\n */\nfunction v6ToV1(uuid) {\n  const v6Bytes = typeof uuid === 'string' ? (0, _parse.default)(uuid) : uuid;\n  const v1Bytes = _v6ToV1(v6Bytes);\n  return typeof uuid === 'string' ? (0, _stringify.unsafeStringify)(v1Bytes) : v1Bytes;\n}\n\n// Do the field transformation needed for v6 -> v1\nfunction _v6ToV1(v6Bytes) {\n  return Uint8Array.of((v6Bytes[3] & 0x0f) << 4 | v6Bytes[4] >> 4 & 0x0f, (v6Bytes[4] & 0x0f) << 4 | (v6Bytes[5] & 0xf0) >> 4, (v6Bytes[5] & 0x0f) << 4 | v6Bytes[6] & 0x0f, v6Bytes[7], (v6Bytes[1] & 0x0f) << 4 | (v6Bytes[2] & 0xf0) >> 4, (v6Bytes[2] & 0x0f) << 4 | (v6Bytes[3] & 0xf0) >> 4, 0x10 | (v6Bytes[0] & 0xf0) >> 4, (v6Bytes[0] & 0x0f) << 4 | (v6Bytes[1] & 0xf0) >> 4, v6Bytes[8], v6Bytes[9], v6Bytes[10], v6Bytes[11], v6Bytes[12], v6Bytes[13], v6Bytes[14], v6Bytes[15]);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\nvar _stringify = require(\"./stringify.js\");\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\n/**\n * UUID V7 - Unix Epoch time-based UUID\n *\n * The IETF has published RFC9562, introducing 3 new UUID versions (6,7,8). This\n * implementation of V7 is based on the accepted, though not yet approved,\n * revisions.\n *\n * RFC 9562:https://www.rfc-editor.org/rfc/rfc9562.html Universally Unique\n * IDentifiers (UUIDs)\n\n *\n * Sample V7 value:\n * https://www.rfc-editor.org/rfc/rfc9562.html#name-example-of-a-uuidv7-value\n *\n * Monotonic Bit Layout: RFC rfc9562.6.2 Method 1, Dedicated Counter Bits ref:\n *     https://www.rfc-editor.org/rfc/rfc9562.html#section-6.2-5.1\n *\n *   0                   1                   2                   3 0 1 2 3 4 5 6\n *   7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                          unix_ts_ms                           |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |          unix_ts_ms           |  ver  |        seq_hi         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |var|               seq_low               |        rand         |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *  |                             rand                              |\n *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n *\n * seq is a 31 bit serialized counter; comprised of 12 bit seq_hi and 19 bit\n * seq_low, and randomly initialized upon timestamp change. 31 bit counter size\n * was selected as any bitwise operations in node are done as _signed_ 32 bit\n * ints. we exclude the sign bit.\n */\n\nlet _seqLow = null;\nlet _seqHigh = null;\nlet _msecs = 0;\nfunction v7(options, buf, offset) {\n  options = options || {};\n\n  // initialize buffer and pointer\n  let i = buf && offset || 0;\n  const b = buf || new Uint8Array(16);\n\n  // rnds is Uint8Array(16) filled with random bytes\n  const rnds = options.random || (options.rng || _rng.default)();\n\n  // milliseconds since unix epoch, 1970-01-01 00:00\n  const msecs = options.msecs !== undefined ? options.msecs : Date.now();\n\n  // seq is user provided 31 bit counter\n  let seq = options.seq !== undefined ? options.seq : null;\n\n  // initialize local seq high/low parts\n  let seqHigh = _seqHigh;\n  let seqLow = _seqLow;\n\n  // check if clock has advanced and user has not provided msecs\n  if (msecs > _msecs && options.msecs === undefined) {\n    _msecs = msecs;\n\n    // unless user provided seq, reset seq parts\n    if (seq !== null) {\n      seqHigh = null;\n      seqLow = null;\n    }\n  }\n\n  // if we have a user provided seq\n  if (seq !== null) {\n    // trim provided seq to 31 bits of value, avoiding overflow\n    if (seq > 0x7fffffff) {\n      seq = 0x7fffffff;\n    }\n\n    // split provided seq into high/low parts\n    seqHigh = seq >>> 19 & 0xfff;\n    seqLow = seq & 0x7ffff;\n  }\n\n  // randomly initialize seq\n  if (seqHigh === null || seqLow === null) {\n    seqHigh = rnds[6] & 0x7f;\n    seqHigh = seqHigh << 8 | rnds[7];\n    seqLow = rnds[8] & 0x3f; // pad for var\n    seqLow = seqLow << 8 | rnds[9];\n    seqLow = seqLow << 5 | rnds[10] >>> 3;\n  }\n\n  // increment seq if within msecs window\n  if (msecs + 10000 > _msecs && seq === null) {\n    if (++seqLow > 0x7ffff) {\n      seqLow = 0;\n      if (++seqHigh > 0xfff) {\n        seqHigh = 0;\n\n        // increment internal _msecs. this allows us to continue incrementing\n        // while staying monotonic. Note, once we hit 10k milliseconds beyond system\n        // clock, we will reset breaking monotonicity (after (2^31)*10000 generations)\n        _msecs++;\n      }\n    }\n  } else {\n    // resetting; we have advanced more than\n    // 10k milliseconds beyond system clock\n    _msecs = msecs;\n  }\n  _seqHigh = seqHigh;\n  _seqLow = seqLow;\n\n  // [bytes 0-5] 48 bits of local timestamp\n  b[i++] = _msecs / 0x10000000000 & 0xff;\n  b[i++] = _msecs / 0x100000000 & 0xff;\n  b[i++] = _msecs / 0x1000000 & 0xff;\n  b[i++] = _msecs / 0x10000 & 0xff;\n  b[i++] = _msecs / 0x100 & 0xff;\n  b[i++] = _msecs & 0xff;\n\n  // [byte 6] - set 4 bits of version (7) with first 4 bits seq_hi\n  b[i++] = seqHigh >>> 4 & 0x0f | 0x70;\n\n  // [byte 7] remaining 8 bits of seq_hi\n  b[i++] = seqHigh & 0xff;\n\n  // [byte 8] - variant (2 bits), first 6 bits seq_low\n  b[i++] = seqLow >>> 13 & 0x3f | 0x80;\n\n  // [byte 9] 8 bits seq_low\n  b[i++] = seqLow >>> 5 & 0xff;\n\n  // [byte 10] remaining 5 bits seq_low, 3 bits random\n  b[i++] = seqLow << 3 & 0xff | rnds[10] & 0x07;\n\n  // [bytes 11-15] always random\n  b[i++] = rnds[11];\n  b[i++] = rnds[12];\n  b[i++] = rnds[13];\n  b[i++] = rnds[14];\n  b[i++] = rnds[15];\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = exports.default = v7;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _regex = _interopRequireDefault(require(\"./regex.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex.default.test(uuid);\n}\nvar _default = exports.default = validate;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\nfunction _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }\nfunction version(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  return parseInt(uuid.slice(14, 15), 16);\n}\nvar _default = exports.default = version;","var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n","'use strict';\nmodule.exports = (promise, onFinally) => {\n\tonFinally = onFinally || (() => {});\n\n\treturn promise.then(\n\t\tval => new Promise(resolve => {\n\t\t\tresolve(onFinally());\n\t\t}).then(() => val),\n\t\terr => new Promise(resolve => {\n\t\t\tresolve(onFinally());\n\t\t}).then(() => {\n\t\t\tthrow err;\n\t\t})\n\t);\n};\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst EventEmitter = require(\"eventemitter3\");\nconst p_timeout_1 = require(\"p-timeout\");\nconst priority_queue_1 = require(\"./priority-queue\");\n// eslint-disable-next-line @typescript-eslint/no-empty-function\nconst empty = () => { };\nconst timeoutError = new p_timeout_1.TimeoutError();\n/**\nPromise queue with concurrency control.\n*/\nclass PQueue extends EventEmitter {\n    constructor(options) {\n        var _a, _b, _c, _d;\n        super();\n        this._intervalCount = 0;\n        this._intervalEnd = 0;\n        this._pendingCount = 0;\n        this._resolveEmpty = empty;\n        this._resolveIdle = empty;\n        // eslint-disable-next-line @typescript-eslint/consistent-type-assertions\n        options = Object.assign({ carryoverConcurrencyCount: false, intervalCap: Infinity, interval: 0, concurrency: Infinity, autoStart: true, queueClass: priority_queue_1.default }, options);\n        if (!(typeof options.intervalCap === 'number' && options.intervalCap >= 1)) {\n            throw new TypeError(`Expected \\`intervalCap\\` to be a number from 1 and up, got \\`${(_b = (_a = options.intervalCap) === null || _a === void 0 ? void 0 : _a.toString()) !== null && _b !== void 0 ? _b : ''}\\` (${typeof options.intervalCap})`);\n        }\n        if (options.interval === undefined || !(Number.isFinite(options.interval) && options.interval >= 0)) {\n            throw new TypeError(`Expected \\`interval\\` to be a finite number >= 0, got \\`${(_d = (_c = options.interval) === null || _c === void 0 ? void 0 : _c.toString()) !== null && _d !== void 0 ? _d : ''}\\` (${typeof options.interval})`);\n        }\n        this._carryoverConcurrencyCount = options.carryoverConcurrencyCount;\n        this._isIntervalIgnored = options.intervalCap === Infinity || options.interval === 0;\n        this._intervalCap = options.intervalCap;\n        this._interval = options.interval;\n        this._queue = new options.queueClass();\n        this._queueClass = options.queueClass;\n        this.concurrency = options.concurrency;\n        this._timeout = options.timeout;\n        this._throwOnTimeout = options.throwOnTimeout === true;\n        this._isPaused = options.autoStart === false;\n    }\n    get _doesIntervalAllowAnother() {\n        return this._isIntervalIgnored || this._intervalCount < this._intervalCap;\n    }\n    get _doesConcurrentAllowAnother() {\n        return this._pendingCount < this._concurrency;\n    }\n    _next() {\n        this._pendingCount--;\n        this._tryToStartAnother();\n        this.emit('next');\n    }\n    _resolvePromises() {\n        this._resolveEmpty();\n        this._resolveEmpty = empty;\n        if (this._pendingCount === 0) {\n            this._resolveIdle();\n            this._resolveIdle = empty;\n            this.emit('idle');\n        }\n    }\n    _onResumeInterval() {\n        this._onInterval();\n        this._initializeIntervalIfNeeded();\n        this._timeoutId = undefined;\n    }\n    _isIntervalPaused() {\n        const now = Date.now();\n        if (this._intervalId === undefined) {\n            const delay = this._intervalEnd - now;\n            if (delay < 0) {\n                // Act as the interval was done\n                // We don't need to resume it here because it will be resumed on line 160\n                this._intervalCount = (this._carryoverConcurrencyCount) ? this._pendingCount : 0;\n            }\n            else {\n                // Act as the interval is pending\n                if (this._timeoutId === undefined) {\n                    this._timeoutId = setTimeout(() => {\n                        this._onResumeInterval();\n                    }, delay);\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    _tryToStartAnother() {\n        if (this._queue.size === 0) {\n            // We can clear the interval (\"pause\")\n            // Because we can redo it later (\"resume\")\n            if (this._intervalId) {\n                clearInterval(this._intervalId);\n            }\n            this._intervalId = undefined;\n            this._resolvePromises();\n            return false;\n        }\n        if (!this._isPaused) {\n            const canInitializeInterval = !this._isIntervalPaused();\n            if (this._doesIntervalAllowAnother && this._doesConcurrentAllowAnother) {\n                const job = this._queue.dequeue();\n                if (!job) {\n                    return false;\n                }\n                this.emit('active');\n                job();\n                if (canInitializeInterval) {\n                    this._initializeIntervalIfNeeded();\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    _initializeIntervalIfNeeded() {\n        if (this._isIntervalIgnored || this._intervalId !== undefined) {\n            return;\n        }\n        this._intervalId = setInterval(() => {\n            this._onInterval();\n        }, this._interval);\n        this._intervalEnd = Date.now() + this._interval;\n    }\n    _onInterval() {\n        if (this._intervalCount === 0 && this._pendingCount === 0 && this._intervalId) {\n            clearInterval(this._intervalId);\n            this._intervalId = undefined;\n        }\n        this._intervalCount = this._carryoverConcurrencyCount ? this._pendingCount : 0;\n        this._processQueue();\n    }\n    /**\n    Executes all queued functions until it reaches the limit.\n    */\n    _processQueue() {\n        // eslint-disable-next-line no-empty\n        while (this._tryToStartAnother()) { }\n    }\n    get concurrency() {\n        return this._concurrency;\n    }\n    set concurrency(newConcurrency) {\n        if (!(typeof newConcurrency === 'number' && newConcurrency >= 1)) {\n            throw new TypeError(`Expected \\`concurrency\\` to be a number from 1 and up, got \\`${newConcurrency}\\` (${typeof newConcurrency})`);\n        }\n        this._concurrency = newConcurrency;\n        this._processQueue();\n    }\n    /**\n    Adds a sync or async task to the queue. Always returns a promise.\n    */\n    async add(fn, options = {}) {\n        return new Promise((resolve, reject) => {\n            const run = async () => {\n                this._pendingCount++;\n                this._intervalCount++;\n                try {\n                    const operation = (this._timeout === undefined && options.timeout === undefined) ? fn() : p_timeout_1.default(Promise.resolve(fn()), (options.timeout === undefined ? this._timeout : options.timeout), () => {\n                        if (options.throwOnTimeout === undefined ? this._throwOnTimeout : options.throwOnTimeout) {\n                            reject(timeoutError);\n                        }\n                        return undefined;\n                    });\n                    resolve(await operation);\n                }\n                catch (error) {\n                    reject(error);\n                }\n                this._next();\n            };\n            this._queue.enqueue(run, options);\n            this._tryToStartAnother();\n            this.emit('add');\n        });\n    }\n    /**\n    Same as `.add()`, but accepts an array of sync or async functions.\n\n    @returns A promise that resolves when all functions are resolved.\n    */\n    async addAll(functions, options) {\n        return Promise.all(functions.map(async (function_) => this.add(function_, options)));\n    }\n    /**\n    Start (or resume) executing enqueued tasks within concurrency limit. No need to call this if queue is not paused (via `options.autoStart = false` or by `.pause()` method.)\n    */\n    start() {\n        if (!this._isPaused) {\n            return this;\n        }\n        this._isPaused = false;\n        this._processQueue();\n        return this;\n    }\n    /**\n    Put queue execution on hold.\n    */\n    pause() {\n        this._isPaused = true;\n    }\n    /**\n    Clear the queue.\n    */\n    clear() {\n        this._queue = new this._queueClass();\n    }\n    /**\n    Can be called multiple times. Useful if you for example add additional items at a later time.\n\n    @returns A promise that settles when the queue becomes empty.\n    */\n    async onEmpty() {\n        // Instantly resolve if the queue is empty\n        if (this._queue.size === 0) {\n            return;\n        }\n        return new Promise(resolve => {\n            const existingResolve = this._resolveEmpty;\n            this._resolveEmpty = () => {\n                existingResolve();\n                resolve();\n            };\n        });\n    }\n    /**\n    The difference with `.onEmpty` is that `.onIdle` guarantees that all work from the queue has finished. `.onEmpty` merely signals that the queue is empty, but it could mean that some promises haven't completed yet.\n\n    @returns A promise that settles when the queue becomes empty, and all promises have completed; `queue.size === 0 && queue.pending === 0`.\n    */\n    async onIdle() {\n        // Instantly resolve if none pending and if nothing else is queued\n        if (this._pendingCount === 0 && this._queue.size === 0) {\n            return;\n        }\n        return new Promise(resolve => {\n            const existingResolve = this._resolveIdle;\n            this._resolveIdle = () => {\n                existingResolve();\n                resolve();\n            };\n        });\n    }\n    /**\n    Size of the queue.\n    */\n    get size() {\n        return this._queue.size;\n    }\n    /**\n    Size of the queue, filtered by the given options.\n\n    For example, this can be used to find the number of items remaining in the queue with a specific priority level.\n    */\n    sizeBy(options) {\n        // eslint-disable-next-line unicorn/no-fn-reference-in-iterator\n        return this._queue.filter(options).length;\n    }\n    /**\n    Number of pending promises.\n    */\n    get pending() {\n        return this._pendingCount;\n    }\n    /**\n    Whether the queue is currently paused.\n    */\n    get isPaused() {\n        return this._isPaused;\n    }\n    get timeout() {\n        return this._timeout;\n    }\n    /**\n    Set the timeout for future operations.\n    */\n    set timeout(milliseconds) {\n        this._timeout = milliseconds;\n    }\n}\nexports.default = PQueue;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Port of lower_bound from https://en.cppreference.com/w/cpp/algorithm/lower_bound\n// Used to compute insertion index to keep queue sorted after insertion\nfunction lowerBound(array, value, comparator) {\n    let first = 0;\n    let count = array.length;\n    while (count > 0) {\n        const step = (count / 2) | 0;\n        let it = first + step;\n        if (comparator(array[it], value) <= 0) {\n            first = ++it;\n            count -= step + 1;\n        }\n        else {\n            count = step;\n        }\n    }\n    return first;\n}\nexports.default = lowerBound;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst lower_bound_1 = require(\"./lower-bound\");\nclass PriorityQueue {\n    constructor() {\n        this._queue = [];\n    }\n    enqueue(run, options) {\n        options = Object.assign({ priority: 0 }, options);\n        const element = {\n            priority: options.priority,\n            run\n        };\n        if (this.size && this._queue[this.size - 1].priority >= options.priority) {\n            this._queue.push(element);\n            return;\n        }\n        const index = lower_bound_1.default(this._queue, element, (a, b) => b.priority - a.priority);\n        this._queue.splice(index, 0, element);\n    }\n    dequeue() {\n        const item = this._queue.shift();\n        return item === null || item === void 0 ? void 0 : item.run;\n    }\n    filter(options) {\n        return this._queue.filter((element) => element.priority === options.priority).map((element) => element.run);\n    }\n    get size() {\n        return this._queue.length;\n    }\n}\nexports.default = PriorityQueue;\n","'use strict';\nconst retry = require('retry');\n\nconst networkErrorMsgs = [\n\t'Failed to fetch', // Chrome\n\t'NetworkError when attempting to fetch resource.', // Firefox\n\t'The Internet connection appears to be offline.', // Safari\n\t'Network request failed' // `cross-fetch`\n];\n\nclass AbortError extends Error {\n\tconstructor(message) {\n\t\tsuper();\n\n\t\tif (message instanceof Error) {\n\t\t\tthis.originalError = message;\n\t\t\t({message} = message);\n\t\t} else {\n\t\t\tthis.originalError = new Error(message);\n\t\t\tthis.originalError.stack = this.stack;\n\t\t}\n\n\t\tthis.name = 'AbortError';\n\t\tthis.message = message;\n\t}\n}\n\nconst decorateErrorWithCounts = (error, attemptNumber, options) => {\n\t// Minus 1 from attemptNumber because the first attempt does not count as a retry\n\tconst retriesLeft = options.retries - (attemptNumber - 1);\n\n\terror.attemptNumber = attemptNumber;\n\terror.retriesLeft = retriesLeft;\n\treturn error;\n};\n\nconst isNetworkError = errorMessage => networkErrorMsgs.includes(errorMessage);\n\nconst pRetry = (input, options) => new Promise((resolve, reject) => {\n\toptions = {\n\t\tonFailedAttempt: () => {},\n\t\tretries: 10,\n\t\t...options\n\t};\n\n\tconst operation = retry.operation(options);\n\n\toperation.attempt(async attemptNumber => {\n\t\ttry {\n\t\t\tresolve(await input(attemptNumber));\n\t\t} catch (error) {\n\t\t\tif (!(error instanceof Error)) {\n\t\t\t\treject(new TypeError(`Non-error was thrown: \"${error}\". You should only throw errors.`));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (error instanceof AbortError) {\n\t\t\t\toperation.stop();\n\t\t\t\treject(error.originalError);\n\t\t\t} else if (error instanceof TypeError && !isNetworkError(error.message)) {\n\t\t\t\toperation.stop();\n\t\t\t\treject(error);\n\t\t\t} else {\n\t\t\t\tdecorateErrorWithCounts(error, attemptNumber, options);\n\n\t\t\t\ttry {\n\t\t\t\t\tawait options.onFailedAttempt(error);\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (!operation.retry(error)) {\n\t\t\t\t\treject(operation.mainError());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n});\n\nmodule.exports = pRetry;\n// TODO: remove this in the next major version\nmodule.exports.default = pRetry;\n\nmodule.exports.AbortError = AbortError;\n","'use strict';\n\nconst pFinally = require('p-finally');\n\nclass TimeoutError extends Error {\n\tconstructor(message) {\n\t\tsuper(message);\n\t\tthis.name = 'TimeoutError';\n\t}\n}\n\nconst pTimeout = (promise, milliseconds, fallback) => new Promise((resolve, reject) => {\n\tif (typeof milliseconds !== 'number' || milliseconds < 0) {\n\t\tthrow new TypeError('Expected `milliseconds` to be a positive number');\n\t}\n\n\tif (milliseconds === Infinity) {\n\t\tresolve(promise);\n\t\treturn;\n\t}\n\n\tconst timer = setTimeout(() => {\n\t\tif (typeof fallback === 'function') {\n\t\t\ttry {\n\t\t\t\tresolve(fallback());\n\t\t\t} catch (error) {\n\t\t\t\treject(error);\n\t\t\t}\n\n\t\t\treturn;\n\t\t}\n\n\t\tconst message = typeof fallback === 'string' ? fallback : `Promise timed out after ${milliseconds} milliseconds`;\n\t\tconst timeoutError = fallback instanceof Error ? fallback : new TimeoutError(message);\n\n\t\tif (typeof promise.cancel === 'function') {\n\t\t\tpromise.cancel();\n\t\t}\n\n\t\treject(timeoutError);\n\t}, milliseconds);\n\n\t// TODO: Use native `finally` keyword when targeting Node.js 10\n\tpFinally(\n\t\t// eslint-disable-next-line promise/prefer-await-to-then\n\t\tpromise.then(resolve, reject),\n\t\t() => {\n\t\t\tclearTimeout(timer);\n\t\t}\n\t);\n});\n\nmodule.exports = pTimeout;\n// TODO: Remove this for the next major release\nmodule.exports.default = pTimeout;\n\nmodule.exports.TimeoutError = TimeoutError;\n","module.exports = require('./lib/retry');","var RetryOperation = require('./retry_operation');\n\nexports.operation = function(options) {\n  var timeouts = exports.timeouts(options);\n  return new RetryOperation(timeouts, {\n      forever: options && (options.forever || options.retries === Infinity),\n      unref: options && options.unref,\n      maxRetryTime: options && options.maxRetryTime\n  });\n};\n\nexports.timeouts = function(options) {\n  if (options instanceof Array) {\n    return [].concat(options);\n  }\n\n  var opts = {\n    retries: 10,\n    factor: 2,\n    minTimeout: 1 * 1000,\n    maxTimeout: Infinity,\n    randomize: false\n  };\n  for (var key in options) {\n    opts[key] = options[key];\n  }\n\n  if (opts.minTimeout > opts.maxTimeout) {\n    throw new Error('minTimeout is greater than maxTimeout');\n  }\n\n  var timeouts = [];\n  for (var i = 0; i < opts.retries; i++) {\n    timeouts.push(this.createTimeout(i, opts));\n  }\n\n  if (options && options.forever && !timeouts.length) {\n    timeouts.push(this.createTimeout(i, opts));\n  }\n\n  // sort the array numerically ascending\n  timeouts.sort(function(a,b) {\n    return a - b;\n  });\n\n  return timeouts;\n};\n\nexports.createTimeout = function(attempt, opts) {\n  var random = (opts.randomize)\n    ? (Math.random() + 1)\n    : 1;\n\n  var timeout = Math.round(random * Math.max(opts.minTimeout, 1) * Math.pow(opts.factor, attempt));\n  timeout = Math.min(timeout, opts.maxTimeout);\n\n  return timeout;\n};\n\nexports.wrap = function(obj, options, methods) {\n  if (options instanceof Array) {\n    methods = options;\n    options = null;\n  }\n\n  if (!methods) {\n    methods = [];\n    for (var key in obj) {\n      if (typeof obj[key] === 'function') {\n        methods.push(key);\n      }\n    }\n  }\n\n  for (var i = 0; i < methods.length; i++) {\n    var method   = methods[i];\n    var original = obj[method];\n\n    obj[method] = function retryWrapper(original) {\n      var op       = exports.operation(options);\n      var args     = Array.prototype.slice.call(arguments, 1);\n      var callback = args.pop();\n\n      args.push(function(err) {\n        if (op.retry(err)) {\n          return;\n        }\n        if (err) {\n          arguments[0] = op.mainError();\n        }\n        callback.apply(this, arguments);\n      });\n\n      op.attempt(function() {\n        original.apply(obj, args);\n      });\n    }.bind(obj, original);\n    obj[method].options = options;\n  }\n};\n","function RetryOperation(timeouts, options) {\n  // Compatibility for the old (timeouts, retryForever) signature\n  if (typeof options === 'boolean') {\n    options = { forever: options };\n  }\n\n  this._originalTimeouts = JSON.parse(JSON.stringify(timeouts));\n  this._timeouts = timeouts;\n  this._options = options || {};\n  this._maxRetryTime = options && options.maxRetryTime || Infinity;\n  this._fn = null;\n  this._errors = [];\n  this._attempts = 1;\n  this._operationTimeout = null;\n  this._operationTimeoutCb = null;\n  this._timeout = null;\n  this._operationStart = null;\n  this._timer = null;\n\n  if (this._options.forever) {\n    this._cachedTimeouts = this._timeouts.slice(0);\n  }\n}\nmodule.exports = RetryOperation;\n\nRetryOperation.prototype.reset = function() {\n  this._attempts = 1;\n  this._timeouts = this._originalTimeouts.slice(0);\n}\n\nRetryOperation.prototype.stop = function() {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n  if (this._timer) {\n    clearTimeout(this._timer);\n  }\n\n  this._timeouts       = [];\n  this._cachedTimeouts = null;\n};\n\nRetryOperation.prototype.retry = function(err) {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n\n  if (!err) {\n    return false;\n  }\n  var currentTime = new Date().getTime();\n  if (err && currentTime - this._operationStart >= this._maxRetryTime) {\n    this._errors.push(err);\n    this._errors.unshift(new Error('RetryOperation timeout occurred'));\n    return false;\n  }\n\n  this._errors.push(err);\n\n  var timeout = this._timeouts.shift();\n  if (timeout === undefined) {\n    if (this._cachedTimeouts) {\n      // retry forever, only keep last error\n      this._errors.splice(0, this._errors.length - 1);\n      timeout = this._cachedTimeouts.slice(-1);\n    } else {\n      return false;\n    }\n  }\n\n  var self = this;\n  this._timer = setTimeout(function() {\n    self._attempts++;\n\n    if (self._operationTimeoutCb) {\n      self._timeout = setTimeout(function() {\n        self._operationTimeoutCb(self._attempts);\n      }, self._operationTimeout);\n\n      if (self._options.unref) {\n          self._timeout.unref();\n      }\n    }\n\n    self._fn(self._attempts);\n  }, timeout);\n\n  if (this._options.unref) {\n      this._timer.unref();\n  }\n\n  return true;\n};\n\nRetryOperation.prototype.attempt = function(fn, timeoutOps) {\n  this._fn = fn;\n\n  if (timeoutOps) {\n    if (timeoutOps.timeout) {\n      this._operationTimeout = timeoutOps.timeout;\n    }\n    if (timeoutOps.cb) {\n      this._operationTimeoutCb = timeoutOps.cb;\n    }\n  }\n\n  var self = this;\n  if (this._operationTimeoutCb) {\n    this._timeout = setTimeout(function() {\n      self._operationTimeoutCb();\n    }, self._operationTimeout);\n  }\n\n  this._operationStart = new Date().getTime();\n\n  this._fn(this._attempts);\n};\n\nRetryOperation.prototype.try = function(fn) {\n  console.log('Using RetryOperation.try() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = function(fn) {\n  console.log('Using RetryOperation.start() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = RetryOperation.prototype.try;\n\nRetryOperation.prototype.errors = function() {\n  return this._errors;\n};\n\nRetryOperation.prototype.attempts = function() {\n  return this._attempts;\n};\n\nRetryOperation.prototype.mainError = function() {\n  if (this._errors.length === 0) {\n    return null;\n  }\n\n  var counts = {};\n  var mainError = null;\n  var mainErrorCount = 0;\n\n  for (var i = 0; i < this._errors.length; i++) {\n    var error = this._errors[i];\n    var message = error.message;\n    var count = (counts[message] || 0) + 1;\n\n    counts[message] = count;\n\n    if (count >= mainErrorCount) {\n      mainError = error;\n      mainErrorCount = count;\n    }\n  }\n\n  return mainError;\n};\n","'use strict'\n\nconst ANY = Symbol('SemVer ANY')\n// hoisted class for cyclic dependency\nclass Comparator {\n  static get ANY () {\n    return ANY\n  }\n\n  constructor (comp, options) {\n    options = parseOptions(options)\n\n    if (comp instanceof Comparator) {\n      if (comp.loose === !!options.loose) {\n        return comp\n      } else {\n        comp = comp.value\n      }\n    }\n\n    comp = comp.trim().split(/\\s+/).join(' ')\n    debug('comparator', comp, options)\n    this.options = options\n    this.loose = !!options.loose\n    this.parse(comp)\n\n    if (this.semver === ANY) {\n      this.value = ''\n    } else {\n      this.value = this.operator + this.semver.version\n    }\n\n    debug('comp', this)\n  }\n\n  parse (comp) {\n    const r = this.options.loose ? re[t.COMPARATORLOOSE] : re[t.COMPARATOR]\n    const m = comp.match(r)\n\n    if (!m) {\n      throw new TypeError(`Invalid comparator: ${comp}`)\n    }\n\n    this.operator = m[1] !== undefined ? m[1] : ''\n    if (this.operator === '=') {\n      this.operator = ''\n    }\n\n    // if it literally is just '>' or '' then allow anything.\n    if (!m[2]) {\n      this.semver = ANY\n    } else {\n      this.semver = new SemVer(m[2], this.options.loose)\n    }\n  }\n\n  toString () {\n    return this.value\n  }\n\n  test (version) {\n    debug('Comparator.test', version, this.options.loose)\n\n    if (this.semver === ANY || version === ANY) {\n      return true\n    }\n\n    if (typeof version === 'string') {\n      try {\n        version = new SemVer(version, this.options)\n      } catch (er) {\n        return false\n      }\n    }\n\n    return cmp(version, this.operator, this.semver, this.options)\n  }\n\n  intersects (comp, options) {\n    if (!(comp instanceof Comparator)) {\n      throw new TypeError('a Comparator is required')\n    }\n\n    if (this.operator === '') {\n      if (this.value === '') {\n        return true\n      }\n      return new Range(comp.value, options).test(this.value)\n    } else if (comp.operator === '') {\n      if (comp.value === '') {\n        return true\n      }\n      return new Range(this.value, options).test(comp.semver)\n    }\n\n    options = parseOptions(options)\n\n    // Special cases where nothing can possibly be lower\n    if (options.includePrerelease &&\n      (this.value === '<0.0.0-0' || comp.value === '<0.0.0-0')) {\n      return false\n    }\n    if (!options.includePrerelease &&\n      (this.value.startsWith('<0.0.0') || comp.value.startsWith('<0.0.0'))) {\n      return false\n    }\n\n    // Same direction increasing (> or >=)\n    if (this.operator.startsWith('>') && comp.operator.startsWith('>')) {\n      return true\n    }\n    // Same direction decreasing (< or <=)\n    if (this.operator.startsWith('<') && comp.operator.startsWith('<')) {\n      return true\n    }\n    // same SemVer and both sides are inclusive (<= or >=)\n    if (\n      (this.semver.version === comp.semver.version) &&\n      this.operator.includes('=') && comp.operator.includes('=')) {\n      return true\n    }\n    // opposite directions less than\n    if (cmp(this.semver, '<', comp.semver, options) &&\n      this.operator.startsWith('>') && comp.operator.startsWith('<')) {\n      return true\n    }\n    // opposite directions greater than\n    if (cmp(this.semver, '>', comp.semver, options) &&\n      this.operator.startsWith('<') && comp.operator.startsWith('>')) {\n      return true\n    }\n    return false\n  }\n}\n\nmodule.exports = Comparator\n\nconst parseOptions = require('../internal/parse-options')\nconst { safeRe: re, t } = require('../internal/re')\nconst cmp = require('../functions/cmp')\nconst debug = require('../internal/debug')\nconst SemVer = require('./semver')\nconst Range = require('./range')\n","'use strict'\n\nconst SPACE_CHARACTERS = /\\s+/g\n\n// hoisted class for cyclic dependency\nclass Range {\n  constructor (range, options) {\n    options = parseOptions(options)\n\n    if (range instanceof Range) {\n      if (\n        range.loose === !!options.loose &&\n        range.includePrerelease === !!options.includePrerelease\n      ) {\n        return range\n      } else {\n        return new Range(range.raw, options)\n      }\n    }\n\n    if (range instanceof Comparator) {\n      // just put it in the set and return\n      this.raw = range.value\n      this.set = [[range]]\n      this.formatted = undefined\n      return this\n    }\n\n    this.options = options\n    this.loose = !!options.loose\n    this.includePrerelease = !!options.includePrerelease\n\n    // First reduce all whitespace as much as possible so we do not have to rely\n    // on potentially slow regexes like \\s*. This is then stored and used for\n    // future error messages as well.\n    this.raw = range.trim().replace(SPACE_CHARACTERS, ' ')\n\n    // First, split on ||\n    this.set = this.raw\n      .split('||')\n      // map the range to a 2d array of comparators\n      .map(r => this.parseRange(r.trim()))\n      // throw out any comparator lists that are empty\n      // this generally means that it was not a valid range, which is allowed\n      // in loose mode, but will still throw if the WHOLE range is invalid.\n      .filter(c => c.length)\n\n    if (!this.set.length) {\n      throw new TypeError(`Invalid SemVer Range: ${this.raw}`)\n    }\n\n    // if we have any that are not the null set, throw out null sets.\n    if (this.set.length > 1) {\n      // keep the first one, in case they're all null sets\n      const first = this.set[0]\n      this.set = this.set.filter(c => !isNullSet(c[0]))\n      if (this.set.length === 0) {\n        this.set = [first]\n      } else if (this.set.length > 1) {\n        // if we have any that are *, then the range is just *\n        for (const c of this.set) {\n          if (c.length === 1 && isAny(c[0])) {\n            this.set = [c]\n            break\n          }\n        }\n      }\n    }\n\n    this.formatted = undefined\n  }\n\n  get range () {\n    if (this.formatted === undefined) {\n      this.formatted = ''\n      for (let i = 0; i < this.set.length; i++) {\n        if (i > 0) {\n          this.formatted += '||'\n        }\n        const comps = this.set[i]\n        for (let k = 0; k < comps.length; k++) {\n          if (k > 0) {\n            this.formatted += ' '\n          }\n          this.formatted += comps[k].toString().trim()\n        }\n      }\n    }\n    return this.formatted\n  }\n\n  format () {\n    return this.range\n  }\n\n  toString () {\n    return this.range\n  }\n\n  parseRange (range) {\n    // memoize range parsing for performance.\n    // this is a very hot path, and fully deterministic.\n    const memoOpts =\n      (this.options.includePrerelease && FLAG_INCLUDE_PRERELEASE) |\n      (this.options.loose && FLAG_LOOSE)\n    const memoKey = memoOpts + ':' + range\n    const cached = cache.get(memoKey)\n    if (cached) {\n      return cached\n    }\n\n    const loose = this.options.loose\n    // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`\n    const hr = loose ? re[t.HYPHENRANGELOOSE] : re[t.HYPHENRANGE]\n    range = range.replace(hr, hyphenReplace(this.options.includePrerelease))\n    debug('hyphen replace', range)\n\n    // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`\n    range = range.replace(re[t.COMPARATORTRIM], comparatorTrimReplace)\n    debug('comparator trim', range)\n\n    // `~ 1.2.3` => `~1.2.3`\n    range = range.replace(re[t.TILDETRIM], tildeTrimReplace)\n    debug('tilde trim', range)\n\n    // `^ 1.2.3` => `^1.2.3`\n    range = range.replace(re[t.CARETTRIM], caretTrimReplace)\n    debug('caret trim', range)\n\n    // At this point, the range is completely trimmed and\n    // ready to be split into comparators.\n\n    let rangeList = range\n      .split(' ')\n      .map(comp => parseComparator(comp, this.options))\n      .join(' ')\n      .split(/\\s+/)\n      // >=0.0.0 is equivalent to *\n      .map(comp => replaceGTE0(comp, this.options))\n\n    if (loose) {\n      // in loose mode, throw out any that are not valid comparators\n      rangeList = rangeList.filter(comp => {\n        debug('loose invalid filter', comp, this.options)\n        return !!comp.match(re[t.COMPARATORLOOSE])\n      })\n    }\n    debug('range list', rangeList)\n\n    // if any comparators are the null set, then replace with JUST null set\n    // if more than one comparator, remove any * comparators\n    // also, don't include the same comparator more than once\n    const rangeMap = new Map()\n    const comparators = rangeList.map(comp => new Comparator(comp, this.options))\n    for (const comp of comparators) {\n      if (isNullSet(comp)) {\n        return [comp]\n      }\n      rangeMap.set(comp.value, comp)\n    }\n    if (rangeMap.size > 1 && rangeMap.has('')) {\n      rangeMap.delete('')\n    }\n\n    const result = [...rangeMap.values()]\n    cache.set(memoKey, result)\n    return result\n  }\n\n  intersects (range, options) {\n    if (!(range instanceof Range)) {\n      throw new TypeError('a Range is required')\n    }\n\n    return this.set.some((thisComparators) => {\n      return (\n        isSatisfiable(thisComparators, options) &&\n        range.set.some((rangeComparators) => {\n          return (\n            isSatisfiable(rangeComparators, options) &&\n            thisComparators.every((thisComparator) => {\n              return rangeComparators.every((rangeComparator) => {\n                return thisComparator.intersects(rangeComparator, options)\n              })\n            })\n          )\n        })\n      )\n    })\n  }\n\n  // if ANY of the sets match ALL of its comparators, then pass\n  test (version) {\n    if (!version) {\n      return false\n    }\n\n    if (typeof version === 'string') {\n      try {\n        version = new SemVer(version, this.options)\n      } catch (er) {\n        return false\n      }\n    }\n\n    for (let i = 0; i < this.set.length; i++) {\n      if (testSet(this.set[i], version, this.options)) {\n        return true\n      }\n    }\n    return false\n  }\n}\n\nmodule.exports = Range\n\nconst LRU = require('../internal/lrucache')\nconst cache = new LRU()\n\nconst parseOptions = require('../internal/parse-options')\nconst Comparator = require('./comparator')\nconst debug = require('../internal/debug')\nconst SemVer = require('./semver')\nconst {\n  safeRe: re,\n  t,\n  comparatorTrimReplace,\n  tildeTrimReplace,\n  caretTrimReplace,\n} = require('../internal/re')\nconst { FLAG_INCLUDE_PRERELEASE, FLAG_LOOSE } = require('../internal/constants')\n\nconst isNullSet = c => c.value === '<0.0.0-0'\nconst isAny = c => c.value === ''\n\n// take a set of comparators and determine whether there\n// exists a version which can satisfy it\nconst isSatisfiable = (comparators, options) => {\n  let result = true\n  const remainingComparators = comparators.slice()\n  let testComparator = remainingComparators.pop()\n\n  while (result && remainingComparators.length) {\n    result = remainingComparators.every((otherComparator) => {\n      return testComparator.intersects(otherComparator, options)\n    })\n\n    testComparator = remainingComparators.pop()\n  }\n\n  return result\n}\n\n// comprised of xranges, tildes, stars, and gtlt's at this point.\n// already replaced the hyphen ranges\n// turn into a set of JUST comparators.\nconst parseComparator = (comp, options) => {\n  comp = comp.replace(re[t.BUILD], '')\n  debug('comp', comp, options)\n  comp = replaceCarets(comp, options)\n  debug('caret', comp)\n  comp = replaceTildes(comp, options)\n  debug('tildes', comp)\n  comp = replaceXRanges(comp, options)\n  debug('xrange', comp)\n  comp = replaceStars(comp, options)\n  debug('stars', comp)\n  return comp\n}\n\nconst isX = id => !id || id.toLowerCase() === 'x' || id === '*'\n\n// ~, ~> --> * (any, kinda silly)\n// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0-0\n// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0-0\n// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0-0\n// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0-0\n// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0-0\n// ~0.0.1 --> >=0.0.1 <0.1.0-0\nconst replaceTildes = (comp, options) => {\n  return comp\n    .trim()\n    .split(/\\s+/)\n    .map((c) => replaceTilde(c, options))\n    .join(' ')\n}\n\nconst replaceTilde = (comp, options) => {\n  const r = options.loose ? re[t.TILDELOOSE] : re[t.TILDE]\n  return comp.replace(r, (_, M, m, p, pr) => {\n    debug('tilde', comp, _, M, m, p, pr)\n    let ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = `>=${M}.0.0 <${+M + 1}.0.0-0`\n    } else if (isX(p)) {\n      // ~1.2 == >=1.2.0 <1.3.0-0\n      ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`\n    } else if (pr) {\n      debug('replaceTilde pr', pr)\n      ret = `>=${M}.${m}.${p}-${pr\n      } <${M}.${+m + 1}.0-0`\n    } else {\n      // ~1.2.3 == >=1.2.3 <1.3.0-0\n      ret = `>=${M}.${m}.${p\n      } <${M}.${+m + 1}.0-0`\n    }\n\n    debug('tilde return', ret)\n    return ret\n  })\n}\n\n// ^ --> * (any, kinda silly)\n// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0-0\n// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0-0\n// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0-0\n// ^1.2.3 --> >=1.2.3 <2.0.0-0\n// ^1.2.0 --> >=1.2.0 <2.0.0-0\n// ^0.0.1 --> >=0.0.1 <0.0.2-0\n// ^0.1.0 --> >=0.1.0 <0.2.0-0\nconst replaceCarets = (comp, options) => {\n  return comp\n    .trim()\n    .split(/\\s+/)\n    .map((c) => replaceCaret(c, options))\n    .join(' ')\n}\n\nconst replaceCaret = (comp, options) => {\n  debug('caret', comp, options)\n  const r = options.loose ? re[t.CARETLOOSE] : re[t.CARET]\n  const z = options.includePrerelease ? '-0' : ''\n  return comp.replace(r, (_, M, m, p, pr) => {\n    debug('caret', comp, _, M, m, p, pr)\n    let ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`\n    } else if (isX(p)) {\n      if (M === '0') {\n        ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`\n      } else {\n        ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`\n      }\n    } else if (pr) {\n      debug('replaceCaret pr', pr)\n      if (M === '0') {\n        if (m === '0') {\n          ret = `>=${M}.${m}.${p}-${pr\n          } <${M}.${m}.${+p + 1}-0`\n        } else {\n          ret = `>=${M}.${m}.${p}-${pr\n          } <${M}.${+m + 1}.0-0`\n        }\n      } else {\n        ret = `>=${M}.${m}.${p}-${pr\n        } <${+M + 1}.0.0-0`\n      }\n    } else {\n      debug('no pr')\n      if (M === '0') {\n        if (m === '0') {\n          ret = `>=${M}.${m}.${p\n          }${z} <${M}.${m}.${+p + 1}-0`\n        } else {\n          ret = `>=${M}.${m}.${p\n          }${z} <${M}.${+m + 1}.0-0`\n        }\n      } else {\n        ret = `>=${M}.${m}.${p\n        } <${+M + 1}.0.0-0`\n      }\n    }\n\n    debug('caret return', ret)\n    return ret\n  })\n}\n\nconst replaceXRanges = (comp, options) => {\n  debug('replaceXRanges', comp, options)\n  return comp\n    .split(/\\s+/)\n    .map((c) => replaceXRange(c, options))\n    .join(' ')\n}\n\nconst replaceXRange = (comp, options) => {\n  comp = comp.trim()\n  const r = options.loose ? re[t.XRANGELOOSE] : re[t.XRANGE]\n  return comp.replace(r, (ret, gtlt, M, m, p, pr) => {\n    debug('xRange', comp, ret, gtlt, M, m, p, pr)\n    const xM = isX(M)\n    const xm = xM || isX(m)\n    const xp = xm || isX(p)\n    const anyX = xp\n\n    if (gtlt === '=' && anyX) {\n      gtlt = ''\n    }\n\n    // if we're including prereleases in the match, then we need\n    // to fix this to -0, the lowest possible prerelease value\n    pr = options.includePrerelease ? '-0' : ''\n\n    if (xM) {\n      if (gtlt === '>' || gtlt === '<') {\n        // nothing is allowed\n        ret = '<0.0.0-0'\n      } else {\n        // nothing is forbidden\n        ret = '*'\n      }\n    } else if (gtlt && anyX) {\n      // we know patch is an x, because we have any x at all.\n      // replace X with 0\n      if (xm) {\n        m = 0\n      }\n      p = 0\n\n      if (gtlt === '>') {\n        // >1 => >=2.0.0\n        // >1.2 => >=1.3.0\n        gtlt = '>='\n        if (xm) {\n          M = +M + 1\n          m = 0\n          p = 0\n        } else {\n          m = +m + 1\n          p = 0\n        }\n      } else if (gtlt === '<=') {\n        // <=0.7.x is actually <0.8.0, since any 0.7.x should\n        // pass.  Similarly, <=7.x is actually <8.0.0, etc.\n        gtlt = '<'\n        if (xm) {\n          M = +M + 1\n        } else {\n          m = +m + 1\n        }\n      }\n\n      if (gtlt === '<') {\n        pr = '-0'\n      }\n\n      ret = `${gtlt + M}.${m}.${p}${pr}`\n    } else if (xm) {\n      ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`\n    } else if (xp) {\n      ret = `>=${M}.${m}.0${pr\n      } <${M}.${+m + 1}.0-0`\n    }\n\n    debug('xRange return', ret)\n\n    return ret\n  })\n}\n\n// Because * is AND-ed with everything else in the comparator,\n// and '' means \"any version\", just remove the *s entirely.\nconst replaceStars = (comp, options) => {\n  debug('replaceStars', comp, options)\n  // Looseness is ignored here.  star is always as loose as it gets!\n  return comp\n    .trim()\n    .replace(re[t.STAR], '')\n}\n\nconst replaceGTE0 = (comp, options) => {\n  debug('replaceGTE0', comp, options)\n  return comp\n    .trim()\n    .replace(re[options.includePrerelease ? t.GTE0PRE : t.GTE0], '')\n}\n\n// This function is passed to string.replace(re[t.HYPHENRANGE])\n// M, m, patch, prerelease, build\n// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5\n// 1.2.3 - 3.4 => >=1.2.0 <3.5.0-0 Any 3.4.x will do\n// 1.2 - 3.4 => >=1.2.0 <3.5.0-0\n// TODO build?\nconst hyphenReplace = incPr => ($0,\n  from, fM, fm, fp, fpr, fb,\n  to, tM, tm, tp, tpr) => {\n  if (isX(fM)) {\n    from = ''\n  } else if (isX(fm)) {\n    from = `>=${fM}.0.0${incPr ? '-0' : ''}`\n  } else if (isX(fp)) {\n    from = `>=${fM}.${fm}.0${incPr ? '-0' : ''}`\n  } else if (fpr) {\n    from = `>=${from}`\n  } else {\n    from = `>=${from}${incPr ? '-0' : ''}`\n  }\n\n  if (isX(tM)) {\n    to = ''\n  } else if (isX(tm)) {\n    to = `<${+tM + 1}.0.0-0`\n  } else if (isX(tp)) {\n    to = `<${tM}.${+tm + 1}.0-0`\n  } else if (tpr) {\n    to = `<=${tM}.${tm}.${tp}-${tpr}`\n  } else if (incPr) {\n    to = `<${tM}.${tm}.${+tp + 1}-0`\n  } else {\n    to = `<=${to}`\n  }\n\n  return `${from} ${to}`.trim()\n}\n\nconst testSet = (set, version, options) => {\n  for (let i = 0; i < set.length; i++) {\n    if (!set[i].test(version)) {\n      return false\n    }\n  }\n\n  if (version.prerelease.length && !options.includePrerelease) {\n    // Find the set of versions that are allowed to have prereleases\n    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0\n    // That should allow `1.2.3-pr.2` to pass.\n    // However, `1.2.4-alpha.notready` should NOT be allowed,\n    // even though it's within the range set by the comparators.\n    for (let i = 0; i < set.length; i++) {\n      debug(set[i].semver)\n      if (set[i].semver === Comparator.ANY) {\n        continue\n      }\n\n      if (set[i].semver.prerelease.length > 0) {\n        const allowed = set[i].semver\n        if (allowed.major === version.major &&\n            allowed.minor === version.minor &&\n            allowed.patch === version.patch) {\n          return true\n        }\n      }\n    }\n\n    // Version has a -pre, but it's not one of the ones we like.\n    return false\n  }\n\n  return true\n}\n","'use strict'\n\nconst debug = require('../internal/debug')\nconst { MAX_LENGTH, MAX_SAFE_INTEGER } = require('../internal/constants')\nconst { safeRe: re, t } = require('../internal/re')\n\nconst parseOptions = require('../internal/parse-options')\nconst { compareIdentifiers } = require('../internal/identifiers')\nclass SemVer {\n  constructor (version, options) {\n    options = parseOptions(options)\n\n    if (version instanceof SemVer) {\n      if (version.loose === !!options.loose &&\n        version.includePrerelease === !!options.includePrerelease) {\n        return version\n      } else {\n        version = version.version\n      }\n    } else if (typeof version !== 'string') {\n      throw new TypeError(`Invalid version. Must be a string. Got type \"${typeof version}\".`)\n    }\n\n    if (version.length > MAX_LENGTH) {\n      throw new TypeError(\n        `version is longer than ${MAX_LENGTH} characters`\n      )\n    }\n\n    debug('SemVer', version, options)\n    this.options = options\n    this.loose = !!options.loose\n    // this isn't actually relevant for versions, but keep it so that we\n    // don't run into trouble passing this.options around.\n    this.includePrerelease = !!options.includePrerelease\n\n    const m = version.trim().match(options.loose ? re[t.LOOSE] : re[t.FULL])\n\n    if (!m) {\n      throw new TypeError(`Invalid Version: ${version}`)\n    }\n\n    this.raw = version\n\n    // these are actually numbers\n    this.major = +m[1]\n    this.minor = +m[2]\n    this.patch = +m[3]\n\n    if (this.major > MAX_SAFE_INTEGER || this.major < 0) {\n      throw new TypeError('Invalid major version')\n    }\n\n    if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {\n      throw new TypeError('Invalid minor version')\n    }\n\n    if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {\n      throw new TypeError('Invalid patch version')\n    }\n\n    // numberify any prerelease numeric ids\n    if (!m[4]) {\n      this.prerelease = []\n    } else {\n      this.prerelease = m[4].split('.').map((id) => {\n        if (/^[0-9]+$/.test(id)) {\n          const num = +id\n          if (num >= 0 && num < MAX_SAFE_INTEGER) {\n            return num\n          }\n        }\n        return id\n      })\n    }\n\n    this.build = m[5] ? m[5].split('.') : []\n    this.format()\n  }\n\n  format () {\n    this.version = `${this.major}.${this.minor}.${this.patch}`\n    if (this.prerelease.length) {\n      this.version += `-${this.prerelease.join('.')}`\n    }\n    return this.version\n  }\n\n  toString () {\n    return this.version\n  }\n\n  compare (other) {\n    debug('SemVer.compare', this.version, this.options, other)\n    if (!(other instanceof SemVer)) {\n      if (typeof other === 'string' && other === this.version) {\n        return 0\n      }\n      other = new SemVer(other, this.options)\n    }\n\n    if (other.version === this.version) {\n      return 0\n    }\n\n    return this.compareMain(other) || this.comparePre(other)\n  }\n\n  compareMain (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    if (this.major < other.major) {\n      return -1\n    }\n    if (this.major > other.major) {\n      return 1\n    }\n    if (this.minor < other.minor) {\n      return -1\n    }\n    if (this.minor > other.minor) {\n      return 1\n    }\n    if (this.patch < other.patch) {\n      return -1\n    }\n    if (this.patch > other.patch) {\n      return 1\n    }\n    return 0\n  }\n\n  comparePre (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    // NOT having a prerelease is > having one\n    if (this.prerelease.length && !other.prerelease.length) {\n      return -1\n    } else if (!this.prerelease.length && other.prerelease.length) {\n      return 1\n    } else if (!this.prerelease.length && !other.prerelease.length) {\n      return 0\n    }\n\n    let i = 0\n    do {\n      const a = this.prerelease[i]\n      const b = other.prerelease[i]\n      debug('prerelease compare', i, a, b)\n      if (a === undefined && b === undefined) {\n        return 0\n      } else if (b === undefined) {\n        return 1\n      } else if (a === undefined) {\n        return -1\n      } else if (a === b) {\n        continue\n      } else {\n        return compareIdentifiers(a, b)\n      }\n    } while (++i)\n  }\n\n  compareBuild (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    let i = 0\n    do {\n      const a = this.build[i]\n      const b = other.build[i]\n      debug('build compare', i, a, b)\n      if (a === undefined && b === undefined) {\n        return 0\n      } else if (b === undefined) {\n        return 1\n      } else if (a === undefined) {\n        return -1\n      } else if (a === b) {\n        continue\n      } else {\n        return compareIdentifiers(a, b)\n      }\n    } while (++i)\n  }\n\n  // preminor will bump the version up to the next minor release, and immediately\n  // down to pre-release. premajor and prepatch work the same way.\n  inc (release, identifier, identifierBase) {\n    if (release.startsWith('pre')) {\n      if (!identifier && identifierBase === false) {\n        throw new Error('invalid increment argument: identifier is empty')\n      }\n      // Avoid an invalid semver results\n      if (identifier) {\n        const match = `-${identifier}`.match(this.options.loose ? re[t.PRERELEASELOOSE] : re[t.PRERELEASE])\n        if (!match || match[1] !== identifier) {\n          throw new Error(`invalid identifier: ${identifier}`)\n        }\n      }\n    }\n\n    switch (release) {\n      case 'premajor':\n        this.prerelease.length = 0\n        this.patch = 0\n        this.minor = 0\n        this.major++\n        this.inc('pre', identifier, identifierBase)\n        break\n      case 'preminor':\n        this.prerelease.length = 0\n        this.patch = 0\n        this.minor++\n        this.inc('pre', identifier, identifierBase)\n        break\n      case 'prepatch':\n        // If this is already a prerelease, it will bump to the next version\n        // drop any prereleases that might already exist, since they are not\n        // relevant at this point.\n        this.prerelease.length = 0\n        this.inc('patch', identifier, identifierBase)\n        this.inc('pre', identifier, identifierBase)\n        break\n      // If the input is a non-prerelease version, this acts the same as\n      // prepatch.\n      case 'prerelease':\n        if (this.prerelease.length === 0) {\n          this.inc('patch', identifier, identifierBase)\n        }\n        this.inc('pre', identifier, identifierBase)\n        break\n      case 'release':\n        if (this.prerelease.length === 0) {\n          throw new Error(`version ${this.raw} is not a prerelease`)\n        }\n        this.prerelease.length = 0\n        break\n\n      case 'major':\n        // If this is a pre-major version, bump up to the same major version.\n        // Otherwise increment major.\n        // 1.0.0-5 bumps to 1.0.0\n        // 1.1.0 bumps to 2.0.0\n        if (\n          this.minor !== 0 ||\n          this.patch !== 0 ||\n          this.prerelease.length === 0\n        ) {\n          this.major++\n        }\n        this.minor = 0\n        this.patch = 0\n        this.prerelease = []\n        break\n      case 'minor':\n        // If this is a pre-minor version, bump up to the same minor version.\n        // Otherwise increment minor.\n        // 1.2.0-5 bumps to 1.2.0\n        // 1.2.1 bumps to 1.3.0\n        if (this.patch !== 0 || this.prerelease.length === 0) {\n          this.minor++\n        }\n        this.patch = 0\n        this.prerelease = []\n        break\n      case 'patch':\n        // If this is not a pre-release version, it will increment the patch.\n        // If it is a pre-release it will bump up to the same patch version.\n        // 1.2.0-5 patches to 1.2.0\n        // 1.2.0 patches to 1.2.1\n        if (this.prerelease.length === 0) {\n          this.patch++\n        }\n        this.prerelease = []\n        break\n      // This probably shouldn't be used publicly.\n      // 1.0.0 'pre' would become 1.0.0-0 which is the wrong direction.\n      case 'pre': {\n        const base = Number(identifierBase) ? 1 : 0\n\n        if (this.prerelease.length === 0) {\n          this.prerelease = [base]\n        } else {\n          let i = this.prerelease.length\n          while (--i >= 0) {\n            if (typeof this.prerelease[i] === 'number') {\n              this.prerelease[i]++\n              i = -2\n            }\n          }\n          if (i === -1) {\n            // didn't increment anything\n            if (identifier === this.prerelease.join('.') && identifierBase === false) {\n              throw new Error('invalid increment argument: identifier already exists')\n            }\n            this.prerelease.push(base)\n          }\n        }\n        if (identifier) {\n          // 1.2.0-beta.1 bumps to 1.2.0-beta.2,\n          // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0\n          let prerelease = [identifier, base]\n          if (identifierBase === false) {\n            prerelease = [identifier]\n          }\n          if (compareIdentifiers(this.prerelease[0], identifier) === 0) {\n            if (isNaN(this.prerelease[1])) {\n              this.prerelease = prerelease\n            }\n          } else {\n            this.prerelease = prerelease\n          }\n        }\n        break\n      }\n      default:\n        throw new Error(`invalid increment argument: ${release}`)\n    }\n    this.raw = this.format()\n    if (this.build.length) {\n      this.raw += `+${this.build.join('.')}`\n    }\n    return this\n  }\n}\n\nmodule.exports = SemVer\n","'use strict'\n\nconst parse = require('./parse')\nconst clean = (version, options) => {\n  const s = parse(version.trim().replace(/^[=v]+/, ''), options)\n  return s ? s.version : null\n}\nmodule.exports = clean\n","'use strict'\n\nconst eq = require('./eq')\nconst neq = require('./neq')\nconst gt = require('./gt')\nconst gte = require('./gte')\nconst lt = require('./lt')\nconst lte = require('./lte')\n\nconst cmp = (a, op, b, loose) => {\n  switch (op) {\n    case '===':\n      if (typeof a === 'object') {\n        a = a.version\n      }\n      if (typeof b === 'object') {\n        b = b.version\n      }\n      return a === b\n\n    case '!==':\n      if (typeof a === 'object') {\n        a = a.version\n      }\n      if (typeof b === 'object') {\n        b = b.version\n      }\n      return a !== b\n\n    case '':\n    case '=':\n    case '==':\n      return eq(a, b, loose)\n\n    case '!=':\n      return neq(a, b, loose)\n\n    case '>':\n      return gt(a, b, loose)\n\n    case '>=':\n      return gte(a, b, loose)\n\n    case '<':\n      return lt(a, b, loose)\n\n    case '<=':\n      return lte(a, b, loose)\n\n    default:\n      throw new TypeError(`Invalid operator: ${op}`)\n  }\n}\nmodule.exports = cmp\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst parse = require('./parse')\nconst { safeRe: re, t } = require('../internal/re')\n\nconst coerce = (version, options) => {\n  if (version instanceof SemVer) {\n    return version\n  }\n\n  if (typeof version === 'number') {\n    version = String(version)\n  }\n\n  if (typeof version !== 'string') {\n    return null\n  }\n\n  options = options || {}\n\n  let match = null\n  if (!options.rtl) {\n    match = version.match(options.includePrerelease ? re[t.COERCEFULL] : re[t.COERCE])\n  } else {\n    // Find the right-most coercible string that does not share\n    // a terminus with a more left-ward coercible string.\n    // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'\n    // With includePrerelease option set, '1.2.3.4-rc' wants to coerce '2.3.4-rc', not '2.3.4'\n    //\n    // Walk through the string checking with a /g regexp\n    // Manually set the index so as to pick up overlapping matches.\n    // Stop when we get a match that ends at the string end, since no\n    // coercible string can be more right-ward without the same terminus.\n    const coerceRtlRegex = options.includePrerelease ? re[t.COERCERTLFULL] : re[t.COERCERTL]\n    let next\n    while ((next = coerceRtlRegex.exec(version)) &&\n        (!match || match.index + match[0].length !== version.length)\n    ) {\n      if (!match ||\n            next.index + next[0].length !== match.index + match[0].length) {\n        match = next\n      }\n      coerceRtlRegex.lastIndex = next.index + next[1].length + next[2].length\n    }\n    // leave it in a clean state\n    coerceRtlRegex.lastIndex = -1\n  }\n\n  if (match === null) {\n    return null\n  }\n\n  const major = match[2]\n  const minor = match[3] || '0'\n  const patch = match[4] || '0'\n  const prerelease = options.includePrerelease && match[5] ? `-${match[5]}` : ''\n  const build = options.includePrerelease && match[6] ? `+${match[6]}` : ''\n\n  return parse(`${major}.${minor}.${patch}${prerelease}${build}`, options)\n}\nmodule.exports = coerce\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst compareBuild = (a, b, loose) => {\n  const versionA = new SemVer(a, loose)\n  const versionB = new SemVer(b, loose)\n  return versionA.compare(versionB) || versionA.compareBuild(versionB)\n}\nmodule.exports = compareBuild\n","'use strict'\n\nconst compare = require('./compare')\nconst compareLoose = (a, b) => compare(a, b, true)\nmodule.exports = compareLoose\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst compare = (a, b, loose) =>\n  new SemVer(a, loose).compare(new SemVer(b, loose))\n\nmodule.exports = compare\n","'use strict'\n\nconst parse = require('./parse.js')\n\nconst diff = (version1, version2) => {\n  const v1 = parse(version1, null, true)\n  const v2 = parse(version2, null, true)\n  const comparison = v1.compare(v2)\n\n  if (comparison === 0) {\n    return null\n  }\n\n  const v1Higher = comparison > 0\n  const highVersion = v1Higher ? v1 : v2\n  const lowVersion = v1Higher ? v2 : v1\n  const highHasPre = !!highVersion.prerelease.length\n  const lowHasPre = !!lowVersion.prerelease.length\n\n  if (lowHasPre && !highHasPre) {\n    // Going from prerelease -> no prerelease requires some special casing\n\n    // If the low version has only a major, then it will always be a major\n    // Some examples:\n    // 1.0.0-1 -> 1.0.0\n    // 1.0.0-1 -> 1.1.1\n    // 1.0.0-1 -> 2.0.0\n    if (!lowVersion.patch && !lowVersion.minor) {\n      return 'major'\n    }\n\n    // If the main part has no difference\n    if (lowVersion.compareMain(highVersion) === 0) {\n      if (lowVersion.minor && !lowVersion.patch) {\n        return 'minor'\n      }\n      return 'patch'\n    }\n  }\n\n  // add the `pre` prefix if we are going to a prerelease version\n  const prefix = highHasPre ? 'pre' : ''\n\n  if (v1.major !== v2.major) {\n    return prefix + 'major'\n  }\n\n  if (v1.minor !== v2.minor) {\n    return prefix + 'minor'\n  }\n\n  if (v1.patch !== v2.patch) {\n    return prefix + 'patch'\n  }\n\n  // high and low are preleases\n  return 'prerelease'\n}\n\nmodule.exports = diff\n","'use strict'\n\nconst compare = require('./compare')\nconst eq = (a, b, loose) => compare(a, b, loose) === 0\nmodule.exports = eq\n","'use strict'\n\nconst compare = require('./compare')\nconst gt = (a, b, loose) => compare(a, b, loose) > 0\nmodule.exports = gt\n","'use strict'\n\nconst compare = require('./compare')\nconst gte = (a, b, loose) => compare(a, b, loose) >= 0\nmodule.exports = gte\n","'use strict'\n\nconst SemVer = require('../classes/semver')\n\nconst inc = (version, release, options, identifier, identifierBase) => {\n  if (typeof (options) === 'string') {\n    identifierBase = identifier\n    identifier = options\n    options = undefined\n  }\n\n  try {\n    return new SemVer(\n      version instanceof SemVer ? version.version : version,\n      options\n    ).inc(release, identifier, identifierBase).version\n  } catch (er) {\n    return null\n  }\n}\nmodule.exports = inc\n","'use strict'\n\nconst compare = require('./compare')\nconst lt = (a, b, loose) => compare(a, b, loose) < 0\nmodule.exports = lt\n","'use strict'\n\nconst compare = require('./compare')\nconst lte = (a, b, loose) => compare(a, b, loose) <= 0\nmodule.exports = lte\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst major = (a, loose) => new SemVer(a, loose).major\nmodule.exports = major\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst minor = (a, loose) => new SemVer(a, loose).minor\nmodule.exports = minor\n","'use strict'\n\nconst compare = require('./compare')\nconst neq = (a, b, loose) => compare(a, b, loose) !== 0\nmodule.exports = neq\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst parse = (version, options, throwErrors = false) => {\n  if (version instanceof SemVer) {\n    return version\n  }\n  try {\n    return new SemVer(version, options)\n  } catch (er) {\n    if (!throwErrors) {\n      return null\n    }\n    throw er\n  }\n}\n\nmodule.exports = parse\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst patch = (a, loose) => new SemVer(a, loose).patch\nmodule.exports = patch\n","'use strict'\n\nconst parse = require('./parse')\nconst prerelease = (version, options) => {\n  const parsed = parse(version, options)\n  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null\n}\nmodule.exports = prerelease\n","'use strict'\n\nconst compare = require('./compare')\nconst rcompare = (a, b, loose) => compare(b, a, loose)\nmodule.exports = rcompare\n","'use strict'\n\nconst compareBuild = require('./compare-build')\nconst rsort = (list, loose) => list.sort((a, b) => compareBuild(b, a, loose))\nmodule.exports = rsort\n","'use strict'\n\nconst Range = require('../classes/range')\nconst satisfies = (version, range, options) => {\n  try {\n    range = new Range(range, options)\n  } catch (er) {\n    return false\n  }\n  return range.test(version)\n}\nmodule.exports = satisfies\n","'use strict'\n\nconst compareBuild = require('./compare-build')\nconst sort = (list, loose) => list.sort((a, b) => compareBuild(a, b, loose))\nmodule.exports = sort\n","'use strict'\n\nconst parse = require('./parse')\nconst valid = (version, options) => {\n  const v = parse(version, options)\n  return v ? v.version : null\n}\nmodule.exports = valid\n","'use strict'\n\n// just pre-load all the stuff that index.js lazily exports\nconst internalRe = require('./internal/re')\nconst constants = require('./internal/constants')\nconst SemVer = require('./classes/semver')\nconst identifiers = require('./internal/identifiers')\nconst parse = require('./functions/parse')\nconst valid = require('./functions/valid')\nconst clean = require('./functions/clean')\nconst inc = require('./functions/inc')\nconst diff = require('./functions/diff')\nconst major = require('./functions/major')\nconst minor = require('./functions/minor')\nconst patch = require('./functions/patch')\nconst prerelease = require('./functions/prerelease')\nconst compare = require('./functions/compare')\nconst rcompare = require('./functions/rcompare')\nconst compareLoose = require('./functions/compare-loose')\nconst compareBuild = require('./functions/compare-build')\nconst sort = require('./functions/sort')\nconst rsort = require('./functions/rsort')\nconst gt = require('./functions/gt')\nconst lt = require('./functions/lt')\nconst eq = require('./functions/eq')\nconst neq = require('./functions/neq')\nconst gte = require('./functions/gte')\nconst lte = require('./functions/lte')\nconst cmp = require('./functions/cmp')\nconst coerce = require('./functions/coerce')\nconst Comparator = require('./classes/comparator')\nconst Range = require('./classes/range')\nconst satisfies = require('./functions/satisfies')\nconst toComparators = require('./ranges/to-comparators')\nconst maxSatisfying = require('./ranges/max-satisfying')\nconst minSatisfying = require('./ranges/min-satisfying')\nconst minVersion = require('./ranges/min-version')\nconst validRange = require('./ranges/valid')\nconst outside = require('./ranges/outside')\nconst gtr = require('./ranges/gtr')\nconst ltr = require('./ranges/ltr')\nconst intersects = require('./ranges/intersects')\nconst simplifyRange = require('./ranges/simplify')\nconst subset = require('./ranges/subset')\nmodule.exports = {\n  parse,\n  valid,\n  clean,\n  inc,\n  diff,\n  major,\n  minor,\n  patch,\n  prerelease,\n  compare,\n  rcompare,\n  compareLoose,\n  compareBuild,\n  sort,\n  rsort,\n  gt,\n  lt,\n  eq,\n  neq,\n  gte,\n  lte,\n  cmp,\n  coerce,\n  Comparator,\n  Range,\n  satisfies,\n  toComparators,\n  maxSatisfying,\n  minSatisfying,\n  minVersion,\n  validRange,\n  outside,\n  gtr,\n  ltr,\n  intersects,\n  simplifyRange,\n  subset,\n  SemVer,\n  re: internalRe.re,\n  src: internalRe.src,\n  tokens: internalRe.t,\n  SEMVER_SPEC_VERSION: constants.SEMVER_SPEC_VERSION,\n  RELEASE_TYPES: constants.RELEASE_TYPES,\n  compareIdentifiers: identifiers.compareIdentifiers,\n  rcompareIdentifiers: identifiers.rcompareIdentifiers,\n}\n","'use strict'\n\n// Note: this is the semver.org version of the spec that it implements\n// Not necessarily the package version of this code.\nconst SEMVER_SPEC_VERSION = '2.0.0'\n\nconst MAX_LENGTH = 256\nconst MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER ||\n/* istanbul ignore next */ 9007199254740991\n\n// Max safe segment length for coercion.\nconst MAX_SAFE_COMPONENT_LENGTH = 16\n\n// Max safe length for a build identifier. The max length minus 6 characters for\n// the shortest version with a build 0.0.0+BUILD.\nconst MAX_SAFE_BUILD_LENGTH = MAX_LENGTH - 6\n\nconst RELEASE_TYPES = [\n  'major',\n  'premajor',\n  'minor',\n  'preminor',\n  'patch',\n  'prepatch',\n  'prerelease',\n]\n\nmodule.exports = {\n  MAX_LENGTH,\n  MAX_SAFE_COMPONENT_LENGTH,\n  MAX_SAFE_BUILD_LENGTH,\n  MAX_SAFE_INTEGER,\n  RELEASE_TYPES,\n  SEMVER_SPEC_VERSION,\n  FLAG_INCLUDE_PRERELEASE: 0b001,\n  FLAG_LOOSE: 0b010,\n}\n","'use strict'\n\nconst debug = (\n  typeof process === 'object' &&\n  process.env &&\n  process.env.NODE_DEBUG &&\n  /\\bsemver\\b/i.test(process.env.NODE_DEBUG)\n) ? (...args) => console.error('SEMVER', ...args)\n  : () => {}\n\nmodule.exports = debug\n","'use strict'\n\nconst numeric = /^[0-9]+$/\nconst compareIdentifiers = (a, b) => {\n  if (typeof a === 'number' && typeof b === 'number') {\n    return a === b ? 0 : a < b ? -1 : 1\n  }\n\n  const anum = numeric.test(a)\n  const bnum = numeric.test(b)\n\n  if (anum && bnum) {\n    a = +a\n    b = +b\n  }\n\n  return a === b ? 0\n    : (anum && !bnum) ? -1\n    : (bnum && !anum) ? 1\n    : a < b ? -1\n    : 1\n}\n\nconst rcompareIdentifiers = (a, b) => compareIdentifiers(b, a)\n\nmodule.exports = {\n  compareIdentifiers,\n  rcompareIdentifiers,\n}\n","'use strict'\n\nclass LRUCache {\n  constructor () {\n    this.max = 1000\n    this.map = new Map()\n  }\n\n  get (key) {\n    const value = this.map.get(key)\n    if (value === undefined) {\n      return undefined\n    } else {\n      // Remove the key from the map and add it to the end\n      this.map.delete(key)\n      this.map.set(key, value)\n      return value\n    }\n  }\n\n  delete (key) {\n    return this.map.delete(key)\n  }\n\n  set (key, value) {\n    const deleted = this.delete(key)\n\n    if (!deleted && value !== undefined) {\n      // If cache is full, delete the least recently used item\n      if (this.map.size >= this.max) {\n        const firstKey = this.map.keys().next().value\n        this.delete(firstKey)\n      }\n\n      this.map.set(key, value)\n    }\n\n    return this\n  }\n}\n\nmodule.exports = LRUCache\n","'use strict'\n\n// parse out just the options we care about\nconst looseOption = Object.freeze({ loose: true })\nconst emptyOpts = Object.freeze({ })\nconst parseOptions = options => {\n  if (!options) {\n    return emptyOpts\n  }\n\n  if (typeof options !== 'object') {\n    return looseOption\n  }\n\n  return options\n}\nmodule.exports = parseOptions\n","'use strict'\n\nconst {\n  MAX_SAFE_COMPONENT_LENGTH,\n  MAX_SAFE_BUILD_LENGTH,\n  MAX_LENGTH,\n} = require('./constants')\nconst debug = require('./debug')\nexports = module.exports = {}\n\n// The actual regexps go on exports.re\nconst re = exports.re = []\nconst safeRe = exports.safeRe = []\nconst src = exports.src = []\nconst safeSrc = exports.safeSrc = []\nconst t = exports.t = {}\nlet R = 0\n\nconst LETTERDASHNUMBER = '[a-zA-Z0-9-]'\n\n// Replace some greedy regex tokens to prevent regex dos issues. These regex are\n// used internally via the safeRe object since all inputs in this library get\n// normalized first to trim and collapse all extra whitespace. The original\n// regexes are exported for userland consumption and lower level usage. A\n// future breaking change could export the safer regex only with a note that\n// all input should have extra whitespace removed.\nconst safeRegexReplacements = [\n  ['\\\\s', 1],\n  ['\\\\d', MAX_LENGTH],\n  [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH],\n]\n\nconst makeSafeRegex = (value) => {\n  for (const [token, max] of safeRegexReplacements) {\n    value = value\n      .split(`${token}*`).join(`${token}{0,${max}}`)\n      .split(`${token}+`).join(`${token}{1,${max}}`)\n  }\n  return value\n}\n\nconst createToken = (name, value, isGlobal) => {\n  const safe = makeSafeRegex(value)\n  const index = R++\n  debug(name, index, value)\n  t[name] = index\n  src[index] = value\n  safeSrc[index] = safe\n  re[index] = new RegExp(value, isGlobal ? 'g' : undefined)\n  safeRe[index] = new RegExp(safe, isGlobal ? 'g' : undefined)\n}\n\n// The following Regular Expressions can be used for tokenizing,\n// validating, and parsing SemVer version strings.\n\n// ## Numeric Identifier\n// A single `0`, or a non-zero digit followed by zero or more digits.\n\ncreateToken('NUMERICIDENTIFIER', '0|[1-9]\\\\d*')\ncreateToken('NUMERICIDENTIFIERLOOSE', '\\\\d+')\n\n// ## Non-numeric Identifier\n// Zero or more digits, followed by a letter or hyphen, and then zero or\n// more letters, digits, or hyphens.\n\ncreateToken('NONNUMERICIDENTIFIER', `\\\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`)\n\n// ## Main Version\n// Three dot-separated numeric identifiers.\n\ncreateToken('MAINVERSION', `(${src[t.NUMERICIDENTIFIER]})\\\\.` +\n                   `(${src[t.NUMERICIDENTIFIER]})\\\\.` +\n                   `(${src[t.NUMERICIDENTIFIER]})`)\n\ncreateToken('MAINVERSIONLOOSE', `(${src[t.NUMERICIDENTIFIERLOOSE]})\\\\.` +\n                        `(${src[t.NUMERICIDENTIFIERLOOSE]})\\\\.` +\n                        `(${src[t.NUMERICIDENTIFIERLOOSE]})`)\n\n// ## Pre-release Version Identifier\n// A numeric identifier, or a non-numeric identifier.\n// Non-numberic identifiers include numberic identifiers but can be longer.\n// Therefore non-numberic identifiers must go first.\n\ncreateToken('PRERELEASEIDENTIFIER', `(?:${src[t.NONNUMERICIDENTIFIER]\n}|${src[t.NUMERICIDENTIFIER]})`)\n\ncreateToken('PRERELEASEIDENTIFIERLOOSE', `(?:${src[t.NONNUMERICIDENTIFIER]\n}|${src[t.NUMERICIDENTIFIERLOOSE]})`)\n\n// ## Pre-release Version\n// Hyphen, followed by one or more dot-separated pre-release version\n// identifiers.\n\ncreateToken('PRERELEASE', `(?:-(${src[t.PRERELEASEIDENTIFIER]\n}(?:\\\\.${src[t.PRERELEASEIDENTIFIER]})*))`)\n\ncreateToken('PRERELEASELOOSE', `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]\n}(?:\\\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`)\n\n// ## Build Metadata Identifier\n// Any combination of digits, letters, or hyphens.\n\ncreateToken('BUILDIDENTIFIER', `${LETTERDASHNUMBER}+`)\n\n// ## Build Metadata\n// Plus sign, followed by one or more period-separated build metadata\n// identifiers.\n\ncreateToken('BUILD', `(?:\\\\+(${src[t.BUILDIDENTIFIER]\n}(?:\\\\.${src[t.BUILDIDENTIFIER]})*))`)\n\n// ## Full Version String\n// A main version, followed optionally by a pre-release version and\n// build metadata.\n\n// Note that the only major, minor, patch, and pre-release sections of\n// the version string are capturing groups.  The build metadata is not a\n// capturing group, because it should not ever be used in version\n// comparison.\n\ncreateToken('FULLPLAIN', `v?${src[t.MAINVERSION]\n}${src[t.PRERELEASE]}?${\n  src[t.BUILD]}?`)\n\ncreateToken('FULL', `^${src[t.FULLPLAIN]}$`)\n\n// like full, but allows v1.2.3 and =1.2.3, which people do sometimes.\n// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty\n// common in the npm registry.\ncreateToken('LOOSEPLAIN', `[v=\\\\s]*${src[t.MAINVERSIONLOOSE]\n}${src[t.PRERELEASELOOSE]}?${\n  src[t.BUILD]}?`)\n\ncreateToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)\n\ncreateToken('GTLT', '((?:<|>)?=?)')\n\n// Something like \"2.*\" or \"1.2.x\".\n// Note that \"x.x\" is a valid xRange identifer, meaning \"any version\"\n// Only the first item is strictly required.\ncreateToken('XRANGEIDENTIFIERLOOSE', `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\\\*`)\ncreateToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\\\*`)\n\ncreateToken('XRANGEPLAIN', `[v=\\\\s]*(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:\\\\.(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:\\\\.(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:${src[t.PRERELEASE]})?${\n                     src[t.BUILD]}?` +\n                   `)?)?`)\n\ncreateToken('XRANGEPLAINLOOSE', `[v=\\\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:\\\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:\\\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:${src[t.PRERELEASELOOSE]})?${\n                          src[t.BUILD]}?` +\n                        `)?)?`)\n\ncreateToken('XRANGE', `^${src[t.GTLT]}\\\\s*${src[t.XRANGEPLAIN]}$`)\ncreateToken('XRANGELOOSE', `^${src[t.GTLT]}\\\\s*${src[t.XRANGEPLAINLOOSE]}$`)\n\n// Coercion.\n// Extract anything that could conceivably be a part of a valid semver\ncreateToken('COERCEPLAIN', `${'(^|[^\\\\d])' +\n              '(\\\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +\n              `(?:\\\\.(\\\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +\n              `(?:\\\\.(\\\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?`)\ncreateToken('COERCE', `${src[t.COERCEPLAIN]}(?:$|[^\\\\d])`)\ncreateToken('COERCEFULL', src[t.COERCEPLAIN] +\n              `(?:${src[t.PRERELEASE]})?` +\n              `(?:${src[t.BUILD]})?` +\n              `(?:$|[^\\\\d])`)\ncreateToken('COERCERTL', src[t.COERCE], true)\ncreateToken('COERCERTLFULL', src[t.COERCEFULL], true)\n\n// Tilde ranges.\n// Meaning is \"reasonably at or greater than\"\ncreateToken('LONETILDE', '(?:~>?)')\n\ncreateToken('TILDETRIM', `(\\\\s*)${src[t.LONETILDE]}\\\\s+`, true)\nexports.tildeTrimReplace = '$1~'\n\ncreateToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)\ncreateToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)\n\n// Caret ranges.\n// Meaning is \"at least and backwards compatible with\"\ncreateToken('LONECARET', '(?:\\\\^)')\n\ncreateToken('CARETTRIM', `(\\\\s*)${src[t.LONECARET]}\\\\s+`, true)\nexports.caretTrimReplace = '$1^'\n\ncreateToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)\ncreateToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)\n\n// A simple gt/lt/eq thing, or just \"\" to indicate \"any version\"\ncreateToken('COMPARATORLOOSE', `^${src[t.GTLT]}\\\\s*(${src[t.LOOSEPLAIN]})$|^$`)\ncreateToken('COMPARATOR', `^${src[t.GTLT]}\\\\s*(${src[t.FULLPLAIN]})$|^$`)\n\n// An expression to strip any whitespace between the gtlt and the thing\n// it modifies, so that `> 1.2.3` ==> `>1.2.3`\ncreateToken('COMPARATORTRIM', `(\\\\s*)${src[t.GTLT]\n}\\\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`, true)\nexports.comparatorTrimReplace = '$1$2$3'\n\n// Something like `1.2.3 - 1.2.4`\n// Note that these all use the loose form, because they'll be\n// checked against either the strict or loose comparator form\n// later.\ncreateToken('HYPHENRANGE', `^\\\\s*(${src[t.XRANGEPLAIN]})` +\n                   `\\\\s+-\\\\s+` +\n                   `(${src[t.XRANGEPLAIN]})` +\n                   `\\\\s*$`)\n\ncreateToken('HYPHENRANGELOOSE', `^\\\\s*(${src[t.XRANGEPLAINLOOSE]})` +\n                        `\\\\s+-\\\\s+` +\n                        `(${src[t.XRANGEPLAINLOOSE]})` +\n                        `\\\\s*$`)\n\n// Star ranges basically just allow anything at all.\ncreateToken('STAR', '(<|>)?=?\\\\s*\\\\*')\n// >=0.0.0 is like a star\ncreateToken('GTE0', '^\\\\s*>=\\\\s*0\\\\.0\\\\.0\\\\s*$')\ncreateToken('GTE0PRE', '^\\\\s*>=\\\\s*0\\\\.0\\\\.0-0\\\\s*$')\n","'use strict'\n\n// Determine if version is greater than all the versions possible in the range.\nconst outside = require('./outside')\nconst gtr = (version, range, options) => outside(version, range, '>', options)\nmodule.exports = gtr\n","'use strict'\n\nconst Range = require('../classes/range')\nconst intersects = (r1, r2, options) => {\n  r1 = new Range(r1, options)\n  r2 = new Range(r2, options)\n  return r1.intersects(r2, options)\n}\nmodule.exports = intersects\n","'use strict'\n\nconst outside = require('./outside')\n// Determine if version is less than all the versions possible in the range\nconst ltr = (version, range, options) => outside(version, range, '<', options)\nmodule.exports = ltr\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst Range = require('../classes/range')\n\nconst maxSatisfying = (versions, range, options) => {\n  let max = null\n  let maxSV = null\n  let rangeObj = null\n  try {\n    rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach((v) => {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!max || maxSV.compare(v) === -1) {\n        // compare(max, v, true)\n        max = v\n        maxSV = new SemVer(max, options)\n      }\n    }\n  })\n  return max\n}\nmodule.exports = maxSatisfying\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst Range = require('../classes/range')\nconst minSatisfying = (versions, range, options) => {\n  let min = null\n  let minSV = null\n  let rangeObj = null\n  try {\n    rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach((v) => {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!min || minSV.compare(v) === 1) {\n        // compare(min, v, true)\n        min = v\n        minSV = new SemVer(min, options)\n      }\n    }\n  })\n  return min\n}\nmodule.exports = minSatisfying\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst Range = require('../classes/range')\nconst gt = require('../functions/gt')\n\nconst minVersion = (range, loose) => {\n  range = new Range(range, loose)\n\n  let minver = new SemVer('0.0.0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = new SemVer('0.0.0-0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = null\n  for (let i = 0; i < range.set.length; ++i) {\n    const comparators = range.set[i]\n\n    let setMin = null\n    comparators.forEach((comparator) => {\n      // Clone to avoid manipulating the comparator's semver object.\n      const compver = new SemVer(comparator.semver.version)\n      switch (comparator.operator) {\n        case '>':\n          if (compver.prerelease.length === 0) {\n            compver.patch++\n          } else {\n            compver.prerelease.push(0)\n          }\n          compver.raw = compver.format()\n          /* fallthrough */\n        case '':\n        case '>=':\n          if (!setMin || gt(compver, setMin)) {\n            setMin = compver\n          }\n          break\n        case '<':\n        case '<=':\n          /* Ignore maximum versions */\n          break\n        /* istanbul ignore next */\n        default:\n          throw new Error(`Unexpected operation: ${comparator.operator}`)\n      }\n    })\n    if (setMin && (!minver || gt(minver, setMin))) {\n      minver = setMin\n    }\n  }\n\n  if (minver && range.test(minver)) {\n    return minver\n  }\n\n  return null\n}\nmodule.exports = minVersion\n","'use strict'\n\nconst SemVer = require('../classes/semver')\nconst Comparator = require('../classes/comparator')\nconst { ANY } = Comparator\nconst Range = require('../classes/range')\nconst satisfies = require('../functions/satisfies')\nconst gt = require('../functions/gt')\nconst lt = require('../functions/lt')\nconst lte = require('../functions/lte')\nconst gte = require('../functions/gte')\n\nconst outside = (version, range, hilo, options) => {\n  version = new SemVer(version, options)\n  range = new Range(range, options)\n\n  let gtfn, ltefn, ltfn, comp, ecomp\n  switch (hilo) {\n    case '>':\n      gtfn = gt\n      ltefn = lte\n      ltfn = lt\n      comp = '>'\n      ecomp = '>='\n      break\n    case '<':\n      gtfn = lt\n      ltefn = gte\n      ltfn = gt\n      comp = '<'\n      ecomp = '<='\n      break\n    default:\n      throw new TypeError('Must provide a hilo val of \"<\" or \">\"')\n  }\n\n  // If it satisfies the range it is not outside\n  if (satisfies(version, range, options)) {\n    return false\n  }\n\n  // From now on, variable terms are as if we're in \"gtr\" mode.\n  // but note that everything is flipped for the \"ltr\" function.\n\n  for (let i = 0; i < range.set.length; ++i) {\n    const comparators = range.set[i]\n\n    let high = null\n    let low = null\n\n    comparators.forEach((comparator) => {\n      if (comparator.semver === ANY) {\n        comparator = new Comparator('>=0.0.0')\n      }\n      high = high || comparator\n      low = low || comparator\n      if (gtfn(comparator.semver, high.semver, options)) {\n        high = comparator\n      } else if (ltfn(comparator.semver, low.semver, options)) {\n        low = comparator\n      }\n    })\n\n    // If the edge version comparator has a operator then our version\n    // isn't outside it\n    if (high.operator === comp || high.operator === ecomp) {\n      return false\n    }\n\n    // If the lowest version comparator has an operator and our version\n    // is less than it then it isn't higher than the range\n    if ((!low.operator || low.operator === comp) &&\n        ltefn(version, low.semver)) {\n      return false\n    } else if (low.operator === ecomp && ltfn(version, low.semver)) {\n      return false\n    }\n  }\n  return true\n}\n\nmodule.exports = outside\n","'use strict'\n\n// given a set of versions and a range, create a \"simplified\" range\n// that includes the same versions that the original range does\n// If the original range is shorter than the simplified one, return that.\nconst satisfies = require('../functions/satisfies.js')\nconst compare = require('../functions/compare.js')\nmodule.exports = (versions, range, options) => {\n  const set = []\n  let first = null\n  let prev = null\n  const v = versions.sort((a, b) => compare(a, b, options))\n  for (const version of v) {\n    const included = satisfies(version, range, options)\n    if (included) {\n      prev = version\n      if (!first) {\n        first = version\n      }\n    } else {\n      if (prev) {\n        set.push([first, prev])\n      }\n      prev = null\n      first = null\n    }\n  }\n  if (first) {\n    set.push([first, null])\n  }\n\n  const ranges = []\n  for (const [min, max] of set) {\n    if (min === max) {\n      ranges.push(min)\n    } else if (!max && min === v[0]) {\n      ranges.push('*')\n    } else if (!max) {\n      ranges.push(`>=${min}`)\n    } else if (min === v[0]) {\n      ranges.push(`<=${max}`)\n    } else {\n      ranges.push(`${min} - ${max}`)\n    }\n  }\n  const simplified = ranges.join(' || ')\n  const original = typeof range.raw === 'string' ? range.raw : String(range)\n  return simplified.length < original.length ? simplified : range\n}\n","'use strict'\n\nconst Range = require('../classes/range.js')\nconst Comparator = require('../classes/comparator.js')\nconst { ANY } = Comparator\nconst satisfies = require('../functions/satisfies.js')\nconst compare = require('../functions/compare.js')\n\n// Complex range `r1 || r2 || ...` is a subset of `R1 || R2 || ...` iff:\n// - Every simple range `r1, r2, ...` is a null set, OR\n// - Every simple range `r1, r2, ...` which is not a null set is a subset of\n//   some `R1, R2, ...`\n//\n// Simple range `c1 c2 ...` is a subset of simple range `C1 C2 ...` iff:\n// - If c is only the ANY comparator\n//   - If C is only the ANY comparator, return true\n//   - Else if in prerelease mode, return false\n//   - else replace c with `[>=0.0.0]`\n// - If C is only the ANY comparator\n//   - if in prerelease mode, return true\n//   - else replace C with `[>=0.0.0]`\n// - Let EQ be the set of = comparators in c\n// - If EQ is more than one, return true (null set)\n// - Let GT be the highest > or >= comparator in c\n// - Let LT be the lowest < or <= comparator in c\n// - If GT and LT, and GT.semver > LT.semver, return true (null set)\n// - If any C is a = range, and GT or LT are set, return false\n// - If EQ\n//   - If GT, and EQ does not satisfy GT, return true (null set)\n//   - If LT, and EQ does not satisfy LT, return true (null set)\n//   - If EQ satisfies every C, return true\n//   - Else return false\n// - If GT\n//   - If GT.semver is lower than any > or >= comp in C, return false\n//   - If GT is >=, and GT.semver does not satisfy every C, return false\n//   - If GT.semver has a prerelease, and not in prerelease mode\n//     - If no C has a prerelease and the GT.semver tuple, return false\n// - If LT\n//   - If LT.semver is greater than any < or <= comp in C, return false\n//   - If LT is <=, and LT.semver does not satisfy every C, return false\n//   - If GT.semver has a prerelease, and not in prerelease mode\n//     - If no C has a prerelease and the LT.semver tuple, return false\n// - Else return true\n\nconst subset = (sub, dom, options = {}) => {\n  if (sub === dom) {\n    return true\n  }\n\n  sub = new Range(sub, options)\n  dom = new Range(dom, options)\n  let sawNonNull = false\n\n  OUTER: for (const simpleSub of sub.set) {\n    for (const simpleDom of dom.set) {\n      const isSub = simpleSubset(simpleSub, simpleDom, options)\n      sawNonNull = sawNonNull || isSub !== null\n      if (isSub) {\n        continue OUTER\n      }\n    }\n    // the null set is a subset of everything, but null simple ranges in\n    // a complex range should be ignored.  so if we saw a non-null range,\n    // then we know this isn't a subset, but if EVERY simple range was null,\n    // then it is a subset.\n    if (sawNonNull) {\n      return false\n    }\n  }\n  return true\n}\n\nconst minimumVersionWithPreRelease = [new Comparator('>=0.0.0-0')]\nconst minimumVersion = [new Comparator('>=0.0.0')]\n\nconst simpleSubset = (sub, dom, options) => {\n  if (sub === dom) {\n    return true\n  }\n\n  if (sub.length === 1 && sub[0].semver === ANY) {\n    if (dom.length === 1 && dom[0].semver === ANY) {\n      return true\n    } else if (options.includePrerelease) {\n      sub = minimumVersionWithPreRelease\n    } else {\n      sub = minimumVersion\n    }\n  }\n\n  if (dom.length === 1 && dom[0].semver === ANY) {\n    if (options.includePrerelease) {\n      return true\n    } else {\n      dom = minimumVersion\n    }\n  }\n\n  const eqSet = new Set()\n  let gt, lt\n  for (const c of sub) {\n    if (c.operator === '>' || c.operator === '>=') {\n      gt = higherGT(gt, c, options)\n    } else if (c.operator === '<' || c.operator === '<=') {\n      lt = lowerLT(lt, c, options)\n    } else {\n      eqSet.add(c.semver)\n    }\n  }\n\n  if (eqSet.size > 1) {\n    return null\n  }\n\n  let gtltComp\n  if (gt && lt) {\n    gtltComp = compare(gt.semver, lt.semver, options)\n    if (gtltComp > 0) {\n      return null\n    } else if (gtltComp === 0 && (gt.operator !== '>=' || lt.operator !== '<=')) {\n      return null\n    }\n  }\n\n  // will iterate one or zero times\n  for (const eq of eqSet) {\n    if (gt && !satisfies(eq, String(gt), options)) {\n      return null\n    }\n\n    if (lt && !satisfies(eq, String(lt), options)) {\n      return null\n    }\n\n    for (const c of dom) {\n      if (!satisfies(eq, String(c), options)) {\n        return false\n      }\n    }\n\n    return true\n  }\n\n  let higher, lower\n  let hasDomLT, hasDomGT\n  // if the subset has a prerelease, we need a comparator in the superset\n  // with the same tuple and a prerelease, or it's not a subset\n  let needDomLTPre = lt &&\n    !options.includePrerelease &&\n    lt.semver.prerelease.length ? lt.semver : false\n  let needDomGTPre = gt &&\n    !options.includePrerelease &&\n    gt.semver.prerelease.length ? gt.semver : false\n  // exception: <1.2.3-0 is the same as <1.2.3\n  if (needDomLTPre && needDomLTPre.prerelease.length === 1 &&\n      lt.operator === '<' && needDomLTPre.prerelease[0] === 0) {\n    needDomLTPre = false\n  }\n\n  for (const c of dom) {\n    hasDomGT = hasDomGT || c.operator === '>' || c.operator === '>='\n    hasDomLT = hasDomLT || c.operator === '<' || c.operator === '<='\n    if (gt) {\n      if (needDomGTPre) {\n        if (c.semver.prerelease && c.semver.prerelease.length &&\n            c.semver.major === needDomGTPre.major &&\n            c.semver.minor === needDomGTPre.minor &&\n            c.semver.patch === needDomGTPre.patch) {\n          needDomGTPre = false\n        }\n      }\n      if (c.operator === '>' || c.operator === '>=') {\n        higher = higherGT(gt, c, options)\n        if (higher === c && higher !== gt) {\n          return false\n        }\n      } else if (gt.operator === '>=' && !satisfies(gt.semver, String(c), options)) {\n        return false\n      }\n    }\n    if (lt) {\n      if (needDomLTPre) {\n        if (c.semver.prerelease && c.semver.prerelease.length &&\n            c.semver.major === needDomLTPre.major &&\n            c.semver.minor === needDomLTPre.minor &&\n            c.semver.patch === needDomLTPre.patch) {\n          needDomLTPre = false\n        }\n      }\n      if (c.operator === '<' || c.operator === '<=') {\n        lower = lowerLT(lt, c, options)\n        if (lower === c && lower !== lt) {\n          return false\n        }\n      } else if (lt.operator === '<=' && !satisfies(lt.semver, String(c), options)) {\n        return false\n      }\n    }\n    if (!c.operator && (lt || gt) && gtltComp !== 0) {\n      return false\n    }\n  }\n\n  // if there was a < or >, and nothing in the dom, then must be false\n  // UNLESS it was limited by another range in the other direction.\n  // Eg, >1.0.0 <1.0.1 is still a subset of <2.0.0\n  if (gt && hasDomLT && !lt && gtltComp !== 0) {\n    return false\n  }\n\n  if (lt && hasDomGT && !gt && gtltComp !== 0) {\n    return false\n  }\n\n  // we needed a prerelease range in a specific tuple, but didn't get one\n  // then this isn't a subset.  eg >=1.2.3-pre is not a subset of >=1.0.0,\n  // because it includes prereleases in the 1.2.3 tuple\n  if (needDomGTPre || needDomLTPre) {\n    return false\n  }\n\n  return true\n}\n\n// >=1.2.3 is lower than >1.2.3\nconst higherGT = (a, b, options) => {\n  if (!a) {\n    return b\n  }\n  const comp = compare(a.semver, b.semver, options)\n  return comp > 0 ? a\n    : comp < 0 ? b\n    : b.operator === '>' && a.operator === '>=' ? b\n    : a\n}\n\n// <=1.2.3 is higher than <1.2.3\nconst lowerLT = (a, b, options) => {\n  if (!a) {\n    return b\n  }\n  const comp = compare(a.semver, b.semver, options)\n  return comp < 0 ? a\n    : comp > 0 ? b\n    : b.operator === '<' && a.operator === '<=' ? b\n    : a\n}\n\nmodule.exports = subset\n","'use strict'\n\nconst Range = require('../classes/range')\n\n// Mostly just for testing and legacy API reasons\nconst toComparators = (range, options) =>\n  new Range(range, options).set\n    .map(comp => comp.map(c => c.value).join(' ').trim().split(' '))\n\nmodule.exports = toComparators\n","'use strict'\n\nconst Range = require('../classes/range')\nconst validRange = (range, options) => {\n  try {\n    // Return '*' instead of '' so that truthiness works.\n    // This will throw if it's invalid anyway\n    return new Range(range, options).range || '*'\n  } catch (er) {\n    return null\n  }\n}\nmodule.exports = validRange\n","module.exports = require('./lib/tunnel');\n","'use strict';\n\nvar net = require('net');\nvar tls = require('tls');\nvar http = require('http');\nvar https = require('https');\nvar events = require('events');\nvar assert = require('assert');\nvar util = require('util');\n\n\nexports.httpOverHttp = httpOverHttp;\nexports.httpsOverHttp = httpsOverHttp;\nexports.httpOverHttps = httpOverHttps;\nexports.httpsOverHttps = httpsOverHttps;\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  return agent;\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  return agent;\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this;\n  self.options = options || {};\n  self.proxyOptions = self.options.proxy || {};\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;\n  self.requests = [];\n  self.sockets = [];\n\n  self.on('free', function onFree(socket, host, port, localAddress) {\n    var options = toOptions(host, port, localAddress);\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i];\n      if (pending.host === options.host && pending.port === options.port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1);\n        pending.request.onSocket(socket);\n        return;\n      }\n    }\n    socket.destroy();\n    self.removeSocket(socket);\n  });\n}\nutil.inherits(TunnelingAgent, events.EventEmitter);\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {\n  var self = this;\n  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push(options);\n    return;\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket(options, function(socket) {\n    socket.on('free', onFree);\n    socket.on('close', onCloseOrRemove);\n    socket.on('agentRemove', onCloseOrRemove);\n    req.onSocket(socket);\n\n    function onFree() {\n      self.emit('free', socket, options);\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket);\n      socket.removeListener('free', onFree);\n      socket.removeListener('close', onCloseOrRemove);\n      socket.removeListener('agentRemove', onCloseOrRemove);\n    }\n  });\n};\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this;\n  var placeholder = {};\n  self.sockets.push(placeholder);\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, {\n    method: 'CONNECT',\n    path: options.host + ':' + options.port,\n    agent: false,\n    headers: {\n      host: options.host + ':' + options.port\n    }\n  });\n  if (options.localAddress) {\n    connectOptions.localAddress = options.localAddress;\n  }\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {};\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64');\n  }\n\n  debug('making CONNECT request');\n  var connectReq = self.request(connectOptions);\n  connectReq.useChunkedEncodingByDefault = false; // for v0.6\n  connectReq.once('response', onResponse); // for v0.6\n  connectReq.once('upgrade', onUpgrade);   // for v0.6\n  connectReq.once('connect', onConnect);   // for v0.7 or later\n  connectReq.once('error', onError);\n  connectReq.end();\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true;\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head);\n    });\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners();\n    socket.removeAllListeners();\n\n    if (res.statusCode !== 200) {\n      debug('tunneling socket could not be established, statusCode=%d',\n        res.statusCode);\n      socket.destroy();\n      var error = new Error('tunneling socket could not be established, ' +\n        'statusCode=' + res.statusCode);\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    if (head.length > 0) {\n      debug('got illegal response body from proxy');\n      socket.destroy();\n      var error = new Error('got illegal response body from proxy');\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    debug('tunneling connection has established');\n    self.sockets[self.sockets.indexOf(placeholder)] = socket;\n    return cb(socket);\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners();\n\n    debug('tunneling socket could not be established, cause=%s\\n',\n          cause.message, cause.stack);\n    var error = new Error('tunneling socket could not be established, ' +\n                          'cause=' + cause.message);\n    error.code = 'ECONNRESET';\n    options.request.emit('error', error);\n    self.removeSocket(placeholder);\n  }\n};\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) {\n    return;\n  }\n  this.sockets.splice(pos, 1);\n\n  var pending = this.requests.shift();\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket);\n    });\n  }\n};\n\nfunction createSecureSocket(options, cb) {\n  var self = this;\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    var hostHeader = options.request.getHeader('host');\n    var tlsOptions = mergeOptions({}, self.options, {\n      socket: socket,\n      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host\n    });\n\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, tlsOptions);\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket;\n    cb(secureSocket);\n  });\n}\n\n\nfunction toOptions(host, port, localAddress) {\n  if (typeof host === 'string') { // since v0.10\n    return {\n      host: host,\n      port: port,\n      localAddress: localAddress\n    };\n  }\n  return host; // for v0.11 or later\n}\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i];\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides);\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j];\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k];\n        }\n      }\n    }\n  }\n  return target;\n}\n\n\nvar debug;\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments);\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0];\n    } else {\n      args.unshift('TUNNEL:');\n    }\n    console.error.apply(console, args);\n  }\n} else {\n  debug = function() {};\n}\nexports.debug = debug; // for test\n","'use strict'\n\nconst Client = require('./lib/client')\nconst Dispatcher = require('./lib/dispatcher')\nconst errors = require('./lib/core/errors')\nconst Pool = require('./lib/pool')\nconst BalancedPool = require('./lib/balanced-pool')\nconst Agent = require('./lib/agent')\nconst util = require('./lib/core/util')\nconst { InvalidArgumentError } = errors\nconst api = require('./lib/api')\nconst buildConnector = require('./lib/core/connect')\nconst MockClient = require('./lib/mock/mock-client')\nconst MockAgent = require('./lib/mock/mock-agent')\nconst MockPool = require('./lib/mock/mock-pool')\nconst mockErrors = require('./lib/mock/mock-errors')\nconst ProxyAgent = require('./lib/proxy-agent')\nconst RetryHandler = require('./lib/handler/RetryHandler')\nconst { getGlobalDispatcher, setGlobalDispatcher } = require('./lib/global')\nconst DecoratorHandler = require('./lib/handler/DecoratorHandler')\nconst RedirectHandler = require('./lib/handler/RedirectHandler')\nconst createRedirectInterceptor = require('./lib/interceptor/redirectInterceptor')\n\nlet hasCrypto\ntry {\n  require('crypto')\n  hasCrypto = true\n} catch {\n  hasCrypto = false\n}\n\nObject.assign(Dispatcher.prototype, api)\n\nmodule.exports.Dispatcher = Dispatcher\nmodule.exports.Client = Client\nmodule.exports.Pool = Pool\nmodule.exports.BalancedPool = BalancedPool\nmodule.exports.Agent = Agent\nmodule.exports.ProxyAgent = ProxyAgent\nmodule.exports.RetryHandler = RetryHandler\n\nmodule.exports.DecoratorHandler = DecoratorHandler\nmodule.exports.RedirectHandler = RedirectHandler\nmodule.exports.createRedirectInterceptor = createRedirectInterceptor\n\nmodule.exports.buildConnector = buildConnector\nmodule.exports.errors = errors\n\nfunction makeDispatcher (fn) {\n  return (url, opts, handler) => {\n    if (typeof opts === 'function') {\n      handler = opts\n      opts = null\n    }\n\n    if (!url || (typeof url !== 'string' && typeof url !== 'object' && !(url instanceof URL))) {\n      throw new InvalidArgumentError('invalid url')\n    }\n\n    if (opts != null && typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (opts && opts.path != null) {\n      if (typeof opts.path !== 'string') {\n        throw new InvalidArgumentError('invalid opts.path')\n      }\n\n      let path = opts.path\n      if (!opts.path.startsWith('/')) {\n        path = `/${path}`\n      }\n\n      url = new URL(util.parseOrigin(url).origin + path)\n    } else {\n      if (!opts) {\n        opts = typeof url === 'object' ? url : {}\n      }\n\n      url = util.parseURL(url)\n    }\n\n    const { agent, dispatcher = getGlobalDispatcher() } = opts\n\n    if (agent) {\n      throw new InvalidArgumentError('unsupported opts.agent. Did you mean opts.client?')\n    }\n\n    return fn.call(dispatcher, {\n      ...opts,\n      origin: url.origin,\n      path: url.search ? `${url.pathname}${url.search}` : url.pathname,\n      method: opts.method || (opts.body ? 'PUT' : 'GET')\n    }, handler)\n  }\n}\n\nmodule.exports.setGlobalDispatcher = setGlobalDispatcher\nmodule.exports.getGlobalDispatcher = getGlobalDispatcher\n\nif (util.nodeMajor > 16 || (util.nodeMajor === 16 && util.nodeMinor >= 8)) {\n  let fetchImpl = null\n  module.exports.fetch = async function fetch (resource) {\n    if (!fetchImpl) {\n      fetchImpl = require('./lib/fetch').fetch\n    }\n\n    try {\n      return await fetchImpl(...arguments)\n    } catch (err) {\n      if (typeof err === 'object') {\n        Error.captureStackTrace(err, this)\n      }\n\n      throw err\n    }\n  }\n  module.exports.Headers = require('./lib/fetch/headers').Headers\n  module.exports.Response = require('./lib/fetch/response').Response\n  module.exports.Request = require('./lib/fetch/request').Request\n  module.exports.FormData = require('./lib/fetch/formdata').FormData\n  module.exports.File = require('./lib/fetch/file').File\n  module.exports.FileReader = require('./lib/fileapi/filereader').FileReader\n\n  const { setGlobalOrigin, getGlobalOrigin } = require('./lib/fetch/global')\n\n  module.exports.setGlobalOrigin = setGlobalOrigin\n  module.exports.getGlobalOrigin = getGlobalOrigin\n\n  const { CacheStorage } = require('./lib/cache/cachestorage')\n  const { kConstruct } = require('./lib/cache/symbols')\n\n  // Cache & CacheStorage are tightly coupled with fetch. Even if it may run\n  // in an older version of Node, it doesn't have any use without fetch.\n  module.exports.caches = new CacheStorage(kConstruct)\n}\n\nif (util.nodeMajor >= 16) {\n  const { deleteCookie, getCookies, getSetCookies, setCookie } = require('./lib/cookies')\n\n  module.exports.deleteCookie = deleteCookie\n  module.exports.getCookies = getCookies\n  module.exports.getSetCookies = getSetCookies\n  module.exports.setCookie = setCookie\n\n  const { parseMIMEType, serializeAMimeType } = require('./lib/fetch/dataURL')\n\n  module.exports.parseMIMEType = parseMIMEType\n  module.exports.serializeAMimeType = serializeAMimeType\n}\n\nif (util.nodeMajor >= 18 && hasCrypto) {\n  const { WebSocket } = require('./lib/websocket/websocket')\n\n  module.exports.WebSocket = WebSocket\n}\n\nmodule.exports.request = makeDispatcher(api.request)\nmodule.exports.stream = makeDispatcher(api.stream)\nmodule.exports.pipeline = makeDispatcher(api.pipeline)\nmodule.exports.connect = makeDispatcher(api.connect)\nmodule.exports.upgrade = makeDispatcher(api.upgrade)\n\nmodule.exports.MockClient = MockClient\nmodule.exports.MockPool = MockPool\nmodule.exports.MockAgent = MockAgent\nmodule.exports.mockErrors = mockErrors\n","'use strict'\n\nconst { InvalidArgumentError } = require('./core/errors')\nconst { kClients, kRunning, kClose, kDestroy, kDispatch, kInterceptors } = require('./core/symbols')\nconst DispatcherBase = require('./dispatcher-base')\nconst Pool = require('./pool')\nconst Client = require('./client')\nconst util = require('./core/util')\nconst createRedirectInterceptor = require('./interceptor/redirectInterceptor')\nconst { WeakRef, FinalizationRegistry } = require('./compat/dispatcher-weakref')()\n\nconst kOnConnect = Symbol('onConnect')\nconst kOnDisconnect = Symbol('onDisconnect')\nconst kOnConnectionError = Symbol('onConnectionError')\nconst kMaxRedirections = Symbol('maxRedirections')\nconst kOnDrain = Symbol('onDrain')\nconst kFactory = Symbol('factory')\nconst kFinalizer = Symbol('finalizer')\nconst kOptions = Symbol('options')\n\nfunction defaultFactory (origin, opts) {\n  return opts && opts.connections === 1\n    ? new Client(origin, opts)\n    : new Pool(origin, opts)\n}\n\nclass Agent extends DispatcherBase {\n  constructor ({ factory = defaultFactory, maxRedirections = 0, connect, ...options } = {}) {\n    super()\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (!Number.isInteger(maxRedirections) || maxRedirections < 0) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    if (connect && typeof connect !== 'function') {\n      connect = { ...connect }\n    }\n\n    this[kInterceptors] = options.interceptors && options.interceptors.Agent && Array.isArray(options.interceptors.Agent)\n      ? options.interceptors.Agent\n      : [createRedirectInterceptor({ maxRedirections })]\n\n    this[kOptions] = { ...util.deepClone(options), connect }\n    this[kOptions].interceptors = options.interceptors\n      ? { ...options.interceptors }\n      : undefined\n    this[kMaxRedirections] = maxRedirections\n    this[kFactory] = factory\n    this[kClients] = new Map()\n    this[kFinalizer] = new FinalizationRegistry(/* istanbul ignore next: gc is undeterministic */ key => {\n      const ref = this[kClients].get(key)\n      if (ref !== undefined && ref.deref() === undefined) {\n        this[kClients].delete(key)\n      }\n    })\n\n    const agent = this\n\n    this[kOnDrain] = (origin, targets) => {\n      agent.emit('drain', origin, [agent, ...targets])\n    }\n\n    this[kOnConnect] = (origin, targets) => {\n      agent.emit('connect', origin, [agent, ...targets])\n    }\n\n    this[kOnDisconnect] = (origin, targets, err) => {\n      agent.emit('disconnect', origin, [agent, ...targets], err)\n    }\n\n    this[kOnConnectionError] = (origin, targets, err) => {\n      agent.emit('connectionError', origin, [agent, ...targets], err)\n    }\n  }\n\n  get [kRunning] () {\n    let ret = 0\n    for (const ref of this[kClients].values()) {\n      const client = ref.deref()\n      /* istanbul ignore next: gc is undeterministic */\n      if (client) {\n        ret += client[kRunning]\n      }\n    }\n    return ret\n  }\n\n  [kDispatch] (opts, handler) {\n    let key\n    if (opts.origin && (typeof opts.origin === 'string' || opts.origin instanceof URL)) {\n      key = String(opts.origin)\n    } else {\n      throw new InvalidArgumentError('opts.origin must be a non-empty string or URL.')\n    }\n\n    const ref = this[kClients].get(key)\n\n    let dispatcher = ref ? ref.deref() : null\n    if (!dispatcher) {\n      dispatcher = this[kFactory](opts.origin, this[kOptions])\n        .on('drain', this[kOnDrain])\n        .on('connect', this[kOnConnect])\n        .on('disconnect', this[kOnDisconnect])\n        .on('connectionError', this[kOnConnectionError])\n\n      this[kClients].set(key, new WeakRef(dispatcher))\n      this[kFinalizer].register(dispatcher, key)\n    }\n\n    return dispatcher.dispatch(opts, handler)\n  }\n\n  async [kClose] () {\n    const closePromises = []\n    for (const ref of this[kClients].values()) {\n      const client = ref.deref()\n      /* istanbul ignore else: gc is undeterministic */\n      if (client) {\n        closePromises.push(client.close())\n      }\n    }\n\n    await Promise.all(closePromises)\n  }\n\n  async [kDestroy] (err) {\n    const destroyPromises = []\n    for (const ref of this[kClients].values()) {\n      const client = ref.deref()\n      /* istanbul ignore else: gc is undeterministic */\n      if (client) {\n        destroyPromises.push(client.destroy(err))\n      }\n    }\n\n    await Promise.all(destroyPromises)\n  }\n}\n\nmodule.exports = Agent\n","const { addAbortListener } = require('../core/util')\nconst { RequestAbortedError } = require('../core/errors')\n\nconst kListener = Symbol('kListener')\nconst kSignal = Symbol('kSignal')\n\nfunction abort (self) {\n  if (self.abort) {\n    self.abort()\n  } else {\n    self.onError(new RequestAbortedError())\n  }\n}\n\nfunction addSignal (self, signal) {\n  self[kSignal] = null\n  self[kListener] = null\n\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    abort(self)\n    return\n  }\n\n  self[kSignal] = signal\n  self[kListener] = () => {\n    abort(self)\n  }\n\n  addAbortListener(self[kSignal], self[kListener])\n}\n\nfunction removeSignal (self) {\n  if (!self[kSignal]) {\n    return\n  }\n\n  if ('removeEventListener' in self[kSignal]) {\n    self[kSignal].removeEventListener('abort', self[kListener])\n  } else {\n    self[kSignal].removeListener('abort', self[kListener])\n  }\n\n  self[kSignal] = null\n  self[kListener] = null\n}\n\nmodule.exports = {\n  addSignal,\n  removeSignal\n}\n","'use strict'\n\nconst { AsyncResource } = require('async_hooks')\nconst { InvalidArgumentError, RequestAbortedError, SocketError } = require('../core/errors')\nconst util = require('../core/util')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass ConnectHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    const { signal, opaque, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    super('UNDICI_CONNECT')\n\n    this.opaque = opaque || null\n    this.responseHeaders = responseHeaders || null\n    this.callback = callback\n    this.abort = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders () {\n    throw new SocketError('bad connect', null)\n  }\n\n  onUpgrade (statusCode, rawHeaders, socket) {\n    const { callback, opaque, context } = this\n\n    removeSignal(this)\n\n    this.callback = null\n\n    let headers = rawHeaders\n    // Indicates is an HTTP2Session\n    if (headers != null) {\n      headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n    }\n\n    this.runInAsyncScope(callback, null, null, {\n      statusCode,\n      headers,\n      socket,\n      opaque,\n      context\n    })\n  }\n\n  onError (err) {\n    const { callback, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n  }\n}\n\nfunction connect (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      connect.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    const connectHandler = new ConnectHandler(opts, callback)\n    this.dispatch({ ...opts, method: 'CONNECT' }, connectHandler)\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = connect\n","'use strict'\n\nconst {\n  Readable,\n  Duplex,\n  PassThrough\n} = require('stream')\nconst {\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { AsyncResource } = require('async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\nconst assert = require('assert')\n\nconst kResume = Symbol('resume')\n\nclass PipelineRequest extends Readable {\n  constructor () {\n    super({ autoDestroy: true })\n\n    this[kResume] = null\n  }\n\n  _read () {\n    const { [kResume]: resume } = this\n\n    if (resume) {\n      this[kResume] = null\n      resume()\n    }\n  }\n\n  _destroy (err, callback) {\n    this._read()\n\n    callback(err)\n  }\n}\n\nclass PipelineResponse extends Readable {\n  constructor (resume) {\n    super({ autoDestroy: true })\n    this[kResume] = resume\n  }\n\n  _read () {\n    this[kResume]()\n  }\n\n  _destroy (err, callback) {\n    if (!err && !this._readableState.endEmitted) {\n      err = new RequestAbortedError()\n    }\n\n    callback(err)\n  }\n}\n\nclass PipelineHandler extends AsyncResource {\n  constructor (opts, handler) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof handler !== 'function') {\n      throw new InvalidArgumentError('invalid handler')\n    }\n\n    const { signal, method, opaque, onInfo, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    if (method === 'CONNECT') {\n      throw new InvalidArgumentError('invalid method')\n    }\n\n    if (onInfo && typeof onInfo !== 'function') {\n      throw new InvalidArgumentError('invalid onInfo callback')\n    }\n\n    super('UNDICI_PIPELINE')\n\n    this.opaque = opaque || null\n    this.responseHeaders = responseHeaders || null\n    this.handler = handler\n    this.abort = null\n    this.context = null\n    this.onInfo = onInfo || null\n\n    this.req = new PipelineRequest().on('error', util.nop)\n\n    this.ret = new Duplex({\n      readableObjectMode: opts.objectMode,\n      autoDestroy: true,\n      read: () => {\n        const { body } = this\n\n        if (body && body.resume) {\n          body.resume()\n        }\n      },\n      write: (chunk, encoding, callback) => {\n        const { req } = this\n\n        if (req.push(chunk, encoding) || req._readableState.destroyed) {\n          callback()\n        } else {\n          req[kResume] = callback\n        }\n      },\n      destroy: (err, callback) => {\n        const { body, req, res, ret, abort } = this\n\n        if (!err && !ret._readableState.endEmitted) {\n          err = new RequestAbortedError()\n        }\n\n        if (abort && err) {\n          abort()\n        }\n\n        util.destroy(body, err)\n        util.destroy(req, err)\n        util.destroy(res, err)\n\n        removeSignal(this)\n\n        callback(err)\n      }\n    }).on('prefinish', () => {\n      const { req } = this\n\n      // Node < 15 does not call _final in same tick.\n      req.push(null)\n    })\n\n    this.res = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    const { ret, res } = this\n\n    assert(!res, 'pipeline cannot be retried')\n\n    if (ret.destroyed) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume) {\n    const { opaque, handler, context } = this\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    this.res = new PipelineResponse(resume)\n\n    let body\n    try {\n      this.handler = null\n      const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n      body = this.runInAsyncScope(handler, null, {\n        statusCode,\n        headers,\n        opaque,\n        body: this.res,\n        context\n      })\n    } catch (err) {\n      this.res.on('error', util.nop)\n      throw err\n    }\n\n    if (!body || typeof body.on !== 'function') {\n      throw new InvalidReturnValueError('expected Readable')\n    }\n\n    body\n      .on('data', (chunk) => {\n        const { ret, body } = this\n\n        if (!ret.push(chunk) && body.pause) {\n          body.pause()\n        }\n      })\n      .on('error', (err) => {\n        const { ret } = this\n\n        util.destroy(ret, err)\n      })\n      .on('end', () => {\n        const { ret } = this\n\n        ret.push(null)\n      })\n      .on('close', () => {\n        const { ret } = this\n\n        if (!ret._readableState.ended) {\n          util.destroy(ret, new RequestAbortedError())\n        }\n      })\n\n    this.body = body\n  }\n\n  onData (chunk) {\n    const { res } = this\n    return res.push(chunk)\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n    res.push(null)\n  }\n\n  onError (err) {\n    const { ret } = this\n    this.handler = null\n    util.destroy(ret, err)\n  }\n}\n\nfunction pipeline (opts, handler) {\n  try {\n    const pipelineHandler = new PipelineHandler(opts, handler)\n    this.dispatch({ ...opts, body: pipelineHandler.req }, pipelineHandler)\n    return pipelineHandler.ret\n  } catch (err) {\n    return new PassThrough().destroy(err)\n  }\n}\n\nmodule.exports = pipeline\n","'use strict'\n\nconst Readable = require('./readable')\nconst {\n  InvalidArgumentError,\n  RequestAbortedError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { getResolveErrorBodyCallback } = require('./util')\nconst { AsyncResource } = require('async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass RequestHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError, highWaterMark } = opts\n\n    try {\n      if (typeof callback !== 'function') {\n        throw new InvalidArgumentError('invalid callback')\n      }\n\n      if (highWaterMark && (typeof highWaterMark !== 'number' || highWaterMark < 0)) {\n        throw new InvalidArgumentError('invalid highWaterMark')\n      }\n\n      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n      }\n\n      if (method === 'CONNECT') {\n        throw new InvalidArgumentError('invalid method')\n      }\n\n      if (onInfo && typeof onInfo !== 'function') {\n        throw new InvalidArgumentError('invalid onInfo callback')\n      }\n\n      super('UNDICI_REQUEST')\n    } catch (err) {\n      if (util.isStream(body)) {\n        util.destroy(body.on('error', util.nop), err)\n      }\n      throw err\n    }\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.callback = callback\n    this.res = null\n    this.abort = null\n    this.body = body\n    this.trailers = {}\n    this.context = null\n    this.onInfo = onInfo || null\n    this.throwOnError = throwOnError\n    this.highWaterMark = highWaterMark\n\n    if (util.isStream(body)) {\n      body.on('error', (err) => {\n        this.onError(err)\n      })\n    }\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const { callback, opaque, abort, context, responseHeaders, highWaterMark } = this\n\n    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers\n    const contentType = parsedHeaders['content-type']\n    const body = new Readable({ resume, abort, contentType, highWaterMark })\n\n    this.callback = null\n    this.res = body\n    if (callback !== null) {\n      if (this.throwOnError && statusCode >= 400) {\n        this.runInAsyncScope(getResolveErrorBodyCallback, null,\n          { callback, body, contentType, statusCode, statusMessage, headers }\n        )\n      } else {\n        this.runInAsyncScope(callback, null, null, {\n          statusCode,\n          headers,\n          trailers: this.trailers,\n          opaque,\n          body,\n          context\n        })\n      }\n    }\n  }\n\n  onData (chunk) {\n    const { res } = this\n    return res.push(chunk)\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n\n    removeSignal(this)\n\n    util.parseHeaders(trailers, this.trailers)\n\n    res.push(null)\n  }\n\n  onError (err) {\n    const { res, callback, body, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      // TODO: Does this need queueMicrotask?\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n\n    if (res) {\n      this.res = null\n      // Ensure all queued handlers are invoked before destroying res.\n      queueMicrotask(() => {\n        util.destroy(res, err)\n      })\n    }\n\n    if (body) {\n      this.body = null\n      util.destroy(body, err)\n    }\n  }\n}\n\nfunction request (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      request.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    this.dispatch(opts, new RequestHandler(opts, callback))\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = request\nmodule.exports.RequestHandler = RequestHandler\n","'use strict'\n\nconst { finished, PassThrough } = require('stream')\nconst {\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { getResolveErrorBodyCallback } = require('./util')\nconst { AsyncResource } = require('async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass StreamHandler extends AsyncResource {\n  constructor (opts, factory, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError } = opts\n\n    try {\n      if (typeof callback !== 'function') {\n        throw new InvalidArgumentError('invalid callback')\n      }\n\n      if (typeof factory !== 'function') {\n        throw new InvalidArgumentError('invalid factory')\n      }\n\n      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n      }\n\n      if (method === 'CONNECT') {\n        throw new InvalidArgumentError('invalid method')\n      }\n\n      if (onInfo && typeof onInfo !== 'function') {\n        throw new InvalidArgumentError('invalid onInfo callback')\n      }\n\n      super('UNDICI_STREAM')\n    } catch (err) {\n      if (util.isStream(body)) {\n        util.destroy(body.on('error', util.nop), err)\n      }\n      throw err\n    }\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.factory = factory\n    this.callback = callback\n    this.res = null\n    this.abort = null\n    this.context = null\n    this.trailers = null\n    this.body = body\n    this.onInfo = onInfo || null\n    this.throwOnError = throwOnError || false\n\n    if (util.isStream(body)) {\n      body.on('error', (err) => {\n        this.onError(err)\n      })\n    }\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const { factory, opaque, context, callback, responseHeaders } = this\n\n    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    this.factory = null\n\n    let res\n\n    if (this.throwOnError && statusCode >= 400) {\n      const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers\n      const contentType = parsedHeaders['content-type']\n      res = new PassThrough()\n\n      this.callback = null\n      this.runInAsyncScope(getResolveErrorBodyCallback, null,\n        { callback, body: res, contentType, statusCode, statusMessage, headers }\n      )\n    } else {\n      if (factory === null) {\n        return\n      }\n\n      res = this.runInAsyncScope(factory, null, {\n        statusCode,\n        headers,\n        opaque,\n        context\n      })\n\n      if (\n        !res ||\n        typeof res.write !== 'function' ||\n        typeof res.end !== 'function' ||\n        typeof res.on !== 'function'\n      ) {\n        throw new InvalidReturnValueError('expected Writable')\n      }\n\n      // TODO: Avoid finished. It registers an unnecessary amount of listeners.\n      finished(res, { readable: false }, (err) => {\n        const { callback, res, opaque, trailers, abort } = this\n\n        this.res = null\n        if (err || !res.readable) {\n          util.destroy(res, err)\n        }\n\n        this.callback = null\n        this.runInAsyncScope(callback, null, err || null, { opaque, trailers })\n\n        if (err) {\n          abort()\n        }\n      })\n    }\n\n    res.on('drain', resume)\n\n    this.res = res\n\n    const needDrain = res.writableNeedDrain !== undefined\n      ? res.writableNeedDrain\n      : res._writableState && res._writableState.needDrain\n\n    return needDrain !== true\n  }\n\n  onData (chunk) {\n    const { res } = this\n\n    return res ? res.write(chunk) : true\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n\n    removeSignal(this)\n\n    if (!res) {\n      return\n    }\n\n    this.trailers = util.parseHeaders(trailers)\n\n    res.end()\n  }\n\n  onError (err) {\n    const { res, callback, opaque, body } = this\n\n    removeSignal(this)\n\n    this.factory = null\n\n    if (res) {\n      this.res = null\n      util.destroy(res, err)\n    } else if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n\n    if (body) {\n      this.body = null\n      util.destroy(body, err)\n    }\n  }\n}\n\nfunction stream (opts, factory, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      stream.call(this, opts, factory, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    this.dispatch(opts, new StreamHandler(opts, factory, callback))\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = stream\n","'use strict'\n\nconst { InvalidArgumentError, RequestAbortedError, SocketError } = require('../core/errors')\nconst { AsyncResource } = require('async_hooks')\nconst util = require('../core/util')\nconst { addSignal, removeSignal } = require('./abort-signal')\nconst assert = require('assert')\n\nclass UpgradeHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    const { signal, opaque, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    super('UNDICI_UPGRADE')\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.callback = callback\n    this.abort = null\n    this.context = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = null\n  }\n\n  onHeaders () {\n    throw new SocketError('bad upgrade', null)\n  }\n\n  onUpgrade (statusCode, rawHeaders, socket) {\n    const { callback, opaque, context } = this\n\n    assert.strictEqual(statusCode, 101)\n\n    removeSignal(this)\n\n    this.callback = null\n    const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n    this.runInAsyncScope(callback, null, null, {\n      headers,\n      socket,\n      opaque,\n      context\n    })\n  }\n\n  onError (err) {\n    const { callback, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n  }\n}\n\nfunction upgrade (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      upgrade.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    const upgradeHandler = new UpgradeHandler(opts, callback)\n    this.dispatch({\n      ...opts,\n      method: opts.method || 'GET',\n      upgrade: opts.protocol || 'Websocket'\n    }, upgradeHandler)\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = upgrade\n","'use strict'\n\nmodule.exports.request = require('./api-request')\nmodule.exports.stream = require('./api-stream')\nmodule.exports.pipeline = require('./api-pipeline')\nmodule.exports.upgrade = require('./api-upgrade')\nmodule.exports.connect = require('./api-connect')\n","// Ported from https://github.com/nodejs/undici/pull/907\n\n'use strict'\n\nconst assert = require('assert')\nconst { Readable } = require('stream')\nconst { RequestAbortedError, NotSupportedError, InvalidArgumentError } = require('../core/errors')\nconst util = require('../core/util')\nconst { ReadableStreamFrom, toUSVString } = require('../core/util')\n\nlet Blob\n\nconst kConsume = Symbol('kConsume')\nconst kReading = Symbol('kReading')\nconst kBody = Symbol('kBody')\nconst kAbort = Symbol('abort')\nconst kContentType = Symbol('kContentType')\n\nconst noop = () => {}\n\nmodule.exports = class BodyReadable extends Readable {\n  constructor ({\n    resume,\n    abort,\n    contentType = '',\n    highWaterMark = 64 * 1024 // Same as nodejs fs streams.\n  }) {\n    super({\n      autoDestroy: true,\n      read: resume,\n      highWaterMark\n    })\n\n    this._readableState.dataEmitted = false\n\n    this[kAbort] = abort\n    this[kConsume] = null\n    this[kBody] = null\n    this[kContentType] = contentType\n\n    // Is stream being consumed through Readable API?\n    // This is an optimization so that we avoid checking\n    // for 'data' and 'readable' listeners in the hot path\n    // inside push().\n    this[kReading] = false\n  }\n\n  destroy (err) {\n    if (this.destroyed) {\n      // Node < 16\n      return this\n    }\n\n    if (!err && !this._readableState.endEmitted) {\n      err = new RequestAbortedError()\n    }\n\n    if (err) {\n      this[kAbort]()\n    }\n\n    return super.destroy(err)\n  }\n\n  emit (ev, ...args) {\n    if (ev === 'data') {\n      // Node < 16.7\n      this._readableState.dataEmitted = true\n    } else if (ev === 'error') {\n      // Node < 16\n      this._readableState.errorEmitted = true\n    }\n    return super.emit(ev, ...args)\n  }\n\n  on (ev, ...args) {\n    if (ev === 'data' || ev === 'readable') {\n      this[kReading] = true\n    }\n    return super.on(ev, ...args)\n  }\n\n  addListener (ev, ...args) {\n    return this.on(ev, ...args)\n  }\n\n  off (ev, ...args) {\n    const ret = super.off(ev, ...args)\n    if (ev === 'data' || ev === 'readable') {\n      this[kReading] = (\n        this.listenerCount('data') > 0 ||\n        this.listenerCount('readable') > 0\n      )\n    }\n    return ret\n  }\n\n  removeListener (ev, ...args) {\n    return this.off(ev, ...args)\n  }\n\n  push (chunk) {\n    if (this[kConsume] && chunk !== null && this.readableLength === 0) {\n      consumePush(this[kConsume], chunk)\n      return this[kReading] ? super.push(chunk) : true\n    }\n    return super.push(chunk)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-text\n  async text () {\n    return consume(this, 'text')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-json\n  async json () {\n    return consume(this, 'json')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-blob\n  async blob () {\n    return consume(this, 'blob')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-arraybuffer\n  async arrayBuffer () {\n    return consume(this, 'arrayBuffer')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-formdata\n  async formData () {\n    // TODO: Implement.\n    throw new NotSupportedError()\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-bodyused\n  get bodyUsed () {\n    return util.isDisturbed(this)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-body\n  get body () {\n    if (!this[kBody]) {\n      this[kBody] = ReadableStreamFrom(this)\n      if (this[kConsume]) {\n        // TODO: Is this the best way to force a lock?\n        this[kBody].getReader() // Ensure stream is locked.\n        assert(this[kBody].locked)\n      }\n    }\n    return this[kBody]\n  }\n\n  dump (opts) {\n    let limit = opts && Number.isFinite(opts.limit) ? opts.limit : 262144\n    const signal = opts && opts.signal\n\n    if (signal) {\n      try {\n        if (typeof signal !== 'object' || !('aborted' in signal)) {\n          throw new InvalidArgumentError('signal must be an AbortSignal')\n        }\n        util.throwIfAborted(signal)\n      } catch (err) {\n        return Promise.reject(err)\n      }\n    }\n\n    if (this.closed) {\n      return Promise.resolve(null)\n    }\n\n    return new Promise((resolve, reject) => {\n      const signalListenerCleanup = signal\n        ? util.addAbortListener(signal, () => {\n          this.destroy()\n        })\n        : noop\n\n      this\n        .on('close', function () {\n          signalListenerCleanup()\n          if (signal && signal.aborted) {\n            reject(signal.reason || Object.assign(new Error('The operation was aborted'), { name: 'AbortError' }))\n          } else {\n            resolve(null)\n          }\n        })\n        .on('error', noop)\n        .on('data', function (chunk) {\n          limit -= chunk.length\n          if (limit <= 0) {\n            this.destroy()\n          }\n        })\n        .resume()\n    })\n  }\n}\n\n// https://streams.spec.whatwg.org/#readablestream-locked\nfunction isLocked (self) {\n  // Consume is an implicit lock.\n  return (self[kBody] && self[kBody].locked === true) || self[kConsume]\n}\n\n// https://fetch.spec.whatwg.org/#body-unusable\nfunction isUnusable (self) {\n  return util.isDisturbed(self) || isLocked(self)\n}\n\nasync function consume (stream, type) {\n  if (isUnusable(stream)) {\n    throw new TypeError('unusable')\n  }\n\n  assert(!stream[kConsume])\n\n  return new Promise((resolve, reject) => {\n    stream[kConsume] = {\n      type,\n      stream,\n      resolve,\n      reject,\n      length: 0,\n      body: []\n    }\n\n    stream\n      .on('error', function (err) {\n        consumeFinish(this[kConsume], err)\n      })\n      .on('close', function () {\n        if (this[kConsume].body !== null) {\n          consumeFinish(this[kConsume], new RequestAbortedError())\n        }\n      })\n\n    process.nextTick(consumeStart, stream[kConsume])\n  })\n}\n\nfunction consumeStart (consume) {\n  if (consume.body === null) {\n    return\n  }\n\n  const { _readableState: state } = consume.stream\n\n  for (const chunk of state.buffer) {\n    consumePush(consume, chunk)\n  }\n\n  if (state.endEmitted) {\n    consumeEnd(this[kConsume])\n  } else {\n    consume.stream.on('end', function () {\n      consumeEnd(this[kConsume])\n    })\n  }\n\n  consume.stream.resume()\n\n  while (consume.stream.read() != null) {\n    // Loop\n  }\n}\n\nfunction consumeEnd (consume) {\n  const { type, body, resolve, stream, length } = consume\n\n  try {\n    if (type === 'text') {\n      resolve(toUSVString(Buffer.concat(body)))\n    } else if (type === 'json') {\n      resolve(JSON.parse(Buffer.concat(body)))\n    } else if (type === 'arrayBuffer') {\n      const dst = new Uint8Array(length)\n\n      let pos = 0\n      for (const buf of body) {\n        dst.set(buf, pos)\n        pos += buf.byteLength\n      }\n\n      resolve(dst.buffer)\n    } else if (type === 'blob') {\n      if (!Blob) {\n        Blob = require('buffer').Blob\n      }\n      resolve(new Blob(body, { type: stream[kContentType] }))\n    }\n\n    consumeFinish(consume)\n  } catch (err) {\n    stream.destroy(err)\n  }\n}\n\nfunction consumePush (consume, chunk) {\n  consume.length += chunk.length\n  consume.body.push(chunk)\n}\n\nfunction consumeFinish (consume, err) {\n  if (consume.body === null) {\n    return\n  }\n\n  if (err) {\n    consume.reject(err)\n  } else {\n    consume.resolve()\n  }\n\n  consume.type = null\n  consume.stream = null\n  consume.resolve = null\n  consume.reject = null\n  consume.length = 0\n  consume.body = null\n}\n","const assert = require('assert')\nconst {\n  ResponseStatusCodeError\n} = require('../core/errors')\nconst { toUSVString } = require('../core/util')\n\nasync function getResolveErrorBodyCallback ({ callback, body, contentType, statusCode, statusMessage, headers }) {\n  assert(body)\n\n  let chunks = []\n  let limit = 0\n\n  for await (const chunk of body) {\n    chunks.push(chunk)\n    limit += chunk.length\n    if (limit > 128 * 1024) {\n      chunks = null\n      break\n    }\n  }\n\n  if (statusCode === 204 || !contentType || !chunks) {\n    process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers))\n    return\n  }\n\n  try {\n    if (contentType.startsWith('application/json')) {\n      const payload = JSON.parse(toUSVString(Buffer.concat(chunks)))\n      process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers, payload))\n      return\n    }\n\n    if (contentType.startsWith('text/')) {\n      const payload = toUSVString(Buffer.concat(chunks))\n      process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers, payload))\n      return\n    }\n  } catch (err) {\n    // Process in a fallback if error\n  }\n\n  process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers))\n}\n\nmodule.exports = { getResolveErrorBodyCallback }\n","'use strict'\n\nconst {\n  BalancedPoolMissingUpstreamError,\n  InvalidArgumentError\n} = require('./core/errors')\nconst {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kRemoveClient,\n  kGetDispatcher\n} = require('./pool-base')\nconst Pool = require('./pool')\nconst { kUrl, kInterceptors } = require('./core/symbols')\nconst { parseOrigin } = require('./core/util')\nconst kFactory = Symbol('factory')\n\nconst kOptions = Symbol('options')\nconst kGreatestCommonDivisor = Symbol('kGreatestCommonDivisor')\nconst kCurrentWeight = Symbol('kCurrentWeight')\nconst kIndex = Symbol('kIndex')\nconst kWeight = Symbol('kWeight')\nconst kMaxWeightPerServer = Symbol('kMaxWeightPerServer')\nconst kErrorPenalty = Symbol('kErrorPenalty')\n\nfunction getGreatestCommonDivisor (a, b) {\n  if (b === 0) return a\n  return getGreatestCommonDivisor(b, a % b)\n}\n\nfunction defaultFactory (origin, opts) {\n  return new Pool(origin, opts)\n}\n\nclass BalancedPool extends PoolBase {\n  constructor (upstreams = [], { factory = defaultFactory, ...opts } = {}) {\n    super()\n\n    this[kOptions] = opts\n    this[kIndex] = -1\n    this[kCurrentWeight] = 0\n\n    this[kMaxWeightPerServer] = this[kOptions].maxWeightPerServer || 100\n    this[kErrorPenalty] = this[kOptions].errorPenalty || 15\n\n    if (!Array.isArray(upstreams)) {\n      upstreams = [upstreams]\n    }\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    this[kInterceptors] = opts.interceptors && opts.interceptors.BalancedPool && Array.isArray(opts.interceptors.BalancedPool)\n      ? opts.interceptors.BalancedPool\n      : []\n    this[kFactory] = factory\n\n    for (const upstream of upstreams) {\n      this.addUpstream(upstream)\n    }\n    this._updateBalancedPoolStats()\n  }\n\n  addUpstream (upstream) {\n    const upstreamOrigin = parseOrigin(upstream).origin\n\n    if (this[kClients].find((pool) => (\n      pool[kUrl].origin === upstreamOrigin &&\n      pool.closed !== true &&\n      pool.destroyed !== true\n    ))) {\n      return this\n    }\n    const pool = this[kFactory](upstreamOrigin, Object.assign({}, this[kOptions]))\n\n    this[kAddClient](pool)\n    pool.on('connect', () => {\n      pool[kWeight] = Math.min(this[kMaxWeightPerServer], pool[kWeight] + this[kErrorPenalty])\n    })\n\n    pool.on('connectionError', () => {\n      pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])\n      this._updateBalancedPoolStats()\n    })\n\n    pool.on('disconnect', (...args) => {\n      const err = args[2]\n      if (err && err.code === 'UND_ERR_SOCKET') {\n        // decrease the weight of the pool.\n        pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])\n        this._updateBalancedPoolStats()\n      }\n    })\n\n    for (const client of this[kClients]) {\n      client[kWeight] = this[kMaxWeightPerServer]\n    }\n\n    this._updateBalancedPoolStats()\n\n    return this\n  }\n\n  _updateBalancedPoolStats () {\n    this[kGreatestCommonDivisor] = this[kClients].map(p => p[kWeight]).reduce(getGreatestCommonDivisor, 0)\n  }\n\n  removeUpstream (upstream) {\n    const upstreamOrigin = parseOrigin(upstream).origin\n\n    const pool = this[kClients].find((pool) => (\n      pool[kUrl].origin === upstreamOrigin &&\n      pool.closed !== true &&\n      pool.destroyed !== true\n    ))\n\n    if (pool) {\n      this[kRemoveClient](pool)\n    }\n\n    return this\n  }\n\n  get upstreams () {\n    return this[kClients]\n      .filter(dispatcher => dispatcher.closed !== true && dispatcher.destroyed !== true)\n      .map((p) => p[kUrl].origin)\n  }\n\n  [kGetDispatcher] () {\n    // We validate that pools is greater than 0,\n    // otherwise we would have to wait until an upstream\n    // is added, which might never happen.\n    if (this[kClients].length === 0) {\n      throw new BalancedPoolMissingUpstreamError()\n    }\n\n    const dispatcher = this[kClients].find(dispatcher => (\n      !dispatcher[kNeedDrain] &&\n      dispatcher.closed !== true &&\n      dispatcher.destroyed !== true\n    ))\n\n    if (!dispatcher) {\n      return\n    }\n\n    const allClientsBusy = this[kClients].map(pool => pool[kNeedDrain]).reduce((a, b) => a && b, true)\n\n    if (allClientsBusy) {\n      return\n    }\n\n    let counter = 0\n\n    let maxWeightIndex = this[kClients].findIndex(pool => !pool[kNeedDrain])\n\n    while (counter++ < this[kClients].length) {\n      this[kIndex] = (this[kIndex] + 1) % this[kClients].length\n      const pool = this[kClients][this[kIndex]]\n\n      // find pool index with the largest weight\n      if (pool[kWeight] > this[kClients][maxWeightIndex][kWeight] && !pool[kNeedDrain]) {\n        maxWeightIndex = this[kIndex]\n      }\n\n      // decrease the current weight every `this[kClients].length`.\n      if (this[kIndex] === 0) {\n        // Set the current weight to the next lower weight.\n        this[kCurrentWeight] = this[kCurrentWeight] - this[kGreatestCommonDivisor]\n\n        if (this[kCurrentWeight] <= 0) {\n          this[kCurrentWeight] = this[kMaxWeightPerServer]\n        }\n      }\n      if (pool[kWeight] >= this[kCurrentWeight] && (!pool[kNeedDrain])) {\n        return pool\n      }\n    }\n\n    this[kCurrentWeight] = this[kClients][maxWeightIndex][kWeight]\n    this[kIndex] = maxWeightIndex\n    return this[kClients][maxWeightIndex]\n  }\n}\n\nmodule.exports = BalancedPool\n","'use strict'\n\nconst { kConstruct } = require('./symbols')\nconst { urlEquals, fieldValues: getFieldValues } = require('./util')\nconst { kEnumerableProperty, isDisturbed } = require('../core/util')\nconst { kHeadersList } = require('../core/symbols')\nconst { webidl } = require('../fetch/webidl')\nconst { Response, cloneResponse } = require('../fetch/response')\nconst { Request } = require('../fetch/request')\nconst { kState, kHeaders, kGuard, kRealm } = require('../fetch/symbols')\nconst { fetching } = require('../fetch/index')\nconst { urlIsHttpHttpsScheme, createDeferredPromise, readAllBytes } = require('../fetch/util')\nconst assert = require('assert')\nconst { getGlobalDispatcher } = require('../global')\n\n/**\n * @see https://w3c.github.io/ServiceWorker/#dfn-cache-batch-operation\n * @typedef {Object} CacheBatchOperation\n * @property {'delete' | 'put'} type\n * @property {any} request\n * @property {any} response\n * @property {import('../../types/cache').CacheQueryOptions} options\n */\n\n/**\n * @see https://w3c.github.io/ServiceWorker/#dfn-request-response-list\n * @typedef {[any, any][]} requestResponseList\n */\n\nclass Cache {\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-request-response-list\n   * @type {requestResponseList}\n   */\n  #relevantRequestResponseList\n\n  constructor () {\n    if (arguments[0] !== kConstruct) {\n      webidl.illegalConstructor()\n    }\n\n    this.#relevantRequestResponseList = arguments[1]\n  }\n\n  async match (request, options = {}) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.match' })\n\n    request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    const p = await this.matchAll(request, options)\n\n    if (p.length === 0) {\n      return\n    }\n\n    return p[0]\n  }\n\n  async matchAll (request = undefined, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    if (request !== undefined) request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    // 1.\n    let r = null\n\n    // 2.\n    if (request !== undefined) {\n      if (request instanceof Request) {\n        // 2.1.1\n        r = request[kState]\n\n        // 2.1.2\n        if (r.method !== 'GET' && !options.ignoreMethod) {\n          return []\n        }\n      } else if (typeof request === 'string') {\n        // 2.2.1\n        r = new Request(request)[kState]\n      }\n    }\n\n    // 5.\n    // 5.1\n    const responses = []\n\n    // 5.2\n    if (request === undefined) {\n      // 5.2.1\n      for (const requestResponse of this.#relevantRequestResponseList) {\n        responses.push(requestResponse[1])\n      }\n    } else { // 5.3\n      // 5.3.1\n      const requestResponses = this.#queryCache(r, options)\n\n      // 5.3.2\n      for (const requestResponse of requestResponses) {\n        responses.push(requestResponse[1])\n      }\n    }\n\n    // 5.4\n    // We don't implement CORs so we don't need to loop over the responses, yay!\n\n    // 5.5.1\n    const responseList = []\n\n    // 5.5.2\n    for (const response of responses) {\n      // 5.5.2.1\n      const responseObject = new Response(response.body?.source ?? null)\n      const body = responseObject[kState].body\n      responseObject[kState] = response\n      responseObject[kState].body = body\n      responseObject[kHeaders][kHeadersList] = response.headersList\n      responseObject[kHeaders][kGuard] = 'immutable'\n\n      responseList.push(responseObject)\n    }\n\n    // 6.\n    return Object.freeze(responseList)\n  }\n\n  async add (request) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.add' })\n\n    request = webidl.converters.RequestInfo(request)\n\n    // 1.\n    const requests = [request]\n\n    // 2.\n    const responseArrayPromise = this.addAll(requests)\n\n    // 3.\n    return await responseArrayPromise\n  }\n\n  async addAll (requests) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.addAll' })\n\n    requests = webidl.converters['sequence<RequestInfo>'](requests)\n\n    // 1.\n    const responsePromises = []\n\n    // 2.\n    const requestList = []\n\n    // 3.\n    for (const request of requests) {\n      if (typeof request === 'string') {\n        continue\n      }\n\n      // 3.1\n      const r = request[kState]\n\n      // 3.2\n      if (!urlIsHttpHttpsScheme(r.url) || r.method !== 'GET') {\n        throw webidl.errors.exception({\n          header: 'Cache.addAll',\n          message: 'Expected http/s scheme when method is not GET.'\n        })\n      }\n    }\n\n    // 4.\n    /** @type {ReturnType<typeof fetching>[]} */\n    const fetchControllers = []\n\n    // 5.\n    for (const request of requests) {\n      // 5.1\n      const r = new Request(request)[kState]\n\n      // 5.2\n      if (!urlIsHttpHttpsScheme(r.url)) {\n        throw webidl.errors.exception({\n          header: 'Cache.addAll',\n          message: 'Expected http/s scheme.'\n        })\n      }\n\n      // 5.4\n      r.initiator = 'fetch'\n      r.destination = 'subresource'\n\n      // 5.5\n      requestList.push(r)\n\n      // 5.6\n      const responsePromise = createDeferredPromise()\n\n      // 5.7\n      fetchControllers.push(fetching({\n        request: r,\n        dispatcher: getGlobalDispatcher(),\n        processResponse (response) {\n          // 1.\n          if (response.type === 'error' || response.status === 206 || response.status < 200 || response.status > 299) {\n            responsePromise.reject(webidl.errors.exception({\n              header: 'Cache.addAll',\n              message: 'Received an invalid status code or the request failed.'\n            }))\n          } else if (response.headersList.contains('vary')) { // 2.\n            // 2.1\n            const fieldValues = getFieldValues(response.headersList.get('vary'))\n\n            // 2.2\n            for (const fieldValue of fieldValues) {\n              // 2.2.1\n              if (fieldValue === '*') {\n                responsePromise.reject(webidl.errors.exception({\n                  header: 'Cache.addAll',\n                  message: 'invalid vary field value'\n                }))\n\n                for (const controller of fetchControllers) {\n                  controller.abort()\n                }\n\n                return\n              }\n            }\n          }\n        },\n        processResponseEndOfBody (response) {\n          // 1.\n          if (response.aborted) {\n            responsePromise.reject(new DOMException('aborted', 'AbortError'))\n            return\n          }\n\n          // 2.\n          responsePromise.resolve(response)\n        }\n      }))\n\n      // 5.8\n      responsePromises.push(responsePromise.promise)\n    }\n\n    // 6.\n    const p = Promise.all(responsePromises)\n\n    // 7.\n    const responses = await p\n\n    // 7.1\n    const operations = []\n\n    // 7.2\n    let index = 0\n\n    // 7.3\n    for (const response of responses) {\n      // 7.3.1\n      /** @type {CacheBatchOperation} */\n      const operation = {\n        type: 'put', // 7.3.2\n        request: requestList[index], // 7.3.3\n        response // 7.3.4\n      }\n\n      operations.push(operation) // 7.3.5\n\n      index++ // 7.3.6\n    }\n\n    // 7.5\n    const cacheJobPromise = createDeferredPromise()\n\n    // 7.6.1\n    let errorData = null\n\n    // 7.6.2\n    try {\n      this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    // 7.6.3\n    queueMicrotask(() => {\n      // 7.6.3.1\n      if (errorData === null) {\n        cacheJobPromise.resolve(undefined)\n      } else {\n        // 7.6.3.2\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    // 7.7\n    return cacheJobPromise.promise\n  }\n\n  async put (request, response) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 2, { header: 'Cache.put' })\n\n    request = webidl.converters.RequestInfo(request)\n    response = webidl.converters.Response(response)\n\n    // 1.\n    let innerRequest = null\n\n    // 2.\n    if (request instanceof Request) {\n      innerRequest = request[kState]\n    } else { // 3.\n      innerRequest = new Request(request)[kState]\n    }\n\n    // 4.\n    if (!urlIsHttpHttpsScheme(innerRequest.url) || innerRequest.method !== 'GET') {\n      throw webidl.errors.exception({\n        header: 'Cache.put',\n        message: 'Expected an http/s scheme when method is not GET'\n      })\n    }\n\n    // 5.\n    const innerResponse = response[kState]\n\n    // 6.\n    if (innerResponse.status === 206) {\n      throw webidl.errors.exception({\n        header: 'Cache.put',\n        message: 'Got 206 status'\n      })\n    }\n\n    // 7.\n    if (innerResponse.headersList.contains('vary')) {\n      // 7.1.\n      const fieldValues = getFieldValues(innerResponse.headersList.get('vary'))\n\n      // 7.2.\n      for (const fieldValue of fieldValues) {\n        // 7.2.1\n        if (fieldValue === '*') {\n          throw webidl.errors.exception({\n            header: 'Cache.put',\n            message: 'Got * vary field value'\n          })\n        }\n      }\n    }\n\n    // 8.\n    if (innerResponse.body && (isDisturbed(innerResponse.body.stream) || innerResponse.body.stream.locked)) {\n      throw webidl.errors.exception({\n        header: 'Cache.put',\n        message: 'Response body is locked or disturbed'\n      })\n    }\n\n    // 9.\n    const clonedResponse = cloneResponse(innerResponse)\n\n    // 10.\n    const bodyReadPromise = createDeferredPromise()\n\n    // 11.\n    if (innerResponse.body != null) {\n      // 11.1\n      const stream = innerResponse.body.stream\n\n      // 11.2\n      const reader = stream.getReader()\n\n      // 11.3\n      readAllBytes(reader).then(bodyReadPromise.resolve, bodyReadPromise.reject)\n    } else {\n      bodyReadPromise.resolve(undefined)\n    }\n\n    // 12.\n    /** @type {CacheBatchOperation[]} */\n    const operations = []\n\n    // 13.\n    /** @type {CacheBatchOperation} */\n    const operation = {\n      type: 'put', // 14.\n      request: innerRequest, // 15.\n      response: clonedResponse // 16.\n    }\n\n    // 17.\n    operations.push(operation)\n\n    // 19.\n    const bytes = await bodyReadPromise.promise\n\n    if (clonedResponse.body != null) {\n      clonedResponse.body.source = bytes\n    }\n\n    // 19.1\n    const cacheJobPromise = createDeferredPromise()\n\n    // 19.2.1\n    let errorData = null\n\n    // 19.2.2\n    try {\n      this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    // 19.2.3\n    queueMicrotask(() => {\n      // 19.2.3.1\n      if (errorData === null) {\n        cacheJobPromise.resolve()\n      } else { // 19.2.3.2\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    return cacheJobPromise.promise\n  }\n\n  async delete (request, options = {}) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.delete' })\n\n    request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    /**\n     * @type {Request}\n     */\n    let r = null\n\n    if (request instanceof Request) {\n      r = request[kState]\n\n      if (r.method !== 'GET' && !options.ignoreMethod) {\n        return false\n      }\n    } else {\n      assert(typeof request === 'string')\n\n      r = new Request(request)[kState]\n    }\n\n    /** @type {CacheBatchOperation[]} */\n    const operations = []\n\n    /** @type {CacheBatchOperation} */\n    const operation = {\n      type: 'delete',\n      request: r,\n      options\n    }\n\n    operations.push(operation)\n\n    const cacheJobPromise = createDeferredPromise()\n\n    let errorData = null\n    let requestResponses\n\n    try {\n      requestResponses = this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    queueMicrotask(() => {\n      if (errorData === null) {\n        cacheJobPromise.resolve(!!requestResponses?.length)\n      } else {\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    return cacheJobPromise.promise\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dom-cache-keys\n   * @param {any} request\n   * @param {import('../../types/cache').CacheQueryOptions} options\n   * @returns {readonly Request[]}\n   */\n  async keys (request = undefined, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    if (request !== undefined) request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    // 1.\n    let r = null\n\n    // 2.\n    if (request !== undefined) {\n      // 2.1\n      if (request instanceof Request) {\n        // 2.1.1\n        r = request[kState]\n\n        // 2.1.2\n        if (r.method !== 'GET' && !options.ignoreMethod) {\n          return []\n        }\n      } else if (typeof request === 'string') { // 2.2\n        r = new Request(request)[kState]\n      }\n    }\n\n    // 4.\n    const promise = createDeferredPromise()\n\n    // 5.\n    // 5.1\n    const requests = []\n\n    // 5.2\n    if (request === undefined) {\n      // 5.2.1\n      for (const requestResponse of this.#relevantRequestResponseList) {\n        // 5.2.1.1\n        requests.push(requestResponse[0])\n      }\n    } else { // 5.3\n      // 5.3.1\n      const requestResponses = this.#queryCache(r, options)\n\n      // 5.3.2\n      for (const requestResponse of requestResponses) {\n        // 5.3.2.1\n        requests.push(requestResponse[0])\n      }\n    }\n\n    // 5.4\n    queueMicrotask(() => {\n      // 5.4.1\n      const requestList = []\n\n      // 5.4.2\n      for (const request of requests) {\n        const requestObject = new Request('https://a')\n        requestObject[kState] = request\n        requestObject[kHeaders][kHeadersList] = request.headersList\n        requestObject[kHeaders][kGuard] = 'immutable'\n        requestObject[kRealm] = request.client\n\n        // 5.4.2.1\n        requestList.push(requestObject)\n      }\n\n      // 5.4.3\n      promise.resolve(Object.freeze(requestList))\n    })\n\n    return promise.promise\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#batch-cache-operations-algorithm\n   * @param {CacheBatchOperation[]} operations\n   * @returns {requestResponseList}\n   */\n  #batchCacheOperations (operations) {\n    // 1.\n    const cache = this.#relevantRequestResponseList\n\n    // 2.\n    const backupCache = [...cache]\n\n    // 3.\n    const addedItems = []\n\n    // 4.1\n    const resultList = []\n\n    try {\n      // 4.2\n      for (const operation of operations) {\n        // 4.2.1\n        if (operation.type !== 'delete' && operation.type !== 'put') {\n          throw webidl.errors.exception({\n            header: 'Cache.#batchCacheOperations',\n            message: 'operation type does not match \"delete\" or \"put\"'\n          })\n        }\n\n        // 4.2.2\n        if (operation.type === 'delete' && operation.response != null) {\n          throw webidl.errors.exception({\n            header: 'Cache.#batchCacheOperations',\n            message: 'delete operation should not have an associated response'\n          })\n        }\n\n        // 4.2.3\n        if (this.#queryCache(operation.request, operation.options, addedItems).length) {\n          throw new DOMException('???', 'InvalidStateError')\n        }\n\n        // 4.2.4\n        let requestResponses\n\n        // 4.2.5\n        if (operation.type === 'delete') {\n          // 4.2.5.1\n          requestResponses = this.#queryCache(operation.request, operation.options)\n\n          // TODO: the spec is wrong, this is needed to pass WPTs\n          if (requestResponses.length === 0) {\n            return []\n          }\n\n          // 4.2.5.2\n          for (const requestResponse of requestResponses) {\n            const idx = cache.indexOf(requestResponse)\n            assert(idx !== -1)\n\n            // 4.2.5.2.1\n            cache.splice(idx, 1)\n          }\n        } else if (operation.type === 'put') { // 4.2.6\n          // 4.2.6.1\n          if (operation.response == null) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'put operation should have an associated response'\n            })\n          }\n\n          // 4.2.6.2\n          const r = operation.request\n\n          // 4.2.6.3\n          if (!urlIsHttpHttpsScheme(r.url)) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'expected http or https scheme'\n            })\n          }\n\n          // 4.2.6.4\n          if (r.method !== 'GET') {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'not get method'\n            })\n          }\n\n          // 4.2.6.5\n          if (operation.options != null) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'options must not be defined'\n            })\n          }\n\n          // 4.2.6.6\n          requestResponses = this.#queryCache(operation.request)\n\n          // 4.2.6.7\n          for (const requestResponse of requestResponses) {\n            const idx = cache.indexOf(requestResponse)\n            assert(idx !== -1)\n\n            // 4.2.6.7.1\n            cache.splice(idx, 1)\n          }\n\n          // 4.2.6.8\n          cache.push([operation.request, operation.response])\n\n          // 4.2.6.10\n          addedItems.push([operation.request, operation.response])\n        }\n\n        // 4.2.7\n        resultList.push([operation.request, operation.response])\n      }\n\n      // 4.3\n      return resultList\n    } catch (e) { // 5.\n      // 5.1\n      this.#relevantRequestResponseList.length = 0\n\n      // 5.2\n      this.#relevantRequestResponseList = backupCache\n\n      // 5.3\n      throw e\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#query-cache\n   * @param {any} requestQuery\n   * @param {import('../../types/cache').CacheQueryOptions} options\n   * @param {requestResponseList} targetStorage\n   * @returns {requestResponseList}\n   */\n  #queryCache (requestQuery, options, targetStorage) {\n    /** @type {requestResponseList} */\n    const resultList = []\n\n    const storage = targetStorage ?? this.#relevantRequestResponseList\n\n    for (const requestResponse of storage) {\n      const [cachedRequest, cachedResponse] = requestResponse\n      if (this.#requestMatchesCachedItem(requestQuery, cachedRequest, cachedResponse, options)) {\n        resultList.push(requestResponse)\n      }\n    }\n\n    return resultList\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#request-matches-cached-item-algorithm\n   * @param {any} requestQuery\n   * @param {any} request\n   * @param {any | null} response\n   * @param {import('../../types/cache').CacheQueryOptions | undefined} options\n   * @returns {boolean}\n   */\n  #requestMatchesCachedItem (requestQuery, request, response = null, options) {\n    // if (options?.ignoreMethod === false && request.method === 'GET') {\n    //   return false\n    // }\n\n    const queryURL = new URL(requestQuery.url)\n\n    const cachedURL = new URL(request.url)\n\n    if (options?.ignoreSearch) {\n      cachedURL.search = ''\n\n      queryURL.search = ''\n    }\n\n    if (!urlEquals(queryURL, cachedURL, true)) {\n      return false\n    }\n\n    if (\n      response == null ||\n      options?.ignoreVary ||\n      !response.headersList.contains('vary')\n    ) {\n      return true\n    }\n\n    const fieldValues = getFieldValues(response.headersList.get('vary'))\n\n    for (const fieldValue of fieldValues) {\n      if (fieldValue === '*') {\n        return false\n      }\n\n      const requestValue = request.headersList.get(fieldValue)\n      const queryValue = requestQuery.headersList.get(fieldValue)\n\n      // If one has the header and the other doesn't, or one has\n      // a different value than the other, return false\n      if (requestValue !== queryValue) {\n        return false\n      }\n    }\n\n    return true\n  }\n}\n\nObject.defineProperties(Cache.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'Cache',\n    configurable: true\n  },\n  match: kEnumerableProperty,\n  matchAll: kEnumerableProperty,\n  add: kEnumerableProperty,\n  addAll: kEnumerableProperty,\n  put: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  keys: kEnumerableProperty\n})\n\nconst cacheQueryOptionConverters = [\n  {\n    key: 'ignoreSearch',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'ignoreMethod',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'ignoreVary',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  }\n]\n\nwebidl.converters.CacheQueryOptions = webidl.dictionaryConverter(cacheQueryOptionConverters)\n\nwebidl.converters.MultiCacheQueryOptions = webidl.dictionaryConverter([\n  ...cacheQueryOptionConverters,\n  {\n    key: 'cacheName',\n    converter: webidl.converters.DOMString\n  }\n])\n\nwebidl.converters.Response = webidl.interfaceConverter(Response)\n\nwebidl.converters['sequence<RequestInfo>'] = webidl.sequenceConverter(\n  webidl.converters.RequestInfo\n)\n\nmodule.exports = {\n  Cache\n}\n","'use strict'\n\nconst { kConstruct } = require('./symbols')\nconst { Cache } = require('./cache')\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../core/util')\n\nclass CacheStorage {\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-name-to-cache-map\n   * @type {Map<string, import('./cache').requestResponseList}\n   */\n  #caches = new Map()\n\n  constructor () {\n    if (arguments[0] !== kConstruct) {\n      webidl.illegalConstructor()\n    }\n  }\n\n  async match (request, options = {}) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.match' })\n\n    request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.MultiCacheQueryOptions(options)\n\n    // 1.\n    if (options.cacheName != null) {\n      // 1.1.1.1\n      if (this.#caches.has(options.cacheName)) {\n        // 1.1.1.1.1\n        const cacheList = this.#caches.get(options.cacheName)\n        const cache = new Cache(kConstruct, cacheList)\n\n        return await cache.match(request, options)\n      }\n    } else { // 2.\n      // 2.2\n      for (const cacheList of this.#caches.values()) {\n        const cache = new Cache(kConstruct, cacheList)\n\n        // 2.2.1.2\n        const response = await cache.match(request, options)\n\n        if (response !== undefined) {\n          return response\n        }\n      }\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-has\n   * @param {string} cacheName\n   * @returns {Promise<boolean>}\n   */\n  async has (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.has' })\n\n    cacheName = webidl.converters.DOMString(cacheName)\n\n    // 2.1.1\n    // 2.2\n    return this.#caches.has(cacheName)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dom-cachestorage-open\n   * @param {string} cacheName\n   * @returns {Promise<Cache>}\n   */\n  async open (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.open' })\n\n    cacheName = webidl.converters.DOMString(cacheName)\n\n    // 2.1\n    if (this.#caches.has(cacheName)) {\n      // await caches.open('v1') !== await caches.open('v1')\n\n      // 2.1.1\n      const cache = this.#caches.get(cacheName)\n\n      // 2.1.1.1\n      return new Cache(kConstruct, cache)\n    }\n\n    // 2.2\n    const cache = []\n\n    // 2.3\n    this.#caches.set(cacheName, cache)\n\n    // 2.4\n    return new Cache(kConstruct, cache)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-delete\n   * @param {string} cacheName\n   * @returns {Promise<boolean>}\n   */\n  async delete (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.delete' })\n\n    cacheName = webidl.converters.DOMString(cacheName)\n\n    return this.#caches.delete(cacheName)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-keys\n   * @returns {string[]}\n   */\n  async keys () {\n    webidl.brandCheck(this, CacheStorage)\n\n    // 2.1\n    const keys = this.#caches.keys()\n\n    // 2.2\n    return [...keys]\n  }\n}\n\nObject.defineProperties(CacheStorage.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'CacheStorage',\n    configurable: true\n  },\n  match: kEnumerableProperty,\n  has: kEnumerableProperty,\n  open: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  keys: kEnumerableProperty\n})\n\nmodule.exports = {\n  CacheStorage\n}\n","'use strict'\n\nmodule.exports = {\n  kConstruct: require('../core/symbols').kConstruct\n}\n","'use strict'\n\nconst assert = require('assert')\nconst { URLSerializer } = require('../fetch/dataURL')\nconst { isValidHeaderName } = require('../fetch/util')\n\n/**\n * @see https://url.spec.whatwg.org/#concept-url-equals\n * @param {URL} A\n * @param {URL} B\n * @param {boolean | undefined} excludeFragment\n * @returns {boolean}\n */\nfunction urlEquals (A, B, excludeFragment = false) {\n  const serializedA = URLSerializer(A, excludeFragment)\n\n  const serializedB = URLSerializer(B, excludeFragment)\n\n  return serializedA === serializedB\n}\n\n/**\n * @see https://github.com/chromium/chromium/blob/694d20d134cb553d8d89e5500b9148012b1ba299/content/browser/cache_storage/cache_storage_cache.cc#L260-L262\n * @param {string} header\n */\nfunction fieldValues (header) {\n  assert(header !== null)\n\n  const values = []\n\n  for (let value of header.split(',')) {\n    value = value.trim()\n\n    if (!value.length) {\n      continue\n    } else if (!isValidHeaderName(value)) {\n      continue\n    }\n\n    values.push(value)\n  }\n\n  return values\n}\n\nmodule.exports = {\n  urlEquals,\n  fieldValues\n}\n","// @ts-check\n\n'use strict'\n\n/* global WebAssembly */\n\nconst assert = require('assert')\nconst net = require('net')\nconst http = require('http')\nconst { pipeline } = require('stream')\nconst util = require('./core/util')\nconst timers = require('./timers')\nconst Request = require('./core/request')\nconst DispatcherBase = require('./dispatcher-base')\nconst {\n  RequestContentLengthMismatchError,\n  ResponseContentLengthMismatchError,\n  InvalidArgumentError,\n  RequestAbortedError,\n  HeadersTimeoutError,\n  HeadersOverflowError,\n  SocketError,\n  InformationalError,\n  BodyTimeoutError,\n  HTTPParserError,\n  ResponseExceededMaxSizeError,\n  ClientDestroyedError\n} = require('./core/errors')\nconst buildConnector = require('./core/connect')\nconst {\n  kUrl,\n  kReset,\n  kServerName,\n  kClient,\n  kBusy,\n  kParser,\n  kConnect,\n  kBlocking,\n  kResuming,\n  kRunning,\n  kPending,\n  kSize,\n  kWriting,\n  kQueue,\n  kConnected,\n  kConnecting,\n  kNeedDrain,\n  kNoRef,\n  kKeepAliveDefaultTimeout,\n  kHostHeader,\n  kPendingIdx,\n  kRunningIdx,\n  kError,\n  kPipelining,\n  kSocket,\n  kKeepAliveTimeoutValue,\n  kMaxHeadersSize,\n  kKeepAliveMaxTimeout,\n  kKeepAliveTimeoutThreshold,\n  kHeadersTimeout,\n  kBodyTimeout,\n  kStrictContentLength,\n  kConnector,\n  kMaxRedirections,\n  kMaxRequests,\n  kCounter,\n  kClose,\n  kDestroy,\n  kDispatch,\n  kInterceptors,\n  kLocalAddress,\n  kMaxResponseSize,\n  kHTTPConnVersion,\n  // HTTP2\n  kHost,\n  kHTTP2Session,\n  kHTTP2SessionState,\n  kHTTP2BuildRequest,\n  kHTTP2CopyHeaders,\n  kHTTP1BuildRequest\n} = require('./core/symbols')\n\n/** @type {import('http2')} */\nlet http2\ntry {\n  http2 = require('http2')\n} catch {\n  // @ts-ignore\n  http2 = { constants: {} }\n}\n\nconst {\n  constants: {\n    HTTP2_HEADER_AUTHORITY,\n    HTTP2_HEADER_METHOD,\n    HTTP2_HEADER_PATH,\n    HTTP2_HEADER_SCHEME,\n    HTTP2_HEADER_CONTENT_LENGTH,\n    HTTP2_HEADER_EXPECT,\n    HTTP2_HEADER_STATUS\n  }\n} = http2\n\n// Experimental\nlet h2ExperimentalWarned = false\n\nconst FastBuffer = Buffer[Symbol.species]\n\nconst kClosedResolve = Symbol('kClosedResolve')\n\nconst channels = {}\n\ntry {\n  const diagnosticsChannel = require('diagnostics_channel')\n  channels.sendHeaders = diagnosticsChannel.channel('undici:client:sendHeaders')\n  channels.beforeConnect = diagnosticsChannel.channel('undici:client:beforeConnect')\n  channels.connectError = diagnosticsChannel.channel('undici:client:connectError')\n  channels.connected = diagnosticsChannel.channel('undici:client:connected')\n} catch {\n  channels.sendHeaders = { hasSubscribers: false }\n  channels.beforeConnect = { hasSubscribers: false }\n  channels.connectError = { hasSubscribers: false }\n  channels.connected = { hasSubscribers: false }\n}\n\n/**\n * @type {import('../types/client').default}\n */\nclass Client extends DispatcherBase {\n  /**\n   *\n   * @param {string|URL} url\n   * @param {import('../types/client').Client.Options} options\n   */\n  constructor (url, {\n    interceptors,\n    maxHeaderSize,\n    headersTimeout,\n    socketTimeout,\n    requestTimeout,\n    connectTimeout,\n    bodyTimeout,\n    idleTimeout,\n    keepAlive,\n    keepAliveTimeout,\n    maxKeepAliveTimeout,\n    keepAliveMaxTimeout,\n    keepAliveTimeoutThreshold,\n    socketPath,\n    pipelining,\n    tls,\n    strictContentLength,\n    maxCachedSessions,\n    maxRedirections,\n    connect,\n    maxRequestsPerClient,\n    localAddress,\n    maxResponseSize,\n    autoSelectFamily,\n    autoSelectFamilyAttemptTimeout,\n    // h2\n    allowH2,\n    maxConcurrentStreams\n  } = {}) {\n    super()\n\n    if (keepAlive !== undefined) {\n      throw new InvalidArgumentError('unsupported keepAlive, use pipelining=0 instead')\n    }\n\n    if (socketTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported socketTimeout, use headersTimeout & bodyTimeout instead')\n    }\n\n    if (requestTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported requestTimeout, use headersTimeout & bodyTimeout instead')\n    }\n\n    if (idleTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported idleTimeout, use keepAliveTimeout instead')\n    }\n\n    if (maxKeepAliveTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported maxKeepAliveTimeout, use keepAliveMaxTimeout instead')\n    }\n\n    if (maxHeaderSize != null && !Number.isFinite(maxHeaderSize)) {\n      throw new InvalidArgumentError('invalid maxHeaderSize')\n    }\n\n    if (socketPath != null && typeof socketPath !== 'string') {\n      throw new InvalidArgumentError('invalid socketPath')\n    }\n\n    if (connectTimeout != null && (!Number.isFinite(connectTimeout) || connectTimeout < 0)) {\n      throw new InvalidArgumentError('invalid connectTimeout')\n    }\n\n    if (keepAliveTimeout != null && (!Number.isFinite(keepAliveTimeout) || keepAliveTimeout <= 0)) {\n      throw new InvalidArgumentError('invalid keepAliveTimeout')\n    }\n\n    if (keepAliveMaxTimeout != null && (!Number.isFinite(keepAliveMaxTimeout) || keepAliveMaxTimeout <= 0)) {\n      throw new InvalidArgumentError('invalid keepAliveMaxTimeout')\n    }\n\n    if (keepAliveTimeoutThreshold != null && !Number.isFinite(keepAliveTimeoutThreshold)) {\n      throw new InvalidArgumentError('invalid keepAliveTimeoutThreshold')\n    }\n\n    if (headersTimeout != null && (!Number.isInteger(headersTimeout) || headersTimeout < 0)) {\n      throw new InvalidArgumentError('headersTimeout must be a positive integer or zero')\n    }\n\n    if (bodyTimeout != null && (!Number.isInteger(bodyTimeout) || bodyTimeout < 0)) {\n      throw new InvalidArgumentError('bodyTimeout must be a positive integer or zero')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    if (maxRequestsPerClient != null && (!Number.isInteger(maxRequestsPerClient) || maxRequestsPerClient < 0)) {\n      throw new InvalidArgumentError('maxRequestsPerClient must be a positive number')\n    }\n\n    if (localAddress != null && (typeof localAddress !== 'string' || net.isIP(localAddress) === 0)) {\n      throw new InvalidArgumentError('localAddress must be valid string IP address')\n    }\n\n    if (maxResponseSize != null && (!Number.isInteger(maxResponseSize) || maxResponseSize < -1)) {\n      throw new InvalidArgumentError('maxResponseSize must be a positive number')\n    }\n\n    if (\n      autoSelectFamilyAttemptTimeout != null &&\n      (!Number.isInteger(autoSelectFamilyAttemptTimeout) || autoSelectFamilyAttemptTimeout < -1)\n    ) {\n      throw new InvalidArgumentError('autoSelectFamilyAttemptTimeout must be a positive number')\n    }\n\n    // h2\n    if (allowH2 != null && typeof allowH2 !== 'boolean') {\n      throw new InvalidArgumentError('allowH2 must be a valid boolean value')\n    }\n\n    if (maxConcurrentStreams != null && (typeof maxConcurrentStreams !== 'number' || maxConcurrentStreams < 1)) {\n      throw new InvalidArgumentError('maxConcurrentStreams must be a possitive integer, greater than 0')\n    }\n\n    if (typeof connect !== 'function') {\n      connect = buildConnector({\n        ...tls,\n        maxCachedSessions,\n        allowH2,\n        socketPath,\n        timeout: connectTimeout,\n        ...(util.nodeHasAutoSelectFamily && autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),\n        ...connect\n      })\n    }\n\n    this[kInterceptors] = interceptors && interceptors.Client && Array.isArray(interceptors.Client)\n      ? interceptors.Client\n      : [createRedirectInterceptor({ maxRedirections })]\n    this[kUrl] = util.parseOrigin(url)\n    this[kConnector] = connect\n    this[kSocket] = null\n    this[kPipelining] = pipelining != null ? pipelining : 1\n    this[kMaxHeadersSize] = maxHeaderSize || http.maxHeaderSize\n    this[kKeepAliveDefaultTimeout] = keepAliveTimeout == null ? 4e3 : keepAliveTimeout\n    this[kKeepAliveMaxTimeout] = keepAliveMaxTimeout == null ? 600e3 : keepAliveMaxTimeout\n    this[kKeepAliveTimeoutThreshold] = keepAliveTimeoutThreshold == null ? 1e3 : keepAliveTimeoutThreshold\n    this[kKeepAliveTimeoutValue] = this[kKeepAliveDefaultTimeout]\n    this[kServerName] = null\n    this[kLocalAddress] = localAddress != null ? localAddress : null\n    this[kResuming] = 0 // 0, idle, 1, scheduled, 2 resuming\n    this[kNeedDrain] = 0 // 0, idle, 1, scheduled, 2 resuming\n    this[kHostHeader] = `host: ${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}\\r\\n`\n    this[kBodyTimeout] = bodyTimeout != null ? bodyTimeout : 300e3\n    this[kHeadersTimeout] = headersTimeout != null ? headersTimeout : 300e3\n    this[kStrictContentLength] = strictContentLength == null ? true : strictContentLength\n    this[kMaxRedirections] = maxRedirections\n    this[kMaxRequests] = maxRequestsPerClient\n    this[kClosedResolve] = null\n    this[kMaxResponseSize] = maxResponseSize > -1 ? maxResponseSize : -1\n    this[kHTTPConnVersion] = 'h1'\n\n    // HTTP/2\n    this[kHTTP2Session] = null\n    this[kHTTP2SessionState] = !allowH2\n      ? null\n      : {\n        // streams: null, // Fixed queue of streams - For future support of `push`\n          openStreams: 0, // Keep track of them to decide wether or not unref the session\n          maxConcurrentStreams: maxConcurrentStreams != null ? maxConcurrentStreams : 100 // Max peerConcurrentStreams for a Node h2 server\n        }\n    this[kHost] = `${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}`\n\n    // kQueue is built up of 3 sections separated by\n    // the kRunningIdx and kPendingIdx indices.\n    // |   complete   |   running   |   pending   |\n    //                ^ kRunningIdx ^ kPendingIdx ^ kQueue.length\n    // kRunningIdx points to the first running element.\n    // kPendingIdx points to the first pending element.\n    // This implements a fast queue with an amortized\n    // time of O(1).\n\n    this[kQueue] = []\n    this[kRunningIdx] = 0\n    this[kPendingIdx] = 0\n  }\n\n  get pipelining () {\n    return this[kPipelining]\n  }\n\n  set pipelining (value) {\n    this[kPipelining] = value\n    resume(this, true)\n  }\n\n  get [kPending] () {\n    return this[kQueue].length - this[kPendingIdx]\n  }\n\n  get [kRunning] () {\n    return this[kPendingIdx] - this[kRunningIdx]\n  }\n\n  get [kSize] () {\n    return this[kQueue].length - this[kRunningIdx]\n  }\n\n  get [kConnected] () {\n    return !!this[kSocket] && !this[kConnecting] && !this[kSocket].destroyed\n  }\n\n  get [kBusy] () {\n    const socket = this[kSocket]\n    return (\n      (socket && (socket[kReset] || socket[kWriting] || socket[kBlocking])) ||\n      (this[kSize] >= (this[kPipelining] || 1)) ||\n      this[kPending] > 0\n    )\n  }\n\n  /* istanbul ignore: only used for test */\n  [kConnect] (cb) {\n    connect(this)\n    this.once('connect', cb)\n  }\n\n  [kDispatch] (opts, handler) {\n    const origin = opts.origin || this[kUrl].origin\n\n    const request = this[kHTTPConnVersion] === 'h2'\n      ? Request[kHTTP2BuildRequest](origin, opts, handler)\n      : Request[kHTTP1BuildRequest](origin, opts, handler)\n\n    this[kQueue].push(request)\n    if (this[kResuming]) {\n      // Do nothing.\n    } else if (util.bodyLength(request.body) == null && util.isIterable(request.body)) {\n      // Wait a tick in case stream/iterator is ended in the same tick.\n      this[kResuming] = 1\n      process.nextTick(resume, this)\n    } else {\n      resume(this, true)\n    }\n\n    if (this[kResuming] && this[kNeedDrain] !== 2 && this[kBusy]) {\n      this[kNeedDrain] = 2\n    }\n\n    return this[kNeedDrain] < 2\n  }\n\n  async [kClose] () {\n    // TODO: for H2 we need to gracefully flush the remaining enqueued\n    // request and close each stream.\n    return new Promise((resolve) => {\n      if (!this[kSize]) {\n        resolve(null)\n      } else {\n        this[kClosedResolve] = resolve\n      }\n    })\n  }\n\n  async [kDestroy] (err) {\n    return new Promise((resolve) => {\n      const requests = this[kQueue].splice(this[kPendingIdx])\n      for (let i = 0; i < requests.length; i++) {\n        const request = requests[i]\n        errorRequest(this, request, err)\n      }\n\n      const callback = () => {\n        if (this[kClosedResolve]) {\n          // TODO (fix): Should we error here with ClientDestroyedError?\n          this[kClosedResolve]()\n          this[kClosedResolve] = null\n        }\n        resolve()\n      }\n\n      if (this[kHTTP2Session] != null) {\n        util.destroy(this[kHTTP2Session], err)\n        this[kHTTP2Session] = null\n        this[kHTTP2SessionState] = null\n      }\n\n      if (!this[kSocket]) {\n        queueMicrotask(callback)\n      } else {\n        util.destroy(this[kSocket].on('close', callback), err)\n      }\n\n      resume(this)\n    })\n  }\n}\n\nfunction onHttp2SessionError (err) {\n  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')\n\n  this[kSocket][kError] = err\n\n  onError(this[kClient], err)\n}\n\nfunction onHttp2FrameError (type, code, id) {\n  const err = new InformationalError(`HTTP/2: \"frameError\" received - type ${type}, code ${code}`)\n\n  if (id === 0) {\n    this[kSocket][kError] = err\n    onError(this[kClient], err)\n  }\n}\n\nfunction onHttp2SessionEnd () {\n  util.destroy(this, new SocketError('other side closed'))\n  util.destroy(this[kSocket], new SocketError('other side closed'))\n}\n\nfunction onHTTP2GoAway (code) {\n  const client = this[kClient]\n  const err = new InformationalError(`HTTP/2: \"GOAWAY\" frame received with code ${code}`)\n  client[kSocket] = null\n  client[kHTTP2Session] = null\n\n  if (client.destroyed) {\n    assert(this[kPending] === 0)\n\n    // Fail entire queue.\n    const requests = client[kQueue].splice(client[kRunningIdx])\n    for (let i = 0; i < requests.length; i++) {\n      const request = requests[i]\n      errorRequest(this, request, err)\n    }\n  } else if (client[kRunning] > 0) {\n    // Fail head of pipeline.\n    const request = client[kQueue][client[kRunningIdx]]\n    client[kQueue][client[kRunningIdx]++] = null\n\n    errorRequest(client, request, err)\n  }\n\n  client[kPendingIdx] = client[kRunningIdx]\n\n  assert(client[kRunning] === 0)\n\n  client.emit('disconnect',\n    client[kUrl],\n    [client],\n    err\n  )\n\n  resume(client)\n}\n\nconst constants = require('./llhttp/constants')\nconst createRedirectInterceptor = require('./interceptor/redirectInterceptor')\nconst EMPTY_BUF = Buffer.alloc(0)\n\nasync function lazyllhttp () {\n  const llhttpWasmData = process.env.JEST_WORKER_ID ? require('./llhttp/llhttp-wasm.js') : undefined\n\n  let mod\n  try {\n    mod = await WebAssembly.compile(Buffer.from(require('./llhttp/llhttp_simd-wasm.js'), 'base64'))\n  } catch (e) {\n    /* istanbul ignore next */\n\n    // We could check if the error was caused by the simd option not\n    // being enabled, but the occurring of this other error\n    // * https://github.com/emscripten-core/emscripten/issues/11495\n    // got me to remove that check to avoid breaking Node 12.\n    mod = await WebAssembly.compile(Buffer.from(llhttpWasmData || require('./llhttp/llhttp-wasm.js'), 'base64'))\n  }\n\n  return await WebAssembly.instantiate(mod, {\n    env: {\n      /* eslint-disable camelcase */\n\n      wasm_on_url: (p, at, len) => {\n        /* istanbul ignore next */\n        return 0\n      },\n      wasm_on_status: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onStatus(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_message_begin: (p) => {\n        assert.strictEqual(currentParser.ptr, p)\n        return currentParser.onMessageBegin() || 0\n      },\n      wasm_on_header_field: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onHeaderField(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_header_value: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onHeaderValue(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_headers_complete: (p, statusCode, upgrade, shouldKeepAlive) => {\n        assert.strictEqual(currentParser.ptr, p)\n        return currentParser.onHeadersComplete(statusCode, Boolean(upgrade), Boolean(shouldKeepAlive)) || 0\n      },\n      wasm_on_body: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onBody(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_message_complete: (p) => {\n        assert.strictEqual(currentParser.ptr, p)\n        return currentParser.onMessageComplete() || 0\n      }\n\n      /* eslint-enable camelcase */\n    }\n  })\n}\n\nlet llhttpInstance = null\nlet llhttpPromise = lazyllhttp()\nllhttpPromise.catch()\n\nlet currentParser = null\nlet currentBufferRef = null\nlet currentBufferSize = 0\nlet currentBufferPtr = null\n\nconst TIMEOUT_HEADERS = 1\nconst TIMEOUT_BODY = 2\nconst TIMEOUT_IDLE = 3\n\nclass Parser {\n  constructor (client, socket, { exports }) {\n    assert(Number.isFinite(client[kMaxHeadersSize]) && client[kMaxHeadersSize] > 0)\n\n    this.llhttp = exports\n    this.ptr = this.llhttp.llhttp_alloc(constants.TYPE.RESPONSE)\n    this.client = client\n    this.socket = socket\n    this.timeout = null\n    this.timeoutValue = null\n    this.timeoutType = null\n    this.statusCode = null\n    this.statusText = ''\n    this.upgrade = false\n    this.headers = []\n    this.headersSize = 0\n    this.headersMaxSize = client[kMaxHeadersSize]\n    this.shouldKeepAlive = false\n    this.paused = false\n    this.resume = this.resume.bind(this)\n\n    this.bytesRead = 0\n\n    this.keepAlive = ''\n    this.contentLength = ''\n    this.connection = ''\n    this.maxResponseSize = client[kMaxResponseSize]\n  }\n\n  setTimeout (value, type) {\n    this.timeoutType = type\n    if (value !== this.timeoutValue) {\n      timers.clearTimeout(this.timeout)\n      if (value) {\n        this.timeout = timers.setTimeout(onParserTimeout, value, this)\n        // istanbul ignore else: only for jest\n        if (this.timeout.unref) {\n          this.timeout.unref()\n        }\n      } else {\n        this.timeout = null\n      }\n      this.timeoutValue = value\n    } else if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n  }\n\n  resume () {\n    if (this.socket.destroyed || !this.paused) {\n      return\n    }\n\n    assert(this.ptr != null)\n    assert(currentParser == null)\n\n    this.llhttp.llhttp_resume(this.ptr)\n\n    assert(this.timeoutType === TIMEOUT_BODY)\n    if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    this.paused = false\n    this.execute(this.socket.read() || EMPTY_BUF) // Flush parser.\n    this.readMore()\n  }\n\n  readMore () {\n    while (!this.paused && this.ptr) {\n      const chunk = this.socket.read()\n      if (chunk === null) {\n        break\n      }\n      this.execute(chunk)\n    }\n  }\n\n  execute (data) {\n    assert(this.ptr != null)\n    assert(currentParser == null)\n    assert(!this.paused)\n\n    const { socket, llhttp } = this\n\n    if (data.length > currentBufferSize) {\n      if (currentBufferPtr) {\n        llhttp.free(currentBufferPtr)\n      }\n      currentBufferSize = Math.ceil(data.length / 4096) * 4096\n      currentBufferPtr = llhttp.malloc(currentBufferSize)\n    }\n\n    new Uint8Array(llhttp.memory.buffer, currentBufferPtr, currentBufferSize).set(data)\n\n    // Call `execute` on the wasm parser.\n    // We pass the `llhttp_parser` pointer address, the pointer address of buffer view data,\n    // and finally the length of bytes to parse.\n    // The return value is an error code or `constants.ERROR.OK`.\n    try {\n      let ret\n\n      try {\n        currentBufferRef = data\n        currentParser = this\n        ret = llhttp.llhttp_execute(this.ptr, currentBufferPtr, data.length)\n        /* eslint-disable-next-line no-useless-catch */\n      } catch (err) {\n        /* istanbul ignore next: difficult to make a test case for */\n        throw err\n      } finally {\n        currentParser = null\n        currentBufferRef = null\n      }\n\n      const offset = llhttp.llhttp_get_error_pos(this.ptr) - currentBufferPtr\n\n      if (ret === constants.ERROR.PAUSED_UPGRADE) {\n        this.onUpgrade(data.slice(offset))\n      } else if (ret === constants.ERROR.PAUSED) {\n        this.paused = true\n        socket.unshift(data.slice(offset))\n      } else if (ret !== constants.ERROR.OK) {\n        const ptr = llhttp.llhttp_get_error_reason(this.ptr)\n        let message = ''\n        /* istanbul ignore else: difficult to make a test case for */\n        if (ptr) {\n          const len = new Uint8Array(llhttp.memory.buffer, ptr).indexOf(0)\n          message =\n            'Response does not match the HTTP/1.1 protocol (' +\n            Buffer.from(llhttp.memory.buffer, ptr, len).toString() +\n            ')'\n        }\n        throw new HTTPParserError(message, constants.ERROR[ret], data.slice(offset))\n      }\n    } catch (err) {\n      util.destroy(socket, err)\n    }\n  }\n\n  destroy () {\n    assert(this.ptr != null)\n    assert(currentParser == null)\n\n    this.llhttp.llhttp_free(this.ptr)\n    this.ptr = null\n\n    timers.clearTimeout(this.timeout)\n    this.timeout = null\n    this.timeoutValue = null\n    this.timeoutType = null\n\n    this.paused = false\n  }\n\n  onStatus (buf) {\n    this.statusText = buf.toString()\n  }\n\n  onMessageBegin () {\n    const { socket, client } = this\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    if (!request) {\n      return -1\n    }\n  }\n\n  onHeaderField (buf) {\n    const len = this.headers.length\n\n    if ((len & 1) === 0) {\n      this.headers.push(buf)\n    } else {\n      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])\n    }\n\n    this.trackHeader(buf.length)\n  }\n\n  onHeaderValue (buf) {\n    let len = this.headers.length\n\n    if ((len & 1) === 1) {\n      this.headers.push(buf)\n      len += 1\n    } else {\n      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])\n    }\n\n    const key = this.headers[len - 2]\n    if (key.length === 10 && key.toString().toLowerCase() === 'keep-alive') {\n      this.keepAlive += buf.toString()\n    } else if (key.length === 10 && key.toString().toLowerCase() === 'connection') {\n      this.connection += buf.toString()\n    } else if (key.length === 14 && key.toString().toLowerCase() === 'content-length') {\n      this.contentLength += buf.toString()\n    }\n\n    this.trackHeader(buf.length)\n  }\n\n  trackHeader (len) {\n    this.headersSize += len\n    if (this.headersSize >= this.headersMaxSize) {\n      util.destroy(this.socket, new HeadersOverflowError())\n    }\n  }\n\n  onUpgrade (head) {\n    const { upgrade, client, socket, headers, statusCode } = this\n\n    assert(upgrade)\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    assert(!socket.destroyed)\n    assert(socket === client[kSocket])\n    assert(!this.paused)\n    assert(request.upgrade || request.method === 'CONNECT')\n\n    this.statusCode = null\n    this.statusText = ''\n    this.shouldKeepAlive = null\n\n    assert(this.headers.length % 2 === 0)\n    this.headers = []\n    this.headersSize = 0\n\n    socket.unshift(head)\n\n    socket[kParser].destroy()\n    socket[kParser] = null\n\n    socket[kClient] = null\n    socket[kError] = null\n    socket\n      .removeListener('error', onSocketError)\n      .removeListener('readable', onSocketReadable)\n      .removeListener('end', onSocketEnd)\n      .removeListener('close', onSocketClose)\n\n    client[kSocket] = null\n    client[kQueue][client[kRunningIdx]++] = null\n    client.emit('disconnect', client[kUrl], [client], new InformationalError('upgrade'))\n\n    try {\n      request.onUpgrade(statusCode, headers, socket)\n    } catch (err) {\n      util.destroy(socket, err)\n    }\n\n    resume(client)\n  }\n\n  onHeadersComplete (statusCode, upgrade, shouldKeepAlive) {\n    const { client, socket, headers, statusText } = this\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (!request) {\n      return -1\n    }\n\n    assert(!this.upgrade)\n    assert(this.statusCode < 200)\n\n    if (statusCode === 100) {\n      util.destroy(socket, new SocketError('bad response', util.getSocketInfo(socket)))\n      return -1\n    }\n\n    /* this can only happen if server is misbehaving */\n    if (upgrade && !request.upgrade) {\n      util.destroy(socket, new SocketError('bad upgrade', util.getSocketInfo(socket)))\n      return -1\n    }\n\n    assert.strictEqual(this.timeoutType, TIMEOUT_HEADERS)\n\n    this.statusCode = statusCode\n    this.shouldKeepAlive = (\n      shouldKeepAlive ||\n      // Override llhttp value which does not allow keepAlive for HEAD.\n      (request.method === 'HEAD' && !socket[kReset] && this.connection.toLowerCase() === 'keep-alive')\n    )\n\n    if (this.statusCode >= 200) {\n      const bodyTimeout = request.bodyTimeout != null\n        ? request.bodyTimeout\n        : client[kBodyTimeout]\n      this.setTimeout(bodyTimeout, TIMEOUT_BODY)\n    } else if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    if (request.method === 'CONNECT') {\n      assert(client[kRunning] === 1)\n      this.upgrade = true\n      return 2\n    }\n\n    if (upgrade) {\n      assert(client[kRunning] === 1)\n      this.upgrade = true\n      return 2\n    }\n\n    assert(this.headers.length % 2 === 0)\n    this.headers = []\n    this.headersSize = 0\n\n    if (this.shouldKeepAlive && client[kPipelining]) {\n      const keepAliveTimeout = this.keepAlive ? util.parseKeepAliveTimeout(this.keepAlive) : null\n\n      if (keepAliveTimeout != null) {\n        const timeout = Math.min(\n          keepAliveTimeout - client[kKeepAliveTimeoutThreshold],\n          client[kKeepAliveMaxTimeout]\n        )\n        if (timeout <= 0) {\n          socket[kReset] = true\n        } else {\n          client[kKeepAliveTimeoutValue] = timeout\n        }\n      } else {\n        client[kKeepAliveTimeoutValue] = client[kKeepAliveDefaultTimeout]\n      }\n    } else {\n      // Stop more requests from being dispatched.\n      socket[kReset] = true\n    }\n\n    const pause = request.onHeaders(statusCode, headers, this.resume, statusText) === false\n\n    if (request.aborted) {\n      return -1\n    }\n\n    if (request.method === 'HEAD') {\n      return 1\n    }\n\n    if (statusCode < 200) {\n      return 1\n    }\n\n    if (socket[kBlocking]) {\n      socket[kBlocking] = false\n      resume(client)\n    }\n\n    return pause ? constants.ERROR.PAUSED : 0\n  }\n\n  onBody (buf) {\n    const { client, socket, statusCode, maxResponseSize } = this\n\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    assert.strictEqual(this.timeoutType, TIMEOUT_BODY)\n    if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    assert(statusCode >= 200)\n\n    if (maxResponseSize > -1 && this.bytesRead + buf.length > maxResponseSize) {\n      util.destroy(socket, new ResponseExceededMaxSizeError())\n      return -1\n    }\n\n    this.bytesRead += buf.length\n\n    if (request.onData(buf) === false) {\n      return constants.ERROR.PAUSED\n    }\n  }\n\n  onMessageComplete () {\n    const { client, socket, statusCode, upgrade, headers, contentLength, bytesRead, shouldKeepAlive } = this\n\n    if (socket.destroyed && (!statusCode || shouldKeepAlive)) {\n      return -1\n    }\n\n    if (upgrade) {\n      return\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    assert(statusCode >= 100)\n\n    this.statusCode = null\n    this.statusText = ''\n    this.bytesRead = 0\n    this.contentLength = ''\n    this.keepAlive = ''\n    this.connection = ''\n\n    assert(this.headers.length % 2 === 0)\n    this.headers = []\n    this.headersSize = 0\n\n    if (statusCode < 200) {\n      return\n    }\n\n    /* istanbul ignore next: should be handled by llhttp? */\n    if (request.method !== 'HEAD' && contentLength && bytesRead !== parseInt(contentLength, 10)) {\n      util.destroy(socket, new ResponseContentLengthMismatchError())\n      return -1\n    }\n\n    request.onComplete(headers)\n\n    client[kQueue][client[kRunningIdx]++] = null\n\n    if (socket[kWriting]) {\n      assert.strictEqual(client[kRunning], 0)\n      // Response completed before request.\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (!shouldKeepAlive) {\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (socket[kReset] && client[kRunning] === 0) {\n      // Destroy socket once all requests have completed.\n      // The request at the tail of the pipeline is the one\n      // that requested reset and no further requests should\n      // have been queued since then.\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (client[kPipelining] === 1) {\n      // We must wait a full event loop cycle to reuse this socket to make sure\n      // that non-spec compliant servers are not closing the connection even if they\n      // said they won't.\n      setImmediate(resume, client)\n    } else {\n      resume(client)\n    }\n  }\n}\n\nfunction onParserTimeout (parser) {\n  const { socket, timeoutType, client } = parser\n\n  /* istanbul ignore else */\n  if (timeoutType === TIMEOUT_HEADERS) {\n    if (!socket[kWriting] || socket.writableNeedDrain || client[kRunning] > 1) {\n      assert(!parser.paused, 'cannot be paused while waiting for headers')\n      util.destroy(socket, new HeadersTimeoutError())\n    }\n  } else if (timeoutType === TIMEOUT_BODY) {\n    if (!parser.paused) {\n      util.destroy(socket, new BodyTimeoutError())\n    }\n  } else if (timeoutType === TIMEOUT_IDLE) {\n    assert(client[kRunning] === 0 && client[kKeepAliveTimeoutValue])\n    util.destroy(socket, new InformationalError('socket idle timeout'))\n  }\n}\n\nfunction onSocketReadable () {\n  const { [kParser]: parser } = this\n  if (parser) {\n    parser.readMore()\n  }\n}\n\nfunction onSocketError (err) {\n  const { [kClient]: client, [kParser]: parser } = this\n\n  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')\n\n  if (client[kHTTPConnVersion] !== 'h2') {\n    // On Mac OS, we get an ECONNRESET even if there is a full body to be forwarded\n    // to the user.\n    if (err.code === 'ECONNRESET' && parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so for as a valid response.\n      parser.onMessageComplete()\n      return\n    }\n  }\n\n  this[kError] = err\n\n  onError(this[kClient], err)\n}\n\nfunction onError (client, err) {\n  if (\n    client[kRunning] === 0 &&\n    err.code !== 'UND_ERR_INFO' &&\n    err.code !== 'UND_ERR_SOCKET'\n  ) {\n    // Error is not caused by running request and not a recoverable\n    // socket error.\n\n    assert(client[kPendingIdx] === client[kRunningIdx])\n\n    const requests = client[kQueue].splice(client[kRunningIdx])\n    for (let i = 0; i < requests.length; i++) {\n      const request = requests[i]\n      errorRequest(client, request, err)\n    }\n    assert(client[kSize] === 0)\n  }\n}\n\nfunction onSocketEnd () {\n  const { [kParser]: parser, [kClient]: client } = this\n\n  if (client[kHTTPConnVersion] !== 'h2') {\n    if (parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so far as a valid response.\n      parser.onMessageComplete()\n      return\n    }\n  }\n\n  util.destroy(this, new SocketError('other side closed', util.getSocketInfo(this)))\n}\n\nfunction onSocketClose () {\n  const { [kClient]: client, [kParser]: parser } = this\n\n  if (client[kHTTPConnVersion] === 'h1' && parser) {\n    if (!this[kError] && parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so far as a valid response.\n      parser.onMessageComplete()\n    }\n\n    this[kParser].destroy()\n    this[kParser] = null\n  }\n\n  const err = this[kError] || new SocketError('closed', util.getSocketInfo(this))\n\n  client[kSocket] = null\n\n  if (client.destroyed) {\n    assert(client[kPending] === 0)\n\n    // Fail entire queue.\n    const requests = client[kQueue].splice(client[kRunningIdx])\n    for (let i = 0; i < requests.length; i++) {\n      const request = requests[i]\n      errorRequest(client, request, err)\n    }\n  } else if (client[kRunning] > 0 && err.code !== 'UND_ERR_INFO') {\n    // Fail head of pipeline.\n    const request = client[kQueue][client[kRunningIdx]]\n    client[kQueue][client[kRunningIdx]++] = null\n\n    errorRequest(client, request, err)\n  }\n\n  client[kPendingIdx] = client[kRunningIdx]\n\n  assert(client[kRunning] === 0)\n\n  client.emit('disconnect', client[kUrl], [client], err)\n\n  resume(client)\n}\n\nasync function connect (client) {\n  assert(!client[kConnecting])\n  assert(!client[kSocket])\n\n  let { host, hostname, protocol, port } = client[kUrl]\n\n  // Resolve ipv6\n  if (hostname[0] === '[') {\n    const idx = hostname.indexOf(']')\n\n    assert(idx !== -1)\n    const ip = hostname.substring(1, idx)\n\n    assert(net.isIP(ip))\n    hostname = ip\n  }\n\n  client[kConnecting] = true\n\n  if (channels.beforeConnect.hasSubscribers) {\n    channels.beforeConnect.publish({\n      connectParams: {\n        host,\n        hostname,\n        protocol,\n        port,\n        servername: client[kServerName],\n        localAddress: client[kLocalAddress]\n      },\n      connector: client[kConnector]\n    })\n  }\n\n  try {\n    const socket = await new Promise((resolve, reject) => {\n      client[kConnector]({\n        host,\n        hostname,\n        protocol,\n        port,\n        servername: client[kServerName],\n        localAddress: client[kLocalAddress]\n      }, (err, socket) => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(socket)\n        }\n      })\n    })\n\n    if (client.destroyed) {\n      util.destroy(socket.on('error', () => {}), new ClientDestroyedError())\n      return\n    }\n\n    client[kConnecting] = false\n\n    assert(socket)\n\n    const isH2 = socket.alpnProtocol === 'h2'\n    if (isH2) {\n      if (!h2ExperimentalWarned) {\n        h2ExperimentalWarned = true\n        process.emitWarning('H2 support is experimental, expect them to change at any time.', {\n          code: 'UNDICI-H2'\n        })\n      }\n\n      const session = http2.connect(client[kUrl], {\n        createConnection: () => socket,\n        peerMaxConcurrentStreams: client[kHTTP2SessionState].maxConcurrentStreams\n      })\n\n      client[kHTTPConnVersion] = 'h2'\n      session[kClient] = client\n      session[kSocket] = socket\n      session.on('error', onHttp2SessionError)\n      session.on('frameError', onHttp2FrameError)\n      session.on('end', onHttp2SessionEnd)\n      session.on('goaway', onHTTP2GoAway)\n      session.on('close', onSocketClose)\n      session.unref()\n\n      client[kHTTP2Session] = session\n      socket[kHTTP2Session] = session\n    } else {\n      if (!llhttpInstance) {\n        llhttpInstance = await llhttpPromise\n        llhttpPromise = null\n      }\n\n      socket[kNoRef] = false\n      socket[kWriting] = false\n      socket[kReset] = false\n      socket[kBlocking] = false\n      socket[kParser] = new Parser(client, socket, llhttpInstance)\n    }\n\n    socket[kCounter] = 0\n    socket[kMaxRequests] = client[kMaxRequests]\n    socket[kClient] = client\n    socket[kError] = null\n\n    socket\n      .on('error', onSocketError)\n      .on('readable', onSocketReadable)\n      .on('end', onSocketEnd)\n      .on('close', onSocketClose)\n\n    client[kSocket] = socket\n\n    if (channels.connected.hasSubscribers) {\n      channels.connected.publish({\n        connectParams: {\n          host,\n          hostname,\n          protocol,\n          port,\n          servername: client[kServerName],\n          localAddress: client[kLocalAddress]\n        },\n        connector: client[kConnector],\n        socket\n      })\n    }\n    client.emit('connect', client[kUrl], [client])\n  } catch (err) {\n    if (client.destroyed) {\n      return\n    }\n\n    client[kConnecting] = false\n\n    if (channels.connectError.hasSubscribers) {\n      channels.connectError.publish({\n        connectParams: {\n          host,\n          hostname,\n          protocol,\n          port,\n          servername: client[kServerName],\n          localAddress: client[kLocalAddress]\n        },\n        connector: client[kConnector],\n        error: err\n      })\n    }\n\n    if (err.code === 'ERR_TLS_CERT_ALTNAME_INVALID') {\n      assert(client[kRunning] === 0)\n      while (client[kPending] > 0 && client[kQueue][client[kPendingIdx]].servername === client[kServerName]) {\n        const request = client[kQueue][client[kPendingIdx]++]\n        errorRequest(client, request, err)\n      }\n    } else {\n      onError(client, err)\n    }\n\n    client.emit('connectionError', client[kUrl], [client], err)\n  }\n\n  resume(client)\n}\n\nfunction emitDrain (client) {\n  client[kNeedDrain] = 0\n  client.emit('drain', client[kUrl], [client])\n}\n\nfunction resume (client, sync) {\n  if (client[kResuming] === 2) {\n    return\n  }\n\n  client[kResuming] = 2\n\n  _resume(client, sync)\n  client[kResuming] = 0\n\n  if (client[kRunningIdx] > 256) {\n    client[kQueue].splice(0, client[kRunningIdx])\n    client[kPendingIdx] -= client[kRunningIdx]\n    client[kRunningIdx] = 0\n  }\n}\n\nfunction _resume (client, sync) {\n  while (true) {\n    if (client.destroyed) {\n      assert(client[kPending] === 0)\n      return\n    }\n\n    if (client[kClosedResolve] && !client[kSize]) {\n      client[kClosedResolve]()\n      client[kClosedResolve] = null\n      return\n    }\n\n    const socket = client[kSocket]\n\n    if (socket && !socket.destroyed && socket.alpnProtocol !== 'h2') {\n      if (client[kSize] === 0) {\n        if (!socket[kNoRef] && socket.unref) {\n          socket.unref()\n          socket[kNoRef] = true\n        }\n      } else if (socket[kNoRef] && socket.ref) {\n        socket.ref()\n        socket[kNoRef] = false\n      }\n\n      if (client[kSize] === 0) {\n        if (socket[kParser].timeoutType !== TIMEOUT_IDLE) {\n          socket[kParser].setTimeout(client[kKeepAliveTimeoutValue], TIMEOUT_IDLE)\n        }\n      } else if (client[kRunning] > 0 && socket[kParser].statusCode < 200) {\n        if (socket[kParser].timeoutType !== TIMEOUT_HEADERS) {\n          const request = client[kQueue][client[kRunningIdx]]\n          const headersTimeout = request.headersTimeout != null\n            ? request.headersTimeout\n            : client[kHeadersTimeout]\n          socket[kParser].setTimeout(headersTimeout, TIMEOUT_HEADERS)\n        }\n      }\n    }\n\n    if (client[kBusy]) {\n      client[kNeedDrain] = 2\n    } else if (client[kNeedDrain] === 2) {\n      if (sync) {\n        client[kNeedDrain] = 1\n        process.nextTick(emitDrain, client)\n      } else {\n        emitDrain(client)\n      }\n      continue\n    }\n\n    if (client[kPending] === 0) {\n      return\n    }\n\n    if (client[kRunning] >= (client[kPipelining] || 1)) {\n      return\n    }\n\n    const request = client[kQueue][client[kPendingIdx]]\n\n    if (client[kUrl].protocol === 'https:' && client[kServerName] !== request.servername) {\n      if (client[kRunning] > 0) {\n        return\n      }\n\n      client[kServerName] = request.servername\n\n      if (socket && socket.servername !== request.servername) {\n        util.destroy(socket, new InformationalError('servername changed'))\n        return\n      }\n    }\n\n    if (client[kConnecting]) {\n      return\n    }\n\n    if (!socket && !client[kHTTP2Session]) {\n      connect(client)\n      return\n    }\n\n    if (socket.destroyed || socket[kWriting] || socket[kReset] || socket[kBlocking]) {\n      return\n    }\n\n    if (client[kRunning] > 0 && !request.idempotent) {\n      // Non-idempotent request cannot be retried.\n      // Ensure that no other requests are inflight and\n      // could cause failure.\n      return\n    }\n\n    if (client[kRunning] > 0 && (request.upgrade || request.method === 'CONNECT')) {\n      // Don't dispatch an upgrade until all preceding requests have completed.\n      // A misbehaving server might upgrade the connection before all pipelined\n      // request has completed.\n      return\n    }\n\n    if (client[kRunning] > 0 && util.bodyLength(request.body) !== 0 &&\n      (util.isStream(request.body) || util.isAsyncIterable(request.body))) {\n      // Request with stream or iterator body can error while other requests\n      // are inflight and indirectly error those as well.\n      // Ensure this doesn't happen by waiting for inflight\n      // to complete before dispatching.\n\n      // Request with stream or iterator body cannot be retried.\n      // Ensure that no other requests are inflight and\n      // could cause failure.\n      return\n    }\n\n    if (!request.aborted && write(client, request)) {\n      client[kPendingIdx]++\n    } else {\n      client[kQueue].splice(client[kPendingIdx], 1)\n    }\n  }\n}\n\n// https://www.rfc-editor.org/rfc/rfc7230#section-3.3.2\nfunction shouldSendContentLength (method) {\n  return method !== 'GET' && method !== 'HEAD' && method !== 'OPTIONS' && method !== 'TRACE' && method !== 'CONNECT'\n}\n\nfunction write (client, request) {\n  if (client[kHTTPConnVersion] === 'h2') {\n    writeH2(client, client[kHTTP2Session], request)\n    return\n  }\n\n  const { body, method, path, host, upgrade, headers, blocking, reset } = request\n\n  // https://tools.ietf.org/html/rfc7231#section-4.3.1\n  // https://tools.ietf.org/html/rfc7231#section-4.3.2\n  // https://tools.ietf.org/html/rfc7231#section-4.3.5\n\n  // Sending a payload body on a request that does not\n  // expect it can cause undefined behavior on some\n  // servers and corrupt connection state. Do not\n  // re-use the connection for further requests.\n\n  const expectsPayload = (\n    method === 'PUT' ||\n    method === 'POST' ||\n    method === 'PATCH'\n  )\n\n  if (body && typeof body.read === 'function') {\n    // Try to read EOF in order to get length.\n    body.read(0)\n  }\n\n  const bodyLength = util.bodyLength(body)\n\n  let contentLength = bodyLength\n\n  if (contentLength === null) {\n    contentLength = request.contentLength\n  }\n\n  if (contentLength === 0 && !expectsPayload) {\n    // https://tools.ietf.org/html/rfc7230#section-3.3.2\n    // A user agent SHOULD NOT send a Content-Length header field when\n    // the request message does not contain a payload body and the method\n    // semantics do not anticipate such a body.\n\n    contentLength = null\n  }\n\n  // https://github.com/nodejs/undici/issues/2046\n  // A user agent may send a Content-Length header with 0 value, this should be allowed.\n  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength !== null && request.contentLength !== contentLength) {\n    if (client[kStrictContentLength]) {\n      errorRequest(client, request, new RequestContentLengthMismatchError())\n      return false\n    }\n\n    process.emitWarning(new RequestContentLengthMismatchError())\n  }\n\n  const socket = client[kSocket]\n\n  try {\n    request.onConnect((err) => {\n      if (request.aborted || request.completed) {\n        return\n      }\n\n      errorRequest(client, request, err || new RequestAbortedError())\n\n      util.destroy(socket, new InformationalError('aborted'))\n    })\n  } catch (err) {\n    errorRequest(client, request, err)\n  }\n\n  if (request.aborted) {\n    return false\n  }\n\n  if (method === 'HEAD') {\n    // https://github.com/mcollina/undici/issues/258\n    // Close after a HEAD request to interop with misbehaving servers\n    // that may send a body in the response.\n\n    socket[kReset] = true\n  }\n\n  if (upgrade || method === 'CONNECT') {\n    // On CONNECT or upgrade, block pipeline from dispatching further\n    // requests on this connection.\n\n    socket[kReset] = true\n  }\n\n  if (reset != null) {\n    socket[kReset] = reset\n  }\n\n  if (client[kMaxRequests] && socket[kCounter]++ >= client[kMaxRequests]) {\n    socket[kReset] = true\n  }\n\n  if (blocking) {\n    socket[kBlocking] = true\n  }\n\n  let header = `${method} ${path} HTTP/1.1\\r\\n`\n\n  if (typeof host === 'string') {\n    header += `host: ${host}\\r\\n`\n  } else {\n    header += client[kHostHeader]\n  }\n\n  if (upgrade) {\n    header += `connection: upgrade\\r\\nupgrade: ${upgrade}\\r\\n`\n  } else if (client[kPipelining] && !socket[kReset]) {\n    header += 'connection: keep-alive\\r\\n'\n  } else {\n    header += 'connection: close\\r\\n'\n  }\n\n  if (headers) {\n    header += headers\n  }\n\n  if (channels.sendHeaders.hasSubscribers) {\n    channels.sendHeaders.publish({ request, headers: header, socket })\n  }\n\n  /* istanbul ignore else: assertion */\n  if (!body || bodyLength === 0) {\n    if (contentLength === 0) {\n      socket.write(`${header}content-length: 0\\r\\n\\r\\n`, 'latin1')\n    } else {\n      assert(contentLength === null, 'no body must not have content length')\n      socket.write(`${header}\\r\\n`, 'latin1')\n    }\n    request.onRequestSent()\n  } else if (util.isBuffer(body)) {\n    assert(contentLength === body.byteLength, 'buffer body must have content length')\n\n    socket.cork()\n    socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n    socket.write(body)\n    socket.uncork()\n    request.onBodySent(body)\n    request.onRequestSent()\n    if (!expectsPayload) {\n      socket[kReset] = true\n    }\n  } else if (util.isBlobLike(body)) {\n    if (typeof body.stream === 'function') {\n      writeIterable({ body: body.stream(), client, request, socket, contentLength, header, expectsPayload })\n    } else {\n      writeBlob({ body, client, request, socket, contentLength, header, expectsPayload })\n    }\n  } else if (util.isStream(body)) {\n    writeStream({ body, client, request, socket, contentLength, header, expectsPayload })\n  } else if (util.isIterable(body)) {\n    writeIterable({ body, client, request, socket, contentLength, header, expectsPayload })\n  } else {\n    assert(false)\n  }\n\n  return true\n}\n\nfunction writeH2 (client, session, request) {\n  const { body, method, path, host, upgrade, expectContinue, signal, headers: reqHeaders } = request\n\n  let headers\n  if (typeof reqHeaders === 'string') headers = Request[kHTTP2CopyHeaders](reqHeaders.trim())\n  else headers = reqHeaders\n\n  if (upgrade) {\n    errorRequest(client, request, new Error('Upgrade not supported for H2'))\n    return false\n  }\n\n  try {\n    // TODO(HTTP/2): Should we call onConnect immediately or on stream ready event?\n    request.onConnect((err) => {\n      if (request.aborted || request.completed) {\n        return\n      }\n\n      errorRequest(client, request, err || new RequestAbortedError())\n    })\n  } catch (err) {\n    errorRequest(client, request, err)\n  }\n\n  if (request.aborted) {\n    return false\n  }\n\n  /** @type {import('node:http2').ClientHttp2Stream} */\n  let stream\n  const h2State = client[kHTTP2SessionState]\n\n  headers[HTTP2_HEADER_AUTHORITY] = host || client[kHost]\n  headers[HTTP2_HEADER_METHOD] = method\n\n  if (method === 'CONNECT') {\n    session.ref()\n    // we are already connected, streams are pending, first request\n    // will create a new stream. We trigger a request to create the stream and wait until\n    // `ready` event is triggered\n    // We disabled endStream to allow the user to write to the stream\n    stream = session.request(headers, { endStream: false, signal })\n\n    if (stream.id && !stream.pending) {\n      request.onUpgrade(null, null, stream)\n      ++h2State.openStreams\n    } else {\n      stream.once('ready', () => {\n        request.onUpgrade(null, null, stream)\n        ++h2State.openStreams\n      })\n    }\n\n    stream.once('close', () => {\n      h2State.openStreams -= 1\n      // TODO(HTTP/2): unref only if current streams count is 0\n      if (h2State.openStreams === 0) session.unref()\n    })\n\n    return true\n  }\n\n  // https://tools.ietf.org/html/rfc7540#section-8.3\n  // :path and :scheme headers must be omited when sending CONNECT\n\n  headers[HTTP2_HEADER_PATH] = path\n  headers[HTTP2_HEADER_SCHEME] = 'https'\n\n  // https://tools.ietf.org/html/rfc7231#section-4.3.1\n  // https://tools.ietf.org/html/rfc7231#section-4.3.2\n  // https://tools.ietf.org/html/rfc7231#section-4.3.5\n\n  // Sending a payload body on a request that does not\n  // expect it can cause undefined behavior on some\n  // servers and corrupt connection state. Do not\n  // re-use the connection for further requests.\n\n  const expectsPayload = (\n    method === 'PUT' ||\n    method === 'POST' ||\n    method === 'PATCH'\n  )\n\n  if (body && typeof body.read === 'function') {\n    // Try to read EOF in order to get length.\n    body.read(0)\n  }\n\n  let contentLength = util.bodyLength(body)\n\n  if (contentLength == null) {\n    contentLength = request.contentLength\n  }\n\n  if (contentLength === 0 || !expectsPayload) {\n    // https://tools.ietf.org/html/rfc7230#section-3.3.2\n    // A user agent SHOULD NOT send a Content-Length header field when\n    // the request message does not contain a payload body and the method\n    // semantics do not anticipate such a body.\n\n    contentLength = null\n  }\n\n  // https://github.com/nodejs/undici/issues/2046\n  // A user agent may send a Content-Length header with 0 value, this should be allowed.\n  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength != null && request.contentLength !== contentLength) {\n    if (client[kStrictContentLength]) {\n      errorRequest(client, request, new RequestContentLengthMismatchError())\n      return false\n    }\n\n    process.emitWarning(new RequestContentLengthMismatchError())\n  }\n\n  if (contentLength != null) {\n    assert(body, 'no body must not have content length')\n    headers[HTTP2_HEADER_CONTENT_LENGTH] = `${contentLength}`\n  }\n\n  session.ref()\n\n  const shouldEndStream = method === 'GET' || method === 'HEAD'\n  if (expectContinue) {\n    headers[HTTP2_HEADER_EXPECT] = '100-continue'\n    stream = session.request(headers, { endStream: shouldEndStream, signal })\n\n    stream.once('continue', writeBodyH2)\n  } else {\n    stream = session.request(headers, {\n      endStream: shouldEndStream,\n      signal\n    })\n    writeBodyH2()\n  }\n\n  // Increment counter as we have new several streams open\n  ++h2State.openStreams\n\n  stream.once('response', headers => {\n    const { [HTTP2_HEADER_STATUS]: statusCode, ...realHeaders } = headers\n\n    if (request.onHeaders(Number(statusCode), realHeaders, stream.resume.bind(stream), '') === false) {\n      stream.pause()\n    }\n  })\n\n  stream.once('end', () => {\n    request.onComplete([])\n  })\n\n  stream.on('data', (chunk) => {\n    if (request.onData(chunk) === false) {\n      stream.pause()\n    }\n  })\n\n  stream.once('close', () => {\n    h2State.openStreams -= 1\n    // TODO(HTTP/2): unref only if current streams count is 0\n    if (h2State.openStreams === 0) {\n      session.unref()\n    }\n  })\n\n  stream.once('error', function (err) {\n    if (client[kHTTP2Session] && !client[kHTTP2Session].destroyed && !this.closed && !this.destroyed) {\n      h2State.streams -= 1\n      util.destroy(stream, err)\n    }\n  })\n\n  stream.once('frameError', (type, code) => {\n    const err = new InformationalError(`HTTP/2: \"frameError\" received - type ${type}, code ${code}`)\n    errorRequest(client, request, err)\n\n    if (client[kHTTP2Session] && !client[kHTTP2Session].destroyed && !this.closed && !this.destroyed) {\n      h2State.streams -= 1\n      util.destroy(stream, err)\n    }\n  })\n\n  // stream.on('aborted', () => {\n  //   // TODO(HTTP/2): Support aborted\n  // })\n\n  // stream.on('timeout', () => {\n  //   // TODO(HTTP/2): Support timeout\n  // })\n\n  // stream.on('push', headers => {\n  //   // TODO(HTTP/2): Suppor push\n  // })\n\n  // stream.on('trailers', headers => {\n  //   // TODO(HTTP/2): Support trailers\n  // })\n\n  return true\n\n  function writeBodyH2 () {\n    /* istanbul ignore else: assertion */\n    if (!body) {\n      request.onRequestSent()\n    } else if (util.isBuffer(body)) {\n      assert(contentLength === body.byteLength, 'buffer body must have content length')\n      stream.cork()\n      stream.write(body)\n      stream.uncork()\n      stream.end()\n      request.onBodySent(body)\n      request.onRequestSent()\n    } else if (util.isBlobLike(body)) {\n      if (typeof body.stream === 'function') {\n        writeIterable({\n          client,\n          request,\n          contentLength,\n          h2stream: stream,\n          expectsPayload,\n          body: body.stream(),\n          socket: client[kSocket],\n          header: ''\n        })\n      } else {\n        writeBlob({\n          body,\n          client,\n          request,\n          contentLength,\n          expectsPayload,\n          h2stream: stream,\n          header: '',\n          socket: client[kSocket]\n        })\n      }\n    } else if (util.isStream(body)) {\n      writeStream({\n        body,\n        client,\n        request,\n        contentLength,\n        expectsPayload,\n        socket: client[kSocket],\n        h2stream: stream,\n        header: ''\n      })\n    } else if (util.isIterable(body)) {\n      writeIterable({\n        body,\n        client,\n        request,\n        contentLength,\n        expectsPayload,\n        header: '',\n        h2stream: stream,\n        socket: client[kSocket]\n      })\n    } else {\n      assert(false)\n    }\n  }\n}\n\nfunction writeStream ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'stream body cannot be pipelined')\n\n  if (client[kHTTPConnVersion] === 'h2') {\n    // For HTTP/2, is enough to pipe the stream\n    const pipe = pipeline(\n      body,\n      h2stream,\n      (err) => {\n        if (err) {\n          util.destroy(body, err)\n          util.destroy(h2stream, err)\n        } else {\n          request.onRequestSent()\n        }\n      }\n    )\n\n    pipe.on('data', onPipeData)\n    pipe.once('end', () => {\n      pipe.removeListener('data', onPipeData)\n      util.destroy(pipe)\n    })\n\n    function onPipeData (chunk) {\n      request.onBodySent(chunk)\n    }\n\n    return\n  }\n\n  let finished = false\n\n  const writer = new AsyncWriter({ socket, request, contentLength, client, expectsPayload, header })\n\n  const onData = function (chunk) {\n    if (finished) {\n      return\n    }\n\n    try {\n      if (!writer.write(chunk) && this.pause) {\n        this.pause()\n      }\n    } catch (err) {\n      util.destroy(this, err)\n    }\n  }\n  const onDrain = function () {\n    if (finished) {\n      return\n    }\n\n    if (body.resume) {\n      body.resume()\n    }\n  }\n  const onAbort = function () {\n    if (finished) {\n      return\n    }\n    const err = new RequestAbortedError()\n    queueMicrotask(() => onFinished(err))\n  }\n  const onFinished = function (err) {\n    if (finished) {\n      return\n    }\n\n    finished = true\n\n    assert(socket.destroyed || (socket[kWriting] && client[kRunning] <= 1))\n\n    socket\n      .off('drain', onDrain)\n      .off('error', onFinished)\n\n    body\n      .removeListener('data', onData)\n      .removeListener('end', onFinished)\n      .removeListener('error', onFinished)\n      .removeListener('close', onAbort)\n\n    if (!err) {\n      try {\n        writer.end()\n      } catch (er) {\n        err = er\n      }\n    }\n\n    writer.destroy(err)\n\n    if (err && (err.code !== 'UND_ERR_INFO' || err.message !== 'reset')) {\n      util.destroy(body, err)\n    } else {\n      util.destroy(body)\n    }\n  }\n\n  body\n    .on('data', onData)\n    .on('end', onFinished)\n    .on('error', onFinished)\n    .on('close', onAbort)\n\n  if (body.resume) {\n    body.resume()\n  }\n\n  socket\n    .on('drain', onDrain)\n    .on('error', onFinished)\n}\n\nasync function writeBlob ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {\n  assert(contentLength === body.size, 'blob body must have content length')\n\n  const isH2 = client[kHTTPConnVersion] === 'h2'\n  try {\n    if (contentLength != null && contentLength !== body.size) {\n      throw new RequestContentLengthMismatchError()\n    }\n\n    const buffer = Buffer.from(await body.arrayBuffer())\n\n    if (isH2) {\n      h2stream.cork()\n      h2stream.write(buffer)\n      h2stream.uncork()\n    } else {\n      socket.cork()\n      socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n      socket.write(buffer)\n      socket.uncork()\n    }\n\n    request.onBodySent(buffer)\n    request.onRequestSent()\n\n    if (!expectsPayload) {\n      socket[kReset] = true\n    }\n\n    resume(client)\n  } catch (err) {\n    util.destroy(isH2 ? h2stream : socket, err)\n  }\n}\n\nasync function writeIterable ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'iterator body cannot be pipelined')\n\n  let callback = null\n  function onDrain () {\n    if (callback) {\n      const cb = callback\n      callback = null\n      cb()\n    }\n  }\n\n  const waitForDrain = () => new Promise((resolve, reject) => {\n    assert(callback === null)\n\n    if (socket[kError]) {\n      reject(socket[kError])\n    } else {\n      callback = resolve\n    }\n  })\n\n  if (client[kHTTPConnVersion] === 'h2') {\n    h2stream\n      .on('close', onDrain)\n      .on('drain', onDrain)\n\n    try {\n      // It's up to the user to somehow abort the async iterable.\n      for await (const chunk of body) {\n        if (socket[kError]) {\n          throw socket[kError]\n        }\n\n        const res = h2stream.write(chunk)\n        request.onBodySent(chunk)\n        if (!res) {\n          await waitForDrain()\n        }\n      }\n    } catch (err) {\n      h2stream.destroy(err)\n    } finally {\n      request.onRequestSent()\n      h2stream.end()\n      h2stream\n        .off('close', onDrain)\n        .off('drain', onDrain)\n    }\n\n    return\n  }\n\n  socket\n    .on('close', onDrain)\n    .on('drain', onDrain)\n\n  const writer = new AsyncWriter({ socket, request, contentLength, client, expectsPayload, header })\n  try {\n    // It's up to the user to somehow abort the async iterable.\n    for await (const chunk of body) {\n      if (socket[kError]) {\n        throw socket[kError]\n      }\n\n      if (!writer.write(chunk)) {\n        await waitForDrain()\n      }\n    }\n\n    writer.end()\n  } catch (err) {\n    writer.destroy(err)\n  } finally {\n    socket\n      .off('close', onDrain)\n      .off('drain', onDrain)\n  }\n}\n\nclass AsyncWriter {\n  constructor ({ socket, request, contentLength, client, expectsPayload, header }) {\n    this.socket = socket\n    this.request = request\n    this.contentLength = contentLength\n    this.client = client\n    this.bytesWritten = 0\n    this.expectsPayload = expectsPayload\n    this.header = header\n\n    socket[kWriting] = true\n  }\n\n  write (chunk) {\n    const { socket, request, contentLength, client, bytesWritten, expectsPayload, header } = this\n\n    if (socket[kError]) {\n      throw socket[kError]\n    }\n\n    if (socket.destroyed) {\n      return false\n    }\n\n    const len = Buffer.byteLength(chunk)\n    if (!len) {\n      return true\n    }\n\n    // We should defer writing chunks.\n    if (contentLength !== null && bytesWritten + len > contentLength) {\n      if (client[kStrictContentLength]) {\n        throw new RequestContentLengthMismatchError()\n      }\n\n      process.emitWarning(new RequestContentLengthMismatchError())\n    }\n\n    socket.cork()\n\n    if (bytesWritten === 0) {\n      if (!expectsPayload) {\n        socket[kReset] = true\n      }\n\n      if (contentLength === null) {\n        socket.write(`${header}transfer-encoding: chunked\\r\\n`, 'latin1')\n      } else {\n        socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n      }\n    }\n\n    if (contentLength === null) {\n      socket.write(`\\r\\n${len.toString(16)}\\r\\n`, 'latin1')\n    }\n\n    this.bytesWritten += len\n\n    const ret = socket.write(chunk)\n\n    socket.uncork()\n\n    request.onBodySent(chunk)\n\n    if (!ret) {\n      if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {\n        // istanbul ignore else: only for jest\n        if (socket[kParser].timeout.refresh) {\n          socket[kParser].timeout.refresh()\n        }\n      }\n    }\n\n    return ret\n  }\n\n  end () {\n    const { socket, contentLength, client, bytesWritten, expectsPayload, header, request } = this\n    request.onRequestSent()\n\n    socket[kWriting] = false\n\n    if (socket[kError]) {\n      throw socket[kError]\n    }\n\n    if (socket.destroyed) {\n      return\n    }\n\n    if (bytesWritten === 0) {\n      if (expectsPayload) {\n        // https://tools.ietf.org/html/rfc7230#section-3.3.2\n        // A user agent SHOULD send a Content-Length in a request message when\n        // no Transfer-Encoding is sent and the request method defines a meaning\n        // for an enclosed payload body.\n\n        socket.write(`${header}content-length: 0\\r\\n\\r\\n`, 'latin1')\n      } else {\n        socket.write(`${header}\\r\\n`, 'latin1')\n      }\n    } else if (contentLength === null) {\n      socket.write('\\r\\n0\\r\\n\\r\\n', 'latin1')\n    }\n\n    if (contentLength !== null && bytesWritten !== contentLength) {\n      if (client[kStrictContentLength]) {\n        throw new RequestContentLengthMismatchError()\n      } else {\n        process.emitWarning(new RequestContentLengthMismatchError())\n      }\n    }\n\n    if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {\n      // istanbul ignore else: only for jest\n      if (socket[kParser].timeout.refresh) {\n        socket[kParser].timeout.refresh()\n      }\n    }\n\n    resume(client)\n  }\n\n  destroy (err) {\n    const { socket, client } = this\n\n    socket[kWriting] = false\n\n    if (err) {\n      assert(client[kRunning] <= 1, 'pipeline should only contain this request')\n      util.destroy(socket, err)\n    }\n  }\n}\n\nfunction errorRequest (client, request, err) {\n  try {\n    request.onError(err)\n    assert(request.aborted)\n  } catch (err) {\n    client.emit('error', err)\n  }\n}\n\nmodule.exports = Client\n","'use strict'\n\n/* istanbul ignore file: only for Node 12 */\n\nconst { kConnected, kSize } = require('../core/symbols')\n\nclass CompatWeakRef {\n  constructor (value) {\n    this.value = value\n  }\n\n  deref () {\n    return this.value[kConnected] === 0 && this.value[kSize] === 0\n      ? undefined\n      : this.value\n  }\n}\n\nclass CompatFinalizer {\n  constructor (finalizer) {\n    this.finalizer = finalizer\n  }\n\n  register (dispatcher, key) {\n    if (dispatcher.on) {\n      dispatcher.on('disconnect', () => {\n        if (dispatcher[kConnected] === 0 && dispatcher[kSize] === 0) {\n          this.finalizer(key)\n        }\n      })\n    }\n  }\n}\n\nmodule.exports = function () {\n  // FIXME: remove workaround when the Node bug is fixed\n  // https://github.com/nodejs/node/issues/49344#issuecomment-1741776308\n  if (process.env.NODE_V8_COVERAGE) {\n    return {\n      WeakRef: CompatWeakRef,\n      FinalizationRegistry: CompatFinalizer\n    }\n  }\n  return {\n    WeakRef: global.WeakRef || CompatWeakRef,\n    FinalizationRegistry: global.FinalizationRegistry || CompatFinalizer\n  }\n}\n","'use strict'\n\n// https://wicg.github.io/cookie-store/#cookie-maximum-attribute-value-size\nconst maxAttributeValueSize = 1024\n\n// https://wicg.github.io/cookie-store/#cookie-maximum-name-value-pair-size\nconst maxNameValuePairSize = 4096\n\nmodule.exports = {\n  maxAttributeValueSize,\n  maxNameValuePairSize\n}\n","'use strict'\n\nconst { parseSetCookie } = require('./parse')\nconst { stringify } = require('./util')\nconst { webidl } = require('../fetch/webidl')\nconst { Headers } = require('../fetch/headers')\n\n/**\n * @typedef {Object} Cookie\n * @property {string} name\n * @property {string} value\n * @property {Date|number|undefined} expires\n * @property {number|undefined} maxAge\n * @property {string|undefined} domain\n * @property {string|undefined} path\n * @property {boolean|undefined} secure\n * @property {boolean|undefined} httpOnly\n * @property {'Strict'|'Lax'|'None'} sameSite\n * @property {string[]} unparsed\n */\n\n/**\n * @param {Headers} headers\n * @returns {Record<string, string>}\n */\nfunction getCookies (headers) {\n  webidl.argumentLengthCheck(arguments, 1, { header: 'getCookies' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  const cookie = headers.get('cookie')\n  const out = {}\n\n  if (!cookie) {\n    return out\n  }\n\n  for (const piece of cookie.split(';')) {\n    const [name, ...value] = piece.split('=')\n\n    out[name.trim()] = value.join('=')\n  }\n\n  return out\n}\n\n/**\n * @param {Headers} headers\n * @param {string} name\n * @param {{ path?: string, domain?: string }|undefined} attributes\n * @returns {void}\n */\nfunction deleteCookie (headers, name, attributes) {\n  webidl.argumentLengthCheck(arguments, 2, { header: 'deleteCookie' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  name = webidl.converters.DOMString(name)\n  attributes = webidl.converters.DeleteCookieAttributes(attributes)\n\n  // Matches behavior of\n  // https://github.com/denoland/deno_std/blob/63827b16330b82489a04614027c33b7904e08be5/http/cookie.ts#L278\n  setCookie(headers, {\n    name,\n    value: '',\n    expires: new Date(0),\n    ...attributes\n  })\n}\n\n/**\n * @param {Headers} headers\n * @returns {Cookie[]}\n */\nfunction getSetCookies (headers) {\n  webidl.argumentLengthCheck(arguments, 1, { header: 'getSetCookies' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  const cookies = headers.getSetCookie()\n\n  if (!cookies) {\n    return []\n  }\n\n  return cookies.map((pair) => parseSetCookie(pair))\n}\n\n/**\n * @param {Headers} headers\n * @param {Cookie} cookie\n * @returns {void}\n */\nfunction setCookie (headers, cookie) {\n  webidl.argumentLengthCheck(arguments, 2, { header: 'setCookie' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  cookie = webidl.converters.Cookie(cookie)\n\n  const str = stringify(cookie)\n\n  if (str) {\n    headers.append('Set-Cookie', stringify(cookie))\n  }\n}\n\nwebidl.converters.DeleteCookieAttributes = webidl.dictionaryConverter([\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'path',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'domain',\n    defaultValue: null\n  }\n])\n\nwebidl.converters.Cookie = webidl.dictionaryConverter([\n  {\n    converter: webidl.converters.DOMString,\n    key: 'name'\n  },\n  {\n    converter: webidl.converters.DOMString,\n    key: 'value'\n  },\n  {\n    converter: webidl.nullableConverter((value) => {\n      if (typeof value === 'number') {\n        return webidl.converters['unsigned long long'](value)\n      }\n\n      return new Date(value)\n    }),\n    key: 'expires',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters['long long']),\n    key: 'maxAge',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'domain',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'path',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.boolean),\n    key: 'secure',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.boolean),\n    key: 'httpOnly',\n    defaultValue: null\n  },\n  {\n    converter: webidl.converters.USVString,\n    key: 'sameSite',\n    allowedValues: ['Strict', 'Lax', 'None']\n  },\n  {\n    converter: webidl.sequenceConverter(webidl.converters.DOMString),\n    key: 'unparsed',\n    defaultValue: []\n  }\n])\n\nmodule.exports = {\n  getCookies,\n  deleteCookie,\n  getSetCookies,\n  setCookie\n}\n","'use strict'\n\nconst { maxNameValuePairSize, maxAttributeValueSize } = require('./constants')\nconst { isCTLExcludingHtab } = require('./util')\nconst { collectASequenceOfCodePointsFast } = require('../fetch/dataURL')\nconst assert = require('assert')\n\n/**\n * @description Parses the field-value attributes of a set-cookie header string.\n * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4\n * @param {string} header\n * @returns if the header is invalid, null will be returned\n */\nfunction parseSetCookie (header) {\n  // 1. If the set-cookie-string contains a %x00-08 / %x0A-1F / %x7F\n  //    character (CTL characters excluding HTAB): Abort these steps and\n  //    ignore the set-cookie-string entirely.\n  if (isCTLExcludingHtab(header)) {\n    return null\n  }\n\n  let nameValuePair = ''\n  let unparsedAttributes = ''\n  let name = ''\n  let value = ''\n\n  // 2. If the set-cookie-string contains a %x3B (\";\") character:\n  if (header.includes(';')) {\n    // 1. The name-value-pair string consists of the characters up to,\n    //    but not including, the first %x3B (\";\"), and the unparsed-\n    //    attributes consist of the remainder of the set-cookie-string\n    //    (including the %x3B (\";\") in question).\n    const position = { position: 0 }\n\n    nameValuePair = collectASequenceOfCodePointsFast(';', header, position)\n    unparsedAttributes = header.slice(position.position)\n  } else {\n    // Otherwise:\n\n    // 1. The name-value-pair string consists of all the characters\n    //    contained in the set-cookie-string, and the unparsed-\n    //    attributes is the empty string.\n    nameValuePair = header\n  }\n\n  // 3. If the name-value-pair string lacks a %x3D (\"=\") character, then\n  //    the name string is empty, and the value string is the value of\n  //    name-value-pair.\n  if (!nameValuePair.includes('=')) {\n    value = nameValuePair\n  } else {\n    //    Otherwise, the name string consists of the characters up to, but\n    //    not including, the first %x3D (\"=\") character, and the (possibly\n    //    empty) value string consists of the characters after the first\n    //    %x3D (\"=\") character.\n    const position = { position: 0 }\n    name = collectASequenceOfCodePointsFast(\n      '=',\n      nameValuePair,\n      position\n    )\n    value = nameValuePair.slice(position.position + 1)\n  }\n\n  // 4. Remove any leading or trailing WSP characters from the name\n  //    string and the value string.\n  name = name.trim()\n  value = value.trim()\n\n  // 5. If the sum of the lengths of the name string and the value string\n  //    is more than 4096 octets, abort these steps and ignore the set-\n  //    cookie-string entirely.\n  if (name.length + value.length > maxNameValuePairSize) {\n    return null\n  }\n\n  // 6. The cookie-name is the name string, and the cookie-value is the\n  //    value string.\n  return {\n    name, value, ...parseUnparsedAttributes(unparsedAttributes)\n  }\n}\n\n/**\n * Parses the remaining attributes of a set-cookie header\n * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4\n * @param {string} unparsedAttributes\n * @param {[Object.<string, unknown>]={}} cookieAttributeList\n */\nfunction parseUnparsedAttributes (unparsedAttributes, cookieAttributeList = {}) {\n  // 1. If the unparsed-attributes string is empty, skip the rest of\n  //    these steps.\n  if (unparsedAttributes.length === 0) {\n    return cookieAttributeList\n  }\n\n  // 2. Discard the first character of the unparsed-attributes (which\n  //    will be a %x3B (\";\") character).\n  assert(unparsedAttributes[0] === ';')\n  unparsedAttributes = unparsedAttributes.slice(1)\n\n  let cookieAv = ''\n\n  // 3. If the remaining unparsed-attributes contains a %x3B (\";\")\n  //    character:\n  if (unparsedAttributes.includes(';')) {\n    // 1. Consume the characters of the unparsed-attributes up to, but\n    //    not including, the first %x3B (\";\") character.\n    cookieAv = collectASequenceOfCodePointsFast(\n      ';',\n      unparsedAttributes,\n      { position: 0 }\n    )\n    unparsedAttributes = unparsedAttributes.slice(cookieAv.length)\n  } else {\n    // Otherwise:\n\n    // 1. Consume the remainder of the unparsed-attributes.\n    cookieAv = unparsedAttributes\n    unparsedAttributes = ''\n  }\n\n  // Let the cookie-av string be the characters consumed in this step.\n\n  let attributeName = ''\n  let attributeValue = ''\n\n  // 4. If the cookie-av string contains a %x3D (\"=\") character:\n  if (cookieAv.includes('=')) {\n    // 1. The (possibly empty) attribute-name string consists of the\n    //    characters up to, but not including, the first %x3D (\"=\")\n    //    character, and the (possibly empty) attribute-value string\n    //    consists of the characters after the first %x3D (\"=\")\n    //    character.\n    const position = { position: 0 }\n\n    attributeName = collectASequenceOfCodePointsFast(\n      '=',\n      cookieAv,\n      position\n    )\n    attributeValue = cookieAv.slice(position.position + 1)\n  } else {\n    // Otherwise:\n\n    // 1. The attribute-name string consists of the entire cookie-av\n    //    string, and the attribute-value string is empty.\n    attributeName = cookieAv\n  }\n\n  // 5. Remove any leading or trailing WSP characters from the attribute-\n  //    name string and the attribute-value string.\n  attributeName = attributeName.trim()\n  attributeValue = attributeValue.trim()\n\n  // 6. If the attribute-value is longer than 1024 octets, ignore the\n  //    cookie-av string and return to Step 1 of this algorithm.\n  if (attributeValue.length > maxAttributeValueSize) {\n    return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n  }\n\n  // 7. Process the attribute-name and attribute-value according to the\n  //    requirements in the following subsections.  (Notice that\n  //    attributes with unrecognized attribute-names are ignored.)\n  const attributeNameLowercase = attributeName.toLowerCase()\n\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.1\n  // If the attribute-name case-insensitively matches the string\n  // \"Expires\", the user agent MUST process the cookie-av as follows.\n  if (attributeNameLowercase === 'expires') {\n    // 1. Let the expiry-time be the result of parsing the attribute-value\n    //    as cookie-date (see Section 5.1.1).\n    const expiryTime = new Date(attributeValue)\n\n    // 2. If the attribute-value failed to parse as a cookie date, ignore\n    //    the cookie-av.\n\n    cookieAttributeList.expires = expiryTime\n  } else if (attributeNameLowercase === 'max-age') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.2\n    // If the attribute-name case-insensitively matches the string \"Max-\n    // Age\", the user agent MUST process the cookie-av as follows.\n\n    // 1. If the first character of the attribute-value is not a DIGIT or a\n    //    \"-\" character, ignore the cookie-av.\n    const charCode = attributeValue.charCodeAt(0)\n\n    if ((charCode < 48 || charCode > 57) && attributeValue[0] !== '-') {\n      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n    }\n\n    // 2. If the remainder of attribute-value contains a non-DIGIT\n    //    character, ignore the cookie-av.\n    if (!/^\\d+$/.test(attributeValue)) {\n      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n    }\n\n    // 3. Let delta-seconds be the attribute-value converted to an integer.\n    const deltaSeconds = Number(attributeValue)\n\n    // 4. Let cookie-age-limit be the maximum age of the cookie (which\n    //    SHOULD be 400 days or less, see Section 4.1.2.2).\n\n    // 5. Set delta-seconds to the smaller of its present value and cookie-\n    //    age-limit.\n    // deltaSeconds = Math.min(deltaSeconds * 1000, maxExpiresMs)\n\n    // 6. If delta-seconds is less than or equal to zero (0), let expiry-\n    //    time be the earliest representable date and time.  Otherwise, let\n    //    the expiry-time be the current date and time plus delta-seconds\n    //    seconds.\n    // const expiryTime = deltaSeconds <= 0 ? Date.now() : Date.now() + deltaSeconds\n\n    // 7. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Max-Age and an attribute-value of expiry-time.\n    cookieAttributeList.maxAge = deltaSeconds\n  } else if (attributeNameLowercase === 'domain') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.3\n    // If the attribute-name case-insensitively matches the string \"Domain\",\n    // the user agent MUST process the cookie-av as follows.\n\n    // 1. Let cookie-domain be the attribute-value.\n    let cookieDomain = attributeValue\n\n    // 2. If cookie-domain starts with %x2E (\".\"), let cookie-domain be\n    //    cookie-domain without its leading %x2E (\".\").\n    if (cookieDomain[0] === '.') {\n      cookieDomain = cookieDomain.slice(1)\n    }\n\n    // 3. Convert the cookie-domain to lower case.\n    cookieDomain = cookieDomain.toLowerCase()\n\n    // 4. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Domain and an attribute-value of cookie-domain.\n    cookieAttributeList.domain = cookieDomain\n  } else if (attributeNameLowercase === 'path') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.4\n    // If the attribute-name case-insensitively matches the string \"Path\",\n    // the user agent MUST process the cookie-av as follows.\n\n    // 1. If the attribute-value is empty or if the first character of the\n    //    attribute-value is not %x2F (\"/\"):\n    let cookiePath = ''\n    if (attributeValue.length === 0 || attributeValue[0] !== '/') {\n      // 1. Let cookie-path be the default-path.\n      cookiePath = '/'\n    } else {\n      // Otherwise:\n\n      // 1. Let cookie-path be the attribute-value.\n      cookiePath = attributeValue\n    }\n\n    // 2. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Path and an attribute-value of cookie-path.\n    cookieAttributeList.path = cookiePath\n  } else if (attributeNameLowercase === 'secure') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.5\n    // If the attribute-name case-insensitively matches the string \"Secure\",\n    // the user agent MUST append an attribute to the cookie-attribute-list\n    // with an attribute-name of Secure and an empty attribute-value.\n\n    cookieAttributeList.secure = true\n  } else if (attributeNameLowercase === 'httponly') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.6\n    // If the attribute-name case-insensitively matches the string\n    // \"HttpOnly\", the user agent MUST append an attribute to the cookie-\n    // attribute-list with an attribute-name of HttpOnly and an empty\n    // attribute-value.\n\n    cookieAttributeList.httpOnly = true\n  } else if (attributeNameLowercase === 'samesite') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.7\n    // If the attribute-name case-insensitively matches the string\n    // \"SameSite\", the user agent MUST process the cookie-av as follows:\n\n    // 1. Let enforcement be \"Default\".\n    let enforcement = 'Default'\n\n    const attributeValueLowercase = attributeValue.toLowerCase()\n    // 2. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"None\", set enforcement to \"None\".\n    if (attributeValueLowercase.includes('none')) {\n      enforcement = 'None'\n    }\n\n    // 3. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"Strict\", set enforcement to \"Strict\".\n    if (attributeValueLowercase.includes('strict')) {\n      enforcement = 'Strict'\n    }\n\n    // 4. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"Lax\", set enforcement to \"Lax\".\n    if (attributeValueLowercase.includes('lax')) {\n      enforcement = 'Lax'\n    }\n\n    // 5. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of \"SameSite\" and an attribute-value of\n    //    enforcement.\n    cookieAttributeList.sameSite = enforcement\n  } else {\n    cookieAttributeList.unparsed ??= []\n\n    cookieAttributeList.unparsed.push(`${attributeName}=${attributeValue}`)\n  }\n\n  // 8. Return to Step 1 of this algorithm.\n  return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n}\n\nmodule.exports = {\n  parseSetCookie,\n  parseUnparsedAttributes\n}\n","'use strict'\n\n/**\n * @param {string} value\n * @returns {boolean}\n */\nfunction isCTLExcludingHtab (value) {\n  if (value.length === 0) {\n    return false\n  }\n\n  for (const char of value) {\n    const code = char.charCodeAt(0)\n\n    if (\n      (code >= 0x00 || code <= 0x08) ||\n      (code >= 0x0A || code <= 0x1F) ||\n      code === 0x7F\n    ) {\n      return false\n    }\n  }\n}\n\n/**\n CHAR           = <any US-ASCII character (octets 0 - 127)>\n token          = 1*<any CHAR except CTLs or separators>\n separators     = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n                | \",\" | \";\" | \":\" | \"\\\" | <\">\n                | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n                | \"{\" | \"}\" | SP | HT\n * @param {string} name\n */\nfunction validateCookieName (name) {\n  for (const char of name) {\n    const code = char.charCodeAt(0)\n\n    if (\n      (code <= 0x20 || code > 0x7F) ||\n      char === '(' ||\n      char === ')' ||\n      char === '>' ||\n      char === '<' ||\n      char === '@' ||\n      char === ',' ||\n      char === ';' ||\n      char === ':' ||\n      char === '\\\\' ||\n      char === '\"' ||\n      char === '/' ||\n      char === '[' ||\n      char === ']' ||\n      char === '?' ||\n      char === '=' ||\n      char === '{' ||\n      char === '}'\n    ) {\n      throw new Error('Invalid cookie name')\n    }\n  }\n}\n\n/**\n cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )\n cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E\n                       ; US-ASCII characters excluding CTLs,\n                       ; whitespace DQUOTE, comma, semicolon,\n                       ; and backslash\n * @param {string} value\n */\nfunction validateCookieValue (value) {\n  for (const char of value) {\n    const code = char.charCodeAt(0)\n\n    if (\n      code < 0x21 || // exclude CTLs (0-31)\n      code === 0x22 ||\n      code === 0x2C ||\n      code === 0x3B ||\n      code === 0x5C ||\n      code > 0x7E // non-ascii\n    ) {\n      throw new Error('Invalid header value')\n    }\n  }\n}\n\n/**\n * path-value        = <any CHAR except CTLs or \";\">\n * @param {string} path\n */\nfunction validateCookiePath (path) {\n  for (const char of path) {\n    const code = char.charCodeAt(0)\n\n    if (code < 0x21 || char === ';') {\n      throw new Error('Invalid cookie path')\n    }\n  }\n}\n\n/**\n * I have no idea why these values aren't allowed to be honest,\n * but Deno tests these. - Khafra\n * @param {string} domain\n */\nfunction validateCookieDomain (domain) {\n  if (\n    domain.startsWith('-') ||\n    domain.endsWith('.') ||\n    domain.endsWith('-')\n  ) {\n    throw new Error('Invalid cookie domain')\n  }\n}\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc7231#section-7.1.1.1\n * @param {number|Date} date\n  IMF-fixdate  = day-name \",\" SP date1 SP time-of-day SP GMT\n  ; fixed length/zone/capitalization subset of the format\n  ; see Section 3.3 of [RFC5322]\n\n  day-name     = %x4D.6F.6E ; \"Mon\", case-sensitive\n              / %x54.75.65 ; \"Tue\", case-sensitive\n              / %x57.65.64 ; \"Wed\", case-sensitive\n              / %x54.68.75 ; \"Thu\", case-sensitive\n              / %x46.72.69 ; \"Fri\", case-sensitive\n              / %x53.61.74 ; \"Sat\", case-sensitive\n              / %x53.75.6E ; \"Sun\", case-sensitive\n  date1        = day SP month SP year\n                  ; e.g., 02 Jun 1982\n\n  day          = 2DIGIT\n  month        = %x4A.61.6E ; \"Jan\", case-sensitive\n              / %x46.65.62 ; \"Feb\", case-sensitive\n              / %x4D.61.72 ; \"Mar\", case-sensitive\n              / %x41.70.72 ; \"Apr\", case-sensitive\n              / %x4D.61.79 ; \"May\", case-sensitive\n              / %x4A.75.6E ; \"Jun\", case-sensitive\n              / %x4A.75.6C ; \"Jul\", case-sensitive\n              / %x41.75.67 ; \"Aug\", case-sensitive\n              / %x53.65.70 ; \"Sep\", case-sensitive\n              / %x4F.63.74 ; \"Oct\", case-sensitive\n              / %x4E.6F.76 ; \"Nov\", case-sensitive\n              / %x44.65.63 ; \"Dec\", case-sensitive\n  year         = 4DIGIT\n\n  GMT          = %x47.4D.54 ; \"GMT\", case-sensitive\n\n  time-of-day  = hour \":\" minute \":\" second\n              ; 00:00:00 - 23:59:60 (leap second)\n\n  hour         = 2DIGIT\n  minute       = 2DIGIT\n  second       = 2DIGIT\n */\nfunction toIMFDate (date) {\n  if (typeof date === 'number') {\n    date = new Date(date)\n  }\n\n  const days = [\n    'Sun', 'Mon', 'Tue', 'Wed',\n    'Thu', 'Fri', 'Sat'\n  ]\n\n  const months = [\n    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n  ]\n\n  const dayName = days[date.getUTCDay()]\n  const day = date.getUTCDate().toString().padStart(2, '0')\n  const month = months[date.getUTCMonth()]\n  const year = date.getUTCFullYear()\n  const hour = date.getUTCHours().toString().padStart(2, '0')\n  const minute = date.getUTCMinutes().toString().padStart(2, '0')\n  const second = date.getUTCSeconds().toString().padStart(2, '0')\n\n  return `${dayName}, ${day} ${month} ${year} ${hour}:${minute}:${second} GMT`\n}\n\n/**\n max-age-av        = \"Max-Age=\" non-zero-digit *DIGIT\n                       ; In practice, both expires-av and max-age-av\n                       ; are limited to dates representable by the\n                       ; user agent.\n * @param {number} maxAge\n */\nfunction validateCookieMaxAge (maxAge) {\n  if (maxAge < 0) {\n    throw new Error('Invalid cookie max-age')\n  }\n}\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc6265#section-4.1.1\n * @param {import('./index').Cookie} cookie\n */\nfunction stringify (cookie) {\n  if (cookie.name.length === 0) {\n    return null\n  }\n\n  validateCookieName(cookie.name)\n  validateCookieValue(cookie.value)\n\n  const out = [`${cookie.name}=${cookie.value}`]\n\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.1\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.2\n  if (cookie.name.startsWith('__Secure-')) {\n    cookie.secure = true\n  }\n\n  if (cookie.name.startsWith('__Host-')) {\n    cookie.secure = true\n    cookie.domain = null\n    cookie.path = '/'\n  }\n\n  if (cookie.secure) {\n    out.push('Secure')\n  }\n\n  if (cookie.httpOnly) {\n    out.push('HttpOnly')\n  }\n\n  if (typeof cookie.maxAge === 'number') {\n    validateCookieMaxAge(cookie.maxAge)\n    out.push(`Max-Age=${cookie.maxAge}`)\n  }\n\n  if (cookie.domain) {\n    validateCookieDomain(cookie.domain)\n    out.push(`Domain=${cookie.domain}`)\n  }\n\n  if (cookie.path) {\n    validateCookiePath(cookie.path)\n    out.push(`Path=${cookie.path}`)\n  }\n\n  if (cookie.expires && cookie.expires.toString() !== 'Invalid Date') {\n    out.push(`Expires=${toIMFDate(cookie.expires)}`)\n  }\n\n  if (cookie.sameSite) {\n    out.push(`SameSite=${cookie.sameSite}`)\n  }\n\n  for (const part of cookie.unparsed) {\n    if (!part.includes('=')) {\n      throw new Error('Invalid unparsed')\n    }\n\n    const [key, ...value] = part.split('=')\n\n    out.push(`${key.trim()}=${value.join('=')}`)\n  }\n\n  return out.join('; ')\n}\n\nmodule.exports = {\n  isCTLExcludingHtab,\n  validateCookieName,\n  validateCookiePath,\n  validateCookieValue,\n  toIMFDate,\n  stringify\n}\n","'use strict'\n\nconst net = require('net')\nconst assert = require('assert')\nconst util = require('./util')\nconst { InvalidArgumentError, ConnectTimeoutError } = require('./errors')\n\nlet tls // include tls conditionally since it is not always available\n\n// TODO: session re-use does not wait for the first\n// connection to resolve the session and might therefore\n// resolve the same servername multiple times even when\n// re-use is enabled.\n\nlet SessionCache\n// FIXME: remove workaround when the Node bug is fixed\n// https://github.com/nodejs/node/issues/49344#issuecomment-1741776308\nif (global.FinalizationRegistry && !process.env.NODE_V8_COVERAGE) {\n  SessionCache = class WeakSessionCache {\n    constructor (maxCachedSessions) {\n      this._maxCachedSessions = maxCachedSessions\n      this._sessionCache = new Map()\n      this._sessionRegistry = new global.FinalizationRegistry((key) => {\n        if (this._sessionCache.size < this._maxCachedSessions) {\n          return\n        }\n\n        const ref = this._sessionCache.get(key)\n        if (ref !== undefined && ref.deref() === undefined) {\n          this._sessionCache.delete(key)\n        }\n      })\n    }\n\n    get (sessionKey) {\n      const ref = this._sessionCache.get(sessionKey)\n      return ref ? ref.deref() : null\n    }\n\n    set (sessionKey, session) {\n      if (this._maxCachedSessions === 0) {\n        return\n      }\n\n      this._sessionCache.set(sessionKey, new WeakRef(session))\n      this._sessionRegistry.register(session, sessionKey)\n    }\n  }\n} else {\n  SessionCache = class SimpleSessionCache {\n    constructor (maxCachedSessions) {\n      this._maxCachedSessions = maxCachedSessions\n      this._sessionCache = new Map()\n    }\n\n    get (sessionKey) {\n      return this._sessionCache.get(sessionKey)\n    }\n\n    set (sessionKey, session) {\n      if (this._maxCachedSessions === 0) {\n        return\n      }\n\n      if (this._sessionCache.size >= this._maxCachedSessions) {\n        // remove the oldest session\n        const { value: oldestKey } = this._sessionCache.keys().next()\n        this._sessionCache.delete(oldestKey)\n      }\n\n      this._sessionCache.set(sessionKey, session)\n    }\n  }\n}\n\nfunction buildConnector ({ allowH2, maxCachedSessions, socketPath, timeout, ...opts }) {\n  if (maxCachedSessions != null && (!Number.isInteger(maxCachedSessions) || maxCachedSessions < 0)) {\n    throw new InvalidArgumentError('maxCachedSessions must be a positive integer or zero')\n  }\n\n  const options = { path: socketPath, ...opts }\n  const sessionCache = new SessionCache(maxCachedSessions == null ? 100 : maxCachedSessions)\n  timeout = timeout == null ? 10e3 : timeout\n  allowH2 = allowH2 != null ? allowH2 : false\n  return function connect ({ hostname, host, protocol, port, servername, localAddress, httpSocket }, callback) {\n    let socket\n    if (protocol === 'https:') {\n      if (!tls) {\n        tls = require('tls')\n      }\n      servername = servername || options.servername || util.getServerName(host) || null\n\n      const sessionKey = servername || hostname\n      const session = sessionCache.get(sessionKey) || null\n\n      assert(sessionKey)\n\n      socket = tls.connect({\n        highWaterMark: 16384, // TLS in node can't have bigger HWM anyway...\n        ...options,\n        servername,\n        session,\n        localAddress,\n        // TODO(HTTP/2): Add support for h2c\n        ALPNProtocols: allowH2 ? ['http/1.1', 'h2'] : ['http/1.1'],\n        socket: httpSocket, // upgrade socket connection\n        port: port || 443,\n        host: hostname\n      })\n\n      socket\n        .on('session', function (session) {\n          // TODO (fix): Can a session become invalid once established? Don't think so?\n          sessionCache.set(sessionKey, session)\n        })\n    } else {\n      assert(!httpSocket, 'httpSocket can only be sent on TLS update')\n      socket = net.connect({\n        highWaterMark: 64 * 1024, // Same as nodejs fs streams.\n        ...options,\n        localAddress,\n        port: port || 80,\n        host: hostname\n      })\n    }\n\n    // Set TCP keep alive options on the socket here instead of in connect() for the case of assigning the socket\n    if (options.keepAlive == null || options.keepAlive) {\n      const keepAliveInitialDelay = options.keepAliveInitialDelay === undefined ? 60e3 : options.keepAliveInitialDelay\n      socket.setKeepAlive(true, keepAliveInitialDelay)\n    }\n\n    const cancelTimeout = setupTimeout(() => onConnectTimeout(socket), timeout)\n\n    socket\n      .setNoDelay(true)\n      .once(protocol === 'https:' ? 'secureConnect' : 'connect', function () {\n        cancelTimeout()\n\n        if (callback) {\n          const cb = callback\n          callback = null\n          cb(null, this)\n        }\n      })\n      .on('error', function (err) {\n        cancelTimeout()\n\n        if (callback) {\n          const cb = callback\n          callback = null\n          cb(err)\n        }\n      })\n\n    return socket\n  }\n}\n\nfunction setupTimeout (onConnectTimeout, timeout) {\n  if (!timeout) {\n    return () => {}\n  }\n\n  let s1 = null\n  let s2 = null\n  const timeoutId = setTimeout(() => {\n    // setImmediate is added to make sure that we priotorise socket error events over timeouts\n    s1 = setImmediate(() => {\n      if (process.platform === 'win32') {\n        // Windows needs an extra setImmediate probably due to implementation differences in the socket logic\n        s2 = setImmediate(() => onConnectTimeout())\n      } else {\n        onConnectTimeout()\n      }\n    })\n  }, timeout)\n  return () => {\n    clearTimeout(timeoutId)\n    clearImmediate(s1)\n    clearImmediate(s2)\n  }\n}\n\nfunction onConnectTimeout (socket) {\n  util.destroy(socket, new ConnectTimeoutError())\n}\n\nmodule.exports = buildConnector\n","'use strict'\n\n/** @type {Record<string, string | undefined>} */\nconst headerNameLowerCasedRecord = {}\n\n// https://developer.mozilla.org/docs/Web/HTTP/Headers\nconst wellknownHeaderNames = [\n  'Accept',\n  'Accept-Encoding',\n  'Accept-Language',\n  'Accept-Ranges',\n  'Access-Control-Allow-Credentials',\n  'Access-Control-Allow-Headers',\n  'Access-Control-Allow-Methods',\n  'Access-Control-Allow-Origin',\n  'Access-Control-Expose-Headers',\n  'Access-Control-Max-Age',\n  'Access-Control-Request-Headers',\n  'Access-Control-Request-Method',\n  'Age',\n  'Allow',\n  'Alt-Svc',\n  'Alt-Used',\n  'Authorization',\n  'Cache-Control',\n  'Clear-Site-Data',\n  'Connection',\n  'Content-Disposition',\n  'Content-Encoding',\n  'Content-Language',\n  'Content-Length',\n  'Content-Location',\n  'Content-Range',\n  'Content-Security-Policy',\n  'Content-Security-Policy-Report-Only',\n  'Content-Type',\n  'Cookie',\n  'Cross-Origin-Embedder-Policy',\n  'Cross-Origin-Opener-Policy',\n  'Cross-Origin-Resource-Policy',\n  'Date',\n  'Device-Memory',\n  'Downlink',\n  'ECT',\n  'ETag',\n  'Expect',\n  'Expect-CT',\n  'Expires',\n  'Forwarded',\n  'From',\n  'Host',\n  'If-Match',\n  'If-Modified-Since',\n  'If-None-Match',\n  'If-Range',\n  'If-Unmodified-Since',\n  'Keep-Alive',\n  'Last-Modified',\n  'Link',\n  'Location',\n  'Max-Forwards',\n  'Origin',\n  'Permissions-Policy',\n  'Pragma',\n  'Proxy-Authenticate',\n  'Proxy-Authorization',\n  'RTT',\n  'Range',\n  'Referer',\n  'Referrer-Policy',\n  'Refresh',\n  'Retry-After',\n  'Sec-WebSocket-Accept',\n  'Sec-WebSocket-Extensions',\n  'Sec-WebSocket-Key',\n  'Sec-WebSocket-Protocol',\n  'Sec-WebSocket-Version',\n  'Server',\n  'Server-Timing',\n  'Service-Worker-Allowed',\n  'Service-Worker-Navigation-Preload',\n  'Set-Cookie',\n  'SourceMap',\n  'Strict-Transport-Security',\n  'Supports-Loading-Mode',\n  'TE',\n  'Timing-Allow-Origin',\n  'Trailer',\n  'Transfer-Encoding',\n  'Upgrade',\n  'Upgrade-Insecure-Requests',\n  'User-Agent',\n  'Vary',\n  'Via',\n  'WWW-Authenticate',\n  'X-Content-Type-Options',\n  'X-DNS-Prefetch-Control',\n  'X-Frame-Options',\n  'X-Permitted-Cross-Domain-Policies',\n  'X-Powered-By',\n  'X-Requested-With',\n  'X-XSS-Protection'\n]\n\nfor (let i = 0; i < wellknownHeaderNames.length; ++i) {\n  const key = wellknownHeaderNames[i]\n  const lowerCasedKey = key.toLowerCase()\n  headerNameLowerCasedRecord[key] = headerNameLowerCasedRecord[lowerCasedKey] =\n    lowerCasedKey\n}\n\n// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.\nObject.setPrototypeOf(headerNameLowerCasedRecord, null)\n\nmodule.exports = {\n  wellknownHeaderNames,\n  headerNameLowerCasedRecord\n}\n","'use strict'\n\nclass UndiciError extends Error {\n  constructor (message) {\n    super(message)\n    this.name = 'UndiciError'\n    this.code = 'UND_ERR'\n  }\n}\n\nclass ConnectTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ConnectTimeoutError)\n    this.name = 'ConnectTimeoutError'\n    this.message = message || 'Connect Timeout Error'\n    this.code = 'UND_ERR_CONNECT_TIMEOUT'\n  }\n}\n\nclass HeadersTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, HeadersTimeoutError)\n    this.name = 'HeadersTimeoutError'\n    this.message = message || 'Headers Timeout Error'\n    this.code = 'UND_ERR_HEADERS_TIMEOUT'\n  }\n}\n\nclass HeadersOverflowError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, HeadersOverflowError)\n    this.name = 'HeadersOverflowError'\n    this.message = message || 'Headers Overflow Error'\n    this.code = 'UND_ERR_HEADERS_OVERFLOW'\n  }\n}\n\nclass BodyTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, BodyTimeoutError)\n    this.name = 'BodyTimeoutError'\n    this.message = message || 'Body Timeout Error'\n    this.code = 'UND_ERR_BODY_TIMEOUT'\n  }\n}\n\nclass ResponseStatusCodeError extends UndiciError {\n  constructor (message, statusCode, headers, body) {\n    super(message)\n    Error.captureStackTrace(this, ResponseStatusCodeError)\n    this.name = 'ResponseStatusCodeError'\n    this.message = message || 'Response Status Code Error'\n    this.code = 'UND_ERR_RESPONSE_STATUS_CODE'\n    this.body = body\n    this.status = statusCode\n    this.statusCode = statusCode\n    this.headers = headers\n  }\n}\n\nclass InvalidArgumentError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, InvalidArgumentError)\n    this.name = 'InvalidArgumentError'\n    this.message = message || 'Invalid Argument Error'\n    this.code = 'UND_ERR_INVALID_ARG'\n  }\n}\n\nclass InvalidReturnValueError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, InvalidReturnValueError)\n    this.name = 'InvalidReturnValueError'\n    this.message = message || 'Invalid Return Value Error'\n    this.code = 'UND_ERR_INVALID_RETURN_VALUE'\n  }\n}\n\nclass RequestAbortedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, RequestAbortedError)\n    this.name = 'AbortError'\n    this.message = message || 'Request aborted'\n    this.code = 'UND_ERR_ABORTED'\n  }\n}\n\nclass InformationalError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, InformationalError)\n    this.name = 'InformationalError'\n    this.message = message || 'Request information'\n    this.code = 'UND_ERR_INFO'\n  }\n}\n\nclass RequestContentLengthMismatchError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, RequestContentLengthMismatchError)\n    this.name = 'RequestContentLengthMismatchError'\n    this.message = message || 'Request body length does not match content-length header'\n    this.code = 'UND_ERR_REQ_CONTENT_LENGTH_MISMATCH'\n  }\n}\n\nclass ResponseContentLengthMismatchError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ResponseContentLengthMismatchError)\n    this.name = 'ResponseContentLengthMismatchError'\n    this.message = message || 'Response body length does not match content-length header'\n    this.code = 'UND_ERR_RES_CONTENT_LENGTH_MISMATCH'\n  }\n}\n\nclass ClientDestroyedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ClientDestroyedError)\n    this.name = 'ClientDestroyedError'\n    this.message = message || 'The client is destroyed'\n    this.code = 'UND_ERR_DESTROYED'\n  }\n}\n\nclass ClientClosedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ClientClosedError)\n    this.name = 'ClientClosedError'\n    this.message = message || 'The client is closed'\n    this.code = 'UND_ERR_CLOSED'\n  }\n}\n\nclass SocketError extends UndiciError {\n  constructor (message, socket) {\n    super(message)\n    Error.captureStackTrace(this, SocketError)\n    this.name = 'SocketError'\n    this.message = message || 'Socket error'\n    this.code = 'UND_ERR_SOCKET'\n    this.socket = socket\n  }\n}\n\nclass NotSupportedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, NotSupportedError)\n    this.name = 'NotSupportedError'\n    this.message = message || 'Not supported error'\n    this.code = 'UND_ERR_NOT_SUPPORTED'\n  }\n}\n\nclass BalancedPoolMissingUpstreamError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, NotSupportedError)\n    this.name = 'MissingUpstreamError'\n    this.message = message || 'No upstream has been added to the BalancedPool'\n    this.code = 'UND_ERR_BPL_MISSING_UPSTREAM'\n  }\n}\n\nclass HTTPParserError extends Error {\n  constructor (message, code, data) {\n    super(message)\n    Error.captureStackTrace(this, HTTPParserError)\n    this.name = 'HTTPParserError'\n    this.code = code ? `HPE_${code}` : undefined\n    this.data = data ? data.toString() : undefined\n  }\n}\n\nclass ResponseExceededMaxSizeError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ResponseExceededMaxSizeError)\n    this.name = 'ResponseExceededMaxSizeError'\n    this.message = message || 'Response content exceeded max size'\n    this.code = 'UND_ERR_RES_EXCEEDED_MAX_SIZE'\n  }\n}\n\nclass RequestRetryError extends UndiciError {\n  constructor (message, code, { headers, data }) {\n    super(message)\n    Error.captureStackTrace(this, RequestRetryError)\n    this.name = 'RequestRetryError'\n    this.message = message || 'Request retry error'\n    this.code = 'UND_ERR_REQ_RETRY'\n    this.statusCode = code\n    this.data = data\n    this.headers = headers\n  }\n}\n\nmodule.exports = {\n  HTTPParserError,\n  UndiciError,\n  HeadersTimeoutError,\n  HeadersOverflowError,\n  BodyTimeoutError,\n  RequestContentLengthMismatchError,\n  ConnectTimeoutError,\n  ResponseStatusCodeError,\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError,\n  ClientDestroyedError,\n  ClientClosedError,\n  InformationalError,\n  SocketError,\n  NotSupportedError,\n  ResponseContentLengthMismatchError,\n  BalancedPoolMissingUpstreamError,\n  ResponseExceededMaxSizeError,\n  RequestRetryError\n}\n","'use strict'\n\nconst {\n  InvalidArgumentError,\n  NotSupportedError\n} = require('./errors')\nconst assert = require('assert')\nconst { kHTTP2BuildRequest, kHTTP2CopyHeaders, kHTTP1BuildRequest } = require('./symbols')\nconst util = require('./util')\n\n// tokenRegExp and headerCharRegex have been lifted from\n// https://github.com/nodejs/node/blob/main/lib/_http_common.js\n\n/**\n * Verifies that the given val is a valid HTTP token\n * per the rules defined in RFC 7230\n * See https://tools.ietf.org/html/rfc7230#section-3.2.6\n */\nconst tokenRegExp = /^[\\^_`a-zA-Z\\-0-9!#$%&'*+.|~]+$/\n\n/**\n * Matches if val contains an invalid field-vchar\n *  field-value    = *( field-content / obs-fold )\n *  field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]\n *  field-vchar    = VCHAR / obs-text\n */\nconst headerCharRegex = /[^\\t\\x20-\\x7e\\x80-\\xff]/\n\n// Verifies that a given path is valid does not contain control chars \\x00 to \\x20\nconst invalidPathRegex = /[^\\u0021-\\u00ff]/\n\nconst kHandler = Symbol('handler')\n\nconst channels = {}\n\nlet extractBody\n\ntry {\n  const diagnosticsChannel = require('diagnostics_channel')\n  channels.create = diagnosticsChannel.channel('undici:request:create')\n  channels.bodySent = diagnosticsChannel.channel('undici:request:bodySent')\n  channels.headers = diagnosticsChannel.channel('undici:request:headers')\n  channels.trailers = diagnosticsChannel.channel('undici:request:trailers')\n  channels.error = diagnosticsChannel.channel('undici:request:error')\n} catch {\n  channels.create = { hasSubscribers: false }\n  channels.bodySent = { hasSubscribers: false }\n  channels.headers = { hasSubscribers: false }\n  channels.trailers = { hasSubscribers: false }\n  channels.error = { hasSubscribers: false }\n}\n\nclass Request {\n  constructor (origin, {\n    path,\n    method,\n    body,\n    headers,\n    query,\n    idempotent,\n    blocking,\n    upgrade,\n    headersTimeout,\n    bodyTimeout,\n    reset,\n    throwOnError,\n    expectContinue\n  }, handler) {\n    if (typeof path !== 'string') {\n      throw new InvalidArgumentError('path must be a string')\n    } else if (\n      path[0] !== '/' &&\n      !(path.startsWith('http://') || path.startsWith('https://')) &&\n      method !== 'CONNECT'\n    ) {\n      throw new InvalidArgumentError('path must be an absolute URL or start with a slash')\n    } else if (invalidPathRegex.exec(path) !== null) {\n      throw new InvalidArgumentError('invalid request path')\n    }\n\n    if (typeof method !== 'string') {\n      throw new InvalidArgumentError('method must be a string')\n    } else if (tokenRegExp.exec(method) === null) {\n      throw new InvalidArgumentError('invalid request method')\n    }\n\n    if (upgrade && typeof upgrade !== 'string') {\n      throw new InvalidArgumentError('upgrade must be a string')\n    }\n\n    if (headersTimeout != null && (!Number.isFinite(headersTimeout) || headersTimeout < 0)) {\n      throw new InvalidArgumentError('invalid headersTimeout')\n    }\n\n    if (bodyTimeout != null && (!Number.isFinite(bodyTimeout) || bodyTimeout < 0)) {\n      throw new InvalidArgumentError('invalid bodyTimeout')\n    }\n\n    if (reset != null && typeof reset !== 'boolean') {\n      throw new InvalidArgumentError('invalid reset')\n    }\n\n    if (expectContinue != null && typeof expectContinue !== 'boolean') {\n      throw new InvalidArgumentError('invalid expectContinue')\n    }\n\n    this.headersTimeout = headersTimeout\n\n    this.bodyTimeout = bodyTimeout\n\n    this.throwOnError = throwOnError === true\n\n    this.method = method\n\n    this.abort = null\n\n    if (body == null) {\n      this.body = null\n    } else if (util.isStream(body)) {\n      this.body = body\n\n      const rState = this.body._readableState\n      if (!rState || !rState.autoDestroy) {\n        this.endHandler = function autoDestroy () {\n          util.destroy(this)\n        }\n        this.body.on('end', this.endHandler)\n      }\n\n      this.errorHandler = err => {\n        if (this.abort) {\n          this.abort(err)\n        } else {\n          this.error = err\n        }\n      }\n      this.body.on('error', this.errorHandler)\n    } else if (util.isBuffer(body)) {\n      this.body = body.byteLength ? body : null\n    } else if (ArrayBuffer.isView(body)) {\n      this.body = body.buffer.byteLength ? Buffer.from(body.buffer, body.byteOffset, body.byteLength) : null\n    } else if (body instanceof ArrayBuffer) {\n      this.body = body.byteLength ? Buffer.from(body) : null\n    } else if (typeof body === 'string') {\n      this.body = body.length ? Buffer.from(body) : null\n    } else if (util.isFormDataLike(body) || util.isIterable(body) || util.isBlobLike(body)) {\n      this.body = body\n    } else {\n      throw new InvalidArgumentError('body must be a string, a Buffer, a Readable stream, an iterable, or an async iterable')\n    }\n\n    this.completed = false\n\n    this.aborted = false\n\n    this.upgrade = upgrade || null\n\n    this.path = query ? util.buildURL(path, query) : path\n\n    this.origin = origin\n\n    this.idempotent = idempotent == null\n      ? method === 'HEAD' || method === 'GET'\n      : idempotent\n\n    this.blocking = blocking == null ? false : blocking\n\n    this.reset = reset == null ? null : reset\n\n    this.host = null\n\n    this.contentLength = null\n\n    this.contentType = null\n\n    this.headers = ''\n\n    // Only for H2\n    this.expectContinue = expectContinue != null ? expectContinue : false\n\n    if (Array.isArray(headers)) {\n      if (headers.length % 2 !== 0) {\n        throw new InvalidArgumentError('headers array must be even')\n      }\n      for (let i = 0; i < headers.length; i += 2) {\n        processHeader(this, headers[i], headers[i + 1])\n      }\n    } else if (headers && typeof headers === 'object') {\n      const keys = Object.keys(headers)\n      for (let i = 0; i < keys.length; i++) {\n        const key = keys[i]\n        processHeader(this, key, headers[key])\n      }\n    } else if (headers != null) {\n      throw new InvalidArgumentError('headers must be an object or an array')\n    }\n\n    if (util.isFormDataLike(this.body)) {\n      if (util.nodeMajor < 16 || (util.nodeMajor === 16 && util.nodeMinor < 8)) {\n        throw new InvalidArgumentError('Form-Data bodies are only supported in node v16.8 and newer.')\n      }\n\n      if (!extractBody) {\n        extractBody = require('../fetch/body.js').extractBody\n      }\n\n      const [bodyStream, contentType] = extractBody(body)\n      if (this.contentType == null) {\n        this.contentType = contentType\n        this.headers += `content-type: ${contentType}\\r\\n`\n      }\n      this.body = bodyStream.stream\n      this.contentLength = bodyStream.length\n    } else if (util.isBlobLike(body) && this.contentType == null && body.type) {\n      this.contentType = body.type\n      this.headers += `content-type: ${body.type}\\r\\n`\n    }\n\n    util.validateHandler(handler, method, upgrade)\n\n    this.servername = util.getServerName(this.host)\n\n    this[kHandler] = handler\n\n    if (channels.create.hasSubscribers) {\n      channels.create.publish({ request: this })\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this[kHandler].onBodySent) {\n      try {\n        return this[kHandler].onBodySent(chunk)\n      } catch (err) {\n        this.abort(err)\n      }\n    }\n  }\n\n  onRequestSent () {\n    if (channels.bodySent.hasSubscribers) {\n      channels.bodySent.publish({ request: this })\n    }\n\n    if (this[kHandler].onRequestSent) {\n      try {\n        return this[kHandler].onRequestSent()\n      } catch (err) {\n        this.abort(err)\n      }\n    }\n  }\n\n  onConnect (abort) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    if (this.error) {\n      abort(this.error)\n    } else {\n      this.abort = abort\n      return this[kHandler].onConnect(abort)\n    }\n  }\n\n  onHeaders (statusCode, headers, resume, statusText) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    if (channels.headers.hasSubscribers) {\n      channels.headers.publish({ request: this, response: { statusCode, headers, statusText } })\n    }\n\n    try {\n      return this[kHandler].onHeaders(statusCode, headers, resume, statusText)\n    } catch (err) {\n      this.abort(err)\n    }\n  }\n\n  onData (chunk) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    try {\n      return this[kHandler].onData(chunk)\n    } catch (err) {\n      this.abort(err)\n      return false\n    }\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    return this[kHandler].onUpgrade(statusCode, headers, socket)\n  }\n\n  onComplete (trailers) {\n    this.onFinally()\n\n    assert(!this.aborted)\n\n    this.completed = true\n    if (channels.trailers.hasSubscribers) {\n      channels.trailers.publish({ request: this, trailers })\n    }\n\n    try {\n      return this[kHandler].onComplete(trailers)\n    } catch (err) {\n      // TODO (fix): This might be a bad idea?\n      this.onError(err)\n    }\n  }\n\n  onError (error) {\n    this.onFinally()\n\n    if (channels.error.hasSubscribers) {\n      channels.error.publish({ request: this, error })\n    }\n\n    if (this.aborted) {\n      return\n    }\n    this.aborted = true\n\n    return this[kHandler].onError(error)\n  }\n\n  onFinally () {\n    if (this.errorHandler) {\n      this.body.off('error', this.errorHandler)\n      this.errorHandler = null\n    }\n\n    if (this.endHandler) {\n      this.body.off('end', this.endHandler)\n      this.endHandler = null\n    }\n  }\n\n  // TODO: adjust to support H2\n  addHeader (key, value) {\n    processHeader(this, key, value)\n    return this\n  }\n\n  static [kHTTP1BuildRequest] (origin, opts, handler) {\n    // TODO: Migrate header parsing here, to make Requests\n    // HTTP agnostic\n    return new Request(origin, opts, handler)\n  }\n\n  static [kHTTP2BuildRequest] (origin, opts, handler) {\n    const headers = opts.headers\n    opts = { ...opts, headers: null }\n\n    const request = new Request(origin, opts, handler)\n\n    request.headers = {}\n\n    if (Array.isArray(headers)) {\n      if (headers.length % 2 !== 0) {\n        throw new InvalidArgumentError('headers array must be even')\n      }\n      for (let i = 0; i < headers.length; i += 2) {\n        processHeader(request, headers[i], headers[i + 1], true)\n      }\n    } else if (headers && typeof headers === 'object') {\n      const keys = Object.keys(headers)\n      for (let i = 0; i < keys.length; i++) {\n        const key = keys[i]\n        processHeader(request, key, headers[key], true)\n      }\n    } else if (headers != null) {\n      throw new InvalidArgumentError('headers must be an object or an array')\n    }\n\n    return request\n  }\n\n  static [kHTTP2CopyHeaders] (raw) {\n    const rawHeaders = raw.split('\\r\\n')\n    const headers = {}\n\n    for (const header of rawHeaders) {\n      const [key, value] = header.split(': ')\n\n      if (value == null || value.length === 0) continue\n\n      if (headers[key]) headers[key] += `,${value}`\n      else headers[key] = value\n    }\n\n    return headers\n  }\n}\n\nfunction processHeaderValue (key, val, skipAppend) {\n  if (val && typeof val === 'object') {\n    throw new InvalidArgumentError(`invalid ${key} header`)\n  }\n\n  val = val != null ? `${val}` : ''\n\n  if (headerCharRegex.exec(val) !== null) {\n    throw new InvalidArgumentError(`invalid ${key} header`)\n  }\n\n  return skipAppend ? val : `${key}: ${val}\\r\\n`\n}\n\nfunction processHeader (request, key, val, skipAppend = false) {\n  if (val && (typeof val === 'object' && !Array.isArray(val))) {\n    throw new InvalidArgumentError(`invalid ${key} header`)\n  } else if (val === undefined) {\n    return\n  }\n\n  if (\n    request.host === null &&\n    key.length === 4 &&\n    key.toLowerCase() === 'host'\n  ) {\n    if (headerCharRegex.exec(val) !== null) {\n      throw new InvalidArgumentError(`invalid ${key} header`)\n    }\n    // Consumed by Client\n    request.host = val\n  } else if (\n    request.contentLength === null &&\n    key.length === 14 &&\n    key.toLowerCase() === 'content-length'\n  ) {\n    request.contentLength = parseInt(val, 10)\n    if (!Number.isFinite(request.contentLength)) {\n      throw new InvalidArgumentError('invalid content-length header')\n    }\n  } else if (\n    request.contentType === null &&\n    key.length === 12 &&\n    key.toLowerCase() === 'content-type'\n  ) {\n    request.contentType = val\n    if (skipAppend) request.headers[key] = processHeaderValue(key, val, skipAppend)\n    else request.headers += processHeaderValue(key, val)\n  } else if (\n    key.length === 17 &&\n    key.toLowerCase() === 'transfer-encoding'\n  ) {\n    throw new InvalidArgumentError('invalid transfer-encoding header')\n  } else if (\n    key.length === 10 &&\n    key.toLowerCase() === 'connection'\n  ) {\n    const value = typeof val === 'string' ? val.toLowerCase() : null\n    if (value !== 'close' && value !== 'keep-alive') {\n      throw new InvalidArgumentError('invalid connection header')\n    } else if (value === 'close') {\n      request.reset = true\n    }\n  } else if (\n    key.length === 10 &&\n    key.toLowerCase() === 'keep-alive'\n  ) {\n    throw new InvalidArgumentError('invalid keep-alive header')\n  } else if (\n    key.length === 7 &&\n    key.toLowerCase() === 'upgrade'\n  ) {\n    throw new InvalidArgumentError('invalid upgrade header')\n  } else if (\n    key.length === 6 &&\n    key.toLowerCase() === 'expect'\n  ) {\n    throw new NotSupportedError('expect header not supported')\n  } else if (tokenRegExp.exec(key) === null) {\n    throw new InvalidArgumentError('invalid header key')\n  } else {\n    if (Array.isArray(val)) {\n      for (let i = 0; i < val.length; i++) {\n        if (skipAppend) {\n          if (request.headers[key]) request.headers[key] += `,${processHeaderValue(key, val[i], skipAppend)}`\n          else request.headers[key] = processHeaderValue(key, val[i], skipAppend)\n        } else {\n          request.headers += processHeaderValue(key, val[i])\n        }\n      }\n    } else {\n      if (skipAppend) request.headers[key] = processHeaderValue(key, val, skipAppend)\n      else request.headers += processHeaderValue(key, val)\n    }\n  }\n}\n\nmodule.exports = Request\n","module.exports = {\n  kClose: Symbol('close'),\n  kDestroy: Symbol('destroy'),\n  kDispatch: Symbol('dispatch'),\n  kUrl: Symbol('url'),\n  kWriting: Symbol('writing'),\n  kResuming: Symbol('resuming'),\n  kQueue: Symbol('queue'),\n  kConnect: Symbol('connect'),\n  kConnecting: Symbol('connecting'),\n  kHeadersList: Symbol('headers list'),\n  kKeepAliveDefaultTimeout: Symbol('default keep alive timeout'),\n  kKeepAliveMaxTimeout: Symbol('max keep alive timeout'),\n  kKeepAliveTimeoutThreshold: Symbol('keep alive timeout threshold'),\n  kKeepAliveTimeoutValue: Symbol('keep alive timeout'),\n  kKeepAlive: Symbol('keep alive'),\n  kHeadersTimeout: Symbol('headers timeout'),\n  kBodyTimeout: Symbol('body timeout'),\n  kServerName: Symbol('server name'),\n  kLocalAddress: Symbol('local address'),\n  kHost: Symbol('host'),\n  kNoRef: Symbol('no ref'),\n  kBodyUsed: Symbol('used'),\n  kRunning: Symbol('running'),\n  kBlocking: Symbol('blocking'),\n  kPending: Symbol('pending'),\n  kSize: Symbol('size'),\n  kBusy: Symbol('busy'),\n  kQueued: Symbol('queued'),\n  kFree: Symbol('free'),\n  kConnected: Symbol('connected'),\n  kClosed: Symbol('closed'),\n  kNeedDrain: Symbol('need drain'),\n  kReset: Symbol('reset'),\n  kDestroyed: Symbol.for('nodejs.stream.destroyed'),\n  kMaxHeadersSize: Symbol('max headers size'),\n  kRunningIdx: Symbol('running index'),\n  kPendingIdx: Symbol('pending index'),\n  kError: Symbol('error'),\n  kClients: Symbol('clients'),\n  kClient: Symbol('client'),\n  kParser: Symbol('parser'),\n  kOnDestroyed: Symbol('destroy callbacks'),\n  kPipelining: Symbol('pipelining'),\n  kSocket: Symbol('socket'),\n  kHostHeader: Symbol('host header'),\n  kConnector: Symbol('connector'),\n  kStrictContentLength: Symbol('strict content length'),\n  kMaxRedirections: Symbol('maxRedirections'),\n  kMaxRequests: Symbol('maxRequestsPerClient'),\n  kProxy: Symbol('proxy agent options'),\n  kCounter: Symbol('socket request counter'),\n  kInterceptors: Symbol('dispatch interceptors'),\n  kMaxResponseSize: Symbol('max response size'),\n  kHTTP2Session: Symbol('http2Session'),\n  kHTTP2SessionState: Symbol('http2Session state'),\n  kHTTP2BuildRequest: Symbol('http2 build request'),\n  kHTTP1BuildRequest: Symbol('http1 build request'),\n  kHTTP2CopyHeaders: Symbol('http2 copy headers'),\n  kHTTPConnVersion: Symbol('http connection version'),\n  kRetryHandlerDefaultRetry: Symbol('retry agent default retry'),\n  kConstruct: Symbol('constructable')\n}\n","'use strict'\n\nconst assert = require('assert')\nconst { kDestroyed, kBodyUsed } = require('./symbols')\nconst { IncomingMessage } = require('http')\nconst stream = require('stream')\nconst net = require('net')\nconst { InvalidArgumentError } = require('./errors')\nconst { Blob } = require('buffer')\nconst nodeUtil = require('util')\nconst { stringify } = require('querystring')\nconst { headerNameLowerCasedRecord } = require('./constants')\n\nconst [nodeMajor, nodeMinor] = process.versions.node.split('.').map(v => Number(v))\n\nfunction nop () {}\n\nfunction isStream (obj) {\n  return obj && typeof obj === 'object' && typeof obj.pipe === 'function' && typeof obj.on === 'function'\n}\n\n// based on https://github.com/node-fetch/fetch-blob/blob/8ab587d34080de94140b54f07168451e7d0b655e/index.js#L229-L241 (MIT License)\nfunction isBlobLike (object) {\n  return (Blob && object instanceof Blob) || (\n    object &&\n    typeof object === 'object' &&\n    (typeof object.stream === 'function' ||\n      typeof object.arrayBuffer === 'function') &&\n    /^(Blob|File)$/.test(object[Symbol.toStringTag])\n  )\n}\n\nfunction buildURL (url, queryParams) {\n  if (url.includes('?') || url.includes('#')) {\n    throw new Error('Query params cannot be passed when url already contains \"?\" or \"#\".')\n  }\n\n  const stringified = stringify(queryParams)\n\n  if (stringified) {\n    url += '?' + stringified\n  }\n\n  return url\n}\n\nfunction parseURL (url) {\n  if (typeof url === 'string') {\n    url = new URL(url)\n\n    if (!/^https?:/.test(url.origin || url.protocol)) {\n      throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')\n    }\n\n    return url\n  }\n\n  if (!url || typeof url !== 'object') {\n    throw new InvalidArgumentError('Invalid URL: The URL argument must be a non-null object.')\n  }\n\n  if (!/^https?:/.test(url.origin || url.protocol)) {\n    throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')\n  }\n\n  if (!(url instanceof URL)) {\n    if (url.port != null && url.port !== '' && !Number.isFinite(parseInt(url.port))) {\n      throw new InvalidArgumentError('Invalid URL: port must be a valid integer or a string representation of an integer.')\n    }\n\n    if (url.path != null && typeof url.path !== 'string') {\n      throw new InvalidArgumentError('Invalid URL path: the path must be a string or null/undefined.')\n    }\n\n    if (url.pathname != null && typeof url.pathname !== 'string') {\n      throw new InvalidArgumentError('Invalid URL pathname: the pathname must be a string or null/undefined.')\n    }\n\n    if (url.hostname != null && typeof url.hostname !== 'string') {\n      throw new InvalidArgumentError('Invalid URL hostname: the hostname must be a string or null/undefined.')\n    }\n\n    if (url.origin != null && typeof url.origin !== 'string') {\n      throw new InvalidArgumentError('Invalid URL origin: the origin must be a string or null/undefined.')\n    }\n\n    const port = url.port != null\n      ? url.port\n      : (url.protocol === 'https:' ? 443 : 80)\n    let origin = url.origin != null\n      ? url.origin\n      : `${url.protocol}//${url.hostname}:${port}`\n    let path = url.path != null\n      ? url.path\n      : `${url.pathname || ''}${url.search || ''}`\n\n    if (origin.endsWith('/')) {\n      origin = origin.substring(0, origin.length - 1)\n    }\n\n    if (path && !path.startsWith('/')) {\n      path = `/${path}`\n    }\n    // new URL(path, origin) is unsafe when `path` contains an absolute URL\n    // From https://developer.mozilla.org/en-US/docs/Web/API/URL/URL:\n    // If first parameter is a relative URL, second param is required, and will be used as the base URL.\n    // If first parameter is an absolute URL, a given second param will be ignored.\n    url = new URL(origin + path)\n  }\n\n  return url\n}\n\nfunction parseOrigin (url) {\n  url = parseURL(url)\n\n  if (url.pathname !== '/' || url.search || url.hash) {\n    throw new InvalidArgumentError('invalid url')\n  }\n\n  return url\n}\n\nfunction getHostname (host) {\n  if (host[0] === '[') {\n    const idx = host.indexOf(']')\n\n    assert(idx !== -1)\n    return host.substring(1, idx)\n  }\n\n  const idx = host.indexOf(':')\n  if (idx === -1) return host\n\n  return host.substring(0, idx)\n}\n\n// IP addresses are not valid server names per RFC6066\n// > Currently, the only server names supported are DNS hostnames\nfunction getServerName (host) {\n  if (!host) {\n    return null\n  }\n\n  assert.strictEqual(typeof host, 'string')\n\n  const servername = getHostname(host)\n  if (net.isIP(servername)) {\n    return ''\n  }\n\n  return servername\n}\n\nfunction deepClone (obj) {\n  return JSON.parse(JSON.stringify(obj))\n}\n\nfunction isAsyncIterable (obj) {\n  return !!(obj != null && typeof obj[Symbol.asyncIterator] === 'function')\n}\n\nfunction isIterable (obj) {\n  return !!(obj != null && (typeof obj[Symbol.iterator] === 'function' || typeof obj[Symbol.asyncIterator] === 'function'))\n}\n\nfunction bodyLength (body) {\n  if (body == null) {\n    return 0\n  } else if (isStream(body)) {\n    const state = body._readableState\n    return state && state.objectMode === false && state.ended === true && Number.isFinite(state.length)\n      ? state.length\n      : null\n  } else if (isBlobLike(body)) {\n    return body.size != null ? body.size : null\n  } else if (isBuffer(body)) {\n    return body.byteLength\n  }\n\n  return null\n}\n\nfunction isDestroyed (stream) {\n  return !stream || !!(stream.destroyed || stream[kDestroyed])\n}\n\nfunction isReadableAborted (stream) {\n  const state = stream && stream._readableState\n  return isDestroyed(stream) && state && !state.endEmitted\n}\n\nfunction destroy (stream, err) {\n  if (stream == null || !isStream(stream) || isDestroyed(stream)) {\n    return\n  }\n\n  if (typeof stream.destroy === 'function') {\n    if (Object.getPrototypeOf(stream).constructor === IncomingMessage) {\n      // See: https://github.com/nodejs/node/pull/38505/files\n      stream.socket = null\n    }\n\n    stream.destroy(err)\n  } else if (err) {\n    process.nextTick((stream, err) => {\n      stream.emit('error', err)\n    }, stream, err)\n  }\n\n  if (stream.destroyed !== true) {\n    stream[kDestroyed] = true\n  }\n}\n\nconst KEEPALIVE_TIMEOUT_EXPR = /timeout=(\\d+)/\nfunction parseKeepAliveTimeout (val) {\n  const m = val.toString().match(KEEPALIVE_TIMEOUT_EXPR)\n  return m ? parseInt(m[1], 10) * 1000 : null\n}\n\n/**\n * Retrieves a header name and returns its lowercase value.\n * @param {string | Buffer} value Header name\n * @returns {string}\n */\nfunction headerNameToString (value) {\n  return headerNameLowerCasedRecord[value] || value.toLowerCase()\n}\n\nfunction parseHeaders (headers, obj = {}) {\n  // For H2 support\n  if (!Array.isArray(headers)) return headers\n\n  for (let i = 0; i < headers.length; i += 2) {\n    const key = headers[i].toString().toLowerCase()\n    let val = obj[key]\n\n    if (!val) {\n      if (Array.isArray(headers[i + 1])) {\n        obj[key] = headers[i + 1].map(x => x.toString('utf8'))\n      } else {\n        obj[key] = headers[i + 1].toString('utf8')\n      }\n    } else {\n      if (!Array.isArray(val)) {\n        val = [val]\n        obj[key] = val\n      }\n      val.push(headers[i + 1].toString('utf8'))\n    }\n  }\n\n  // See https://github.com/nodejs/node/pull/46528\n  if ('content-length' in obj && 'content-disposition' in obj) {\n    obj['content-disposition'] = Buffer.from(obj['content-disposition']).toString('latin1')\n  }\n\n  return obj\n}\n\nfunction parseRawHeaders (headers) {\n  const ret = []\n  let hasContentLength = false\n  let contentDispositionIdx = -1\n\n  for (let n = 0; n < headers.length; n += 2) {\n    const key = headers[n + 0].toString()\n    const val = headers[n + 1].toString('utf8')\n\n    if (key.length === 14 && (key === 'content-length' || key.toLowerCase() === 'content-length')) {\n      ret.push(key, val)\n      hasContentLength = true\n    } else if (key.length === 19 && (key === 'content-disposition' || key.toLowerCase() === 'content-disposition')) {\n      contentDispositionIdx = ret.push(key, val) - 1\n    } else {\n      ret.push(key, val)\n    }\n  }\n\n  // See https://github.com/nodejs/node/pull/46528\n  if (hasContentLength && contentDispositionIdx !== -1) {\n    ret[contentDispositionIdx] = Buffer.from(ret[contentDispositionIdx]).toString('latin1')\n  }\n\n  return ret\n}\n\nfunction isBuffer (buffer) {\n  // See, https://github.com/mcollina/undici/pull/319\n  return buffer instanceof Uint8Array || Buffer.isBuffer(buffer)\n}\n\nfunction validateHandler (handler, method, upgrade) {\n  if (!handler || typeof handler !== 'object') {\n    throw new InvalidArgumentError('handler must be an object')\n  }\n\n  if (typeof handler.onConnect !== 'function') {\n    throw new InvalidArgumentError('invalid onConnect method')\n  }\n\n  if (typeof handler.onError !== 'function') {\n    throw new InvalidArgumentError('invalid onError method')\n  }\n\n  if (typeof handler.onBodySent !== 'function' && handler.onBodySent !== undefined) {\n    throw new InvalidArgumentError('invalid onBodySent method')\n  }\n\n  if (upgrade || method === 'CONNECT') {\n    if (typeof handler.onUpgrade !== 'function') {\n      throw new InvalidArgumentError('invalid onUpgrade method')\n    }\n  } else {\n    if (typeof handler.onHeaders !== 'function') {\n      throw new InvalidArgumentError('invalid onHeaders method')\n    }\n\n    if (typeof handler.onData !== 'function') {\n      throw new InvalidArgumentError('invalid onData method')\n    }\n\n    if (typeof handler.onComplete !== 'function') {\n      throw new InvalidArgumentError('invalid onComplete method')\n    }\n  }\n}\n\n// A body is disturbed if it has been read from and it cannot\n// be re-used without losing state or data.\nfunction isDisturbed (body) {\n  return !!(body && (\n    stream.isDisturbed\n      ? stream.isDisturbed(body) || body[kBodyUsed] // TODO (fix): Why is body[kBodyUsed] needed?\n      : body[kBodyUsed] ||\n        body.readableDidRead ||\n        (body._readableState && body._readableState.dataEmitted) ||\n        isReadableAborted(body)\n  ))\n}\n\nfunction isErrored (body) {\n  return !!(body && (\n    stream.isErrored\n      ? stream.isErrored(body)\n      : /state: 'errored'/.test(nodeUtil.inspect(body)\n      )))\n}\n\nfunction isReadable (body) {\n  return !!(body && (\n    stream.isReadable\n      ? stream.isReadable(body)\n      : /state: 'readable'/.test(nodeUtil.inspect(body)\n      )))\n}\n\nfunction getSocketInfo (socket) {\n  return {\n    localAddress: socket.localAddress,\n    localPort: socket.localPort,\n    remoteAddress: socket.remoteAddress,\n    remotePort: socket.remotePort,\n    remoteFamily: socket.remoteFamily,\n    timeout: socket.timeout,\n    bytesWritten: socket.bytesWritten,\n    bytesRead: socket.bytesRead\n  }\n}\n\nasync function * convertIterableToBuffer (iterable) {\n  for await (const chunk of iterable) {\n    yield Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk)\n  }\n}\n\nlet ReadableStream\nfunction ReadableStreamFrom (iterable) {\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  if (ReadableStream.from) {\n    return ReadableStream.from(convertIterableToBuffer(iterable))\n  }\n\n  let iterator\n  return new ReadableStream(\n    {\n      async start () {\n        iterator = iterable[Symbol.asyncIterator]()\n      },\n      async pull (controller) {\n        const { done, value } = await iterator.next()\n        if (done) {\n          queueMicrotask(() => {\n            controller.close()\n          })\n        } else {\n          const buf = Buffer.isBuffer(value) ? value : Buffer.from(value)\n          controller.enqueue(new Uint8Array(buf))\n        }\n        return controller.desiredSize > 0\n      },\n      async cancel (reason) {\n        await iterator.return()\n      }\n    },\n    0\n  )\n}\n\n// The chunk should be a FormData instance and contains\n// all the required methods.\nfunction isFormDataLike (object) {\n  return (\n    object &&\n    typeof object === 'object' &&\n    typeof object.append === 'function' &&\n    typeof object.delete === 'function' &&\n    typeof object.get === 'function' &&\n    typeof object.getAll === 'function' &&\n    typeof object.has === 'function' &&\n    typeof object.set === 'function' &&\n    object[Symbol.toStringTag] === 'FormData'\n  )\n}\n\nfunction throwIfAborted (signal) {\n  if (!signal) { return }\n  if (typeof signal.throwIfAborted === 'function') {\n    signal.throwIfAborted()\n  } else {\n    if (signal.aborted) {\n      // DOMException not available < v17.0.0\n      const err = new Error('The operation was aborted')\n      err.name = 'AbortError'\n      throw err\n    }\n  }\n}\n\nfunction addAbortListener (signal, listener) {\n  if ('addEventListener' in signal) {\n    signal.addEventListener('abort', listener, { once: true })\n    return () => signal.removeEventListener('abort', listener)\n  }\n  signal.addListener('abort', listener)\n  return () => signal.removeListener('abort', listener)\n}\n\nconst hasToWellFormed = !!String.prototype.toWellFormed\n\n/**\n * @param {string} val\n */\nfunction toUSVString (val) {\n  if (hasToWellFormed) {\n    return `${val}`.toWellFormed()\n  } else if (nodeUtil.toUSVString) {\n    return nodeUtil.toUSVString(val)\n  }\n\n  return `${val}`\n}\n\n// Parsed accordingly to RFC 9110\n// https://www.rfc-editor.org/rfc/rfc9110#field.content-range\nfunction parseRangeHeader (range) {\n  if (range == null || range === '') return { start: 0, end: null, size: null }\n\n  const m = range ? range.match(/^bytes (\\d+)-(\\d+)\\/(\\d+)?$/) : null\n  return m\n    ? {\n        start: parseInt(m[1]),\n        end: m[2] ? parseInt(m[2]) : null,\n        size: m[3] ? parseInt(m[3]) : null\n      }\n    : null\n}\n\nconst kEnumerableProperty = Object.create(null)\nkEnumerableProperty.enumerable = true\n\nmodule.exports = {\n  kEnumerableProperty,\n  nop,\n  isDisturbed,\n  isErrored,\n  isReadable,\n  toUSVString,\n  isReadableAborted,\n  isBlobLike,\n  parseOrigin,\n  parseURL,\n  getServerName,\n  isStream,\n  isIterable,\n  isAsyncIterable,\n  isDestroyed,\n  headerNameToString,\n  parseRawHeaders,\n  parseHeaders,\n  parseKeepAliveTimeout,\n  destroy,\n  bodyLength,\n  deepClone,\n  ReadableStreamFrom,\n  isBuffer,\n  validateHandler,\n  getSocketInfo,\n  isFormDataLike,\n  buildURL,\n  throwIfAborted,\n  addAbortListener,\n  parseRangeHeader,\n  nodeMajor,\n  nodeMinor,\n  nodeHasAutoSelectFamily: nodeMajor > 18 || (nodeMajor === 18 && nodeMinor >= 13),\n  safeHTTPMethods: ['GET', 'HEAD', 'OPTIONS', 'TRACE']\n}\n","'use strict'\n\nconst Dispatcher = require('./dispatcher')\nconst {\n  ClientDestroyedError,\n  ClientClosedError,\n  InvalidArgumentError\n} = require('./core/errors')\nconst { kDestroy, kClose, kDispatch, kInterceptors } = require('./core/symbols')\n\nconst kDestroyed = Symbol('destroyed')\nconst kClosed = Symbol('closed')\nconst kOnDestroyed = Symbol('onDestroyed')\nconst kOnClosed = Symbol('onClosed')\nconst kInterceptedDispatch = Symbol('Intercepted Dispatch')\n\nclass DispatcherBase extends Dispatcher {\n  constructor () {\n    super()\n\n    this[kDestroyed] = false\n    this[kOnDestroyed] = null\n    this[kClosed] = false\n    this[kOnClosed] = []\n  }\n\n  get destroyed () {\n    return this[kDestroyed]\n  }\n\n  get closed () {\n    return this[kClosed]\n  }\n\n  get interceptors () {\n    return this[kInterceptors]\n  }\n\n  set interceptors (newInterceptors) {\n    if (newInterceptors) {\n      for (let i = newInterceptors.length - 1; i >= 0; i--) {\n        const interceptor = this[kInterceptors][i]\n        if (typeof interceptor !== 'function') {\n          throw new InvalidArgumentError('interceptor must be an function')\n        }\n      }\n    }\n\n    this[kInterceptors] = newInterceptors\n  }\n\n  close (callback) {\n    if (callback === undefined) {\n      return new Promise((resolve, reject) => {\n        this.close((err, data) => {\n          return err ? reject(err) : resolve(data)\n        })\n      })\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    if (this[kDestroyed]) {\n      queueMicrotask(() => callback(new ClientDestroyedError(), null))\n      return\n    }\n\n    if (this[kClosed]) {\n      if (this[kOnClosed]) {\n        this[kOnClosed].push(callback)\n      } else {\n        queueMicrotask(() => callback(null, null))\n      }\n      return\n    }\n\n    this[kClosed] = true\n    this[kOnClosed].push(callback)\n\n    const onClosed = () => {\n      const callbacks = this[kOnClosed]\n      this[kOnClosed] = null\n      for (let i = 0; i < callbacks.length; i++) {\n        callbacks[i](null, null)\n      }\n    }\n\n    // Should not error.\n    this[kClose]()\n      .then(() => this.destroy())\n      .then(() => {\n        queueMicrotask(onClosed)\n      })\n  }\n\n  destroy (err, callback) {\n    if (typeof err === 'function') {\n      callback = err\n      err = null\n    }\n\n    if (callback === undefined) {\n      return new Promise((resolve, reject) => {\n        this.destroy(err, (err, data) => {\n          return err ? /* istanbul ignore next: should never error */ reject(err) : resolve(data)\n        })\n      })\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    if (this[kDestroyed]) {\n      if (this[kOnDestroyed]) {\n        this[kOnDestroyed].push(callback)\n      } else {\n        queueMicrotask(() => callback(null, null))\n      }\n      return\n    }\n\n    if (!err) {\n      err = new ClientDestroyedError()\n    }\n\n    this[kDestroyed] = true\n    this[kOnDestroyed] = this[kOnDestroyed] || []\n    this[kOnDestroyed].push(callback)\n\n    const onDestroyed = () => {\n      const callbacks = this[kOnDestroyed]\n      this[kOnDestroyed] = null\n      for (let i = 0; i < callbacks.length; i++) {\n        callbacks[i](null, null)\n      }\n    }\n\n    // Should not error.\n    this[kDestroy](err).then(() => {\n      queueMicrotask(onDestroyed)\n    })\n  }\n\n  [kInterceptedDispatch] (opts, handler) {\n    if (!this[kInterceptors] || this[kInterceptors].length === 0) {\n      this[kInterceptedDispatch] = this[kDispatch]\n      return this[kDispatch](opts, handler)\n    }\n\n    let dispatch = this[kDispatch].bind(this)\n    for (let i = this[kInterceptors].length - 1; i >= 0; i--) {\n      dispatch = this[kInterceptors][i](dispatch)\n    }\n    this[kInterceptedDispatch] = dispatch\n    return dispatch(opts, handler)\n  }\n\n  dispatch (opts, handler) {\n    if (!handler || typeof handler !== 'object') {\n      throw new InvalidArgumentError('handler must be an object')\n    }\n\n    try {\n      if (!opts || typeof opts !== 'object') {\n        throw new InvalidArgumentError('opts must be an object.')\n      }\n\n      if (this[kDestroyed] || this[kOnDestroyed]) {\n        throw new ClientDestroyedError()\n      }\n\n      if (this[kClosed]) {\n        throw new ClientClosedError()\n      }\n\n      return this[kInterceptedDispatch](opts, handler)\n    } catch (err) {\n      if (typeof handler.onError !== 'function') {\n        throw new InvalidArgumentError('invalid onError method')\n      }\n\n      handler.onError(err)\n\n      return false\n    }\n  }\n}\n\nmodule.exports = DispatcherBase\n","'use strict'\n\nconst EventEmitter = require('events')\n\nclass Dispatcher extends EventEmitter {\n  dispatch () {\n    throw new Error('not implemented')\n  }\n\n  close () {\n    throw new Error('not implemented')\n  }\n\n  destroy () {\n    throw new Error('not implemented')\n  }\n}\n\nmodule.exports = Dispatcher\n","'use strict'\n\nconst Busboy = require('@fastify/busboy')\nconst util = require('../core/util')\nconst {\n  ReadableStreamFrom,\n  isBlobLike,\n  isReadableStreamLike,\n  readableStreamClose,\n  createDeferredPromise,\n  fullyReadBody\n} = require('./util')\nconst { FormData } = require('./formdata')\nconst { kState } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { DOMException, structuredClone } = require('./constants')\nconst { Blob, File: NativeFile } = require('buffer')\nconst { kBodyUsed } = require('../core/symbols')\nconst assert = require('assert')\nconst { isErrored } = require('../core/util')\nconst { isUint8Array, isArrayBuffer } = require('util/types')\nconst { File: UndiciFile } = require('./file')\nconst { parseMIMEType, serializeAMimeType } = require('./dataURL')\n\nlet random\ntry {\n  const crypto = require('node:crypto')\n  random = (max) => crypto.randomInt(0, max)\n} catch {\n  random = (max) => Math.floor(Math.random(max))\n}\n\nlet ReadableStream = globalThis.ReadableStream\n\n/** @type {globalThis['File']} */\nconst File = NativeFile ?? UndiciFile\nconst textEncoder = new TextEncoder()\nconst textDecoder = new TextDecoder()\n\n// https://fetch.spec.whatwg.org/#concept-bodyinit-extract\nfunction extractBody (object, keepalive = false) {\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  // 1. Let stream be null.\n  let stream = null\n\n  // 2. If object is a ReadableStream object, then set stream to object.\n  if (object instanceof ReadableStream) {\n    stream = object\n  } else if (isBlobLike(object)) {\n    // 3. Otherwise, if object is a Blob object, set stream to the\n    //    result of running objects get stream.\n    stream = object.stream()\n  } else {\n    // 4. Otherwise, set stream to a new ReadableStream object, and set\n    //    up stream.\n    stream = new ReadableStream({\n      async pull (controller) {\n        controller.enqueue(\n          typeof source === 'string' ? textEncoder.encode(source) : source\n        )\n        queueMicrotask(() => readableStreamClose(controller))\n      },\n      start () {},\n      type: undefined\n    })\n  }\n\n  // 5. Assert: stream is a ReadableStream object.\n  assert(isReadableStreamLike(stream))\n\n  // 6. Let action be null.\n  let action = null\n\n  // 7. Let source be null.\n  let source = null\n\n  // 8. Let length be null.\n  let length = null\n\n  // 9. Let type be null.\n  let type = null\n\n  // 10. Switch on object:\n  if (typeof object === 'string') {\n    // Set source to the UTF-8 encoding of object.\n    // Note: setting source to a Uint8Array here breaks some mocking assumptions.\n    source = object\n\n    // Set type to `text/plain;charset=UTF-8`.\n    type = 'text/plain;charset=UTF-8'\n  } else if (object instanceof URLSearchParams) {\n    // URLSearchParams\n\n    // spec says to run application/x-www-form-urlencoded on body.list\n    // this is implemented in Node.js as apart of an URLSearchParams instance toString method\n    // See: https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L490\n    // and https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L1100\n\n    // Set source to the result of running the application/x-www-form-urlencoded serializer with objects list.\n    source = object.toString()\n\n    // Set type to `application/x-www-form-urlencoded;charset=UTF-8`.\n    type = 'application/x-www-form-urlencoded;charset=UTF-8'\n  } else if (isArrayBuffer(object)) {\n    // BufferSource/ArrayBuffer\n\n    // Set source to a copy of the bytes held by object.\n    source = new Uint8Array(object.slice())\n  } else if (ArrayBuffer.isView(object)) {\n    // BufferSource/ArrayBufferView\n\n    // Set source to a copy of the bytes held by object.\n    source = new Uint8Array(object.buffer.slice(object.byteOffset, object.byteOffset + object.byteLength))\n  } else if (util.isFormDataLike(object)) {\n    const boundary = `----formdata-undici-0${`${random(1e11)}`.padStart(11, '0')}`\n    const prefix = `--${boundary}\\r\\nContent-Disposition: form-data`\n\n    /*! formdata-polyfill. MIT License. Jimmy Wrting <https://jimmy.warting.se/opensource> */\n    const escape = (str) =>\n      str.replace(/\\n/g, '%0A').replace(/\\r/g, '%0D').replace(/\"/g, '%22')\n    const normalizeLinefeeds = (value) => value.replace(/\\r?\\n|\\r/g, '\\r\\n')\n\n    // Set action to this step: run the multipart/form-data\n    // encoding algorithm, with objects entry list and UTF-8.\n    // - This ensures that the body is immutable and can't be changed afterwords\n    // - That the content-length is calculated in advance.\n    // - And that all parts are pre-encoded and ready to be sent.\n\n    const blobParts = []\n    const rn = new Uint8Array([13, 10]) // '\\r\\n'\n    length = 0\n    let hasUnknownSizeValue = false\n\n    for (const [name, value] of object) {\n      if (typeof value === 'string') {\n        const chunk = textEncoder.encode(prefix +\n          `; name=\"${escape(normalizeLinefeeds(name))}\"` +\n          `\\r\\n\\r\\n${normalizeLinefeeds(value)}\\r\\n`)\n        blobParts.push(chunk)\n        length += chunk.byteLength\n      } else {\n        const chunk = textEncoder.encode(`${prefix}; name=\"${escape(normalizeLinefeeds(name))}\"` +\n          (value.name ? `; filename=\"${escape(value.name)}\"` : '') + '\\r\\n' +\n          `Content-Type: ${\n            value.type || 'application/octet-stream'\n          }\\r\\n\\r\\n`)\n        blobParts.push(chunk, value, rn)\n        if (typeof value.size === 'number') {\n          length += chunk.byteLength + value.size + rn.byteLength\n        } else {\n          hasUnknownSizeValue = true\n        }\n      }\n    }\n\n    const chunk = textEncoder.encode(`--${boundary}--`)\n    blobParts.push(chunk)\n    length += chunk.byteLength\n    if (hasUnknownSizeValue) {\n      length = null\n    }\n\n    // Set source to object.\n    source = object\n\n    action = async function * () {\n      for (const part of blobParts) {\n        if (part.stream) {\n          yield * part.stream()\n        } else {\n          yield part\n        }\n      }\n    }\n\n    // Set type to `multipart/form-data; boundary=`,\n    // followed by the multipart/form-data boundary string generated\n    // by the multipart/form-data encoding algorithm.\n    type = 'multipart/form-data; boundary=' + boundary\n  } else if (isBlobLike(object)) {\n    // Blob\n\n    // Set source to object.\n    source = object\n\n    // Set length to objects size.\n    length = object.size\n\n    // If objects type attribute is not the empty byte sequence, set\n    // type to its value.\n    if (object.type) {\n      type = object.type\n    }\n  } else if (typeof object[Symbol.asyncIterator] === 'function') {\n    // If keepalive is true, then throw a TypeError.\n    if (keepalive) {\n      throw new TypeError('keepalive')\n    }\n\n    // If object is disturbed or locked, then throw a TypeError.\n    if (util.isDisturbed(object) || object.locked) {\n      throw new TypeError(\n        'Response body object should not be disturbed or locked'\n      )\n    }\n\n    stream =\n      object instanceof ReadableStream ? object : ReadableStreamFrom(object)\n  }\n\n  // 11. If source is a byte sequence, then set action to a\n  // step that returns source and length to sources length.\n  if (typeof source === 'string' || util.isBuffer(source)) {\n    length = Buffer.byteLength(source)\n  }\n\n  // 12. If action is non-null, then run these steps in in parallel:\n  if (action != null) {\n    // Run action.\n    let iterator\n    stream = new ReadableStream({\n      async start () {\n        iterator = action(object)[Symbol.asyncIterator]()\n      },\n      async pull (controller) {\n        const { value, done } = await iterator.next()\n        if (done) {\n          // When running action is done, close stream.\n          queueMicrotask(() => {\n            controller.close()\n          })\n        } else {\n          // Whenever one or more bytes are available and stream is not errored,\n          // enqueue a Uint8Array wrapping an ArrayBuffer containing the available\n          // bytes into stream.\n          if (!isErrored(stream)) {\n            controller.enqueue(new Uint8Array(value))\n          }\n        }\n        return controller.desiredSize > 0\n      },\n      async cancel (reason) {\n        await iterator.return()\n      },\n      type: undefined\n    })\n  }\n\n  // 13. Let body be a body whose stream is stream, source is source,\n  // and length is length.\n  const body = { stream, source, length }\n\n  // 14. Return (body, type).\n  return [body, type]\n}\n\n// https://fetch.spec.whatwg.org/#bodyinit-safely-extract\nfunction safelyExtractBody (object, keepalive = false) {\n  if (!ReadableStream) {\n    // istanbul ignore next\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  // To safely extract a body and a `Content-Type` value from\n  // a byte sequence or BodyInit object object, run these steps:\n\n  // 1. If object is a ReadableStream object, then:\n  if (object instanceof ReadableStream) {\n    // Assert: object is neither disturbed nor locked.\n    // istanbul ignore next\n    assert(!util.isDisturbed(object), 'The body has already been consumed.')\n    // istanbul ignore next\n    assert(!object.locked, 'The stream is locked.')\n  }\n\n  // 2. Return the results of extracting object.\n  return extractBody(object, keepalive)\n}\n\nfunction cloneBody (body) {\n  // To clone a body body, run these steps:\n\n  // https://fetch.spec.whatwg.org/#concept-body-clone\n\n  // 1. Let  out1, out2  be the result of teeing bodys stream.\n  const [out1, out2] = body.stream.tee()\n  const out2Clone = structuredClone(out2, { transfer: [out2] })\n  // This, for whatever reasons, unrefs out2Clone which allows\n  // the process to exit by itself.\n  const [, finalClone] = out2Clone.tee()\n\n  // 2. Set bodys stream to out1.\n  body.stream = out1\n\n  // 3. Return a body whose stream is out2 and other members are copied from body.\n  return {\n    stream: finalClone,\n    length: body.length,\n    source: body.source\n  }\n}\n\nasync function * consumeBody (body) {\n  if (body) {\n    if (isUint8Array(body)) {\n      yield body\n    } else {\n      const stream = body.stream\n\n      if (util.isDisturbed(stream)) {\n        throw new TypeError('The body has already been consumed.')\n      }\n\n      if (stream.locked) {\n        throw new TypeError('The stream is locked.')\n      }\n\n      // Compat.\n      stream[kBodyUsed] = true\n\n      yield * stream\n    }\n  }\n}\n\nfunction throwIfAborted (state) {\n  if (state.aborted) {\n    throw new DOMException('The operation was aborted.', 'AbortError')\n  }\n}\n\nfunction bodyMixinMethods (instance) {\n  const methods = {\n    blob () {\n      // The blob() method steps are to return the result of\n      // running consume body with this and the following step\n      // given a byte sequence bytes: return a Blob whose\n      // contents are bytes and whose type attribute is thiss\n      // MIME type.\n      return specConsumeBody(this, (bytes) => {\n        let mimeType = bodyMimeType(this)\n\n        if (mimeType === 'failure') {\n          mimeType = ''\n        } else if (mimeType) {\n          mimeType = serializeAMimeType(mimeType)\n        }\n\n        // Return a Blob whose contents are bytes and type attribute\n        // is mimeType.\n        return new Blob([bytes], { type: mimeType })\n      }, instance)\n    },\n\n    arrayBuffer () {\n      // The arrayBuffer() method steps are to return the result\n      // of running consume body with this and the following step\n      // given a byte sequence bytes: return a new ArrayBuffer\n      // whose contents are bytes.\n      return specConsumeBody(this, (bytes) => {\n        return new Uint8Array(bytes).buffer\n      }, instance)\n    },\n\n    text () {\n      // The text() method steps are to return the result of running\n      // consume body with this and UTF-8 decode.\n      return specConsumeBody(this, utf8DecodeBytes, instance)\n    },\n\n    json () {\n      // The json() method steps are to return the result of running\n      // consume body with this and parse JSON from bytes.\n      return specConsumeBody(this, parseJSONFromBytes, instance)\n    },\n\n    async formData () {\n      webidl.brandCheck(this, instance)\n\n      throwIfAborted(this[kState])\n\n      const contentType = this.headers.get('Content-Type')\n\n      // If mimeTypes essence is \"multipart/form-data\", then:\n      if (/multipart\\/form-data/.test(contentType)) {\n        const headers = {}\n        for (const [key, value] of this.headers) headers[key.toLowerCase()] = value\n\n        const responseFormData = new FormData()\n\n        let busboy\n\n        try {\n          busboy = new Busboy({\n            headers,\n            preservePath: true\n          })\n        } catch (err) {\n          throw new DOMException(`${err}`, 'AbortError')\n        }\n\n        busboy.on('field', (name, value) => {\n          responseFormData.append(name, value)\n        })\n        busboy.on('file', (name, value, filename, encoding, mimeType) => {\n          const chunks = []\n\n          if (encoding === 'base64' || encoding.toLowerCase() === 'base64') {\n            let base64chunk = ''\n\n            value.on('data', (chunk) => {\n              base64chunk += chunk.toString().replace(/[\\r\\n]/gm, '')\n\n              const end = base64chunk.length - base64chunk.length % 4\n              chunks.push(Buffer.from(base64chunk.slice(0, end), 'base64'))\n\n              base64chunk = base64chunk.slice(end)\n            })\n            value.on('end', () => {\n              chunks.push(Buffer.from(base64chunk, 'base64'))\n              responseFormData.append(name, new File(chunks, filename, { type: mimeType }))\n            })\n          } else {\n            value.on('data', (chunk) => {\n              chunks.push(chunk)\n            })\n            value.on('end', () => {\n              responseFormData.append(name, new File(chunks, filename, { type: mimeType }))\n            })\n          }\n        })\n\n        const busboyResolve = new Promise((resolve, reject) => {\n          busboy.on('finish', resolve)\n          busboy.on('error', (err) => reject(new TypeError(err)))\n        })\n\n        if (this.body !== null) for await (const chunk of consumeBody(this[kState].body)) busboy.write(chunk)\n        busboy.end()\n        await busboyResolve\n\n        return responseFormData\n      } else if (/application\\/x-www-form-urlencoded/.test(contentType)) {\n        // Otherwise, if mimeTypes essence is \"application/x-www-form-urlencoded\", then:\n\n        // 1. Let entries be the result of parsing bytes.\n        let entries\n        try {\n          let text = ''\n          // application/x-www-form-urlencoded parser will keep the BOM.\n          // https://url.spec.whatwg.org/#concept-urlencoded-parser\n          // Note that streaming decoder is stateful and cannot be reused\n          const streamingDecoder = new TextDecoder('utf-8', { ignoreBOM: true })\n\n          for await (const chunk of consumeBody(this[kState].body)) {\n            if (!isUint8Array(chunk)) {\n              throw new TypeError('Expected Uint8Array chunk')\n            }\n            text += streamingDecoder.decode(chunk, { stream: true })\n          }\n          text += streamingDecoder.decode()\n          entries = new URLSearchParams(text)\n        } catch (err) {\n          // istanbul ignore next: Unclear when new URLSearchParams can fail on a string.\n          // 2. If entries is failure, then throw a TypeError.\n          throw Object.assign(new TypeError(), { cause: err })\n        }\n\n        // 3. Return a new FormData object whose entries are entries.\n        const formData = new FormData()\n        for (const [name, value] of entries) {\n          formData.append(name, value)\n        }\n        return formData\n      } else {\n        // Wait a tick before checking if the request has been aborted.\n        // Otherwise, a TypeError can be thrown when an AbortError should.\n        await Promise.resolve()\n\n        throwIfAborted(this[kState])\n\n        // Otherwise, throw a TypeError.\n        throw webidl.errors.exception({\n          header: `${instance.name}.formData`,\n          message: 'Could not parse content as FormData.'\n        })\n      }\n    }\n  }\n\n  return methods\n}\n\nfunction mixinBody (prototype) {\n  Object.assign(prototype.prototype, bodyMixinMethods(prototype))\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-body-consume-body\n * @param {Response|Request} object\n * @param {(value: unknown) => unknown} convertBytesToJSValue\n * @param {Response|Request} instance\n */\nasync function specConsumeBody (object, convertBytesToJSValue, instance) {\n  webidl.brandCheck(object, instance)\n\n  throwIfAborted(object[kState])\n\n  // 1. If object is unusable, then return a promise rejected\n  //    with a TypeError.\n  if (bodyUnusable(object[kState].body)) {\n    throw new TypeError('Body is unusable')\n  }\n\n  // 2. Let promise be a new promise.\n  const promise = createDeferredPromise()\n\n  // 3. Let errorSteps given error be to reject promise with error.\n  const errorSteps = (error) => promise.reject(error)\n\n  // 4. Let successSteps given a byte sequence data be to resolve\n  //    promise with the result of running convertBytesToJSValue\n  //    with data. If that threw an exception, then run errorSteps\n  //    with that exception.\n  const successSteps = (data) => {\n    try {\n      promise.resolve(convertBytesToJSValue(data))\n    } catch (e) {\n      errorSteps(e)\n    }\n  }\n\n  // 5. If objects body is null, then run successSteps with an\n  //    empty byte sequence.\n  if (object[kState].body == null) {\n    successSteps(new Uint8Array())\n    return promise.promise\n  }\n\n  // 6. Otherwise, fully read objects body given successSteps,\n  //    errorSteps, and objects relevant global object.\n  await fullyReadBody(object[kState].body, successSteps, errorSteps)\n\n  // 7. Return promise.\n  return promise.promise\n}\n\n// https://fetch.spec.whatwg.org/#body-unusable\nfunction bodyUnusable (body) {\n  // An object including the Body interface mixin is\n  // said to be unusable if its body is non-null and\n  // its bodys stream is disturbed or locked.\n  return body != null && (body.stream.locked || util.isDisturbed(body.stream))\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#utf-8-decode\n * @param {Buffer} buffer\n */\nfunction utf8DecodeBytes (buffer) {\n  if (buffer.length === 0) {\n    return ''\n  }\n\n  // 1. Let buffer be the result of peeking three bytes from\n  //    ioQueue, converted to a byte sequence.\n\n  // 2. If buffer is 0xEF 0xBB 0xBF, then read three\n  //    bytes from ioQueue. (Do nothing with those bytes.)\n  if (buffer[0] === 0xEF && buffer[1] === 0xBB && buffer[2] === 0xBF) {\n    buffer = buffer.subarray(3)\n  }\n\n  // 3. Process a queue with an instance of UTF-8s\n  //    decoder, ioQueue, output, and \"replacement\".\n  const output = textDecoder.decode(buffer)\n\n  // 4. Return output.\n  return output\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#parse-json-bytes-to-a-javascript-value\n * @param {Uint8Array} bytes\n */\nfunction parseJSONFromBytes (bytes) {\n  return JSON.parse(utf8DecodeBytes(bytes))\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-body-mime-type\n * @param {import('./response').Response|import('./request').Request} object\n */\nfunction bodyMimeType (object) {\n  const { headersList } = object[kState]\n  const contentType = headersList.get('content-type')\n\n  if (contentType === null) {\n    return 'failure'\n  }\n\n  return parseMIMEType(contentType)\n}\n\nmodule.exports = {\n  extractBody,\n  safelyExtractBody,\n  cloneBody,\n  mixinBody\n}\n","'use strict'\n\nconst { MessageChannel, receiveMessageOnPort } = require('worker_threads')\n\nconst corsSafeListedMethods = ['GET', 'HEAD', 'POST']\nconst corsSafeListedMethodsSet = new Set(corsSafeListedMethods)\n\nconst nullBodyStatus = [101, 204, 205, 304]\n\nconst redirectStatus = [301, 302, 303, 307, 308]\nconst redirectStatusSet = new Set(redirectStatus)\n\n// https://fetch.spec.whatwg.org/#block-bad-port\nconst badPorts = [\n  '1', '7', '9', '11', '13', '15', '17', '19', '20', '21', '22', '23', '25', '37', '42', '43', '53', '69', '77', '79',\n  '87', '95', '101', '102', '103', '104', '109', '110', '111', '113', '115', '117', '119', '123', '135', '137',\n  '139', '143', '161', '179', '389', '427', '465', '512', '513', '514', '515', '526', '530', '531', '532',\n  '540', '548', '554', '556', '563', '587', '601', '636', '989', '990', '993', '995', '1719', '1720', '1723',\n  '2049', '3659', '4045', '5060', '5061', '6000', '6566', '6665', '6666', '6667', '6668', '6669', '6697',\n  '10080'\n]\n\nconst badPortsSet = new Set(badPorts)\n\n// https://w3c.github.io/webappsec-referrer-policy/#referrer-policies\nconst referrerPolicy = [\n  '',\n  'no-referrer',\n  'no-referrer-when-downgrade',\n  'same-origin',\n  'origin',\n  'strict-origin',\n  'origin-when-cross-origin',\n  'strict-origin-when-cross-origin',\n  'unsafe-url'\n]\nconst referrerPolicySet = new Set(referrerPolicy)\n\nconst requestRedirect = ['follow', 'manual', 'error']\n\nconst safeMethods = ['GET', 'HEAD', 'OPTIONS', 'TRACE']\nconst safeMethodsSet = new Set(safeMethods)\n\nconst requestMode = ['navigate', 'same-origin', 'no-cors', 'cors']\n\nconst requestCredentials = ['omit', 'same-origin', 'include']\n\nconst requestCache = [\n  'default',\n  'no-store',\n  'reload',\n  'no-cache',\n  'force-cache',\n  'only-if-cached'\n]\n\n// https://fetch.spec.whatwg.org/#request-body-header-name\nconst requestBodyHeader = [\n  'content-encoding',\n  'content-language',\n  'content-location',\n  'content-type',\n  // See https://github.com/nodejs/undici/issues/2021\n  // 'Content-Length' is a forbidden header name, which is typically\n  // removed in the Headers implementation. However, undici doesn't\n  // filter out headers, so we add it here.\n  'content-length'\n]\n\n// https://fetch.spec.whatwg.org/#enumdef-requestduplex\nconst requestDuplex = [\n  'half'\n]\n\n// http://fetch.spec.whatwg.org/#forbidden-method\nconst forbiddenMethods = ['CONNECT', 'TRACE', 'TRACK']\nconst forbiddenMethodsSet = new Set(forbiddenMethods)\n\nconst subresource = [\n  'audio',\n  'audioworklet',\n  'font',\n  'image',\n  'manifest',\n  'paintworklet',\n  'script',\n  'style',\n  'track',\n  'video',\n  'xslt',\n  ''\n]\nconst subresourceSet = new Set(subresource)\n\n/** @type {globalThis['DOMException']} */\nconst DOMException = globalThis.DOMException ?? (() => {\n  // DOMException was only made a global in Node v17.0.0,\n  // but fetch supports >= v16.8.\n  try {\n    atob('~')\n  } catch (err) {\n    return Object.getPrototypeOf(err).constructor\n  }\n})()\n\nlet channel\n\n/** @type {globalThis['structuredClone']} */\nconst structuredClone =\n  globalThis.structuredClone ??\n  // https://github.com/nodejs/node/blob/b27ae24dcc4251bad726d9d84baf678d1f707fed/lib/internal/structured_clone.js\n  // structuredClone was added in v17.0.0, but fetch supports v16.8\n  function structuredClone (value, options = undefined) {\n    if (arguments.length === 0) {\n      throw new TypeError('missing argument')\n    }\n\n    if (!channel) {\n      channel = new MessageChannel()\n    }\n    channel.port1.unref()\n    channel.port2.unref()\n    channel.port1.postMessage(value, options?.transfer)\n    return receiveMessageOnPort(channel.port2).message\n  }\n\nmodule.exports = {\n  DOMException,\n  structuredClone,\n  subresource,\n  forbiddenMethods,\n  requestBodyHeader,\n  referrerPolicy,\n  requestRedirect,\n  requestMode,\n  requestCredentials,\n  requestCache,\n  redirectStatus,\n  corsSafeListedMethods,\n  nullBodyStatus,\n  safeMethods,\n  badPorts,\n  requestDuplex,\n  subresourceSet,\n  badPortsSet,\n  redirectStatusSet,\n  corsSafeListedMethodsSet,\n  safeMethodsSet,\n  forbiddenMethodsSet,\n  referrerPolicySet\n}\n","const assert = require('assert')\nconst { atob } = require('buffer')\nconst { isomorphicDecode } = require('./util')\n\nconst encoder = new TextEncoder()\n\n/**\n * @see https://mimesniff.spec.whatwg.org/#http-token-code-point\n */\nconst HTTP_TOKEN_CODEPOINTS = /^[!#$%&'*+-.^_|~A-Za-z0-9]+$/\nconst HTTP_WHITESPACE_REGEX = /(\\u000A|\\u000D|\\u0009|\\u0020)/ // eslint-disable-line\n/**\n * @see https://mimesniff.spec.whatwg.org/#http-quoted-string-token-code-point\n */\nconst HTTP_QUOTED_STRING_TOKENS = /[\\u0009|\\u0020-\\u007E|\\u0080-\\u00FF]/ // eslint-disable-line\n\n// https://fetch.spec.whatwg.org/#data-url-processor\n/** @param {URL} dataURL */\nfunction dataURLProcessor (dataURL) {\n  // 1. Assert: dataURLs scheme is \"data\".\n  assert(dataURL.protocol === 'data:')\n\n  // 2. Let input be the result of running the URL\n  // serializer on dataURL with exclude fragment\n  // set to true.\n  let input = URLSerializer(dataURL, true)\n\n  // 3. Remove the leading \"data:\" string from input.\n  input = input.slice(5)\n\n  // 4. Let position point at the start of input.\n  const position = { position: 0 }\n\n  // 5. Let mimeType be the result of collecting a\n  // sequence of code points that are not equal\n  // to U+002C (,), given position.\n  let mimeType = collectASequenceOfCodePointsFast(\n    ',',\n    input,\n    position\n  )\n\n  // 6. Strip leading and trailing ASCII whitespace\n  // from mimeType.\n  // Undici implementation note: we need to store the\n  // length because if the mimetype has spaces removed,\n  // the wrong amount will be sliced from the input in\n  // step #9\n  const mimeTypeLength = mimeType.length\n  mimeType = removeASCIIWhitespace(mimeType, true, true)\n\n  // 7. If position is past the end of input, then\n  // return failure\n  if (position.position >= input.length) {\n    return 'failure'\n  }\n\n  // 8. Advance position by 1.\n  position.position++\n\n  // 9. Let encodedBody be the remainder of input.\n  const encodedBody = input.slice(mimeTypeLength + 1)\n\n  // 10. Let body be the percent-decoding of encodedBody.\n  let body = stringPercentDecode(encodedBody)\n\n  // 11. If mimeType ends with U+003B (;), followed by\n  // zero or more U+0020 SPACE, followed by an ASCII\n  // case-insensitive match for \"base64\", then:\n  if (/;(\\u0020){0,}base64$/i.test(mimeType)) {\n    // 1. Let stringBody be the isomorphic decode of body.\n    const stringBody = isomorphicDecode(body)\n\n    // 2. Set body to the forgiving-base64 decode of\n    // stringBody.\n    body = forgivingBase64(stringBody)\n\n    // 3. If body is failure, then return failure.\n    if (body === 'failure') {\n      return 'failure'\n    }\n\n    // 4. Remove the last 6 code points from mimeType.\n    mimeType = mimeType.slice(0, -6)\n\n    // 5. Remove trailing U+0020 SPACE code points from mimeType,\n    // if any.\n    mimeType = mimeType.replace(/(\\u0020)+$/, '')\n\n    // 6. Remove the last U+003B (;) code point from mimeType.\n    mimeType = mimeType.slice(0, -1)\n  }\n\n  // 12. If mimeType starts with U+003B (;), then prepend\n  // \"text/plain\" to mimeType.\n  if (mimeType.startsWith(';')) {\n    mimeType = 'text/plain' + mimeType\n  }\n\n  // 13. Let mimeTypeRecord be the result of parsing\n  // mimeType.\n  let mimeTypeRecord = parseMIMEType(mimeType)\n\n  // 14. If mimeTypeRecord is failure, then set\n  // mimeTypeRecord to text/plain;charset=US-ASCII.\n  if (mimeTypeRecord === 'failure') {\n    mimeTypeRecord = parseMIMEType('text/plain;charset=US-ASCII')\n  }\n\n  // 15. Return a new data: URL struct whose MIME\n  // type is mimeTypeRecord and body is body.\n  // https://fetch.spec.whatwg.org/#data-url-struct\n  return { mimeType: mimeTypeRecord, body }\n}\n\n// https://url.spec.whatwg.org/#concept-url-serializer\n/**\n * @param {URL} url\n * @param {boolean} excludeFragment\n */\nfunction URLSerializer (url, excludeFragment = false) {\n  if (!excludeFragment) {\n    return url.href\n  }\n\n  const href = url.href\n  const hashLength = url.hash.length\n\n  return hashLength === 0 ? href : href.substring(0, href.length - hashLength)\n}\n\n// https://infra.spec.whatwg.org/#collect-a-sequence-of-code-points\n/**\n * @param {(char: string) => boolean} condition\n * @param {string} input\n * @param {{ position: number }} position\n */\nfunction collectASequenceOfCodePoints (condition, input, position) {\n  // 1. Let result be the empty string.\n  let result = ''\n\n  // 2. While position doesnt point past the end of input and the\n  // code point at position within input meets the condition condition:\n  while (position.position < input.length && condition(input[position.position])) {\n    // 1. Append that code point to the end of result.\n    result += input[position.position]\n\n    // 2. Advance position by 1.\n    position.position++\n  }\n\n  // 3. Return result.\n  return result\n}\n\n/**\n * A faster collectASequenceOfCodePoints that only works when comparing a single character.\n * @param {string} char\n * @param {string} input\n * @param {{ position: number }} position\n */\nfunction collectASequenceOfCodePointsFast (char, input, position) {\n  const idx = input.indexOf(char, position.position)\n  const start = position.position\n\n  if (idx === -1) {\n    position.position = input.length\n    return input.slice(start)\n  }\n\n  position.position = idx\n  return input.slice(start, position.position)\n}\n\n// https://url.spec.whatwg.org/#string-percent-decode\n/** @param {string} input */\nfunction stringPercentDecode (input) {\n  // 1. Let bytes be the UTF-8 encoding of input.\n  const bytes = encoder.encode(input)\n\n  // 2. Return the percent-decoding of bytes.\n  return percentDecode(bytes)\n}\n\n// https://url.spec.whatwg.org/#percent-decode\n/** @param {Uint8Array} input */\nfunction percentDecode (input) {\n  // 1. Let output be an empty byte sequence.\n  /** @type {number[]} */\n  const output = []\n\n  // 2. For each byte byte in input:\n  for (let i = 0; i < input.length; i++) {\n    const byte = input[i]\n\n    // 1. If byte is not 0x25 (%), then append byte to output.\n    if (byte !== 0x25) {\n      output.push(byte)\n\n    // 2. Otherwise, if byte is 0x25 (%) and the next two bytes\n    // after byte in input are not in the ranges\n    // 0x30 (0) to 0x39 (9), 0x41 (A) to 0x46 (F),\n    // and 0x61 (a) to 0x66 (f), all inclusive, append byte\n    // to output.\n    } else if (\n      byte === 0x25 &&\n      !/^[0-9A-Fa-f]{2}$/i.test(String.fromCharCode(input[i + 1], input[i + 2]))\n    ) {\n      output.push(0x25)\n\n    // 3. Otherwise:\n    } else {\n      // 1. Let bytePoint be the two bytes after byte in input,\n      // decoded, and then interpreted as hexadecimal number.\n      const nextTwoBytes = String.fromCharCode(input[i + 1], input[i + 2])\n      const bytePoint = Number.parseInt(nextTwoBytes, 16)\n\n      // 2. Append a byte whose value is bytePoint to output.\n      output.push(bytePoint)\n\n      // 3. Skip the next two bytes in input.\n      i += 2\n    }\n  }\n\n  // 3. Return output.\n  return Uint8Array.from(output)\n}\n\n// https://mimesniff.spec.whatwg.org/#parse-a-mime-type\n/** @param {string} input */\nfunction parseMIMEType (input) {\n  // 1. Remove any leading and trailing HTTP whitespace\n  // from input.\n  input = removeHTTPWhitespace(input, true, true)\n\n  // 2. Let position be a position variable for input,\n  // initially pointing at the start of input.\n  const position = { position: 0 }\n\n  // 3. Let type be the result of collecting a sequence\n  // of code points that are not U+002F (/) from\n  // input, given position.\n  const type = collectASequenceOfCodePointsFast(\n    '/',\n    input,\n    position\n  )\n\n  // 4. If type is the empty string or does not solely\n  // contain HTTP token code points, then return failure.\n  // https://mimesniff.spec.whatwg.org/#http-token-code-point\n  if (type.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(type)) {\n    return 'failure'\n  }\n\n  // 5. If position is past the end of input, then return\n  // failure\n  if (position.position > input.length) {\n    return 'failure'\n  }\n\n  // 6. Advance position by 1. (This skips past U+002F (/).)\n  position.position++\n\n  // 7. Let subtype be the result of collecting a sequence of\n  // code points that are not U+003B (;) from input, given\n  // position.\n  let subtype = collectASequenceOfCodePointsFast(\n    ';',\n    input,\n    position\n  )\n\n  // 8. Remove any trailing HTTP whitespace from subtype.\n  subtype = removeHTTPWhitespace(subtype, false, true)\n\n  // 9. If subtype is the empty string or does not solely\n  // contain HTTP token code points, then return failure.\n  if (subtype.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(subtype)) {\n    return 'failure'\n  }\n\n  const typeLowercase = type.toLowerCase()\n  const subtypeLowercase = subtype.toLowerCase()\n\n  // 10. Let mimeType be a new MIME type record whose type\n  // is type, in ASCII lowercase, and subtype is subtype,\n  // in ASCII lowercase.\n  // https://mimesniff.spec.whatwg.org/#mime-type\n  const mimeType = {\n    type: typeLowercase,\n    subtype: subtypeLowercase,\n    /** @type {Map<string, string>} */\n    parameters: new Map(),\n    // https://mimesniff.spec.whatwg.org/#mime-type-essence\n    essence: `${typeLowercase}/${subtypeLowercase}`\n  }\n\n  // 11. While position is not past the end of input:\n  while (position.position < input.length) {\n    // 1. Advance position by 1. (This skips past U+003B (;).)\n    position.position++\n\n    // 2. Collect a sequence of code points that are HTTP\n    // whitespace from input given position.\n    collectASequenceOfCodePoints(\n      // https://fetch.spec.whatwg.org/#http-whitespace\n      char => HTTP_WHITESPACE_REGEX.test(char),\n      input,\n      position\n    )\n\n    // 3. Let parameterName be the result of collecting a\n    // sequence of code points that are not U+003B (;)\n    // or U+003D (=) from input, given position.\n    let parameterName = collectASequenceOfCodePoints(\n      (char) => char !== ';' && char !== '=',\n      input,\n      position\n    )\n\n    // 4. Set parameterName to parameterName, in ASCII\n    // lowercase.\n    parameterName = parameterName.toLowerCase()\n\n    // 5. If position is not past the end of input, then:\n    if (position.position < input.length) {\n      // 1. If the code point at position within input is\n      // U+003B (;), then continue.\n      if (input[position.position] === ';') {\n        continue\n      }\n\n      // 2. Advance position by 1. (This skips past U+003D (=).)\n      position.position++\n    }\n\n    // 6. If position is past the end of input, then break.\n    if (position.position > input.length) {\n      break\n    }\n\n    // 7. Let parameterValue be null.\n    let parameterValue = null\n\n    // 8. If the code point at position within input is\n    // U+0022 (\"), then:\n    if (input[position.position] === '\"') {\n      // 1. Set parameterValue to the result of collecting\n      // an HTTP quoted string from input, given position\n      // and the extract-value flag.\n      parameterValue = collectAnHTTPQuotedString(input, position, true)\n\n      // 2. Collect a sequence of code points that are not\n      // U+003B (;) from input, given position.\n      collectASequenceOfCodePointsFast(\n        ';',\n        input,\n        position\n      )\n\n    // 9. Otherwise:\n    } else {\n      // 1. Set parameterValue to the result of collecting\n      // a sequence of code points that are not U+003B (;)\n      // from input, given position.\n      parameterValue = collectASequenceOfCodePointsFast(\n        ';',\n        input,\n        position\n      )\n\n      // 2. Remove any trailing HTTP whitespace from parameterValue.\n      parameterValue = removeHTTPWhitespace(parameterValue, false, true)\n\n      // 3. If parameterValue is the empty string, then continue.\n      if (parameterValue.length === 0) {\n        continue\n      }\n    }\n\n    // 10. If all of the following are true\n    // - parameterName is not the empty string\n    // - parameterName solely contains HTTP token code points\n    // - parameterValue solely contains HTTP quoted-string token code points\n    // - mimeTypes parameters[parameterName] does not exist\n    // then set mimeTypes parameters[parameterName] to parameterValue.\n    if (\n      parameterName.length !== 0 &&\n      HTTP_TOKEN_CODEPOINTS.test(parameterName) &&\n      (parameterValue.length === 0 || HTTP_QUOTED_STRING_TOKENS.test(parameterValue)) &&\n      !mimeType.parameters.has(parameterName)\n    ) {\n      mimeType.parameters.set(parameterName, parameterValue)\n    }\n  }\n\n  // 12. Return mimeType.\n  return mimeType\n}\n\n// https://infra.spec.whatwg.org/#forgiving-base64-decode\n/** @param {string} data */\nfunction forgivingBase64 (data) {\n  // 1. Remove all ASCII whitespace from data.\n  data = data.replace(/[\\u0009\\u000A\\u000C\\u000D\\u0020]/g, '')  // eslint-disable-line\n\n  // 2. If datas code point length divides by 4 leaving\n  // no remainder, then:\n  if (data.length % 4 === 0) {\n    // 1. If data ends with one or two U+003D (=) code points,\n    // then remove them from data.\n    data = data.replace(/=?=$/, '')\n  }\n\n  // 3. If datas code point length divides by 4 leaving\n  // a remainder of 1, then return failure.\n  if (data.length % 4 === 1) {\n    return 'failure'\n  }\n\n  // 4. If data contains a code point that is not one of\n  //  U+002B (+)\n  //  U+002F (/)\n  //  ASCII alphanumeric\n  // then return failure.\n  if (/[^+/0-9A-Za-z]/.test(data)) {\n    return 'failure'\n  }\n\n  const binary = atob(data)\n  const bytes = new Uint8Array(binary.length)\n\n  for (let byte = 0; byte < binary.length; byte++) {\n    bytes[byte] = binary.charCodeAt(byte)\n  }\n\n  return bytes\n}\n\n// https://fetch.spec.whatwg.org/#collect-an-http-quoted-string\n// tests: https://fetch.spec.whatwg.org/#example-http-quoted-string\n/**\n * @param {string} input\n * @param {{ position: number }} position\n * @param {boolean?} extractValue\n */\nfunction collectAnHTTPQuotedString (input, position, extractValue) {\n  // 1. Let positionStart be position.\n  const positionStart = position.position\n\n  // 2. Let value be the empty string.\n  let value = ''\n\n  // 3. Assert: the code point at position within input\n  // is U+0022 (\").\n  assert(input[position.position] === '\"')\n\n  // 4. Advance position by 1.\n  position.position++\n\n  // 5. While true:\n  while (true) {\n    // 1. Append the result of collecting a sequence of code points\n    // that are not U+0022 (\") or U+005C (\\) from input, given\n    // position, to value.\n    value += collectASequenceOfCodePoints(\n      (char) => char !== '\"' && char !== '\\\\',\n      input,\n      position\n    )\n\n    // 2. If position is past the end of input, then break.\n    if (position.position >= input.length) {\n      break\n    }\n\n    // 3. Let quoteOrBackslash be the code point at position within\n    // input.\n    const quoteOrBackslash = input[position.position]\n\n    // 4. Advance position by 1.\n    position.position++\n\n    // 5. If quoteOrBackslash is U+005C (\\), then:\n    if (quoteOrBackslash === '\\\\') {\n      // 1. If position is past the end of input, then append\n      // U+005C (\\) to value and break.\n      if (position.position >= input.length) {\n        value += '\\\\'\n        break\n      }\n\n      // 2. Append the code point at position within input to value.\n      value += input[position.position]\n\n      // 3. Advance position by 1.\n      position.position++\n\n    // 6. Otherwise:\n    } else {\n      // 1. Assert: quoteOrBackslash is U+0022 (\").\n      assert(quoteOrBackslash === '\"')\n\n      // 2. Break.\n      break\n    }\n  }\n\n  // 6. If the extract-value flag is set, then return value.\n  if (extractValue) {\n    return value\n  }\n\n  // 7. Return the code points from positionStart to position,\n  // inclusive, within input.\n  return input.slice(positionStart, position.position)\n}\n\n/**\n * @see https://mimesniff.spec.whatwg.org/#serialize-a-mime-type\n */\nfunction serializeAMimeType (mimeType) {\n  assert(mimeType !== 'failure')\n  const { parameters, essence } = mimeType\n\n  // 1. Let serialization be the concatenation of mimeTypes\n  //    type, U+002F (/), and mimeTypes subtype.\n  let serialization = essence\n\n  // 2. For each name  value of mimeTypes parameters:\n  for (let [name, value] of parameters.entries()) {\n    // 1. Append U+003B (;) to serialization.\n    serialization += ';'\n\n    // 2. Append name to serialization.\n    serialization += name\n\n    // 3. Append U+003D (=) to serialization.\n    serialization += '='\n\n    // 4. If value does not solely contain HTTP token code\n    //    points or value is the empty string, then:\n    if (!HTTP_TOKEN_CODEPOINTS.test(value)) {\n      // 1. Precede each occurence of U+0022 (\") or\n      //    U+005C (\\) in value with U+005C (\\).\n      value = value.replace(/(\\\\|\")/g, '\\\\$1')\n\n      // 2. Prepend U+0022 (\") to value.\n      value = '\"' + value\n\n      // 3. Append U+0022 (\") to value.\n      value += '\"'\n    }\n\n    // 5. Append value to serialization.\n    serialization += value\n  }\n\n  // 3. Return serialization.\n  return serialization\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-whitespace\n * @param {string} char\n */\nfunction isHTTPWhiteSpace (char) {\n  return char === '\\r' || char === '\\n' || char === '\\t' || char === ' '\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-whitespace\n * @param {string} str\n */\nfunction removeHTTPWhitespace (str, leading = true, trailing = true) {\n  let lead = 0\n  let trail = str.length - 1\n\n  if (leading) {\n    for (; lead < str.length && isHTTPWhiteSpace(str[lead]); lead++);\n  }\n\n  if (trailing) {\n    for (; trail > 0 && isHTTPWhiteSpace(str[trail]); trail--);\n  }\n\n  return str.slice(lead, trail + 1)\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#ascii-whitespace\n * @param {string} char\n */\nfunction isASCIIWhitespace (char) {\n  return char === '\\r' || char === '\\n' || char === '\\t' || char === '\\f' || char === ' '\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#strip-leading-and-trailing-ascii-whitespace\n */\nfunction removeASCIIWhitespace (str, leading = true, trailing = true) {\n  let lead = 0\n  let trail = str.length - 1\n\n  if (leading) {\n    for (; lead < str.length && isASCIIWhitespace(str[lead]); lead++);\n  }\n\n  if (trailing) {\n    for (; trail > 0 && isASCIIWhitespace(str[trail]); trail--);\n  }\n\n  return str.slice(lead, trail + 1)\n}\n\nmodule.exports = {\n  dataURLProcessor,\n  URLSerializer,\n  collectASequenceOfCodePoints,\n  collectASequenceOfCodePointsFast,\n  stringPercentDecode,\n  parseMIMEType,\n  collectAnHTTPQuotedString,\n  serializeAMimeType\n}\n","'use strict'\n\nconst { Blob, File: NativeFile } = require('buffer')\nconst { types } = require('util')\nconst { kState } = require('./symbols')\nconst { isBlobLike } = require('./util')\nconst { webidl } = require('./webidl')\nconst { parseMIMEType, serializeAMimeType } = require('./dataURL')\nconst { kEnumerableProperty } = require('../core/util')\nconst encoder = new TextEncoder()\n\nclass File extends Blob {\n  constructor (fileBits, fileName, options = {}) {\n    // The File constructor is invoked with two or three parameters, depending\n    // on whether the optional dictionary parameter is used. When the File()\n    // constructor is invoked, user agents must run the following steps:\n    webidl.argumentLengthCheck(arguments, 2, { header: 'File constructor' })\n\n    fileBits = webidl.converters['sequence<BlobPart>'](fileBits)\n    fileName = webidl.converters.USVString(fileName)\n    options = webidl.converters.FilePropertyBag(options)\n\n    // 1. Let bytes be the result of processing blob parts given fileBits and\n    // options.\n    // Note: Blob handles this for us\n\n    // 2. Let n be the fileName argument to the constructor.\n    const n = fileName\n\n    // 3. Process FilePropertyBag dictionary argument by running the following\n    // substeps:\n\n    //    1. If the type member is provided and is not the empty string, let t\n    //    be set to the type dictionary member. If t contains any characters\n    //    outside the range U+0020 to U+007E, then set t to the empty string\n    //    and return from these substeps.\n    //    2. Convert every character in t to ASCII lowercase.\n    let t = options.type\n    let d\n\n    // eslint-disable-next-line no-labels\n    substep: {\n      if (t) {\n        t = parseMIMEType(t)\n\n        if (t === 'failure') {\n          t = ''\n          // eslint-disable-next-line no-labels\n          break substep\n        }\n\n        t = serializeAMimeType(t).toLowerCase()\n      }\n\n      //    3. If the lastModified member is provided, let d be set to the\n      //    lastModified dictionary member. If it is not provided, set d to the\n      //    current date and time represented as the number of milliseconds since\n      //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).\n      d = options.lastModified\n    }\n\n    // 4. Return a new File object F such that:\n    // F refers to the bytes byte sequence.\n    // F.size is set to the number of total bytes in bytes.\n    // F.name is set to n.\n    // F.type is set to t.\n    // F.lastModified is set to d.\n\n    super(processBlobParts(fileBits, options), { type: t })\n    this[kState] = {\n      name: n,\n      lastModified: d,\n      type: t\n    }\n  }\n\n  get name () {\n    webidl.brandCheck(this, File)\n\n    return this[kState].name\n  }\n\n  get lastModified () {\n    webidl.brandCheck(this, File)\n\n    return this[kState].lastModified\n  }\n\n  get type () {\n    webidl.brandCheck(this, File)\n\n    return this[kState].type\n  }\n}\n\nclass FileLike {\n  constructor (blobLike, fileName, options = {}) {\n    // TODO: argument idl type check\n\n    // The File constructor is invoked with two or three parameters, depending\n    // on whether the optional dictionary parameter is used. When the File()\n    // constructor is invoked, user agents must run the following steps:\n\n    // 1. Let bytes be the result of processing blob parts given fileBits and\n    // options.\n\n    // 2. Let n be the fileName argument to the constructor.\n    const n = fileName\n\n    // 3. Process FilePropertyBag dictionary argument by running the following\n    // substeps:\n\n    //    1. If the type member is provided and is not the empty string, let t\n    //    be set to the type dictionary member. If t contains any characters\n    //    outside the range U+0020 to U+007E, then set t to the empty string\n    //    and return from these substeps.\n    //    TODO\n    const t = options.type\n\n    //    2. Convert every character in t to ASCII lowercase.\n    //    TODO\n\n    //    3. If the lastModified member is provided, let d be set to the\n    //    lastModified dictionary member. If it is not provided, set d to the\n    //    current date and time represented as the number of milliseconds since\n    //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).\n    const d = options.lastModified ?? Date.now()\n\n    // 4. Return a new File object F such that:\n    // F refers to the bytes byte sequence.\n    // F.size is set to the number of total bytes in bytes.\n    // F.name is set to n.\n    // F.type is set to t.\n    // F.lastModified is set to d.\n\n    this[kState] = {\n      blobLike,\n      name: n,\n      type: t,\n      lastModified: d\n    }\n  }\n\n  stream (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.stream(...args)\n  }\n\n  arrayBuffer (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.arrayBuffer(...args)\n  }\n\n  slice (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.slice(...args)\n  }\n\n  text (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.text(...args)\n  }\n\n  get size () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.size\n  }\n\n  get type () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.type\n  }\n\n  get name () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].name\n  }\n\n  get lastModified () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].lastModified\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'File'\n  }\n}\n\nObject.defineProperties(File.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'File',\n    configurable: true\n  },\n  name: kEnumerableProperty,\n  lastModified: kEnumerableProperty\n})\n\nwebidl.converters.Blob = webidl.interfaceConverter(Blob)\n\nwebidl.converters.BlobPart = function (V, opts) {\n  if (webidl.util.Type(V) === 'Object') {\n    if (isBlobLike(V)) {\n      return webidl.converters.Blob(V, { strict: false })\n    }\n\n    if (\n      ArrayBuffer.isView(V) ||\n      types.isAnyArrayBuffer(V)\n    ) {\n      return webidl.converters.BufferSource(V, opts)\n    }\n  }\n\n  return webidl.converters.USVString(V, opts)\n}\n\nwebidl.converters['sequence<BlobPart>'] = webidl.sequenceConverter(\n  webidl.converters.BlobPart\n)\n\n// https://www.w3.org/TR/FileAPI/#dfn-FilePropertyBag\nwebidl.converters.FilePropertyBag = webidl.dictionaryConverter([\n  {\n    key: 'lastModified',\n    converter: webidl.converters['long long'],\n    get defaultValue () {\n      return Date.now()\n    }\n  },\n  {\n    key: 'type',\n    converter: webidl.converters.DOMString,\n    defaultValue: ''\n  },\n  {\n    key: 'endings',\n    converter: (value) => {\n      value = webidl.converters.DOMString(value)\n      value = value.toLowerCase()\n\n      if (value !== 'native') {\n        value = 'transparent'\n      }\n\n      return value\n    },\n    defaultValue: 'transparent'\n  }\n])\n\n/**\n * @see https://www.w3.org/TR/FileAPI/#process-blob-parts\n * @param {(NodeJS.TypedArray|Blob|string)[]} parts\n * @param {{ type: string, endings: string }} options\n */\nfunction processBlobParts (parts, options) {\n  // 1. Let bytes be an empty sequence of bytes.\n  /** @type {NodeJS.TypedArray[]} */\n  const bytes = []\n\n  // 2. For each element in parts:\n  for (const element of parts) {\n    // 1. If element is a USVString, run the following substeps:\n    if (typeof element === 'string') {\n      // 1. Let s be element.\n      let s = element\n\n      // 2. If the endings member of options is \"native\", set s\n      //    to the result of converting line endings to native\n      //    of element.\n      if (options.endings === 'native') {\n        s = convertLineEndingsNative(s)\n      }\n\n      // 3. Append the result of UTF-8 encoding s to bytes.\n      bytes.push(encoder.encode(s))\n    } else if (\n      types.isAnyArrayBuffer(element) ||\n      types.isTypedArray(element)\n    ) {\n      // 2. If element is a BufferSource, get a copy of the\n      //    bytes held by the buffer source, and append those\n      //    bytes to bytes.\n      if (!element.buffer) { // ArrayBuffer\n        bytes.push(new Uint8Array(element))\n      } else {\n        bytes.push(\n          new Uint8Array(element.buffer, element.byteOffset, element.byteLength)\n        )\n      }\n    } else if (isBlobLike(element)) {\n      // 3. If element is a Blob, append the bytes it represents\n      //    to bytes.\n      bytes.push(element)\n    }\n  }\n\n  // 3. Return bytes.\n  return bytes\n}\n\n/**\n * @see https://www.w3.org/TR/FileAPI/#convert-line-endings-to-native\n * @param {string} s\n */\nfunction convertLineEndingsNative (s) {\n  // 1. Let native line ending be be the code point U+000A LF.\n  let nativeLineEnding = '\\n'\n\n  // 2. If the underlying platforms conventions are to\n  //    represent newlines as a carriage return and line feed\n  //    sequence, set native line ending to the code point\n  //    U+000D CR followed by the code point U+000A LF.\n  if (process.platform === 'win32') {\n    nativeLineEnding = '\\r\\n'\n  }\n\n  return s.replace(/\\r?\\n/g, nativeLineEnding)\n}\n\n// If this function is moved to ./util.js, some tools (such as\n// rollup) will warn about circular dependencies. See:\n// https://github.com/nodejs/undici/issues/1629\nfunction isFileLike (object) {\n  return (\n    (NativeFile && object instanceof NativeFile) ||\n    object instanceof File || (\n      object &&\n      (typeof object.stream === 'function' ||\n      typeof object.arrayBuffer === 'function') &&\n      object[Symbol.toStringTag] === 'File'\n    )\n  )\n}\n\nmodule.exports = { File, FileLike, isFileLike }\n","'use strict'\n\nconst { isBlobLike, toUSVString, makeIterator } = require('./util')\nconst { kState } = require('./symbols')\nconst { File: UndiciFile, FileLike, isFileLike } = require('./file')\nconst { webidl } = require('./webidl')\nconst { Blob, File: NativeFile } = require('buffer')\n\n/** @type {globalThis['File']} */\nconst File = NativeFile ?? UndiciFile\n\n// https://xhr.spec.whatwg.org/#formdata\nclass FormData {\n  constructor (form) {\n    if (form !== undefined) {\n      throw webidl.errors.conversionFailed({\n        prefix: 'FormData constructor',\n        argument: 'Argument 1',\n        types: ['undefined']\n      })\n    }\n\n    this[kState] = []\n  }\n\n  append (name, value, filename = undefined) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'FormData.append' })\n\n    if (arguments.length === 3 && !isBlobLike(value)) {\n      throw new TypeError(\n        \"Failed to execute 'append' on 'FormData': parameter 2 is not of type 'Blob'\"\n      )\n    }\n\n    // 1. Let value be value if given; otherwise blobValue.\n\n    name = webidl.converters.USVString(name)\n    value = isBlobLike(value)\n      ? webidl.converters.Blob(value, { strict: false })\n      : webidl.converters.USVString(value)\n    filename = arguments.length === 3\n      ? webidl.converters.USVString(filename)\n      : undefined\n\n    // 2. Let entry be the result of creating an entry with\n    // name, value, and filename if given.\n    const entry = makeEntry(name, value, filename)\n\n    // 3. Append entry to thiss entry list.\n    this[kState].push(entry)\n  }\n\n  delete (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.delete' })\n\n    name = webidl.converters.USVString(name)\n\n    // The delete(name) method steps are to remove all entries whose name\n    // is name from thiss entry list.\n    this[kState] = this[kState].filter(entry => entry.name !== name)\n  }\n\n  get (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.get' })\n\n    name = webidl.converters.USVString(name)\n\n    // 1. If there is no entry whose name is name in thiss entry list,\n    // then return null.\n    const idx = this[kState].findIndex((entry) => entry.name === name)\n    if (idx === -1) {\n      return null\n    }\n\n    // 2. Return the value of the first entry whose name is name from\n    // thiss entry list.\n    return this[kState][idx].value\n  }\n\n  getAll (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.getAll' })\n\n    name = webidl.converters.USVString(name)\n\n    // 1. If there is no entry whose name is name in thiss entry list,\n    // then return the empty list.\n    // 2. Return the values of all entries whose name is name, in order,\n    // from thiss entry list.\n    return this[kState]\n      .filter((entry) => entry.name === name)\n      .map((entry) => entry.value)\n  }\n\n  has (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.has' })\n\n    name = webidl.converters.USVString(name)\n\n    // The has(name) method steps are to return true if there is an entry\n    // whose name is name in thiss entry list; otherwise false.\n    return this[kState].findIndex((entry) => entry.name === name) !== -1\n  }\n\n  set (name, value, filename = undefined) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'FormData.set' })\n\n    if (arguments.length === 3 && !isBlobLike(value)) {\n      throw new TypeError(\n        \"Failed to execute 'set' on 'FormData': parameter 2 is not of type 'Blob'\"\n      )\n    }\n\n    // The set(name, value) and set(name, blobValue, filename) method steps\n    // are:\n\n    // 1. Let value be value if given; otherwise blobValue.\n\n    name = webidl.converters.USVString(name)\n    value = isBlobLike(value)\n      ? webidl.converters.Blob(value, { strict: false })\n      : webidl.converters.USVString(value)\n    filename = arguments.length === 3\n      ? toUSVString(filename)\n      : undefined\n\n    // 2. Let entry be the result of creating an entry with name, value, and\n    // filename if given.\n    const entry = makeEntry(name, value, filename)\n\n    // 3. If there are entries in thiss entry list whose name is name, then\n    // replace the first such entry with entry and remove the others.\n    const idx = this[kState].findIndex((entry) => entry.name === name)\n    if (idx !== -1) {\n      this[kState] = [\n        ...this[kState].slice(0, idx),\n        entry,\n        ...this[kState].slice(idx + 1).filter((entry) => entry.name !== name)\n      ]\n    } else {\n      // 4. Otherwise, append entry to thiss entry list.\n      this[kState].push(entry)\n    }\n  }\n\n  entries () {\n    webidl.brandCheck(this, FormData)\n\n    return makeIterator(\n      () => this[kState].map(pair => [pair.name, pair.value]),\n      'FormData',\n      'key+value'\n    )\n  }\n\n  keys () {\n    webidl.brandCheck(this, FormData)\n\n    return makeIterator(\n      () => this[kState].map(pair => [pair.name, pair.value]),\n      'FormData',\n      'key'\n    )\n  }\n\n  values () {\n    webidl.brandCheck(this, FormData)\n\n    return makeIterator(\n      () => this[kState].map(pair => [pair.name, pair.value]),\n      'FormData',\n      'value'\n    )\n  }\n\n  /**\n   * @param {(value: string, key: string, self: FormData) => void} callbackFn\n   * @param {unknown} thisArg\n   */\n  forEach (callbackFn, thisArg = globalThis) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.forEach' })\n\n    if (typeof callbackFn !== 'function') {\n      throw new TypeError(\n        \"Failed to execute 'forEach' on 'FormData': parameter 1 is not of type 'Function'.\"\n      )\n    }\n\n    for (const [key, value] of this) {\n      callbackFn.apply(thisArg, [value, key, this])\n    }\n  }\n}\n\nFormData.prototype[Symbol.iterator] = FormData.prototype.entries\n\nObject.defineProperties(FormData.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'FormData',\n    configurable: true\n  }\n})\n\n/**\n * @see https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#create-an-entry\n * @param {string} name\n * @param {string|Blob} value\n * @param {?string} filename\n * @returns\n */\nfunction makeEntry (name, value, filename) {\n  // 1. Set name to the result of converting name into a scalar value string.\n  // \"To convert a string into a scalar value string, replace any surrogates\n  //  with U+FFFD.\"\n  // see: https://nodejs.org/dist/latest-v18.x/docs/api/buffer.html#buftostringencoding-start-end\n  name = Buffer.from(name).toString('utf8')\n\n  // 2. If value is a string, then set value to the result of converting\n  //    value into a scalar value string.\n  if (typeof value === 'string') {\n    value = Buffer.from(value).toString('utf8')\n  } else {\n    // 3. Otherwise:\n\n    // 1. If value is not a File object, then set value to a new File object,\n    //    representing the same bytes, whose name attribute value is \"blob\"\n    if (!isFileLike(value)) {\n      value = value instanceof Blob\n        ? new File([value], 'blob', { type: value.type })\n        : new FileLike(value, 'blob', { type: value.type })\n    }\n\n    // 2. If filename is given, then set value to a new File object,\n    //    representing the same bytes, whose name attribute is filename.\n    if (filename !== undefined) {\n      /** @type {FilePropertyBag} */\n      const options = {\n        type: value.type,\n        lastModified: value.lastModified\n      }\n\n      value = (NativeFile && value instanceof NativeFile) || value instanceof UndiciFile\n        ? new File([value], filename, options)\n        : new FileLike(value, filename, options)\n    }\n  }\n\n  // 4. Return an entry whose name is name and whose value is value.\n  return { name, value }\n}\n\nmodule.exports = { FormData }\n","'use strict'\n\n// In case of breaking changes, increase the version\n// number to avoid conflicts.\nconst globalOrigin = Symbol.for('undici.globalOrigin.1')\n\nfunction getGlobalOrigin () {\n  return globalThis[globalOrigin]\n}\n\nfunction setGlobalOrigin (newOrigin) {\n  if (newOrigin === undefined) {\n    Object.defineProperty(globalThis, globalOrigin, {\n      value: undefined,\n      writable: true,\n      enumerable: false,\n      configurable: false\n    })\n\n    return\n  }\n\n  const parsedURL = new URL(newOrigin)\n\n  if (parsedURL.protocol !== 'http:' && parsedURL.protocol !== 'https:') {\n    throw new TypeError(`Only http & https urls are allowed, received ${parsedURL.protocol}`)\n  }\n\n  Object.defineProperty(globalThis, globalOrigin, {\n    value: parsedURL,\n    writable: true,\n    enumerable: false,\n    configurable: false\n  })\n}\n\nmodule.exports = {\n  getGlobalOrigin,\n  setGlobalOrigin\n}\n","// https://github.com/Ethan-Arrowood/undici-fetch\n\n'use strict'\n\nconst { kHeadersList, kConstruct } = require('../core/symbols')\nconst { kGuard } = require('./symbols')\nconst { kEnumerableProperty } = require('../core/util')\nconst {\n  makeIterator,\n  isValidHeaderName,\n  isValidHeaderValue\n} = require('./util')\nconst util = require('util')\nconst { webidl } = require('./webidl')\nconst assert = require('assert')\n\nconst kHeadersMap = Symbol('headers map')\nconst kHeadersSortedMap = Symbol('headers map sorted')\n\n/**\n * @param {number} code\n */\nfunction isHTTPWhiteSpaceCharCode (code) {\n  return code === 0x00a || code === 0x00d || code === 0x009 || code === 0x020\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-header-value-normalize\n * @param {string} potentialValue\n */\nfunction headerValueNormalize (potentialValue) {\n  //  To normalize a byte sequence potentialValue, remove\n  //  any leading and trailing HTTP whitespace bytes from\n  //  potentialValue.\n  let i = 0; let j = potentialValue.length\n\n  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(j - 1))) --j\n  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(i))) ++i\n\n  return i === 0 && j === potentialValue.length ? potentialValue : potentialValue.substring(i, j)\n}\n\nfunction fill (headers, object) {\n  // To fill a Headers object headers with a given object object, run these steps:\n\n  // 1. If object is a sequence, then for each header in object:\n  // Note: webidl conversion to array has already been done.\n  if (Array.isArray(object)) {\n    for (let i = 0; i < object.length; ++i) {\n      const header = object[i]\n      // 1. If header does not contain exactly two items, then throw a TypeError.\n      if (header.length !== 2) {\n        throw webidl.errors.exception({\n          header: 'Headers constructor',\n          message: `expected name/value pair to be length 2, found ${header.length}.`\n        })\n      }\n\n      // 2. Append (headers first item, headers second item) to headers.\n      appendHeader(headers, header[0], header[1])\n    }\n  } else if (typeof object === 'object' && object !== null) {\n    // Note: null should throw\n\n    // 2. Otherwise, object is a record, then for each key  value in object,\n    //    append (key, value) to headers\n    const keys = Object.keys(object)\n    for (let i = 0; i < keys.length; ++i) {\n      appendHeader(headers, keys[i], object[keys[i]])\n    }\n  } else {\n    throw webidl.errors.conversionFailed({\n      prefix: 'Headers constructor',\n      argument: 'Argument 1',\n      types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']\n    })\n  }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-headers-append\n */\nfunction appendHeader (headers, name, value) {\n  // 1. Normalize value.\n  value = headerValueNormalize(value)\n\n  // 2. If name is not a header name or value is not a\n  //    header value, then throw a TypeError.\n  if (!isValidHeaderName(name)) {\n    throw webidl.errors.invalidArgument({\n      prefix: 'Headers.append',\n      value: name,\n      type: 'header name'\n    })\n  } else if (!isValidHeaderValue(value)) {\n    throw webidl.errors.invalidArgument({\n      prefix: 'Headers.append',\n      value,\n      type: 'header value'\n    })\n  }\n\n  // 3. If headerss guard is \"immutable\", then throw a TypeError.\n  // 4. Otherwise, if headerss guard is \"request\" and name is a\n  //    forbidden header name, return.\n  // Note: undici does not implement forbidden header names\n  if (headers[kGuard] === 'immutable') {\n    throw new TypeError('immutable')\n  } else if (headers[kGuard] === 'request-no-cors') {\n    // 5. Otherwise, if headerss guard is \"request-no-cors\":\n    // TODO\n  }\n\n  // 6. Otherwise, if headerss guard is \"response\" and name is a\n  //    forbidden response-header name, return.\n\n  // 7. Append (name, value) to headerss header list.\n  return headers[kHeadersList].append(name, value)\n\n  // 8. If headerss guard is \"request-no-cors\", then remove\n  //    privileged no-CORS request headers from headers\n}\n\nclass HeadersList {\n  /** @type {[string, string][]|null} */\n  cookies = null\n\n  constructor (init) {\n    if (init instanceof HeadersList) {\n      this[kHeadersMap] = new Map(init[kHeadersMap])\n      this[kHeadersSortedMap] = init[kHeadersSortedMap]\n      this.cookies = init.cookies === null ? null : [...init.cookies]\n    } else {\n      this[kHeadersMap] = new Map(init)\n      this[kHeadersSortedMap] = null\n    }\n  }\n\n  // https://fetch.spec.whatwg.org/#header-list-contains\n  contains (name) {\n    // A header list list contains a header name name if list\n    // contains a header whose name is a byte-case-insensitive\n    // match for name.\n    name = name.toLowerCase()\n\n    return this[kHeadersMap].has(name)\n  }\n\n  clear () {\n    this[kHeadersMap].clear()\n    this[kHeadersSortedMap] = null\n    this.cookies = null\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-append\n  append (name, value) {\n    this[kHeadersSortedMap] = null\n\n    // 1. If list contains name, then set name to the first such\n    //    headers name.\n    const lowercaseName = name.toLowerCase()\n    const exists = this[kHeadersMap].get(lowercaseName)\n\n    // 2. Append (name, value) to list.\n    if (exists) {\n      const delimiter = lowercaseName === 'cookie' ? '; ' : ', '\n      this[kHeadersMap].set(lowercaseName, {\n        name: exists.name,\n        value: `${exists.value}${delimiter}${value}`\n      })\n    } else {\n      this[kHeadersMap].set(lowercaseName, { name, value })\n    }\n\n    if (lowercaseName === 'set-cookie') {\n      this.cookies ??= []\n      this.cookies.push(value)\n    }\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-set\n  set (name, value) {\n    this[kHeadersSortedMap] = null\n    const lowercaseName = name.toLowerCase()\n\n    if (lowercaseName === 'set-cookie') {\n      this.cookies = [value]\n    }\n\n    // 1. If list contains name, then set the value of\n    //    the first such header to value and remove the\n    //    others.\n    // 2. Otherwise, append header (name, value) to list.\n    this[kHeadersMap].set(lowercaseName, { name, value })\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-delete\n  delete (name) {\n    this[kHeadersSortedMap] = null\n\n    name = name.toLowerCase()\n\n    if (name === 'set-cookie') {\n      this.cookies = null\n    }\n\n    this[kHeadersMap].delete(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-get\n  get (name) {\n    const value = this[kHeadersMap].get(name.toLowerCase())\n\n    // 1. If list does not contain name, then return null.\n    // 2. Return the values of all headers in list whose name\n    //    is a byte-case-insensitive match for name,\n    //    separated from each other by 0x2C 0x20, in order.\n    return value === undefined ? null : value.value\n  }\n\n  * [Symbol.iterator] () {\n    // use the lowercased name\n    for (const [name, { value }] of this[kHeadersMap]) {\n      yield [name, value]\n    }\n  }\n\n  get entries () {\n    const headers = {}\n\n    if (this[kHeadersMap].size) {\n      for (const { name, value } of this[kHeadersMap].values()) {\n        headers[name] = value\n      }\n    }\n\n    return headers\n  }\n}\n\n// https://fetch.spec.whatwg.org/#headers-class\nclass Headers {\n  constructor (init = undefined) {\n    if (init === kConstruct) {\n      return\n    }\n    this[kHeadersList] = new HeadersList()\n\n    // The new Headers(init) constructor steps are:\n\n    // 1. Set thiss guard to \"none\".\n    this[kGuard] = 'none'\n\n    // 2. If init is given, then fill this with init.\n    if (init !== undefined) {\n      init = webidl.converters.HeadersInit(init)\n      fill(this, init)\n    }\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-append\n  append (name, value) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'Headers.append' })\n\n    name = webidl.converters.ByteString(name)\n    value = webidl.converters.ByteString(value)\n\n    return appendHeader(this, name, value)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-delete\n  delete (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.delete' })\n\n    name = webidl.converters.ByteString(name)\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.delete',\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. If thiss guard is \"immutable\", then throw a TypeError.\n    // 3. Otherwise, if thiss guard is \"request\" and name is a\n    //    forbidden header name, return.\n    // 4. Otherwise, if thiss guard is \"request-no-cors\", name\n    //    is not a no-CORS-safelisted request-header name, and\n    //    name is not a privileged no-CORS request-header name,\n    //    return.\n    // 5. Otherwise, if thiss guard is \"response\" and name is\n    //    a forbidden response-header name, return.\n    // Note: undici does not implement forbidden header names\n    if (this[kGuard] === 'immutable') {\n      throw new TypeError('immutable')\n    } else if (this[kGuard] === 'request-no-cors') {\n      // TODO\n    }\n\n    // 6. If thiss header list does not contain name, then\n    //    return.\n    if (!this[kHeadersList].contains(name)) {\n      return\n    }\n\n    // 7. Delete name from thiss header list.\n    // 8. If thiss guard is \"request-no-cors\", then remove\n    //    privileged no-CORS request headers from this.\n    this[kHeadersList].delete(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-get\n  get (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.get' })\n\n    name = webidl.converters.ByteString(name)\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.get',\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. Return the result of getting name from thiss header\n    //    list.\n    return this[kHeadersList].get(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-has\n  has (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.has' })\n\n    name = webidl.converters.ByteString(name)\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.has',\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. Return true if thiss header list contains name;\n    //    otherwise false.\n    return this[kHeadersList].contains(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-set\n  set (name, value) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'Headers.set' })\n\n    name = webidl.converters.ByteString(name)\n    value = webidl.converters.ByteString(value)\n\n    // 1. Normalize value.\n    value = headerValueNormalize(value)\n\n    // 2. If name is not a header name or value is not a\n    //    header value, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.set',\n        value: name,\n        type: 'header name'\n      })\n    } else if (!isValidHeaderValue(value)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.set',\n        value,\n        type: 'header value'\n      })\n    }\n\n    // 3. If thiss guard is \"immutable\", then throw a TypeError.\n    // 4. Otherwise, if thiss guard is \"request\" and name is a\n    //    forbidden header name, return.\n    // 5. Otherwise, if thiss guard is \"request-no-cors\" and\n    //    name/value is not a no-CORS-safelisted request-header,\n    //    return.\n    // 6. Otherwise, if thiss guard is \"response\" and name is a\n    //    forbidden response-header name, return.\n    // Note: undici does not implement forbidden header names\n    if (this[kGuard] === 'immutable') {\n      throw new TypeError('immutable')\n    } else if (this[kGuard] === 'request-no-cors') {\n      // TODO\n    }\n\n    // 7. Set (name, value) in thiss header list.\n    // 8. If thiss guard is \"request-no-cors\", then remove\n    //    privileged no-CORS request headers from this\n    this[kHeadersList].set(name, value)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-getsetcookie\n  getSetCookie () {\n    webidl.brandCheck(this, Headers)\n\n    // 1. If thiss header list does not contain `Set-Cookie`, then return  .\n    // 2. Return the values of all headers in thiss header list whose name is\n    //    a byte-case-insensitive match for `Set-Cookie`, in order.\n\n    const list = this[kHeadersList].cookies\n\n    if (list) {\n      return [...list]\n    }\n\n    return []\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine\n  get [kHeadersSortedMap] () {\n    if (this[kHeadersList][kHeadersSortedMap]) {\n      return this[kHeadersList][kHeadersSortedMap]\n    }\n\n    // 1. Let headers be an empty list of headers with the key being the name\n    //    and value the value.\n    const headers = []\n\n    // 2. Let names be the result of convert header names to a sorted-lowercase\n    //    set with all the names of the headers in list.\n    const names = [...this[kHeadersList]].sort((a, b) => a[0] < b[0] ? -1 : 1)\n    const cookies = this[kHeadersList].cookies\n\n    // 3. For each name of names:\n    for (let i = 0; i < names.length; ++i) {\n      const [name, value] = names[i]\n      // 1. If name is `set-cookie`, then:\n      if (name === 'set-cookie') {\n        // 1. Let values be a list of all values of headers in list whose name\n        //    is a byte-case-insensitive match for name, in order.\n\n        // 2. For each value of values:\n        // 1. Append (name, value) to headers.\n        for (let j = 0; j < cookies.length; ++j) {\n          headers.push([name, cookies[j]])\n        }\n      } else {\n        // 2. Otherwise:\n\n        // 1. Let value be the result of getting name from list.\n\n        // 2. Assert: value is non-null.\n        assert(value !== null)\n\n        // 3. Append (name, value) to headers.\n        headers.push([name, value])\n      }\n    }\n\n    this[kHeadersList][kHeadersSortedMap] = headers\n\n    // 4. Return headers.\n    return headers\n  }\n\n  keys () {\n    webidl.brandCheck(this, Headers)\n\n    if (this[kGuard] === 'immutable') {\n      const value = this[kHeadersSortedMap]\n      return makeIterator(() => value, 'Headers',\n        'key')\n    }\n\n    return makeIterator(\n      () => [...this[kHeadersSortedMap].values()],\n      'Headers',\n      'key'\n    )\n  }\n\n  values () {\n    webidl.brandCheck(this, Headers)\n\n    if (this[kGuard] === 'immutable') {\n      const value = this[kHeadersSortedMap]\n      return makeIterator(() => value, 'Headers',\n        'value')\n    }\n\n    return makeIterator(\n      () => [...this[kHeadersSortedMap].values()],\n      'Headers',\n      'value'\n    )\n  }\n\n  entries () {\n    webidl.brandCheck(this, Headers)\n\n    if (this[kGuard] === 'immutable') {\n      const value = this[kHeadersSortedMap]\n      return makeIterator(() => value, 'Headers',\n        'key+value')\n    }\n\n    return makeIterator(\n      () => [...this[kHeadersSortedMap].values()],\n      'Headers',\n      'key+value'\n    )\n  }\n\n  /**\n   * @param {(value: string, key: string, self: Headers) => void} callbackFn\n   * @param {unknown} thisArg\n   */\n  forEach (callbackFn, thisArg = globalThis) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.forEach' })\n\n    if (typeof callbackFn !== 'function') {\n      throw new TypeError(\n        \"Failed to execute 'forEach' on 'Headers': parameter 1 is not of type 'Function'.\"\n      )\n    }\n\n    for (const [key, value] of this) {\n      callbackFn.apply(thisArg, [value, key, this])\n    }\n  }\n\n  [Symbol.for('nodejs.util.inspect.custom')] () {\n    webidl.brandCheck(this, Headers)\n\n    return this[kHeadersList]\n  }\n}\n\nHeaders.prototype[Symbol.iterator] = Headers.prototype.entries\n\nObject.defineProperties(Headers.prototype, {\n  append: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  get: kEnumerableProperty,\n  has: kEnumerableProperty,\n  set: kEnumerableProperty,\n  getSetCookie: kEnumerableProperty,\n  keys: kEnumerableProperty,\n  values: kEnumerableProperty,\n  entries: kEnumerableProperty,\n  forEach: kEnumerableProperty,\n  [Symbol.iterator]: { enumerable: false },\n  [Symbol.toStringTag]: {\n    value: 'Headers',\n    configurable: true\n  },\n  [util.inspect.custom]: {\n    enumerable: false\n  }\n})\n\nwebidl.converters.HeadersInit = function (V) {\n  if (webidl.util.Type(V) === 'Object') {\n    if (V[Symbol.iterator]) {\n      return webidl.converters['sequence<sequence<ByteString>>'](V)\n    }\n\n    return webidl.converters['record<ByteString, ByteString>'](V)\n  }\n\n  throw webidl.errors.conversionFailed({\n    prefix: 'Headers constructor',\n    argument: 'Argument 1',\n    types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']\n  })\n}\n\nmodule.exports = {\n  fill,\n  Headers,\n  HeadersList\n}\n","// https://github.com/Ethan-Arrowood/undici-fetch\n\n'use strict'\n\nconst {\n  Response,\n  makeNetworkError,\n  makeAppropriateNetworkError,\n  filterResponse,\n  makeResponse\n} = require('./response')\nconst { Headers } = require('./headers')\nconst { Request, makeRequest } = require('./request')\nconst zlib = require('zlib')\nconst {\n  bytesMatch,\n  makePolicyContainer,\n  clonePolicyContainer,\n  requestBadPort,\n  TAOCheck,\n  appendRequestOriginHeader,\n  responseLocationURL,\n  requestCurrentURL,\n  setRequestReferrerPolicyOnRedirect,\n  tryUpgradeRequestToAPotentiallyTrustworthyURL,\n  createOpaqueTimingInfo,\n  appendFetchMetadata,\n  corsCheck,\n  crossOriginResourcePolicyCheck,\n  determineRequestsReferrer,\n  coarsenedSharedCurrentTime,\n  createDeferredPromise,\n  isBlobLike,\n  sameOrigin,\n  isCancelled,\n  isAborted,\n  isErrorLike,\n  fullyReadBody,\n  readableStreamClose,\n  isomorphicEncode,\n  urlIsLocal,\n  urlIsHttpHttpsScheme,\n  urlHasHttpsScheme\n} = require('./util')\nconst { kState, kHeaders, kGuard, kRealm } = require('./symbols')\nconst assert = require('assert')\nconst { safelyExtractBody } = require('./body')\nconst {\n  redirectStatusSet,\n  nullBodyStatus,\n  safeMethodsSet,\n  requestBodyHeader,\n  subresourceSet,\n  DOMException\n} = require('./constants')\nconst { kHeadersList } = require('../core/symbols')\nconst EE = require('events')\nconst { Readable, pipeline } = require('stream')\nconst { addAbortListener, isErrored, isReadable, nodeMajor, nodeMinor } = require('../core/util')\nconst { dataURLProcessor, serializeAMimeType } = require('./dataURL')\nconst { TransformStream } = require('stream/web')\nconst { getGlobalDispatcher } = require('../global')\nconst { webidl } = require('./webidl')\nconst { STATUS_CODES } = require('http')\nconst GET_OR_HEAD = ['GET', 'HEAD']\n\n/** @type {import('buffer').resolveObjectURL} */\nlet resolveObjectURL\nlet ReadableStream = globalThis.ReadableStream\n\nclass Fetch extends EE {\n  constructor (dispatcher) {\n    super()\n\n    this.dispatcher = dispatcher\n    this.connection = null\n    this.dump = false\n    this.state = 'ongoing'\n    // 2 terminated listeners get added per request,\n    // but only 1 gets removed. If there are 20 redirects,\n    // 21 listeners will be added.\n    // See https://github.com/nodejs/undici/issues/1711\n    // TODO (fix): Find and fix root cause for leaked listener.\n    this.setMaxListeners(21)\n  }\n\n  terminate (reason) {\n    if (this.state !== 'ongoing') {\n      return\n    }\n\n    this.state = 'terminated'\n    this.connection?.destroy(reason)\n    this.emit('terminated', reason)\n  }\n\n  // https://fetch.spec.whatwg.org/#fetch-controller-abort\n  abort (error) {\n    if (this.state !== 'ongoing') {\n      return\n    }\n\n    // 1. Set controllers state to \"aborted\".\n    this.state = 'aborted'\n\n    // 2. Let fallbackError be an \"AbortError\" DOMException.\n    // 3. Set error to fallbackError if it is not given.\n    if (!error) {\n      error = new DOMException('The operation was aborted.', 'AbortError')\n    }\n\n    // 4. Let serializedError be StructuredSerialize(error).\n    //    If that threw an exception, catch it, and let\n    //    serializedError be StructuredSerialize(fallbackError).\n\n    // 5. Set controllers serialized abort reason to serializedError.\n    this.serializedAbortReason = error\n\n    this.connection?.destroy(error)\n    this.emit('terminated', error)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetch-method\nfunction fetch (input, init = {}) {\n  webidl.argumentLengthCheck(arguments, 1, { header: 'globalThis.fetch' })\n\n  // 1. Let p be a new promise.\n  const p = createDeferredPromise()\n\n  // 2. Let requestObject be the result of invoking the initial value of\n  // Request as constructor with input and init as arguments. If this throws\n  // an exception, reject p with it and return p.\n  let requestObject\n\n  try {\n    requestObject = new Request(input, init)\n  } catch (e) {\n    p.reject(e)\n    return p.promise\n  }\n\n  // 3. Let request be requestObjects request.\n  const request = requestObject[kState]\n\n  // 4. If requestObjects signals aborted flag is set, then:\n  if (requestObject.signal.aborted) {\n    // 1. Abort the fetch() call with p, request, null, and\n    //    requestObjects signals abort reason.\n    abortFetch(p, request, null, requestObject.signal.reason)\n\n    // 2. Return p.\n    return p.promise\n  }\n\n  // 5. Let globalObject be requests clients global object.\n  const globalObject = request.client.globalObject\n\n  // 6. If globalObject is a ServiceWorkerGlobalScope object, then set\n  // requests service-workers mode to \"none\".\n  if (globalObject?.constructor?.name === 'ServiceWorkerGlobalScope') {\n    request.serviceWorkers = 'none'\n  }\n\n  // 7. Let responseObject be null.\n  let responseObject = null\n\n  // 8. Let relevantRealm be thiss relevant Realm.\n  const relevantRealm = null\n\n  // 9. Let locallyAborted be false.\n  let locallyAborted = false\n\n  // 10. Let controller be null.\n  let controller = null\n\n  // 11. Add the following abort steps to requestObjects signal:\n  addAbortListener(\n    requestObject.signal,\n    () => {\n      // 1. Set locallyAborted to true.\n      locallyAborted = true\n\n      // 2. Assert: controller is non-null.\n      assert(controller != null)\n\n      // 3. Abort controller with requestObjects signals abort reason.\n      controller.abort(requestObject.signal.reason)\n\n      // 4. Abort the fetch() call with p, request, responseObject,\n      //    and requestObjects signals abort reason.\n      abortFetch(p, request, responseObject, requestObject.signal.reason)\n    }\n  )\n\n  // 12. Let handleFetchDone given response response be to finalize and\n  // report timing with response, globalObject, and \"fetch\".\n  const handleFetchDone = (response) =>\n    finalizeAndReportTiming(response, 'fetch')\n\n  // 13. Set controller to the result of calling fetch given request,\n  // with processResponseEndOfBody set to handleFetchDone, and processResponse\n  // given response being these substeps:\n\n  const processResponse = (response) => {\n    // 1. If locallyAborted is true, terminate these substeps.\n    if (locallyAborted) {\n      return Promise.resolve()\n    }\n\n    // 2. If responses aborted flag is set, then:\n    if (response.aborted) {\n      // 1. Let deserializedError be the result of deserialize a serialized\n      //    abort reason given controllers serialized abort reason and\n      //    relevantRealm.\n\n      // 2. Abort the fetch() call with p, request, responseObject, and\n      //    deserializedError.\n\n      abortFetch(p, request, responseObject, controller.serializedAbortReason)\n      return Promise.resolve()\n    }\n\n    // 3. If response is a network error, then reject p with a TypeError\n    // and terminate these substeps.\n    if (response.type === 'error') {\n      p.reject(\n        Object.assign(new TypeError('fetch failed'), { cause: response.error })\n      )\n      return Promise.resolve()\n    }\n\n    // 4. Set responseObject to the result of creating a Response object,\n    // given response, \"immutable\", and relevantRealm.\n    responseObject = new Response()\n    responseObject[kState] = response\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kHeadersList] = response.headersList\n    responseObject[kHeaders][kGuard] = 'immutable'\n    responseObject[kHeaders][kRealm] = relevantRealm\n\n    // 5. Resolve p with responseObject.\n    p.resolve(responseObject)\n  }\n\n  controller = fetching({\n    request,\n    processResponseEndOfBody: handleFetchDone,\n    processResponse,\n    dispatcher: init.dispatcher ?? getGlobalDispatcher() // undici\n  })\n\n  // 14. Return p.\n  return p.promise\n}\n\n// https://fetch.spec.whatwg.org/#finalize-and-report-timing\nfunction finalizeAndReportTiming (response, initiatorType = 'other') {\n  // 1. If response is an aborted network error, then return.\n  if (response.type === 'error' && response.aborted) {\n    return\n  }\n\n  // 2. If responses URL list is null or empty, then return.\n  if (!response.urlList?.length) {\n    return\n  }\n\n  // 3. Let originalURL be responses URL list[0].\n  const originalURL = response.urlList[0]\n\n  // 4. Let timingInfo be responses timing info.\n  let timingInfo = response.timingInfo\n\n  // 5. Let cacheState be responses cache state.\n  let cacheState = response.cacheState\n\n  // 6. If originalURLs scheme is not an HTTP(S) scheme, then return.\n  if (!urlIsHttpHttpsScheme(originalURL)) {\n    return\n  }\n\n  // 7. If timingInfo is null, then return.\n  if (timingInfo === null) {\n    return\n  }\n\n  // 8. If responses timing allow passed flag is not set, then:\n  if (!response.timingAllowPassed) {\n    //  1. Set timingInfo to a the result of creating an opaque timing info for timingInfo.\n    timingInfo = createOpaqueTimingInfo({\n      startTime: timingInfo.startTime\n    })\n\n    //  2. Set cacheState to the empty string.\n    cacheState = ''\n  }\n\n  // 9. Set timingInfos end time to the coarsened shared current time\n  // given globals relevant settings objects cross-origin isolated\n  // capability.\n  // TODO: given globals relevant settings objects cross-origin isolated\n  // capability?\n  timingInfo.endTime = coarsenedSharedCurrentTime()\n\n  // 10. Set responses timing info to timingInfo.\n  response.timingInfo = timingInfo\n\n  // 11. Mark resource timing for timingInfo, originalURL, initiatorType,\n  // global, and cacheState.\n  markResourceTiming(\n    timingInfo,\n    originalURL,\n    initiatorType,\n    globalThis,\n    cacheState\n  )\n}\n\n// https://w3c.github.io/resource-timing/#dfn-mark-resource-timing\nfunction markResourceTiming (timingInfo, originalURL, initiatorType, globalThis, cacheState) {\n  if (nodeMajor > 18 || (nodeMajor === 18 && nodeMinor >= 2)) {\n    performance.markResourceTiming(timingInfo, originalURL.href, initiatorType, globalThis, cacheState)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#abort-fetch\nfunction abortFetch (p, request, responseObject, error) {\n  // Note: AbortSignal.reason was added in node v17.2.0\n  // which would give us an undefined error to reject with.\n  // Remove this once node v16 is no longer supported.\n  if (!error) {\n    error = new DOMException('The operation was aborted.', 'AbortError')\n  }\n\n  // 1. Reject promise with error.\n  p.reject(error)\n\n  // 2. If requests body is not null and is readable, then cancel requests\n  // body with error.\n  if (request.body != null && isReadable(request.body?.stream)) {\n    request.body.stream.cancel(error).catch((err) => {\n      if (err.code === 'ERR_INVALID_STATE') {\n        // Node bug?\n        return\n      }\n      throw err\n    })\n  }\n\n  // 3. If responseObject is null, then return.\n  if (responseObject == null) {\n    return\n  }\n\n  // 4. Let response be responseObjects response.\n  const response = responseObject[kState]\n\n  // 5. If responses body is not null and is readable, then error responses\n  // body with error.\n  if (response.body != null && isReadable(response.body?.stream)) {\n    response.body.stream.cancel(error).catch((err) => {\n      if (err.code === 'ERR_INVALID_STATE') {\n        // Node bug?\n        return\n      }\n      throw err\n    })\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetching\nfunction fetching ({\n  request,\n  processRequestBodyChunkLength,\n  processRequestEndOfBody,\n  processResponse,\n  processResponseEndOfBody,\n  processResponseConsumeBody,\n  useParallelQueue = false,\n  dispatcher // undici\n}) {\n  // 1. Let taskDestination be null.\n  let taskDestination = null\n\n  // 2. Let crossOriginIsolatedCapability be false.\n  let crossOriginIsolatedCapability = false\n\n  // 3. If requests client is non-null, then:\n  if (request.client != null) {\n    // 1. Set taskDestination to requests clients global object.\n    taskDestination = request.client.globalObject\n\n    // 2. Set crossOriginIsolatedCapability to requests clients cross-origin\n    // isolated capability.\n    crossOriginIsolatedCapability =\n      request.client.crossOriginIsolatedCapability\n  }\n\n  // 4. If useParallelQueue is true, then set taskDestination to the result of\n  // starting a new parallel queue.\n  // TODO\n\n  // 5. Let timingInfo be a new fetch timing info whose start time and\n  // post-redirect start time are the coarsened shared current time given\n  // crossOriginIsolatedCapability.\n  const currenTime = coarsenedSharedCurrentTime(crossOriginIsolatedCapability)\n  const timingInfo = createOpaqueTimingInfo({\n    startTime: currenTime\n  })\n\n  // 6. Let fetchParams be a new fetch params whose\n  // request is request,\n  // timing info is timingInfo,\n  // process request body chunk length is processRequestBodyChunkLength,\n  // process request end-of-body is processRequestEndOfBody,\n  // process response is processResponse,\n  // process response consume body is processResponseConsumeBody,\n  // process response end-of-body is processResponseEndOfBody,\n  // task destination is taskDestination,\n  // and cross-origin isolated capability is crossOriginIsolatedCapability.\n  const fetchParams = {\n    controller: new Fetch(dispatcher),\n    request,\n    timingInfo,\n    processRequestBodyChunkLength,\n    processRequestEndOfBody,\n    processResponse,\n    processResponseConsumeBody,\n    processResponseEndOfBody,\n    taskDestination,\n    crossOriginIsolatedCapability\n  }\n\n  // 7. If requests body is a byte sequence, then set requests body to\n  //    requests body as a body.\n  // NOTE: Since fetching is only called from fetch, body should already be\n  // extracted.\n  assert(!request.body || request.body.stream)\n\n  // 8. If requests window is \"client\", then set requests window to requests\n  // client, if requests clients global object is a Window object; otherwise\n  // \"no-window\".\n  if (request.window === 'client') {\n    // TODO: What if request.client is null?\n    request.window =\n      request.client?.globalObject?.constructor?.name === 'Window'\n        ? request.client\n        : 'no-window'\n  }\n\n  // 9. If requests origin is \"client\", then set requests origin to requests\n  // clients origin.\n  if (request.origin === 'client') {\n    // TODO: What if request.client is null?\n    request.origin = request.client?.origin\n  }\n\n  // 10. If all of the following conditions are true:\n  // TODO\n\n  // 11. If requests policy container is \"client\", then:\n  if (request.policyContainer === 'client') {\n    // 1. If requests client is non-null, then set requests policy\n    // container to a clone of requests clients policy container. [HTML]\n    if (request.client != null) {\n      request.policyContainer = clonePolicyContainer(\n        request.client.policyContainer\n      )\n    } else {\n      // 2. Otherwise, set requests policy container to a new policy\n      // container.\n      request.policyContainer = makePolicyContainer()\n    }\n  }\n\n  // 12. If requests header list does not contain `Accept`, then:\n  if (!request.headersList.contains('accept')) {\n    // 1. Let value be `*/*`.\n    const value = '*/*'\n\n    // 2. A user agent should set value to the first matching statement, if\n    // any, switching on requests destination:\n    // \"document\"\n    // \"frame\"\n    // \"iframe\"\n    // `text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8`\n    // \"image\"\n    // `image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5`\n    // \"style\"\n    // `text/css,*/*;q=0.1`\n    // TODO\n\n    // 3. Append `Accept`/value to requests header list.\n    request.headersList.append('accept', value)\n  }\n\n  // 13. If requests header list does not contain `Accept-Language`, then\n  // user agents should append `Accept-Language`/an appropriate value to\n  // requests header list.\n  if (!request.headersList.contains('accept-language')) {\n    request.headersList.append('accept-language', '*')\n  }\n\n  // 14. If requests priority is null, then use requests initiator and\n  // destination appropriately in setting requests priority to a\n  // user-agent-defined object.\n  if (request.priority === null) {\n    // TODO\n  }\n\n  // 15. If request is a subresource request, then:\n  if (subresourceSet.has(request.destination)) {\n    // TODO\n  }\n\n  // 16. Run main fetch given fetchParams.\n  mainFetch(fetchParams)\n    .catch(err => {\n      fetchParams.controller.terminate(err)\n    })\n\n  // 17. Return fetchParam's controller\n  return fetchParams.controller\n}\n\n// https://fetch.spec.whatwg.org/#concept-main-fetch\nasync function mainFetch (fetchParams, recursive = false) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. If requests local-URLs-only flag is set and requests current URL is\n  // not local, then set response to a network error.\n  if (request.localURLsOnly && !urlIsLocal(requestCurrentURL(request))) {\n    response = makeNetworkError('local URLs only')\n  }\n\n  // 4. Run report Content Security Policy violations for request.\n  // TODO\n\n  // 5. Upgrade request to a potentially trustworthy URL, if appropriate.\n  tryUpgradeRequestToAPotentiallyTrustworthyURL(request)\n\n  // 6. If should request be blocked due to a bad port, should fetching request\n  // be blocked as mixed content, or should request be blocked by Content\n  // Security Policy returns blocked, then set response to a network error.\n  if (requestBadPort(request) === 'blocked') {\n    response = makeNetworkError('bad port')\n  }\n  // TODO: should fetching request be blocked as mixed content?\n  // TODO: should request be blocked by Content Security Policy?\n\n  // 7. If requests referrer policy is the empty string, then set requests\n  // referrer policy to requests policy containers referrer policy.\n  if (request.referrerPolicy === '') {\n    request.referrerPolicy = request.policyContainer.referrerPolicy\n  }\n\n  // 8. If requests referrer is not \"no-referrer\", then set requests\n  // referrer to the result of invoking determine requests referrer.\n  if (request.referrer !== 'no-referrer') {\n    request.referrer = determineRequestsReferrer(request)\n  }\n\n  // 9. Set requests current URLs scheme to \"https\" if all of the following\n  // conditions are true:\n  // - requests current URLs scheme is \"http\"\n  // - requests current URLs host is a domain\n  // - Matching requests current URLs host per Known HSTS Host Domain Name\n  //   Matching results in either a superdomain match with an asserted\n  //   includeSubDomains directive or a congruent match (with or without an\n  //   asserted includeSubDomains directive). [HSTS]\n  // TODO\n\n  // 10. If recursive is false, then run the remaining steps in parallel.\n  // TODO\n\n  // 11. If response is null, then set response to the result of running\n  // the steps corresponding to the first matching statement:\n  if (response === null) {\n    response = await (async () => {\n      const currentURL = requestCurrentURL(request)\n\n      if (\n        // - requests current URLs origin is same origin with requests origin,\n        //   and requests response tainting is \"basic\"\n        (sameOrigin(currentURL, request.url) && request.responseTainting === 'basic') ||\n        // requests current URLs scheme is \"data\"\n        (currentURL.protocol === 'data:') ||\n        // - requests mode is \"navigate\" or \"websocket\"\n        (request.mode === 'navigate' || request.mode === 'websocket')\n      ) {\n        // 1. Set requests response tainting to \"basic\".\n        request.responseTainting = 'basic'\n\n        // 2. Return the result of running scheme fetch given fetchParams.\n        return await schemeFetch(fetchParams)\n      }\n\n      // requests mode is \"same-origin\"\n      if (request.mode === 'same-origin') {\n        // 1. Return a network error.\n        return makeNetworkError('request mode cannot be \"same-origin\"')\n      }\n\n      // requests mode is \"no-cors\"\n      if (request.mode === 'no-cors') {\n        // 1. If requests redirect mode is not \"follow\", then return a network\n        // error.\n        if (request.redirect !== 'follow') {\n          return makeNetworkError(\n            'redirect mode cannot be \"follow\" for \"no-cors\" request'\n          )\n        }\n\n        // 2. Set requests response tainting to \"opaque\".\n        request.responseTainting = 'opaque'\n\n        // 3. Return the result of running scheme fetch given fetchParams.\n        return await schemeFetch(fetchParams)\n      }\n\n      // requests current URLs scheme is not an HTTP(S) scheme\n      if (!urlIsHttpHttpsScheme(requestCurrentURL(request))) {\n        // Return a network error.\n        return makeNetworkError('URL scheme must be a HTTP(S) scheme')\n      }\n\n      // - requests use-CORS-preflight flag is set\n      // - requests unsafe-request flag is set and either requests method is\n      //   not a CORS-safelisted method or CORS-unsafe request-header names with\n      //   requests header list is not empty\n      //    1. Set requests response tainting to \"cors\".\n      //    2. Let corsWithPreflightResponse be the result of running HTTP fetch\n      //    given fetchParams and true.\n      //    3. If corsWithPreflightResponse is a network error, then clear cache\n      //    entries using request.\n      //    4. Return corsWithPreflightResponse.\n      // TODO\n\n      // Otherwise\n      //    1. Set requests response tainting to \"cors\".\n      request.responseTainting = 'cors'\n\n      //    2. Return the result of running HTTP fetch given fetchParams.\n      return await httpFetch(fetchParams)\n    })()\n  }\n\n  // 12. If recursive is true, then return response.\n  if (recursive) {\n    return response\n  }\n\n  // 13. If response is not a network error and response is not a filtered\n  // response, then:\n  if (response.status !== 0 && !response.internalResponse) {\n    // If requests response tainting is \"cors\", then:\n    if (request.responseTainting === 'cors') {\n      // 1. Let headerNames be the result of extracting header list values\n      // given `Access-Control-Expose-Headers` and responses header list.\n      // TODO\n      // 2. If requests credentials mode is not \"include\" and headerNames\n      // contains `*`, then set responses CORS-exposed header-name list to\n      // all unique header names in responses header list.\n      // TODO\n      // 3. Otherwise, if headerNames is not null or failure, then set\n      // responses CORS-exposed header-name list to headerNames.\n      // TODO\n    }\n\n    // Set response to the following filtered response with response as its\n    // internal response, depending on requests response tainting:\n    if (request.responseTainting === 'basic') {\n      response = filterResponse(response, 'basic')\n    } else if (request.responseTainting === 'cors') {\n      response = filterResponse(response, 'cors')\n    } else if (request.responseTainting === 'opaque') {\n      response = filterResponse(response, 'opaque')\n    } else {\n      assert(false)\n    }\n  }\n\n  // 14. Let internalResponse be response, if response is a network error,\n  // and responses internal response otherwise.\n  let internalResponse =\n    response.status === 0 ? response : response.internalResponse\n\n  // 15. If internalResponses URL list is empty, then set it to a clone of\n  // requests URL list.\n  if (internalResponse.urlList.length === 0) {\n    internalResponse.urlList.push(...request.urlList)\n  }\n\n  // 16. If requests timing allow failed flag is unset, then set\n  // internalResponses timing allow passed flag.\n  if (!request.timingAllowFailed) {\n    response.timingAllowPassed = true\n  }\n\n  // 17. If response is not a network error and any of the following returns\n  // blocked\n  // - should internalResponse to request be blocked as mixed content\n  // - should internalResponse to request be blocked by Content Security Policy\n  // - should internalResponse to request be blocked due to its MIME type\n  // - should internalResponse to request be blocked due to nosniff\n  // TODO\n\n  // 18. If responses type is \"opaque\", internalResponses status is 206,\n  // internalResponses range-requested flag is set, and requests header\n  // list does not contain `Range`, then set response and internalResponse\n  // to a network error.\n  if (\n    response.type === 'opaque' &&\n    internalResponse.status === 206 &&\n    internalResponse.rangeRequested &&\n    !request.headers.contains('range')\n  ) {\n    response = internalResponse = makeNetworkError()\n  }\n\n  // 19. If response is not a network error and either requests method is\n  // `HEAD` or `CONNECT`, or internalResponses status is a null body status,\n  // set internalResponses body to null and disregard any enqueuing toward\n  // it (if any).\n  if (\n    response.status !== 0 &&\n    (request.method === 'HEAD' ||\n      request.method === 'CONNECT' ||\n      nullBodyStatus.includes(internalResponse.status))\n  ) {\n    internalResponse.body = null\n    fetchParams.controller.dump = true\n  }\n\n  // 20. If requests integrity metadata is not the empty string, then:\n  if (request.integrity) {\n    // 1. Let processBodyError be this step: run fetch finale given fetchParams\n    // and a network error.\n    const processBodyError = (reason) =>\n      fetchFinale(fetchParams, makeNetworkError(reason))\n\n    // 2. If requests response tainting is \"opaque\", or responses body is null,\n    // then run processBodyError and abort these steps.\n    if (request.responseTainting === 'opaque' || response.body == null) {\n      processBodyError(response.error)\n      return\n    }\n\n    // 3. Let processBody given bytes be these steps:\n    const processBody = (bytes) => {\n      // 1. If bytes do not match requests integrity metadata,\n      // then run processBodyError and abort these steps. [SRI]\n      if (!bytesMatch(bytes, request.integrity)) {\n        processBodyError('integrity mismatch')\n        return\n      }\n\n      // 2. Set responses body to bytes as a body.\n      response.body = safelyExtractBody(bytes)[0]\n\n      // 3. Run fetch finale given fetchParams and response.\n      fetchFinale(fetchParams, response)\n    }\n\n    // 4. Fully read responses body given processBody and processBodyError.\n    await fullyReadBody(response.body, processBody, processBodyError)\n  } else {\n    // 21. Otherwise, run fetch finale given fetchParams and response.\n    fetchFinale(fetchParams, response)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#concept-scheme-fetch\n// given a fetch params fetchParams\nfunction schemeFetch (fetchParams) {\n  // Note: since the connection is destroyed on redirect, which sets fetchParams to a\n  // cancelled state, we do not want this condition to trigger *unless* there have been\n  // no redirects. See https://github.com/nodejs/undici/issues/1776\n  // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n  if (isCancelled(fetchParams) && fetchParams.request.redirectCount === 0) {\n    return Promise.resolve(makeAppropriateNetworkError(fetchParams))\n  }\n\n  // 2. Let request be fetchParamss request.\n  const { request } = fetchParams\n\n  const { protocol: scheme } = requestCurrentURL(request)\n\n  // 3. Switch on requests current URLs scheme and run the associated steps:\n  switch (scheme) {\n    case 'about:': {\n      // If requests current URLs path is the string \"blank\", then return a new response\n      // whose status message is `OK`, header list is  (`Content-Type`, `text/html;charset=utf-8`) ,\n      // and body is the empty byte sequence as a body.\n\n      // Otherwise, return a network error.\n      return Promise.resolve(makeNetworkError('about scheme is not supported'))\n    }\n    case 'blob:': {\n      if (!resolveObjectURL) {\n        resolveObjectURL = require('buffer').resolveObjectURL\n      }\n\n      // 1. Let blobURLEntry be requests current URLs blob URL entry.\n      const blobURLEntry = requestCurrentURL(request)\n\n      // https://github.com/web-platform-tests/wpt/blob/7b0ebaccc62b566a1965396e5be7bb2bc06f841f/FileAPI/url/resources/fetch-tests.js#L52-L56\n      // Buffer.resolveObjectURL does not ignore URL queries.\n      if (blobURLEntry.search.length !== 0) {\n        return Promise.resolve(makeNetworkError('NetworkError when attempting to fetch resource.'))\n      }\n\n      const blobURLEntryObject = resolveObjectURL(blobURLEntry.toString())\n\n      // 2. If requests method is not `GET`, blobURLEntry is null, or blobURLEntrys\n      //    object is not a Blob object, then return a network error.\n      if (request.method !== 'GET' || !isBlobLike(blobURLEntryObject)) {\n        return Promise.resolve(makeNetworkError('invalid method'))\n      }\n\n      // 3. Let bodyWithType be the result of safely extracting blobURLEntrys object.\n      const bodyWithType = safelyExtractBody(blobURLEntryObject)\n\n      // 4. Let body be bodyWithTypes body.\n      const body = bodyWithType[0]\n\n      // 5. Let length be bodys length, serialized and isomorphic encoded.\n      const length = isomorphicEncode(`${body.length}`)\n\n      // 6. Let type be bodyWithTypes type if it is non-null; otherwise the empty byte sequence.\n      const type = bodyWithType[1] ?? ''\n\n      // 7. Return a new response whose status message is `OK`, header list is\n      //     (`Content-Length`, length), (`Content-Type`, type) , and body is body.\n      const response = makeResponse({\n        statusText: 'OK',\n        headersList: [\n          ['content-length', { name: 'Content-Length', value: length }],\n          ['content-type', { name: 'Content-Type', value: type }]\n        ]\n      })\n\n      response.body = body\n\n      return Promise.resolve(response)\n    }\n    case 'data:': {\n      // 1. Let dataURLStruct be the result of running the\n      //    data: URL processor on requests current URL.\n      const currentURL = requestCurrentURL(request)\n      const dataURLStruct = dataURLProcessor(currentURL)\n\n      // 2. If dataURLStruct is failure, then return a\n      //    network error.\n      if (dataURLStruct === 'failure') {\n        return Promise.resolve(makeNetworkError('failed to fetch the data URL'))\n      }\n\n      // 3. Let mimeType be dataURLStructs MIME type, serialized.\n      const mimeType = serializeAMimeType(dataURLStruct.mimeType)\n\n      // 4. Return a response whose status message is `OK`,\n      //    header list is  (`Content-Type`, mimeType) ,\n      //    and body is dataURLStructs body as a body.\n      return Promise.resolve(makeResponse({\n        statusText: 'OK',\n        headersList: [\n          ['content-type', { name: 'Content-Type', value: mimeType }]\n        ],\n        body: safelyExtractBody(dataURLStruct.body)[0]\n      }))\n    }\n    case 'file:': {\n      // For now, unfortunate as it is, file URLs are left as an exercise for the reader.\n      // When in doubt, return a network error.\n      return Promise.resolve(makeNetworkError('not implemented... yet...'))\n    }\n    case 'http:':\n    case 'https:': {\n      // Return the result of running HTTP fetch given fetchParams.\n\n      return httpFetch(fetchParams)\n        .catch((err) => makeNetworkError(err))\n    }\n    default: {\n      return Promise.resolve(makeNetworkError('unknown scheme'))\n    }\n  }\n}\n\n// https://fetch.spec.whatwg.org/#finalize-response\nfunction finalizeResponse (fetchParams, response) {\n  // 1. Set fetchParamss requests done flag.\n  fetchParams.request.done = true\n\n  // 2, If fetchParamss process response done is not null, then queue a fetch\n  // task to run fetchParamss process response done given response, with\n  // fetchParamss task destination.\n  if (fetchParams.processResponseDone != null) {\n    queueMicrotask(() => fetchParams.processResponseDone(response))\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetch-finale\nfunction fetchFinale (fetchParams, response) {\n  // 1. If response is a network error, then:\n  if (response.type === 'error') {\n    // 1. Set responses URL list to  fetchParamss requests URL list[0] .\n    response.urlList = [fetchParams.request.urlList[0]]\n\n    // 2. Set responses timing info to the result of creating an opaque timing\n    // info for fetchParamss timing info.\n    response.timingInfo = createOpaqueTimingInfo({\n      startTime: fetchParams.timingInfo.startTime\n    })\n  }\n\n  // 2. Let processResponseEndOfBody be the following steps:\n  const processResponseEndOfBody = () => {\n    // 1. Set fetchParamss requests done flag.\n    fetchParams.request.done = true\n\n    // If fetchParamss process response end-of-body is not null,\n    // then queue a fetch task to run fetchParamss process response\n    // end-of-body given response with fetchParamss task destination.\n    if (fetchParams.processResponseEndOfBody != null) {\n      queueMicrotask(() => fetchParams.processResponseEndOfBody(response))\n    }\n  }\n\n  // 3. If fetchParamss process response is non-null, then queue a fetch task\n  // to run fetchParamss process response given response, with fetchParamss\n  // task destination.\n  if (fetchParams.processResponse != null) {\n    queueMicrotask(() => fetchParams.processResponse(response))\n  }\n\n  // 4. If responses body is null, then run processResponseEndOfBody.\n  if (response.body == null) {\n    processResponseEndOfBody()\n  } else {\n  // 5. Otherwise:\n\n    // 1. Let transformStream be a new a TransformStream.\n\n    // 2. Let identityTransformAlgorithm be an algorithm which, given chunk,\n    // enqueues chunk in transformStream.\n    const identityTransformAlgorithm = (chunk, controller) => {\n      controller.enqueue(chunk)\n    }\n\n    // 3. Set up transformStream with transformAlgorithm set to identityTransformAlgorithm\n    // and flushAlgorithm set to processResponseEndOfBody.\n    const transformStream = new TransformStream({\n      start () {},\n      transform: identityTransformAlgorithm,\n      flush: processResponseEndOfBody\n    }, {\n      size () {\n        return 1\n      }\n    }, {\n      size () {\n        return 1\n      }\n    })\n\n    // 4. Set responses body to the result of piping responses body through transformStream.\n    response.body = { stream: response.body.stream.pipeThrough(transformStream) }\n  }\n\n  // 6. If fetchParamss process response consume body is non-null, then:\n  if (fetchParams.processResponseConsumeBody != null) {\n    // 1. Let processBody given nullOrBytes be this step: run fetchParamss\n    // process response consume body given response and nullOrBytes.\n    const processBody = (nullOrBytes) => fetchParams.processResponseConsumeBody(response, nullOrBytes)\n\n    // 2. Let processBodyError be this step: run fetchParamss process\n    // response consume body given response and failure.\n    const processBodyError = (failure) => fetchParams.processResponseConsumeBody(response, failure)\n\n    // 3. If responses body is null, then queue a fetch task to run processBody\n    // given null, with fetchParamss task destination.\n    if (response.body == null) {\n      queueMicrotask(() => processBody(null))\n    } else {\n      // 4. Otherwise, fully read responses body given processBody, processBodyError,\n      // and fetchParamss task destination.\n      return fullyReadBody(response.body, processBody, processBodyError)\n    }\n    return Promise.resolve()\n  }\n}\n\n// https://fetch.spec.whatwg.org/#http-fetch\nasync function httpFetch (fetchParams) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. Let actualResponse be null.\n  let actualResponse = null\n\n  // 4. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 5. If requests service-workers mode is \"all\", then:\n  if (request.serviceWorkers === 'all') {\n    // TODO\n  }\n\n  // 6. If response is null, then:\n  if (response === null) {\n    // 1. If makeCORSPreflight is true and one of these conditions is true:\n    // TODO\n\n    // 2. If requests redirect mode is \"follow\", then set requests\n    // service-workers mode to \"none\".\n    if (request.redirect === 'follow') {\n      request.serviceWorkers = 'none'\n    }\n\n    // 3. Set response and actualResponse to the result of running\n    // HTTP-network-or-cache fetch given fetchParams.\n    actualResponse = response = await httpNetworkOrCacheFetch(fetchParams)\n\n    // 4. If requests response tainting is \"cors\" and a CORS check\n    // for request and response returns failure, then return a network error.\n    if (\n      request.responseTainting === 'cors' &&\n      corsCheck(request, response) === 'failure'\n    ) {\n      return makeNetworkError('cors failure')\n    }\n\n    // 5. If the TAO check for request and response returns failure, then set\n    // requests timing allow failed flag.\n    if (TAOCheck(request, response) === 'failure') {\n      request.timingAllowFailed = true\n    }\n  }\n\n  // 7. If either requests response tainting or responses type\n  // is \"opaque\", and the cross-origin resource policy check with\n  // requests origin, requests client, requests destination,\n  // and actualResponse returns blocked, then return a network error.\n  if (\n    (request.responseTainting === 'opaque' || response.type === 'opaque') &&\n    crossOriginResourcePolicyCheck(\n      request.origin,\n      request.client,\n      request.destination,\n      actualResponse\n    ) === 'blocked'\n  ) {\n    return makeNetworkError('blocked')\n  }\n\n  // 8. If actualResponses status is a redirect status, then:\n  if (redirectStatusSet.has(actualResponse.status)) {\n    // 1. If actualResponses status is not 303, requests body is not null,\n    // and the connection uses HTTP/2, then user agents may, and are even\n    // encouraged to, transmit an RST_STREAM frame.\n    // See, https://github.com/whatwg/fetch/issues/1288\n    if (request.redirect !== 'manual') {\n      fetchParams.controller.connection.destroy()\n    }\n\n    // 2. Switch on requests redirect mode:\n    if (request.redirect === 'error') {\n      // Set response to a network error.\n      response = makeNetworkError('unexpected redirect')\n    } else if (request.redirect === 'manual') {\n      // Set response to an opaque-redirect filtered response whose internal\n      // response is actualResponse.\n      // NOTE(spec): On the web this would return an `opaqueredirect` response,\n      // but that doesn't make sense server side.\n      // See https://github.com/nodejs/undici/issues/1193.\n      response = actualResponse\n    } else if (request.redirect === 'follow') {\n      // Set response to the result of running HTTP-redirect fetch given\n      // fetchParams and response.\n      response = await httpRedirectFetch(fetchParams, response)\n    } else {\n      assert(false)\n    }\n  }\n\n  // 9. Set responses timing info to timingInfo.\n  response.timingInfo = timingInfo\n\n  // 10. Return response.\n  return response\n}\n\n// https://fetch.spec.whatwg.org/#http-redirect-fetch\nfunction httpRedirectFetch (fetchParams, response) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let actualResponse be response, if response is not a filtered response,\n  // and responses internal response otherwise.\n  const actualResponse = response.internalResponse\n    ? response.internalResponse\n    : response\n\n  // 3. Let locationURL be actualResponses location URL given requests current\n  // URLs fragment.\n  let locationURL\n\n  try {\n    locationURL = responseLocationURL(\n      actualResponse,\n      requestCurrentURL(request).hash\n    )\n\n    // 4. If locationURL is null, then return response.\n    if (locationURL == null) {\n      return response\n    }\n  } catch (err) {\n    // 5. If locationURL is failure, then return a network error.\n    return Promise.resolve(makeNetworkError(err))\n  }\n\n  // 6. If locationURLs scheme is not an HTTP(S) scheme, then return a network\n  // error.\n  if (!urlIsHttpHttpsScheme(locationURL)) {\n    return Promise.resolve(makeNetworkError('URL scheme must be a HTTP(S) scheme'))\n  }\n\n  // 7. If requests redirect count is 20, then return a network error.\n  if (request.redirectCount === 20) {\n    return Promise.resolve(makeNetworkError('redirect count exceeded'))\n  }\n\n  // 8. Increase requests redirect count by 1.\n  request.redirectCount += 1\n\n  // 9. If requests mode is \"cors\", locationURL includes credentials, and\n  // requests origin is not same origin with locationURLs origin, then return\n  //  a network error.\n  if (\n    request.mode === 'cors' &&\n    (locationURL.username || locationURL.password) &&\n    !sameOrigin(request, locationURL)\n  ) {\n    return Promise.resolve(makeNetworkError('cross origin not allowed for request mode \"cors\"'))\n  }\n\n  // 10. If requests response tainting is \"cors\" and locationURL includes\n  // credentials, then return a network error.\n  if (\n    request.responseTainting === 'cors' &&\n    (locationURL.username || locationURL.password)\n  ) {\n    return Promise.resolve(makeNetworkError(\n      'URL cannot contain credentials for request mode \"cors\"'\n    ))\n  }\n\n  // 11. If actualResponses status is not 303, requests body is non-null,\n  // and requests bodys source is null, then return a network error.\n  if (\n    actualResponse.status !== 303 &&\n    request.body != null &&\n    request.body.source == null\n  ) {\n    return Promise.resolve(makeNetworkError())\n  }\n\n  // 12. If one of the following is true\n  // - actualResponses status is 301 or 302 and requests method is `POST`\n  // - actualResponses status is 303 and requests method is not `GET` or `HEAD`\n  if (\n    ([301, 302].includes(actualResponse.status) && request.method === 'POST') ||\n    (actualResponse.status === 303 &&\n      !GET_OR_HEAD.includes(request.method))\n  ) {\n    // then:\n    // 1. Set requests method to `GET` and requests body to null.\n    request.method = 'GET'\n    request.body = null\n\n    // 2. For each headerName of request-body-header name, delete headerName from\n    // requests header list.\n    for (const headerName of requestBodyHeader) {\n      request.headersList.delete(headerName)\n    }\n  }\n\n  // 13. If requests current URLs origin is not same origin with locationURLs\n  //     origin, then for each headerName of CORS non-wildcard request-header name,\n  //     delete headerName from requests header list.\n  if (!sameOrigin(requestCurrentURL(request), locationURL)) {\n    // https://fetch.spec.whatwg.org/#cors-non-wildcard-request-header-name\n    request.headersList.delete('authorization')\n\n    // https://fetch.spec.whatwg.org/#authentication-entries\n    request.headersList.delete('proxy-authorization', true)\n\n    // \"Cookie\" and \"Host\" are forbidden request-headers, which undici doesn't implement.\n    request.headersList.delete('cookie')\n    request.headersList.delete('host')\n  }\n\n  // 14. If requests body is non-null, then set requests body to the first return\n  // value of safely extracting requests bodys source.\n  if (request.body != null) {\n    assert(request.body.source != null)\n    request.body = safelyExtractBody(request.body.source)[0]\n  }\n\n  // 15. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 16. Set timingInfos redirect end time and post-redirect start time to the\n  // coarsened shared current time given fetchParamss cross-origin isolated\n  // capability.\n  timingInfo.redirectEndTime = timingInfo.postRedirectStartTime =\n    coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability)\n\n  // 17. If timingInfos redirect start time is 0, then set timingInfos\n  //  redirect start time to timingInfos start time.\n  if (timingInfo.redirectStartTime === 0) {\n    timingInfo.redirectStartTime = timingInfo.startTime\n  }\n\n  // 18. Append locationURL to requests URL list.\n  request.urlList.push(locationURL)\n\n  // 19. Invoke set requests referrer policy on redirect on request and\n  // actualResponse.\n  setRequestReferrerPolicyOnRedirect(request, actualResponse)\n\n  // 20. Return the result of running main fetch given fetchParams and true.\n  return mainFetch(fetchParams, true)\n}\n\n// https://fetch.spec.whatwg.org/#http-network-or-cache-fetch\nasync function httpNetworkOrCacheFetch (\n  fetchParams,\n  isAuthenticationFetch = false,\n  isNewConnectionFetch = false\n) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let httpFetchParams be null.\n  let httpFetchParams = null\n\n  // 3. Let httpRequest be null.\n  let httpRequest = null\n\n  // 4. Let response be null.\n  let response = null\n\n  // 5. Let storedResponse be null.\n  // TODO: cache\n\n  // 6. Let httpCache be null.\n  const httpCache = null\n\n  // 7. Let the revalidatingFlag be unset.\n  const revalidatingFlag = false\n\n  // 8. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. If requests window is \"no-window\" and requests redirect mode is\n  //    \"error\", then set httpFetchParams to fetchParams and httpRequest to\n  //    request.\n  if (request.window === 'no-window' && request.redirect === 'error') {\n    httpFetchParams = fetchParams\n    httpRequest = request\n  } else {\n    // Otherwise:\n\n    // 1. Set httpRequest to a clone of request.\n    httpRequest = makeRequest(request)\n\n    // 2. Set httpFetchParams to a copy of fetchParams.\n    httpFetchParams = { ...fetchParams }\n\n    // 3. Set httpFetchParamss request to httpRequest.\n    httpFetchParams.request = httpRequest\n  }\n\n  //    3. Let includeCredentials be true if one of\n  const includeCredentials =\n    request.credentials === 'include' ||\n    (request.credentials === 'same-origin' &&\n      request.responseTainting === 'basic')\n\n  //    4. Let contentLength be httpRequests bodys length, if httpRequests\n  //    body is non-null; otherwise null.\n  const contentLength = httpRequest.body ? httpRequest.body.length : null\n\n  //    5. Let contentLengthHeaderValue be null.\n  let contentLengthHeaderValue = null\n\n  //    6. If httpRequests body is null and httpRequests method is `POST` or\n  //    `PUT`, then set contentLengthHeaderValue to `0`.\n  if (\n    httpRequest.body == null &&\n    ['POST', 'PUT'].includes(httpRequest.method)\n  ) {\n    contentLengthHeaderValue = '0'\n  }\n\n  //    7. If contentLength is non-null, then set contentLengthHeaderValue to\n  //    contentLength, serialized and isomorphic encoded.\n  if (contentLength != null) {\n    contentLengthHeaderValue = isomorphicEncode(`${contentLength}`)\n  }\n\n  //    8. If contentLengthHeaderValue is non-null, then append\n  //    `Content-Length`/contentLengthHeaderValue to httpRequests header\n  //    list.\n  if (contentLengthHeaderValue != null) {\n    httpRequest.headersList.append('content-length', contentLengthHeaderValue)\n  }\n\n  //    9. If contentLengthHeaderValue is non-null, then append (`Content-Length`,\n  //    contentLengthHeaderValue) to httpRequests header list.\n\n  //    10. If contentLength is non-null and httpRequests keepalive is true,\n  //    then:\n  if (contentLength != null && httpRequest.keepalive) {\n    // NOTE: keepalive is a noop outside of browser context.\n  }\n\n  //    11. If httpRequests referrer is a URL, then append\n  //    `Referer`/httpRequests referrer, serialized and isomorphic encoded,\n  //     to httpRequests header list.\n  if (httpRequest.referrer instanceof URL) {\n    httpRequest.headersList.append('referer', isomorphicEncode(httpRequest.referrer.href))\n  }\n\n  //    12. Append a request `Origin` header for httpRequest.\n  appendRequestOriginHeader(httpRequest)\n\n  //    13. Append the Fetch metadata headers for httpRequest. [FETCH-METADATA]\n  appendFetchMetadata(httpRequest)\n\n  //    14. If httpRequests header list does not contain `User-Agent`, then\n  //    user agents should append `User-Agent`/default `User-Agent` value to\n  //    httpRequests header list.\n  if (!httpRequest.headersList.contains('user-agent')) {\n    httpRequest.headersList.append('user-agent', typeof esbuildDetection === 'undefined' ? 'undici' : 'node')\n  }\n\n  //    15. If httpRequests cache mode is \"default\" and httpRequests header\n  //    list contains `If-Modified-Since`, `If-None-Match`,\n  //    `If-Unmodified-Since`, `If-Match`, or `If-Range`, then set\n  //    httpRequests cache mode to \"no-store\".\n  if (\n    httpRequest.cache === 'default' &&\n    (httpRequest.headersList.contains('if-modified-since') ||\n      httpRequest.headersList.contains('if-none-match') ||\n      httpRequest.headersList.contains('if-unmodified-since') ||\n      httpRequest.headersList.contains('if-match') ||\n      httpRequest.headersList.contains('if-range'))\n  ) {\n    httpRequest.cache = 'no-store'\n  }\n\n  //    16. If httpRequests cache mode is \"no-cache\", httpRequests prevent\n  //    no-cache cache-control header modification flag is unset, and\n  //    httpRequests header list does not contain `Cache-Control`, then append\n  //    `Cache-Control`/`max-age=0` to httpRequests header list.\n  if (\n    httpRequest.cache === 'no-cache' &&\n    !httpRequest.preventNoCacheCacheControlHeaderModification &&\n    !httpRequest.headersList.contains('cache-control')\n  ) {\n    httpRequest.headersList.append('cache-control', 'max-age=0')\n  }\n\n  //    17. If httpRequests cache mode is \"no-store\" or \"reload\", then:\n  if (httpRequest.cache === 'no-store' || httpRequest.cache === 'reload') {\n    // 1. If httpRequests header list does not contain `Pragma`, then append\n    // `Pragma`/`no-cache` to httpRequests header list.\n    if (!httpRequest.headersList.contains('pragma')) {\n      httpRequest.headersList.append('pragma', 'no-cache')\n    }\n\n    // 2. If httpRequests header list does not contain `Cache-Control`,\n    // then append `Cache-Control`/`no-cache` to httpRequests header list.\n    if (!httpRequest.headersList.contains('cache-control')) {\n      httpRequest.headersList.append('cache-control', 'no-cache')\n    }\n  }\n\n  //    18. If httpRequests header list contains `Range`, then append\n  //    `Accept-Encoding`/`identity` to httpRequests header list.\n  if (httpRequest.headersList.contains('range')) {\n    httpRequest.headersList.append('accept-encoding', 'identity')\n  }\n\n  //    19. Modify httpRequests header list per HTTP. Do not append a given\n  //    header if httpRequests header list contains that headers name.\n  //    TODO: https://github.com/whatwg/fetch/issues/1285#issuecomment-896560129\n  if (!httpRequest.headersList.contains('accept-encoding')) {\n    if (urlHasHttpsScheme(requestCurrentURL(httpRequest))) {\n      httpRequest.headersList.append('accept-encoding', 'br, gzip, deflate')\n    } else {\n      httpRequest.headersList.append('accept-encoding', 'gzip, deflate')\n    }\n  }\n\n  httpRequest.headersList.delete('host')\n\n  //    20. If includeCredentials is true, then:\n  if (includeCredentials) {\n    // 1. If the user agent is not configured to block cookies for httpRequest\n    // (see section 7 of [COOKIES]), then:\n    // TODO: credentials\n    // 2. If httpRequests header list does not contain `Authorization`, then:\n    // TODO: credentials\n  }\n\n  //    21. If theres a proxy-authentication entry, use it as appropriate.\n  //    TODO: proxy-authentication\n\n  //    22. Set httpCache to the result of determining the HTTP cache\n  //    partition, given httpRequest.\n  //    TODO: cache\n\n  //    23. If httpCache is null, then set httpRequests cache mode to\n  //    \"no-store\".\n  if (httpCache == null) {\n    httpRequest.cache = 'no-store'\n  }\n\n  //    24. If httpRequests cache mode is neither \"no-store\" nor \"reload\",\n  //    then:\n  if (httpRequest.mode !== 'no-store' && httpRequest.mode !== 'reload') {\n    // TODO: cache\n  }\n\n  // 9. If aborted, then return the appropriate network error for fetchParams.\n  // TODO\n\n  // 10. If response is null, then:\n  if (response == null) {\n    // 1. If httpRequests cache mode is \"only-if-cached\", then return a\n    // network error.\n    if (httpRequest.mode === 'only-if-cached') {\n      return makeNetworkError('only if cached')\n    }\n\n    // 2. Let forwardResponse be the result of running HTTP-network fetch\n    // given httpFetchParams, includeCredentials, and isNewConnectionFetch.\n    const forwardResponse = await httpNetworkFetch(\n      httpFetchParams,\n      includeCredentials,\n      isNewConnectionFetch\n    )\n\n    // 3. If httpRequests method is unsafe and forwardResponses status is\n    // in the range 200 to 399, inclusive, invalidate appropriate stored\n    // responses in httpCache, as per the \"Invalidation\" chapter of HTTP\n    // Caching, and set storedResponse to null. [HTTP-CACHING]\n    if (\n      !safeMethodsSet.has(httpRequest.method) &&\n      forwardResponse.status >= 200 &&\n      forwardResponse.status <= 399\n    ) {\n      // TODO: cache\n    }\n\n    // 4. If the revalidatingFlag is set and forwardResponses status is 304,\n    // then:\n    if (revalidatingFlag && forwardResponse.status === 304) {\n      // TODO: cache\n    }\n\n    // 5. If response is null, then:\n    if (response == null) {\n      // 1. Set response to forwardResponse.\n      response = forwardResponse\n\n      // 2. Store httpRequest and forwardResponse in httpCache, as per the\n      // \"Storing Responses in Caches\" chapter of HTTP Caching. [HTTP-CACHING]\n      // TODO: cache\n    }\n  }\n\n  // 11. Set responses URL list to a clone of httpRequests URL list.\n  response.urlList = [...httpRequest.urlList]\n\n  // 12. If httpRequests header list contains `Range`, then set responses\n  // range-requested flag.\n  if (httpRequest.headersList.contains('range')) {\n    response.rangeRequested = true\n  }\n\n  // 13. Set responses request-includes-credentials to includeCredentials.\n  response.requestIncludesCredentials = includeCredentials\n\n  // 14. If responses status is 401, httpRequests response tainting is not\n  // \"cors\", includeCredentials is true, and requests window is an environment\n  // settings object, then:\n  // TODO\n\n  // 15. If responses status is 407, then:\n  if (response.status === 407) {\n    // 1. If requests window is \"no-window\", then return a network error.\n    if (request.window === 'no-window') {\n      return makeNetworkError()\n    }\n\n    // 2. ???\n\n    // 3. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n    if (isCancelled(fetchParams)) {\n      return makeAppropriateNetworkError(fetchParams)\n    }\n\n    // 4. Prompt the end user as appropriate in requests window and store\n    // the result as a proxy-authentication entry. [HTTP-AUTH]\n    // TODO: Invoke some kind of callback?\n\n    // 5. Set response to the result of running HTTP-network-or-cache fetch given\n    // fetchParams.\n    // TODO\n    return makeNetworkError('proxy authentication required')\n  }\n\n  // 16. If all of the following are true\n  if (\n    // responses status is 421\n    response.status === 421 &&\n    // isNewConnectionFetch is false\n    !isNewConnectionFetch &&\n    // requests body is null, or requests body is non-null and requests bodys source is non-null\n    (request.body == null || request.body.source != null)\n  ) {\n    // then:\n\n    // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n    if (isCancelled(fetchParams)) {\n      return makeAppropriateNetworkError(fetchParams)\n    }\n\n    // 2. Set response to the result of running HTTP-network-or-cache\n    // fetch given fetchParams, isAuthenticationFetch, and true.\n\n    // TODO (spec): The spec doesn't specify this but we need to cancel\n    // the active response before we can start a new one.\n    // https://github.com/whatwg/fetch/issues/1293\n    fetchParams.controller.connection.destroy()\n\n    response = await httpNetworkOrCacheFetch(\n      fetchParams,\n      isAuthenticationFetch,\n      true\n    )\n  }\n\n  // 17. If isAuthenticationFetch is true, then create an authentication entry\n  if (isAuthenticationFetch) {\n    // TODO\n  }\n\n  // 18. Return response.\n  return response\n}\n\n// https://fetch.spec.whatwg.org/#http-network-fetch\nasync function httpNetworkFetch (\n  fetchParams,\n  includeCredentials = false,\n  forceNewConnection = false\n) {\n  assert(!fetchParams.controller.connection || fetchParams.controller.connection.destroyed)\n\n  fetchParams.controller.connection = {\n    abort: null,\n    destroyed: false,\n    destroy (err) {\n      if (!this.destroyed) {\n        this.destroyed = true\n        this.abort?.(err ?? new DOMException('The operation was aborted.', 'AbortError'))\n      }\n    }\n  }\n\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 4. Let httpCache be the result of determining the HTTP cache partition,\n  // given request.\n  // TODO: cache\n  const httpCache = null\n\n  // 5. If httpCache is null, then set requests cache mode to \"no-store\".\n  if (httpCache == null) {\n    request.cache = 'no-store'\n  }\n\n  // 6. Let networkPartitionKey be the result of determining the network\n  // partition key given request.\n  // TODO\n\n  // 7. Let newConnection be \"yes\" if forceNewConnection is true; otherwise\n  // \"no\".\n  const newConnection = forceNewConnection ? 'yes' : 'no' // eslint-disable-line no-unused-vars\n\n  // 8. Switch on requests mode:\n  if (request.mode === 'websocket') {\n    // Let connection be the result of obtaining a WebSocket connection,\n    // given requests current URL.\n    // TODO\n  } else {\n    // Let connection be the result of obtaining a connection, given\n    // networkPartitionKey, requests current URLs origin,\n    // includeCredentials, and forceNewConnection.\n    // TODO\n  }\n\n  // 9. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. If connection is failure, then return a network error.\n\n  //    2. Set timingInfos final connection timing info to the result of\n  //    calling clamp and coarsen connection timing info with connections\n  //    timing info, timingInfos post-redirect start time, and fetchParamss\n  //    cross-origin isolated capability.\n\n  //    3. If connection is not an HTTP/2 connection, requests body is non-null,\n  //    and requests bodys source is null, then append (`Transfer-Encoding`,\n  //    `chunked`) to requests header list.\n\n  //    4. Set timingInfos final network-request start time to the coarsened\n  //    shared current time given fetchParamss cross-origin isolated\n  //    capability.\n\n  //    5. Set response to the result of making an HTTP request over connection\n  //    using request with the following caveats:\n\n  //        - Follow the relevant requirements from HTTP. [HTTP] [HTTP-SEMANTICS]\n  //        [HTTP-COND] [HTTP-CACHING] [HTTP-AUTH]\n\n  //        - If requests body is non-null, and requests bodys source is null,\n  //        then the user agent may have a buffer of up to 64 kibibytes and store\n  //        a part of requests body in that buffer. If the user agent reads from\n  //        requests body beyond that buffers size and the user agent needs to\n  //        resend request, then instead return a network error.\n\n  //        - Set timingInfos final network-response start time to the coarsened\n  //        shared current time given fetchParamss cross-origin isolated capability,\n  //        immediately after the user agents HTTP parser receives the first byte\n  //        of the response (e.g., frame header bytes for HTTP/2 or response status\n  //        line for HTTP/1.x).\n\n  //        - Wait until all the headers are transmitted.\n\n  //        - Any responses whose status is in the range 100 to 199, inclusive,\n  //        and is not 101, are to be ignored, except for the purposes of setting\n  //        timingInfos final network-response start time above.\n\n  //    - If requests header list contains `Transfer-Encoding`/`chunked` and\n  //    response is transferred via HTTP/1.0 or older, then return a network\n  //    error.\n\n  //    - If the HTTP request results in a TLS client certificate dialog, then:\n\n  //        1. If requests window is an environment settings object, make the\n  //        dialog available in requests window.\n\n  //        2. Otherwise, return a network error.\n\n  // To transmit requests body body, run these steps:\n  let requestBody = null\n  // 1. If body is null and fetchParamss process request end-of-body is\n  // non-null, then queue a fetch task given fetchParamss process request\n  // end-of-body and fetchParamss task destination.\n  if (request.body == null && fetchParams.processRequestEndOfBody) {\n    queueMicrotask(() => fetchParams.processRequestEndOfBody())\n  } else if (request.body != null) {\n    // 2. Otherwise, if body is non-null:\n\n    //    1. Let processBodyChunk given bytes be these steps:\n    const processBodyChunk = async function * (bytes) {\n      // 1. If the ongoing fetch is terminated, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. Run this step in parallel: transmit bytes.\n      yield bytes\n\n      // 3. If fetchParamss process request body is non-null, then run\n      // fetchParamss process request body given bytess length.\n      fetchParams.processRequestBodyChunkLength?.(bytes.byteLength)\n    }\n\n    // 2. Let processEndOfBody be these steps:\n    const processEndOfBody = () => {\n      // 1. If fetchParams is canceled, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. If fetchParamss process request end-of-body is non-null,\n      // then run fetchParamss process request end-of-body.\n      if (fetchParams.processRequestEndOfBody) {\n        fetchParams.processRequestEndOfBody()\n      }\n    }\n\n    // 3. Let processBodyError given e be these steps:\n    const processBodyError = (e) => {\n      // 1. If fetchParams is canceled, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. If e is an \"AbortError\" DOMException, then abort fetchParamss controller.\n      if (e.name === 'AbortError') {\n        fetchParams.controller.abort()\n      } else {\n        fetchParams.controller.terminate(e)\n      }\n    }\n\n    // 4. Incrementally read requests body given processBodyChunk, processEndOfBody,\n    // processBodyError, and fetchParamss task destination.\n    requestBody = (async function * () {\n      try {\n        for await (const bytes of request.body.stream) {\n          yield * processBodyChunk(bytes)\n        }\n        processEndOfBody()\n      } catch (err) {\n        processBodyError(err)\n      }\n    })()\n  }\n\n  try {\n    // socket is only provided for websockets\n    const { body, status, statusText, headersList, socket } = await dispatch({ body: requestBody })\n\n    if (socket) {\n      response = makeResponse({ status, statusText, headersList, socket })\n    } else {\n      const iterator = body[Symbol.asyncIterator]()\n      fetchParams.controller.next = () => iterator.next()\n\n      response = makeResponse({ status, statusText, headersList })\n    }\n  } catch (err) {\n    // 10. If aborted, then:\n    if (err.name === 'AbortError') {\n      // 1. If connection uses HTTP/2, then transmit an RST_STREAM frame.\n      fetchParams.controller.connection.destroy()\n\n      // 2. Return the appropriate network error for fetchParams.\n      return makeAppropriateNetworkError(fetchParams, err)\n    }\n\n    return makeNetworkError(err)\n  }\n\n  // 11. Let pullAlgorithm be an action that resumes the ongoing fetch\n  // if it is suspended.\n  const pullAlgorithm = () => {\n    fetchParams.controller.resume()\n  }\n\n  // 12. Let cancelAlgorithm be an algorithm that aborts fetchParamss\n  // controller with reason, given reason.\n  const cancelAlgorithm = (reason) => {\n    fetchParams.controller.abort(reason)\n  }\n\n  // 13. Let highWaterMark be a non-negative, non-NaN number, chosen by\n  // the user agent.\n  // TODO\n\n  // 14. Let sizeAlgorithm be an algorithm that accepts a chunk object\n  // and returns a non-negative, non-NaN, non-infinite number, chosen by the user agent.\n  // TODO\n\n  // 15. Let stream be a new ReadableStream.\n  // 16. Set up stream with pullAlgorithm set to pullAlgorithm,\n  // cancelAlgorithm set to cancelAlgorithm, highWaterMark set to\n  // highWaterMark, and sizeAlgorithm set to sizeAlgorithm.\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  const stream = new ReadableStream(\n    {\n      async start (controller) {\n        fetchParams.controller.controller = controller\n      },\n      async pull (controller) {\n        await pullAlgorithm(controller)\n      },\n      async cancel (reason) {\n        await cancelAlgorithm(reason)\n      }\n    },\n    {\n      highWaterMark: 0,\n      size () {\n        return 1\n      }\n    }\n  )\n\n  // 17. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. Set responses body to a new body whose stream is stream.\n  response.body = { stream }\n\n  //    2. If response is not a network error and requests cache mode is\n  //    not \"no-store\", then update response in httpCache for request.\n  //    TODO\n\n  //    3. If includeCredentials is true and the user agent is not configured\n  //    to block cookies for request (see section 7 of [COOKIES]), then run the\n  //    \"set-cookie-string\" parsing algorithm (see section 5.2 of [COOKIES]) on\n  //    the value of each header whose name is a byte-case-insensitive match for\n  //    `Set-Cookie` in responses header list, if any, and requests current URL.\n  //    TODO\n\n  // 18. If aborted, then:\n  // TODO\n\n  // 19. Run these steps in parallel:\n\n  //    1. Run these steps, but abort when fetchParams is canceled:\n  fetchParams.controller.on('terminated', onAborted)\n  fetchParams.controller.resume = async () => {\n    // 1. While true\n    while (true) {\n      // 1-3. See onData...\n\n      // 4. Set bytes to the result of handling content codings given\n      // codings and bytes.\n      let bytes\n      let isFailure\n      try {\n        const { done, value } = await fetchParams.controller.next()\n\n        if (isAborted(fetchParams)) {\n          break\n        }\n\n        bytes = done ? undefined : value\n      } catch (err) {\n        if (fetchParams.controller.ended && !timingInfo.encodedBodySize) {\n          // zlib doesn't like empty streams.\n          bytes = undefined\n        } else {\n          bytes = err\n\n          // err may be propagated from the result of calling readablestream.cancel,\n          // which might not be an error. https://github.com/nodejs/undici/issues/2009\n          isFailure = true\n        }\n      }\n\n      if (bytes === undefined) {\n        // 2. Otherwise, if the bytes transmission for responses message\n        // body is done normally and stream is readable, then close\n        // stream, finalize response for fetchParams and response, and\n        // abort these in-parallel steps.\n        readableStreamClose(fetchParams.controller.controller)\n\n        finalizeResponse(fetchParams, response)\n\n        return\n      }\n\n      // 5. Increase timingInfos decoded body size by bytess length.\n      timingInfo.decodedBodySize += bytes?.byteLength ?? 0\n\n      // 6. If bytes is failure, then terminate fetchParamss controller.\n      if (isFailure) {\n        fetchParams.controller.terminate(bytes)\n        return\n      }\n\n      // 7. Enqueue a Uint8Array wrapping an ArrayBuffer containing bytes\n      // into stream.\n      fetchParams.controller.controller.enqueue(new Uint8Array(bytes))\n\n      // 8. If stream is errored, then terminate the ongoing fetch.\n      if (isErrored(stream)) {\n        fetchParams.controller.terminate()\n        return\n      }\n\n      // 9. If stream doesnt need more data ask the user agent to suspend\n      // the ongoing fetch.\n      if (!fetchParams.controller.controller.desiredSize) {\n        return\n      }\n    }\n  }\n\n  //    2. If aborted, then:\n  function onAborted (reason) {\n    // 2. If fetchParams is aborted, then:\n    if (isAborted(fetchParams)) {\n      // 1. Set responses aborted flag.\n      response.aborted = true\n\n      // 2. If stream is readable, then error stream with the result of\n      //    deserialize a serialized abort reason given fetchParamss\n      //    controllers serialized abort reason and an\n      //    implementation-defined realm.\n      if (isReadable(stream)) {\n        fetchParams.controller.controller.error(\n          fetchParams.controller.serializedAbortReason\n        )\n      }\n    } else {\n      // 3. Otherwise, if stream is readable, error stream with a TypeError.\n      if (isReadable(stream)) {\n        fetchParams.controller.controller.error(new TypeError('terminated', {\n          cause: isErrorLike(reason) ? reason : undefined\n        }))\n      }\n    }\n\n    // 4. If connection uses HTTP/2, then transmit an RST_STREAM frame.\n    // 5. Otherwise, the user agent should close connection unless it would be bad for performance to do so.\n    fetchParams.controller.connection.destroy()\n  }\n\n  // 20. Return response.\n  return response\n\n  async function dispatch ({ body }) {\n    const url = requestCurrentURL(request)\n    /** @type {import('../..').Agent} */\n    const agent = fetchParams.controller.dispatcher\n\n    return new Promise((resolve, reject) => agent.dispatch(\n      {\n        path: url.pathname + url.search,\n        origin: url.origin,\n        method: request.method,\n        body: fetchParams.controller.dispatcher.isMockActive ? request.body && (request.body.source || request.body.stream) : body,\n        headers: request.headersList.entries,\n        maxRedirections: 0,\n        upgrade: request.mode === 'websocket' ? 'websocket' : undefined\n      },\n      {\n        body: null,\n        abort: null,\n\n        onConnect (abort) {\n          // TODO (fix): Do we need connection here?\n          const { connection } = fetchParams.controller\n\n          if (connection.destroyed) {\n            abort(new DOMException('The operation was aborted.', 'AbortError'))\n          } else {\n            fetchParams.controller.on('terminated', abort)\n            this.abort = connection.abort = abort\n          }\n        },\n\n        onHeaders (status, headersList, resume, statusText) {\n          if (status < 200) {\n            return\n          }\n\n          let codings = []\n          let location = ''\n\n          const headers = new Headers()\n\n          // For H2, the headers are a plain JS object\n          // We distinguish between them and iterate accordingly\n          if (Array.isArray(headersList)) {\n            for (let n = 0; n < headersList.length; n += 2) {\n              const key = headersList[n + 0].toString('latin1')\n              const val = headersList[n + 1].toString('latin1')\n              if (key.toLowerCase() === 'content-encoding') {\n                // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1\n                // \"All content-coding values are case-insensitive...\"\n                codings = val.toLowerCase().split(',').map((x) => x.trim())\n              } else if (key.toLowerCase() === 'location') {\n                location = val\n              }\n\n              headers[kHeadersList].append(key, val)\n            }\n          } else {\n            const keys = Object.keys(headersList)\n            for (const key of keys) {\n              const val = headersList[key]\n              if (key.toLowerCase() === 'content-encoding') {\n                // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1\n                // \"All content-coding values are case-insensitive...\"\n                codings = val.toLowerCase().split(',').map((x) => x.trim()).reverse()\n              } else if (key.toLowerCase() === 'location') {\n                location = val\n              }\n\n              headers[kHeadersList].append(key, val)\n            }\n          }\n\n          this.body = new Readable({ read: resume })\n\n          const decoders = []\n\n          const willFollow = request.redirect === 'follow' &&\n            location &&\n            redirectStatusSet.has(status)\n\n          // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding\n          if (request.method !== 'HEAD' && request.method !== 'CONNECT' && !nullBodyStatus.includes(status) && !willFollow) {\n            for (const coding of codings) {\n              // https://www.rfc-editor.org/rfc/rfc9112.html#section-7.2\n              if (coding === 'x-gzip' || coding === 'gzip') {\n                decoders.push(zlib.createGunzip({\n                  // Be less strict when decoding compressed responses, since sometimes\n                  // servers send slightly invalid responses that are still accepted\n                  // by common browsers.\n                  // Always using Z_SYNC_FLUSH is what cURL does.\n                  flush: zlib.constants.Z_SYNC_FLUSH,\n                  finishFlush: zlib.constants.Z_SYNC_FLUSH\n                }))\n              } else if (coding === 'deflate') {\n                decoders.push(zlib.createInflate())\n              } else if (coding === 'br') {\n                decoders.push(zlib.createBrotliDecompress())\n              } else {\n                decoders.length = 0\n                break\n              }\n            }\n          }\n\n          resolve({\n            status,\n            statusText,\n            headersList: headers[kHeadersList],\n            body: decoders.length\n              ? pipeline(this.body, ...decoders, () => { })\n              : this.body.on('error', () => {})\n          })\n\n          return true\n        },\n\n        onData (chunk) {\n          if (fetchParams.controller.dump) {\n            return\n          }\n\n          // 1. If one or more bytes have been transmitted from responses\n          // message body, then:\n\n          //  1. Let bytes be the transmitted bytes.\n          const bytes = chunk\n\n          //  2. Let codings be the result of extracting header list values\n          //  given `Content-Encoding` and responses header list.\n          //  See pullAlgorithm.\n\n          //  3. Increase timingInfos encoded body size by bytess length.\n          timingInfo.encodedBodySize += bytes.byteLength\n\n          //  4. See pullAlgorithm...\n\n          return this.body.push(bytes)\n        },\n\n        onComplete () {\n          if (this.abort) {\n            fetchParams.controller.off('terminated', this.abort)\n          }\n\n          fetchParams.controller.ended = true\n\n          this.body.push(null)\n        },\n\n        onError (error) {\n          if (this.abort) {\n            fetchParams.controller.off('terminated', this.abort)\n          }\n\n          this.body?.destroy(error)\n\n          fetchParams.controller.terminate(error)\n\n          reject(error)\n        },\n\n        onUpgrade (status, headersList, socket) {\n          if (status !== 101) {\n            return\n          }\n\n          const headers = new Headers()\n\n          for (let n = 0; n < headersList.length; n += 2) {\n            const key = headersList[n + 0].toString('latin1')\n            const val = headersList[n + 1].toString('latin1')\n\n            headers[kHeadersList].append(key, val)\n          }\n\n          resolve({\n            status,\n            statusText: STATUS_CODES[status],\n            headersList: headers[kHeadersList],\n            socket\n          })\n\n          return true\n        }\n      }\n    ))\n  }\n}\n\nmodule.exports = {\n  fetch,\n  Fetch,\n  fetching,\n  finalizeAndReportTiming\n}\n","/* globals AbortController */\n\n'use strict'\n\nconst { extractBody, mixinBody, cloneBody } = require('./body')\nconst { Headers, fill: fillHeaders, HeadersList } = require('./headers')\nconst { FinalizationRegistry } = require('../compat/dispatcher-weakref')()\nconst util = require('../core/util')\nconst {\n  isValidHTTPToken,\n  sameOrigin,\n  normalizeMethod,\n  makePolicyContainer,\n  normalizeMethodRecord\n} = require('./util')\nconst {\n  forbiddenMethodsSet,\n  corsSafeListedMethodsSet,\n  referrerPolicy,\n  requestRedirect,\n  requestMode,\n  requestCredentials,\n  requestCache,\n  requestDuplex\n} = require('./constants')\nconst { kEnumerableProperty } = util\nconst { kHeaders, kSignal, kState, kGuard, kRealm } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { getGlobalOrigin } = require('./global')\nconst { URLSerializer } = require('./dataURL')\nconst { kHeadersList, kConstruct } = require('../core/symbols')\nconst assert = require('assert')\nconst { getMaxListeners, setMaxListeners, getEventListeners, defaultMaxListeners } = require('events')\n\nlet TransformStream = globalThis.TransformStream\n\nconst kAbortController = Symbol('abortController')\n\nconst requestFinalizer = new FinalizationRegistry(({ signal, abort }) => {\n  signal.removeEventListener('abort', abort)\n})\n\n// https://fetch.spec.whatwg.org/#request-class\nclass Request {\n  // https://fetch.spec.whatwg.org/#dom-request\n  constructor (input, init = {}) {\n    if (input === kConstruct) {\n      return\n    }\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Request constructor' })\n\n    input = webidl.converters.RequestInfo(input)\n    init = webidl.converters.RequestInit(init)\n\n    // https://html.spec.whatwg.org/multipage/webappapis.html#environment-settings-object\n    this[kRealm] = {\n      settingsObject: {\n        baseUrl: getGlobalOrigin(),\n        get origin () {\n          return this.baseUrl?.origin\n        },\n        policyContainer: makePolicyContainer()\n      }\n    }\n\n    // 1. Let request be null.\n    let request = null\n\n    // 2. Let fallbackMode be null.\n    let fallbackMode = null\n\n    // 3. Let baseURL be thiss relevant settings objects API base URL.\n    const baseUrl = this[kRealm].settingsObject.baseUrl\n\n    // 4. Let signal be null.\n    let signal = null\n\n    // 5. If input is a string, then:\n    if (typeof input === 'string') {\n      // 1. Let parsedURL be the result of parsing input with baseURL.\n      // 2. If parsedURL is failure, then throw a TypeError.\n      let parsedURL\n      try {\n        parsedURL = new URL(input, baseUrl)\n      } catch (err) {\n        throw new TypeError('Failed to parse URL from ' + input, { cause: err })\n      }\n\n      // 3. If parsedURL includes credentials, then throw a TypeError.\n      if (parsedURL.username || parsedURL.password) {\n        throw new TypeError(\n          'Request cannot be constructed from a URL that includes credentials: ' +\n            input\n        )\n      }\n\n      // 4. Set request to a new request whose URL is parsedURL.\n      request = makeRequest({ urlList: [parsedURL] })\n\n      // 5. Set fallbackMode to \"cors\".\n      fallbackMode = 'cors'\n    } else {\n      // 6. Otherwise:\n\n      // 7. Assert: input is a Request object.\n      assert(input instanceof Request)\n\n      // 8. Set request to inputs request.\n      request = input[kState]\n\n      // 9. Set signal to inputs signal.\n      signal = input[kSignal]\n    }\n\n    // 7. Let origin be thiss relevant settings objects origin.\n    const origin = this[kRealm].settingsObject.origin\n\n    // 8. Let window be \"client\".\n    let window = 'client'\n\n    // 9. If requests window is an environment settings object and its origin\n    // is same origin with origin, then set window to requests window.\n    if (\n      request.window?.constructor?.name === 'EnvironmentSettingsObject' &&\n      sameOrigin(request.window, origin)\n    ) {\n      window = request.window\n    }\n\n    // 10. If init[\"window\"] exists and is non-null, then throw a TypeError.\n    if (init.window != null) {\n      throw new TypeError(`'window' option '${window}' must be null`)\n    }\n\n    // 11. If init[\"window\"] exists, then set window to \"no-window\".\n    if ('window' in init) {\n      window = 'no-window'\n    }\n\n    // 12. Set request to a new request with the following properties:\n    request = makeRequest({\n      // URL requests URL.\n      // undici implementation note: this is set as the first item in request's urlList in makeRequest\n      // method requests method.\n      method: request.method,\n      // header list A copy of requests header list.\n      // undici implementation note: headersList is cloned in makeRequest\n      headersList: request.headersList,\n      // unsafe-request flag Set.\n      unsafeRequest: request.unsafeRequest,\n      // client Thiss relevant settings object.\n      client: this[kRealm].settingsObject,\n      // window window.\n      window,\n      // priority requests priority.\n      priority: request.priority,\n      // origin requests origin. The propagation of the origin is only significant for navigation requests\n      // being handled by a service worker. In this scenario a request can have an origin that is different\n      // from the current client.\n      origin: request.origin,\n      // referrer requests referrer.\n      referrer: request.referrer,\n      // referrer policy requests referrer policy.\n      referrerPolicy: request.referrerPolicy,\n      // mode requests mode.\n      mode: request.mode,\n      // credentials mode requests credentials mode.\n      credentials: request.credentials,\n      // cache mode requests cache mode.\n      cache: request.cache,\n      // redirect mode requests redirect mode.\n      redirect: request.redirect,\n      // integrity metadata requests integrity metadata.\n      integrity: request.integrity,\n      // keepalive requests keepalive.\n      keepalive: request.keepalive,\n      // reload-navigation flag requests reload-navigation flag.\n      reloadNavigation: request.reloadNavigation,\n      // history-navigation flag requests history-navigation flag.\n      historyNavigation: request.historyNavigation,\n      // URL list A clone of requests URL list.\n      urlList: [...request.urlList]\n    })\n\n    const initHasKey = Object.keys(init).length !== 0\n\n    // 13. If init is not empty, then:\n    if (initHasKey) {\n      // 1. If requests mode is \"navigate\", then set it to \"same-origin\".\n      if (request.mode === 'navigate') {\n        request.mode = 'same-origin'\n      }\n\n      // 2. Unset requests reload-navigation flag.\n      request.reloadNavigation = false\n\n      // 3. Unset requests history-navigation flag.\n      request.historyNavigation = false\n\n      // 4. Set requests origin to \"client\".\n      request.origin = 'client'\n\n      // 5. Set requests referrer to \"client\"\n      request.referrer = 'client'\n\n      // 6. Set requests referrer policy to the empty string.\n      request.referrerPolicy = ''\n\n      // 7. Set requests URL to requests current URL.\n      request.url = request.urlList[request.urlList.length - 1]\n\n      // 8. Set requests URL list to  requests URL .\n      request.urlList = [request.url]\n    }\n\n    // 14. If init[\"referrer\"] exists, then:\n    if (init.referrer !== undefined) {\n      // 1. Let referrer be init[\"referrer\"].\n      const referrer = init.referrer\n\n      // 2. If referrer is the empty string, then set requests referrer to \"no-referrer\".\n      if (referrer === '') {\n        request.referrer = 'no-referrer'\n      } else {\n        // 1. Let parsedReferrer be the result of parsing referrer with\n        // baseURL.\n        // 2. If parsedReferrer is failure, then throw a TypeError.\n        let parsedReferrer\n        try {\n          parsedReferrer = new URL(referrer, baseUrl)\n        } catch (err) {\n          throw new TypeError(`Referrer \"${referrer}\" is not a valid URL.`, { cause: err })\n        }\n\n        // 3. If one of the following is true\n        // - parsedReferrers scheme is \"about\" and path is the string \"client\"\n        // - parsedReferrers origin is not same origin with origin\n        // then set requests referrer to \"client\".\n        if (\n          (parsedReferrer.protocol === 'about:' && parsedReferrer.hostname === 'client') ||\n          (origin && !sameOrigin(parsedReferrer, this[kRealm].settingsObject.baseUrl))\n        ) {\n          request.referrer = 'client'\n        } else {\n          // 4. Otherwise, set requests referrer to parsedReferrer.\n          request.referrer = parsedReferrer\n        }\n      }\n    }\n\n    // 15. If init[\"referrerPolicy\"] exists, then set requests referrer policy\n    // to it.\n    if (init.referrerPolicy !== undefined) {\n      request.referrerPolicy = init.referrerPolicy\n    }\n\n    // 16. Let mode be init[\"mode\"] if it exists, and fallbackMode otherwise.\n    let mode\n    if (init.mode !== undefined) {\n      mode = init.mode\n    } else {\n      mode = fallbackMode\n    }\n\n    // 17. If mode is \"navigate\", then throw a TypeError.\n    if (mode === 'navigate') {\n      throw webidl.errors.exception({\n        header: 'Request constructor',\n        message: 'invalid request mode navigate.'\n      })\n    }\n\n    // 18. If mode is non-null, set requests mode to mode.\n    if (mode != null) {\n      request.mode = mode\n    }\n\n    // 19. If init[\"credentials\"] exists, then set requests credentials mode\n    // to it.\n    if (init.credentials !== undefined) {\n      request.credentials = init.credentials\n    }\n\n    // 18. If init[\"cache\"] exists, then set requests cache mode to it.\n    if (init.cache !== undefined) {\n      request.cache = init.cache\n    }\n\n    // 21. If requests cache mode is \"only-if-cached\" and requests mode is\n    // not \"same-origin\", then throw a TypeError.\n    if (request.cache === 'only-if-cached' && request.mode !== 'same-origin') {\n      throw new TypeError(\n        \"'only-if-cached' can be set only with 'same-origin' mode\"\n      )\n    }\n\n    // 22. If init[\"redirect\"] exists, then set requests redirect mode to it.\n    if (init.redirect !== undefined) {\n      request.redirect = init.redirect\n    }\n\n    // 23. If init[\"integrity\"] exists, then set requests integrity metadata to it.\n    if (init.integrity != null) {\n      request.integrity = String(init.integrity)\n    }\n\n    // 24. If init[\"keepalive\"] exists, then set requests keepalive to it.\n    if (init.keepalive !== undefined) {\n      request.keepalive = Boolean(init.keepalive)\n    }\n\n    // 25. If init[\"method\"] exists, then:\n    if (init.method !== undefined) {\n      // 1. Let method be init[\"method\"].\n      let method = init.method\n\n      // 2. If method is not a method or method is a forbidden method, then\n      // throw a TypeError.\n      if (!isValidHTTPToken(method)) {\n        throw new TypeError(`'${method}' is not a valid HTTP method.`)\n      }\n\n      if (forbiddenMethodsSet.has(method.toUpperCase())) {\n        throw new TypeError(`'${method}' HTTP method is unsupported.`)\n      }\n\n      // 3. Normalize method.\n      method = normalizeMethodRecord[method] ?? normalizeMethod(method)\n\n      // 4. Set requests method to method.\n      request.method = method\n    }\n\n    // 26. If init[\"signal\"] exists, then set signal to it.\n    if (init.signal !== undefined) {\n      signal = init.signal\n    }\n\n    // 27. Set thiss request to request.\n    this[kState] = request\n\n    // 28. Set thiss signal to a new AbortSignal object with thiss relevant\n    // Realm.\n    // TODO: could this be simplified with AbortSignal.any\n    // (https://dom.spec.whatwg.org/#dom-abortsignal-any)\n    const ac = new AbortController()\n    this[kSignal] = ac.signal\n    this[kSignal][kRealm] = this[kRealm]\n\n    // 29. If signal is not null, then make thiss signal follow signal.\n    if (signal != null) {\n      if (\n        !signal ||\n        typeof signal.aborted !== 'boolean' ||\n        typeof signal.addEventListener !== 'function'\n      ) {\n        throw new TypeError(\n          \"Failed to construct 'Request': member signal is not of type AbortSignal.\"\n        )\n      }\n\n      if (signal.aborted) {\n        ac.abort(signal.reason)\n      } else {\n        // Keep a strong ref to ac while request object\n        // is alive. This is needed to prevent AbortController\n        // from being prematurely garbage collected.\n        // See, https://github.com/nodejs/undici/issues/1926.\n        this[kAbortController] = ac\n\n        const acRef = new WeakRef(ac)\n        const abort = function () {\n          const ac = acRef.deref()\n          if (ac !== undefined) {\n            ac.abort(this.reason)\n          }\n        }\n\n        // Third-party AbortControllers may not work with these.\n        // See, https://github.com/nodejs/undici/pull/1910#issuecomment-1464495619.\n        try {\n          // If the max amount of listeners is equal to the default, increase it\n          // This is only available in node >= v19.9.0\n          if (typeof getMaxListeners === 'function' && getMaxListeners(signal) === defaultMaxListeners) {\n            setMaxListeners(100, signal)\n          } else if (getEventListeners(signal, 'abort').length >= defaultMaxListeners) {\n            setMaxListeners(100, signal)\n          }\n        } catch {}\n\n        util.addAbortListener(signal, abort)\n        requestFinalizer.register(ac, { signal, abort })\n      }\n    }\n\n    // 30. Set thiss headers to a new Headers object with thiss relevant\n    // Realm, whose header list is requests header list and guard is\n    // \"request\".\n    this[kHeaders] = new Headers(kConstruct)\n    this[kHeaders][kHeadersList] = request.headersList\n    this[kHeaders][kGuard] = 'request'\n    this[kHeaders][kRealm] = this[kRealm]\n\n    // 31. If thiss requests mode is \"no-cors\", then:\n    if (mode === 'no-cors') {\n      // 1. If thiss requests method is not a CORS-safelisted method,\n      // then throw a TypeError.\n      if (!corsSafeListedMethodsSet.has(request.method)) {\n        throw new TypeError(\n          `'${request.method} is unsupported in no-cors mode.`\n        )\n      }\n\n      // 2. Set thiss headerss guard to \"request-no-cors\".\n      this[kHeaders][kGuard] = 'request-no-cors'\n    }\n\n    // 32. If init is not empty, then:\n    if (initHasKey) {\n      /** @type {HeadersList} */\n      const headersList = this[kHeaders][kHeadersList]\n      // 1. Let headers be a copy of thiss headers and its associated header\n      // list.\n      // 2. If init[\"headers\"] exists, then set headers to init[\"headers\"].\n      const headers = init.headers !== undefined ? init.headers : new HeadersList(headersList)\n\n      // 3. Empty thiss headerss header list.\n      headersList.clear()\n\n      // 4. If headers is a Headers object, then for each header in its header\n      // list, append headers name/headers value to thiss headers.\n      if (headers instanceof HeadersList) {\n        for (const [key, val] of headers) {\n          headersList.append(key, val)\n        }\n        // Note: Copy the `set-cookie` meta-data.\n        headersList.cookies = headers.cookies\n      } else {\n        // 5. Otherwise, fill thiss headers with headers.\n        fillHeaders(this[kHeaders], headers)\n      }\n    }\n\n    // 33. Let inputBody be inputs requests body if input is a Request\n    // object; otherwise null.\n    const inputBody = input instanceof Request ? input[kState].body : null\n\n    // 34. If either init[\"body\"] exists and is non-null or inputBody is\n    // non-null, and requests method is `GET` or `HEAD`, then throw a\n    // TypeError.\n    if (\n      (init.body != null || inputBody != null) &&\n      (request.method === 'GET' || request.method === 'HEAD')\n    ) {\n      throw new TypeError('Request with GET/HEAD method cannot have body.')\n    }\n\n    // 35. Let initBody be null.\n    let initBody = null\n\n    // 36. If init[\"body\"] exists and is non-null, then:\n    if (init.body != null) {\n      // 1. Let Content-Type be null.\n      // 2. Set initBody and Content-Type to the result of extracting\n      // init[\"body\"], with keepalive set to requests keepalive.\n      const [extractedBody, contentType] = extractBody(\n        init.body,\n        request.keepalive\n      )\n      initBody = extractedBody\n\n      // 3, If Content-Type is non-null and thiss headerss header list does\n      // not contain `Content-Type`, then append `Content-Type`/Content-Type to\n      // thiss headers.\n      if (contentType && !this[kHeaders][kHeadersList].contains('content-type')) {\n        this[kHeaders].append('content-type', contentType)\n      }\n    }\n\n    // 37. Let inputOrInitBody be initBody if it is non-null; otherwise\n    // inputBody.\n    const inputOrInitBody = initBody ?? inputBody\n\n    // 38. If inputOrInitBody is non-null and inputOrInitBodys source is\n    // null, then:\n    if (inputOrInitBody != null && inputOrInitBody.source == null) {\n      // 1. If initBody is non-null and init[\"duplex\"] does not exist,\n      //    then throw a TypeError.\n      if (initBody != null && init.duplex == null) {\n        throw new TypeError('RequestInit: duplex option is required when sending a body.')\n      }\n\n      // 2. If thiss requests mode is neither \"same-origin\" nor \"cors\",\n      // then throw a TypeError.\n      if (request.mode !== 'same-origin' && request.mode !== 'cors') {\n        throw new TypeError(\n          'If request is made from ReadableStream, mode should be \"same-origin\" or \"cors\"'\n        )\n      }\n\n      // 3. Set thiss requests use-CORS-preflight flag.\n      request.useCORSPreflightFlag = true\n    }\n\n    // 39. Let finalBody be inputOrInitBody.\n    let finalBody = inputOrInitBody\n\n    // 40. If initBody is null and inputBody is non-null, then:\n    if (initBody == null && inputBody != null) {\n      // 1. If input is unusable, then throw a TypeError.\n      if (util.isDisturbed(inputBody.stream) || inputBody.stream.locked) {\n        throw new TypeError(\n          'Cannot construct a Request with a Request object that has already been used.'\n        )\n      }\n\n      // 2. Set finalBody to the result of creating a proxy for inputBody.\n      if (!TransformStream) {\n        TransformStream = require('stream/web').TransformStream\n      }\n\n      // https://streams.spec.whatwg.org/#readablestream-create-a-proxy\n      const identityTransform = new TransformStream()\n      inputBody.stream.pipeThrough(identityTransform)\n      finalBody = {\n        source: inputBody.source,\n        length: inputBody.length,\n        stream: identityTransform.readable\n      }\n    }\n\n    // 41. Set thiss requests body to finalBody.\n    this[kState].body = finalBody\n  }\n\n  // Returns requests HTTP method, which is \"GET\" by default.\n  get method () {\n    webidl.brandCheck(this, Request)\n\n    // The method getter steps are to return thiss requests method.\n    return this[kState].method\n  }\n\n  // Returns the URL of request as a string.\n  get url () {\n    webidl.brandCheck(this, Request)\n\n    // The url getter steps are to return thiss requests URL, serialized.\n    return URLSerializer(this[kState].url)\n  }\n\n  // Returns a Headers object consisting of the headers associated with request.\n  // Note that headers added in the network layer by the user agent will not\n  // be accounted for in this object, e.g., the \"Host\" header.\n  get headers () {\n    webidl.brandCheck(this, Request)\n\n    // The headers getter steps are to return thiss headers.\n    return this[kHeaders]\n  }\n\n  // Returns the kind of resource requested by request, e.g., \"document\"\n  // or \"script\".\n  get destination () {\n    webidl.brandCheck(this, Request)\n\n    // The destination getter are to return thiss requests destination.\n    return this[kState].destination\n  }\n\n  // Returns the referrer of request. Its value can be a same-origin URL if\n  // explicitly set in init, the empty string to indicate no referrer, and\n  // \"about:client\" when defaulting to the globals default. This is used\n  // during fetching to determine the value of the `Referer` header of the\n  // request being made.\n  get referrer () {\n    webidl.brandCheck(this, Request)\n\n    // 1. If thiss requests referrer is \"no-referrer\", then return the\n    // empty string.\n    if (this[kState].referrer === 'no-referrer') {\n      return ''\n    }\n\n    // 2. If thiss requests referrer is \"client\", then return\n    // \"about:client\".\n    if (this[kState].referrer === 'client') {\n      return 'about:client'\n    }\n\n    // Return thiss requests referrer, serialized.\n    return this[kState].referrer.toString()\n  }\n\n  // Returns the referrer policy associated with request.\n  // This is used during fetching to compute the value of the requests\n  // referrer.\n  get referrerPolicy () {\n    webidl.brandCheck(this, Request)\n\n    // The referrerPolicy getter steps are to return thiss requests referrer policy.\n    return this[kState].referrerPolicy\n  }\n\n  // Returns the mode associated with request, which is a string indicating\n  // whether the request will use CORS, or will be restricted to same-origin\n  // URLs.\n  get mode () {\n    webidl.brandCheck(this, Request)\n\n    // The mode getter steps are to return thiss requests mode.\n    return this[kState].mode\n  }\n\n  // Returns the credentials mode associated with request,\n  // which is a string indicating whether credentials will be sent with the\n  // request always, never, or only when sent to a same-origin URL.\n  get credentials () {\n    // The credentials getter steps are to return thiss requests credentials mode.\n    return this[kState].credentials\n  }\n\n  // Returns the cache mode associated with request,\n  // which is a string indicating how the request will\n  // interact with the browsers cache when fetching.\n  get cache () {\n    webidl.brandCheck(this, Request)\n\n    // The cache getter steps are to return thiss requests cache mode.\n    return this[kState].cache\n  }\n\n  // Returns the redirect mode associated with request,\n  // which is a string indicating how redirects for the\n  // request will be handled during fetching. A request\n  // will follow redirects by default.\n  get redirect () {\n    webidl.brandCheck(this, Request)\n\n    // The redirect getter steps are to return thiss requests redirect mode.\n    return this[kState].redirect\n  }\n\n  // Returns requests subresource integrity metadata, which is a\n  // cryptographic hash of the resource being fetched. Its value\n  // consists of multiple hashes separated by whitespace. [SRI]\n  get integrity () {\n    webidl.brandCheck(this, Request)\n\n    // The integrity getter steps are to return thiss requests integrity\n    // metadata.\n    return this[kState].integrity\n  }\n\n  // Returns a boolean indicating whether or not request can outlive the\n  // global in which it was created.\n  get keepalive () {\n    webidl.brandCheck(this, Request)\n\n    // The keepalive getter steps are to return thiss requests keepalive.\n    return this[kState].keepalive\n  }\n\n  // Returns a boolean indicating whether or not request is for a reload\n  // navigation.\n  get isReloadNavigation () {\n    webidl.brandCheck(this, Request)\n\n    // The isReloadNavigation getter steps are to return true if thiss\n    // requests reload-navigation flag is set; otherwise false.\n    return this[kState].reloadNavigation\n  }\n\n  // Returns a boolean indicating whether or not request is for a history\n  // navigation (a.k.a. back-foward navigation).\n  get isHistoryNavigation () {\n    webidl.brandCheck(this, Request)\n\n    // The isHistoryNavigation getter steps are to return true if thiss requests\n    // history-navigation flag is set; otherwise false.\n    return this[kState].historyNavigation\n  }\n\n  // Returns the signal associated with request, which is an AbortSignal\n  // object indicating whether or not request has been aborted, and its\n  // abort event handler.\n  get signal () {\n    webidl.brandCheck(this, Request)\n\n    // The signal getter steps are to return thiss signal.\n    return this[kSignal]\n  }\n\n  get body () {\n    webidl.brandCheck(this, Request)\n\n    return this[kState].body ? this[kState].body.stream : null\n  }\n\n  get bodyUsed () {\n    webidl.brandCheck(this, Request)\n\n    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)\n  }\n\n  get duplex () {\n    webidl.brandCheck(this, Request)\n\n    return 'half'\n  }\n\n  // Returns a clone of request.\n  clone () {\n    webidl.brandCheck(this, Request)\n\n    // 1. If this is unusable, then throw a TypeError.\n    if (this.bodyUsed || this.body?.locked) {\n      throw new TypeError('unusable')\n    }\n\n    // 2. Let clonedRequest be the result of cloning thiss request.\n    const clonedRequest = cloneRequest(this[kState])\n\n    // 3. Let clonedRequestObject be the result of creating a Request object,\n    // given clonedRequest, thiss headerss guard, and thiss relevant Realm.\n    const clonedRequestObject = new Request(kConstruct)\n    clonedRequestObject[kState] = clonedRequest\n    clonedRequestObject[kRealm] = this[kRealm]\n    clonedRequestObject[kHeaders] = new Headers(kConstruct)\n    clonedRequestObject[kHeaders][kHeadersList] = clonedRequest.headersList\n    clonedRequestObject[kHeaders][kGuard] = this[kHeaders][kGuard]\n    clonedRequestObject[kHeaders][kRealm] = this[kHeaders][kRealm]\n\n    // 4. Make clonedRequestObjects signal follow thiss signal.\n    const ac = new AbortController()\n    if (this.signal.aborted) {\n      ac.abort(this.signal.reason)\n    } else {\n      util.addAbortListener(\n        this.signal,\n        () => {\n          ac.abort(this.signal.reason)\n        }\n      )\n    }\n    clonedRequestObject[kSignal] = ac.signal\n\n    // 4. Return clonedRequestObject.\n    return clonedRequestObject\n  }\n}\n\nmixinBody(Request)\n\nfunction makeRequest (init) {\n  // https://fetch.spec.whatwg.org/#requests\n  const request = {\n    method: 'GET',\n    localURLsOnly: false,\n    unsafeRequest: false,\n    body: null,\n    client: null,\n    reservedClient: null,\n    replacesClientId: '',\n    window: 'client',\n    keepalive: false,\n    serviceWorkers: 'all',\n    initiator: '',\n    destination: '',\n    priority: null,\n    origin: 'client',\n    policyContainer: 'client',\n    referrer: 'client',\n    referrerPolicy: '',\n    mode: 'no-cors',\n    useCORSPreflightFlag: false,\n    credentials: 'same-origin',\n    useCredentials: false,\n    cache: 'default',\n    redirect: 'follow',\n    integrity: '',\n    cryptoGraphicsNonceMetadata: '',\n    parserMetadata: '',\n    reloadNavigation: false,\n    historyNavigation: false,\n    userActivation: false,\n    taintedOrigin: false,\n    redirectCount: 0,\n    responseTainting: 'basic',\n    preventNoCacheCacheControlHeaderModification: false,\n    done: false,\n    timingAllowFailed: false,\n    ...init,\n    headersList: init.headersList\n      ? new HeadersList(init.headersList)\n      : new HeadersList()\n  }\n  request.url = request.urlList[0]\n  return request\n}\n\n// https://fetch.spec.whatwg.org/#concept-request-clone\nfunction cloneRequest (request) {\n  // To clone a request request, run these steps:\n\n  // 1. Let newRequest be a copy of request, except for its body.\n  const newRequest = makeRequest({ ...request, body: null })\n\n  // 2. If requests body is non-null, set newRequests body to the\n  // result of cloning requests body.\n  if (request.body != null) {\n    newRequest.body = cloneBody(request.body)\n  }\n\n  // 3. Return newRequest.\n  return newRequest\n}\n\nObject.defineProperties(Request.prototype, {\n  method: kEnumerableProperty,\n  url: kEnumerableProperty,\n  headers: kEnumerableProperty,\n  redirect: kEnumerableProperty,\n  clone: kEnumerableProperty,\n  signal: kEnumerableProperty,\n  duplex: kEnumerableProperty,\n  destination: kEnumerableProperty,\n  body: kEnumerableProperty,\n  bodyUsed: kEnumerableProperty,\n  isHistoryNavigation: kEnumerableProperty,\n  isReloadNavigation: kEnumerableProperty,\n  keepalive: kEnumerableProperty,\n  integrity: kEnumerableProperty,\n  cache: kEnumerableProperty,\n  credentials: kEnumerableProperty,\n  attribute: kEnumerableProperty,\n  referrerPolicy: kEnumerableProperty,\n  referrer: kEnumerableProperty,\n  mode: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'Request',\n    configurable: true\n  }\n})\n\nwebidl.converters.Request = webidl.interfaceConverter(\n  Request\n)\n\n// https://fetch.spec.whatwg.org/#requestinfo\nwebidl.converters.RequestInfo = function (V) {\n  if (typeof V === 'string') {\n    return webidl.converters.USVString(V)\n  }\n\n  if (V instanceof Request) {\n    return webidl.converters.Request(V)\n  }\n\n  return webidl.converters.USVString(V)\n}\n\nwebidl.converters.AbortSignal = webidl.interfaceConverter(\n  AbortSignal\n)\n\n// https://fetch.spec.whatwg.org/#requestinit\nwebidl.converters.RequestInit = webidl.dictionaryConverter([\n  {\n    key: 'method',\n    converter: webidl.converters.ByteString\n  },\n  {\n    key: 'headers',\n    converter: webidl.converters.HeadersInit\n  },\n  {\n    key: 'body',\n    converter: webidl.nullableConverter(\n      webidl.converters.BodyInit\n    )\n  },\n  {\n    key: 'referrer',\n    converter: webidl.converters.USVString\n  },\n  {\n    key: 'referrerPolicy',\n    converter: webidl.converters.DOMString,\n    // https://w3c.github.io/webappsec-referrer-policy/#referrer-policy\n    allowedValues: referrerPolicy\n  },\n  {\n    key: 'mode',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#concept-request-mode\n    allowedValues: requestMode\n  },\n  {\n    key: 'credentials',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestcredentials\n    allowedValues: requestCredentials\n  },\n  {\n    key: 'cache',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestcache\n    allowedValues: requestCache\n  },\n  {\n    key: 'redirect',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestredirect\n    allowedValues: requestRedirect\n  },\n  {\n    key: 'integrity',\n    converter: webidl.converters.DOMString\n  },\n  {\n    key: 'keepalive',\n    converter: webidl.converters.boolean\n  },\n  {\n    key: 'signal',\n    converter: webidl.nullableConverter(\n      (signal) => webidl.converters.AbortSignal(\n        signal,\n        { strict: false }\n      )\n    )\n  },\n  {\n    key: 'window',\n    converter: webidl.converters.any\n  },\n  {\n    key: 'duplex',\n    converter: webidl.converters.DOMString,\n    allowedValues: requestDuplex\n  }\n])\n\nmodule.exports = { Request, makeRequest }\n","'use strict'\n\nconst { Headers, HeadersList, fill } = require('./headers')\nconst { extractBody, cloneBody, mixinBody } = require('./body')\nconst util = require('../core/util')\nconst { kEnumerableProperty } = util\nconst {\n  isValidReasonPhrase,\n  isCancelled,\n  isAborted,\n  isBlobLike,\n  serializeJavascriptValueToJSONString,\n  isErrorLike,\n  isomorphicEncode\n} = require('./util')\nconst {\n  redirectStatusSet,\n  nullBodyStatus,\n  DOMException\n} = require('./constants')\nconst { kState, kHeaders, kGuard, kRealm } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { FormData } = require('./formdata')\nconst { getGlobalOrigin } = require('./global')\nconst { URLSerializer } = require('./dataURL')\nconst { kHeadersList, kConstruct } = require('../core/symbols')\nconst assert = require('assert')\nconst { types } = require('util')\n\nconst ReadableStream = globalThis.ReadableStream || require('stream/web').ReadableStream\nconst textEncoder = new TextEncoder('utf-8')\n\n// https://fetch.spec.whatwg.org/#response-class\nclass Response {\n  // Creates network error Response.\n  static error () {\n    // TODO\n    const relevantRealm = { settingsObject: {} }\n\n    // The static error() method steps are to return the result of creating a\n    // Response object, given a new network error, \"immutable\", and thiss\n    // relevant Realm.\n    const responseObject = new Response()\n    responseObject[kState] = makeNetworkError()\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kHeadersList] = responseObject[kState].headersList\n    responseObject[kHeaders][kGuard] = 'immutable'\n    responseObject[kHeaders][kRealm] = relevantRealm\n    return responseObject\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-response-json\n  static json (data, init = {}) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Response.json' })\n\n    if (init !== null) {\n      init = webidl.converters.ResponseInit(init)\n    }\n\n    // 1. Let bytes the result of running serialize a JavaScript value to JSON bytes on data.\n    const bytes = textEncoder.encode(\n      serializeJavascriptValueToJSONString(data)\n    )\n\n    // 2. Let body be the result of extracting bytes.\n    const body = extractBody(bytes)\n\n    // 3. Let responseObject be the result of creating a Response object, given a new response,\n    //    \"response\", and thiss relevant Realm.\n    const relevantRealm = { settingsObject: {} }\n    const responseObject = new Response()\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kGuard] = 'response'\n    responseObject[kHeaders][kRealm] = relevantRealm\n\n    // 4. Perform initialize a response given responseObject, init, and (body, \"application/json\").\n    initializeResponse(responseObject, init, { body: body[0], type: 'application/json' })\n\n    // 5. Return responseObject.\n    return responseObject\n  }\n\n  // Creates a redirect Response that redirects to url with status status.\n  static redirect (url, status = 302) {\n    const relevantRealm = { settingsObject: {} }\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Response.redirect' })\n\n    url = webidl.converters.USVString(url)\n    status = webidl.converters['unsigned short'](status)\n\n    // 1. Let parsedURL be the result of parsing url with current settings\n    // objects API base URL.\n    // 2. If parsedURL is failure, then throw a TypeError.\n    // TODO: base-URL?\n    let parsedURL\n    try {\n      parsedURL = new URL(url, getGlobalOrigin())\n    } catch (err) {\n      throw Object.assign(new TypeError('Failed to parse URL from ' + url), {\n        cause: err\n      })\n    }\n\n    // 3. If status is not a redirect status, then throw a RangeError.\n    if (!redirectStatusSet.has(status)) {\n      throw new RangeError('Invalid status code ' + status)\n    }\n\n    // 4. Let responseObject be the result of creating a Response object,\n    // given a new response, \"immutable\", and thiss relevant Realm.\n    const responseObject = new Response()\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kGuard] = 'immutable'\n    responseObject[kHeaders][kRealm] = relevantRealm\n\n    // 5. Set responseObjects responses status to status.\n    responseObject[kState].status = status\n\n    // 6. Let value be parsedURL, serialized and isomorphic encoded.\n    const value = isomorphicEncode(URLSerializer(parsedURL))\n\n    // 7. Append `Location`/value to responseObjects responses header list.\n    responseObject[kState].headersList.append('location', value)\n\n    // 8. Return responseObject.\n    return responseObject\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-response\n  constructor (body = null, init = {}) {\n    if (body !== null) {\n      body = webidl.converters.BodyInit(body)\n    }\n\n    init = webidl.converters.ResponseInit(init)\n\n    // TODO\n    this[kRealm] = { settingsObject: {} }\n\n    // 1. Set thiss response to a new response.\n    this[kState] = makeResponse({})\n\n    // 2. Set thiss headers to a new Headers object with thiss relevant\n    // Realm, whose header list is thiss responses header list and guard\n    // is \"response\".\n    this[kHeaders] = new Headers(kConstruct)\n    this[kHeaders][kGuard] = 'response'\n    this[kHeaders][kHeadersList] = this[kState].headersList\n    this[kHeaders][kRealm] = this[kRealm]\n\n    // 3. Let bodyWithType be null.\n    let bodyWithType = null\n\n    // 4. If body is non-null, then set bodyWithType to the result of extracting body.\n    if (body != null) {\n      const [extractedBody, type] = extractBody(body)\n      bodyWithType = { body: extractedBody, type }\n    }\n\n    // 5. Perform initialize a response given this, init, and bodyWithType.\n    initializeResponse(this, init, bodyWithType)\n  }\n\n  // Returns responses type, e.g., \"cors\".\n  get type () {\n    webidl.brandCheck(this, Response)\n\n    // The type getter steps are to return thiss responses type.\n    return this[kState].type\n  }\n\n  // Returns responses URL, if it has one; otherwise the empty string.\n  get url () {\n    webidl.brandCheck(this, Response)\n\n    const urlList = this[kState].urlList\n\n    // The url getter steps are to return the empty string if thiss\n    // responses URL is null; otherwise thiss responses URL,\n    // serialized with exclude fragment set to true.\n    const url = urlList[urlList.length - 1] ?? null\n\n    if (url === null) {\n      return ''\n    }\n\n    return URLSerializer(url, true)\n  }\n\n  // Returns whether response was obtained through a redirect.\n  get redirected () {\n    webidl.brandCheck(this, Response)\n\n    // The redirected getter steps are to return true if thiss responses URL\n    // list has more than one item; otherwise false.\n    return this[kState].urlList.length > 1\n  }\n\n  // Returns responses status.\n  get status () {\n    webidl.brandCheck(this, Response)\n\n    // The status getter steps are to return thiss responses status.\n    return this[kState].status\n  }\n\n  // Returns whether responses status is an ok status.\n  get ok () {\n    webidl.brandCheck(this, Response)\n\n    // The ok getter steps are to return true if thiss responses status is an\n    // ok status; otherwise false.\n    return this[kState].status >= 200 && this[kState].status <= 299\n  }\n\n  // Returns responses status message.\n  get statusText () {\n    webidl.brandCheck(this, Response)\n\n    // The statusText getter steps are to return thiss responses status\n    // message.\n    return this[kState].statusText\n  }\n\n  // Returns responses headers as Headers.\n  get headers () {\n    webidl.brandCheck(this, Response)\n\n    // The headers getter steps are to return thiss headers.\n    return this[kHeaders]\n  }\n\n  get body () {\n    webidl.brandCheck(this, Response)\n\n    return this[kState].body ? this[kState].body.stream : null\n  }\n\n  get bodyUsed () {\n    webidl.brandCheck(this, Response)\n\n    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)\n  }\n\n  // Returns a clone of response.\n  clone () {\n    webidl.brandCheck(this, Response)\n\n    // 1. If this is unusable, then throw a TypeError.\n    if (this.bodyUsed || (this.body && this.body.locked)) {\n      throw webidl.errors.exception({\n        header: 'Response.clone',\n        message: 'Body has already been consumed.'\n      })\n    }\n\n    // 2. Let clonedResponse be the result of cloning thiss response.\n    const clonedResponse = cloneResponse(this[kState])\n\n    // 3. Return the result of creating a Response object, given\n    // clonedResponse, thiss headerss guard, and thiss relevant Realm.\n    const clonedResponseObject = new Response()\n    clonedResponseObject[kState] = clonedResponse\n    clonedResponseObject[kRealm] = this[kRealm]\n    clonedResponseObject[kHeaders][kHeadersList] = clonedResponse.headersList\n    clonedResponseObject[kHeaders][kGuard] = this[kHeaders][kGuard]\n    clonedResponseObject[kHeaders][kRealm] = this[kHeaders][kRealm]\n\n    return clonedResponseObject\n  }\n}\n\nmixinBody(Response)\n\nObject.defineProperties(Response.prototype, {\n  type: kEnumerableProperty,\n  url: kEnumerableProperty,\n  status: kEnumerableProperty,\n  ok: kEnumerableProperty,\n  redirected: kEnumerableProperty,\n  statusText: kEnumerableProperty,\n  headers: kEnumerableProperty,\n  clone: kEnumerableProperty,\n  body: kEnumerableProperty,\n  bodyUsed: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'Response',\n    configurable: true\n  }\n})\n\nObject.defineProperties(Response, {\n  json: kEnumerableProperty,\n  redirect: kEnumerableProperty,\n  error: kEnumerableProperty\n})\n\n// https://fetch.spec.whatwg.org/#concept-response-clone\nfunction cloneResponse (response) {\n  // To clone a response response, run these steps:\n\n  // 1. If response is a filtered response, then return a new identical\n  // filtered response whose internal response is a clone of responses\n  // internal response.\n  if (response.internalResponse) {\n    return filterResponse(\n      cloneResponse(response.internalResponse),\n      response.type\n    )\n  }\n\n  // 2. Let newResponse be a copy of response, except for its body.\n  const newResponse = makeResponse({ ...response, body: null })\n\n  // 3. If responses body is non-null, then set newResponses body to the\n  // result of cloning responses body.\n  if (response.body != null) {\n    newResponse.body = cloneBody(response.body)\n  }\n\n  // 4. Return newResponse.\n  return newResponse\n}\n\nfunction makeResponse (init) {\n  return {\n    aborted: false,\n    rangeRequested: false,\n    timingAllowPassed: false,\n    requestIncludesCredentials: false,\n    type: 'default',\n    status: 200,\n    timingInfo: null,\n    cacheState: '',\n    statusText: '',\n    ...init,\n    headersList: init.headersList\n      ? new HeadersList(init.headersList)\n      : new HeadersList(),\n    urlList: init.urlList ? [...init.urlList] : []\n  }\n}\n\nfunction makeNetworkError (reason) {\n  const isError = isErrorLike(reason)\n  return makeResponse({\n    type: 'error',\n    status: 0,\n    error: isError\n      ? reason\n      : new Error(reason ? String(reason) : reason),\n    aborted: reason && reason.name === 'AbortError'\n  })\n}\n\nfunction makeFilteredResponse (response, state) {\n  state = {\n    internalResponse: response,\n    ...state\n  }\n\n  return new Proxy(response, {\n    get (target, p) {\n      return p in state ? state[p] : target[p]\n    },\n    set (target, p, value) {\n      assert(!(p in state))\n      target[p] = value\n      return true\n    }\n  })\n}\n\n// https://fetch.spec.whatwg.org/#concept-filtered-response\nfunction filterResponse (response, type) {\n  // Set response to the following filtered response with response as its\n  // internal response, depending on requests response tainting:\n  if (type === 'basic') {\n    // A basic filtered response is a filtered response whose type is \"basic\"\n    // and header list excludes any headers in internal responses header list\n    // whose name is a forbidden response-header name.\n\n    // Note: undici does not implement forbidden response-header names\n    return makeFilteredResponse(response, {\n      type: 'basic',\n      headersList: response.headersList\n    })\n  } else if (type === 'cors') {\n    // A CORS filtered response is a filtered response whose type is \"cors\"\n    // and header list excludes any headers in internal responses header\n    // list whose name is not a CORS-safelisted response-header name, given\n    // internal responses CORS-exposed header-name list.\n\n    // Note: undici does not implement CORS-safelisted response-header names\n    return makeFilteredResponse(response, {\n      type: 'cors',\n      headersList: response.headersList\n    })\n  } else if (type === 'opaque') {\n    // An opaque filtered response is a filtered response whose type is\n    // \"opaque\", URL list is the empty list, status is 0, status message\n    // is the empty byte sequence, header list is empty, and body is null.\n\n    return makeFilteredResponse(response, {\n      type: 'opaque',\n      urlList: Object.freeze([]),\n      status: 0,\n      statusText: '',\n      body: null\n    })\n  } else if (type === 'opaqueredirect') {\n    // An opaque-redirect filtered response is a filtered response whose type\n    // is \"opaqueredirect\", status is 0, status message is the empty byte\n    // sequence, header list is empty, and body is null.\n\n    return makeFilteredResponse(response, {\n      type: 'opaqueredirect',\n      status: 0,\n      statusText: '',\n      headersList: [],\n      body: null\n    })\n  } else {\n    assert(false)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#appropriate-network-error\nfunction makeAppropriateNetworkError (fetchParams, err = null) {\n  // 1. Assert: fetchParams is canceled.\n  assert(isCancelled(fetchParams))\n\n  // 2. Return an aborted network error if fetchParams is aborted;\n  // otherwise return a network error.\n  return isAborted(fetchParams)\n    ? makeNetworkError(Object.assign(new DOMException('The operation was aborted.', 'AbortError'), { cause: err }))\n    : makeNetworkError(Object.assign(new DOMException('Request was cancelled.'), { cause: err }))\n}\n\n// https://whatpr.org/fetch/1392.html#initialize-a-response\nfunction initializeResponse (response, init, body) {\n  // 1. If init[\"status\"] is not in the range 200 to 599, inclusive, then\n  //    throw a RangeError.\n  if (init.status !== null && (init.status < 200 || init.status > 599)) {\n    throw new RangeError('init[\"status\"] must be in the range of 200 to 599, inclusive.')\n  }\n\n  // 2. If init[\"statusText\"] does not match the reason-phrase token production,\n  //    then throw a TypeError.\n  if ('statusText' in init && init.statusText != null) {\n    // See, https://datatracker.ietf.org/doc/html/rfc7230#section-3.1.2:\n    //   reason-phrase  = *( HTAB / SP / VCHAR / obs-text )\n    if (!isValidReasonPhrase(String(init.statusText))) {\n      throw new TypeError('Invalid statusText')\n    }\n  }\n\n  // 3. Set responses responses status to init[\"status\"].\n  if ('status' in init && init.status != null) {\n    response[kState].status = init.status\n  }\n\n  // 4. Set responses responses status message to init[\"statusText\"].\n  if ('statusText' in init && init.statusText != null) {\n    response[kState].statusText = init.statusText\n  }\n\n  // 5. If init[\"headers\"] exists, then fill responses headers with init[\"headers\"].\n  if ('headers' in init && init.headers != null) {\n    fill(response[kHeaders], init.headers)\n  }\n\n  // 6. If body was given, then:\n  if (body) {\n    // 1. If response's status is a null body status, then throw a TypeError.\n    if (nullBodyStatus.includes(response.status)) {\n      throw webidl.errors.exception({\n        header: 'Response constructor',\n        message: 'Invalid response status code ' + response.status\n      })\n    }\n\n    // 2. Set response's body to body's body.\n    response[kState].body = body.body\n\n    // 3. If body's type is non-null and response's header list does not contain\n    //    `Content-Type`, then append (`Content-Type`, body's type) to response's header list.\n    if (body.type != null && !response[kState].headersList.contains('Content-Type')) {\n      response[kState].headersList.append('content-type', body.type)\n    }\n  }\n}\n\nwebidl.converters.ReadableStream = webidl.interfaceConverter(\n  ReadableStream\n)\n\nwebidl.converters.FormData = webidl.interfaceConverter(\n  FormData\n)\n\nwebidl.converters.URLSearchParams = webidl.interfaceConverter(\n  URLSearchParams\n)\n\n// https://fetch.spec.whatwg.org/#typedefdef-xmlhttprequestbodyinit\nwebidl.converters.XMLHttpRequestBodyInit = function (V) {\n  if (typeof V === 'string') {\n    return webidl.converters.USVString(V)\n  }\n\n  if (isBlobLike(V)) {\n    return webidl.converters.Blob(V, { strict: false })\n  }\n\n  if (types.isArrayBuffer(V) || types.isTypedArray(V) || types.isDataView(V)) {\n    return webidl.converters.BufferSource(V)\n  }\n\n  if (util.isFormDataLike(V)) {\n    return webidl.converters.FormData(V, { strict: false })\n  }\n\n  if (V instanceof URLSearchParams) {\n    return webidl.converters.URLSearchParams(V)\n  }\n\n  return webidl.converters.DOMString(V)\n}\n\n// https://fetch.spec.whatwg.org/#bodyinit\nwebidl.converters.BodyInit = function (V) {\n  if (V instanceof ReadableStream) {\n    return webidl.converters.ReadableStream(V)\n  }\n\n  // Note: the spec doesn't include async iterables,\n  // this is an undici extension.\n  if (V?.[Symbol.asyncIterator]) {\n    return V\n  }\n\n  return webidl.converters.XMLHttpRequestBodyInit(V)\n}\n\nwebidl.converters.ResponseInit = webidl.dictionaryConverter([\n  {\n    key: 'status',\n    converter: webidl.converters['unsigned short'],\n    defaultValue: 200\n  },\n  {\n    key: 'statusText',\n    converter: webidl.converters.ByteString,\n    defaultValue: ''\n  },\n  {\n    key: 'headers',\n    converter: webidl.converters.HeadersInit\n  }\n])\n\nmodule.exports = {\n  makeNetworkError,\n  makeResponse,\n  makeAppropriateNetworkError,\n  filterResponse,\n  Response,\n  cloneResponse\n}\n","'use strict'\n\nmodule.exports = {\n  kUrl: Symbol('url'),\n  kHeaders: Symbol('headers'),\n  kSignal: Symbol('signal'),\n  kState: Symbol('state'),\n  kGuard: Symbol('guard'),\n  kRealm: Symbol('realm')\n}\n","'use strict'\n\nconst { redirectStatusSet, referrerPolicySet: referrerPolicyTokens, badPortsSet } = require('./constants')\nconst { getGlobalOrigin } = require('./global')\nconst { performance } = require('perf_hooks')\nconst { isBlobLike, toUSVString, ReadableStreamFrom } = require('../core/util')\nconst assert = require('assert')\nconst { isUint8Array } = require('util/types')\n\nlet supportedHashes = []\n\n// https://nodejs.org/api/crypto.html#determining-if-crypto-support-is-unavailable\n/** @type {import('crypto')|undefined} */\nlet crypto\n\ntry {\n  crypto = require('crypto')\n  const possibleRelevantHashes = ['sha256', 'sha384', 'sha512']\n  supportedHashes = crypto.getHashes().filter((hash) => possibleRelevantHashes.includes(hash))\n/* c8 ignore next 3 */\n} catch {\n}\n\nfunction responseURL (response) {\n  // https://fetch.spec.whatwg.org/#responses\n  // A response has an associated URL. It is a pointer to the last URL\n  // in responses URL list and null if responses URL list is empty.\n  const urlList = response.urlList\n  const length = urlList.length\n  return length === 0 ? null : urlList[length - 1].toString()\n}\n\n// https://fetch.spec.whatwg.org/#concept-response-location-url\nfunction responseLocationURL (response, requestFragment) {\n  // 1. If responses status is not a redirect status, then return null.\n  if (!redirectStatusSet.has(response.status)) {\n    return null\n  }\n\n  // 2. Let location be the result of extracting header list values given\n  // `Location` and responses header list.\n  let location = response.headersList.get('location')\n\n  // 3. If location is a header value, then set location to the result of\n  //    parsing location with responses URL.\n  if (location !== null && isValidHeaderValue(location)) {\n    location = new URL(location, responseURL(response))\n  }\n\n  // 4. If location is a URL whose fragment is null, then set locations\n  // fragment to requestFragment.\n  if (location && !location.hash) {\n    location.hash = requestFragment\n  }\n\n  // 5. Return location.\n  return location\n}\n\n/** @returns {URL} */\nfunction requestCurrentURL (request) {\n  return request.urlList[request.urlList.length - 1]\n}\n\nfunction requestBadPort (request) {\n  // 1. Let url be requests current URL.\n  const url = requestCurrentURL(request)\n\n  // 2. If urls scheme is an HTTP(S) scheme and urls port is a bad port,\n  // then return blocked.\n  if (urlIsHttpHttpsScheme(url) && badPortsSet.has(url.port)) {\n    return 'blocked'\n  }\n\n  // 3. Return allowed.\n  return 'allowed'\n}\n\nfunction isErrorLike (object) {\n  return object instanceof Error || (\n    object?.constructor?.name === 'Error' ||\n    object?.constructor?.name === 'DOMException'\n  )\n}\n\n// Check whether |statusText| is a ByteString and\n// matches the Reason-Phrase token production.\n// RFC 2616: https://tools.ietf.org/html/rfc2616\n// RFC 7230: https://tools.ietf.org/html/rfc7230\n// \"reason-phrase = *( HTAB / SP / VCHAR / obs-text )\"\n// https://github.com/chromium/chromium/blob/94.0.4604.1/third_party/blink/renderer/core/fetch/response.cc#L116\nfunction isValidReasonPhrase (statusText) {\n  for (let i = 0; i < statusText.length; ++i) {\n    const c = statusText.charCodeAt(i)\n    if (\n      !(\n        (\n          c === 0x09 || // HTAB\n          (c >= 0x20 && c <= 0x7e) || // SP / VCHAR\n          (c >= 0x80 && c <= 0xff)\n        ) // obs-text\n      )\n    ) {\n      return false\n    }\n  }\n  return true\n}\n\n/**\n * @see https://tools.ietf.org/html/rfc7230#section-3.2.6\n * @param {number} c\n */\nfunction isTokenCharCode (c) {\n  switch (c) {\n    case 0x22:\n    case 0x28:\n    case 0x29:\n    case 0x2c:\n    case 0x2f:\n    case 0x3a:\n    case 0x3b:\n    case 0x3c:\n    case 0x3d:\n    case 0x3e:\n    case 0x3f:\n    case 0x40:\n    case 0x5b:\n    case 0x5c:\n    case 0x5d:\n    case 0x7b:\n    case 0x7d:\n      // DQUOTE and \"(),/:;<=>?@[\\]{}\"\n      return false\n    default:\n      // VCHAR %x21-7E\n      return c >= 0x21 && c <= 0x7e\n  }\n}\n\n/**\n * @param {string} characters\n */\nfunction isValidHTTPToken (characters) {\n  if (characters.length === 0) {\n    return false\n  }\n  for (let i = 0; i < characters.length; ++i) {\n    if (!isTokenCharCode(characters.charCodeAt(i))) {\n      return false\n    }\n  }\n  return true\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#header-name\n * @param {string} potentialValue\n */\nfunction isValidHeaderName (potentialValue) {\n  return isValidHTTPToken(potentialValue)\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#header-value\n * @param {string} potentialValue\n */\nfunction isValidHeaderValue (potentialValue) {\n  // - Has no leading or trailing HTTP tab or space bytes.\n  // - Contains no 0x00 (NUL) or HTTP newline bytes.\n  if (\n    potentialValue.startsWith('\\t') ||\n    potentialValue.startsWith(' ') ||\n    potentialValue.endsWith('\\t') ||\n    potentialValue.endsWith(' ')\n  ) {\n    return false\n  }\n\n  if (\n    potentialValue.includes('\\0') ||\n    potentialValue.includes('\\r') ||\n    potentialValue.includes('\\n')\n  ) {\n    return false\n  }\n\n  return true\n}\n\n// https://w3c.github.io/webappsec-referrer-policy/#set-requests-referrer-policy-on-redirect\nfunction setRequestReferrerPolicyOnRedirect (request, actualResponse) {\n  //  Given a request request and a response actualResponse, this algorithm\n  //  updates requests referrer policy according to the Referrer-Policy\n  //  header (if any) in actualResponse.\n\n  // 1. Let policy be the result of executing  8.1 Parse a referrer policy\n  // from a Referrer-Policy header on actualResponse.\n\n  // 8.1 Parse a referrer policy from a Referrer-Policy header\n  // 1. Let policy-tokens be the result of extracting header list values given `Referrer-Policy` and responses header list.\n  const { headersList } = actualResponse\n  // 2. Let policy be the empty string.\n  // 3. For each token in policy-tokens, if token is a referrer policy and token is not the empty string, then set policy to token.\n  // 4. Return policy.\n  const policyHeader = (headersList.get('referrer-policy') ?? '').split(',')\n\n  // Note: As the referrer-policy can contain multiple policies\n  // separated by comma, we need to loop through all of them\n  // and pick the first valid one.\n  // Ref: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy#specify_a_fallback_policy\n  let policy = ''\n  if (policyHeader.length > 0) {\n    // The right-most policy takes precedence.\n    // The left-most policy is the fallback.\n    for (let i = policyHeader.length; i !== 0; i--) {\n      const token = policyHeader[i - 1].trim()\n      if (referrerPolicyTokens.has(token)) {\n        policy = token\n        break\n      }\n    }\n  }\n\n  // 2. If policy is not the empty string, then set requests referrer policy to policy.\n  if (policy !== '') {\n    request.referrerPolicy = policy\n  }\n}\n\n// https://fetch.spec.whatwg.org/#cross-origin-resource-policy-check\nfunction crossOriginResourcePolicyCheck () {\n  // TODO\n  return 'allowed'\n}\n\n// https://fetch.spec.whatwg.org/#concept-cors-check\nfunction corsCheck () {\n  // TODO\n  return 'success'\n}\n\n// https://fetch.spec.whatwg.org/#concept-tao-check\nfunction TAOCheck () {\n  // TODO\n  return 'success'\n}\n\nfunction appendFetchMetadata (httpRequest) {\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-dest-header\n  //  TODO\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-mode-header\n\n  //  1. Assert: rs url is a potentially trustworthy URL.\n  //  TODO\n\n  //  2. Let header be a Structured Header whose value is a token.\n  let header = null\n\n  //  3. Set headers value to rs mode.\n  header = httpRequest.mode\n\n  //  4. Set a structured field value `Sec-Fetch-Mode`/header in rs header list.\n  httpRequest.headersList.set('sec-fetch-mode', header)\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-site-header\n  //  TODO\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-user-header\n  //  TODO\n}\n\n// https://fetch.spec.whatwg.org/#append-a-request-origin-header\nfunction appendRequestOriginHeader (request) {\n  // 1. Let serializedOrigin be the result of byte-serializing a request origin with request.\n  let serializedOrigin = request.origin\n\n  // 2. If requests response tainting is \"cors\" or requests mode is \"websocket\", then append (`Origin`, serializedOrigin) to requests header list.\n  if (request.responseTainting === 'cors' || request.mode === 'websocket') {\n    if (serializedOrigin) {\n      request.headersList.append('origin', serializedOrigin)\n    }\n\n  // 3. Otherwise, if requests method is neither `GET` nor `HEAD`, then:\n  } else if (request.method !== 'GET' && request.method !== 'HEAD') {\n    // 1. Switch on requests referrer policy:\n    switch (request.referrerPolicy) {\n      case 'no-referrer':\n        // Set serializedOrigin to `null`.\n        serializedOrigin = null\n        break\n      case 'no-referrer-when-downgrade':\n      case 'strict-origin':\n      case 'strict-origin-when-cross-origin':\n        // If requests origin is a tuple origin, its scheme is \"https\", and requests current URLs scheme is not \"https\", then set serializedOrigin to `null`.\n        if (request.origin && urlHasHttpsScheme(request.origin) && !urlHasHttpsScheme(requestCurrentURL(request))) {\n          serializedOrigin = null\n        }\n        break\n      case 'same-origin':\n        // If requests origin is not same origin with requests current URLs origin, then set serializedOrigin to `null`.\n        if (!sameOrigin(request, requestCurrentURL(request))) {\n          serializedOrigin = null\n        }\n        break\n      default:\n        // Do nothing.\n    }\n\n    if (serializedOrigin) {\n      // 2. Append (`Origin`, serializedOrigin) to requests header list.\n      request.headersList.append('origin', serializedOrigin)\n    }\n  }\n}\n\nfunction coarsenedSharedCurrentTime (crossOriginIsolatedCapability) {\n  // TODO\n  return performance.now()\n}\n\n// https://fetch.spec.whatwg.org/#create-an-opaque-timing-info\nfunction createOpaqueTimingInfo (timingInfo) {\n  return {\n    startTime: timingInfo.startTime ?? 0,\n    redirectStartTime: 0,\n    redirectEndTime: 0,\n    postRedirectStartTime: timingInfo.startTime ?? 0,\n    finalServiceWorkerStartTime: 0,\n    finalNetworkResponseStartTime: 0,\n    finalNetworkRequestStartTime: 0,\n    endTime: 0,\n    encodedBodySize: 0,\n    decodedBodySize: 0,\n    finalConnectionTimingInfo: null\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/origin.html#policy-container\nfunction makePolicyContainer () {\n  // Note: the fetch spec doesn't make use of embedder policy or CSP list\n  return {\n    referrerPolicy: 'strict-origin-when-cross-origin'\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/origin.html#clone-a-policy-container\nfunction clonePolicyContainer (policyContainer) {\n  return {\n    referrerPolicy: policyContainer.referrerPolicy\n  }\n}\n\n// https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer\nfunction determineRequestsReferrer (request) {\n  // 1. Let policy be request's referrer policy.\n  const policy = request.referrerPolicy\n\n  // Note: policy cannot (shouldn't) be null or an empty string.\n  assert(policy)\n\n  // 2. Let environment be requests client.\n\n  let referrerSource = null\n\n  // 3. Switch on requests referrer:\n  if (request.referrer === 'client') {\n    // Note: node isn't a browser and doesn't implement document/iframes,\n    // so we bypass this step and replace it with our own.\n\n    const globalOrigin = getGlobalOrigin()\n\n    if (!globalOrigin || globalOrigin.origin === 'null') {\n      return 'no-referrer'\n    }\n\n    // note: we need to clone it as it's mutated\n    referrerSource = new URL(globalOrigin)\n  } else if (request.referrer instanceof URL) {\n    // Let referrerSource be requests referrer.\n    referrerSource = request.referrer\n  }\n\n  // 4. Let requests referrerURL be the result of stripping referrerSource for\n  //    use as a referrer.\n  let referrerURL = stripURLForReferrer(referrerSource)\n\n  // 5. Let referrerOrigin be the result of stripping referrerSource for use as\n  //    a referrer, with the origin-only flag set to true.\n  const referrerOrigin = stripURLForReferrer(referrerSource, true)\n\n  // 6. If the result of serializing referrerURL is a string whose length is\n  //    greater than 4096, set referrerURL to referrerOrigin.\n  if (referrerURL.toString().length > 4096) {\n    referrerURL = referrerOrigin\n  }\n\n  const areSameOrigin = sameOrigin(request, referrerURL)\n  const isNonPotentiallyTrustWorthy = isURLPotentiallyTrustworthy(referrerURL) &&\n    !isURLPotentiallyTrustworthy(request.url)\n\n  // 8. Execute the switch statements corresponding to the value of policy:\n  switch (policy) {\n    case 'origin': return referrerOrigin != null ? referrerOrigin : stripURLForReferrer(referrerSource, true)\n    case 'unsafe-url': return referrerURL\n    case 'same-origin':\n      return areSameOrigin ? referrerOrigin : 'no-referrer'\n    case 'origin-when-cross-origin':\n      return areSameOrigin ? referrerURL : referrerOrigin\n    case 'strict-origin-when-cross-origin': {\n      const currentURL = requestCurrentURL(request)\n\n      // 1. If the origin of referrerURL and the origin of requests current\n      //    URL are the same, then return referrerURL.\n      if (sameOrigin(referrerURL, currentURL)) {\n        return referrerURL\n      }\n\n      // 2. If referrerURL is a potentially trustworthy URL and requests\n      //    current URL is not a potentially trustworthy URL, then return no\n      //    referrer.\n      if (isURLPotentiallyTrustworthy(referrerURL) && !isURLPotentiallyTrustworthy(currentURL)) {\n        return 'no-referrer'\n      }\n\n      // 3. Return referrerOrigin.\n      return referrerOrigin\n    }\n    case 'strict-origin': // eslint-disable-line\n      /**\n         * 1. If referrerURL is a potentially trustworthy URL and\n         * requests current URL is not a potentially trustworthy URL,\n         * then return no referrer.\n         * 2. Return referrerOrigin\n        */\n    case 'no-referrer-when-downgrade': // eslint-disable-line\n      /**\n       * 1. If referrerURL is a potentially trustworthy URL and\n       * requests current URL is not a potentially trustworthy URL,\n       * then return no referrer.\n       * 2. Return referrerOrigin\n      */\n\n    default: // eslint-disable-line\n      return isNonPotentiallyTrustWorthy ? 'no-referrer' : referrerOrigin\n  }\n}\n\n/**\n * @see https://w3c.github.io/webappsec-referrer-policy/#strip-url\n * @param {URL} url\n * @param {boolean|undefined} originOnly\n */\nfunction stripURLForReferrer (url, originOnly) {\n  // 1. Assert: url is a URL.\n  assert(url instanceof URL)\n\n  // 2. If urls scheme is a local scheme, then return no referrer.\n  if (url.protocol === 'file:' || url.protocol === 'about:' || url.protocol === 'blank:') {\n    return 'no-referrer'\n  }\n\n  // 3. Set urls username to the empty string.\n  url.username = ''\n\n  // 4. Set urls password to the empty string.\n  url.password = ''\n\n  // 5. Set urls fragment to null.\n  url.hash = ''\n\n  // 6. If the origin-only flag is true, then:\n  if (originOnly) {\n    // 1. Set urls path to  the empty string .\n    url.pathname = ''\n\n    // 2. Set urls query to null.\n    url.search = ''\n  }\n\n  // 7. Return url.\n  return url\n}\n\nfunction isURLPotentiallyTrustworthy (url) {\n  if (!(url instanceof URL)) {\n    return false\n  }\n\n  // If child of about, return true\n  if (url.href === 'about:blank' || url.href === 'about:srcdoc') {\n    return true\n  }\n\n  // If scheme is data, return true\n  if (url.protocol === 'data:') return true\n\n  // If file, return true\n  if (url.protocol === 'file:') return true\n\n  return isOriginPotentiallyTrustworthy(url.origin)\n\n  function isOriginPotentiallyTrustworthy (origin) {\n    // If origin is explicitly null, return false\n    if (origin == null || origin === 'null') return false\n\n    const originAsURL = new URL(origin)\n\n    // If secure, return true\n    if (originAsURL.protocol === 'https:' || originAsURL.protocol === 'wss:') {\n      return true\n    }\n\n    // If localhost or variants, return true\n    if (/^127(?:\\.[0-9]+){0,2}\\.[0-9]+$|^\\[(?:0*:)*?:?0*1\\]$/.test(originAsURL.hostname) ||\n     (originAsURL.hostname === 'localhost' || originAsURL.hostname.includes('localhost.')) ||\n     (originAsURL.hostname.endsWith('.localhost'))) {\n      return true\n    }\n\n    // If any other, return false\n    return false\n  }\n}\n\n/**\n * @see https://w3c.github.io/webappsec-subresource-integrity/#does-response-match-metadatalist\n * @param {Uint8Array} bytes\n * @param {string} metadataList\n */\nfunction bytesMatch (bytes, metadataList) {\n  // If node is not built with OpenSSL support, we cannot check\n  // a request's integrity, so allow it by default (the spec will\n  // allow requests if an invalid hash is given, as precedence).\n  /* istanbul ignore if: only if node is built with --without-ssl */\n  if (crypto === undefined) {\n    return true\n  }\n\n  // 1. Let parsedMetadata be the result of parsing metadataList.\n  const parsedMetadata = parseMetadata(metadataList)\n\n  // 2. If parsedMetadata is no metadata, return true.\n  if (parsedMetadata === 'no metadata') {\n    return true\n  }\n\n  // 3. If response is not eligible for integrity validation, return false.\n  // TODO\n\n  // 4. If parsedMetadata is the empty set, return true.\n  if (parsedMetadata.length === 0) {\n    return true\n  }\n\n  // 5. Let metadata be the result of getting the strongest\n  //    metadata from parsedMetadata.\n  const strongest = getStrongestMetadata(parsedMetadata)\n  const metadata = filterMetadataListByAlgorithm(parsedMetadata, strongest)\n\n  // 6. For each item in metadata:\n  for (const item of metadata) {\n    // 1. Let algorithm be the alg component of item.\n    const algorithm = item.algo\n\n    // 2. Let expectedValue be the val component of item.\n    const expectedValue = item.hash\n\n    // See https://github.com/web-platform-tests/wpt/commit/e4c5cc7a5e48093220528dfdd1c4012dc3837a0e\n    // \"be liberal with padding\". This is annoying, and it's not even in the spec.\n\n    // 3. Let actualValue be the result of applying algorithm to bytes.\n    let actualValue = crypto.createHash(algorithm).update(bytes).digest('base64')\n\n    if (actualValue[actualValue.length - 1] === '=') {\n      if (actualValue[actualValue.length - 2] === '=') {\n        actualValue = actualValue.slice(0, -2)\n      } else {\n        actualValue = actualValue.slice(0, -1)\n      }\n    }\n\n    // 4. If actualValue is a case-sensitive match for expectedValue,\n    //    return true.\n    if (compareBase64Mixed(actualValue, expectedValue)) {\n      return true\n    }\n  }\n\n  // 7. Return false.\n  return false\n}\n\n// https://w3c.github.io/webappsec-subresource-integrity/#grammardef-hash-with-options\n// https://www.w3.org/TR/CSP2/#source-list-syntax\n// https://www.rfc-editor.org/rfc/rfc5234#appendix-B.1\nconst parseHashWithOptions = /(?<algo>sha256|sha384|sha512)-((?<hash>[A-Za-z0-9+/]+|[A-Za-z0-9_-]+)={0,2}(?:\\s|$)( +[!-~]*)?)?/i\n\n/**\n * @see https://w3c.github.io/webappsec-subresource-integrity/#parse-metadata\n * @param {string} metadata\n */\nfunction parseMetadata (metadata) {\n  // 1. Let result be the empty set.\n  /** @type {{ algo: string, hash: string }[]} */\n  const result = []\n\n  // 2. Let empty be equal to true.\n  let empty = true\n\n  // 3. For each token returned by splitting metadata on spaces:\n  for (const token of metadata.split(' ')) {\n    // 1. Set empty to false.\n    empty = false\n\n    // 2. Parse token as a hash-with-options.\n    const parsedToken = parseHashWithOptions.exec(token)\n\n    // 3. If token does not parse, continue to the next token.\n    if (\n      parsedToken === null ||\n      parsedToken.groups === undefined ||\n      parsedToken.groups.algo === undefined\n    ) {\n      // Note: Chromium blocks the request at this point, but Firefox\n      // gives a warning that an invalid integrity was given. The\n      // correct behavior is to ignore these, and subsequently not\n      // check the integrity of the resource.\n      continue\n    }\n\n    // 4. Let algorithm be the hash-algo component of token.\n    const algorithm = parsedToken.groups.algo.toLowerCase()\n\n    // 5. If algorithm is a hash function recognized by the user\n    //    agent, add the parsed token to result.\n    if (supportedHashes.includes(algorithm)) {\n      result.push(parsedToken.groups)\n    }\n  }\n\n  // 4. Return no metadata if empty is true, otherwise return result.\n  if (empty === true) {\n    return 'no metadata'\n  }\n\n  return result\n}\n\n/**\n * @param {{ algo: 'sha256' | 'sha384' | 'sha512' }[]} metadataList\n */\nfunction getStrongestMetadata (metadataList) {\n  // Let algorithm be the algo component of the first item in metadataList.\n  // Can be sha256\n  let algorithm = metadataList[0].algo\n  // If the algorithm is sha512, then it is the strongest\n  // and we can return immediately\n  if (algorithm[3] === '5') {\n    return algorithm\n  }\n\n  for (let i = 1; i < metadataList.length; ++i) {\n    const metadata = metadataList[i]\n    // If the algorithm is sha512, then it is the strongest\n    // and we can break the loop immediately\n    if (metadata.algo[3] === '5') {\n      algorithm = 'sha512'\n      break\n    // If the algorithm is sha384, then a potential sha256 or sha384 is ignored\n    } else if (algorithm[3] === '3') {\n      continue\n    // algorithm is sha256, check if algorithm is sha384 and if so, set it as\n    // the strongest\n    } else if (metadata.algo[3] === '3') {\n      algorithm = 'sha384'\n    }\n  }\n  return algorithm\n}\n\nfunction filterMetadataListByAlgorithm (metadataList, algorithm) {\n  if (metadataList.length === 1) {\n    return metadataList\n  }\n\n  let pos = 0\n  for (let i = 0; i < metadataList.length; ++i) {\n    if (metadataList[i].algo === algorithm) {\n      metadataList[pos++] = metadataList[i]\n    }\n  }\n\n  metadataList.length = pos\n\n  return metadataList\n}\n\n/**\n * Compares two base64 strings, allowing for base64url\n * in the second string.\n *\n* @param {string} actualValue always base64\n * @param {string} expectedValue base64 or base64url\n * @returns {boolean}\n */\nfunction compareBase64Mixed (actualValue, expectedValue) {\n  if (actualValue.length !== expectedValue.length) {\n    return false\n  }\n  for (let i = 0; i < actualValue.length; ++i) {\n    if (actualValue[i] !== expectedValue[i]) {\n      if (\n        (actualValue[i] === '+' && expectedValue[i] === '-') ||\n        (actualValue[i] === '/' && expectedValue[i] === '_')\n      ) {\n        continue\n      }\n      return false\n    }\n  }\n\n  return true\n}\n\n// https://w3c.github.io/webappsec-upgrade-insecure-requests/#upgrade-request\nfunction tryUpgradeRequestToAPotentiallyTrustworthyURL (request) {\n  // TODO\n}\n\n/**\n * @link {https://html.spec.whatwg.org/multipage/origin.html#same-origin}\n * @param {URL} A\n * @param {URL} B\n */\nfunction sameOrigin (A, B) {\n  // 1. If A and B are the same opaque origin, then return true.\n  if (A.origin === B.origin && A.origin === 'null') {\n    return true\n  }\n\n  // 2. If A and B are both tuple origins and their schemes,\n  //    hosts, and port are identical, then return true.\n  if (A.protocol === B.protocol && A.hostname === B.hostname && A.port === B.port) {\n    return true\n  }\n\n  // 3. Return false.\n  return false\n}\n\nfunction createDeferredPromise () {\n  let res\n  let rej\n  const promise = new Promise((resolve, reject) => {\n    res = resolve\n    rej = reject\n  })\n\n  return { promise, resolve: res, reject: rej }\n}\n\nfunction isAborted (fetchParams) {\n  return fetchParams.controller.state === 'aborted'\n}\n\nfunction isCancelled (fetchParams) {\n  return fetchParams.controller.state === 'aborted' ||\n    fetchParams.controller.state === 'terminated'\n}\n\nconst normalizeMethodRecord = {\n  delete: 'DELETE',\n  DELETE: 'DELETE',\n  get: 'GET',\n  GET: 'GET',\n  head: 'HEAD',\n  HEAD: 'HEAD',\n  options: 'OPTIONS',\n  OPTIONS: 'OPTIONS',\n  post: 'POST',\n  POST: 'POST',\n  put: 'PUT',\n  PUT: 'PUT'\n}\n\n// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.\nObject.setPrototypeOf(normalizeMethodRecord, null)\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-method-normalize\n * @param {string} method\n */\nfunction normalizeMethod (method) {\n  return normalizeMethodRecord[method.toLowerCase()] ?? method\n}\n\n// https://infra.spec.whatwg.org/#serialize-a-javascript-value-to-a-json-string\nfunction serializeJavascriptValueToJSONString (value) {\n  // 1. Let result be ? Call(%JSON.stringify%, undefined,  value ).\n  const result = JSON.stringify(value)\n\n  // 2. If result is undefined, then throw a TypeError.\n  if (result === undefined) {\n    throw new TypeError('Value is not JSON serializable')\n  }\n\n  // 3. Assert: result is a string.\n  assert(typeof result === 'string')\n\n  // 4. Return result.\n  return result\n}\n\n// https://tc39.es/ecma262/#sec-%25iteratorprototype%25-object\nconst esIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]()))\n\n/**\n * @see https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object\n * @param {() => unknown[]} iterator\n * @param {string} name name of the instance\n * @param {'key'|'value'|'key+value'} kind\n */\nfunction makeIterator (iterator, name, kind) {\n  const object = {\n    index: 0,\n    kind,\n    target: iterator\n  }\n\n  const i = {\n    next () {\n      // 1. Let interface be the interface for which the iterator prototype object exists.\n\n      // 2. Let thisValue be the this value.\n\n      // 3. Let object be ? ToObject(thisValue).\n\n      // 4. If object is a platform object, then perform a security\n      //    check, passing:\n\n      // 5. If object is not a default iterator object for interface,\n      //    then throw a TypeError.\n      if (Object.getPrototypeOf(this) !== i) {\n        throw new TypeError(\n          `'next' called on an object that does not implement interface ${name} Iterator.`\n        )\n      }\n\n      // 6. Let index be objects index.\n      // 7. Let kind be objects kind.\n      // 8. Let values be objects target's value pairs to iterate over.\n      const { index, kind, target } = object\n      const values = target()\n\n      // 9. Let len be the length of values.\n      const len = values.length\n\n      // 10. If index is greater than or equal to len, then return\n      //     CreateIterResultObject(undefined, true).\n      if (index >= len) {\n        return { value: undefined, done: true }\n      }\n\n      // 11. Let pair be the entry in values at index index.\n      const pair = values[index]\n\n      // 12. Set objects index to index + 1.\n      object.index = index + 1\n\n      // 13. Return the iterator result for pair and kind.\n      return iteratorResult(pair, kind)\n    },\n    // The class string of an iterator prototype object for a given interface is the\n    // result of concatenating the identifier of the interface and the string \" Iterator\".\n    [Symbol.toStringTag]: `${name} Iterator`\n  }\n\n  // The [[Prototype]] internal slot of an iterator prototype object must be %IteratorPrototype%.\n  Object.setPrototypeOf(i, esIteratorPrototype)\n  // esIteratorPrototype needs to be the prototype of i\n  // which is the prototype of an empty object. Yes, it's confusing.\n  return Object.setPrototypeOf({}, i)\n}\n\n// https://webidl.spec.whatwg.org/#iterator-result\nfunction iteratorResult (pair, kind) {\n  let result\n\n  // 1. Let result be a value determined by the value of kind:\n  switch (kind) {\n    case 'key': {\n      // 1. Let idlKey be pairs key.\n      // 2. Let key be the result of converting idlKey to an\n      //    ECMAScript value.\n      // 3. result is key.\n      result = pair[0]\n      break\n    }\n    case 'value': {\n      // 1. Let idlValue be pairs value.\n      // 2. Let value be the result of converting idlValue to\n      //    an ECMAScript value.\n      // 3. result is value.\n      result = pair[1]\n      break\n    }\n    case 'key+value': {\n      // 1. Let idlKey be pairs key.\n      // 2. Let idlValue be pairs value.\n      // 3. Let key be the result of converting idlKey to an\n      //    ECMAScript value.\n      // 4. Let value be the result of converting idlValue to\n      //    an ECMAScript value.\n      // 5. Let array be ! ArrayCreate(2).\n      // 6. Call ! CreateDataProperty(array, \"0\", key).\n      // 7. Call ! CreateDataProperty(array, \"1\", value).\n      // 8. result is array.\n      result = pair\n      break\n    }\n  }\n\n  // 2. Return CreateIterResultObject(result, false).\n  return { value: result, done: false }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#body-fully-read\n */\nasync function fullyReadBody (body, processBody, processBodyError) {\n  // 1. If taskDestination is null, then set taskDestination to\n  //    the result of starting a new parallel queue.\n\n  // 2. Let successSteps given a byte sequence bytes be to queue a\n  //    fetch task to run processBody given bytes, with taskDestination.\n  const successSteps = processBody\n\n  // 3. Let errorSteps be to queue a fetch task to run processBodyError,\n  //    with taskDestination.\n  const errorSteps = processBodyError\n\n  // 4. Let reader be the result of getting a reader for bodys stream.\n  //    If that threw an exception, then run errorSteps with that\n  //    exception and return.\n  let reader\n\n  try {\n    reader = body.stream.getReader()\n  } catch (e) {\n    errorSteps(e)\n    return\n  }\n\n  // 5. Read all bytes from reader, given successSteps and errorSteps.\n  try {\n    const result = await readAllBytes(reader)\n    successSteps(result)\n  } catch (e) {\n    errorSteps(e)\n  }\n}\n\n/** @type {ReadableStream} */\nlet ReadableStream = globalThis.ReadableStream\n\nfunction isReadableStreamLike (stream) {\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  return stream instanceof ReadableStream || (\n    stream[Symbol.toStringTag] === 'ReadableStream' &&\n    typeof stream.tee === 'function'\n  )\n}\n\nconst MAXIMUM_ARGUMENT_LENGTH = 65535\n\n/**\n * @see https://infra.spec.whatwg.org/#isomorphic-decode\n * @param {number[]|Uint8Array} input\n */\nfunction isomorphicDecode (input) {\n  // 1. To isomorphic decode a byte sequence input, return a string whose code point\n  //    length is equal to inputs length and whose code points have the same values\n  //    as the values of inputs bytes, in the same order.\n\n  if (input.length < MAXIMUM_ARGUMENT_LENGTH) {\n    return String.fromCharCode(...input)\n  }\n\n  return input.reduce((previous, current) => previous + String.fromCharCode(current), '')\n}\n\n/**\n * @param {ReadableStreamController<Uint8Array>} controller\n */\nfunction readableStreamClose (controller) {\n  try {\n    controller.close()\n  } catch (err) {\n    // TODO: add comment explaining why this error occurs.\n    if (!err.message.includes('Controller is already closed')) {\n      throw err\n    }\n  }\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#isomorphic-encode\n * @param {string} input\n */\nfunction isomorphicEncode (input) {\n  // 1. Assert: input contains no code points greater than U+00FF.\n  for (let i = 0; i < input.length; i++) {\n    assert(input.charCodeAt(i) <= 0xFF)\n  }\n\n  // 2. Return a byte sequence whose length is equal to inputs code\n  //    point length and whose bytes have the same values as the\n  //    values of inputs code points, in the same order\n  return input\n}\n\n/**\n * @see https://streams.spec.whatwg.org/#readablestreamdefaultreader-read-all-bytes\n * @see https://streams.spec.whatwg.org/#read-loop\n * @param {ReadableStreamDefaultReader} reader\n */\nasync function readAllBytes (reader) {\n  const bytes = []\n  let byteLength = 0\n\n  while (true) {\n    const { done, value: chunk } = await reader.read()\n\n    if (done) {\n      // 1. Call successSteps with bytes.\n      return Buffer.concat(bytes, byteLength)\n    }\n\n    // 1. If chunk is not a Uint8Array object, call failureSteps\n    //    with a TypeError and abort these steps.\n    if (!isUint8Array(chunk)) {\n      throw new TypeError('Received non-Uint8Array chunk')\n    }\n\n    // 2. Append the bytes represented by chunk to bytes.\n    bytes.push(chunk)\n    byteLength += chunk.length\n\n    // 3. Read-loop given reader, bytes, successSteps, and failureSteps.\n  }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#is-local\n * @param {URL} url\n */\nfunction urlIsLocal (url) {\n  assert('protocol' in url) // ensure it's a url object\n\n  const protocol = url.protocol\n\n  return protocol === 'about:' || protocol === 'blob:' || protocol === 'data:'\n}\n\n/**\n * @param {string|URL} url\n */\nfunction urlHasHttpsScheme (url) {\n  if (typeof url === 'string') {\n    return url.startsWith('https:')\n  }\n\n  return url.protocol === 'https:'\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-scheme\n * @param {URL} url\n */\nfunction urlIsHttpHttpsScheme (url) {\n  assert('protocol' in url) // ensure it's a url object\n\n  const protocol = url.protocol\n\n  return protocol === 'http:' || protocol === 'https:'\n}\n\n/**\n * Fetch supports node >= 16.8.0, but Object.hasOwn was added in v16.9.0.\n */\nconst hasOwn = Object.hasOwn || ((dict, key) => Object.prototype.hasOwnProperty.call(dict, key))\n\nmodule.exports = {\n  isAborted,\n  isCancelled,\n  createDeferredPromise,\n  ReadableStreamFrom,\n  toUSVString,\n  tryUpgradeRequestToAPotentiallyTrustworthyURL,\n  coarsenedSharedCurrentTime,\n  determineRequestsReferrer,\n  makePolicyContainer,\n  clonePolicyContainer,\n  appendFetchMetadata,\n  appendRequestOriginHeader,\n  TAOCheck,\n  corsCheck,\n  crossOriginResourcePolicyCheck,\n  createOpaqueTimingInfo,\n  setRequestReferrerPolicyOnRedirect,\n  isValidHTTPToken,\n  requestBadPort,\n  requestCurrentURL,\n  responseURL,\n  responseLocationURL,\n  isBlobLike,\n  isURLPotentiallyTrustworthy,\n  isValidReasonPhrase,\n  sameOrigin,\n  normalizeMethod,\n  serializeJavascriptValueToJSONString,\n  makeIterator,\n  isValidHeaderName,\n  isValidHeaderValue,\n  hasOwn,\n  isErrorLike,\n  fullyReadBody,\n  bytesMatch,\n  isReadableStreamLike,\n  readableStreamClose,\n  isomorphicEncode,\n  isomorphicDecode,\n  urlIsLocal,\n  urlHasHttpsScheme,\n  urlIsHttpHttpsScheme,\n  readAllBytes,\n  normalizeMethodRecord,\n  parseMetadata\n}\n","'use strict'\n\nconst { types } = require('util')\nconst { hasOwn, toUSVString } = require('./util')\n\n/** @type {import('../../types/webidl').Webidl} */\nconst webidl = {}\nwebidl.converters = {}\nwebidl.util = {}\nwebidl.errors = {}\n\nwebidl.errors.exception = function (message) {\n  return new TypeError(`${message.header}: ${message.message}`)\n}\n\nwebidl.errors.conversionFailed = function (context) {\n  const plural = context.types.length === 1 ? '' : ' one of'\n  const message =\n    `${context.argument} could not be converted to` +\n    `${plural}: ${context.types.join(', ')}.`\n\n  return webidl.errors.exception({\n    header: context.prefix,\n    message\n  })\n}\n\nwebidl.errors.invalidArgument = function (context) {\n  return webidl.errors.exception({\n    header: context.prefix,\n    message: `\"${context.value}\" is an invalid ${context.type}.`\n  })\n}\n\n// https://webidl.spec.whatwg.org/#implements\nwebidl.brandCheck = function (V, I, opts = undefined) {\n  if (opts?.strict !== false && !(V instanceof I)) {\n    throw new TypeError('Illegal invocation')\n  } else {\n    return V?.[Symbol.toStringTag] === I.prototype[Symbol.toStringTag]\n  }\n}\n\nwebidl.argumentLengthCheck = function ({ length }, min, ctx) {\n  if (length < min) {\n    throw webidl.errors.exception({\n      message: `${min} argument${min !== 1 ? 's' : ''} required, ` +\n               `but${length ? ' only' : ''} ${length} found.`,\n      ...ctx\n    })\n  }\n}\n\nwebidl.illegalConstructor = function () {\n  throw webidl.errors.exception({\n    header: 'TypeError',\n    message: 'Illegal constructor'\n  })\n}\n\n// https://tc39.es/ecma262/#sec-ecmascript-data-types-and-values\nwebidl.util.Type = function (V) {\n  switch (typeof V) {\n    case 'undefined': return 'Undefined'\n    case 'boolean': return 'Boolean'\n    case 'string': return 'String'\n    case 'symbol': return 'Symbol'\n    case 'number': return 'Number'\n    case 'bigint': return 'BigInt'\n    case 'function':\n    case 'object': {\n      if (V === null) {\n        return 'Null'\n      }\n\n      return 'Object'\n    }\n  }\n}\n\n// https://webidl.spec.whatwg.org/#abstract-opdef-converttoint\nwebidl.util.ConvertToInt = function (V, bitLength, signedness, opts = {}) {\n  let upperBound\n  let lowerBound\n\n  // 1. If bitLength is 64, then:\n  if (bitLength === 64) {\n    // 1. Let upperBound be 2^53  1.\n    upperBound = Math.pow(2, 53) - 1\n\n    // 2. If signedness is \"unsigned\", then let lowerBound be 0.\n    if (signedness === 'unsigned') {\n      lowerBound = 0\n    } else {\n      // 3. Otherwise let lowerBound be 2^53 + 1.\n      lowerBound = Math.pow(-2, 53) + 1\n    }\n  } else if (signedness === 'unsigned') {\n    // 2. Otherwise, if signedness is \"unsigned\", then:\n\n    // 1. Let lowerBound be 0.\n    lowerBound = 0\n\n    // 2. Let upperBound be 2^bitLength  1.\n    upperBound = Math.pow(2, bitLength) - 1\n  } else {\n    // 3. Otherwise:\n\n    // 1. Let lowerBound be -2^bitLength  1.\n    lowerBound = Math.pow(-2, bitLength) - 1\n\n    // 2. Let upperBound be 2^bitLength  1  1.\n    upperBound = Math.pow(2, bitLength - 1) - 1\n  }\n\n  // 4. Let x be ? ToNumber(V).\n  let x = Number(V)\n\n  // 5. If x is 0, then set x to +0.\n  if (x === 0) {\n    x = 0\n  }\n\n  // 6. If the conversion is to an IDL type associated\n  //    with the [EnforceRange] extended attribute, then:\n  if (opts.enforceRange === true) {\n    // 1. If x is NaN, +, or , then throw a TypeError.\n    if (\n      Number.isNaN(x) ||\n      x === Number.POSITIVE_INFINITY ||\n      x === Number.NEGATIVE_INFINITY\n    ) {\n      throw webidl.errors.exception({\n        header: 'Integer conversion',\n        message: `Could not convert ${V} to an integer.`\n      })\n    }\n\n    // 2. Set x to IntegerPart(x).\n    x = webidl.util.IntegerPart(x)\n\n    // 3. If x < lowerBound or x > upperBound, then\n    //    throw a TypeError.\n    if (x < lowerBound || x > upperBound) {\n      throw webidl.errors.exception({\n        header: 'Integer conversion',\n        message: `Value must be between ${lowerBound}-${upperBound}, got ${x}.`\n      })\n    }\n\n    // 4. Return x.\n    return x\n  }\n\n  // 7. If x is not NaN and the conversion is to an IDL\n  //    type associated with the [Clamp] extended\n  //    attribute, then:\n  if (!Number.isNaN(x) && opts.clamp === true) {\n    // 1. Set x to min(max(x, lowerBound), upperBound).\n    x = Math.min(Math.max(x, lowerBound), upperBound)\n\n    // 2. Round x to the nearest integer, choosing the\n    //    even integer if it lies halfway between two,\n    //    and choosing +0 rather than 0.\n    if (Math.floor(x) % 2 === 0) {\n      x = Math.floor(x)\n    } else {\n      x = Math.ceil(x)\n    }\n\n    // 3. Return x.\n    return x\n  }\n\n  // 8. If x is NaN, +0, +, or , then return +0.\n  if (\n    Number.isNaN(x) ||\n    (x === 0 && Object.is(0, x)) ||\n    x === Number.POSITIVE_INFINITY ||\n    x === Number.NEGATIVE_INFINITY\n  ) {\n    return 0\n  }\n\n  // 9. Set x to IntegerPart(x).\n  x = webidl.util.IntegerPart(x)\n\n  // 10. Set x to x modulo 2^bitLength.\n  x = x % Math.pow(2, bitLength)\n\n  // 11. If signedness is \"signed\" and x  2^bitLength  1,\n  //    then return x  2^bitLength.\n  if (signedness === 'signed' && x >= Math.pow(2, bitLength) - 1) {\n    return x - Math.pow(2, bitLength)\n  }\n\n  // 12. Otherwise, return x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#abstract-opdef-integerpart\nwebidl.util.IntegerPart = function (n) {\n  // 1. Let r be floor(abs(n)).\n  const r = Math.floor(Math.abs(n))\n\n  // 2. If n < 0, then return -1  r.\n  if (n < 0) {\n    return -1 * r\n  }\n\n  // 3. Otherwise, return r.\n  return r\n}\n\n// https://webidl.spec.whatwg.org/#es-sequence\nwebidl.sequenceConverter = function (converter) {\n  return (V) => {\n    // 1. If Type(V) is not Object, throw a TypeError.\n    if (webidl.util.Type(V) !== 'Object') {\n      throw webidl.errors.exception({\n        header: 'Sequence',\n        message: `Value of type ${webidl.util.Type(V)} is not an Object.`\n      })\n    }\n\n    // 2. Let method be ? GetMethod(V, @@iterator).\n    /** @type {Generator} */\n    const method = V?.[Symbol.iterator]?.()\n    const seq = []\n\n    // 3. If method is undefined, throw a TypeError.\n    if (\n      method === undefined ||\n      typeof method.next !== 'function'\n    ) {\n      throw webidl.errors.exception({\n        header: 'Sequence',\n        message: 'Object is not an iterator.'\n      })\n    }\n\n    // https://webidl.spec.whatwg.org/#create-sequence-from-iterable\n    while (true) {\n      const { done, value } = method.next()\n\n      if (done) {\n        break\n      }\n\n      seq.push(converter(value))\n    }\n\n    return seq\n  }\n}\n\n// https://webidl.spec.whatwg.org/#es-to-record\nwebidl.recordConverter = function (keyConverter, valueConverter) {\n  return (O) => {\n    // 1. If Type(O) is not Object, throw a TypeError.\n    if (webidl.util.Type(O) !== 'Object') {\n      throw webidl.errors.exception({\n        header: 'Record',\n        message: `Value of type ${webidl.util.Type(O)} is not an Object.`\n      })\n    }\n\n    // 2. Let result be a new empty instance of record<K, V>.\n    const result = {}\n\n    if (!types.isProxy(O)) {\n      // Object.keys only returns enumerable properties\n      const keys = Object.keys(O)\n\n      for (const key of keys) {\n        // 1. Let typedKey be key converted to an IDL value of type K.\n        const typedKey = keyConverter(key)\n\n        // 2. Let value be ? Get(O, key).\n        // 3. Let typedValue be value converted to an IDL value of type V.\n        const typedValue = valueConverter(O[key])\n\n        // 4. Set result[typedKey] to typedValue.\n        result[typedKey] = typedValue\n      }\n\n      // 5. Return result.\n      return result\n    }\n\n    // 3. Let keys be ? O.[[OwnPropertyKeys]]().\n    const keys = Reflect.ownKeys(O)\n\n    // 4. For each key of keys.\n    for (const key of keys) {\n      // 1. Let desc be ? O.[[GetOwnProperty]](key).\n      const desc = Reflect.getOwnPropertyDescriptor(O, key)\n\n      // 2. If desc is not undefined and desc.[[Enumerable]] is true:\n      if (desc?.enumerable) {\n        // 1. Let typedKey be key converted to an IDL value of type K.\n        const typedKey = keyConverter(key)\n\n        // 2. Let value be ? Get(O, key).\n        // 3. Let typedValue be value converted to an IDL value of type V.\n        const typedValue = valueConverter(O[key])\n\n        // 4. Set result[typedKey] to typedValue.\n        result[typedKey] = typedValue\n      }\n    }\n\n    // 5. Return result.\n    return result\n  }\n}\n\nwebidl.interfaceConverter = function (i) {\n  return (V, opts = {}) => {\n    if (opts.strict !== false && !(V instanceof i)) {\n      throw webidl.errors.exception({\n        header: i.name,\n        message: `Expected ${V} to be an instance of ${i.name}.`\n      })\n    }\n\n    return V\n  }\n}\n\nwebidl.dictionaryConverter = function (converters) {\n  return (dictionary) => {\n    const type = webidl.util.Type(dictionary)\n    const dict = {}\n\n    if (type === 'Null' || type === 'Undefined') {\n      return dict\n    } else if (type !== 'Object') {\n      throw webidl.errors.exception({\n        header: 'Dictionary',\n        message: `Expected ${dictionary} to be one of: Null, Undefined, Object.`\n      })\n    }\n\n    for (const options of converters) {\n      const { key, defaultValue, required, converter } = options\n\n      if (required === true) {\n        if (!hasOwn(dictionary, key)) {\n          throw webidl.errors.exception({\n            header: 'Dictionary',\n            message: `Missing required key \"${key}\".`\n          })\n        }\n      }\n\n      let value = dictionary[key]\n      const hasDefault = hasOwn(options, 'defaultValue')\n\n      // Only use defaultValue if value is undefined and\n      // a defaultValue options was provided.\n      if (hasDefault && value !== null) {\n        value = value ?? defaultValue\n      }\n\n      // A key can be optional and have no default value.\n      // When this happens, do not perform a conversion,\n      // and do not assign the key a value.\n      if (required || hasDefault || value !== undefined) {\n        value = converter(value)\n\n        if (\n          options.allowedValues &&\n          !options.allowedValues.includes(value)\n        ) {\n          throw webidl.errors.exception({\n            header: 'Dictionary',\n            message: `${value} is not an accepted type. Expected one of ${options.allowedValues.join(', ')}.`\n          })\n        }\n\n        dict[key] = value\n      }\n    }\n\n    return dict\n  }\n}\n\nwebidl.nullableConverter = function (converter) {\n  return (V) => {\n    if (V === null) {\n      return V\n    }\n\n    return converter(V)\n  }\n}\n\n// https://webidl.spec.whatwg.org/#es-DOMString\nwebidl.converters.DOMString = function (V, opts = {}) {\n  // 1. If V is null and the conversion is to an IDL type\n  //    associated with the [LegacyNullToEmptyString]\n  //    extended attribute, then return the DOMString value\n  //    that represents the empty string.\n  if (V === null && opts.legacyNullToEmptyString) {\n    return ''\n  }\n\n  // 2. Let x be ? ToString(V).\n  if (typeof V === 'symbol') {\n    throw new TypeError('Could not convert argument of type symbol to string.')\n  }\n\n  // 3. Return the IDL DOMString value that represents the\n  //    same sequence of code units as the one the\n  //    ECMAScript String value x represents.\n  return String(V)\n}\n\n// https://webidl.spec.whatwg.org/#es-ByteString\nwebidl.converters.ByteString = function (V) {\n  // 1. Let x be ? ToString(V).\n  // Note: DOMString converter perform ? ToString(V)\n  const x = webidl.converters.DOMString(V)\n\n  // 2. If the value of any element of x is greater than\n  //    255, then throw a TypeError.\n  for (let index = 0; index < x.length; index++) {\n    if (x.charCodeAt(index) > 255) {\n      throw new TypeError(\n        'Cannot convert argument to a ByteString because the character at ' +\n        `index ${index} has a value of ${x.charCodeAt(index)} which is greater than 255.`\n      )\n    }\n  }\n\n  // 3. Return an IDL ByteString value whose length is the\n  //    length of x, and where the value of each element is\n  //    the value of the corresponding element of x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-USVString\nwebidl.converters.USVString = toUSVString\n\n// https://webidl.spec.whatwg.org/#es-boolean\nwebidl.converters.boolean = function (V) {\n  // 1. Let x be the result of computing ToBoolean(V).\n  const x = Boolean(V)\n\n  // 2. Return the IDL boolean value that is the one that represents\n  //    the same truth value as the ECMAScript Boolean value x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-any\nwebidl.converters.any = function (V) {\n  return V\n}\n\n// https://webidl.spec.whatwg.org/#es-long-long\nwebidl.converters['long long'] = function (V) {\n  // 1. Let x be ? ConvertToInt(V, 64, \"signed\").\n  const x = webidl.util.ConvertToInt(V, 64, 'signed')\n\n  // 2. Return the IDL long long value that represents\n  //    the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-long-long\nwebidl.converters['unsigned long long'] = function (V) {\n  // 1. Let x be ? ConvertToInt(V, 64, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 64, 'unsigned')\n\n  // 2. Return the IDL unsigned long long value that\n  //    represents the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-long\nwebidl.converters['unsigned long'] = function (V) {\n  // 1. Let x be ? ConvertToInt(V, 32, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 32, 'unsigned')\n\n  // 2. Return the IDL unsigned long value that\n  //    represents the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-short\nwebidl.converters['unsigned short'] = function (V, opts) {\n  // 1. Let x be ? ConvertToInt(V, 16, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 16, 'unsigned', opts)\n\n  // 2. Return the IDL unsigned short value that represents\n  //    the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#idl-ArrayBuffer\nwebidl.converters.ArrayBuffer = function (V, opts = {}) {\n  // 1. If Type(V) is not Object, or V does not have an\n  //    [[ArrayBufferData]] internal slot, then throw a\n  //    TypeError.\n  // see: https://tc39.es/ecma262/#sec-properties-of-the-arraybuffer-instances\n  // see: https://tc39.es/ecma262/#sec-properties-of-the-sharedarraybuffer-instances\n  if (\n    webidl.util.Type(V) !== 'Object' ||\n    !types.isAnyArrayBuffer(V)\n  ) {\n    throw webidl.errors.conversionFailed({\n      prefix: `${V}`,\n      argument: `${V}`,\n      types: ['ArrayBuffer']\n    })\n  }\n\n  // 2. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V) is true, then throw a\n  //    TypeError.\n  if (opts.allowShared === false && types.isSharedArrayBuffer(V)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V) is true, then throw a\n  //    TypeError.\n  // Note: resizable ArrayBuffers are currently a proposal.\n\n  // 4. Return the IDL ArrayBuffer value that is a\n  //    reference to the same object as V.\n  return V\n}\n\nwebidl.converters.TypedArray = function (V, T, opts = {}) {\n  // 1. Let T be the IDL type V is being converted to.\n\n  // 2. If Type(V) is not Object, or V does not have a\n  //    [[TypedArrayName]] internal slot with a value\n  //    equal to Ts name, then throw a TypeError.\n  if (\n    webidl.util.Type(V) !== 'Object' ||\n    !types.isTypedArray(V) ||\n    V.constructor.name !== T.name\n  ) {\n    throw webidl.errors.conversionFailed({\n      prefix: `${T.name}`,\n      argument: `${V}`,\n      types: [T.name]\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  if (opts.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 4. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  // Note: resizable array buffers are currently a proposal\n\n  // 5. Return the IDL value of type T that is a reference\n  //    to the same object as V.\n  return V\n}\n\nwebidl.converters.DataView = function (V, opts = {}) {\n  // 1. If Type(V) is not Object, or V does not have a\n  //    [[DataView]] internal slot, then throw a TypeError.\n  if (webidl.util.Type(V) !== 'Object' || !types.isDataView(V)) {\n    throw webidl.errors.exception({\n      header: 'DataView',\n      message: 'Object is not a DataView.'\n    })\n  }\n\n  // 2. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is true,\n  //    then throw a TypeError.\n  if (opts.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  // Note: resizable ArrayBuffers are currently a proposal\n\n  // 4. Return the IDL DataView value that is a reference\n  //    to the same object as V.\n  return V\n}\n\n// https://webidl.spec.whatwg.org/#BufferSource\nwebidl.converters.BufferSource = function (V, opts = {}) {\n  if (types.isAnyArrayBuffer(V)) {\n    return webidl.converters.ArrayBuffer(V, opts)\n  }\n\n  if (types.isTypedArray(V)) {\n    return webidl.converters.TypedArray(V, V.constructor)\n  }\n\n  if (types.isDataView(V)) {\n    return webidl.converters.DataView(V, opts)\n  }\n\n  throw new TypeError(`Could not convert ${V} to a BufferSource.`)\n}\n\nwebidl.converters['sequence<ByteString>'] = webidl.sequenceConverter(\n  webidl.converters.ByteString\n)\n\nwebidl.converters['sequence<sequence<ByteString>>'] = webidl.sequenceConverter(\n  webidl.converters['sequence<ByteString>']\n)\n\nwebidl.converters['record<ByteString, ByteString>'] = webidl.recordConverter(\n  webidl.converters.ByteString,\n  webidl.converters.ByteString\n)\n\nmodule.exports = {\n  webidl\n}\n","'use strict'\n\n/**\n * @see https://encoding.spec.whatwg.org/#concept-encoding-get\n * @param {string|undefined} label\n */\nfunction getEncoding (label) {\n  if (!label) {\n    return 'failure'\n  }\n\n  // 1. Remove any leading and trailing ASCII whitespace from label.\n  // 2. If label is an ASCII case-insensitive match for any of the\n  //    labels listed in the table below, then return the\n  //    corresponding encoding; otherwise return failure.\n  switch (label.trim().toLowerCase()) {\n    case 'unicode-1-1-utf-8':\n    case 'unicode11utf8':\n    case 'unicode20utf8':\n    case 'utf-8':\n    case 'utf8':\n    case 'x-unicode20utf8':\n      return 'UTF-8'\n    case '866':\n    case 'cp866':\n    case 'csibm866':\n    case 'ibm866':\n      return 'IBM866'\n    case 'csisolatin2':\n    case 'iso-8859-2':\n    case 'iso-ir-101':\n    case 'iso8859-2':\n    case 'iso88592':\n    case 'iso_8859-2':\n    case 'iso_8859-2:1987':\n    case 'l2':\n    case 'latin2':\n      return 'ISO-8859-2'\n    case 'csisolatin3':\n    case 'iso-8859-3':\n    case 'iso-ir-109':\n    case 'iso8859-3':\n    case 'iso88593':\n    case 'iso_8859-3':\n    case 'iso_8859-3:1988':\n    case 'l3':\n    case 'latin3':\n      return 'ISO-8859-3'\n    case 'csisolatin4':\n    case 'iso-8859-4':\n    case 'iso-ir-110':\n    case 'iso8859-4':\n    case 'iso88594':\n    case 'iso_8859-4':\n    case 'iso_8859-4:1988':\n    case 'l4':\n    case 'latin4':\n      return 'ISO-8859-4'\n    case 'csisolatincyrillic':\n    case 'cyrillic':\n    case 'iso-8859-5':\n    case 'iso-ir-144':\n    case 'iso8859-5':\n    case 'iso88595':\n    case 'iso_8859-5':\n    case 'iso_8859-5:1988':\n      return 'ISO-8859-5'\n    case 'arabic':\n    case 'asmo-708':\n    case 'csiso88596e':\n    case 'csiso88596i':\n    case 'csisolatinarabic':\n    case 'ecma-114':\n    case 'iso-8859-6':\n    case 'iso-8859-6-e':\n    case 'iso-8859-6-i':\n    case 'iso-ir-127':\n    case 'iso8859-6':\n    case 'iso88596':\n    case 'iso_8859-6':\n    case 'iso_8859-6:1987':\n      return 'ISO-8859-6'\n    case 'csisolatingreek':\n    case 'ecma-118':\n    case 'elot_928':\n    case 'greek':\n    case 'greek8':\n    case 'iso-8859-7':\n    case 'iso-ir-126':\n    case 'iso8859-7':\n    case 'iso88597':\n    case 'iso_8859-7':\n    case 'iso_8859-7:1987':\n    case 'sun_eu_greek':\n      return 'ISO-8859-7'\n    case 'csiso88598e':\n    case 'csisolatinhebrew':\n    case 'hebrew':\n    case 'iso-8859-8':\n    case 'iso-8859-8-e':\n    case 'iso-ir-138':\n    case 'iso8859-8':\n    case 'iso88598':\n    case 'iso_8859-8':\n    case 'iso_8859-8:1988':\n    case 'visual':\n      return 'ISO-8859-8'\n    case 'csiso88598i':\n    case 'iso-8859-8-i':\n    case 'logical':\n      return 'ISO-8859-8-I'\n    case 'csisolatin6':\n    case 'iso-8859-10':\n    case 'iso-ir-157':\n    case 'iso8859-10':\n    case 'iso885910':\n    case 'l6':\n    case 'latin6':\n      return 'ISO-8859-10'\n    case 'iso-8859-13':\n    case 'iso8859-13':\n    case 'iso885913':\n      return 'ISO-8859-13'\n    case 'iso-8859-14':\n    case 'iso8859-14':\n    case 'iso885914':\n      return 'ISO-8859-14'\n    case 'csisolatin9':\n    case 'iso-8859-15':\n    case 'iso8859-15':\n    case 'iso885915':\n    case 'iso_8859-15':\n    case 'l9':\n      return 'ISO-8859-15'\n    case 'iso-8859-16':\n      return 'ISO-8859-16'\n    case 'cskoi8r':\n    case 'koi':\n    case 'koi8':\n    case 'koi8-r':\n    case 'koi8_r':\n      return 'KOI8-R'\n    case 'koi8-ru':\n    case 'koi8-u':\n      return 'KOI8-U'\n    case 'csmacintosh':\n    case 'mac':\n    case 'macintosh':\n    case 'x-mac-roman':\n      return 'macintosh'\n    case 'iso-8859-11':\n    case 'iso8859-11':\n    case 'iso885911':\n    case 'tis-620':\n    case 'windows-874':\n      return 'windows-874'\n    case 'cp1250':\n    case 'windows-1250':\n    case 'x-cp1250':\n      return 'windows-1250'\n    case 'cp1251':\n    case 'windows-1251':\n    case 'x-cp1251':\n      return 'windows-1251'\n    case 'ansi_x3.4-1968':\n    case 'ascii':\n    case 'cp1252':\n    case 'cp819':\n    case 'csisolatin1':\n    case 'ibm819':\n    case 'iso-8859-1':\n    case 'iso-ir-100':\n    case 'iso8859-1':\n    case 'iso88591':\n    case 'iso_8859-1':\n    case 'iso_8859-1:1987':\n    case 'l1':\n    case 'latin1':\n    case 'us-ascii':\n    case 'windows-1252':\n    case 'x-cp1252':\n      return 'windows-1252'\n    case 'cp1253':\n    case 'windows-1253':\n    case 'x-cp1253':\n      return 'windows-1253'\n    case 'cp1254':\n    case 'csisolatin5':\n    case 'iso-8859-9':\n    case 'iso-ir-148':\n    case 'iso8859-9':\n    case 'iso88599':\n    case 'iso_8859-9':\n    case 'iso_8859-9:1989':\n    case 'l5':\n    case 'latin5':\n    case 'windows-1254':\n    case 'x-cp1254':\n      return 'windows-1254'\n    case 'cp1255':\n    case 'windows-1255':\n    case 'x-cp1255':\n      return 'windows-1255'\n    case 'cp1256':\n    case 'windows-1256':\n    case 'x-cp1256':\n      return 'windows-1256'\n    case 'cp1257':\n    case 'windows-1257':\n    case 'x-cp1257':\n      return 'windows-1257'\n    case 'cp1258':\n    case 'windows-1258':\n    case 'x-cp1258':\n      return 'windows-1258'\n    case 'x-mac-cyrillic':\n    case 'x-mac-ukrainian':\n      return 'x-mac-cyrillic'\n    case 'chinese':\n    case 'csgb2312':\n    case 'csiso58gb231280':\n    case 'gb2312':\n    case 'gb_2312':\n    case 'gb_2312-80':\n    case 'gbk':\n    case 'iso-ir-58':\n    case 'x-gbk':\n      return 'GBK'\n    case 'gb18030':\n      return 'gb18030'\n    case 'big5':\n    case 'big5-hkscs':\n    case 'cn-big5':\n    case 'csbig5':\n    case 'x-x-big5':\n      return 'Big5'\n    case 'cseucpkdfmtjapanese':\n    case 'euc-jp':\n    case 'x-euc-jp':\n      return 'EUC-JP'\n    case 'csiso2022jp':\n    case 'iso-2022-jp':\n      return 'ISO-2022-JP'\n    case 'csshiftjis':\n    case 'ms932':\n    case 'ms_kanji':\n    case 'shift-jis':\n    case 'shift_jis':\n    case 'sjis':\n    case 'windows-31j':\n    case 'x-sjis':\n      return 'Shift_JIS'\n    case 'cseuckr':\n    case 'csksc56011987':\n    case 'euc-kr':\n    case 'iso-ir-149':\n    case 'korean':\n    case 'ks_c_5601-1987':\n    case 'ks_c_5601-1989':\n    case 'ksc5601':\n    case 'ksc_5601':\n    case 'windows-949':\n      return 'EUC-KR'\n    case 'csiso2022kr':\n    case 'hz-gb-2312':\n    case 'iso-2022-cn':\n    case 'iso-2022-cn-ext':\n    case 'iso-2022-kr':\n    case 'replacement':\n      return 'replacement'\n    case 'unicodefffe':\n    case 'utf-16be':\n      return 'UTF-16BE'\n    case 'csunicode':\n    case 'iso-10646-ucs-2':\n    case 'ucs-2':\n    case 'unicode':\n    case 'unicodefeff':\n    case 'utf-16':\n    case 'utf-16le':\n      return 'UTF-16LE'\n    case 'x-user-defined':\n      return 'x-user-defined'\n    default: return 'failure'\n  }\n}\n\nmodule.exports = {\n  getEncoding\n}\n","'use strict'\n\nconst {\n  staticPropertyDescriptors,\n  readOperation,\n  fireAProgressEvent\n} = require('./util')\nconst {\n  kState,\n  kError,\n  kResult,\n  kEvents,\n  kAborted\n} = require('./symbols')\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../core/util')\n\nclass FileReader extends EventTarget {\n  constructor () {\n    super()\n\n    this[kState] = 'empty'\n    this[kResult] = null\n    this[kError] = null\n    this[kEvents] = {\n      loadend: null,\n      error: null,\n      abort: null,\n      load: null,\n      progress: null,\n      loadstart: null\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-readAsArrayBuffer\n   * @param {import('buffer').Blob} blob\n   */\n  readAsArrayBuffer (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsArrayBuffer' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsArrayBuffer(blob) method, when invoked,\n    // must initiate a read operation for blob with ArrayBuffer.\n    readOperation(this, blob, 'ArrayBuffer')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#readAsBinaryString\n   * @param {import('buffer').Blob} blob\n   */\n  readAsBinaryString (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsBinaryString' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsBinaryString(blob) method, when invoked,\n    // must initiate a read operation for blob with BinaryString.\n    readOperation(this, blob, 'BinaryString')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#readAsDataText\n   * @param {import('buffer').Blob} blob\n   * @param {string?} encoding\n   */\n  readAsText (blob, encoding = undefined) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsText' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    if (encoding !== undefined) {\n      encoding = webidl.converters.DOMString(encoding)\n    }\n\n    // The readAsText(blob, encoding) method, when invoked,\n    // must initiate a read operation for blob with Text and encoding.\n    readOperation(this, blob, 'Text', encoding)\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-readAsDataURL\n   * @param {import('buffer').Blob} blob\n   */\n  readAsDataURL (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsDataURL' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsDataURL(blob) method, when invoked, must\n    // initiate a read operation for blob with DataURL.\n    readOperation(this, blob, 'DataURL')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-abort\n   */\n  abort () {\n    // 1. If this's state is \"empty\" or if this's state is\n    //    \"done\" set this's result to null and terminate\n    //    this algorithm.\n    if (this[kState] === 'empty' || this[kState] === 'done') {\n      this[kResult] = null\n      return\n    }\n\n    // 2. If this's state is \"loading\" set this's state to\n    //    \"done\" and set this's result to null.\n    if (this[kState] === 'loading') {\n      this[kState] = 'done'\n      this[kResult] = null\n    }\n\n    // 3. If there are any tasks from this on the file reading\n    //    task source in an affiliated task queue, then remove\n    //    those tasks from that task queue.\n    this[kAborted] = true\n\n    // 4. Terminate the algorithm for the read method being processed.\n    // TODO\n\n    // 5. Fire a progress event called abort at this.\n    fireAProgressEvent('abort', this)\n\n    // 6. If this's state is not \"loading\", fire a progress\n    //    event called loadend at this.\n    if (this[kState] !== 'loading') {\n      fireAProgressEvent('loadend', this)\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-readystate\n   */\n  get readyState () {\n    webidl.brandCheck(this, FileReader)\n\n    switch (this[kState]) {\n      case 'empty': return this.EMPTY\n      case 'loading': return this.LOADING\n      case 'done': return this.DONE\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-result\n   */\n  get result () {\n    webidl.brandCheck(this, FileReader)\n\n    // The result attributes getter, when invoked, must return\n    // this's result.\n    return this[kResult]\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-error\n   */\n  get error () {\n    webidl.brandCheck(this, FileReader)\n\n    // The error attributes getter, when invoked, must return\n    // this's error.\n    return this[kError]\n  }\n\n  get onloadend () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].loadend\n  }\n\n  set onloadend (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].loadend) {\n      this.removeEventListener('loadend', this[kEvents].loadend)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].loadend = fn\n      this.addEventListener('loadend', fn)\n    } else {\n      this[kEvents].loadend = null\n    }\n  }\n\n  get onerror () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].error\n  }\n\n  set onerror (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].error) {\n      this.removeEventListener('error', this[kEvents].error)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].error = fn\n      this.addEventListener('error', fn)\n    } else {\n      this[kEvents].error = null\n    }\n  }\n\n  get onloadstart () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].loadstart\n  }\n\n  set onloadstart (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].loadstart) {\n      this.removeEventListener('loadstart', this[kEvents].loadstart)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].loadstart = fn\n      this.addEventListener('loadstart', fn)\n    } else {\n      this[kEvents].loadstart = null\n    }\n  }\n\n  get onprogress () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].progress\n  }\n\n  set onprogress (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].progress) {\n      this.removeEventListener('progress', this[kEvents].progress)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].progress = fn\n      this.addEventListener('progress', fn)\n    } else {\n      this[kEvents].progress = null\n    }\n  }\n\n  get onload () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].load\n  }\n\n  set onload (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].load) {\n      this.removeEventListener('load', this[kEvents].load)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].load = fn\n      this.addEventListener('load', fn)\n    } else {\n      this[kEvents].load = null\n    }\n  }\n\n  get onabort () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].abort\n  }\n\n  set onabort (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].abort) {\n      this.removeEventListener('abort', this[kEvents].abort)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].abort = fn\n      this.addEventListener('abort', fn)\n    } else {\n      this[kEvents].abort = null\n    }\n  }\n}\n\n// https://w3c.github.io/FileAPI/#dom-filereader-empty\nFileReader.EMPTY = FileReader.prototype.EMPTY = 0\n// https://w3c.github.io/FileAPI/#dom-filereader-loading\nFileReader.LOADING = FileReader.prototype.LOADING = 1\n// https://w3c.github.io/FileAPI/#dom-filereader-done\nFileReader.DONE = FileReader.prototype.DONE = 2\n\nObject.defineProperties(FileReader.prototype, {\n  EMPTY: staticPropertyDescriptors,\n  LOADING: staticPropertyDescriptors,\n  DONE: staticPropertyDescriptors,\n  readAsArrayBuffer: kEnumerableProperty,\n  readAsBinaryString: kEnumerableProperty,\n  readAsText: kEnumerableProperty,\n  readAsDataURL: kEnumerableProperty,\n  abort: kEnumerableProperty,\n  readyState: kEnumerableProperty,\n  result: kEnumerableProperty,\n  error: kEnumerableProperty,\n  onloadstart: kEnumerableProperty,\n  onprogress: kEnumerableProperty,\n  onload: kEnumerableProperty,\n  onabort: kEnumerableProperty,\n  onerror: kEnumerableProperty,\n  onloadend: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'FileReader',\n    writable: false,\n    enumerable: false,\n    configurable: true\n  }\n})\n\nObject.defineProperties(FileReader, {\n  EMPTY: staticPropertyDescriptors,\n  LOADING: staticPropertyDescriptors,\n  DONE: staticPropertyDescriptors\n})\n\nmodule.exports = {\n  FileReader\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\n\nconst kState = Symbol('ProgressEvent state')\n\n/**\n * @see https://xhr.spec.whatwg.org/#progressevent\n */\nclass ProgressEvent extends Event {\n  constructor (type, eventInitDict = {}) {\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.ProgressEventInit(eventInitDict ?? {})\n\n    super(type, eventInitDict)\n\n    this[kState] = {\n      lengthComputable: eventInitDict.lengthComputable,\n      loaded: eventInitDict.loaded,\n      total: eventInitDict.total\n    }\n  }\n\n  get lengthComputable () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].lengthComputable\n  }\n\n  get loaded () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].loaded\n  }\n\n  get total () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].total\n  }\n}\n\nwebidl.converters.ProgressEventInit = webidl.dictionaryConverter([\n  {\n    key: 'lengthComputable',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'loaded',\n    converter: webidl.converters['unsigned long long'],\n    defaultValue: 0\n  },\n  {\n    key: 'total',\n    converter: webidl.converters['unsigned long long'],\n    defaultValue: 0\n  },\n  {\n    key: 'bubbles',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'cancelable',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'composed',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  }\n])\n\nmodule.exports = {\n  ProgressEvent\n}\n","'use strict'\n\nmodule.exports = {\n  kState: Symbol('FileReader state'),\n  kResult: Symbol('FileReader result'),\n  kError: Symbol('FileReader error'),\n  kLastProgressEventFired: Symbol('FileReader last progress event fired timestamp'),\n  kEvents: Symbol('FileReader events'),\n  kAborted: Symbol('FileReader aborted')\n}\n","'use strict'\n\nconst {\n  kState,\n  kError,\n  kResult,\n  kAborted,\n  kLastProgressEventFired\n} = require('./symbols')\nconst { ProgressEvent } = require('./progressevent')\nconst { getEncoding } = require('./encoding')\nconst { DOMException } = require('../fetch/constants')\nconst { serializeAMimeType, parseMIMEType } = require('../fetch/dataURL')\nconst { types } = require('util')\nconst { StringDecoder } = require('string_decoder')\nconst { btoa } = require('buffer')\n\n/** @type {PropertyDescriptor} */\nconst staticPropertyDescriptors = {\n  enumerable: true,\n  writable: false,\n  configurable: false\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#readOperation\n * @param {import('./filereader').FileReader} fr\n * @param {import('buffer').Blob} blob\n * @param {string} type\n * @param {string?} encodingName\n */\nfunction readOperation (fr, blob, type, encodingName) {\n  // 1. If frs state is \"loading\", throw an InvalidStateError\n  //    DOMException.\n  if (fr[kState] === 'loading') {\n    throw new DOMException('Invalid state', 'InvalidStateError')\n  }\n\n  // 2. Set frs state to \"loading\".\n  fr[kState] = 'loading'\n\n  // 3. Set frs result to null.\n  fr[kResult] = null\n\n  // 4. Set frs error to null.\n  fr[kError] = null\n\n  // 5. Let stream be the result of calling get stream on blob.\n  /** @type {import('stream/web').ReadableStream} */\n  const stream = blob.stream()\n\n  // 6. Let reader be the result of getting a reader from stream.\n  const reader = stream.getReader()\n\n  // 7. Let bytes be an empty byte sequence.\n  /** @type {Uint8Array[]} */\n  const bytes = []\n\n  // 8. Let chunkPromise be the result of reading a chunk from\n  //    stream with reader.\n  let chunkPromise = reader.read()\n\n  // 9. Let isFirstChunk be true.\n  let isFirstChunk = true\n\n  // 10. In parallel, while true:\n  // Note: \"In parallel\" just means non-blocking\n  // Note 2: readOperation itself cannot be async as double\n  // reading the body would then reject the promise, instead\n  // of throwing an error.\n  ;(async () => {\n    while (!fr[kAborted]) {\n      // 1. Wait for chunkPromise to be fulfilled or rejected.\n      try {\n        const { done, value } = await chunkPromise\n\n        // 2. If chunkPromise is fulfilled, and isFirstChunk is\n        //    true, queue a task to fire a progress event called\n        //    loadstart at fr.\n        if (isFirstChunk && !fr[kAborted]) {\n          queueMicrotask(() => {\n            fireAProgressEvent('loadstart', fr)\n          })\n        }\n\n        // 3. Set isFirstChunk to false.\n        isFirstChunk = false\n\n        // 4. If chunkPromise is fulfilled with an object whose\n        //    done property is false and whose value property is\n        //    a Uint8Array object, run these steps:\n        if (!done && types.isUint8Array(value)) {\n          // 1. Let bs be the byte sequence represented by the\n          //    Uint8Array object.\n\n          // 2. Append bs to bytes.\n          bytes.push(value)\n\n          // 3. If roughly 50ms have passed since these steps\n          //    were last invoked, queue a task to fire a\n          //    progress event called progress at fr.\n          if (\n            (\n              fr[kLastProgressEventFired] === undefined ||\n              Date.now() - fr[kLastProgressEventFired] >= 50\n            ) &&\n            !fr[kAborted]\n          ) {\n            fr[kLastProgressEventFired] = Date.now()\n            queueMicrotask(() => {\n              fireAProgressEvent('progress', fr)\n            })\n          }\n\n          // 4. Set chunkPromise to the result of reading a\n          //    chunk from stream with reader.\n          chunkPromise = reader.read()\n        } else if (done) {\n          // 5. Otherwise, if chunkPromise is fulfilled with an\n          //    object whose done property is true, queue a task\n          //    to run the following steps and abort this algorithm:\n          queueMicrotask(() => {\n            // 1. Set frs state to \"done\".\n            fr[kState] = 'done'\n\n            // 2. Let result be the result of package data given\n            //    bytes, type, blobs type, and encodingName.\n            try {\n              const result = packageData(bytes, type, blob.type, encodingName)\n\n              // 4. Else:\n\n              if (fr[kAborted]) {\n                return\n              }\n\n              // 1. Set frs result to result.\n              fr[kResult] = result\n\n              // 2. Fire a progress event called load at the fr.\n              fireAProgressEvent('load', fr)\n            } catch (error) {\n              // 3. If package data threw an exception error:\n\n              // 1. Set frs error to error.\n              fr[kError] = error\n\n              // 2. Fire a progress event called error at fr.\n              fireAProgressEvent('error', fr)\n            }\n\n            // 5. If frs state is not \"loading\", fire a progress\n            //    event called loadend at the fr.\n            if (fr[kState] !== 'loading') {\n              fireAProgressEvent('loadend', fr)\n            }\n          })\n\n          break\n        }\n      } catch (error) {\n        if (fr[kAborted]) {\n          return\n        }\n\n        // 6. Otherwise, if chunkPromise is rejected with an\n        //    error error, queue a task to run the following\n        //    steps and abort this algorithm:\n        queueMicrotask(() => {\n          // 1. Set frs state to \"done\".\n          fr[kState] = 'done'\n\n          // 2. Set frs error to error.\n          fr[kError] = error\n\n          // 3. Fire a progress event called error at fr.\n          fireAProgressEvent('error', fr)\n\n          // 4. If frs state is not \"loading\", fire a progress\n          //    event called loadend at fr.\n          if (fr[kState] !== 'loading') {\n            fireAProgressEvent('loadend', fr)\n          }\n        })\n\n        break\n      }\n    }\n  })()\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#fire-a-progress-event\n * @see https://dom.spec.whatwg.org/#concept-event-fire\n * @param {string} e The name of the event\n * @param {import('./filereader').FileReader} reader\n */\nfunction fireAProgressEvent (e, reader) {\n  // The progress event e does not bubble. e.bubbles must be false\n  // The progress event e is NOT cancelable. e.cancelable must be false\n  const event = new ProgressEvent(e, {\n    bubbles: false,\n    cancelable: false\n  })\n\n  reader.dispatchEvent(event)\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#blob-package-data\n * @param {Uint8Array[]} bytes\n * @param {string} type\n * @param {string?} mimeType\n * @param {string?} encodingName\n */\nfunction packageData (bytes, type, mimeType, encodingName) {\n  // 1. A Blob has an associated package data algorithm, given\n  //    bytes, a type, a optional mimeType, and a optional\n  //    encodingName, which switches on type and runs the\n  //    associated steps:\n\n  switch (type) {\n    case 'DataURL': {\n      // 1. Return bytes as a DataURL [RFC2397] subject to\n      //    the considerations below:\n      //  * Use mimeType as part of the Data URL if it is\n      //    available in keeping with the Data URL\n      //    specification [RFC2397].\n      //  * If mimeType is not available return a Data URL\n      //    without a media-type. [RFC2397].\n\n      // https://datatracker.ietf.org/doc/html/rfc2397#section-3\n      // dataurl    := \"data:\" [ mediatype ] [ \";base64\" ] \",\" data\n      // mediatype  := [ type \"/\" subtype ] *( \";\" parameter )\n      // data       := *urlchar\n      // parameter  := attribute \"=\" value\n      let dataURL = 'data:'\n\n      const parsed = parseMIMEType(mimeType || 'application/octet-stream')\n\n      if (parsed !== 'failure') {\n        dataURL += serializeAMimeType(parsed)\n      }\n\n      dataURL += ';base64,'\n\n      const decoder = new StringDecoder('latin1')\n\n      for (const chunk of bytes) {\n        dataURL += btoa(decoder.write(chunk))\n      }\n\n      dataURL += btoa(decoder.end())\n\n      return dataURL\n    }\n    case 'Text': {\n      // 1. Let encoding be failure\n      let encoding = 'failure'\n\n      // 2. If the encodingName is present, set encoding to the\n      //    result of getting an encoding from encodingName.\n      if (encodingName) {\n        encoding = getEncoding(encodingName)\n      }\n\n      // 3. If encoding is failure, and mimeType is present:\n      if (encoding === 'failure' && mimeType) {\n        // 1. Let type be the result of parse a MIME type\n        //    given mimeType.\n        const type = parseMIMEType(mimeType)\n\n        // 2. If type is not failure, set encoding to the result\n        //    of getting an encoding from types parameters[\"charset\"].\n        if (type !== 'failure') {\n          encoding = getEncoding(type.parameters.get('charset'))\n        }\n      }\n\n      // 4. If encoding is failure, then set encoding to UTF-8.\n      if (encoding === 'failure') {\n        encoding = 'UTF-8'\n      }\n\n      // 5. Decode bytes using fallback encoding encoding, and\n      //    return the result.\n      return decode(bytes, encoding)\n    }\n    case 'ArrayBuffer': {\n      // Return a new ArrayBuffer whose contents are bytes.\n      const sequence = combineByteSequences(bytes)\n\n      return sequence.buffer\n    }\n    case 'BinaryString': {\n      // Return bytes as a binary string, in which every byte\n      //  is represented by a code unit of equal value [0..255].\n      let binaryString = ''\n\n      const decoder = new StringDecoder('latin1')\n\n      for (const chunk of bytes) {\n        binaryString += decoder.write(chunk)\n      }\n\n      binaryString += decoder.end()\n\n      return binaryString\n    }\n  }\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#decode\n * @param {Uint8Array[]} ioQueue\n * @param {string} encoding\n */\nfunction decode (ioQueue, encoding) {\n  const bytes = combineByteSequences(ioQueue)\n\n  // 1. Let BOMEncoding be the result of BOM sniffing ioQueue.\n  const BOMEncoding = BOMSniffing(bytes)\n\n  let slice = 0\n\n  // 2. If BOMEncoding is non-null:\n  if (BOMEncoding !== null) {\n    // 1. Set encoding to BOMEncoding.\n    encoding = BOMEncoding\n\n    // 2. Read three bytes from ioQueue, if BOMEncoding is\n    //    UTF-8; otherwise read two bytes.\n    //    (Do nothing with those bytes.)\n    slice = BOMEncoding === 'UTF-8' ? 3 : 2\n  }\n\n  // 3. Process a queue with an instance of encodings\n  //    decoder, ioQueue, output, and \"replacement\".\n\n  // 4. Return output.\n\n  const sliced = bytes.slice(slice)\n  return new TextDecoder(encoding).decode(sliced)\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#bom-sniff\n * @param {Uint8Array} ioQueue\n */\nfunction BOMSniffing (ioQueue) {\n  // 1. Let BOM be the result of peeking 3 bytes from ioQueue,\n  //    converted to a byte sequence.\n  const [a, b, c] = ioQueue\n\n  // 2. For each of the rows in the table below, starting with\n  //    the first one and going down, if BOM starts with the\n  //    bytes given in the first column, then return the\n  //    encoding given in the cell in the second column of that\n  //    row. Otherwise, return null.\n  if (a === 0xEF && b === 0xBB && c === 0xBF) {\n    return 'UTF-8'\n  } else if (a === 0xFE && b === 0xFF) {\n    return 'UTF-16BE'\n  } else if (a === 0xFF && b === 0xFE) {\n    return 'UTF-16LE'\n  }\n\n  return null\n}\n\n/**\n * @param {Uint8Array[]} sequences\n */\nfunction combineByteSequences (sequences) {\n  const size = sequences.reduce((a, b) => {\n    return a + b.byteLength\n  }, 0)\n\n  let offset = 0\n\n  return sequences.reduce((a, b) => {\n    a.set(b, offset)\n    offset += b.byteLength\n    return a\n  }, new Uint8Array(size))\n}\n\nmodule.exports = {\n  staticPropertyDescriptors,\n  readOperation,\n  fireAProgressEvent\n}\n","'use strict'\n\n// We include a version number for the Dispatcher API. In case of breaking changes,\n// this version number must be increased to avoid conflicts.\nconst globalDispatcher = Symbol.for('undici.globalDispatcher.1')\nconst { InvalidArgumentError } = require('./core/errors')\nconst Agent = require('./agent')\n\nif (getGlobalDispatcher() === undefined) {\n  setGlobalDispatcher(new Agent())\n}\n\nfunction setGlobalDispatcher (agent) {\n  if (!agent || typeof agent.dispatch !== 'function') {\n    throw new InvalidArgumentError('Argument agent must implement Agent')\n  }\n  Object.defineProperty(globalThis, globalDispatcher, {\n    value: agent,\n    writable: true,\n    enumerable: false,\n    configurable: false\n  })\n}\n\nfunction getGlobalDispatcher () {\n  return globalThis[globalDispatcher]\n}\n\nmodule.exports = {\n  setGlobalDispatcher,\n  getGlobalDispatcher\n}\n","'use strict'\n\nmodule.exports = class DecoratorHandler {\n  constructor (handler) {\n    this.handler = handler\n  }\n\n  onConnect (...args) {\n    return this.handler.onConnect(...args)\n  }\n\n  onError (...args) {\n    return this.handler.onError(...args)\n  }\n\n  onUpgrade (...args) {\n    return this.handler.onUpgrade(...args)\n  }\n\n  onHeaders (...args) {\n    return this.handler.onHeaders(...args)\n  }\n\n  onData (...args) {\n    return this.handler.onData(...args)\n  }\n\n  onComplete (...args) {\n    return this.handler.onComplete(...args)\n  }\n\n  onBodySent (...args) {\n    return this.handler.onBodySent(...args)\n  }\n}\n","'use strict'\n\nconst util = require('../core/util')\nconst { kBodyUsed } = require('../core/symbols')\nconst assert = require('assert')\nconst { InvalidArgumentError } = require('../core/errors')\nconst EE = require('events')\n\nconst redirectableStatusCodes = [300, 301, 302, 303, 307, 308]\n\nconst kBody = Symbol('body')\n\nclass BodyAsyncIterable {\n  constructor (body) {\n    this[kBody] = body\n    this[kBodyUsed] = false\n  }\n\n  async * [Symbol.asyncIterator] () {\n    assert(!this[kBodyUsed], 'disturbed')\n    this[kBodyUsed] = true\n    yield * this[kBody]\n  }\n}\n\nclass RedirectHandler {\n  constructor (dispatch, maxRedirections, opts, handler) {\n    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    util.validateHandler(handler, opts.method, opts.upgrade)\n\n    this.dispatch = dispatch\n    this.location = null\n    this.abort = null\n    this.opts = { ...opts, maxRedirections: 0 } // opts must be a copy\n    this.maxRedirections = maxRedirections\n    this.handler = handler\n    this.history = []\n\n    if (util.isStream(this.opts.body)) {\n      // TODO (fix): Provide some way for the user to cache the file to e.g. /tmp\n      // so that it can be dispatched again?\n      // TODO (fix): Do we need 100-expect support to provide a way to do this properly?\n      if (util.bodyLength(this.opts.body) === 0) {\n        this.opts.body\n          .on('data', function () {\n            assert(false)\n          })\n      }\n\n      if (typeof this.opts.body.readableDidRead !== 'boolean') {\n        this.opts.body[kBodyUsed] = false\n        EE.prototype.on.call(this.opts.body, 'data', function () {\n          this[kBodyUsed] = true\n        })\n      }\n    } else if (this.opts.body && typeof this.opts.body.pipeTo === 'function') {\n      // TODO (fix): We can't access ReadableStream internal state\n      // to determine whether or not it has been disturbed. This is just\n      // a workaround.\n      this.opts.body = new BodyAsyncIterable(this.opts.body)\n    } else if (\n      this.opts.body &&\n      typeof this.opts.body !== 'string' &&\n      !ArrayBuffer.isView(this.opts.body) &&\n      util.isIterable(this.opts.body)\n    ) {\n      // TODO: Should we allow re-using iterable if !this.opts.idempotent\n      // or through some other flag?\n      this.opts.body = new BodyAsyncIterable(this.opts.body)\n    }\n  }\n\n  onConnect (abort) {\n    this.abort = abort\n    this.handler.onConnect(abort, { history: this.history })\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    this.handler.onUpgrade(statusCode, headers, socket)\n  }\n\n  onError (error) {\n    this.handler.onError(error)\n  }\n\n  onHeaders (statusCode, headers, resume, statusText) {\n    this.location = this.history.length >= this.maxRedirections || util.isDisturbed(this.opts.body)\n      ? null\n      : parseLocation(statusCode, headers)\n\n    if (this.opts.origin) {\n      this.history.push(new URL(this.opts.path, this.opts.origin))\n    }\n\n    if (!this.location) {\n      return this.handler.onHeaders(statusCode, headers, resume, statusText)\n    }\n\n    const { origin, pathname, search } = util.parseURL(new URL(this.location, this.opts.origin && new URL(this.opts.path, this.opts.origin)))\n    const path = search ? `${pathname}${search}` : pathname\n\n    // Remove headers referring to the original URL.\n    // By default it is Host only, unless it's a 303 (see below), which removes also all Content-* headers.\n    // https://tools.ietf.org/html/rfc7231#section-6.4\n    this.opts.headers = cleanRequestHeaders(this.opts.headers, statusCode === 303, this.opts.origin !== origin)\n    this.opts.path = path\n    this.opts.origin = origin\n    this.opts.maxRedirections = 0\n    this.opts.query = null\n\n    // https://tools.ietf.org/html/rfc7231#section-6.4.4\n    // In case of HTTP 303, always replace method to be either HEAD or GET\n    if (statusCode === 303 && this.opts.method !== 'HEAD') {\n      this.opts.method = 'GET'\n      this.opts.body = null\n    }\n  }\n\n  onData (chunk) {\n    if (this.location) {\n      /*\n        https://tools.ietf.org/html/rfc7231#section-6.4\n\n        TLDR: undici always ignores 3xx response bodies.\n\n        Redirection is used to serve the requested resource from another URL, so it is assumes that\n        no body is generated (and thus can be ignored). Even though generating a body is not prohibited.\n\n        For status 301, 302, 303, 307 and 308 (the latter from RFC 7238), the specs mention that the body usually\n        (which means it's optional and not mandated) contain just an hyperlink to the value of\n        the Location response header, so the body can be ignored safely.\n\n        For status 300, which is \"Multiple Choices\", the spec mentions both generating a Location\n        response header AND a response body with the other possible location to follow.\n        Since the spec explicitily chooses not to specify a format for such body and leave it to\n        servers and browsers implementors, we ignore the body as there is no specified way to eventually parse it.\n      */\n    } else {\n      return this.handler.onData(chunk)\n    }\n  }\n\n  onComplete (trailers) {\n    if (this.location) {\n      /*\n        https://tools.ietf.org/html/rfc7231#section-6.4\n\n        TLDR: undici always ignores 3xx response trailers as they are not expected in case of redirections\n        and neither are useful if present.\n\n        See comment on onData method above for more detailed informations.\n      */\n\n      this.location = null\n      this.abort = null\n\n      this.dispatch(this.opts, this)\n    } else {\n      this.handler.onComplete(trailers)\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this.handler.onBodySent) {\n      this.handler.onBodySent(chunk)\n    }\n  }\n}\n\nfunction parseLocation (statusCode, headers) {\n  if (redirectableStatusCodes.indexOf(statusCode) === -1) {\n    return null\n  }\n\n  for (let i = 0; i < headers.length; i += 2) {\n    if (headers[i].toString().toLowerCase() === 'location') {\n      return headers[i + 1]\n    }\n  }\n}\n\n// https://tools.ietf.org/html/rfc7231#section-6.4.4\nfunction shouldRemoveHeader (header, removeContent, unknownOrigin) {\n  if (header.length === 4) {\n    return util.headerNameToString(header) === 'host'\n  }\n  if (removeContent && util.headerNameToString(header).startsWith('content-')) {\n    return true\n  }\n  if (unknownOrigin && (header.length === 13 || header.length === 6 || header.length === 19)) {\n    const name = util.headerNameToString(header)\n    return name === 'authorization' || name === 'cookie' || name === 'proxy-authorization'\n  }\n  return false\n}\n\n// https://tools.ietf.org/html/rfc7231#section-6.4\nfunction cleanRequestHeaders (headers, removeContent, unknownOrigin) {\n  const ret = []\n  if (Array.isArray(headers)) {\n    for (let i = 0; i < headers.length; i += 2) {\n      if (!shouldRemoveHeader(headers[i], removeContent, unknownOrigin)) {\n        ret.push(headers[i], headers[i + 1])\n      }\n    }\n  } else if (headers && typeof headers === 'object') {\n    for (const key of Object.keys(headers)) {\n      if (!shouldRemoveHeader(key, removeContent, unknownOrigin)) {\n        ret.push(key, headers[key])\n      }\n    }\n  } else {\n    assert(headers == null, 'headers must be an object or an array')\n  }\n  return ret\n}\n\nmodule.exports = RedirectHandler\n","const assert = require('assert')\n\nconst { kRetryHandlerDefaultRetry } = require('../core/symbols')\nconst { RequestRetryError } = require('../core/errors')\nconst { isDisturbed, parseHeaders, parseRangeHeader } = require('../core/util')\n\nfunction calculateRetryAfterHeader (retryAfter) {\n  const current = Date.now()\n  const diff = new Date(retryAfter).getTime() - current\n\n  return diff\n}\n\nclass RetryHandler {\n  constructor (opts, handlers) {\n    const { retryOptions, ...dispatchOpts } = opts\n    const {\n      // Retry scoped\n      retry: retryFn,\n      maxRetries,\n      maxTimeout,\n      minTimeout,\n      timeoutFactor,\n      // Response scoped\n      methods,\n      errorCodes,\n      retryAfter,\n      statusCodes\n    } = retryOptions ?? {}\n\n    this.dispatch = handlers.dispatch\n    this.handler = handlers.handler\n    this.opts = dispatchOpts\n    this.abort = null\n    this.aborted = false\n    this.retryOpts = {\n      retry: retryFn ?? RetryHandler[kRetryHandlerDefaultRetry],\n      retryAfter: retryAfter ?? true,\n      maxTimeout: maxTimeout ?? 30 * 1000, // 30s,\n      timeout: minTimeout ?? 500, // .5s\n      timeoutFactor: timeoutFactor ?? 2,\n      maxRetries: maxRetries ?? 5,\n      // What errors we should retry\n      methods: methods ?? ['GET', 'HEAD', 'OPTIONS', 'PUT', 'DELETE', 'TRACE'],\n      // Indicates which errors to retry\n      statusCodes: statusCodes ?? [500, 502, 503, 504, 429],\n      // List of errors to retry\n      errorCodes: errorCodes ?? [\n        'ECONNRESET',\n        'ECONNREFUSED',\n        'ENOTFOUND',\n        'ENETDOWN',\n        'ENETUNREACH',\n        'EHOSTDOWN',\n        'EHOSTUNREACH',\n        'EPIPE'\n      ]\n    }\n\n    this.retryCount = 0\n    this.start = 0\n    this.end = null\n    this.etag = null\n    this.resume = null\n\n    // Handle possible onConnect duplication\n    this.handler.onConnect(reason => {\n      this.aborted = true\n      if (this.abort) {\n        this.abort(reason)\n      } else {\n        this.reason = reason\n      }\n    })\n  }\n\n  onRequestSent () {\n    if (this.handler.onRequestSent) {\n      this.handler.onRequestSent()\n    }\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    if (this.handler.onUpgrade) {\n      this.handler.onUpgrade(statusCode, headers, socket)\n    }\n  }\n\n  onConnect (abort) {\n    if (this.aborted) {\n      abort(this.reason)\n    } else {\n      this.abort = abort\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this.handler.onBodySent) return this.handler.onBodySent(chunk)\n  }\n\n  static [kRetryHandlerDefaultRetry] (err, { state, opts }, cb) {\n    const { statusCode, code, headers } = err\n    const { method, retryOptions } = opts\n    const {\n      maxRetries,\n      timeout,\n      maxTimeout,\n      timeoutFactor,\n      statusCodes,\n      errorCodes,\n      methods\n    } = retryOptions\n    let { counter, currentTimeout } = state\n\n    currentTimeout =\n      currentTimeout != null && currentTimeout > 0 ? currentTimeout : timeout\n\n    // Any code that is not a Undici's originated and allowed to retry\n    if (\n      code &&\n      code !== 'UND_ERR_REQ_RETRY' &&\n      code !== 'UND_ERR_SOCKET' &&\n      !errorCodes.includes(code)\n    ) {\n      cb(err)\n      return\n    }\n\n    // If a set of method are provided and the current method is not in the list\n    if (Array.isArray(methods) && !methods.includes(method)) {\n      cb(err)\n      return\n    }\n\n    // If a set of status code are provided and the current status code is not in the list\n    if (\n      statusCode != null &&\n      Array.isArray(statusCodes) &&\n      !statusCodes.includes(statusCode)\n    ) {\n      cb(err)\n      return\n    }\n\n    // If we reached the max number of retries\n    if (counter > maxRetries) {\n      cb(err)\n      return\n    }\n\n    let retryAfterHeader = headers != null && headers['retry-after']\n    if (retryAfterHeader) {\n      retryAfterHeader = Number(retryAfterHeader)\n      retryAfterHeader = isNaN(retryAfterHeader)\n        ? calculateRetryAfterHeader(retryAfterHeader)\n        : retryAfterHeader * 1e3 // Retry-After is in seconds\n    }\n\n    const retryTimeout =\n      retryAfterHeader > 0\n        ? Math.min(retryAfterHeader, maxTimeout)\n        : Math.min(currentTimeout * timeoutFactor ** counter, maxTimeout)\n\n    state.currentTimeout = retryTimeout\n\n    setTimeout(() => cb(null), retryTimeout)\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const headers = parseHeaders(rawHeaders)\n\n    this.retryCount += 1\n\n    if (statusCode >= 300) {\n      this.abort(\n        new RequestRetryError('Request failed', statusCode, {\n          headers,\n          count: this.retryCount\n        })\n      )\n      return false\n    }\n\n    // Checkpoint for resume from where we left it\n    if (this.resume != null) {\n      this.resume = null\n\n      if (statusCode !== 206) {\n        return true\n      }\n\n      const contentRange = parseRangeHeader(headers['content-range'])\n      // If no content range\n      if (!contentRange) {\n        this.abort(\n          new RequestRetryError('Content-Range mismatch', statusCode, {\n            headers,\n            count: this.retryCount\n          })\n        )\n        return false\n      }\n\n      // Let's start with a weak etag check\n      if (this.etag != null && this.etag !== headers.etag) {\n        this.abort(\n          new RequestRetryError('ETag mismatch', statusCode, {\n            headers,\n            count: this.retryCount\n          })\n        )\n        return false\n      }\n\n      const { start, size, end = size } = contentRange\n\n      assert(this.start === start, 'content-range mismatch')\n      assert(this.end == null || this.end === end, 'content-range mismatch')\n\n      this.resume = resume\n      return true\n    }\n\n    if (this.end == null) {\n      if (statusCode === 206) {\n        // First time we receive 206\n        const range = parseRangeHeader(headers['content-range'])\n\n        if (range == null) {\n          return this.handler.onHeaders(\n            statusCode,\n            rawHeaders,\n            resume,\n            statusMessage\n          )\n        }\n\n        const { start, size, end = size } = range\n\n        assert(\n          start != null && Number.isFinite(start) && this.start !== start,\n          'content-range mismatch'\n        )\n        assert(Number.isFinite(start))\n        assert(\n          end != null && Number.isFinite(end) && this.end !== end,\n          'invalid content-length'\n        )\n\n        this.start = start\n        this.end = end\n      }\n\n      // We make our best to checkpoint the body for further range headers\n      if (this.end == null) {\n        const contentLength = headers['content-length']\n        this.end = contentLength != null ? Number(contentLength) : null\n      }\n\n      assert(Number.isFinite(this.start))\n      assert(\n        this.end == null || Number.isFinite(this.end),\n        'invalid content-length'\n      )\n\n      this.resume = resume\n      this.etag = headers.etag != null ? headers.etag : null\n\n      return this.handler.onHeaders(\n        statusCode,\n        rawHeaders,\n        resume,\n        statusMessage\n      )\n    }\n\n    const err = new RequestRetryError('Request failed', statusCode, {\n      headers,\n      count: this.retryCount\n    })\n\n    this.abort(err)\n\n    return false\n  }\n\n  onData (chunk) {\n    this.start += chunk.length\n\n    return this.handler.onData(chunk)\n  }\n\n  onComplete (rawTrailers) {\n    this.retryCount = 0\n    return this.handler.onComplete(rawTrailers)\n  }\n\n  onError (err) {\n    if (this.aborted || isDisturbed(this.opts.body)) {\n      return this.handler.onError(err)\n    }\n\n    this.retryOpts.retry(\n      err,\n      {\n        state: { counter: this.retryCount++, currentTimeout: this.retryAfter },\n        opts: { retryOptions: this.retryOpts, ...this.opts }\n      },\n      onRetry.bind(this)\n    )\n\n    function onRetry (err) {\n      if (err != null || this.aborted || isDisturbed(this.opts.body)) {\n        return this.handler.onError(err)\n      }\n\n      if (this.start !== 0) {\n        this.opts = {\n          ...this.opts,\n          headers: {\n            ...this.opts.headers,\n            range: `bytes=${this.start}-${this.end ?? ''}`\n          }\n        }\n      }\n\n      try {\n        this.dispatch(this.opts, this)\n      } catch (err) {\n        this.handler.onError(err)\n      }\n    }\n  }\n}\n\nmodule.exports = RetryHandler\n","'use strict'\n\nconst RedirectHandler = require('../handler/RedirectHandler')\n\nfunction createRedirectInterceptor ({ maxRedirections: defaultMaxRedirections }) {\n  return (dispatch) => {\n    return function Intercept (opts, handler) {\n      const { maxRedirections = defaultMaxRedirections } = opts\n\n      if (!maxRedirections) {\n        return dispatch(opts, handler)\n      }\n\n      const redirectHandler = new RedirectHandler(dispatch, maxRedirections, opts, handler)\n      opts = { ...opts, maxRedirections: 0 } // Stop sub dispatcher from also redirecting.\n      return dispatch(opts, redirectHandler)\n    }\n  }\n}\n\nmodule.exports = createRedirectInterceptor\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SPECIAL_HEADERS = exports.HEADER_STATE = exports.MINOR = exports.MAJOR = exports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS = exports.TOKEN = exports.STRICT_TOKEN = exports.HEX = exports.URL_CHAR = exports.STRICT_URL_CHAR = exports.USERINFO_CHARS = exports.MARK = exports.ALPHANUM = exports.NUM = exports.HEX_MAP = exports.NUM_MAP = exports.ALPHA = exports.FINISH = exports.H_METHOD_MAP = exports.METHOD_MAP = exports.METHODS_RTSP = exports.METHODS_ICE = exports.METHODS_HTTP = exports.METHODS = exports.LENIENT_FLAGS = exports.FLAGS = exports.TYPE = exports.ERROR = void 0;\nconst utils_1 = require(\"./utils\");\n// C headers\nvar ERROR;\n(function (ERROR) {\n    ERROR[ERROR[\"OK\"] = 0] = \"OK\";\n    ERROR[ERROR[\"INTERNAL\"] = 1] = \"INTERNAL\";\n    ERROR[ERROR[\"STRICT\"] = 2] = \"STRICT\";\n    ERROR[ERROR[\"LF_EXPECTED\"] = 3] = \"LF_EXPECTED\";\n    ERROR[ERROR[\"UNEXPECTED_CONTENT_LENGTH\"] = 4] = \"UNEXPECTED_CONTENT_LENGTH\";\n    ERROR[ERROR[\"CLOSED_CONNECTION\"] = 5] = \"CLOSED_CONNECTION\";\n    ERROR[ERROR[\"INVALID_METHOD\"] = 6] = \"INVALID_METHOD\";\n    ERROR[ERROR[\"INVALID_URL\"] = 7] = \"INVALID_URL\";\n    ERROR[ERROR[\"INVALID_CONSTANT\"] = 8] = \"INVALID_CONSTANT\";\n    ERROR[ERROR[\"INVALID_VERSION\"] = 9] = \"INVALID_VERSION\";\n    ERROR[ERROR[\"INVALID_HEADER_TOKEN\"] = 10] = \"INVALID_HEADER_TOKEN\";\n    ERROR[ERROR[\"INVALID_CONTENT_LENGTH\"] = 11] = \"INVALID_CONTENT_LENGTH\";\n    ERROR[ERROR[\"INVALID_CHUNK_SIZE\"] = 12] = \"INVALID_CHUNK_SIZE\";\n    ERROR[ERROR[\"INVALID_STATUS\"] = 13] = \"INVALID_STATUS\";\n    ERROR[ERROR[\"INVALID_EOF_STATE\"] = 14] = \"INVALID_EOF_STATE\";\n    ERROR[ERROR[\"INVALID_TRANSFER_ENCODING\"] = 15] = \"INVALID_TRANSFER_ENCODING\";\n    ERROR[ERROR[\"CB_MESSAGE_BEGIN\"] = 16] = \"CB_MESSAGE_BEGIN\";\n    ERROR[ERROR[\"CB_HEADERS_COMPLETE\"] = 17] = \"CB_HEADERS_COMPLETE\";\n    ERROR[ERROR[\"CB_MESSAGE_COMPLETE\"] = 18] = \"CB_MESSAGE_COMPLETE\";\n    ERROR[ERROR[\"CB_CHUNK_HEADER\"] = 19] = \"CB_CHUNK_HEADER\";\n    ERROR[ERROR[\"CB_CHUNK_COMPLETE\"] = 20] = \"CB_CHUNK_COMPLETE\";\n    ERROR[ERROR[\"PAUSED\"] = 21] = \"PAUSED\";\n    ERROR[ERROR[\"PAUSED_UPGRADE\"] = 22] = \"PAUSED_UPGRADE\";\n    ERROR[ERROR[\"PAUSED_H2_UPGRADE\"] = 23] = \"PAUSED_H2_UPGRADE\";\n    ERROR[ERROR[\"USER\"] = 24] = \"USER\";\n})(ERROR = exports.ERROR || (exports.ERROR = {}));\nvar TYPE;\n(function (TYPE) {\n    TYPE[TYPE[\"BOTH\"] = 0] = \"BOTH\";\n    TYPE[TYPE[\"REQUEST\"] = 1] = \"REQUEST\";\n    TYPE[TYPE[\"RESPONSE\"] = 2] = \"RESPONSE\";\n})(TYPE = exports.TYPE || (exports.TYPE = {}));\nvar FLAGS;\n(function (FLAGS) {\n    FLAGS[FLAGS[\"CONNECTION_KEEP_ALIVE\"] = 1] = \"CONNECTION_KEEP_ALIVE\";\n    FLAGS[FLAGS[\"CONNECTION_CLOSE\"] = 2] = \"CONNECTION_CLOSE\";\n    FLAGS[FLAGS[\"CONNECTION_UPGRADE\"] = 4] = \"CONNECTION_UPGRADE\";\n    FLAGS[FLAGS[\"CHUNKED\"] = 8] = \"CHUNKED\";\n    FLAGS[FLAGS[\"UPGRADE\"] = 16] = \"UPGRADE\";\n    FLAGS[FLAGS[\"CONTENT_LENGTH\"] = 32] = \"CONTENT_LENGTH\";\n    FLAGS[FLAGS[\"SKIPBODY\"] = 64] = \"SKIPBODY\";\n    FLAGS[FLAGS[\"TRAILING\"] = 128] = \"TRAILING\";\n    // 1 << 8 is unused\n    FLAGS[FLAGS[\"TRANSFER_ENCODING\"] = 512] = \"TRANSFER_ENCODING\";\n})(FLAGS = exports.FLAGS || (exports.FLAGS = {}));\nvar LENIENT_FLAGS;\n(function (LENIENT_FLAGS) {\n    LENIENT_FLAGS[LENIENT_FLAGS[\"HEADERS\"] = 1] = \"HEADERS\";\n    LENIENT_FLAGS[LENIENT_FLAGS[\"CHUNKED_LENGTH\"] = 2] = \"CHUNKED_LENGTH\";\n    LENIENT_FLAGS[LENIENT_FLAGS[\"KEEP_ALIVE\"] = 4] = \"KEEP_ALIVE\";\n})(LENIENT_FLAGS = exports.LENIENT_FLAGS || (exports.LENIENT_FLAGS = {}));\nvar METHODS;\n(function (METHODS) {\n    METHODS[METHODS[\"DELETE\"] = 0] = \"DELETE\";\n    METHODS[METHODS[\"GET\"] = 1] = \"GET\";\n    METHODS[METHODS[\"HEAD\"] = 2] = \"HEAD\";\n    METHODS[METHODS[\"POST\"] = 3] = \"POST\";\n    METHODS[METHODS[\"PUT\"] = 4] = \"PUT\";\n    /* pathological */\n    METHODS[METHODS[\"CONNECT\"] = 5] = \"CONNECT\";\n    METHODS[METHODS[\"OPTIONS\"] = 6] = \"OPTIONS\";\n    METHODS[METHODS[\"TRACE\"] = 7] = \"TRACE\";\n    /* WebDAV */\n    METHODS[METHODS[\"COPY\"] = 8] = \"COPY\";\n    METHODS[METHODS[\"LOCK\"] = 9] = \"LOCK\";\n    METHODS[METHODS[\"MKCOL\"] = 10] = \"MKCOL\";\n    METHODS[METHODS[\"MOVE\"] = 11] = \"MOVE\";\n    METHODS[METHODS[\"PROPFIND\"] = 12] = \"PROPFIND\";\n    METHODS[METHODS[\"PROPPATCH\"] = 13] = \"PROPPATCH\";\n    METHODS[METHODS[\"SEARCH\"] = 14] = \"SEARCH\";\n    METHODS[METHODS[\"UNLOCK\"] = 15] = \"UNLOCK\";\n    METHODS[METHODS[\"BIND\"] = 16] = \"BIND\";\n    METHODS[METHODS[\"REBIND\"] = 17] = \"REBIND\";\n    METHODS[METHODS[\"UNBIND\"] = 18] = \"UNBIND\";\n    METHODS[METHODS[\"ACL\"] = 19] = \"ACL\";\n    /* subversion */\n    METHODS[METHODS[\"REPORT\"] = 20] = \"REPORT\";\n    METHODS[METHODS[\"MKACTIVITY\"] = 21] = \"MKACTIVITY\";\n    METHODS[METHODS[\"CHECKOUT\"] = 22] = \"CHECKOUT\";\n    METHODS[METHODS[\"MERGE\"] = 23] = \"MERGE\";\n    /* upnp */\n    METHODS[METHODS[\"M-SEARCH\"] = 24] = \"M-SEARCH\";\n    METHODS[METHODS[\"NOTIFY\"] = 25] = \"NOTIFY\";\n    METHODS[METHODS[\"SUBSCRIBE\"] = 26] = \"SUBSCRIBE\";\n    METHODS[METHODS[\"UNSUBSCRIBE\"] = 27] = \"UNSUBSCRIBE\";\n    /* RFC-5789 */\n    METHODS[METHODS[\"PATCH\"] = 28] = \"PATCH\";\n    METHODS[METHODS[\"PURGE\"] = 29] = \"PURGE\";\n    /* CalDAV */\n    METHODS[METHODS[\"MKCALENDAR\"] = 30] = \"MKCALENDAR\";\n    /* RFC-2068, section 19.6.1.2 */\n    METHODS[METHODS[\"LINK\"] = 31] = \"LINK\";\n    METHODS[METHODS[\"UNLINK\"] = 32] = \"UNLINK\";\n    /* icecast */\n    METHODS[METHODS[\"SOURCE\"] = 33] = \"SOURCE\";\n    /* RFC-7540, section 11.6 */\n    METHODS[METHODS[\"PRI\"] = 34] = \"PRI\";\n    /* RFC-2326 RTSP */\n    METHODS[METHODS[\"DESCRIBE\"] = 35] = \"DESCRIBE\";\n    METHODS[METHODS[\"ANNOUNCE\"] = 36] = \"ANNOUNCE\";\n    METHODS[METHODS[\"SETUP\"] = 37] = \"SETUP\";\n    METHODS[METHODS[\"PLAY\"] = 38] = \"PLAY\";\n    METHODS[METHODS[\"PAUSE\"] = 39] = \"PAUSE\";\n    METHODS[METHODS[\"TEARDOWN\"] = 40] = \"TEARDOWN\";\n    METHODS[METHODS[\"GET_PARAMETER\"] = 41] = \"GET_PARAMETER\";\n    METHODS[METHODS[\"SET_PARAMETER\"] = 42] = \"SET_PARAMETER\";\n    METHODS[METHODS[\"REDIRECT\"] = 43] = \"REDIRECT\";\n    METHODS[METHODS[\"RECORD\"] = 44] = \"RECORD\";\n    /* RAOP */\n    METHODS[METHODS[\"FLUSH\"] = 45] = \"FLUSH\";\n})(METHODS = exports.METHODS || (exports.METHODS = {}));\nexports.METHODS_HTTP = [\n    METHODS.DELETE,\n    METHODS.GET,\n    METHODS.HEAD,\n    METHODS.POST,\n    METHODS.PUT,\n    METHODS.CONNECT,\n    METHODS.OPTIONS,\n    METHODS.TRACE,\n    METHODS.COPY,\n    METHODS.LOCK,\n    METHODS.MKCOL,\n    METHODS.MOVE,\n    METHODS.PROPFIND,\n    METHODS.PROPPATCH,\n    METHODS.SEARCH,\n    METHODS.UNLOCK,\n    METHODS.BIND,\n    METHODS.REBIND,\n    METHODS.UNBIND,\n    METHODS.ACL,\n    METHODS.REPORT,\n    METHODS.MKACTIVITY,\n    METHODS.CHECKOUT,\n    METHODS.MERGE,\n    METHODS['M-SEARCH'],\n    METHODS.NOTIFY,\n    METHODS.SUBSCRIBE,\n    METHODS.UNSUBSCRIBE,\n    METHODS.PATCH,\n    METHODS.PURGE,\n    METHODS.MKCALENDAR,\n    METHODS.LINK,\n    METHODS.UNLINK,\n    METHODS.PRI,\n    // TODO(indutny): should we allow it with HTTP?\n    METHODS.SOURCE,\n];\nexports.METHODS_ICE = [\n    METHODS.SOURCE,\n];\nexports.METHODS_RTSP = [\n    METHODS.OPTIONS,\n    METHODS.DESCRIBE,\n    METHODS.ANNOUNCE,\n    METHODS.SETUP,\n    METHODS.PLAY,\n    METHODS.PAUSE,\n    METHODS.TEARDOWN,\n    METHODS.GET_PARAMETER,\n    METHODS.SET_PARAMETER,\n    METHODS.REDIRECT,\n    METHODS.RECORD,\n    METHODS.FLUSH,\n    // For AirPlay\n    METHODS.GET,\n    METHODS.POST,\n];\nexports.METHOD_MAP = utils_1.enumToMap(METHODS);\nexports.H_METHOD_MAP = {};\nObject.keys(exports.METHOD_MAP).forEach((key) => {\n    if (/^H/.test(key)) {\n        exports.H_METHOD_MAP[key] = exports.METHOD_MAP[key];\n    }\n});\nvar FINISH;\n(function (FINISH) {\n    FINISH[FINISH[\"SAFE\"] = 0] = \"SAFE\";\n    FINISH[FINISH[\"SAFE_WITH_CB\"] = 1] = \"SAFE_WITH_CB\";\n    FINISH[FINISH[\"UNSAFE\"] = 2] = \"UNSAFE\";\n})(FINISH = exports.FINISH || (exports.FINISH = {}));\nexports.ALPHA = [];\nfor (let i = 'A'.charCodeAt(0); i <= 'Z'.charCodeAt(0); i++) {\n    // Upper case\n    exports.ALPHA.push(String.fromCharCode(i));\n    // Lower case\n    exports.ALPHA.push(String.fromCharCode(i + 0x20));\n}\nexports.NUM_MAP = {\n    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,\n    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,\n};\nexports.HEX_MAP = {\n    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,\n    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,\n    A: 0XA, B: 0XB, C: 0XC, D: 0XD, E: 0XE, F: 0XF,\n    a: 0xa, b: 0xb, c: 0xc, d: 0xd, e: 0xe, f: 0xf,\n};\nexports.NUM = [\n    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n];\nexports.ALPHANUM = exports.ALPHA.concat(exports.NUM);\nexports.MARK = ['-', '_', '.', '!', '~', '*', '\\'', '(', ')'];\nexports.USERINFO_CHARS = exports.ALPHANUM\n    .concat(exports.MARK)\n    .concat(['%', ';', ':', '&', '=', '+', '$', ',']);\n// TODO(indutny): use RFC\nexports.STRICT_URL_CHAR = [\n    '!', '\"', '$', '%', '&', '\\'',\n    '(', ')', '*', '+', ',', '-', '.', '/',\n    ':', ';', '<', '=', '>',\n    '@', '[', '\\\\', ']', '^', '_',\n    '`',\n    '{', '|', '}', '~',\n].concat(exports.ALPHANUM);\nexports.URL_CHAR = exports.STRICT_URL_CHAR\n    .concat(['\\t', '\\f']);\n// All characters with 0x80 bit set to 1\nfor (let i = 0x80; i <= 0xff; i++) {\n    exports.URL_CHAR.push(i);\n}\nexports.HEX = exports.NUM.concat(['a', 'b', 'c', 'd', 'e', 'f', 'A', 'B', 'C', 'D', 'E', 'F']);\n/* Tokens as defined by rfc 2616. Also lowercases them.\n *        token       = 1*<any CHAR except CTLs or separators>\n *     separators     = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n *                    | \",\" | \";\" | \":\" | \"\\\" | <\">\n *                    | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n *                    | \"{\" | \"}\" | SP | HT\n */\nexports.STRICT_TOKEN = [\n    '!', '#', '$', '%', '&', '\\'',\n    '*', '+', '-', '.',\n    '^', '_', '`',\n    '|', '~',\n].concat(exports.ALPHANUM);\nexports.TOKEN = exports.STRICT_TOKEN.concat([' ']);\n/*\n * Verify that a char is a valid visible (printable) US-ASCII\n * character or %x80-FF\n */\nexports.HEADER_CHARS = ['\\t'];\nfor (let i = 32; i <= 255; i++) {\n    if (i !== 127) {\n        exports.HEADER_CHARS.push(i);\n    }\n}\n// ',' = \\x44\nexports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS.filter((c) => c !== 44);\nexports.MAJOR = exports.NUM_MAP;\nexports.MINOR = exports.MAJOR;\nvar HEADER_STATE;\n(function (HEADER_STATE) {\n    HEADER_STATE[HEADER_STATE[\"GENERAL\"] = 0] = \"GENERAL\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION\"] = 1] = \"CONNECTION\";\n    HEADER_STATE[HEADER_STATE[\"CONTENT_LENGTH\"] = 2] = \"CONTENT_LENGTH\";\n    HEADER_STATE[HEADER_STATE[\"TRANSFER_ENCODING\"] = 3] = \"TRANSFER_ENCODING\";\n    HEADER_STATE[HEADER_STATE[\"UPGRADE\"] = 4] = \"UPGRADE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_KEEP_ALIVE\"] = 5] = \"CONNECTION_KEEP_ALIVE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_CLOSE\"] = 6] = \"CONNECTION_CLOSE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_UPGRADE\"] = 7] = \"CONNECTION_UPGRADE\";\n    HEADER_STATE[HEADER_STATE[\"TRANSFER_ENCODING_CHUNKED\"] = 8] = \"TRANSFER_ENCODING_CHUNKED\";\n})(HEADER_STATE = exports.HEADER_STATE || (exports.HEADER_STATE = {}));\nexports.SPECIAL_HEADERS = {\n    'connection': HEADER_STATE.CONNECTION,\n    'content-length': HEADER_STATE.CONTENT_LENGTH,\n    'proxy-connection': HEADER_STATE.CONNECTION,\n    'transfer-encoding': HEADER_STATE.TRANSFER_ENCODING,\n    'upgrade': HEADER_STATE.UPGRADE,\n};\n//# sourceMappingURL=constants.js.map","module.exports = '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'\n","module.exports = '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'\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.enumToMap = void 0;\nfunction enumToMap(obj) {\n    const res = {};\n    Object.keys(obj).forEach((key) => {\n        const value = obj[key];\n        if (typeof value === 'number') {\n            res[key] = value;\n        }\n    });\n    return res;\n}\nexports.enumToMap = enumToMap;\n//# sourceMappingURL=utils.js.map","'use strict'\n\nconst { kClients } = require('../core/symbols')\nconst Agent = require('../agent')\nconst {\n  kAgent,\n  kMockAgentSet,\n  kMockAgentGet,\n  kDispatches,\n  kIsMockActive,\n  kNetConnect,\n  kGetNetConnect,\n  kOptions,\n  kFactory\n} = require('./mock-symbols')\nconst MockClient = require('./mock-client')\nconst MockPool = require('./mock-pool')\nconst { matchValue, buildMockOptions } = require('./mock-utils')\nconst { InvalidArgumentError, UndiciError } = require('../core/errors')\nconst Dispatcher = require('../dispatcher')\nconst Pluralizer = require('./pluralizer')\nconst PendingInterceptorsFormatter = require('./pending-interceptors-formatter')\n\nclass FakeWeakRef {\n  constructor (value) {\n    this.value = value\n  }\n\n  deref () {\n    return this.value\n  }\n}\n\nclass MockAgent extends Dispatcher {\n  constructor (opts) {\n    super(opts)\n\n    this[kNetConnect] = true\n    this[kIsMockActive] = true\n\n    // Instantiate Agent and encapsulate\n    if ((opts && opts.agent && typeof opts.agent.dispatch !== 'function')) {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n    const agent = opts && opts.agent ? opts.agent : new Agent(opts)\n    this[kAgent] = agent\n\n    this[kClients] = agent[kClients]\n    this[kOptions] = buildMockOptions(opts)\n  }\n\n  get (origin) {\n    let dispatcher = this[kMockAgentGet](origin)\n\n    if (!dispatcher) {\n      dispatcher = this[kFactory](origin)\n      this[kMockAgentSet](origin, dispatcher)\n    }\n    return dispatcher\n  }\n\n  dispatch (opts, handler) {\n    // Call MockAgent.get to perform additional setup before dispatching as normal\n    this.get(opts.origin)\n    return this[kAgent].dispatch(opts, handler)\n  }\n\n  async close () {\n    await this[kAgent].close()\n    this[kClients].clear()\n  }\n\n  deactivate () {\n    this[kIsMockActive] = false\n  }\n\n  activate () {\n    this[kIsMockActive] = true\n  }\n\n  enableNetConnect (matcher) {\n    if (typeof matcher === 'string' || typeof matcher === 'function' || matcher instanceof RegExp) {\n      if (Array.isArray(this[kNetConnect])) {\n        this[kNetConnect].push(matcher)\n      } else {\n        this[kNetConnect] = [matcher]\n      }\n    } else if (typeof matcher === 'undefined') {\n      this[kNetConnect] = true\n    } else {\n      throw new InvalidArgumentError('Unsupported matcher. Must be one of String|Function|RegExp.')\n    }\n  }\n\n  disableNetConnect () {\n    this[kNetConnect] = false\n  }\n\n  // This is required to bypass issues caused by using global symbols - see:\n  // https://github.com/nodejs/undici/issues/1447\n  get isMockActive () {\n    return this[kIsMockActive]\n  }\n\n  [kMockAgentSet] (origin, dispatcher) {\n    this[kClients].set(origin, new FakeWeakRef(dispatcher))\n  }\n\n  [kFactory] (origin) {\n    const mockOptions = Object.assign({ agent: this }, this[kOptions])\n    return this[kOptions] && this[kOptions].connections === 1\n      ? new MockClient(origin, mockOptions)\n      : new MockPool(origin, mockOptions)\n  }\n\n  [kMockAgentGet] (origin) {\n    // First check if we can immediately find it\n    const ref = this[kClients].get(origin)\n    if (ref) {\n      return ref.deref()\n    }\n\n    // If the origin is not a string create a dummy parent pool and return to user\n    if (typeof origin !== 'string') {\n      const dispatcher = this[kFactory]('http://localhost:9999')\n      this[kMockAgentSet](origin, dispatcher)\n      return dispatcher\n    }\n\n    // If we match, create a pool and assign the same dispatches\n    for (const [keyMatcher, nonExplicitRef] of Array.from(this[kClients])) {\n      const nonExplicitDispatcher = nonExplicitRef.deref()\n      if (nonExplicitDispatcher && typeof keyMatcher !== 'string' && matchValue(keyMatcher, origin)) {\n        const dispatcher = this[kFactory](origin)\n        this[kMockAgentSet](origin, dispatcher)\n        dispatcher[kDispatches] = nonExplicitDispatcher[kDispatches]\n        return dispatcher\n      }\n    }\n  }\n\n  [kGetNetConnect] () {\n    return this[kNetConnect]\n  }\n\n  pendingInterceptors () {\n    const mockAgentClients = this[kClients]\n\n    return Array.from(mockAgentClients.entries())\n      .flatMap(([origin, scope]) => scope.deref()[kDispatches].map(dispatch => ({ ...dispatch, origin })))\n      .filter(({ pending }) => pending)\n  }\n\n  assertNoPendingInterceptors ({ pendingInterceptorsFormatter = new PendingInterceptorsFormatter() } = {}) {\n    const pending = this.pendingInterceptors()\n\n    if (pending.length === 0) {\n      return\n    }\n\n    const pluralizer = new Pluralizer('interceptor', 'interceptors').pluralize(pending.length)\n\n    throw new UndiciError(`\n${pluralizer.count} ${pluralizer.noun} ${pluralizer.is} pending:\n\n${pendingInterceptorsFormatter.format(pending)}\n`.trim())\n  }\n}\n\nmodule.exports = MockAgent\n","'use strict'\n\nconst { promisify } = require('util')\nconst Client = require('../client')\nconst { buildMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kMockAgent,\n  kClose,\n  kOriginalClose,\n  kOrigin,\n  kOriginalDispatch,\n  kConnected\n} = require('./mock-symbols')\nconst { MockInterceptor } = require('./mock-interceptor')\nconst Symbols = require('../core/symbols')\nconst { InvalidArgumentError } = require('../core/errors')\n\n/**\n * MockClient provides an API that extends the Client to influence the mockDispatches.\n */\nclass MockClient extends Client {\n  constructor (origin, opts) {\n    super(origin, opts)\n\n    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n\n    this[kMockAgent] = opts.agent\n    this[kOrigin] = origin\n    this[kDispatches] = []\n    this[kConnected] = 1\n    this[kOriginalDispatch] = this.dispatch\n    this[kOriginalClose] = this.close.bind(this)\n\n    this.dispatch = buildMockDispatch.call(this)\n    this.close = this[kClose]\n  }\n\n  get [Symbols.kConnected] () {\n    return this[kConnected]\n  }\n\n  /**\n   * Sets up the base interceptor for mocking replies from undici.\n   */\n  intercept (opts) {\n    return new MockInterceptor(opts, this[kDispatches])\n  }\n\n  async [kClose] () {\n    await promisify(this[kOriginalClose])()\n    this[kConnected] = 0\n    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])\n  }\n}\n\nmodule.exports = MockClient\n","'use strict'\n\nconst { UndiciError } = require('../core/errors')\n\nclass MockNotMatchedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, MockNotMatchedError)\n    this.name = 'MockNotMatchedError'\n    this.message = message || 'The request does not match any registered mock dispatches'\n    this.code = 'UND_MOCK_ERR_MOCK_NOT_MATCHED'\n  }\n}\n\nmodule.exports = {\n  MockNotMatchedError\n}\n","'use strict'\n\nconst { getResponseData, buildKey, addMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kDispatchKey,\n  kDefaultHeaders,\n  kDefaultTrailers,\n  kContentLength,\n  kMockDispatch\n} = require('./mock-symbols')\nconst { InvalidArgumentError } = require('../core/errors')\nconst { buildURL } = require('../core/util')\n\n/**\n * Defines the scope API for an interceptor reply\n */\nclass MockScope {\n  constructor (mockDispatch) {\n    this[kMockDispatch] = mockDispatch\n  }\n\n  /**\n   * Delay a reply by a set amount in ms.\n   */\n  delay (waitInMs) {\n    if (typeof waitInMs !== 'number' || !Number.isInteger(waitInMs) || waitInMs <= 0) {\n      throw new InvalidArgumentError('waitInMs must be a valid integer > 0')\n    }\n\n    this[kMockDispatch].delay = waitInMs\n    return this\n  }\n\n  /**\n   * For a defined reply, never mark as consumed.\n   */\n  persist () {\n    this[kMockDispatch].persist = true\n    return this\n  }\n\n  /**\n   * Allow one to define a reply for a set amount of matching requests.\n   */\n  times (repeatTimes) {\n    if (typeof repeatTimes !== 'number' || !Number.isInteger(repeatTimes) || repeatTimes <= 0) {\n      throw new InvalidArgumentError('repeatTimes must be a valid integer > 0')\n    }\n\n    this[kMockDispatch].times = repeatTimes\n    return this\n  }\n}\n\n/**\n * Defines an interceptor for a Mock\n */\nclass MockInterceptor {\n  constructor (opts, mockDispatches) {\n    if (typeof opts !== 'object') {\n      throw new InvalidArgumentError('opts must be an object')\n    }\n    if (typeof opts.path === 'undefined') {\n      throw new InvalidArgumentError('opts.path must be defined')\n    }\n    if (typeof opts.method === 'undefined') {\n      opts.method = 'GET'\n    }\n    // See https://github.com/nodejs/undici/issues/1245\n    // As per RFC 3986, clients are not supposed to send URI\n    // fragments to servers when they retrieve a document,\n    if (typeof opts.path === 'string') {\n      if (opts.query) {\n        opts.path = buildURL(opts.path, opts.query)\n      } else {\n        // Matches https://github.com/nodejs/undici/blob/main/lib/fetch/index.js#L1811\n        const parsedURL = new URL(opts.path, 'data://')\n        opts.path = parsedURL.pathname + parsedURL.search\n      }\n    }\n    if (typeof opts.method === 'string') {\n      opts.method = opts.method.toUpperCase()\n    }\n\n    this[kDispatchKey] = buildKey(opts)\n    this[kDispatches] = mockDispatches\n    this[kDefaultHeaders] = {}\n    this[kDefaultTrailers] = {}\n    this[kContentLength] = false\n  }\n\n  createMockScopeDispatchData (statusCode, data, responseOptions = {}) {\n    const responseData = getResponseData(data)\n    const contentLength = this[kContentLength] ? { 'content-length': responseData.length } : {}\n    const headers = { ...this[kDefaultHeaders], ...contentLength, ...responseOptions.headers }\n    const trailers = { ...this[kDefaultTrailers], ...responseOptions.trailers }\n\n    return { statusCode, data, headers, trailers }\n  }\n\n  validateReplyParameters (statusCode, data, responseOptions) {\n    if (typeof statusCode === 'undefined') {\n      throw new InvalidArgumentError('statusCode must be defined')\n    }\n    if (typeof data === 'undefined') {\n      throw new InvalidArgumentError('data must be defined')\n    }\n    if (typeof responseOptions !== 'object') {\n      throw new InvalidArgumentError('responseOptions must be an object')\n    }\n  }\n\n  /**\n   * Mock an undici request with a defined reply.\n   */\n  reply (replyData) {\n    // Values of reply aren't available right now as they\n    // can only be available when the reply callback is invoked.\n    if (typeof replyData === 'function') {\n      // We'll first wrap the provided callback in another function,\n      // this function will properly resolve the data from the callback\n      // when invoked.\n      const wrappedDefaultsCallback = (opts) => {\n        // Our reply options callback contains the parameter for statusCode, data and options.\n        const resolvedData = replyData(opts)\n\n        // Check if it is in the right format\n        if (typeof resolvedData !== 'object') {\n          throw new InvalidArgumentError('reply options callback must return an object')\n        }\n\n        const { statusCode, data = '', responseOptions = {} } = resolvedData\n        this.validateReplyParameters(statusCode, data, responseOptions)\n        // Since the values can be obtained immediately we return them\n        // from this higher order function that will be resolved later.\n        return {\n          ...this.createMockScopeDispatchData(statusCode, data, responseOptions)\n        }\n      }\n\n      // Add usual dispatch data, but this time set the data parameter to function that will eventually provide data.\n      const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], wrappedDefaultsCallback)\n      return new MockScope(newMockDispatch)\n    }\n\n    // We can have either one or three parameters, if we get here,\n    // we should have 1-3 parameters. So we spread the arguments of\n    // this function to obtain the parameters, since replyData will always\n    // just be the statusCode.\n    const [statusCode, data = '', responseOptions = {}] = [...arguments]\n    this.validateReplyParameters(statusCode, data, responseOptions)\n\n    // Send in-already provided data like usual\n    const dispatchData = this.createMockScopeDispatchData(statusCode, data, responseOptions)\n    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], dispatchData)\n    return new MockScope(newMockDispatch)\n  }\n\n  /**\n   * Mock an undici request with a defined error.\n   */\n  replyWithError (error) {\n    if (typeof error === 'undefined') {\n      throw new InvalidArgumentError('error must be defined')\n    }\n\n    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], { error })\n    return new MockScope(newMockDispatch)\n  }\n\n  /**\n   * Set default reply headers on the interceptor for subsequent replies\n   */\n  defaultReplyHeaders (headers) {\n    if (typeof headers === 'undefined') {\n      throw new InvalidArgumentError('headers must be defined')\n    }\n\n    this[kDefaultHeaders] = headers\n    return this\n  }\n\n  /**\n   * Set default reply trailers on the interceptor for subsequent replies\n   */\n  defaultReplyTrailers (trailers) {\n    if (typeof trailers === 'undefined') {\n      throw new InvalidArgumentError('trailers must be defined')\n    }\n\n    this[kDefaultTrailers] = trailers\n    return this\n  }\n\n  /**\n   * Set reply content length header for replies on the interceptor\n   */\n  replyContentLength () {\n    this[kContentLength] = true\n    return this\n  }\n}\n\nmodule.exports.MockInterceptor = MockInterceptor\nmodule.exports.MockScope = MockScope\n","'use strict'\n\nconst { promisify } = require('util')\nconst Pool = require('../pool')\nconst { buildMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kMockAgent,\n  kClose,\n  kOriginalClose,\n  kOrigin,\n  kOriginalDispatch,\n  kConnected\n} = require('./mock-symbols')\nconst { MockInterceptor } = require('./mock-interceptor')\nconst Symbols = require('../core/symbols')\nconst { InvalidArgumentError } = require('../core/errors')\n\n/**\n * MockPool provides an API that extends the Pool to influence the mockDispatches.\n */\nclass MockPool extends Pool {\n  constructor (origin, opts) {\n    super(origin, opts)\n\n    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n\n    this[kMockAgent] = opts.agent\n    this[kOrigin] = origin\n    this[kDispatches] = []\n    this[kConnected] = 1\n    this[kOriginalDispatch] = this.dispatch\n    this[kOriginalClose] = this.close.bind(this)\n\n    this.dispatch = buildMockDispatch.call(this)\n    this.close = this[kClose]\n  }\n\n  get [Symbols.kConnected] () {\n    return this[kConnected]\n  }\n\n  /**\n   * Sets up the base interceptor for mocking replies from undici.\n   */\n  intercept (opts) {\n    return new MockInterceptor(opts, this[kDispatches])\n  }\n\n  async [kClose] () {\n    await promisify(this[kOriginalClose])()\n    this[kConnected] = 0\n    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])\n  }\n}\n\nmodule.exports = MockPool\n","'use strict'\n\nmodule.exports = {\n  kAgent: Symbol('agent'),\n  kOptions: Symbol('options'),\n  kFactory: Symbol('factory'),\n  kDispatches: Symbol('dispatches'),\n  kDispatchKey: Symbol('dispatch key'),\n  kDefaultHeaders: Symbol('default headers'),\n  kDefaultTrailers: Symbol('default trailers'),\n  kContentLength: Symbol('content length'),\n  kMockAgent: Symbol('mock agent'),\n  kMockAgentSet: Symbol('mock agent set'),\n  kMockAgentGet: Symbol('mock agent get'),\n  kMockDispatch: Symbol('mock dispatch'),\n  kClose: Symbol('close'),\n  kOriginalClose: Symbol('original agent close'),\n  kOrigin: Symbol('origin'),\n  kIsMockActive: Symbol('is mock active'),\n  kNetConnect: Symbol('net connect'),\n  kGetNetConnect: Symbol('get net connect'),\n  kConnected: Symbol('connected')\n}\n","'use strict'\n\nconst { MockNotMatchedError } = require('./mock-errors')\nconst {\n  kDispatches,\n  kMockAgent,\n  kOriginalDispatch,\n  kOrigin,\n  kGetNetConnect\n} = require('./mock-symbols')\nconst { buildURL, nop } = require('../core/util')\nconst { STATUS_CODES } = require('http')\nconst {\n  types: {\n    isPromise\n  }\n} = require('util')\n\nfunction matchValue (match, value) {\n  if (typeof match === 'string') {\n    return match === value\n  }\n  if (match instanceof RegExp) {\n    return match.test(value)\n  }\n  if (typeof match === 'function') {\n    return match(value) === true\n  }\n  return false\n}\n\nfunction lowerCaseEntries (headers) {\n  return Object.fromEntries(\n    Object.entries(headers).map(([headerName, headerValue]) => {\n      return [headerName.toLocaleLowerCase(), headerValue]\n    })\n  )\n}\n\n/**\n * @param {import('../../index').Headers|string[]|Record<string, string>} headers\n * @param {string} key\n */\nfunction getHeaderByName (headers, key) {\n  if (Array.isArray(headers)) {\n    for (let i = 0; i < headers.length; i += 2) {\n      if (headers[i].toLocaleLowerCase() === key.toLocaleLowerCase()) {\n        return headers[i + 1]\n      }\n    }\n\n    return undefined\n  } else if (typeof headers.get === 'function') {\n    return headers.get(key)\n  } else {\n    return lowerCaseEntries(headers)[key.toLocaleLowerCase()]\n  }\n}\n\n/** @param {string[]} headers */\nfunction buildHeadersFromArray (headers) { // fetch HeadersList\n  const clone = headers.slice()\n  const entries = []\n  for (let index = 0; index < clone.length; index += 2) {\n    entries.push([clone[index], clone[index + 1]])\n  }\n  return Object.fromEntries(entries)\n}\n\nfunction matchHeaders (mockDispatch, headers) {\n  if (typeof mockDispatch.headers === 'function') {\n    if (Array.isArray(headers)) { // fetch HeadersList\n      headers = buildHeadersFromArray(headers)\n    }\n    return mockDispatch.headers(headers ? lowerCaseEntries(headers) : {})\n  }\n  if (typeof mockDispatch.headers === 'undefined') {\n    return true\n  }\n  if (typeof headers !== 'object' || typeof mockDispatch.headers !== 'object') {\n    return false\n  }\n\n  for (const [matchHeaderName, matchHeaderValue] of Object.entries(mockDispatch.headers)) {\n    const headerValue = getHeaderByName(headers, matchHeaderName)\n\n    if (!matchValue(matchHeaderValue, headerValue)) {\n      return false\n    }\n  }\n  return true\n}\n\nfunction safeUrl (path) {\n  if (typeof path !== 'string') {\n    return path\n  }\n\n  const pathSegments = path.split('?')\n\n  if (pathSegments.length !== 2) {\n    return path\n  }\n\n  const qp = new URLSearchParams(pathSegments.pop())\n  qp.sort()\n  return [...pathSegments, qp.toString()].join('?')\n}\n\nfunction matchKey (mockDispatch, { path, method, body, headers }) {\n  const pathMatch = matchValue(mockDispatch.path, path)\n  const methodMatch = matchValue(mockDispatch.method, method)\n  const bodyMatch = typeof mockDispatch.body !== 'undefined' ? matchValue(mockDispatch.body, body) : true\n  const headersMatch = matchHeaders(mockDispatch, headers)\n  return pathMatch && methodMatch && bodyMatch && headersMatch\n}\n\nfunction getResponseData (data) {\n  if (Buffer.isBuffer(data)) {\n    return data\n  } else if (typeof data === 'object') {\n    return JSON.stringify(data)\n  } else {\n    return data.toString()\n  }\n}\n\nfunction getMockDispatch (mockDispatches, key) {\n  const basePath = key.query ? buildURL(key.path, key.query) : key.path\n  const resolvedPath = typeof basePath === 'string' ? safeUrl(basePath) : basePath\n\n  // Match path\n  let matchedMockDispatches = mockDispatches.filter(({ consumed }) => !consumed).filter(({ path }) => matchValue(safeUrl(path), resolvedPath))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for path '${resolvedPath}'`)\n  }\n\n  // Match method\n  matchedMockDispatches = matchedMockDispatches.filter(({ method }) => matchValue(method, key.method))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for method '${key.method}'`)\n  }\n\n  // Match body\n  matchedMockDispatches = matchedMockDispatches.filter(({ body }) => typeof body !== 'undefined' ? matchValue(body, key.body) : true)\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for body '${key.body}'`)\n  }\n\n  // Match headers\n  matchedMockDispatches = matchedMockDispatches.filter((mockDispatch) => matchHeaders(mockDispatch, key.headers))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for headers '${typeof key.headers === 'object' ? JSON.stringify(key.headers) : key.headers}'`)\n  }\n\n  return matchedMockDispatches[0]\n}\n\nfunction addMockDispatch (mockDispatches, key, data) {\n  const baseData = { timesInvoked: 0, times: 1, persist: false, consumed: false }\n  const replyData = typeof data === 'function' ? { callback: data } : { ...data }\n  const newMockDispatch = { ...baseData, ...key, pending: true, data: { error: null, ...replyData } }\n  mockDispatches.push(newMockDispatch)\n  return newMockDispatch\n}\n\nfunction deleteMockDispatch (mockDispatches, key) {\n  const index = mockDispatches.findIndex(dispatch => {\n    if (!dispatch.consumed) {\n      return false\n    }\n    return matchKey(dispatch, key)\n  })\n  if (index !== -1) {\n    mockDispatches.splice(index, 1)\n  }\n}\n\nfunction buildKey (opts) {\n  const { path, method, body, headers, query } = opts\n  return {\n    path,\n    method,\n    body,\n    headers,\n    query\n  }\n}\n\nfunction generateKeyValues (data) {\n  return Object.entries(data).reduce((keyValuePairs, [key, value]) => [\n    ...keyValuePairs,\n    Buffer.from(`${key}`),\n    Array.isArray(value) ? value.map(x => Buffer.from(`${x}`)) : Buffer.from(`${value}`)\n  ], [])\n}\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\n * @param {number} statusCode\n */\nfunction getStatusText (statusCode) {\n  return STATUS_CODES[statusCode] || 'unknown'\n}\n\nasync function getResponse (body) {\n  const buffers = []\n  for await (const data of body) {\n    buffers.push(data)\n  }\n  return Buffer.concat(buffers).toString('utf8')\n}\n\n/**\n * Mock dispatch function used to simulate undici dispatches\n */\nfunction mockDispatch (opts, handler) {\n  // Get mock dispatch from built key\n  const key = buildKey(opts)\n  const mockDispatch = getMockDispatch(this[kDispatches], key)\n\n  mockDispatch.timesInvoked++\n\n  // Here's where we resolve a callback if a callback is present for the dispatch data.\n  if (mockDispatch.data.callback) {\n    mockDispatch.data = { ...mockDispatch.data, ...mockDispatch.data.callback(opts) }\n  }\n\n  // Parse mockDispatch data\n  const { data: { statusCode, data, headers, trailers, error }, delay, persist } = mockDispatch\n  const { timesInvoked, times } = mockDispatch\n\n  // If it's used up and not persistent, mark as consumed\n  mockDispatch.consumed = !persist && timesInvoked >= times\n  mockDispatch.pending = timesInvoked < times\n\n  // If specified, trigger dispatch error\n  if (error !== null) {\n    deleteMockDispatch(this[kDispatches], key)\n    handler.onError(error)\n    return true\n  }\n\n  // Handle the request with a delay if necessary\n  if (typeof delay === 'number' && delay > 0) {\n    setTimeout(() => {\n      handleReply(this[kDispatches])\n    }, delay)\n  } else {\n    handleReply(this[kDispatches])\n  }\n\n  function handleReply (mockDispatches, _data = data) {\n    // fetch's HeadersList is a 1D string array\n    const optsHeaders = Array.isArray(opts.headers)\n      ? buildHeadersFromArray(opts.headers)\n      : opts.headers\n    const body = typeof _data === 'function'\n      ? _data({ ...opts, headers: optsHeaders })\n      : _data\n\n    // util.types.isPromise is likely needed for jest.\n    if (isPromise(body)) {\n      // If handleReply is asynchronous, throwing an error\n      // in the callback will reject the promise, rather than\n      // synchronously throw the error, which breaks some tests.\n      // Rather, we wait for the callback to resolve if it is a\n      // promise, and then re-run handleReply with the new body.\n      body.then((newData) => handleReply(mockDispatches, newData))\n      return\n    }\n\n    const responseData = getResponseData(body)\n    const responseHeaders = generateKeyValues(headers)\n    const responseTrailers = generateKeyValues(trailers)\n\n    handler.abort = nop\n    handler.onHeaders(statusCode, responseHeaders, resume, getStatusText(statusCode))\n    handler.onData(Buffer.from(responseData))\n    handler.onComplete(responseTrailers)\n    deleteMockDispatch(mockDispatches, key)\n  }\n\n  function resume () {}\n\n  return true\n}\n\nfunction buildMockDispatch () {\n  const agent = this[kMockAgent]\n  const origin = this[kOrigin]\n  const originalDispatch = this[kOriginalDispatch]\n\n  return function dispatch (opts, handler) {\n    if (agent.isMockActive) {\n      try {\n        mockDispatch.call(this, opts, handler)\n      } catch (error) {\n        if (error instanceof MockNotMatchedError) {\n          const netConnect = agent[kGetNetConnect]()\n          if (netConnect === false) {\n            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect disabled)`)\n          }\n          if (checkNetConnect(netConnect, origin)) {\n            originalDispatch.call(this, opts, handler)\n          } else {\n            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect is not enabled for this origin)`)\n          }\n        } else {\n          throw error\n        }\n      }\n    } else {\n      originalDispatch.call(this, opts, handler)\n    }\n  }\n}\n\nfunction checkNetConnect (netConnect, origin) {\n  const url = new URL(origin)\n  if (netConnect === true) {\n    return true\n  } else if (Array.isArray(netConnect) && netConnect.some((matcher) => matchValue(matcher, url.host))) {\n    return true\n  }\n  return false\n}\n\nfunction buildMockOptions (opts) {\n  if (opts) {\n    const { agent, ...mockOptions } = opts\n    return mockOptions\n  }\n}\n\nmodule.exports = {\n  getResponseData,\n  getMockDispatch,\n  addMockDispatch,\n  deleteMockDispatch,\n  buildKey,\n  generateKeyValues,\n  matchValue,\n  getResponse,\n  getStatusText,\n  mockDispatch,\n  buildMockDispatch,\n  checkNetConnect,\n  buildMockOptions,\n  getHeaderByName\n}\n","'use strict'\n\nconst { Transform } = require('stream')\nconst { Console } = require('console')\n\n/**\n * Gets the output of `console.table()` as a string.\n */\nmodule.exports = class PendingInterceptorsFormatter {\n  constructor ({ disableColors } = {}) {\n    this.transform = new Transform({\n      transform (chunk, _enc, cb) {\n        cb(null, chunk)\n      }\n    })\n\n    this.logger = new Console({\n      stdout: this.transform,\n      inspectOptions: {\n        colors: !disableColors && !process.env.CI\n      }\n    })\n  }\n\n  format (pendingInterceptors) {\n    const withPrettyHeaders = pendingInterceptors.map(\n      ({ method, path, data: { statusCode }, persist, times, timesInvoked, origin }) => ({\n        Method: method,\n        Origin: origin,\n        Path: path,\n        'Status code': statusCode,\n        Persistent: persist ? '' : '',\n        Invocations: timesInvoked,\n        Remaining: persist ? Infinity : times - timesInvoked\n      }))\n\n    this.logger.table(withPrettyHeaders)\n    return this.transform.read().toString()\n  }\n}\n","'use strict'\n\nconst singulars = {\n  pronoun: 'it',\n  is: 'is',\n  was: 'was',\n  this: 'this'\n}\n\nconst plurals = {\n  pronoun: 'they',\n  is: 'are',\n  was: 'were',\n  this: 'these'\n}\n\nmodule.exports = class Pluralizer {\n  constructor (singular, plural) {\n    this.singular = singular\n    this.plural = plural\n  }\n\n  pluralize (count) {\n    const one = count === 1\n    const keys = one ? singulars : plurals\n    const noun = one ? this.singular : this.plural\n    return { ...keys, count, noun }\n  }\n}\n","/* eslint-disable */\n\n'use strict'\n\n// Extracted from node/lib/internal/fixed_queue.js\n\n// Currently optimal queue size, tested on V8 6.0 - 6.6. Must be power of two.\nconst kSize = 2048;\nconst kMask = kSize - 1;\n\n// The FixedQueue is implemented as a singly-linked list of fixed-size\n// circular buffers. It looks something like this:\n//\n//  head                                                       tail\n//    |                                                          |\n//    v                                                          v\n// +-----------+ <-----\\       +-----------+ <------\\         +-----------+\n// |  [null]   |        \\----- |   next    |         \\------- |   next    |\n// +-----------+               +-----------+                  +-----------+\n// |   item    | <-- bottom    |   item    | <-- bottom       |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |       bottom --> |   item    |\n// |   item    |               |   item    |                  |   item    |\n// |    ...    |               |    ...    |                  |    ...    |\n// |   item    |               |   item    |                  |   item    |\n// |   item    |               |   item    |                  |   item    |\n// |  [empty]  | <-- top       |   item    |                  |   item    |\n// |  [empty]  |               |   item    |                  |   item    |\n// |  [empty]  |               |  [empty]  | <-- top  top --> |  [empty]  |\n// +-----------+               +-----------+                  +-----------+\n//\n// Or, if there is only one circular buffer, it looks something\n// like either of these:\n//\n//  head   tail                                 head   tail\n//    |     |                                     |     |\n//    v     v                                     v     v\n// +-----------+                               +-----------+\n// |  [null]   |                               |  [null]   |\n// +-----------+                               +-----------+\n// |  [empty]  |                               |   item    |\n// |  [empty]  |                               |   item    |\n// |   item    | <-- bottom            top --> |  [empty]  |\n// |   item    |                               |  [empty]  |\n// |  [empty]  | <-- top            bottom --> |   item    |\n// |  [empty]  |                               |   item    |\n// +-----------+                               +-----------+\n//\n// Adding a value means moving `top` forward by one, removing means\n// moving `bottom` forward by one. After reaching the end, the queue\n// wraps around.\n//\n// When `top === bottom` the current queue is empty and when\n// `top + 1 === bottom` it's full. This wastes a single space of storage\n// but allows much quicker checks.\n\nclass FixedCircularBuffer {\n  constructor() {\n    this.bottom = 0;\n    this.top = 0;\n    this.list = new Array(kSize);\n    this.next = null;\n  }\n\n  isEmpty() {\n    return this.top === this.bottom;\n  }\n\n  isFull() {\n    return ((this.top + 1) & kMask) === this.bottom;\n  }\n\n  push(data) {\n    this.list[this.top] = data;\n    this.top = (this.top + 1) & kMask;\n  }\n\n  shift() {\n    const nextItem = this.list[this.bottom];\n    if (nextItem === undefined)\n      return null;\n    this.list[this.bottom] = undefined;\n    this.bottom = (this.bottom + 1) & kMask;\n    return nextItem;\n  }\n}\n\nmodule.exports = class FixedQueue {\n  constructor() {\n    this.head = this.tail = new FixedCircularBuffer();\n  }\n\n  isEmpty() {\n    return this.head.isEmpty();\n  }\n\n  push(data) {\n    if (this.head.isFull()) {\n      // Head is full: Creates a new queue, sets the old queue's `.next` to it,\n      // and sets it as the new main queue.\n      this.head = this.head.next = new FixedCircularBuffer();\n    }\n    this.head.push(data);\n  }\n\n  shift() {\n    const tail = this.tail;\n    const next = tail.shift();\n    if (tail.isEmpty() && tail.next !== null) {\n      // If there is another queue, it forms the new tail.\n      this.tail = tail.next;\n    }\n    return next;\n  }\n};\n","'use strict'\n\nconst DispatcherBase = require('./dispatcher-base')\nconst FixedQueue = require('./node/fixed-queue')\nconst { kConnected, kSize, kRunning, kPending, kQueued, kBusy, kFree, kUrl, kClose, kDestroy, kDispatch } = require('./core/symbols')\nconst PoolStats = require('./pool-stats')\n\nconst kClients = Symbol('clients')\nconst kNeedDrain = Symbol('needDrain')\nconst kQueue = Symbol('queue')\nconst kClosedResolve = Symbol('closed resolve')\nconst kOnDrain = Symbol('onDrain')\nconst kOnConnect = Symbol('onConnect')\nconst kOnDisconnect = Symbol('onDisconnect')\nconst kOnConnectionError = Symbol('onConnectionError')\nconst kGetDispatcher = Symbol('get dispatcher')\nconst kAddClient = Symbol('add client')\nconst kRemoveClient = Symbol('remove client')\nconst kStats = Symbol('stats')\n\nclass PoolBase extends DispatcherBase {\n  constructor () {\n    super()\n\n    this[kQueue] = new FixedQueue()\n    this[kClients] = []\n    this[kQueued] = 0\n\n    const pool = this\n\n    this[kOnDrain] = function onDrain (origin, targets) {\n      const queue = pool[kQueue]\n\n      let needDrain = false\n\n      while (!needDrain) {\n        const item = queue.shift()\n        if (!item) {\n          break\n        }\n        pool[kQueued]--\n        needDrain = !this.dispatch(item.opts, item.handler)\n      }\n\n      this[kNeedDrain] = needDrain\n\n      if (!this[kNeedDrain] && pool[kNeedDrain]) {\n        pool[kNeedDrain] = false\n        pool.emit('drain', origin, [pool, ...targets])\n      }\n\n      if (pool[kClosedResolve] && queue.isEmpty()) {\n        Promise\n          .all(pool[kClients].map(c => c.close()))\n          .then(pool[kClosedResolve])\n      }\n    }\n\n    this[kOnConnect] = (origin, targets) => {\n      pool.emit('connect', origin, [pool, ...targets])\n    }\n\n    this[kOnDisconnect] = (origin, targets, err) => {\n      pool.emit('disconnect', origin, [pool, ...targets], err)\n    }\n\n    this[kOnConnectionError] = (origin, targets, err) => {\n      pool.emit('connectionError', origin, [pool, ...targets], err)\n    }\n\n    this[kStats] = new PoolStats(this)\n  }\n\n  get [kBusy] () {\n    return this[kNeedDrain]\n  }\n\n  get [kConnected] () {\n    return this[kClients].filter(client => client[kConnected]).length\n  }\n\n  get [kFree] () {\n    return this[kClients].filter(client => client[kConnected] && !client[kNeedDrain]).length\n  }\n\n  get [kPending] () {\n    let ret = this[kQueued]\n    for (const { [kPending]: pending } of this[kClients]) {\n      ret += pending\n    }\n    return ret\n  }\n\n  get [kRunning] () {\n    let ret = 0\n    for (const { [kRunning]: running } of this[kClients]) {\n      ret += running\n    }\n    return ret\n  }\n\n  get [kSize] () {\n    let ret = this[kQueued]\n    for (const { [kSize]: size } of this[kClients]) {\n      ret += size\n    }\n    return ret\n  }\n\n  get stats () {\n    return this[kStats]\n  }\n\n  async [kClose] () {\n    if (this[kQueue].isEmpty()) {\n      return Promise.all(this[kClients].map(c => c.close()))\n    } else {\n      return new Promise((resolve) => {\n        this[kClosedResolve] = resolve\n      })\n    }\n  }\n\n  async [kDestroy] (err) {\n    while (true) {\n      const item = this[kQueue].shift()\n      if (!item) {\n        break\n      }\n      item.handler.onError(err)\n    }\n\n    return Promise.all(this[kClients].map(c => c.destroy(err)))\n  }\n\n  [kDispatch] (opts, handler) {\n    const dispatcher = this[kGetDispatcher]()\n\n    if (!dispatcher) {\n      this[kNeedDrain] = true\n      this[kQueue].push({ opts, handler })\n      this[kQueued]++\n    } else if (!dispatcher.dispatch(opts, handler)) {\n      dispatcher[kNeedDrain] = true\n      this[kNeedDrain] = !this[kGetDispatcher]()\n    }\n\n    return !this[kNeedDrain]\n  }\n\n  [kAddClient] (client) {\n    client\n      .on('drain', this[kOnDrain])\n      .on('connect', this[kOnConnect])\n      .on('disconnect', this[kOnDisconnect])\n      .on('connectionError', this[kOnConnectionError])\n\n    this[kClients].push(client)\n\n    if (this[kNeedDrain]) {\n      process.nextTick(() => {\n        if (this[kNeedDrain]) {\n          this[kOnDrain](client[kUrl], [this, client])\n        }\n      })\n    }\n\n    return this\n  }\n\n  [kRemoveClient] (client) {\n    client.close(() => {\n      const idx = this[kClients].indexOf(client)\n      if (idx !== -1) {\n        this[kClients].splice(idx, 1)\n      }\n    })\n\n    this[kNeedDrain] = this[kClients].some(dispatcher => (\n      !dispatcher[kNeedDrain] &&\n      dispatcher.closed !== true &&\n      dispatcher.destroyed !== true\n    ))\n  }\n}\n\nmodule.exports = {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kRemoveClient,\n  kGetDispatcher\n}\n","const { kFree, kConnected, kPending, kQueued, kRunning, kSize } = require('./core/symbols')\nconst kPool = Symbol('pool')\n\nclass PoolStats {\n  constructor (pool) {\n    this[kPool] = pool\n  }\n\n  get connected () {\n    return this[kPool][kConnected]\n  }\n\n  get free () {\n    return this[kPool][kFree]\n  }\n\n  get pending () {\n    return this[kPool][kPending]\n  }\n\n  get queued () {\n    return this[kPool][kQueued]\n  }\n\n  get running () {\n    return this[kPool][kRunning]\n  }\n\n  get size () {\n    return this[kPool][kSize]\n  }\n}\n\nmodule.exports = PoolStats\n","'use strict'\n\nconst {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kGetDispatcher\n} = require('./pool-base')\nconst Client = require('./client')\nconst {\n  InvalidArgumentError\n} = require('./core/errors')\nconst util = require('./core/util')\nconst { kUrl, kInterceptors } = require('./core/symbols')\nconst buildConnector = require('./core/connect')\n\nconst kOptions = Symbol('options')\nconst kConnections = Symbol('connections')\nconst kFactory = Symbol('factory')\n\nfunction defaultFactory (origin, opts) {\n  return new Client(origin, opts)\n}\n\nclass Pool extends PoolBase {\n  constructor (origin, {\n    connections,\n    factory = defaultFactory,\n    connect,\n    connectTimeout,\n    tls,\n    maxCachedSessions,\n    socketPath,\n    autoSelectFamily,\n    autoSelectFamilyAttemptTimeout,\n    allowH2,\n    ...options\n  } = {}) {\n    super()\n\n    if (connections != null && (!Number.isFinite(connections) || connections < 0)) {\n      throw new InvalidArgumentError('invalid connections')\n    }\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (typeof connect !== 'function') {\n      connect = buildConnector({\n        ...tls,\n        maxCachedSessions,\n        allowH2,\n        socketPath,\n        timeout: connectTimeout,\n        ...(util.nodeHasAutoSelectFamily && autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),\n        ...connect\n      })\n    }\n\n    this[kInterceptors] = options.interceptors && options.interceptors.Pool && Array.isArray(options.interceptors.Pool)\n      ? options.interceptors.Pool\n      : []\n    this[kConnections] = connections || null\n    this[kUrl] = util.parseOrigin(origin)\n    this[kOptions] = { ...util.deepClone(options), connect, allowH2 }\n    this[kOptions].interceptors = options.interceptors\n      ? { ...options.interceptors }\n      : undefined\n    this[kFactory] = factory\n\n    this.on('connectionError', (origin, targets, error) => {\n      // If a connection error occurs, we remove the client from the pool,\n      // and emit a connectionError event. They will not be re-used.\n      // Fixes https://github.com/nodejs/undici/issues/3895\n      for (const target of targets) {\n        // Do not use kRemoveClient here, as it will close the client,\n        // but the client cannot be closed in this state.\n        const idx = this[kClients].indexOf(target)\n        if (idx !== -1) {\n          this[kClients].splice(idx, 1)\n        }\n      }\n    })\n  }\n\n  [kGetDispatcher] () {\n    let dispatcher = this[kClients].find(dispatcher => !dispatcher[kNeedDrain])\n\n    if (dispatcher) {\n      return dispatcher\n    }\n\n    if (!this[kConnections] || this[kClients].length < this[kConnections]) {\n      dispatcher = this[kFactory](this[kUrl], this[kOptions])\n      this[kAddClient](dispatcher)\n    }\n\n    return dispatcher\n  }\n}\n\nmodule.exports = Pool\n","'use strict'\n\nconst { kProxy, kClose, kDestroy, kInterceptors } = require('./core/symbols')\nconst { URL } = require('url')\nconst Agent = require('./agent')\nconst Pool = require('./pool')\nconst DispatcherBase = require('./dispatcher-base')\nconst { InvalidArgumentError, RequestAbortedError } = require('./core/errors')\nconst buildConnector = require('./core/connect')\n\nconst kAgent = Symbol('proxy agent')\nconst kClient = Symbol('proxy client')\nconst kProxyHeaders = Symbol('proxy headers')\nconst kRequestTls = Symbol('request tls settings')\nconst kProxyTls = Symbol('proxy tls settings')\nconst kConnectEndpoint = Symbol('connect endpoint function')\n\nfunction defaultProtocolPort (protocol) {\n  return protocol === 'https:' ? 443 : 80\n}\n\nfunction buildProxyOptions (opts) {\n  if (typeof opts === 'string') {\n    opts = { uri: opts }\n  }\n\n  if (!opts || !opts.uri) {\n    throw new InvalidArgumentError('Proxy opts.uri is mandatory')\n  }\n\n  return {\n    uri: opts.uri,\n    protocol: opts.protocol || 'https'\n  }\n}\n\nfunction defaultFactory (origin, opts) {\n  return new Pool(origin, opts)\n}\n\nclass ProxyAgent extends DispatcherBase {\n  constructor (opts) {\n    super(opts)\n    this[kProxy] = buildProxyOptions(opts)\n    this[kAgent] = new Agent(opts)\n    this[kInterceptors] = opts.interceptors && opts.interceptors.ProxyAgent && Array.isArray(opts.interceptors.ProxyAgent)\n      ? opts.interceptors.ProxyAgent\n      : []\n\n    if (typeof opts === 'string') {\n      opts = { uri: opts }\n    }\n\n    if (!opts || !opts.uri) {\n      throw new InvalidArgumentError('Proxy opts.uri is mandatory')\n    }\n\n    const { clientFactory = defaultFactory } = opts\n\n    if (typeof clientFactory !== 'function') {\n      throw new InvalidArgumentError('Proxy opts.clientFactory must be a function.')\n    }\n\n    this[kRequestTls] = opts.requestTls\n    this[kProxyTls] = opts.proxyTls\n    this[kProxyHeaders] = opts.headers || {}\n\n    const resolvedUrl = new URL(opts.uri)\n    const { origin, port, host, username, password } = resolvedUrl\n\n    if (opts.auth && opts.token) {\n      throw new InvalidArgumentError('opts.auth cannot be used in combination with opts.token')\n    } else if (opts.auth) {\n      /* @deprecated in favour of opts.token */\n      this[kProxyHeaders]['proxy-authorization'] = `Basic ${opts.auth}`\n    } else if (opts.token) {\n      this[kProxyHeaders]['proxy-authorization'] = opts.token\n    } else if (username && password) {\n      this[kProxyHeaders]['proxy-authorization'] = `Basic ${Buffer.from(`${decodeURIComponent(username)}:${decodeURIComponent(password)}`).toString('base64')}`\n    }\n\n    const connect = buildConnector({ ...opts.proxyTls })\n    this[kConnectEndpoint] = buildConnector({ ...opts.requestTls })\n    this[kClient] = clientFactory(resolvedUrl, { connect })\n    this[kAgent] = new Agent({\n      ...opts,\n      connect: async (opts, callback) => {\n        let requestedHost = opts.host\n        if (!opts.port) {\n          requestedHost += `:${defaultProtocolPort(opts.protocol)}`\n        }\n        try {\n          const { socket, statusCode } = await this[kClient].connect({\n            origin,\n            port,\n            path: requestedHost,\n            signal: opts.signal,\n            headers: {\n              ...this[kProxyHeaders],\n              host\n            }\n          })\n          if (statusCode !== 200) {\n            socket.on('error', () => {}).destroy()\n            callback(new RequestAbortedError(`Proxy response (${statusCode}) !== 200 when HTTP Tunneling`))\n          }\n          if (opts.protocol !== 'https:') {\n            callback(null, socket)\n            return\n          }\n          let servername\n          if (this[kRequestTls]) {\n            servername = this[kRequestTls].servername\n          } else {\n            servername = opts.servername\n          }\n          this[kConnectEndpoint]({ ...opts, servername, httpSocket: socket }, callback)\n        } catch (err) {\n          callback(err)\n        }\n      }\n    })\n  }\n\n  dispatch (opts, handler) {\n    const { host } = new URL(opts.origin)\n    const headers = buildHeaders(opts.headers)\n    throwIfProxyAuthIsSent(headers)\n    return this[kAgent].dispatch(\n      {\n        ...opts,\n        headers: {\n          ...headers,\n          host\n        }\n      },\n      handler\n    )\n  }\n\n  async [kClose] () {\n    await this[kAgent].close()\n    await this[kClient].close()\n  }\n\n  async [kDestroy] () {\n    await this[kAgent].destroy()\n    await this[kClient].destroy()\n  }\n}\n\n/**\n * @param {string[] | Record<string, string>} headers\n * @returns {Record<string, string>}\n */\nfunction buildHeaders (headers) {\n  // When using undici.fetch, the headers list is stored\n  // as an array.\n  if (Array.isArray(headers)) {\n    /** @type {Record<string, string>} */\n    const headersPair = {}\n\n    for (let i = 0; i < headers.length; i += 2) {\n      headersPair[headers[i]] = headers[i + 1]\n    }\n\n    return headersPair\n  }\n\n  return headers\n}\n\n/**\n * @param {Record<string, string>} headers\n *\n * Previous versions of ProxyAgent suggests the Proxy-Authorization in request headers\n * Nevertheless, it was changed and to avoid a security vulnerability by end users\n * this check was created.\n * It should be removed in the next major version for performance reasons\n */\nfunction throwIfProxyAuthIsSent (headers) {\n  const existProxyAuth = headers && Object.keys(headers)\n    .find((key) => key.toLowerCase() === 'proxy-authorization')\n  if (existProxyAuth) {\n    throw new InvalidArgumentError('Proxy-Authorization should be sent in ProxyAgent constructor')\n  }\n}\n\nmodule.exports = ProxyAgent\n","'use strict'\n\nlet fastNow = Date.now()\nlet fastNowTimeout\n\nconst fastTimers = []\n\nfunction onTimeout () {\n  fastNow = Date.now()\n\n  let len = fastTimers.length\n  let idx = 0\n  while (idx < len) {\n    const timer = fastTimers[idx]\n\n    if (timer.state === 0) {\n      timer.state = fastNow + timer.delay\n    } else if (timer.state > 0 && fastNow >= timer.state) {\n      timer.state = -1\n      timer.callback(timer.opaque)\n    }\n\n    if (timer.state === -1) {\n      timer.state = -2\n      if (idx !== len - 1) {\n        fastTimers[idx] = fastTimers.pop()\n      } else {\n        fastTimers.pop()\n      }\n      len -= 1\n    } else {\n      idx += 1\n    }\n  }\n\n  if (fastTimers.length > 0) {\n    refreshTimeout()\n  }\n}\n\nfunction refreshTimeout () {\n  if (fastNowTimeout && fastNowTimeout.refresh) {\n    fastNowTimeout.refresh()\n  } else {\n    clearTimeout(fastNowTimeout)\n    fastNowTimeout = setTimeout(onTimeout, 1e3)\n    if (fastNowTimeout.unref) {\n      fastNowTimeout.unref()\n    }\n  }\n}\n\nclass Timeout {\n  constructor (callback, delay, opaque) {\n    this.callback = callback\n    this.delay = delay\n    this.opaque = opaque\n\n    //  -2 not in timer list\n    //  -1 in timer list but inactive\n    //   0 in timer list waiting for time\n    // > 0 in timer list waiting for time to expire\n    this.state = -2\n\n    this.refresh()\n  }\n\n  refresh () {\n    if (this.state === -2) {\n      fastTimers.push(this)\n      if (!fastNowTimeout || fastTimers.length === 1) {\n        refreshTimeout()\n      }\n    }\n\n    this.state = 0\n  }\n\n  clear () {\n    this.state = -1\n  }\n}\n\nmodule.exports = {\n  setTimeout (callback, delay, opaque) {\n    return delay < 1e3\n      ? setTimeout(callback, delay, opaque)\n      : new Timeout(callback, delay, opaque)\n  },\n  clearTimeout (timeout) {\n    if (timeout instanceof Timeout) {\n      timeout.clear()\n    } else {\n      clearTimeout(timeout)\n    }\n  }\n}\n","'use strict'\n\nconst diagnosticsChannel = require('diagnostics_channel')\nconst { uid, states } = require('./constants')\nconst {\n  kReadyState,\n  kSentClose,\n  kByteParser,\n  kReceivedClose\n} = require('./symbols')\nconst { fireEvent, failWebsocketConnection } = require('./util')\nconst { CloseEvent } = require('./events')\nconst { makeRequest } = require('../fetch/request')\nconst { fetching } = require('../fetch/index')\nconst { Headers } = require('../fetch/headers')\nconst { getGlobalDispatcher } = require('../global')\nconst { kHeadersList } = require('../core/symbols')\n\nconst channels = {}\nchannels.open = diagnosticsChannel.channel('undici:websocket:open')\nchannels.close = diagnosticsChannel.channel('undici:websocket:close')\nchannels.socketError = diagnosticsChannel.channel('undici:websocket:socket_error')\n\n/** @type {import('crypto')} */\nlet crypto\ntry {\n  crypto = require('crypto')\n} catch {\n\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#concept-websocket-establish\n * @param {URL} url\n * @param {string|string[]} protocols\n * @param {import('./websocket').WebSocket} ws\n * @param {(response: any) => void} onEstablish\n * @param {Partial<import('../../types/websocket').WebSocketInit>} options\n */\nfunction establishWebSocketConnection (url, protocols, ws, onEstablish, options) {\n  // 1. Let requestURL be a copy of url, with its scheme set to \"http\", if urls\n  //    scheme is \"ws\", and to \"https\" otherwise.\n  const requestURL = url\n\n  requestURL.protocol = url.protocol === 'ws:' ? 'http:' : 'https:'\n\n  // 2. Let request be a new request, whose URL is requestURL, client is client,\n  //    service-workers mode is \"none\", referrer is \"no-referrer\", mode is\n  //    \"websocket\", credentials mode is \"include\", cache mode is \"no-store\" ,\n  //    and redirect mode is \"error\".\n  const request = makeRequest({\n    urlList: [requestURL],\n    serviceWorkers: 'none',\n    referrer: 'no-referrer',\n    mode: 'websocket',\n    credentials: 'include',\n    cache: 'no-store',\n    redirect: 'error'\n  })\n\n  // Note: undici extension, allow setting custom headers.\n  if (options.headers) {\n    const headersList = new Headers(options.headers)[kHeadersList]\n\n    request.headersList = headersList\n  }\n\n  // 3. Append (`Upgrade`, `websocket`) to requests header list.\n  // 4. Append (`Connection`, `Upgrade`) to requests header list.\n  // Note: both of these are handled by undici currently.\n  // https://github.com/nodejs/undici/blob/68c269c4144c446f3f1220951338daef4a6b5ec4/lib/client.js#L1397\n\n  // 5. Let keyValue be a nonce consisting of a randomly selected\n  //    16-byte value that has been forgiving-base64-encoded and\n  //    isomorphic encoded.\n  const keyValue = crypto.randomBytes(16).toString('base64')\n\n  // 6. Append (`Sec-WebSocket-Key`, keyValue) to requests\n  //    header list.\n  request.headersList.append('sec-websocket-key', keyValue)\n\n  // 7. Append (`Sec-WebSocket-Version`, `13`) to requests\n  //    header list.\n  request.headersList.append('sec-websocket-version', '13')\n\n  // 8. For each protocol in protocols, combine\n  //    (`Sec-WebSocket-Protocol`, protocol) in requests header\n  //    list.\n  for (const protocol of protocols) {\n    request.headersList.append('sec-websocket-protocol', protocol)\n  }\n\n  // 9. Let permessageDeflate be a user-agent defined\n  //    \"permessage-deflate\" extension header value.\n  // https://github.com/mozilla/gecko-dev/blob/ce78234f5e653a5d3916813ff990f053510227bc/netwerk/protocol/websocket/WebSocketChannel.cpp#L2673\n  // TODO: enable once permessage-deflate is supported\n  const permessageDeflate = '' // 'permessage-deflate; 15'\n\n  // 10. Append (`Sec-WebSocket-Extensions`, permessageDeflate) to\n  //     requests header list.\n  // request.headersList.append('sec-websocket-extensions', permessageDeflate)\n\n  // 11. Fetch request with useParallelQueue set to true, and\n  //     processResponse given response being these steps:\n  const controller = fetching({\n    request,\n    useParallelQueue: true,\n    dispatcher: options.dispatcher ?? getGlobalDispatcher(),\n    processResponse (response) {\n      // 1. If response is a network error or its status is not 101,\n      //    fail the WebSocket connection.\n      if (response.type === 'error' || response.status !== 101) {\n        failWebsocketConnection(ws, 'Received network error or non-101 status code.')\n        return\n      }\n\n      // 2. If protocols is not the empty list and extracting header\n      //    list values given `Sec-WebSocket-Protocol` and responses\n      //    header list results in null, failure, or the empty byte\n      //    sequence, then fail the WebSocket connection.\n      if (protocols.length !== 0 && !response.headersList.get('Sec-WebSocket-Protocol')) {\n        failWebsocketConnection(ws, 'Server did not respond with sent protocols.')\n        return\n      }\n\n      // 3. Follow the requirements stated step 2 to step 6, inclusive,\n      //    of the last set of steps in section 4.1 of The WebSocket\n      //    Protocol to validate response. This either results in fail\n      //    the WebSocket connection or the WebSocket connection is\n      //    established.\n\n      // 2. If the response lacks an |Upgrade| header field or the |Upgrade|\n      //    header field contains a value that is not an ASCII case-\n      //    insensitive match for the value \"websocket\", the client MUST\n      //    _Fail the WebSocket Connection_.\n      if (response.headersList.get('Upgrade')?.toLowerCase() !== 'websocket') {\n        failWebsocketConnection(ws, 'Server did not set Upgrade header to \"websocket\".')\n        return\n      }\n\n      // 3. If the response lacks a |Connection| header field or the\n      //    |Connection| header field doesn't contain a token that is an\n      //    ASCII case-insensitive match for the value \"Upgrade\", the client\n      //    MUST _Fail the WebSocket Connection_.\n      if (response.headersList.get('Connection')?.toLowerCase() !== 'upgrade') {\n        failWebsocketConnection(ws, 'Server did not set Connection header to \"upgrade\".')\n        return\n      }\n\n      // 4. If the response lacks a |Sec-WebSocket-Accept| header field or\n      //    the |Sec-WebSocket-Accept| contains a value other than the\n      //    base64-encoded SHA-1 of the concatenation of the |Sec-WebSocket-\n      //    Key| (as a string, not base64-decoded) with the string \"258EAFA5-\n      //    E914-47DA-95CA-C5AB0DC85B11\" but ignoring any leading and\n      //    trailing whitespace, the client MUST _Fail the WebSocket\n      //    Connection_.\n      const secWSAccept = response.headersList.get('Sec-WebSocket-Accept')\n      const digest = crypto.createHash('sha1').update(keyValue + uid).digest('base64')\n      if (secWSAccept !== digest) {\n        failWebsocketConnection(ws, 'Incorrect hash received in Sec-WebSocket-Accept header.')\n        return\n      }\n\n      // 5. If the response includes a |Sec-WebSocket-Extensions| header\n      //    field and this header field indicates the use of an extension\n      //    that was not present in the client's handshake (the server has\n      //    indicated an extension not requested by the client), the client\n      //    MUST _Fail the WebSocket Connection_.  (The parsing of this\n      //    header field to determine which extensions are requested is\n      //    discussed in Section 9.1.)\n      const secExtension = response.headersList.get('Sec-WebSocket-Extensions')\n\n      if (secExtension !== null && secExtension !== permessageDeflate) {\n        failWebsocketConnection(ws, 'Received different permessage-deflate than the one set.')\n        return\n      }\n\n      // 6. If the response includes a |Sec-WebSocket-Protocol| header field\n      //    and this header field indicates the use of a subprotocol that was\n      //    not present in the client's handshake (the server has indicated a\n      //    subprotocol not requested by the client), the client MUST _Fail\n      //    the WebSocket Connection_.\n      const secProtocol = response.headersList.get('Sec-WebSocket-Protocol')\n\n      if (secProtocol !== null && secProtocol !== request.headersList.get('Sec-WebSocket-Protocol')) {\n        failWebsocketConnection(ws, 'Protocol was not set in the opening handshake.')\n        return\n      }\n\n      response.socket.on('data', onSocketData)\n      response.socket.on('close', onSocketClose)\n      response.socket.on('error', onSocketError)\n\n      if (channels.open.hasSubscribers) {\n        channels.open.publish({\n          address: response.socket.address(),\n          protocol: secProtocol,\n          extensions: secExtension\n        })\n      }\n\n      onEstablish(response)\n    }\n  })\n\n  return controller\n}\n\n/**\n * @param {Buffer} chunk\n */\nfunction onSocketData (chunk) {\n  if (!this.ws[kByteParser].write(chunk)) {\n    this.pause()\n  }\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.4\n */\nfunction onSocketClose () {\n  const { ws } = this\n\n  // If the TCP connection was closed after the\n  // WebSocket closing handshake was completed, the WebSocket connection\n  // is said to have been closed _cleanly_.\n  const wasClean = ws[kSentClose] && ws[kReceivedClose]\n\n  let code = 1005\n  let reason = ''\n\n  const result = ws[kByteParser].closingInfo\n\n  if (result) {\n    code = result.code ?? 1005\n    reason = result.reason\n  } else if (!ws[kSentClose]) {\n    // If _The WebSocket\n    // Connection is Closed_ and no Close control frame was received by the\n    // endpoint (such as could occur if the underlying transport connection\n    // is lost), _The WebSocket Connection Close Code_ is considered to be\n    // 1006.\n    code = 1006\n  }\n\n  // 1. Change the ready state to CLOSED (3).\n  ws[kReadyState] = states.CLOSED\n\n  // 2. If the user agent was required to fail the WebSocket\n  //    connection, or if the WebSocket connection was closed\n  //    after being flagged as full, fire an event named error\n  //    at the WebSocket object.\n  // TODO\n\n  // 3. Fire an event named close at the WebSocket object,\n  //    using CloseEvent, with the wasClean attribute\n  //    initialized to true if the connection closed cleanly\n  //    and false otherwise, the code attribute initialized to\n  //    the WebSocket connection close code, and the reason\n  //    attribute initialized to the result of applying UTF-8\n  //    decode without BOM to the WebSocket connection close\n  //    reason.\n  fireEvent('close', ws, CloseEvent, {\n    wasClean, code, reason\n  })\n\n  if (channels.close.hasSubscribers) {\n    channels.close.publish({\n      websocket: ws,\n      code,\n      reason\n    })\n  }\n}\n\nfunction onSocketError (error) {\n  const { ws } = this\n\n  ws[kReadyState] = states.CLOSING\n\n  if (channels.socketError.hasSubscribers) {\n    channels.socketError.publish(error)\n  }\n\n  this.destroy()\n}\n\nmodule.exports = {\n  establishWebSocketConnection\n}\n","'use strict'\n\n// This is a Globally Unique Identifier unique used\n// to validate that the endpoint accepts websocket\n// connections.\n// See https://www.rfc-editor.org/rfc/rfc6455.html#section-1.3\nconst uid = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'\n\n/** @type {PropertyDescriptor} */\nconst staticPropertyDescriptors = {\n  enumerable: true,\n  writable: false,\n  configurable: false\n}\n\nconst states = {\n  CONNECTING: 0,\n  OPEN: 1,\n  CLOSING: 2,\n  CLOSED: 3\n}\n\nconst opcodes = {\n  CONTINUATION: 0x0,\n  TEXT: 0x1,\n  BINARY: 0x2,\n  CLOSE: 0x8,\n  PING: 0x9,\n  PONG: 0xA\n}\n\nconst maxUnsigned16Bit = 2 ** 16 - 1 // 65535\n\nconst parserStates = {\n  INFO: 0,\n  PAYLOADLENGTH_16: 2,\n  PAYLOADLENGTH_64: 3,\n  READ_DATA: 4\n}\n\nconst emptyBuffer = Buffer.allocUnsafe(0)\n\nmodule.exports = {\n  uid,\n  staticPropertyDescriptors,\n  states,\n  opcodes,\n  maxUnsigned16Bit,\n  parserStates,\n  emptyBuffer\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../core/util')\nconst { MessagePort } = require('worker_threads')\n\n/**\n * @see https://html.spec.whatwg.org/multipage/comms.html#messageevent\n */\nclass MessageEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict = {}) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'MessageEvent constructor' })\n\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.MessageEventInit(eventInitDict)\n\n    super(type, eventInitDict)\n\n    this.#eventInit = eventInitDict\n  }\n\n  get data () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.data\n  }\n\n  get origin () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.origin\n  }\n\n  get lastEventId () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.lastEventId\n  }\n\n  get source () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.source\n  }\n\n  get ports () {\n    webidl.brandCheck(this, MessageEvent)\n\n    if (!Object.isFrozen(this.#eventInit.ports)) {\n      Object.freeze(this.#eventInit.ports)\n    }\n\n    return this.#eventInit.ports\n  }\n\n  initMessageEvent (\n    type,\n    bubbles = false,\n    cancelable = false,\n    data = null,\n    origin = '',\n    lastEventId = '',\n    source = null,\n    ports = []\n  ) {\n    webidl.brandCheck(this, MessageEvent)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'MessageEvent.initMessageEvent' })\n\n    return new MessageEvent(type, {\n      bubbles, cancelable, data, origin, lastEventId, source, ports\n    })\n  }\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#the-closeevent-interface\n */\nclass CloseEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict = {}) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CloseEvent constructor' })\n\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.CloseEventInit(eventInitDict)\n\n    super(type, eventInitDict)\n\n    this.#eventInit = eventInitDict\n  }\n\n  get wasClean () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.wasClean\n  }\n\n  get code () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.code\n  }\n\n  get reason () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.reason\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/webappapis.html#the-errorevent-interface\nclass ErrorEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'ErrorEvent constructor' })\n\n    super(type, eventInitDict)\n\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.ErrorEventInit(eventInitDict ?? {})\n\n    this.#eventInit = eventInitDict\n  }\n\n  get message () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.message\n  }\n\n  get filename () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.filename\n  }\n\n  get lineno () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.lineno\n  }\n\n  get colno () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.colno\n  }\n\n  get error () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.error\n  }\n}\n\nObject.defineProperties(MessageEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'MessageEvent',\n    configurable: true\n  },\n  data: kEnumerableProperty,\n  origin: kEnumerableProperty,\n  lastEventId: kEnumerableProperty,\n  source: kEnumerableProperty,\n  ports: kEnumerableProperty,\n  initMessageEvent: kEnumerableProperty\n})\n\nObject.defineProperties(CloseEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'CloseEvent',\n    configurable: true\n  },\n  reason: kEnumerableProperty,\n  code: kEnumerableProperty,\n  wasClean: kEnumerableProperty\n})\n\nObject.defineProperties(ErrorEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'ErrorEvent',\n    configurable: true\n  },\n  message: kEnumerableProperty,\n  filename: kEnumerableProperty,\n  lineno: kEnumerableProperty,\n  colno: kEnumerableProperty,\n  error: kEnumerableProperty\n})\n\nwebidl.converters.MessagePort = webidl.interfaceConverter(MessagePort)\n\nwebidl.converters['sequence<MessagePort>'] = webidl.sequenceConverter(\n  webidl.converters.MessagePort\n)\n\nconst eventInit = [\n  {\n    key: 'bubbles',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'cancelable',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'composed',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  }\n]\n\nwebidl.converters.MessageEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'data',\n    converter: webidl.converters.any,\n    defaultValue: null\n  },\n  {\n    key: 'origin',\n    converter: webidl.converters.USVString,\n    defaultValue: ''\n  },\n  {\n    key: 'lastEventId',\n    converter: webidl.converters.DOMString,\n    defaultValue: ''\n  },\n  {\n    key: 'source',\n    // Node doesn't implement WindowProxy or ServiceWorker, so the only\n    // valid value for source is a MessagePort.\n    converter: webidl.nullableConverter(webidl.converters.MessagePort),\n    defaultValue: null\n  },\n  {\n    key: 'ports',\n    converter: webidl.converters['sequence<MessagePort>'],\n    get defaultValue () {\n      return []\n    }\n  }\n])\n\nwebidl.converters.CloseEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'wasClean',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'code',\n    converter: webidl.converters['unsigned short'],\n    defaultValue: 0\n  },\n  {\n    key: 'reason',\n    converter: webidl.converters.USVString,\n    defaultValue: ''\n  }\n])\n\nwebidl.converters.ErrorEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'message',\n    converter: webidl.converters.DOMString,\n    defaultValue: ''\n  },\n  {\n    key: 'filename',\n    converter: webidl.converters.USVString,\n    defaultValue: ''\n  },\n  {\n    key: 'lineno',\n    converter: webidl.converters['unsigned long'],\n    defaultValue: 0\n  },\n  {\n    key: 'colno',\n    converter: webidl.converters['unsigned long'],\n    defaultValue: 0\n  },\n  {\n    key: 'error',\n    converter: webidl.converters.any\n  }\n])\n\nmodule.exports = {\n  MessageEvent,\n  CloseEvent,\n  ErrorEvent\n}\n","'use strict'\n\nconst { maxUnsigned16Bit } = require('./constants')\n\n/** @type {import('crypto')} */\nlet crypto\ntry {\n  crypto = require('crypto')\n} catch {\n\n}\n\nclass WebsocketFrameSend {\n  /**\n   * @param {Buffer|undefined} data\n   */\n  constructor (data) {\n    this.frameData = data\n    this.maskKey = crypto.randomBytes(4)\n  }\n\n  createFrame (opcode) {\n    const bodyLength = this.frameData?.byteLength ?? 0\n\n    /** @type {number} */\n    let payloadLength = bodyLength // 0-125\n    let offset = 6\n\n    if (bodyLength > maxUnsigned16Bit) {\n      offset += 8 // payload length is next 8 bytes\n      payloadLength = 127\n    } else if (bodyLength > 125) {\n      offset += 2 // payload length is next 2 bytes\n      payloadLength = 126\n    }\n\n    const buffer = Buffer.allocUnsafe(bodyLength + offset)\n\n    // Clear first 2 bytes, everything else is overwritten\n    buffer[0] = buffer[1] = 0\n    buffer[0] |= 0x80 // FIN\n    buffer[0] = (buffer[0] & 0xF0) + opcode // opcode\n\n    /*! ws. MIT License. Einar Otto Stangvik <einaros@gmail.com> */\n    buffer[offset - 4] = this.maskKey[0]\n    buffer[offset - 3] = this.maskKey[1]\n    buffer[offset - 2] = this.maskKey[2]\n    buffer[offset - 1] = this.maskKey[3]\n\n    buffer[1] = payloadLength\n\n    if (payloadLength === 126) {\n      buffer.writeUInt16BE(bodyLength, 2)\n    } else if (payloadLength === 127) {\n      // Clear extended payload length\n      buffer[2] = buffer[3] = 0\n      buffer.writeUIntBE(bodyLength, 4, 6)\n    }\n\n    buffer[1] |= 0x80 // MASK\n\n    // mask body\n    for (let i = 0; i < bodyLength; i++) {\n      buffer[offset + i] = this.frameData[i] ^ this.maskKey[i % 4]\n    }\n\n    return buffer\n  }\n}\n\nmodule.exports = {\n  WebsocketFrameSend\n}\n","'use strict'\n\nconst { Writable } = require('stream')\nconst diagnosticsChannel = require('diagnostics_channel')\nconst { parserStates, opcodes, states, emptyBuffer } = require('./constants')\nconst { kReadyState, kSentClose, kResponse, kReceivedClose } = require('./symbols')\nconst { isValidStatusCode, failWebsocketConnection, websocketMessageReceived } = require('./util')\nconst { WebsocketFrameSend } = require('./frame')\n\n// This code was influenced by ws released under the MIT license.\n// Copyright (c) 2011 Einar Otto Stangvik <einaros@gmail.com>\n// Copyright (c) 2013 Arnout Kazemier and contributors\n// Copyright (c) 2016 Luigi Pinca and contributors\n\nconst channels = {}\nchannels.ping = diagnosticsChannel.channel('undici:websocket:ping')\nchannels.pong = diagnosticsChannel.channel('undici:websocket:pong')\n\nclass ByteParser extends Writable {\n  #buffers = []\n  #byteOffset = 0\n\n  #state = parserStates.INFO\n\n  #info = {}\n  #fragments = []\n\n  constructor (ws) {\n    super()\n\n    this.ws = ws\n  }\n\n  /**\n   * @param {Buffer} chunk\n   * @param {() => void} callback\n   */\n  _write (chunk, _, callback) {\n    this.#buffers.push(chunk)\n    this.#byteOffset += chunk.length\n\n    this.run(callback)\n  }\n\n  /**\n   * Runs whenever a new chunk is received.\n   * Callback is called whenever there are no more chunks buffering,\n   * or not enough bytes are buffered to parse.\n   */\n  run (callback) {\n    while (true) {\n      if (this.#state === parserStates.INFO) {\n        // If there aren't enough bytes to parse the payload length, etc.\n        if (this.#byteOffset < 2) {\n          return callback()\n        }\n\n        const buffer = this.consume(2)\n\n        this.#info.fin = (buffer[0] & 0x80) !== 0\n        this.#info.opcode = buffer[0] & 0x0F\n\n        // If we receive a fragmented message, we use the type of the first\n        // frame to parse the full message as binary/text, when it's terminated\n        this.#info.originalOpcode ??= this.#info.opcode\n\n        this.#info.fragmented = !this.#info.fin && this.#info.opcode !== opcodes.CONTINUATION\n\n        if (this.#info.fragmented && this.#info.opcode !== opcodes.BINARY && this.#info.opcode !== opcodes.TEXT) {\n          // Only text and binary frames can be fragmented\n          failWebsocketConnection(this.ws, 'Invalid frame type was fragmented.')\n          return\n        }\n\n        const payloadLength = buffer[1] & 0x7F\n\n        if (payloadLength <= 125) {\n          this.#info.payloadLength = payloadLength\n          this.#state = parserStates.READ_DATA\n        } else if (payloadLength === 126) {\n          this.#state = parserStates.PAYLOADLENGTH_16\n        } else if (payloadLength === 127) {\n          this.#state = parserStates.PAYLOADLENGTH_64\n        }\n\n        if (this.#info.fragmented && payloadLength > 125) {\n          // A fragmented frame can't be fragmented itself\n          failWebsocketConnection(this.ws, 'Fragmented frame exceeded 125 bytes.')\n          return\n        } else if (\n          (this.#info.opcode === opcodes.PING ||\n            this.#info.opcode === opcodes.PONG ||\n            this.#info.opcode === opcodes.CLOSE) &&\n          payloadLength > 125\n        ) {\n          // Control frames can have a payload length of 125 bytes MAX\n          failWebsocketConnection(this.ws, 'Payload length for control frame exceeded 125 bytes.')\n          return\n        } else if (this.#info.opcode === opcodes.CLOSE) {\n          if (payloadLength === 1) {\n            failWebsocketConnection(this.ws, 'Received close frame with a 1-byte body.')\n            return\n          }\n\n          const body = this.consume(payloadLength)\n\n          this.#info.closeInfo = this.parseCloseBody(false, body)\n\n          if (!this.ws[kSentClose]) {\n            // If an endpoint receives a Close frame and did not previously send a\n            // Close frame, the endpoint MUST send a Close frame in response.  (When\n            // sending a Close frame in response, the endpoint typically echos the\n            // status code it received.)\n            const body = Buffer.allocUnsafe(2)\n            body.writeUInt16BE(this.#info.closeInfo.code, 0)\n            const closeFrame = new WebsocketFrameSend(body)\n\n            this.ws[kResponse].socket.write(\n              closeFrame.createFrame(opcodes.CLOSE),\n              (err) => {\n                if (!err) {\n                  this.ws[kSentClose] = true\n                }\n              }\n            )\n          }\n\n          // Upon either sending or receiving a Close control frame, it is said\n          // that _The WebSocket Closing Handshake is Started_ and that the\n          // WebSocket connection is in the CLOSING state.\n          this.ws[kReadyState] = states.CLOSING\n          this.ws[kReceivedClose] = true\n\n          this.end()\n\n          return\n        } else if (this.#info.opcode === opcodes.PING) {\n          // Upon receipt of a Ping frame, an endpoint MUST send a Pong frame in\n          // response, unless it already received a Close frame.\n          // A Pong frame sent in response to a Ping frame must have identical\n          // \"Application data\"\n\n          const body = this.consume(payloadLength)\n\n          if (!this.ws[kReceivedClose]) {\n            const frame = new WebsocketFrameSend(body)\n\n            this.ws[kResponse].socket.write(frame.createFrame(opcodes.PONG))\n\n            if (channels.ping.hasSubscribers) {\n              channels.ping.publish({\n                payload: body\n              })\n            }\n          }\n\n          this.#state = parserStates.INFO\n\n          if (this.#byteOffset > 0) {\n            continue\n          } else {\n            callback()\n            return\n          }\n        } else if (this.#info.opcode === opcodes.PONG) {\n          // A Pong frame MAY be sent unsolicited.  This serves as a\n          // unidirectional heartbeat.  A response to an unsolicited Pong frame is\n          // not expected.\n\n          const body = this.consume(payloadLength)\n\n          if (channels.pong.hasSubscribers) {\n            channels.pong.publish({\n              payload: body\n            })\n          }\n\n          if (this.#byteOffset > 0) {\n            continue\n          } else {\n            callback()\n            return\n          }\n        }\n      } else if (this.#state === parserStates.PAYLOADLENGTH_16) {\n        if (this.#byteOffset < 2) {\n          return callback()\n        }\n\n        const buffer = this.consume(2)\n\n        this.#info.payloadLength = buffer.readUInt16BE(0)\n        this.#state = parserStates.READ_DATA\n      } else if (this.#state === parserStates.PAYLOADLENGTH_64) {\n        if (this.#byteOffset < 8) {\n          return callback()\n        }\n\n        const buffer = this.consume(8)\n        const upper = buffer.readUInt32BE(0)\n\n        // 2^31 is the maxinimum bytes an arraybuffer can contain\n        // on 32-bit systems. Although, on 64-bit systems, this is\n        // 2^53-1 bytes.\n        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length\n        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/common/globals.h;drc=1946212ac0100668f14eb9e2843bdd846e510a1e;bpv=1;bpt=1;l=1275\n        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-array-buffer.h;l=34;drc=1946212ac0100668f14eb9e2843bdd846e510a1e\n        if (upper > 2 ** 31 - 1) {\n          failWebsocketConnection(this.ws, 'Received payload length > 2^31 bytes.')\n          return\n        }\n\n        const lower = buffer.readUInt32BE(4)\n\n        this.#info.payloadLength = (upper << 8) + lower\n        this.#state = parserStates.READ_DATA\n      } else if (this.#state === parserStates.READ_DATA) {\n        if (this.#byteOffset < this.#info.payloadLength) {\n          // If there is still more data in this chunk that needs to be read\n          return callback()\n        } else if (this.#byteOffset >= this.#info.payloadLength) {\n          // If the server sent multiple frames in a single chunk\n\n          const body = this.consume(this.#info.payloadLength)\n\n          this.#fragments.push(body)\n\n          // If the frame is unfragmented, or a fragmented frame was terminated,\n          // a message was received\n          if (!this.#info.fragmented || (this.#info.fin && this.#info.opcode === opcodes.CONTINUATION)) {\n            const fullMessage = Buffer.concat(this.#fragments)\n\n            websocketMessageReceived(this.ws, this.#info.originalOpcode, fullMessage)\n\n            this.#info = {}\n            this.#fragments.length = 0\n          }\n\n          this.#state = parserStates.INFO\n        }\n      }\n\n      if (this.#byteOffset > 0) {\n        continue\n      } else {\n        callback()\n        break\n      }\n    }\n  }\n\n  /**\n   * Take n bytes from the buffered Buffers\n   * @param {number} n\n   * @returns {Buffer|null}\n   */\n  consume (n) {\n    if (n > this.#byteOffset) {\n      return null\n    } else if (n === 0) {\n      return emptyBuffer\n    }\n\n    if (this.#buffers[0].length === n) {\n      this.#byteOffset -= this.#buffers[0].length\n      return this.#buffers.shift()\n    }\n\n    const buffer = Buffer.allocUnsafe(n)\n    let offset = 0\n\n    while (offset !== n) {\n      const next = this.#buffers[0]\n      const { length } = next\n\n      if (length + offset === n) {\n        buffer.set(this.#buffers.shift(), offset)\n        break\n      } else if (length + offset > n) {\n        buffer.set(next.subarray(0, n - offset), offset)\n        this.#buffers[0] = next.subarray(n - offset)\n        break\n      } else {\n        buffer.set(this.#buffers.shift(), offset)\n        offset += next.length\n      }\n    }\n\n    this.#byteOffset -= n\n\n    return buffer\n  }\n\n  parseCloseBody (onlyCode, data) {\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.5\n    /** @type {number|undefined} */\n    let code\n\n    if (data.length >= 2) {\n      // _The WebSocket Connection Close Code_ is\n      // defined as the status code (Section 7.4) contained in the first Close\n      // control frame received by the application\n      code = data.readUInt16BE(0)\n    }\n\n    if (onlyCode) {\n      if (!isValidStatusCode(code)) {\n        return null\n      }\n\n      return { code }\n    }\n\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.6\n    /** @type {Buffer} */\n    let reason = data.subarray(2)\n\n    // Remove BOM\n    if (reason[0] === 0xEF && reason[1] === 0xBB && reason[2] === 0xBF) {\n      reason = reason.subarray(3)\n    }\n\n    if (code !== undefined && !isValidStatusCode(code)) {\n      return null\n    }\n\n    try {\n      // TODO: optimize this\n      reason = new TextDecoder('utf-8', { fatal: true }).decode(reason)\n    } catch {\n      return null\n    }\n\n    return { code, reason }\n  }\n\n  get closingInfo () {\n    return this.#info.closeInfo\n  }\n}\n\nmodule.exports = {\n  ByteParser\n}\n","'use strict'\n\nmodule.exports = {\n  kWebSocketURL: Symbol('url'),\n  kReadyState: Symbol('ready state'),\n  kController: Symbol('controller'),\n  kResponse: Symbol('response'),\n  kBinaryType: Symbol('binary type'),\n  kSentClose: Symbol('sent close'),\n  kReceivedClose: Symbol('received close'),\n  kByteParser: Symbol('byte parser')\n}\n","'use strict'\n\nconst { kReadyState, kController, kResponse, kBinaryType, kWebSocketURL } = require('./symbols')\nconst { states, opcodes } = require('./constants')\nconst { MessageEvent, ErrorEvent } = require('./events')\n\n/* globals Blob */\n\n/**\n * @param {import('./websocket').WebSocket} ws\n */\nfunction isEstablished (ws) {\n  // If the server's response is validated as provided for above, it is\n  // said that _The WebSocket Connection is Established_ and that the\n  // WebSocket Connection is in the OPEN state.\n  return ws[kReadyState] === states.OPEN\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n */\nfunction isClosing (ws) {\n  // Upon either sending or receiving a Close control frame, it is said\n  // that _The WebSocket Closing Handshake is Started_ and that the\n  // WebSocket connection is in the CLOSING state.\n  return ws[kReadyState] === states.CLOSING\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n */\nfunction isClosed (ws) {\n  return ws[kReadyState] === states.CLOSED\n}\n\n/**\n * @see https://dom.spec.whatwg.org/#concept-event-fire\n * @param {string} e\n * @param {EventTarget} target\n * @param {EventInit | undefined} eventInitDict\n */\nfunction fireEvent (e, target, eventConstructor = Event, eventInitDict) {\n  // 1. If eventConstructor is not given, then let eventConstructor be Event.\n\n  // 2. Let event be the result of creating an event given eventConstructor,\n  //    in the relevant realm of target.\n  // 3. Initialize events type attribute to e.\n  const event = new eventConstructor(e, eventInitDict) // eslint-disable-line new-cap\n\n  // 4. Initialize any other IDL attributes of event as described in the\n  //    invocation of this algorithm.\n\n  // 5. Return the result of dispatching event at target, with legacy target\n  //    override flag set if set.\n  target.dispatchEvent(event)\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n * @param {import('./websocket').WebSocket} ws\n * @param {number} type Opcode\n * @param {Buffer} data application data\n */\nfunction websocketMessageReceived (ws, type, data) {\n  // 1. If ready state is not OPEN (1), then return.\n  if (ws[kReadyState] !== states.OPEN) {\n    return\n  }\n\n  // 2. Let dataForEvent be determined by switching on type and binary type:\n  let dataForEvent\n\n  if (type === opcodes.TEXT) {\n    // -> type indicates that the data is Text\n    //      a new DOMString containing data\n    try {\n      dataForEvent = new TextDecoder('utf-8', { fatal: true }).decode(data)\n    } catch {\n      failWebsocketConnection(ws, 'Received invalid UTF-8 in text frame.')\n      return\n    }\n  } else if (type === opcodes.BINARY) {\n    if (ws[kBinaryType] === 'blob') {\n      // -> type indicates that the data is Binary and binary type is \"blob\"\n      //      a new Blob object, created in the relevant Realm of the WebSocket\n      //      object, that represents data as its raw data\n      dataForEvent = new Blob([data])\n    } else {\n      // -> type indicates that the data is Binary and binary type is \"arraybuffer\"\n      //      a new ArrayBuffer object, created in the relevant Realm of the\n      //      WebSocket object, whose contents are data\n      dataForEvent = new Uint8Array(data).buffer\n    }\n  }\n\n  // 3. Fire an event named message at the WebSocket object, using MessageEvent,\n  //    with the origin attribute initialized to the serialization of the WebSocket\n  //    objects url's origin, and the data attribute initialized to dataForEvent.\n  fireEvent('message', ws, MessageEvent, {\n    origin: ws[kWebSocketURL].origin,\n    data: dataForEvent\n  })\n}\n\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc6455\n * @see https://datatracker.ietf.org/doc/html/rfc2616\n * @see https://bugs.chromium.org/p/chromium/issues/detail?id=398407\n * @param {string} protocol\n */\nfunction isValidSubprotocol (protocol) {\n  // If present, this value indicates one\n  // or more comma-separated subprotocol the client wishes to speak,\n  // ordered by preference.  The elements that comprise this value\n  // MUST be non-empty strings with characters in the range U+0021 to\n  // U+007E not including separator characters as defined in\n  // [RFC2616] and MUST all be unique strings.\n  if (protocol.length === 0) {\n    return false\n  }\n\n  for (const char of protocol) {\n    const code = char.charCodeAt(0)\n\n    if (\n      code < 0x21 ||\n      code > 0x7E ||\n      char === '(' ||\n      char === ')' ||\n      char === '<' ||\n      char === '>' ||\n      char === '@' ||\n      char === ',' ||\n      char === ';' ||\n      char === ':' ||\n      char === '\\\\' ||\n      char === '\"' ||\n      char === '/' ||\n      char === '[' ||\n      char === ']' ||\n      char === '?' ||\n      char === '=' ||\n      char === '{' ||\n      char === '}' ||\n      code === 32 || // SP\n      code === 9 // HT\n    ) {\n      return false\n    }\n  }\n\n  return true\n}\n\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7-4\n * @param {number} code\n */\nfunction isValidStatusCode (code) {\n  if (code >= 1000 && code < 1015) {\n    return (\n      code !== 1004 && // reserved\n      code !== 1005 && // \"MUST NOT be set as a status code\"\n      code !== 1006 // \"MUST NOT be set as a status code\"\n    )\n  }\n\n  return code >= 3000 && code <= 4999\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n * @param {string|undefined} reason\n */\nfunction failWebsocketConnection (ws, reason) {\n  const { [kController]: controller, [kResponse]: response } = ws\n\n  controller.abort()\n\n  if (response?.socket && !response.socket.destroyed) {\n    response.socket.destroy()\n  }\n\n  if (reason) {\n    fireEvent('error', ws, ErrorEvent, {\n      error: new Error(reason)\n    })\n  }\n}\n\nmodule.exports = {\n  isEstablished,\n  isClosing,\n  isClosed,\n  fireEvent,\n  isValidSubprotocol,\n  isValidStatusCode,\n  failWebsocketConnection,\n  websocketMessageReceived\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\nconst { DOMException } = require('../fetch/constants')\nconst { URLSerializer } = require('../fetch/dataURL')\nconst { getGlobalOrigin } = require('../fetch/global')\nconst { staticPropertyDescriptors, states, opcodes, emptyBuffer } = require('./constants')\nconst {\n  kWebSocketURL,\n  kReadyState,\n  kController,\n  kBinaryType,\n  kResponse,\n  kSentClose,\n  kByteParser\n} = require('./symbols')\nconst { isEstablished, isClosing, isValidSubprotocol, failWebsocketConnection, fireEvent } = require('./util')\nconst { establishWebSocketConnection } = require('./connection')\nconst { WebsocketFrameSend } = require('./frame')\nconst { ByteParser } = require('./receiver')\nconst { kEnumerableProperty, isBlobLike } = require('../core/util')\nconst { getGlobalDispatcher } = require('../global')\nconst { types } = require('util')\n\nlet experimentalWarned = false\n\n// https://websockets.spec.whatwg.org/#interface-definition\nclass WebSocket extends EventTarget {\n  #events = {\n    open: null,\n    error: null,\n    close: null,\n    message: null\n  }\n\n  #bufferedAmount = 0\n  #protocol = ''\n  #extensions = ''\n\n  /**\n   * @param {string} url\n   * @param {string|string[]} protocols\n   */\n  constructor (url, protocols = []) {\n    super()\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'WebSocket constructor' })\n\n    if (!experimentalWarned) {\n      experimentalWarned = true\n      process.emitWarning('WebSockets are experimental, expect them to change at any time.', {\n        code: 'UNDICI-WS'\n      })\n    }\n\n    const options = webidl.converters['DOMString or sequence<DOMString> or WebSocketInit'](protocols)\n\n    url = webidl.converters.USVString(url)\n    protocols = options.protocols\n\n    // 1. Let baseURL be this's relevant settings object's API base URL.\n    const baseURL = getGlobalOrigin()\n\n    // 1. Let urlRecord be the result of applying the URL parser to url with baseURL.\n    let urlRecord\n\n    try {\n      urlRecord = new URL(url, baseURL)\n    } catch (e) {\n      // 3. If urlRecord is failure, then throw a \"SyntaxError\" DOMException.\n      throw new DOMException(e, 'SyntaxError')\n    }\n\n    // 4. If urlRecords scheme is \"http\", then set urlRecords scheme to \"ws\".\n    if (urlRecord.protocol === 'http:') {\n      urlRecord.protocol = 'ws:'\n    } else if (urlRecord.protocol === 'https:') {\n      // 5. Otherwise, if urlRecords scheme is \"https\", set urlRecords scheme to \"wss\".\n      urlRecord.protocol = 'wss:'\n    }\n\n    // 6. If urlRecords scheme is not \"ws\" or \"wss\", then throw a \"SyntaxError\" DOMException.\n    if (urlRecord.protocol !== 'ws:' && urlRecord.protocol !== 'wss:') {\n      throw new DOMException(\n        `Expected a ws: or wss: protocol, got ${urlRecord.protocol}`,\n        'SyntaxError'\n      )\n    }\n\n    // 7. If urlRecords fragment is non-null, then throw a \"SyntaxError\"\n    //    DOMException.\n    if (urlRecord.hash || urlRecord.href.endsWith('#')) {\n      throw new DOMException('Got fragment', 'SyntaxError')\n    }\n\n    // 8. If protocols is a string, set protocols to a sequence consisting\n    //    of just that string.\n    if (typeof protocols === 'string') {\n      protocols = [protocols]\n    }\n\n    // 9. If any of the values in protocols occur more than once or otherwise\n    //    fail to match the requirements for elements that comprise the value\n    //    of `Sec-WebSocket-Protocol` fields as defined by The WebSocket\n    //    protocol, then throw a \"SyntaxError\" DOMException.\n    if (protocols.length !== new Set(protocols.map(p => p.toLowerCase())).size) {\n      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')\n    }\n\n    if (protocols.length > 0 && !protocols.every(p => isValidSubprotocol(p))) {\n      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')\n    }\n\n    // 10. Set this's url to urlRecord.\n    this[kWebSocketURL] = new URL(urlRecord.href)\n\n    // 11. Let client be this's relevant settings object.\n\n    // 12. Run this step in parallel:\n\n    //    1. Establish a WebSocket connection given urlRecord, protocols,\n    //       and client.\n    this[kController] = establishWebSocketConnection(\n      urlRecord,\n      protocols,\n      this,\n      (response) => this.#onConnectionEstablished(response),\n      options\n    )\n\n    // Each WebSocket object has an associated ready state, which is a\n    // number representing the state of the connection. Initially it must\n    // be CONNECTING (0).\n    this[kReadyState] = WebSocket.CONNECTING\n\n    // The extensions attribute must initially return the empty string.\n\n    // The protocol attribute must initially return the empty string.\n\n    // Each WebSocket object has an associated binary type, which is a\n    // BinaryType. Initially it must be \"blob\".\n    this[kBinaryType] = 'blob'\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#dom-websocket-close\n   * @param {number|undefined} code\n   * @param {string|undefined} reason\n   */\n  close (code = undefined, reason = undefined) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (code !== undefined) {\n      code = webidl.converters['unsigned short'](code, { clamp: true })\n    }\n\n    if (reason !== undefined) {\n      reason = webidl.converters.USVString(reason)\n    }\n\n    // 1. If code is present, but is neither an integer equal to 1000 nor an\n    //    integer in the range 3000 to 4999, inclusive, throw an\n    //    \"InvalidAccessError\" DOMException.\n    if (code !== undefined) {\n      if (code !== 1000 && (code < 3000 || code > 4999)) {\n        throw new DOMException('invalid code', 'InvalidAccessError')\n      }\n    }\n\n    let reasonByteLength = 0\n\n    // 2. If reason is present, then run these substeps:\n    if (reason !== undefined) {\n      // 1. Let reasonBytes be the result of encoding reason.\n      // 2. If reasonBytes is longer than 123 bytes, then throw a\n      //    \"SyntaxError\" DOMException.\n      reasonByteLength = Buffer.byteLength(reason)\n\n      if (reasonByteLength > 123) {\n        throw new DOMException(\n          `Reason must be less than 123 bytes; received ${reasonByteLength}`,\n          'SyntaxError'\n        )\n      }\n    }\n\n    // 3. Run the first matching steps from the following list:\n    if (this[kReadyState] === WebSocket.CLOSING || this[kReadyState] === WebSocket.CLOSED) {\n      // If this's ready state is CLOSING (2) or CLOSED (3)\n      // Do nothing.\n    } else if (!isEstablished(this)) {\n      // If the WebSocket connection is not yet established\n      // Fail the WebSocket connection and set this's ready state\n      // to CLOSING (2).\n      failWebsocketConnection(this, 'Connection was closed before it was established.')\n      this[kReadyState] = WebSocket.CLOSING\n    } else if (!isClosing(this)) {\n      // If the WebSocket closing handshake has not yet been started\n      // Start the WebSocket closing handshake and set this's ready\n      // state to CLOSING (2).\n      // - If neither code nor reason is present, the WebSocket Close\n      //   message must not have a body.\n      // - If code is present, then the status code to use in the\n      //   WebSocket Close message must be the integer given by code.\n      // - If reason is also present, then reasonBytes must be\n      //   provided in the Close message after the status code.\n\n      const frame = new WebsocketFrameSend()\n\n      // If neither code nor reason is present, the WebSocket Close\n      // message must not have a body.\n\n      // If code is present, then the status code to use in the\n      // WebSocket Close message must be the integer given by code.\n      if (code !== undefined && reason === undefined) {\n        frame.frameData = Buffer.allocUnsafe(2)\n        frame.frameData.writeUInt16BE(code, 0)\n      } else if (code !== undefined && reason !== undefined) {\n        // If reason is also present, then reasonBytes must be\n        // provided in the Close message after the status code.\n        frame.frameData = Buffer.allocUnsafe(2 + reasonByteLength)\n        frame.frameData.writeUInt16BE(code, 0)\n        // the body MAY contain UTF-8-encoded data with value /reason/\n        frame.frameData.write(reason, 2, 'utf-8')\n      } else {\n        frame.frameData = emptyBuffer\n      }\n\n      /** @type {import('stream').Duplex} */\n      const socket = this[kResponse].socket\n\n      socket.write(frame.createFrame(opcodes.CLOSE), (err) => {\n        if (!err) {\n          this[kSentClose] = true\n        }\n      })\n\n      // Upon either sending or receiving a Close control frame, it is said\n      // that _The WebSocket Closing Handshake is Started_ and that the\n      // WebSocket connection is in the CLOSING state.\n      this[kReadyState] = states.CLOSING\n    } else {\n      // Otherwise\n      // Set this's ready state to CLOSING (2).\n      this[kReadyState] = WebSocket.CLOSING\n    }\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#dom-websocket-send\n   * @param {NodeJS.TypedArray|ArrayBuffer|Blob|string} data\n   */\n  send (data) {\n    webidl.brandCheck(this, WebSocket)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'WebSocket.send' })\n\n    data = webidl.converters.WebSocketSendData(data)\n\n    // 1. If this's ready state is CONNECTING, then throw an\n    //    \"InvalidStateError\" DOMException.\n    if (this[kReadyState] === WebSocket.CONNECTING) {\n      throw new DOMException('Sent before connected.', 'InvalidStateError')\n    }\n\n    // 2. Run the appropriate set of steps from the following list:\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-6.1\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-5.2\n\n    if (!isEstablished(this) || isClosing(this)) {\n      return\n    }\n\n    /** @type {import('stream').Duplex} */\n    const socket = this[kResponse].socket\n\n    // If data is a string\n    if (typeof data === 'string') {\n      // If the WebSocket connection is established and the WebSocket\n      // closing handshake has not yet started, then the user agent\n      // must send a WebSocket Message comprised of the data argument\n      // using a text frame opcode; if the data cannot be sent, e.g.\n      // because it would need to be buffered but the buffer is full,\n      // the user agent must flag the WebSocket as full and then close\n      // the WebSocket connection. Any invocation of this method with a\n      // string argument that does not throw an exception must increase\n      // the bufferedAmount attribute by the number of bytes needed to\n      // express the argument as UTF-8.\n\n      const value = Buffer.from(data)\n      const frame = new WebsocketFrameSend(value)\n      const buffer = frame.createFrame(opcodes.TEXT)\n\n      this.#bufferedAmount += value.byteLength\n      socket.write(buffer, () => {\n        this.#bufferedAmount -= value.byteLength\n      })\n    } else if (types.isArrayBuffer(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need\n      // to be buffered but the buffer is full, the user agent must flag\n      // the WebSocket as full and then close the WebSocket connection.\n      // The data to be sent is the data stored in the buffer described\n      // by the ArrayBuffer object. Any invocation of this method with an\n      // ArrayBuffer argument that does not throw an exception must\n      // increase the bufferedAmount attribute by the length of the\n      // ArrayBuffer in bytes.\n\n      const value = Buffer.from(data)\n      const frame = new WebsocketFrameSend(value)\n      const buffer = frame.createFrame(opcodes.BINARY)\n\n      this.#bufferedAmount += value.byteLength\n      socket.write(buffer, () => {\n        this.#bufferedAmount -= value.byteLength\n      })\n    } else if (ArrayBuffer.isView(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need to\n      // be buffered but the buffer is full, the user agent must flag the\n      // WebSocket as full and then close the WebSocket connection. The\n      // data to be sent is the data stored in the section of the buffer\n      // described by the ArrayBuffer object that data references. Any\n      // invocation of this method with this kind of argument that does\n      // not throw an exception must increase the bufferedAmount attribute\n      // by the length of datas buffer in bytes.\n\n      const ab = Buffer.from(data, data.byteOffset, data.byteLength)\n\n      const frame = new WebsocketFrameSend(ab)\n      const buffer = frame.createFrame(opcodes.BINARY)\n\n      this.#bufferedAmount += ab.byteLength\n      socket.write(buffer, () => {\n        this.#bufferedAmount -= ab.byteLength\n      })\n    } else if (isBlobLike(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need to\n      // be buffered but the buffer is full, the user agent must flag the\n      // WebSocket as full and then close the WebSocket connection. The data\n      // to be sent is the raw data represented by the Blob object. Any\n      // invocation of this method with a Blob argument that does not throw\n      // an exception must increase the bufferedAmount attribute by the size\n      // of the Blob objects raw data, in bytes.\n\n      const frame = new WebsocketFrameSend()\n\n      data.arrayBuffer().then((ab) => {\n        const value = Buffer.from(ab)\n        frame.frameData = value\n        const buffer = frame.createFrame(opcodes.BINARY)\n\n        this.#bufferedAmount += value.byteLength\n        socket.write(buffer, () => {\n          this.#bufferedAmount -= value.byteLength\n        })\n      })\n    }\n  }\n\n  get readyState () {\n    webidl.brandCheck(this, WebSocket)\n\n    // The readyState getter steps are to return this's ready state.\n    return this[kReadyState]\n  }\n\n  get bufferedAmount () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#bufferedAmount\n  }\n\n  get url () {\n    webidl.brandCheck(this, WebSocket)\n\n    // The url getter steps are to return this's url, serialized.\n    return URLSerializer(this[kWebSocketURL])\n  }\n\n  get extensions () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#extensions\n  }\n\n  get protocol () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#protocol\n  }\n\n  get onopen () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.open\n  }\n\n  set onopen (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.open) {\n      this.removeEventListener('open', this.#events.open)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.open = fn\n      this.addEventListener('open', fn)\n    } else {\n      this.#events.open = null\n    }\n  }\n\n  get onerror () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.error\n  }\n\n  set onerror (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.error) {\n      this.removeEventListener('error', this.#events.error)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.error = fn\n      this.addEventListener('error', fn)\n    } else {\n      this.#events.error = null\n    }\n  }\n\n  get onclose () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.close\n  }\n\n  set onclose (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.close) {\n      this.removeEventListener('close', this.#events.close)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.close = fn\n      this.addEventListener('close', fn)\n    } else {\n      this.#events.close = null\n    }\n  }\n\n  get onmessage () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.message\n  }\n\n  set onmessage (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.message) {\n      this.removeEventListener('message', this.#events.message)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.message = fn\n      this.addEventListener('message', fn)\n    } else {\n      this.#events.message = null\n    }\n  }\n\n  get binaryType () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this[kBinaryType]\n  }\n\n  set binaryType (type) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (type !== 'blob' && type !== 'arraybuffer') {\n      this[kBinaryType] = 'blob'\n    } else {\n      this[kBinaryType] = type\n    }\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n   */\n  #onConnectionEstablished (response) {\n    // processResponse is called when the \"responses header list has been received and initialized.\"\n    // once this happens, the connection is open\n    this[kResponse] = response\n\n    const parser = new ByteParser(this)\n    parser.on('drain', function onParserDrain () {\n      this.ws[kResponse].socket.resume()\n    })\n\n    response.socket.ws = this\n    this[kByteParser] = parser\n\n    // 1. Change the ready state to OPEN (1).\n    this[kReadyState] = states.OPEN\n\n    // 2. Change the extensions attributes value to the extensions in use, if\n    //    it is not the null value.\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-9.1\n    const extensions = response.headersList.get('sec-websocket-extensions')\n\n    if (extensions !== null) {\n      this.#extensions = extensions\n    }\n\n    // 3. Change the protocol attributes value to the subprotocol in use, if\n    //    it is not the null value.\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-1.9\n    const protocol = response.headersList.get('sec-websocket-protocol')\n\n    if (protocol !== null) {\n      this.#protocol = protocol\n    }\n\n    // 4. Fire an event named open at the WebSocket object.\n    fireEvent('open', this)\n  }\n}\n\n// https://websockets.spec.whatwg.org/#dom-websocket-connecting\nWebSocket.CONNECTING = WebSocket.prototype.CONNECTING = states.CONNECTING\n// https://websockets.spec.whatwg.org/#dom-websocket-open\nWebSocket.OPEN = WebSocket.prototype.OPEN = states.OPEN\n// https://websockets.spec.whatwg.org/#dom-websocket-closing\nWebSocket.CLOSING = WebSocket.prototype.CLOSING = states.CLOSING\n// https://websockets.spec.whatwg.org/#dom-websocket-closed\nWebSocket.CLOSED = WebSocket.prototype.CLOSED = states.CLOSED\n\nObject.defineProperties(WebSocket.prototype, {\n  CONNECTING: staticPropertyDescriptors,\n  OPEN: staticPropertyDescriptors,\n  CLOSING: staticPropertyDescriptors,\n  CLOSED: staticPropertyDescriptors,\n  url: kEnumerableProperty,\n  readyState: kEnumerableProperty,\n  bufferedAmount: kEnumerableProperty,\n  onopen: kEnumerableProperty,\n  onerror: kEnumerableProperty,\n  onclose: kEnumerableProperty,\n  close: kEnumerableProperty,\n  onmessage: kEnumerableProperty,\n  binaryType: kEnumerableProperty,\n  send: kEnumerableProperty,\n  extensions: kEnumerableProperty,\n  protocol: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'WebSocket',\n    writable: false,\n    enumerable: false,\n    configurable: true\n  }\n})\n\nObject.defineProperties(WebSocket, {\n  CONNECTING: staticPropertyDescriptors,\n  OPEN: staticPropertyDescriptors,\n  CLOSING: staticPropertyDescriptors,\n  CLOSED: staticPropertyDescriptors\n})\n\nwebidl.converters['sequence<DOMString>'] = webidl.sequenceConverter(\n  webidl.converters.DOMString\n)\n\nwebidl.converters['DOMString or sequence<DOMString>'] = function (V) {\n  if (webidl.util.Type(V) === 'Object' && Symbol.iterator in V) {\n    return webidl.converters['sequence<DOMString>'](V)\n  }\n\n  return webidl.converters.DOMString(V)\n}\n\n// This implements the propsal made in https://github.com/whatwg/websockets/issues/42\nwebidl.converters.WebSocketInit = webidl.dictionaryConverter([\n  {\n    key: 'protocols',\n    converter: webidl.converters['DOMString or sequence<DOMString>'],\n    get defaultValue () {\n      return []\n    }\n  },\n  {\n    key: 'dispatcher',\n    converter: (V) => V,\n    get defaultValue () {\n      return getGlobalDispatcher()\n    }\n  },\n  {\n    key: 'headers',\n    converter: webidl.nullableConverter(webidl.converters.HeadersInit)\n  }\n])\n\nwebidl.converters['DOMString or sequence<DOMString> or WebSocketInit'] = function (V) {\n  if (webidl.util.Type(V) === 'Object' && !(Symbol.iterator in V)) {\n    return webidl.converters.WebSocketInit(V)\n  }\n\n  return { protocols: webidl.converters['DOMString or sequence<DOMString>'](V) }\n}\n\nwebidl.converters.WebSocketSendData = function (V) {\n  if (webidl.util.Type(V) === 'Object') {\n    if (isBlobLike(V)) {\n      return webidl.converters.Blob(V, { strict: false })\n    }\n\n    if (ArrayBuffer.isView(V) || types.isAnyArrayBuffer(V)) {\n      return webidl.converters.BufferSource(V)\n    }\n  }\n\n  return webidl.converters.USVString(V)\n}\n\nmodule.exports = {\n  WebSocket\n}\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction getUserAgent() {\n  if (typeof navigator === \"object\" && \"userAgent\" in navigator) {\n    return navigator.userAgent;\n  }\n\n  if (typeof process === \"object\" && process.version !== undefined) {\n    return `Node.js/${process.version.substr(1)} (${process.platform}; ${process.arch})`;\n  }\n\n  return \"<environment undetectable>\";\n}\n\nexports.getUserAgent = getUserAgent;\n//# sourceMappingURL=index.js.map\n","// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"assert\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"async_hooks\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"buffer\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"child_process\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"console\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"crypto\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"diagnostics_channel\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"events\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"fs\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"http\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"http2\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"https\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"net\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:crypto\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:events\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:stream\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:util\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"os\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"path\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"perf_hooks\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"querystring\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"stream\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"stream/web\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"string_decoder\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"timers\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"tls\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"url\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"util\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"util/types\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"worker_threads\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"zlib\");","'use strict'\n\nconst WritableStream = require('node:stream').Writable\nconst inherits = require('node:util').inherits\n\nconst StreamSearch = require('../../streamsearch/sbmh')\n\nconst PartStream = require('./PartStream')\nconst HeaderParser = require('./HeaderParser')\n\nconst DASH = 45\nconst B_ONEDASH = Buffer.from('-')\nconst B_CRLF = Buffer.from('\\r\\n')\nconst EMPTY_FN = function () {}\n\nfunction Dicer (cfg) {\n  if (!(this instanceof Dicer)) { return new Dicer(cfg) }\n  WritableStream.call(this, cfg)\n\n  if (!cfg || (!cfg.headerFirst && typeof cfg.boundary !== 'string')) { throw new TypeError('Boundary required') }\n\n  if (typeof cfg.boundary === 'string') { this.setBoundary(cfg.boundary) } else { this._bparser = undefined }\n\n  this._headerFirst = cfg.headerFirst\n\n  this._dashes = 0\n  this._parts = 0\n  this._finished = false\n  this._realFinish = false\n  this._isPreamble = true\n  this._justMatched = false\n  this._firstWrite = true\n  this._inHeader = true\n  this._part = undefined\n  this._cb = undefined\n  this._ignoreData = false\n  this._partOpts = { highWaterMark: cfg.partHwm }\n  this._pause = false\n\n  const self = this\n  this._hparser = new HeaderParser(cfg)\n  this._hparser.on('header', function (header) {\n    self._inHeader = false\n    self._part.emit('header', header)\n  })\n}\ninherits(Dicer, WritableStream)\n\nDicer.prototype.emit = function (ev) {\n  if (ev === 'finish' && !this._realFinish) {\n    if (!this._finished) {\n      const self = this\n      process.nextTick(function () {\n        self.emit('error', new Error('Unexpected end of multipart data'))\n        if (self._part && !self._ignoreData) {\n          const type = (self._isPreamble ? 'Preamble' : 'Part')\n          self._part.emit('error', new Error(type + ' terminated early due to unexpected end of multipart data'))\n          self._part.push(null)\n          process.nextTick(function () {\n            self._realFinish = true\n            self.emit('finish')\n            self._realFinish = false\n          })\n          return\n        }\n        self._realFinish = true\n        self.emit('finish')\n        self._realFinish = false\n      })\n    }\n  } else { WritableStream.prototype.emit.apply(this, arguments) }\n}\n\nDicer.prototype._write = function (data, encoding, cb) {\n  // ignore unexpected data (e.g. extra trailer data after finished)\n  if (!this._hparser && !this._bparser) { return cb() }\n\n  if (this._headerFirst && this._isPreamble) {\n    if (!this._part) {\n      this._part = new PartStream(this._partOpts)\n      if (this.listenerCount('preamble') !== 0) { this.emit('preamble', this._part) } else { this._ignore() }\n    }\n    const r = this._hparser.push(data)\n    if (!this._inHeader && r !== undefined && r < data.length) { data = data.slice(r) } else { return cb() }\n  }\n\n  // allows for \"easier\" testing\n  if (this._firstWrite) {\n    this._bparser.push(B_CRLF)\n    this._firstWrite = false\n  }\n\n  this._bparser.push(data)\n\n  if (this._pause) { this._cb = cb } else { cb() }\n}\n\nDicer.prototype.reset = function () {\n  this._part = undefined\n  this._bparser = undefined\n  this._hparser = undefined\n}\n\nDicer.prototype.setBoundary = function (boundary) {\n  const self = this\n  this._bparser = new StreamSearch('\\r\\n--' + boundary)\n  this._bparser.on('info', function (isMatch, data, start, end) {\n    self._oninfo(isMatch, data, start, end)\n  })\n}\n\nDicer.prototype._ignore = function () {\n  if (this._part && !this._ignoreData) {\n    this._ignoreData = true\n    this._part.on('error', EMPTY_FN)\n    // we must perform some kind of read on the stream even though we are\n    // ignoring the data, otherwise node's Readable stream will not emit 'end'\n    // after pushing null to the stream\n    this._part.resume()\n  }\n}\n\nDicer.prototype._oninfo = function (isMatch, data, start, end) {\n  let buf; const self = this; let i = 0; let r; let shouldWriteMore = true\n\n  if (!this._part && this._justMatched && data) {\n    while (this._dashes < 2 && (start + i) < end) {\n      if (data[start + i] === DASH) {\n        ++i\n        ++this._dashes\n      } else {\n        if (this._dashes) { buf = B_ONEDASH }\n        this._dashes = 0\n        break\n      }\n    }\n    if (this._dashes === 2) {\n      if ((start + i) < end && this.listenerCount('trailer') !== 0) { this.emit('trailer', data.slice(start + i, end)) }\n      this.reset()\n      this._finished = true\n      // no more parts will be added\n      if (self._parts === 0) {\n        self._realFinish = true\n        self.emit('finish')\n        self._realFinish = false\n      }\n    }\n    if (this._dashes) { return }\n  }\n  if (this._justMatched) { this._justMatched = false }\n  if (!this._part) {\n    this._part = new PartStream(this._partOpts)\n    this._part._read = function (n) {\n      self._unpause()\n    }\n    if (this._isPreamble && this.listenerCount('preamble') !== 0) {\n      this.emit('preamble', this._part)\n    } else if (this._isPreamble !== true && this.listenerCount('part') !== 0) {\n      this.emit('part', this._part)\n    } else {\n      this._ignore()\n    }\n    if (!this._isPreamble) { this._inHeader = true }\n  }\n  if (data && start < end && !this._ignoreData) {\n    if (this._isPreamble || !this._inHeader) {\n      if (buf) { shouldWriteMore = this._part.push(buf) }\n      shouldWriteMore = this._part.push(data.slice(start, end))\n      if (!shouldWriteMore) { this._pause = true }\n    } else if (!this._isPreamble && this._inHeader) {\n      if (buf) { this._hparser.push(buf) }\n      r = this._hparser.push(data.slice(start, end))\n      if (!this._inHeader && r !== undefined && r < end) { this._oninfo(false, data, start + r, end) }\n    }\n  }\n  if (isMatch) {\n    this._hparser.reset()\n    if (this._isPreamble) { this._isPreamble = false } else {\n      if (start !== end) {\n        ++this._parts\n        this._part.on('end', function () {\n          if (--self._parts === 0) {\n            if (self._finished) {\n              self._realFinish = true\n              self.emit('finish')\n              self._realFinish = false\n            } else {\n              self._unpause()\n            }\n          }\n        })\n      }\n    }\n    this._part.push(null)\n    this._part = undefined\n    this._ignoreData = false\n    this._justMatched = true\n    this._dashes = 0\n  }\n}\n\nDicer.prototype._unpause = function () {\n  if (!this._pause) { return }\n\n  this._pause = false\n  if (this._cb) {\n    const cb = this._cb\n    this._cb = undefined\n    cb()\n  }\n}\n\nmodule.exports = Dicer\n","'use strict'\n\nconst EventEmitter = require('node:events').EventEmitter\nconst inherits = require('node:util').inherits\nconst getLimit = require('../../../lib/utils/getLimit')\n\nconst StreamSearch = require('../../streamsearch/sbmh')\n\nconst B_DCRLF = Buffer.from('\\r\\n\\r\\n')\nconst RE_CRLF = /\\r\\n/g\nconst RE_HDR = /^([^:]+):[ \\t]?([\\x00-\\xFF]+)?$/ // eslint-disable-line no-control-regex\n\nfunction HeaderParser (cfg) {\n  EventEmitter.call(this)\n\n  cfg = cfg || {}\n  const self = this\n  this.nread = 0\n  this.maxed = false\n  this.npairs = 0\n  this.maxHeaderPairs = getLimit(cfg, 'maxHeaderPairs', 2000)\n  this.maxHeaderSize = getLimit(cfg, 'maxHeaderSize', 80 * 1024)\n  this.buffer = ''\n  this.header = {}\n  this.finished = false\n  this.ss = new StreamSearch(B_DCRLF)\n  this.ss.on('info', function (isMatch, data, start, end) {\n    if (data && !self.maxed) {\n      if (self.nread + end - start >= self.maxHeaderSize) {\n        end = self.maxHeaderSize - self.nread + start\n        self.nread = self.maxHeaderSize\n        self.maxed = true\n      } else { self.nread += (end - start) }\n\n      self.buffer += data.toString('binary', start, end)\n    }\n    if (isMatch) { self._finish() }\n  })\n}\ninherits(HeaderParser, EventEmitter)\n\nHeaderParser.prototype.push = function (data) {\n  const r = this.ss.push(data)\n  if (this.finished) { return r }\n}\n\nHeaderParser.prototype.reset = function () {\n  this.finished = false\n  this.buffer = ''\n  this.header = {}\n  this.ss.reset()\n}\n\nHeaderParser.prototype._finish = function () {\n  if (this.buffer) { this._parseHeader() }\n  this.ss.matches = this.ss.maxMatches\n  const header = this.header\n  this.header = {}\n  this.buffer = ''\n  this.finished = true\n  this.nread = this.npairs = 0\n  this.maxed = false\n  this.emit('header', header)\n}\n\nHeaderParser.prototype._parseHeader = function () {\n  if (this.npairs === this.maxHeaderPairs) { return }\n\n  const lines = this.buffer.split(RE_CRLF)\n  const len = lines.length\n  let m, h\n\n  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var\n    if (lines[i].length === 0) { continue }\n    if (lines[i][0] === '\\t' || lines[i][0] === ' ') {\n      // folded header content\n      // RFC2822 says to just remove the CRLF and not the whitespace following\n      // it, so we follow the RFC and include the leading whitespace ...\n      if (h) {\n        this.header[h][this.header[h].length - 1] += lines[i]\n        continue\n      }\n    }\n\n    const posColon = lines[i].indexOf(':')\n    if (\n      posColon === -1 ||\n      posColon === 0\n    ) {\n      return\n    }\n    m = RE_HDR.exec(lines[i])\n    h = m[1].toLowerCase()\n    this.header[h] = this.header[h] || []\n    this.header[h].push((m[2] || ''))\n    if (++this.npairs === this.maxHeaderPairs) { break }\n  }\n}\n\nmodule.exports = HeaderParser\n","'use strict'\n\nconst inherits = require('node:util').inherits\nconst ReadableStream = require('node:stream').Readable\n\nfunction PartStream (opts) {\n  ReadableStream.call(this, opts)\n}\ninherits(PartStream, ReadableStream)\n\nPartStream.prototype._read = function (n) {}\n\nmodule.exports = PartStream\n","'use strict'\n\n/**\n * Copyright Brian White. All rights reserved.\n *\n * @see https://github.com/mscdex/streamsearch\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to\n * deal in the Software without restriction, including without limitation the\n * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n * sell copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n *\n * Based heavily on the Streaming Boyer-Moore-Horspool C++ implementation\n * by Hongli Lai at: https://github.com/FooBarWidget/boyer-moore-horspool\n */\nconst EventEmitter = require('node:events').EventEmitter\nconst inherits = require('node:util').inherits\n\nfunction SBMH (needle) {\n  if (typeof needle === 'string') {\n    needle = Buffer.from(needle)\n  }\n\n  if (!Buffer.isBuffer(needle)) {\n    throw new TypeError('The needle has to be a String or a Buffer.')\n  }\n\n  const needleLength = needle.length\n\n  if (needleLength === 0) {\n    throw new Error('The needle cannot be an empty String/Buffer.')\n  }\n\n  if (needleLength > 256) {\n    throw new Error('The needle cannot have a length bigger than 256.')\n  }\n\n  this.maxMatches = Infinity\n  this.matches = 0\n\n  this._occ = new Array(256)\n    .fill(needleLength) // Initialize occurrence table.\n  this._lookbehind_size = 0\n  this._needle = needle\n  this._bufpos = 0\n\n  this._lookbehind = Buffer.alloc(needleLength)\n\n  // Populate occurrence table with analysis of the needle,\n  // ignoring last letter.\n  for (var i = 0; i < needleLength - 1; ++i) { // eslint-disable-line no-var\n    this._occ[needle[i]] = needleLength - 1 - i\n  }\n}\ninherits(SBMH, EventEmitter)\n\nSBMH.prototype.reset = function () {\n  this._lookbehind_size = 0\n  this.matches = 0\n  this._bufpos = 0\n}\n\nSBMH.prototype.push = function (chunk, pos) {\n  if (!Buffer.isBuffer(chunk)) {\n    chunk = Buffer.from(chunk, 'binary')\n  }\n  const chlen = chunk.length\n  this._bufpos = pos || 0\n  let r\n  while (r !== chlen && this.matches < this.maxMatches) { r = this._sbmh_feed(chunk) }\n  return r\n}\n\nSBMH.prototype._sbmh_feed = function (data) {\n  const len = data.length\n  const needle = this._needle\n  const needleLength = needle.length\n  const lastNeedleChar = needle[needleLength - 1]\n\n  // Positive: points to a position in `data`\n  //           pos == 3 points to data[3]\n  // Negative: points to a position in the lookbehind buffer\n  //           pos == -2 points to lookbehind[lookbehind_size - 2]\n  let pos = -this._lookbehind_size\n  let ch\n\n  if (pos < 0) {\n    // Lookbehind buffer is not empty. Perform Boyer-Moore-Horspool\n    // search with character lookup code that considers both the\n    // lookbehind buffer and the current round's haystack data.\n    //\n    // Loop until\n    //   there is a match.\n    // or until\n    //   we've moved past the position that requires the\n    //   lookbehind buffer. In this case we switch to the\n    //   optimized loop.\n    // or until\n    //   the character to look at lies outside the haystack.\n    while (pos < 0 && pos <= len - needleLength) {\n      ch = this._sbmh_lookup_char(data, pos + needleLength - 1)\n\n      if (\n        ch === lastNeedleChar &&\n        this._sbmh_memcmp(data, pos, needleLength - 1)\n      ) {\n        this._lookbehind_size = 0\n        ++this.matches\n        this.emit('info', true)\n\n        return (this._bufpos = pos + needleLength)\n      }\n      pos += this._occ[ch]\n    }\n\n    // No match.\n\n    if (pos < 0) {\n      // There's too few data for Boyer-Moore-Horspool to run,\n      // so let's use a different algorithm to skip as much as\n      // we can.\n      // Forward pos until\n      //   the trailing part of lookbehind + data\n      //   looks like the beginning of the needle\n      // or until\n      //   pos == 0\n      while (pos < 0 && !this._sbmh_memcmp(data, pos, len - pos)) { ++pos }\n    }\n\n    if (pos >= 0) {\n      // Discard lookbehind buffer.\n      this.emit('info', false, this._lookbehind, 0, this._lookbehind_size)\n      this._lookbehind_size = 0\n    } else {\n      // Cut off part of the lookbehind buffer that has\n      // been processed and append the entire haystack\n      // into it.\n      const bytesToCutOff = this._lookbehind_size + pos\n      if (bytesToCutOff > 0) {\n        // The cut off data is guaranteed not to contain the needle.\n        this.emit('info', false, this._lookbehind, 0, bytesToCutOff)\n      }\n\n      this._lookbehind.copy(this._lookbehind, 0, bytesToCutOff,\n        this._lookbehind_size - bytesToCutOff)\n      this._lookbehind_size -= bytesToCutOff\n\n      data.copy(this._lookbehind, this._lookbehind_size)\n      this._lookbehind_size += len\n\n      this._bufpos = len\n      return len\n    }\n  }\n\n  pos += (pos >= 0) * this._bufpos\n\n  // Lookbehind buffer is now empty. We only need to check if the\n  // needle is in the haystack.\n  if (data.indexOf(needle, pos) !== -1) {\n    pos = data.indexOf(needle, pos)\n    ++this.matches\n    if (pos > 0) { this.emit('info', true, data, this._bufpos, pos) } else { this.emit('info', true) }\n\n    return (this._bufpos = pos + needleLength)\n  } else {\n    pos = len - needleLength\n  }\n\n  // There was no match. If there's trailing haystack data that we cannot\n  // match yet using the Boyer-Moore-Horspool algorithm (because the trailing\n  // data is less than the needle size) then match using a modified\n  // algorithm that starts matching from the beginning instead of the end.\n  // Whatever trailing data is left after running this algorithm is added to\n  // the lookbehind buffer.\n  while (\n    pos < len &&\n    (\n      data[pos] !== needle[0] ||\n      (\n        (Buffer.compare(\n          data.subarray(pos, pos + len - pos),\n          needle.subarray(0, len - pos)\n        ) !== 0)\n      )\n    )\n  ) {\n    ++pos\n  }\n  if (pos < len) {\n    data.copy(this._lookbehind, 0, pos, pos + (len - pos))\n    this._lookbehind_size = len - pos\n  }\n\n  // Everything until pos is guaranteed not to contain needle data.\n  if (pos > 0) { this.emit('info', false, data, this._bufpos, pos < len ? pos : len) }\n\n  this._bufpos = len\n  return len\n}\n\nSBMH.prototype._sbmh_lookup_char = function (data, pos) {\n  return (pos < 0)\n    ? this._lookbehind[this._lookbehind_size + pos]\n    : data[pos]\n}\n\nSBMH.prototype._sbmh_memcmp = function (data, pos, len) {\n  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var\n    if (this._sbmh_lookup_char(data, pos + i) !== this._needle[i]) { return false }\n  }\n  return true\n}\n\nmodule.exports = SBMH\n","'use strict'\n\nconst WritableStream = require('node:stream').Writable\nconst { inherits } = require('node:util')\nconst Dicer = require('../deps/dicer/lib/Dicer')\n\nconst MultipartParser = require('./types/multipart')\nconst UrlencodedParser = require('./types/urlencoded')\nconst parseParams = require('./utils/parseParams')\n\nfunction Busboy (opts) {\n  if (!(this instanceof Busboy)) { return new Busboy(opts) }\n\n  if (typeof opts !== 'object') {\n    throw new TypeError('Busboy expected an options-Object.')\n  }\n  if (typeof opts.headers !== 'object') {\n    throw new TypeError('Busboy expected an options-Object with headers-attribute.')\n  }\n  if (typeof opts.headers['content-type'] !== 'string') {\n    throw new TypeError('Missing Content-Type-header.')\n  }\n\n  const {\n    headers,\n    ...streamOptions\n  } = opts\n\n  this.opts = {\n    autoDestroy: false,\n    ...streamOptions\n  }\n  WritableStream.call(this, this.opts)\n\n  this._done = false\n  this._parser = this.getParserByHeaders(headers)\n  this._finished = false\n}\ninherits(Busboy, WritableStream)\n\nBusboy.prototype.emit = function (ev) {\n  if (ev === 'finish') {\n    if (!this._done) {\n      this._parser?.end()\n      return\n    } else if (this._finished) {\n      return\n    }\n    this._finished = true\n  }\n  WritableStream.prototype.emit.apply(this, arguments)\n}\n\nBusboy.prototype.getParserByHeaders = function (headers) {\n  const parsed = parseParams(headers['content-type'])\n\n  const cfg = {\n    defCharset: this.opts.defCharset,\n    fileHwm: this.opts.fileHwm,\n    headers,\n    highWaterMark: this.opts.highWaterMark,\n    isPartAFile: this.opts.isPartAFile,\n    limits: this.opts.limits,\n    parsedConType: parsed,\n    preservePath: this.opts.preservePath\n  }\n\n  if (MultipartParser.detect.test(parsed[0])) {\n    return new MultipartParser(this, cfg)\n  }\n  if (UrlencodedParser.detect.test(parsed[0])) {\n    return new UrlencodedParser(this, cfg)\n  }\n  throw new Error('Unsupported Content-Type.')\n}\n\nBusboy.prototype._write = function (chunk, encoding, cb) {\n  this._parser.write(chunk, cb)\n}\n\nmodule.exports = Busboy\nmodule.exports.default = Busboy\nmodule.exports.Busboy = Busboy\n\nmodule.exports.Dicer = Dicer\n","'use strict'\n\n// TODO:\n//  * support 1 nested multipart level\n//    (see second multipart example here:\n//     http://www.w3.org/TR/html401/interact/forms.html#didx-multipartform-data)\n//  * support limits.fieldNameSize\n//     -- this will require modifications to utils.parseParams\n\nconst { Readable } = require('node:stream')\nconst { inherits } = require('node:util')\n\nconst Dicer = require('../../deps/dicer/lib/Dicer')\n\nconst parseParams = require('../utils/parseParams')\nconst decodeText = require('../utils/decodeText')\nconst basename = require('../utils/basename')\nconst getLimit = require('../utils/getLimit')\n\nconst RE_BOUNDARY = /^boundary$/i\nconst RE_FIELD = /^form-data$/i\nconst RE_CHARSET = /^charset$/i\nconst RE_FILENAME = /^filename$/i\nconst RE_NAME = /^name$/i\n\nMultipart.detect = /^multipart\\/form-data/i\nfunction Multipart (boy, cfg) {\n  let i\n  let len\n  const self = this\n  let boundary\n  const limits = cfg.limits\n  const isPartAFile = cfg.isPartAFile || ((fieldName, contentType, fileName) => (contentType === 'application/octet-stream' || fileName !== undefined))\n  const parsedConType = cfg.parsedConType || []\n  const defCharset = cfg.defCharset || 'utf8'\n  const preservePath = cfg.preservePath\n  const fileOpts = { highWaterMark: cfg.fileHwm }\n\n  for (i = 0, len = parsedConType.length; i < len; ++i) {\n    if (Array.isArray(parsedConType[i]) &&\n      RE_BOUNDARY.test(parsedConType[i][0])) {\n      boundary = parsedConType[i][1]\n      break\n    }\n  }\n\n  function checkFinished () {\n    if (nends === 0 && finished && !boy._done) {\n      finished = false\n      self.end()\n    }\n  }\n\n  if (typeof boundary !== 'string') { throw new Error('Multipart: Boundary not found') }\n\n  const fieldSizeLimit = getLimit(limits, 'fieldSize', 1 * 1024 * 1024)\n  const fileSizeLimit = getLimit(limits, 'fileSize', Infinity)\n  const filesLimit = getLimit(limits, 'files', Infinity)\n  const fieldsLimit = getLimit(limits, 'fields', Infinity)\n  const partsLimit = getLimit(limits, 'parts', Infinity)\n  const headerPairsLimit = getLimit(limits, 'headerPairs', 2000)\n  const headerSizeLimit = getLimit(limits, 'headerSize', 80 * 1024)\n\n  let nfiles = 0\n  let nfields = 0\n  let nends = 0\n  let curFile\n  let curField\n  let finished = false\n\n  this._needDrain = false\n  this._pause = false\n  this._cb = undefined\n  this._nparts = 0\n  this._boy = boy\n\n  const parserCfg = {\n    boundary,\n    maxHeaderPairs: headerPairsLimit,\n    maxHeaderSize: headerSizeLimit,\n    partHwm: fileOpts.highWaterMark,\n    highWaterMark: cfg.highWaterMark\n  }\n\n  this.parser = new Dicer(parserCfg)\n  this.parser.on('drain', function () {\n    self._needDrain = false\n    if (self._cb && !self._pause) {\n      const cb = self._cb\n      self._cb = undefined\n      cb()\n    }\n  }).on('part', function onPart (part) {\n    if (++self._nparts > partsLimit) {\n      self.parser.removeListener('part', onPart)\n      self.parser.on('part', skipPart)\n      boy.hitPartsLimit = true\n      boy.emit('partsLimit')\n      return skipPart(part)\n    }\n\n    // hack because streams2 _always_ doesn't emit 'end' until nextTick, so let\n    // us emit 'end' early since we know the part has ended if we are already\n    // seeing the next part\n    if (curField) {\n      const field = curField\n      field.emit('end')\n      field.removeAllListeners('end')\n    }\n\n    part.on('header', function (header) {\n      let contype\n      let fieldname\n      let parsed\n      let charset\n      let encoding\n      let filename\n      let nsize = 0\n\n      if (header['content-type']) {\n        parsed = parseParams(header['content-type'][0])\n        if (parsed[0]) {\n          contype = parsed[0].toLowerCase()\n          for (i = 0, len = parsed.length; i < len; ++i) {\n            if (RE_CHARSET.test(parsed[i][0])) {\n              charset = parsed[i][1].toLowerCase()\n              break\n            }\n          }\n        }\n      }\n\n      if (contype === undefined) { contype = 'text/plain' }\n      if (charset === undefined) { charset = defCharset }\n\n      if (header['content-disposition']) {\n        parsed = parseParams(header['content-disposition'][0])\n        if (!RE_FIELD.test(parsed[0])) { return skipPart(part) }\n        for (i = 0, len = parsed.length; i < len; ++i) {\n          if (RE_NAME.test(parsed[i][0])) {\n            fieldname = parsed[i][1]\n          } else if (RE_FILENAME.test(parsed[i][0])) {\n            filename = parsed[i][1]\n            if (!preservePath) { filename = basename(filename) }\n          }\n        }\n      } else { return skipPart(part) }\n\n      if (header['content-transfer-encoding']) { encoding = header['content-transfer-encoding'][0].toLowerCase() } else { encoding = '7bit' }\n\n      let onData,\n        onEnd\n\n      if (isPartAFile(fieldname, contype, filename)) {\n        // file/binary field\n        if (nfiles === filesLimit) {\n          if (!boy.hitFilesLimit) {\n            boy.hitFilesLimit = true\n            boy.emit('filesLimit')\n          }\n          return skipPart(part)\n        }\n\n        ++nfiles\n\n        if (boy.listenerCount('file') === 0) {\n          self.parser._ignore()\n          return\n        }\n\n        ++nends\n        const file = new FileStream(fileOpts)\n        curFile = file\n        file.on('end', function () {\n          --nends\n          self._pause = false\n          checkFinished()\n          if (self._cb && !self._needDrain) {\n            const cb = self._cb\n            self._cb = undefined\n            cb()\n          }\n        })\n        file._read = function (n) {\n          if (!self._pause) { return }\n          self._pause = false\n          if (self._cb && !self._needDrain) {\n            const cb = self._cb\n            self._cb = undefined\n            cb()\n          }\n        }\n        boy.emit('file', fieldname, file, filename, encoding, contype)\n\n        onData = function (data) {\n          if ((nsize += data.length) > fileSizeLimit) {\n            const extralen = fileSizeLimit - nsize + data.length\n            if (extralen > 0) { file.push(data.slice(0, extralen)) }\n            file.truncated = true\n            file.bytesRead = fileSizeLimit\n            part.removeAllListeners('data')\n            file.emit('limit')\n            return\n          } else if (!file.push(data)) { self._pause = true }\n\n          file.bytesRead = nsize\n        }\n\n        onEnd = function () {\n          curFile = undefined\n          file.push(null)\n        }\n      } else {\n        // non-file field\n        if (nfields === fieldsLimit) {\n          if (!boy.hitFieldsLimit) {\n            boy.hitFieldsLimit = true\n            boy.emit('fieldsLimit')\n          }\n          return skipPart(part)\n        }\n\n        ++nfields\n        ++nends\n        let buffer = ''\n        let truncated = false\n        curField = part\n\n        onData = function (data) {\n          if ((nsize += data.length) > fieldSizeLimit) {\n            const extralen = (fieldSizeLimit - (nsize - data.length))\n            buffer += data.toString('binary', 0, extralen)\n            truncated = true\n            part.removeAllListeners('data')\n          } else { buffer += data.toString('binary') }\n        }\n\n        onEnd = function () {\n          curField = undefined\n          if (buffer.length) { buffer = decodeText(buffer, 'binary', charset) }\n          boy.emit('field', fieldname, buffer, false, truncated, encoding, contype)\n          --nends\n          checkFinished()\n        }\n      }\n\n      /* As of node@2efe4ab761666 (v0.10.29+/v0.11.14+), busboy had become\n         broken. Streams2/streams3 is a huge black box of confusion, but\n         somehow overriding the sync state seems to fix things again (and still\n         seems to work for previous node versions).\n      */\n      part._readableState.sync = false\n\n      part.on('data', onData)\n      part.on('end', onEnd)\n    }).on('error', function (err) {\n      if (curFile) { curFile.emit('error', err) }\n    })\n  }).on('error', function (err) {\n    boy.emit('error', err)\n  }).on('finish', function () {\n    finished = true\n    checkFinished()\n  })\n}\n\nMultipart.prototype.write = function (chunk, cb) {\n  const r = this.parser.write(chunk)\n  if (r && !this._pause) {\n    cb()\n  } else {\n    this._needDrain = !r\n    this._cb = cb\n  }\n}\n\nMultipart.prototype.end = function () {\n  const self = this\n\n  if (self.parser.writable) {\n    self.parser.end()\n  } else if (!self._boy._done) {\n    process.nextTick(function () {\n      self._boy._done = true\n      self._boy.emit('finish')\n    })\n  }\n}\n\nfunction skipPart (part) {\n  part.resume()\n}\n\nfunction FileStream (opts) {\n  Readable.call(this, opts)\n\n  this.bytesRead = 0\n\n  this.truncated = false\n}\n\ninherits(FileStream, Readable)\n\nFileStream.prototype._read = function (n) {}\n\nmodule.exports = Multipart\n","'use strict'\n\nconst Decoder = require('../utils/Decoder')\nconst decodeText = require('../utils/decodeText')\nconst getLimit = require('../utils/getLimit')\n\nconst RE_CHARSET = /^charset$/i\n\nUrlEncoded.detect = /^application\\/x-www-form-urlencoded/i\nfunction UrlEncoded (boy, cfg) {\n  const limits = cfg.limits\n  const parsedConType = cfg.parsedConType\n  this.boy = boy\n\n  this.fieldSizeLimit = getLimit(limits, 'fieldSize', 1 * 1024 * 1024)\n  this.fieldNameSizeLimit = getLimit(limits, 'fieldNameSize', 100)\n  this.fieldsLimit = getLimit(limits, 'fields', Infinity)\n\n  let charset\n  for (var i = 0, len = parsedConType.length; i < len; ++i) { // eslint-disable-line no-var\n    if (Array.isArray(parsedConType[i]) &&\n        RE_CHARSET.test(parsedConType[i][0])) {\n      charset = parsedConType[i][1].toLowerCase()\n      break\n    }\n  }\n\n  if (charset === undefined) { charset = cfg.defCharset || 'utf8' }\n\n  this.decoder = new Decoder()\n  this.charset = charset\n  this._fields = 0\n  this._state = 'key'\n  this._checkingBytes = true\n  this._bytesKey = 0\n  this._bytesVal = 0\n  this._key = ''\n  this._val = ''\n  this._keyTrunc = false\n  this._valTrunc = false\n  this._hitLimit = false\n}\n\nUrlEncoded.prototype.write = function (data, cb) {\n  if (this._fields === this.fieldsLimit) {\n    if (!this.boy.hitFieldsLimit) {\n      this.boy.hitFieldsLimit = true\n      this.boy.emit('fieldsLimit')\n    }\n    return cb()\n  }\n\n  let idxeq; let idxamp; let i; let p = 0; const len = data.length\n\n  while (p < len) {\n    if (this._state === 'key') {\n      idxeq = idxamp = undefined\n      for (i = p; i < len; ++i) {\n        if (!this._checkingBytes) { ++p }\n        if (data[i] === 0x3D/* = */) {\n          idxeq = i\n          break\n        } else if (data[i] === 0x26/* & */) {\n          idxamp = i\n          break\n        }\n        if (this._checkingBytes && this._bytesKey === this.fieldNameSizeLimit) {\n          this._hitLimit = true\n          break\n        } else if (this._checkingBytes) { ++this._bytesKey }\n      }\n\n      if (idxeq !== undefined) {\n        // key with assignment\n        if (idxeq > p) { this._key += this.decoder.write(data.toString('binary', p, idxeq)) }\n        this._state = 'val'\n\n        this._hitLimit = false\n        this._checkingBytes = true\n        this._val = ''\n        this._bytesVal = 0\n        this._valTrunc = false\n        this.decoder.reset()\n\n        p = idxeq + 1\n      } else if (idxamp !== undefined) {\n        // key with no assignment\n        ++this._fields\n        let key; const keyTrunc = this._keyTrunc\n        if (idxamp > p) { key = (this._key += this.decoder.write(data.toString('binary', p, idxamp))) } else { key = this._key }\n\n        this._hitLimit = false\n        this._checkingBytes = true\n        this._key = ''\n        this._bytesKey = 0\n        this._keyTrunc = false\n        this.decoder.reset()\n\n        if (key.length) {\n          this.boy.emit('field', decodeText(key, 'binary', this.charset),\n            '',\n            keyTrunc,\n            false)\n        }\n\n        p = idxamp + 1\n        if (this._fields === this.fieldsLimit) { return cb() }\n      } else if (this._hitLimit) {\n        // we may not have hit the actual limit if there are encoded bytes...\n        if (i > p) { this._key += this.decoder.write(data.toString('binary', p, i)) }\n        p = i\n        if ((this._bytesKey = this._key.length) === this.fieldNameSizeLimit) {\n          // yep, we actually did hit the limit\n          this._checkingBytes = false\n          this._keyTrunc = true\n        }\n      } else {\n        if (p < len) { this._key += this.decoder.write(data.toString('binary', p)) }\n        p = len\n      }\n    } else {\n      idxamp = undefined\n      for (i = p; i < len; ++i) {\n        if (!this._checkingBytes) { ++p }\n        if (data[i] === 0x26/* & */) {\n          idxamp = i\n          break\n        }\n        if (this._checkingBytes && this._bytesVal === this.fieldSizeLimit) {\n          this._hitLimit = true\n          break\n        } else if (this._checkingBytes) { ++this._bytesVal }\n      }\n\n      if (idxamp !== undefined) {\n        ++this._fields\n        if (idxamp > p) { this._val += this.decoder.write(data.toString('binary', p, idxamp)) }\n        this.boy.emit('field', decodeText(this._key, 'binary', this.charset),\n          decodeText(this._val, 'binary', this.charset),\n          this._keyTrunc,\n          this._valTrunc)\n        this._state = 'key'\n\n        this._hitLimit = false\n        this._checkingBytes = true\n        this._key = ''\n        this._bytesKey = 0\n        this._keyTrunc = false\n        this.decoder.reset()\n\n        p = idxamp + 1\n        if (this._fields === this.fieldsLimit) { return cb() }\n      } else if (this._hitLimit) {\n        // we may not have hit the actual limit if there are encoded bytes...\n        if (i > p) { this._val += this.decoder.write(data.toString('binary', p, i)) }\n        p = i\n        if ((this._val === '' && this.fieldSizeLimit === 0) ||\n            (this._bytesVal = this._val.length) === this.fieldSizeLimit) {\n          // yep, we actually did hit the limit\n          this._checkingBytes = false\n          this._valTrunc = true\n        }\n      } else {\n        if (p < len) { this._val += this.decoder.write(data.toString('binary', p)) }\n        p = len\n      }\n    }\n  }\n  cb()\n}\n\nUrlEncoded.prototype.end = function () {\n  if (this.boy._done) { return }\n\n  if (this._state === 'key' && this._key.length > 0) {\n    this.boy.emit('field', decodeText(this._key, 'binary', this.charset),\n      '',\n      this._keyTrunc,\n      false)\n  } else if (this._state === 'val') {\n    this.boy.emit('field', decodeText(this._key, 'binary', this.charset),\n      decodeText(this._val, 'binary', this.charset),\n      this._keyTrunc,\n      this._valTrunc)\n  }\n  this.boy._done = true\n  this.boy.emit('finish')\n}\n\nmodule.exports = UrlEncoded\n","'use strict'\n\nconst RE_PLUS = /\\+/g\n\nconst HEX = [\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n  0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n]\n\nfunction Decoder () {\n  this.buffer = undefined\n}\nDecoder.prototype.write = function (str) {\n  // Replace '+' with ' ' before decoding\n  str = str.replace(RE_PLUS, ' ')\n  let res = ''\n  let i = 0; let p = 0; const len = str.length\n  for (; i < len; ++i) {\n    if (this.buffer !== undefined) {\n      if (!HEX[str.charCodeAt(i)]) {\n        res += '%' + this.buffer\n        this.buffer = undefined\n        --i // retry character\n      } else {\n        this.buffer += str[i]\n        ++p\n        if (this.buffer.length === 2) {\n          res += String.fromCharCode(parseInt(this.buffer, 16))\n          this.buffer = undefined\n        }\n      }\n    } else if (str[i] === '%') {\n      if (i > p) {\n        res += str.substring(p, i)\n        p = i\n      }\n      this.buffer = ''\n      ++p\n    }\n  }\n  if (p < len && this.buffer === undefined) { res += str.substring(p) }\n  return res\n}\nDecoder.prototype.reset = function () {\n  this.buffer = undefined\n}\n\nmodule.exports = Decoder\n","'use strict'\n\nmodule.exports = function basename (path) {\n  if (typeof path !== 'string') { return '' }\n  for (var i = path.length - 1; i >= 0; --i) { // eslint-disable-line no-var\n    switch (path.charCodeAt(i)) {\n      case 0x2F: // '/'\n      case 0x5C: // '\\'\n        path = path.slice(i + 1)\n        return (path === '..' || path === '.' ? '' : path)\n    }\n  }\n  return (path === '..' || path === '.' ? '' : path)\n}\n","'use strict'\n\n// Node has always utf-8\nconst utf8Decoder = new TextDecoder('utf-8')\nconst textDecoders = new Map([\n  ['utf-8', utf8Decoder],\n  ['utf8', utf8Decoder]\n])\n\nfunction getDecoder (charset) {\n  let lc\n  while (true) {\n    switch (charset) {\n      case 'utf-8':\n      case 'utf8':\n        return decoders.utf8\n      case 'latin1':\n      case 'ascii': // TODO: Make these a separate, strict decoder?\n      case 'us-ascii':\n      case 'iso-8859-1':\n      case 'iso8859-1':\n      case 'iso88591':\n      case 'iso_8859-1':\n      case 'windows-1252':\n      case 'iso_8859-1:1987':\n      case 'cp1252':\n      case 'x-cp1252':\n        return decoders.latin1\n      case 'utf16le':\n      case 'utf-16le':\n      case 'ucs2':\n      case 'ucs-2':\n        return decoders.utf16le\n      case 'base64':\n        return decoders.base64\n      default:\n        if (lc === undefined) {\n          lc = true\n          charset = charset.toLowerCase()\n          continue\n        }\n        return decoders.other.bind(charset)\n    }\n  }\n}\n\nconst decoders = {\n  utf8: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n    return data.utf8Slice(0, data.length)\n  },\n\n  latin1: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      return data\n    }\n    return data.latin1Slice(0, data.length)\n  },\n\n  utf16le: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n    return data.ucs2Slice(0, data.length)\n  },\n\n  base64: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n    return data.base64Slice(0, data.length)\n  },\n\n  other: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n\n    if (textDecoders.has(this.toString())) {\n      try {\n        return textDecoders.get(this).decode(data)\n      } catch {}\n    }\n    return typeof data === 'string'\n      ? data\n      : data.toString()\n  }\n}\n\nfunction decodeText (text, sourceEncoding, destEncoding) {\n  if (text) {\n    return getDecoder(destEncoding)(text, sourceEncoding)\n  }\n  return text\n}\n\nmodule.exports = decodeText\n","'use strict'\n\nmodule.exports = function getLimit (limits, name, defaultLimit) {\n  if (\n    !limits ||\n    limits[name] === undefined ||\n    limits[name] === null\n  ) { return defaultLimit }\n\n  if (\n    typeof limits[name] !== 'number' ||\n    isNaN(limits[name])\n  ) { throw new TypeError('Limit ' + name + ' is not a valid number') }\n\n  return limits[name]\n}\n","/* eslint-disable object-property-newline */\n'use strict'\n\nconst decodeText = require('./decodeText')\n\nconst RE_ENCODED = /%[a-fA-F0-9][a-fA-F0-9]/g\n\nconst EncodedLookup = {\n  '%00': '\\x00', '%01': '\\x01', '%02': '\\x02', '%03': '\\x03', '%04': '\\x04',\n  '%05': '\\x05', '%06': '\\x06', '%07': '\\x07', '%08': '\\x08', '%09': '\\x09',\n  '%0a': '\\x0a', '%0A': '\\x0a', '%0b': '\\x0b', '%0B': '\\x0b', '%0c': '\\x0c',\n  '%0C': '\\x0c', '%0d': '\\x0d', '%0D': '\\x0d', '%0e': '\\x0e', '%0E': '\\x0e',\n  '%0f': '\\x0f', '%0F': '\\x0f', '%10': '\\x10', '%11': '\\x11', '%12': '\\x12',\n  '%13': '\\x13', '%14': '\\x14', '%15': '\\x15', '%16': '\\x16', '%17': '\\x17',\n  '%18': '\\x18', '%19': '\\x19', '%1a': '\\x1a', '%1A': '\\x1a', '%1b': '\\x1b',\n  '%1B': '\\x1b', '%1c': '\\x1c', '%1C': '\\x1c', '%1d': '\\x1d', '%1D': '\\x1d',\n  '%1e': '\\x1e', '%1E': '\\x1e', '%1f': '\\x1f', '%1F': '\\x1f', '%20': '\\x20',\n  '%21': '\\x21', '%22': '\\x22', '%23': '\\x23', '%24': '\\x24', '%25': '\\x25',\n  '%26': '\\x26', '%27': '\\x27', '%28': '\\x28', '%29': '\\x29', '%2a': '\\x2a',\n  '%2A': '\\x2a', '%2b': '\\x2b', '%2B': '\\x2b', '%2c': '\\x2c', '%2C': '\\x2c',\n  '%2d': '\\x2d', '%2D': '\\x2d', '%2e': '\\x2e', '%2E': '\\x2e', '%2f': '\\x2f',\n  '%2F': '\\x2f', '%30': '\\x30', '%31': '\\x31', '%32': '\\x32', '%33': '\\x33',\n  '%34': '\\x34', '%35': '\\x35', '%36': '\\x36', '%37': '\\x37', '%38': '\\x38',\n  '%39': '\\x39', '%3a': '\\x3a', '%3A': '\\x3a', '%3b': '\\x3b', '%3B': '\\x3b',\n  '%3c': '\\x3c', '%3C': '\\x3c', '%3d': '\\x3d', '%3D': '\\x3d', '%3e': '\\x3e',\n  '%3E': '\\x3e', '%3f': '\\x3f', '%3F': '\\x3f', '%40': '\\x40', '%41': '\\x41',\n  '%42': '\\x42', '%43': '\\x43', '%44': '\\x44', '%45': '\\x45', '%46': '\\x46',\n  '%47': '\\x47', '%48': '\\x48', '%49': '\\x49', '%4a': '\\x4a', '%4A': '\\x4a',\n  '%4b': '\\x4b', '%4B': '\\x4b', '%4c': '\\x4c', '%4C': '\\x4c', '%4d': '\\x4d',\n  '%4D': '\\x4d', '%4e': '\\x4e', '%4E': '\\x4e', '%4f': '\\x4f', '%4F': '\\x4f',\n  '%50': '\\x50', '%51': '\\x51', '%52': '\\x52', '%53': '\\x53', '%54': '\\x54',\n  '%55': '\\x55', '%56': '\\x56', '%57': '\\x57', '%58': '\\x58', '%59': '\\x59',\n  '%5a': '\\x5a', '%5A': '\\x5a', '%5b': '\\x5b', '%5B': '\\x5b', '%5c': '\\x5c',\n  '%5C': '\\x5c', '%5d': '\\x5d', '%5D': '\\x5d', '%5e': '\\x5e', '%5E': '\\x5e',\n  '%5f': '\\x5f', '%5F': '\\x5f', '%60': '\\x60', '%61': '\\x61', '%62': '\\x62',\n  '%63': '\\x63', '%64': '\\x64', '%65': '\\x65', '%66': '\\x66', '%67': '\\x67',\n  '%68': '\\x68', '%69': '\\x69', '%6a': '\\x6a', '%6A': '\\x6a', '%6b': '\\x6b',\n  '%6B': '\\x6b', '%6c': '\\x6c', '%6C': '\\x6c', '%6d': '\\x6d', '%6D': '\\x6d',\n  '%6e': '\\x6e', '%6E': '\\x6e', '%6f': '\\x6f', '%6F': '\\x6f', '%70': '\\x70',\n  '%71': '\\x71', '%72': '\\x72', '%73': '\\x73', '%74': '\\x74', '%75': '\\x75',\n  '%76': '\\x76', '%77': '\\x77', '%78': '\\x78', '%79': '\\x79', '%7a': '\\x7a',\n  '%7A': '\\x7a', '%7b': '\\x7b', '%7B': '\\x7b', '%7c': '\\x7c', '%7C': '\\x7c',\n  '%7d': '\\x7d', '%7D': '\\x7d', '%7e': '\\x7e', '%7E': '\\x7e', '%7f': '\\x7f',\n  '%7F': '\\x7f', '%80': '\\x80', '%81': '\\x81', '%82': '\\x82', '%83': '\\x83',\n  '%84': '\\x84', '%85': '\\x85', '%86': '\\x86', '%87': '\\x87', '%88': '\\x88',\n  '%89': '\\x89', '%8a': '\\x8a', '%8A': '\\x8a', '%8b': '\\x8b', '%8B': '\\x8b',\n  '%8c': '\\x8c', '%8C': '\\x8c', '%8d': '\\x8d', '%8D': '\\x8d', '%8e': '\\x8e',\n  '%8E': '\\x8e', '%8f': '\\x8f', '%8F': '\\x8f', '%90': '\\x90', '%91': '\\x91',\n  '%92': '\\x92', '%93': '\\x93', '%94': '\\x94', '%95': '\\x95', '%96': '\\x96',\n  '%97': '\\x97', '%98': '\\x98', '%99': '\\x99', '%9a': '\\x9a', '%9A': '\\x9a',\n  '%9b': '\\x9b', '%9B': '\\x9b', '%9c': '\\x9c', '%9C': '\\x9c', '%9d': '\\x9d',\n  '%9D': '\\x9d', '%9e': '\\x9e', '%9E': '\\x9e', '%9f': '\\x9f', '%9F': '\\x9f',\n  '%a0': '\\xa0', '%A0': '\\xa0', '%a1': '\\xa1', '%A1': '\\xa1', '%a2': '\\xa2',\n  '%A2': '\\xa2', '%a3': '\\xa3', '%A3': '\\xa3', '%a4': '\\xa4', '%A4': '\\xa4',\n  '%a5': '\\xa5', '%A5': '\\xa5', '%a6': '\\xa6', '%A6': '\\xa6', '%a7': '\\xa7',\n  '%A7': '\\xa7', '%a8': '\\xa8', '%A8': '\\xa8', '%a9': '\\xa9', '%A9': '\\xa9',\n  '%aa': '\\xaa', '%Aa': '\\xaa', '%aA': '\\xaa', '%AA': '\\xaa', '%ab': '\\xab',\n  '%Ab': '\\xab', '%aB': '\\xab', '%AB': '\\xab', '%ac': '\\xac', '%Ac': '\\xac',\n  '%aC': '\\xac', '%AC': '\\xac', '%ad': '\\xad', '%Ad': '\\xad', '%aD': '\\xad',\n  '%AD': '\\xad', '%ae': '\\xae', '%Ae': '\\xae', '%aE': '\\xae', '%AE': '\\xae',\n  '%af': '\\xaf', '%Af': '\\xaf', '%aF': '\\xaf', '%AF': '\\xaf', '%b0': '\\xb0',\n  '%B0': '\\xb0', '%b1': '\\xb1', '%B1': '\\xb1', '%b2': '\\xb2', '%B2': '\\xb2',\n  '%b3': '\\xb3', '%B3': '\\xb3', '%b4': '\\xb4', '%B4': '\\xb4', '%b5': '\\xb5',\n  '%B5': '\\xb5', '%b6': '\\xb6', '%B6': '\\xb6', '%b7': '\\xb7', '%B7': '\\xb7',\n  '%b8': '\\xb8', '%B8': '\\xb8', '%b9': '\\xb9', '%B9': '\\xb9', '%ba': '\\xba',\n  '%Ba': '\\xba', '%bA': '\\xba', '%BA': '\\xba', '%bb': '\\xbb', '%Bb': '\\xbb',\n  '%bB': '\\xbb', '%BB': '\\xbb', '%bc': '\\xbc', '%Bc': '\\xbc', '%bC': '\\xbc',\n  '%BC': '\\xbc', '%bd': '\\xbd', '%Bd': '\\xbd', '%bD': '\\xbd', '%BD': '\\xbd',\n  '%be': '\\xbe', '%Be': '\\xbe', '%bE': '\\xbe', '%BE': '\\xbe', '%bf': '\\xbf',\n  '%Bf': '\\xbf', '%bF': '\\xbf', '%BF': '\\xbf', '%c0': '\\xc0', '%C0': '\\xc0',\n  '%c1': '\\xc1', '%C1': '\\xc1', '%c2': '\\xc2', '%C2': '\\xc2', '%c3': '\\xc3',\n  '%C3': '\\xc3', '%c4': '\\xc4', '%C4': '\\xc4', '%c5': '\\xc5', '%C5': '\\xc5',\n  '%c6': '\\xc6', '%C6': '\\xc6', '%c7': '\\xc7', '%C7': '\\xc7', '%c8': '\\xc8',\n  '%C8': '\\xc8', '%c9': '\\xc9', '%C9': '\\xc9', '%ca': '\\xca', '%Ca': '\\xca',\n  '%cA': '\\xca', '%CA': '\\xca', '%cb': '\\xcb', '%Cb': '\\xcb', '%cB': '\\xcb',\n  '%CB': '\\xcb', '%cc': '\\xcc', '%Cc': '\\xcc', '%cC': '\\xcc', '%CC': '\\xcc',\n  '%cd': '\\xcd', '%Cd': '\\xcd', '%cD': '\\xcd', '%CD': '\\xcd', '%ce': '\\xce',\n  '%Ce': '\\xce', '%cE': '\\xce', '%CE': '\\xce', '%cf': '\\xcf', '%Cf': '\\xcf',\n  '%cF': '\\xcf', '%CF': '\\xcf', '%d0': '\\xd0', '%D0': '\\xd0', '%d1': '\\xd1',\n  '%D1': '\\xd1', '%d2': '\\xd2', '%D2': '\\xd2', '%d3': '\\xd3', '%D3': '\\xd3',\n  '%d4': '\\xd4', '%D4': '\\xd4', '%d5': '\\xd5', '%D5': '\\xd5', '%d6': '\\xd6',\n  '%D6': '\\xd6', '%d7': '\\xd7', '%D7': '\\xd7', '%d8': '\\xd8', '%D8': '\\xd8',\n  '%d9': '\\xd9', '%D9': '\\xd9', '%da': '\\xda', '%Da': '\\xda', '%dA': '\\xda',\n  '%DA': '\\xda', '%db': '\\xdb', '%Db': '\\xdb', '%dB': '\\xdb', '%DB': '\\xdb',\n  '%dc': '\\xdc', '%Dc': '\\xdc', '%dC': '\\xdc', '%DC': '\\xdc', '%dd': '\\xdd',\n  '%Dd': '\\xdd', '%dD': '\\xdd', '%DD': '\\xdd', '%de': '\\xde', '%De': '\\xde',\n  '%dE': '\\xde', '%DE': '\\xde', '%df': '\\xdf', '%Df': '\\xdf', '%dF': '\\xdf',\n  '%DF': '\\xdf', '%e0': '\\xe0', '%E0': '\\xe0', '%e1': '\\xe1', '%E1': '\\xe1',\n  '%e2': '\\xe2', '%E2': '\\xe2', '%e3': '\\xe3', '%E3': '\\xe3', '%e4': '\\xe4',\n  '%E4': '\\xe4', '%e5': '\\xe5', '%E5': '\\xe5', '%e6': '\\xe6', '%E6': '\\xe6',\n  '%e7': '\\xe7', '%E7': '\\xe7', '%e8': '\\xe8', '%E8': '\\xe8', '%e9': '\\xe9',\n  '%E9': '\\xe9', '%ea': '\\xea', '%Ea': '\\xea', '%eA': '\\xea', '%EA': '\\xea',\n  '%eb': '\\xeb', '%Eb': '\\xeb', '%eB': '\\xeb', '%EB': '\\xeb', '%ec': '\\xec',\n  '%Ec': '\\xec', '%eC': '\\xec', '%EC': '\\xec', '%ed': '\\xed', '%Ed': '\\xed',\n  '%eD': '\\xed', '%ED': '\\xed', '%ee': '\\xee', '%Ee': '\\xee', '%eE': '\\xee',\n  '%EE': '\\xee', '%ef': '\\xef', '%Ef': '\\xef', '%eF': '\\xef', '%EF': '\\xef',\n  '%f0': '\\xf0', '%F0': '\\xf0', '%f1': '\\xf1', '%F1': '\\xf1', '%f2': '\\xf2',\n  '%F2': '\\xf2', '%f3': '\\xf3', '%F3': '\\xf3', '%f4': '\\xf4', '%F4': '\\xf4',\n  '%f5': '\\xf5', '%F5': '\\xf5', '%f6': '\\xf6', '%F6': '\\xf6', '%f7': '\\xf7',\n  '%F7': '\\xf7', '%f8': '\\xf8', '%F8': '\\xf8', '%f9': '\\xf9', '%F9': '\\xf9',\n  '%fa': '\\xfa', '%Fa': '\\xfa', '%fA': '\\xfa', '%FA': '\\xfa', '%fb': '\\xfb',\n  '%Fb': '\\xfb', '%fB': '\\xfb', '%FB': '\\xfb', '%fc': '\\xfc', '%Fc': '\\xfc',\n  '%fC': '\\xfc', '%FC': '\\xfc', '%fd': '\\xfd', '%Fd': '\\xfd', '%fD': '\\xfd',\n  '%FD': '\\xfd', '%fe': '\\xfe', '%Fe': '\\xfe', '%fE': '\\xfe', '%FE': '\\xfe',\n  '%ff': '\\xff', '%Ff': '\\xff', '%fF': '\\xff', '%FF': '\\xff'\n}\n\nfunction encodedReplacer (match) {\n  return EncodedLookup[match]\n}\n\nconst STATE_KEY = 0\nconst STATE_VALUE = 1\nconst STATE_CHARSET = 2\nconst STATE_LANG = 3\n\nfunction parseParams (str) {\n  const res = []\n  let state = STATE_KEY\n  let charset = ''\n  let inquote = false\n  let escaping = false\n  let p = 0\n  let tmp = ''\n  const len = str.length\n\n  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var\n    const char = str[i]\n    if (char === '\\\\' && inquote) {\n      if (escaping) { escaping = false } else {\n        escaping = true\n        continue\n      }\n    } else if (char === '\"') {\n      if (!escaping) {\n        if (inquote) {\n          inquote = false\n          state = STATE_KEY\n        } else { inquote = true }\n        continue\n      } else { escaping = false }\n    } else {\n      if (escaping && inquote) { tmp += '\\\\' }\n      escaping = false\n      if ((state === STATE_CHARSET || state === STATE_LANG) && char === \"'\") {\n        if (state === STATE_CHARSET) {\n          state = STATE_LANG\n          charset = tmp.substring(1)\n        } else { state = STATE_VALUE }\n        tmp = ''\n        continue\n      } else if (state === STATE_KEY &&\n        (char === '*' || char === '=') &&\n        res.length) {\n        state = char === '*'\n          ? STATE_CHARSET\n          : STATE_VALUE\n        res[p] = [tmp, undefined]\n        tmp = ''\n        continue\n      } else if (!inquote && char === ';') {\n        state = STATE_KEY\n        if (charset) {\n          if (tmp.length) {\n            tmp = decodeText(tmp.replace(RE_ENCODED, encodedReplacer),\n              'binary',\n              charset)\n          }\n          charset = ''\n        } else if (tmp.length) {\n          tmp = decodeText(tmp, 'binary', 'utf8')\n        }\n        if (res[p] === undefined) { res[p] = tmp } else { res[p][1] = tmp }\n        tmp = ''\n        ++p\n        continue\n      } else if (!inquote && (char === ' ' || char === '\\t')) { continue }\n    }\n    tmp += char\n  }\n  if (charset && tmp.length) {\n    tmp = decodeText(tmp.replace(RE_ENCODED, encodedReplacer),\n      'binary',\n      charset)\n  } else if (tmp) {\n    tmp = decodeText(tmp, 'binary', 'utf8')\n  }\n\n  if (res[p] === undefined) {\n    if (tmp) { res[p] = tmp }\n  } else { res[p][1] = tmp }\n\n  return res\n}\n\nmodule.exports = parseParams\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\tid: moduleId,\n\t\tloaded: false,\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Flag the module as loaded\n\tmodule.loaded = true;\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","__webpack_require__.nmd = (module) => {\n\tmodule.paths = [];\n\tif (!module.children) module.children = [];\n\treturn module;\n};","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = new URL('.', import.meta.url).pathname.slice(import.meta.url.match(/^file:\\/\\/\\/\\w:/) ? 1 : 0, -1) + \"/\";","//#region rolldown:runtime\nvar __defProp = Object.defineProperty;\nvar __export = (target, all) => {\n\tfor (var name in all) __defProp(target, name, {\n\t\tget: all[name],\n\t\tenumerable: true\n\t});\n};\n\n//#endregion\nexport { __export };","//#region src/singletons/async_local_storage/globals.ts\nconst TRACING_ALS_KEY = Symbol.for(\"ls:tracing_async_local_storage\");\nconst _CONTEXT_VARIABLES_KEY = Symbol.for(\"lc:context_variables\");\nconst setGlobalAsyncLocalStorageInstance = (instance) => {\n\tglobalThis[TRACING_ALS_KEY] = instance;\n};\nconst getGlobalAsyncLocalStorageInstance = () => {\n\treturn globalThis[TRACING_ALS_KEY];\n};\n\n//#endregion\nexport { _CONTEXT_VARIABLES_KEY, getGlobalAsyncLocalStorageInstance, setGlobalAsyncLocalStorageInstance };\n//# sourceMappingURL=globals.js.map","import snakeCase from \"decamelize\";\nimport camelCase from \"camelcase\";\n\n//#region src/load/map_keys.ts\nfunction keyToJson(key, map) {\n\treturn map?.[key] || snakeCase(key);\n}\nfunction keyFromJson(key, map) {\n\treturn map?.[key] || camelCase(key);\n}\nfunction mapKeys(fields, mapper, map) {\n\tconst mapped = {};\n\tfor (const key in fields) if (Object.hasOwn(fields, key)) mapped[mapper(key, map)] = fields[key];\n\treturn mapped;\n}\n\n//#endregion\nexport { keyFromJson, keyToJson, mapKeys };\n//# sourceMappingURL=map_keys.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { keyToJson, mapKeys } from \"./map_keys.js\";\n\n//#region src/load/serializable.ts\nvar serializable_exports = {};\n__export(serializable_exports, {\n\tSerializable: () => Serializable,\n\tget_lc_unique_name: () => get_lc_unique_name\n});\nfunction shallowCopy(obj) {\n\treturn Array.isArray(obj) ? [...obj] : { ...obj };\n}\nfunction replaceSecrets(root, secretsMap) {\n\tconst result = shallowCopy(root);\n\tfor (const [path, secretId] of Object.entries(secretsMap)) {\n\t\tconst [last, ...partsReverse] = path.split(\".\").reverse();\n\t\tlet current = result;\n\t\tfor (const part of partsReverse.reverse()) {\n\t\t\tif (current[part] === void 0) break;\n\t\t\tcurrent[part] = shallowCopy(current[part]);\n\t\t\tcurrent = current[part];\n\t\t}\n\t\tif (current[last] !== void 0) current[last] = {\n\t\t\tlc: 1,\n\t\t\ttype: \"secret\",\n\t\t\tid: [secretId]\n\t\t};\n\t}\n\treturn result;\n}\n/**\n* Get a unique name for the module, rather than parent class implementations.\n* Should not be subclassed, subclass lc_name above instead.\n*/\nfunction get_lc_unique_name(serializableClass) {\n\tconst parentClass = Object.getPrototypeOf(serializableClass);\n\tconst lcNameIsSubclassed = typeof serializableClass.lc_name === \"function\" && (typeof parentClass.lc_name !== \"function\" || serializableClass.lc_name() !== parentClass.lc_name());\n\tif (lcNameIsSubclassed) return serializableClass.lc_name();\n\telse return serializableClass.name;\n}\nvar Serializable = class Serializable {\n\tlc_serializable = false;\n\tlc_kwargs;\n\t/**\n\t* The name of the serializable. Override to provide an alias or\n\t* to preserve the serialized module name in minified environments.\n\t*\n\t* Implemented as a static method to support loading logic.\n\t*/\n\tstatic lc_name() {\n\t\treturn this.name;\n\t}\n\t/**\n\t* The final serialized identifier for the module.\n\t*/\n\tget lc_id() {\n\t\treturn [...this.lc_namespace, get_lc_unique_name(this.constructor)];\n\t}\n\t/**\n\t* A map of secrets, which will be omitted from serialization.\n\t* Keys are paths to the secret in constructor args, e.g. \"foo.bar.baz\".\n\t* Values are the secret ids, which will be used when deserializing.\n\t*/\n\tget lc_secrets() {\n\t\treturn void 0;\n\t}\n\t/**\n\t* A map of additional attributes to merge with constructor args.\n\t* Keys are the attribute names, e.g. \"foo\".\n\t* Values are the attribute values, which will be serialized.\n\t* These attributes need to be accepted by the constructor as arguments.\n\t*/\n\tget lc_attributes() {\n\t\treturn void 0;\n\t}\n\t/**\n\t* A map of aliases for constructor args.\n\t* Keys are the attribute names, e.g. \"foo\".\n\t* Values are the alias that will replace the key in serialization.\n\t* This is used to eg. make argument names match Python.\n\t*/\n\tget lc_aliases() {\n\t\treturn void 0;\n\t}\n\t/**\n\t* A manual list of keys that should be serialized.\n\t* If not overridden, all fields passed into the constructor will be serialized.\n\t*/\n\tget lc_serializable_keys() {\n\t\treturn void 0;\n\t}\n\tconstructor(kwargs, ..._args) {\n\t\tif (this.lc_serializable_keys !== void 0) this.lc_kwargs = Object.fromEntries(Object.entries(kwargs || {}).filter(([key]) => this.lc_serializable_keys?.includes(key)));\n\t\telse this.lc_kwargs = kwargs ?? {};\n\t}\n\ttoJSON() {\n\t\tif (!this.lc_serializable) return this.toJSONNotImplemented();\n\t\tif (this.lc_kwargs instanceof Serializable || typeof this.lc_kwargs !== \"object\" || Array.isArray(this.lc_kwargs)) return this.toJSONNotImplemented();\n\t\tconst aliases = {};\n\t\tconst secrets = {};\n\t\tconst kwargs = Object.keys(this.lc_kwargs).reduce((acc, key) => {\n\t\t\tacc[key] = key in this ? this[key] : this.lc_kwargs[key];\n\t\t\treturn acc;\n\t\t}, {});\n\t\tfor (let current = Object.getPrototypeOf(this); current; current = Object.getPrototypeOf(current)) {\n\t\t\tObject.assign(aliases, Reflect.get(current, \"lc_aliases\", this));\n\t\t\tObject.assign(secrets, Reflect.get(current, \"lc_secrets\", this));\n\t\t\tObject.assign(kwargs, Reflect.get(current, \"lc_attributes\", this));\n\t\t}\n\t\tObject.keys(secrets).forEach((keyPath) => {\n\t\t\tlet read = this;\n\t\t\tlet write = kwargs;\n\t\t\tconst [last, ...partsReverse] = keyPath.split(\".\").reverse();\n\t\t\tfor (const key of partsReverse.reverse()) {\n\t\t\t\tif (!(key in read) || read[key] === void 0) return;\n\t\t\t\tif (!(key in write) || write[key] === void 0) {\n\t\t\t\t\tif (typeof read[key] === \"object\" && read[key] != null) write[key] = {};\n\t\t\t\t\telse if (Array.isArray(read[key])) write[key] = [];\n\t\t\t\t}\n\t\t\t\tread = read[key];\n\t\t\t\twrite = write[key];\n\t\t\t}\n\t\t\tif (last in read && read[last] !== void 0) write[last] = write[last] || read[last];\n\t\t});\n\t\treturn {\n\t\t\tlc: 1,\n\t\t\ttype: \"constructor\",\n\t\t\tid: this.lc_id,\n\t\t\tkwargs: mapKeys(Object.keys(secrets).length ? replaceSecrets(kwargs, secrets) : kwargs, keyToJson, aliases)\n\t\t};\n\t}\n\ttoJSONNotImplemented() {\n\t\treturn {\n\t\t\tlc: 1,\n\t\t\ttype: \"not_implemented\",\n\t\t\tid: this.lc_id\n\t\t};\n\t}\n};\n\n//#endregion\nexport { Serializable, get_lc_unique_name, serializable_exports };\n//# sourceMappingURL=serializable.js.map","//#region src/messages/content/data.ts\n/**\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction isDataContentBlock(content_block) {\n\treturn typeof content_block === \"object\" && content_block !== null && \"type\" in content_block && typeof content_block.type === \"string\" && \"source_type\" in content_block && (content_block.source_type === \"url\" || content_block.source_type === \"base64\" || content_block.source_type === \"text\" || content_block.source_type === \"id\");\n}\n/**\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction isURLContentBlock(content_block) {\n\treturn isDataContentBlock(content_block) && content_block.source_type === \"url\" && \"url\" in content_block && typeof content_block.url === \"string\";\n}\n/**\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction isBase64ContentBlock(content_block) {\n\treturn isDataContentBlock(content_block) && content_block.source_type === \"base64\" && \"data\" in content_block && typeof content_block.data === \"string\";\n}\n/**\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction isPlainTextContentBlock(content_block) {\n\treturn isDataContentBlock(content_block) && content_block.source_type === \"text\" && \"text\" in content_block && typeof content_block.text === \"string\";\n}\n/**\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction isIDContentBlock(content_block) {\n\treturn isDataContentBlock(content_block) && content_block.source_type === \"id\" && \"id\" in content_block && typeof content_block.id === \"string\";\n}\n/**\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction convertToOpenAIImageBlock(content_block) {\n\tif (isDataContentBlock(content_block)) {\n\t\tif (content_block.source_type === \"url\") return {\n\t\t\ttype: \"image_url\",\n\t\t\timage_url: { url: content_block.url }\n\t\t};\n\t\tif (content_block.source_type === \"base64\") {\n\t\t\tif (!content_block.mime_type) throw new Error(\"mime_type key is required for base64 data.\");\n\t\t\tconst mime_type = content_block.mime_type;\n\t\t\treturn {\n\t\t\t\ttype: \"image_url\",\n\t\t\t\timage_url: { url: `data:${mime_type};base64,${content_block.data}` }\n\t\t\t};\n\t\t}\n\t}\n\tthrow new Error(\"Unsupported source type. Only 'url' and 'base64' are supported.\");\n}\n/**\n* Utility function for ChatModelProviders. Parses a mime type into a type, subtype, and parameters.\n*\n* @param mime_type - The mime type to parse.\n* @returns An object containing the type, subtype, and parameters.\n*\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction parseMimeType(mime_type) {\n\tconst parts = mime_type.split(\";\")[0].split(\"/\");\n\tif (parts.length !== 2) throw new Error(`Invalid mime type: \"${mime_type}\" - does not match type/subtype format.`);\n\tconst type = parts[0].trim();\n\tconst subtype = parts[1].trim();\n\tif (type === \"\" || subtype === \"\") throw new Error(`Invalid mime type: \"${mime_type}\" - type or subtype is empty.`);\n\tconst parameters = {};\n\tfor (const parameterKvp of mime_type.split(\";\").slice(1)) {\n\t\tconst parameterParts = parameterKvp.split(\"=\");\n\t\tif (parameterParts.length !== 2) throw new Error(`Invalid parameter syntax in mime type: \"${mime_type}\".`);\n\t\tconst key = parameterParts[0].trim();\n\t\tconst value = parameterParts[1].trim();\n\t\tif (key === \"\") throw new Error(`Invalid parameter syntax in mime type: \"${mime_type}\".`);\n\t\tparameters[key] = value;\n\t}\n\treturn {\n\t\ttype,\n\t\tsubtype,\n\t\tparameters\n\t};\n}\n/**\n* Utility function for ChatModelProviders. Parses a base64 data URL into a typed array or string.\n*\n* @param dataUrl - The base64 data URL to parse.\n* @param asTypedArray - Whether to return the data as a typed array.\n* @returns The parsed data and mime type, or undefined if the data URL is invalid.\n*\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction parseBase64DataUrl({ dataUrl: data_url, asTypedArray = false }) {\n\tconst formatMatch = data_url.match(/^data:(\\w+\\/\\w+);base64,([A-Za-z0-9+/]+=*)$/);\n\tlet mime_type;\n\tif (formatMatch) {\n\t\tmime_type = formatMatch[1].toLowerCase();\n\t\tconst data = asTypedArray ? Uint8Array.from(atob(formatMatch[2]), (c) => c.charCodeAt(0)) : formatMatch[2];\n\t\treturn {\n\t\t\tmime_type,\n\t\t\tdata\n\t\t};\n\t}\n\treturn void 0;\n}\n/**\n* Convert from a standard data content block to a provider's proprietary data content block format.\n*\n* Don't override this method. Instead, override the more specific conversion methods and use this\n* method unmodified.\n*\n* @param block - The standard data content block to convert.\n* @returns The provider data content block.\n* @throws An error if the standard data content block type is not supported.\n*\n* @deprecated Don't use data content blocks. Use {@link ContentBlock.Multimodal.Data} instead.\n*/\nfunction convertToProviderContentBlock(block, converter) {\n\tif (block.type === \"text\") {\n\t\tif (!converter.fromStandardTextBlock) throw new Error(`Converter for ${converter.providerName} does not implement \\`fromStandardTextBlock\\` method.`);\n\t\treturn converter.fromStandardTextBlock(block);\n\t}\n\tif (block.type === \"image\") {\n\t\tif (!converter.fromStandardImageBlock) throw new Error(`Converter for ${converter.providerName} does not implement \\`fromStandardImageBlock\\` method.`);\n\t\treturn converter.fromStandardImageBlock(block);\n\t}\n\tif (block.type === \"audio\") {\n\t\tif (!converter.fromStandardAudioBlock) throw new Error(`Converter for ${converter.providerName} does not implement \\`fromStandardAudioBlock\\` method.`);\n\t\treturn converter.fromStandardAudioBlock(block);\n\t}\n\tif (block.type === \"file\") {\n\t\tif (!converter.fromStandardFileBlock) throw new Error(`Converter for ${converter.providerName} does not implement \\`fromStandardFileBlock\\` method.`);\n\t\treturn converter.fromStandardFileBlock(block);\n\t}\n\tthrow new Error(`Unable to convert content block type '${block.type}' to provider-specific format: not recognized.`);\n}\n\n//#endregion\nexport { convertToOpenAIImageBlock, convertToProviderContentBlock, isBase64ContentBlock, isDataContentBlock, isIDContentBlock, isPlainTextContentBlock, isURLContentBlock, parseBase64DataUrl, parseMimeType };\n//# sourceMappingURL=data.js.map","//#region src/messages/block_translators/utils.ts\nfunction _isContentBlock(block, type) {\n\treturn _isObject(block) && block.type === type;\n}\nfunction _isObject(value) {\n\treturn typeof value === \"object\" && value !== null;\n}\nfunction _isArray(value) {\n\treturn Array.isArray(value);\n}\nfunction _isString(value) {\n\treturn typeof value === \"string\";\n}\nfunction _isNumber(value) {\n\treturn typeof value === \"number\";\n}\nfunction _isBytesArray(value) {\n\treturn value instanceof Uint8Array;\n}\nfunction safeParseJson(value) {\n\ttry {\n\t\treturn JSON.parse(value);\n\t} catch {\n\t\treturn void 0;\n\t}\n}\nconst iife = (fn) => fn();\n\n//#endregion\nexport { _isArray, _isBytesArray, _isContentBlock, _isNumber, _isObject, _isString, iife, safeParseJson };\n//# sourceMappingURL=utils.js.map","import { _isArray, _isContentBlock, _isNumber, _isObject, _isString, iife, safeParseJson } from \"./utils.js\";\n\n//#region src/messages/block_translators/anthropic.ts\nfunction convertAnthropicAnnotation(citation) {\n\tif (citation.type === \"char_location\" && _isString(citation.document_title) && _isNumber(citation.start_char_index) && _isNumber(citation.end_char_index) && _isString(citation.cited_text)) {\n\t\tconst { document_title, start_char_index, end_char_index, cited_text,...rest } = citation;\n\t\treturn {\n\t\t\t...rest,\n\t\t\ttype: \"citation\",\n\t\t\tsource: \"char\",\n\t\t\ttitle: document_title ?? void 0,\n\t\t\tstartIndex: start_char_index,\n\t\t\tendIndex: end_char_index,\n\t\t\tcitedText: cited_text\n\t\t};\n\t}\n\tif (citation.type === \"page_location\" && _isString(citation.document_title) && _isNumber(citation.start_page_number) && _isNumber(citation.end_page_number) && _isString(citation.cited_text)) {\n\t\tconst { document_title, start_page_number, end_page_number, cited_text,...rest } = citation;\n\t\treturn {\n\t\t\t...rest,\n\t\t\ttype: \"citation\",\n\t\t\tsource: \"page\",\n\t\t\ttitle: document_title ?? void 0,\n\t\t\tstartIndex: start_page_number,\n\t\t\tendIndex: end_page_number,\n\t\t\tcitedText: cited_text\n\t\t};\n\t}\n\tif (citation.type === \"content_block_location\" && _isString(citation.document_title) && _isNumber(citation.start_block_index) && _isNumber(citation.end_block_index) && _isString(citation.cited_text)) {\n\t\tconst { document_title, start_block_index, end_block_index, cited_text,...rest } = citation;\n\t\treturn {\n\t\t\t...rest,\n\t\t\ttype: \"citation\",\n\t\t\tsource: \"block\",\n\t\t\ttitle: document_title ?? void 0,\n\t\t\tstartIndex: start_block_index,\n\t\t\tendIndex: end_block_index,\n\t\t\tcitedText: cited_text\n\t\t};\n\t}\n\tif (citation.type === \"web_search_result_location\" && _isString(citation.url) && _isString(citation.title) && _isString(citation.encrypted_index) && _isString(citation.cited_text)) {\n\t\tconst { url, title, encrypted_index, cited_text,...rest } = citation;\n\t\treturn {\n\t\t\t...rest,\n\t\t\ttype: \"citation\",\n\t\t\tsource: \"url\",\n\t\t\turl,\n\t\t\ttitle,\n\t\t\tstartIndex: Number(encrypted_index),\n\t\t\tendIndex: Number(encrypted_index),\n\t\t\tcitedText: cited_text\n\t\t};\n\t}\n\tif (citation.type === \"search_result_location\" && _isString(citation.source) && _isString(citation.title) && _isNumber(citation.start_block_index) && _isNumber(citation.end_block_index) && _isString(citation.cited_text)) {\n\t\tconst { source, title, start_block_index, end_block_index, cited_text,...rest } = citation;\n\t\treturn {\n\t\t\t...rest,\n\t\t\ttype: \"citation\",\n\t\t\tsource: \"search\",\n\t\t\turl: source,\n\t\t\ttitle: title ?? void 0,\n\t\t\tstartIndex: start_block_index,\n\t\t\tendIndex: end_block_index,\n\t\t\tcitedText: cited_text\n\t\t};\n\t}\n\treturn void 0;\n}\n/**\n* Converts an Anthropic content block to a standard V1 content block.\n*\n* This function handles the conversion of Anthropic-specific content blocks\n* (document and image blocks) to the standardized V1 format. It supports\n* various source types including base64 data, URLs, file IDs, and text data.\n*\n* @param block - The Anthropic content block to convert\n* @returns A standard V1 content block if conversion is successful, undefined otherwise\n*\n* @example\n* ```typescript\n* const anthropicBlock = {\n*   type: \"image\",\n*   source: {\n*     type: \"base64\",\n*     media_type: \"image/png\",\n*     data: \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==\"\n*   }\n* };\n*\n* const standardBlock = convertToV1FromAnthropicContentBlock(anthropicBlock);\n* // Returns: { type: \"image\", mimeType: \"image/png\", data: \"...\" }\n* ```\n*/\nfunction convertToV1FromAnthropicContentBlock(block) {\n\tif (_isContentBlock(block, \"document\") && _isObject(block.source) && \"type\" in block.source) {\n\t\tif (block.source.type === \"base64\" && _isString(block.source.media_type) && _isString(block.source.data)) return {\n\t\t\ttype: \"file\",\n\t\t\tmimeType: block.source.media_type,\n\t\t\tdata: block.source.data\n\t\t};\n\t\telse if (block.source.type === \"url\" && _isString(block.source.url)) return {\n\t\t\ttype: \"file\",\n\t\t\turl: block.source.url\n\t\t};\n\t\telse if (block.source.type === \"file\" && _isString(block.source.file_id)) return {\n\t\t\ttype: \"file\",\n\t\t\tfileId: block.source.file_id\n\t\t};\n\t\telse if (block.source.type === \"text\" && _isString(block.source.data)) return {\n\t\t\ttype: \"file\",\n\t\t\tmimeType: String(block.source.media_type ?? \"text/plain\"),\n\t\t\tdata: block.source.data\n\t\t};\n\t} else if (_isContentBlock(block, \"image\") && _isObject(block.source) && \"type\" in block.source) {\n\t\tif (block.source.type === \"base64\" && _isString(block.source.media_type) && _isString(block.source.data)) return {\n\t\t\ttype: \"image\",\n\t\t\tmimeType: block.source.media_type,\n\t\t\tdata: block.source.data\n\t\t};\n\t\telse if (block.source.type === \"url\" && _isString(block.source.url)) return {\n\t\t\ttype: \"image\",\n\t\t\turl: block.source.url\n\t\t};\n\t\telse if (block.source.type === \"file\" && _isString(block.source.file_id)) return {\n\t\t\ttype: \"image\",\n\t\t\tfileId: block.source.file_id\n\t\t};\n\t}\n\treturn void 0;\n}\n/**\n* Converts an array of content blocks from Anthropic format to v1 standard format.\n*\n* This function processes each content block in the input array, attempting to convert\n* Anthropic-specific block formats (like image blocks with source objects, document blocks, etc.)\n* to the standardized v1 content block format. If a block cannot be converted, it is\n* passed through as-is with a type assertion to ContentBlock.Standard.\n*\n* @param content - Array of content blocks in Anthropic format to be converted\n* @returns Array of content blocks in v1 standard format\n*/\nfunction convertToV1FromAnthropicInput(content) {\n\tfunction* iterateContent() {\n\t\tfor (const block of content) {\n\t\t\tconst stdBlock = convertToV1FromAnthropicContentBlock(block);\n\t\t\tif (stdBlock) yield stdBlock;\n\t\t\telse yield block;\n\t\t}\n\t}\n\treturn Array.from(iterateContent());\n}\n/**\n* Converts an Anthropic AI message to an array of v1 standard content blocks.\n*\n* This function processes an AI message containing Anthropic-specific content blocks\n* and converts them to the standardized v1 content block format.\n*\n* @param message - The AI message containing Anthropic-formatted content blocks\n* @returns Array of content blocks in v1 standard format\n*\n* @example\n* ```typescript\n* const message = new AIMessage([\n*   { type: \"text\", text: \"Hello world\" },\n*   { type: \"thinking\", text: \"Let me think about this...\" },\n*   { type: \"tool_use\", id: \"123\", name: \"calculator\", input: { a: 1, b: 2 } }\n* ]);\n*\n* const standardBlocks = convertToV1FromAnthropicMessage(message);\n* // Returns:\n* // [\n* //   { type: \"text\", text: \"Hello world\" },\n* //   { type: \"reasoning\", reasoning: \"Let me think about this...\" },\n* //   { type: \"tool_call\", id: \"123\", name: \"calculator\", args: { a: 1, b: 2 } }\n* // ]\n* ```\n*/\nfunction convertToV1FromAnthropicMessage(message) {\n\tfunction* iterateContent() {\n\t\tconst content = typeof message.content === \"string\" ? [{\n\t\t\ttype: \"text\",\n\t\t\ttext: message.content\n\t\t}] : message.content;\n\t\tfor (const block of content) {\n\t\t\tif (_isContentBlock(block, \"text\") && _isString(block.text)) {\n\t\t\t\tconst { text, citations,...rest } = block;\n\t\t\t\tif (_isArray(citations) && citations.length) {\n\t\t\t\t\tconst _citations = citations.reduce((acc, item) => {\n\t\t\t\t\t\tconst citation = convertAnthropicAnnotation(item);\n\t\t\t\t\t\tif (citation) return [...acc, citation];\n\t\t\t\t\t\treturn acc;\n\t\t\t\t\t}, []);\n\t\t\t\t\tyield {\n\t\t\t\t\t\t...rest,\n\t\t\t\t\t\ttype: \"text\",\n\t\t\t\t\t\ttext,\n\t\t\t\t\t\tannotations: _citations\n\t\t\t\t\t};\n\t\t\t\t\tcontinue;\n\t\t\t\t} else {\n\t\t\t\t\tyield {\n\t\t\t\t\t\t...rest,\n\t\t\t\t\t\ttype: \"text\",\n\t\t\t\t\t\ttext\n\t\t\t\t\t};\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t} else if (_isContentBlock(block, \"thinking\") && _isString(block.thinking)) {\n\t\t\t\tconst { thinking, signature,...rest } = block;\n\t\t\t\tyield {\n\t\t\t\t\t...rest,\n\t\t\t\t\ttype: \"reasoning\",\n\t\t\t\t\treasoning: thinking,\n\t\t\t\t\tsignature\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"redacted_thinking\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"tool_use\") && _isString(block.name) && _isString(block.id)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"tool_call\",\n\t\t\t\t\tid: block.id,\n\t\t\t\t\tname: block.name,\n\t\t\t\t\targs: block.input\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"input_json_delta\")) {\n\t\t\t\tif (_isAIMessageChunk(message) && message.tool_call_chunks?.length) {\n\t\t\t\t\tconst tool_call_chunk = message.tool_call_chunks[0];\n\t\t\t\t\tyield {\n\t\t\t\t\t\ttype: \"tool_call_chunk\",\n\t\t\t\t\t\tid: tool_call_chunk.id,\n\t\t\t\t\t\tname: tool_call_chunk.name,\n\t\t\t\t\t\targs: tool_call_chunk.args,\n\t\t\t\t\t\tindex: tool_call_chunk.index\n\t\t\t\t\t};\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t} else if (_isContentBlock(block, \"server_tool_use\") && _isString(block.name) && _isString(block.id)) {\n\t\t\t\tconst { name, id } = block;\n\t\t\t\tif (name === \"web_search\") {\n\t\t\t\t\tconst query = iife(() => {\n\t\t\t\t\t\tif (typeof block.input === \"string\") return block.input;\n\t\t\t\t\t\telse if (_isObject(block.input) && _isString(block.input.query)) return block.input.query;\n\t\t\t\t\t\telse if (_isString(block.partial_json)) {\n\t\t\t\t\t\t\tconst json = safeParseJson(block.partial_json);\n\t\t\t\t\t\t\tif (json?.query) return json.query;\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn \"\";\n\t\t\t\t\t});\n\t\t\t\t\tyield {\n\t\t\t\t\t\tid,\n\t\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\t\tname: \"web_search\",\n\t\t\t\t\t\targs: { query }\n\t\t\t\t\t};\n\t\t\t\t\tcontinue;\n\t\t\t\t} else if (block.name === \"code_execution\") {\n\t\t\t\t\tconst code = iife(() => {\n\t\t\t\t\t\tif (typeof block.input === \"string\") return block.input;\n\t\t\t\t\t\telse if (_isObject(block.input) && _isString(block.input.code)) return block.input.code;\n\t\t\t\t\t\telse if (_isString(block.partial_json)) {\n\t\t\t\t\t\t\tconst json = safeParseJson(block.partial_json);\n\t\t\t\t\t\t\tif (json?.code) return json.code;\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn \"\";\n\t\t\t\t\t});\n\t\t\t\t\tyield {\n\t\t\t\t\t\tid,\n\t\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\t\tname: \"code_execution\",\n\t\t\t\t\t\targs: { code }\n\t\t\t\t\t};\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t} else if (_isContentBlock(block, \"web_search_tool_result\") && _isString(block.tool_use_id) && _isArray(block.content)) {\n\t\t\t\tconst { content: content$1, tool_use_id } = block;\n\t\t\t\tconst urls = content$1.reduce((acc, content$2) => {\n\t\t\t\t\tif (_isContentBlock(content$2, \"web_search_result\")) return [...acc, content$2.url];\n\t\t\t\t\treturn acc;\n\t\t\t\t}, []);\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"server_tool_call_result\",\n\t\t\t\t\tname: \"web_search\",\n\t\t\t\t\ttoolCallId: tool_use_id,\n\t\t\t\t\tstatus: \"success\",\n\t\t\t\t\toutput: { urls }\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"code_execution_tool_result\") && _isString(block.tool_use_id) && _isObject(block.content)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"server_tool_call_result\",\n\t\t\t\t\tname: \"code_execution\",\n\t\t\t\t\ttoolCallId: block.tool_use_id,\n\t\t\t\t\tstatus: \"success\",\n\t\t\t\t\toutput: block.content\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"mcp_tool_use\")) {\n\t\t\t\tyield {\n\t\t\t\t\tid: block.id,\n\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\tname: \"mcp_tool_use\",\n\t\t\t\t\targs: block.input\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"mcp_tool_result\") && _isString(block.tool_use_id) && _isObject(block.content)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"server_tool_call_result\",\n\t\t\t\t\tname: \"mcp_tool_use\",\n\t\t\t\t\ttoolCallId: block.tool_use_id,\n\t\t\t\t\tstatus: \"success\",\n\t\t\t\t\toutput: block.content\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"container_upload\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\tname: \"container_upload\",\n\t\t\t\t\targs: block.input\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"search_result\")) {\n\t\t\t\tyield {\n\t\t\t\t\tid: block.id,\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"tool_result\")) {\n\t\t\t\tyield {\n\t\t\t\t\tid: block.id,\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tconst stdBlock = convertToV1FromAnthropicContentBlock(block);\n\t\t\t\tif (stdBlock) {\n\t\t\t\t\tyield stdBlock;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tyield {\n\t\t\t\ttype: \"non_standard\",\n\t\t\t\tvalue: block\n\t\t\t};\n\t\t}\n\t}\n\treturn Array.from(iterateContent());\n}\nconst ChatAnthropicTranslator = {\n\ttranslateContent: convertToV1FromAnthropicMessage,\n\ttranslateContentChunk: convertToV1FromAnthropicMessage\n};\nfunction _isAIMessageChunk(message) {\n\treturn typeof message?._getType === \"function\" && typeof message.concat === \"function\" && message._getType() === \"ai\";\n}\n\n//#endregion\nexport { ChatAnthropicTranslator, convertToV1FromAnthropicInput };\n//# sourceMappingURL=anthropic.js.map","import { isBase64ContentBlock, isIDContentBlock, isURLContentBlock, parseBase64DataUrl } from \"../content/data.js\";\nimport { _isContentBlock, _isObject, _isString } from \"./utils.js\";\n\n//#region src/messages/block_translators/data.ts\nfunction convertToV1FromDataContentBlock(block) {\n\tif (isURLContentBlock(block)) return {\n\t\ttype: block.type,\n\t\tmimeType: block.mime_type,\n\t\turl: block.url,\n\t\tmetadata: block.metadata\n\t};\n\tif (isBase64ContentBlock(block)) return {\n\t\ttype: block.type,\n\t\tmimeType: block.mime_type ?? \"application/octet-stream\",\n\t\tdata: block.data,\n\t\tmetadata: block.metadata\n\t};\n\tif (isIDContentBlock(block)) return {\n\t\ttype: block.type,\n\t\tmimeType: block.mime_type,\n\t\tfileId: block.id,\n\t\tmetadata: block.metadata\n\t};\n\treturn block;\n}\nfunction convertToV1FromDataContent(content) {\n\treturn content.map(convertToV1FromDataContentBlock);\n}\nfunction isOpenAIDataBlock(block) {\n\tif (_isContentBlock(block, \"image_url\") && _isObject(block.image_url)) return true;\n\tif (_isContentBlock(block, \"input_audio\") && _isObject(block.input_audio)) return true;\n\tif (_isContentBlock(block, \"file\") && _isObject(block.file)) return true;\n\treturn false;\n}\nfunction convertToV1FromOpenAIDataBlock(block) {\n\tif (_isContentBlock(block, \"image_url\") && _isObject(block.image_url) && _isString(block.image_url.url)) {\n\t\tconst parsed = parseBase64DataUrl({ dataUrl: block.image_url.url });\n\t\tif (parsed) return {\n\t\t\ttype: \"image\",\n\t\t\tmimeType: parsed.mime_type,\n\t\t\tdata: parsed.data\n\t\t};\n\t\telse return {\n\t\t\ttype: \"image\",\n\t\t\turl: block.image_url.url\n\t\t};\n\t} else if (_isContentBlock(block, \"input_audio\") && _isObject(block.input_audio) && _isString(block.input_audio.data) && _isString(block.input_audio.format)) return {\n\t\ttype: \"audio\",\n\t\tdata: block.input_audio.data,\n\t\tmimeType: `audio/${block.input_audio.format}`\n\t};\n\telse if (_isContentBlock(block, \"file\") && _isObject(block.file) && _isString(block.file.data)) {\n\t\tconst parsed = parseBase64DataUrl({ dataUrl: block.file.data });\n\t\tif (parsed) return {\n\t\t\ttype: \"file\",\n\t\t\tdata: parsed.data,\n\t\t\tmimeType: parsed.mime_type\n\t\t};\n\t\telse if (_isString(block.file.file_id)) return {\n\t\t\ttype: \"file\",\n\t\t\tfileId: block.file.file_id\n\t\t};\n\t}\n\treturn block;\n}\n\n//#endregion\nexport { convertToV1FromDataContent, convertToV1FromOpenAIDataBlock, isOpenAIDataBlock };\n//# sourceMappingURL=data.js.map","import { _isArray, _isContentBlock, _isObject, _isString, iife } from \"./utils.js\";\nimport { convertToV1FromOpenAIDataBlock, isOpenAIDataBlock } from \"./data.js\";\n\n//#region src/messages/block_translators/openai.ts\n/**\n* Converts a ChatOpenAICompletions message to an array of v1 standard content blocks.\n*\n* This function processes an AI message from ChatOpenAICompletions API format\n* and converts it to the standardized v1 content block format. It handles both\n* string content and structured content blocks, as well as tool calls.\n*\n* @param message - The AI message containing ChatOpenAICompletions formatted content\n* @returns Array of content blocks in v1 standard format\n*\n* @example\n* ```typescript\n* const message = new AIMessage(\"Hello world\");\n* const standardBlocks = convertToV1FromChatCompletions(message);\n* // Returns: [{ type: \"text\", text: \"Hello world\" }]\n* ```\n*\n* @example\n* ```typescript\n* const message = new AIMessage([\n*   { type: \"text\", text: \"Hello\" },\n*   { type: \"image_url\", image_url: { url: \"https://example.com/image.png\" } }\n* ]);\n* message.tool_calls = [\n*   { id: \"call_123\", name: \"calculator\", args: { a: 1, b: 2 } }\n* ];\n*\n* const standardBlocks = convertToV1FromChatCompletions(message);\n* // Returns:\n* // [\n* //   { type: \"text\", text: \"Hello\" },\n* //   { type: \"image\", url: \"https://example.com/image.png\" },\n* //   { type: \"tool_call\", id: \"call_123\", name: \"calculator\", args: { a: 1, b: 2 } }\n* // ]\n* ```\n*/\nfunction convertToV1FromChatCompletions(message) {\n\tconst blocks = [];\n\tif (typeof message.content === \"string\") blocks.push({\n\t\ttype: \"text\",\n\t\ttext: message.content\n\t});\n\telse blocks.push(...convertToV1FromChatCompletionsInput(message.content));\n\tfor (const toolCall of message.tool_calls ?? []) blocks.push({\n\t\ttype: \"tool_call\",\n\t\tid: toolCall.id,\n\t\tname: toolCall.name,\n\t\targs: toolCall.args\n\t});\n\treturn blocks;\n}\n/**\n* Converts a ChatOpenAICompletions message chunk to an array of v1 standard content blocks.\n*\n* This function processes an AI message chunk from OpenAI's chat completions API and converts\n* it to the standardized v1 content block format. It handles both string and array content,\n* as well as tool calls that may be present in the chunk.\n*\n* @param message - The AI message chunk containing OpenAI-formatted content blocks\n* @returns Array of content blocks in v1 standard format\n*\n* @example\n* ```typescript\n* const chunk = new AIMessage(\"Hello\");\n* const standardBlocks = convertToV1FromChatCompletionsChunk(chunk);\n* // Returns: [{ type: \"text\", text: \"Hello\" }]\n* ```\n*\n* @example\n* ```typescript\n* const chunk = new AIMessage([\n*   { type: \"text\", text: \"Processing...\" }\n* ]);\n* chunk.tool_calls = [\n*   { id: \"call_456\", name: \"search\", args: { query: \"test\" } }\n* ];\n*\n* const standardBlocks = convertToV1FromChatCompletionsChunk(chunk);\n* // Returns:\n* // [\n* //   { type: \"text\", text: \"Processing...\" },\n* //   { type: \"tool_call\", id: \"call_456\", name: \"search\", args: { query: \"test\" } }\n* // ]\n* ```\n*/\nfunction convertToV1FromChatCompletionsChunk(message) {\n\tconst blocks = [];\n\tif (typeof message.content === \"string\") blocks.push({\n\t\ttype: \"text\",\n\t\ttext: message.content\n\t});\n\telse blocks.push(...convertToV1FromChatCompletionsInput(message.content));\n\tfor (const toolCall of message.tool_calls ?? []) blocks.push({\n\t\ttype: \"tool_call\",\n\t\tid: toolCall.id,\n\t\tname: toolCall.name,\n\t\targs: toolCall.args\n\t});\n\treturn blocks;\n}\n/**\n* Converts an array of ChatOpenAICompletions content blocks to v1 standard content blocks.\n*\n* This function processes content blocks from OpenAI's Chat Completions API format\n* and converts them to the standardized v1 content block format. It handles both\n* OpenAI-specific data blocks (which require conversion) and standard blocks\n* (which are passed through with type assertion).\n*\n* @param blocks - Array of content blocks in ChatOpenAICompletions format\n* @returns Array of content blocks in v1 standard format\n*\n* @example\n* ```typescript\n* const openaiBlocks = [\n*   { type: \"text\", text: \"Hello world\" },\n*   { type: \"image_url\", image_url: { url: \"https://example.com/image.png\" } }\n* ];\n*\n* const standardBlocks = convertToV1FromChatCompletionsInput(openaiBlocks);\n* // Returns:\n* // [\n* //   { type: \"text\", text: \"Hello world\" },\n* //   { type: \"image\", url: \"https://example.com/image.png\" }\n* // ]\n* ```\n*/\nfunction convertToV1FromChatCompletionsInput(blocks) {\n\tconst convertedBlocks = [];\n\tfor (const block of blocks) if (isOpenAIDataBlock(block)) convertedBlocks.push(convertToV1FromOpenAIDataBlock(block));\n\telse convertedBlocks.push(block);\n\treturn convertedBlocks;\n}\nfunction convertResponsesAnnotation(annotation) {\n\tif (annotation.type === \"url_citation\") {\n\t\tconst { url, title, start_index, end_index } = annotation;\n\t\treturn {\n\t\t\ttype: \"citation\",\n\t\t\turl,\n\t\t\ttitle,\n\t\t\tstartIndex: start_index,\n\t\t\tendIndex: end_index\n\t\t};\n\t}\n\tif (annotation.type === \"file_citation\") {\n\t\tconst { file_id, filename, index } = annotation;\n\t\treturn {\n\t\t\ttype: \"citation\",\n\t\t\ttitle: filename,\n\t\t\tstartIndex: index,\n\t\t\tendIndex: index,\n\t\t\tfileId: file_id\n\t\t};\n\t}\n\treturn annotation;\n}\n/**\n* Converts a ChatOpenAIResponses message to an array of v1 standard content blocks.\n*\n* This function processes an AI message containing OpenAI Responses-specific content blocks\n* and converts them to the standardized v1 content block format. It handles reasoning summaries,\n* text content with annotations, tool calls, and various tool outputs including code interpreter,\n* web search, file search, computer calls, and MCP-related blocks.\n*\n* @param message - The AI message containing OpenAI Responses-formatted content blocks\n* @returns Array of content blocks in v1 standard format\n*\n* @example\n* ```typescript\n* const message = new AIMessage({\n*   content: [{ type: \"text\", text: \"Hello world\", annotations: [] }],\n*   tool_calls: [{ id: \"123\", name: \"calculator\", args: { a: 1, b: 2 } }],\n*   additional_kwargs: {\n*     reasoning: { summary: [{ text: \"Let me calculate this...\" }] },\n*     tool_outputs: [\n*       {\n*         type: \"code_interpreter_call\",\n*         code: \"print('hello')\",\n*         outputs: [{ type: \"logs\", logs: \"hello\" }]\n*       }\n*     ]\n*   }\n* });\n*\n* const standardBlocks = convertToV1FromResponses(message);\n* // Returns:\n* // [\n* //   { type: \"reasoning\", reasoning: \"Let me calculate this...\" },\n* //   { type: \"text\", text: \"Hello world\", annotations: [] },\n* //   { type: \"tool_call\", id: \"123\", name: \"calculator\", args: { a: 1, b: 2 } },\n* //   { type: \"code_interpreter_call\", code: \"print('hello')\" },\n* //   { type: \"code_interpreter_result\", output: [{ type: \"code_interpreter_output\", returnCode: 0, stdout: \"hello\" }] }\n* // ]\n* ```\n*/\nfunction convertToV1FromResponses(message) {\n\tfunction* iterateContent() {\n\t\tif (_isObject(message.additional_kwargs?.reasoning) && _isArray(message.additional_kwargs.reasoning.summary)) {\n\t\t\tconst summary = message.additional_kwargs.reasoning.summary.reduce((acc, item) => {\n\t\t\t\tif (_isObject(item) && _isString(item.text)) return `${acc}${item.text}`;\n\t\t\t\treturn acc;\n\t\t\t}, \"\");\n\t\t\tyield {\n\t\t\t\ttype: \"reasoning\",\n\t\t\t\treasoning: summary\n\t\t\t};\n\t\t}\n\t\tconst content = typeof message.content === \"string\" ? [{\n\t\t\ttype: \"text\",\n\t\t\ttext: message.content\n\t\t}] : message.content;\n\t\tfor (const block of content) if (_isContentBlock(block, \"text\")) {\n\t\t\tconst { text, annotations,...rest } = block;\n\t\t\tif (Array.isArray(annotations)) yield {\n\t\t\t\t...rest,\n\t\t\t\ttype: \"text\",\n\t\t\t\ttext: String(text),\n\t\t\t\tannotations: annotations.map(convertResponsesAnnotation)\n\t\t\t};\n\t\t\telse yield {\n\t\t\t\t...rest,\n\t\t\t\ttype: \"text\",\n\t\t\t\ttext: String(text)\n\t\t\t};\n\t\t}\n\t\tfor (const toolCall of message.tool_calls ?? []) yield {\n\t\t\ttype: \"tool_call\",\n\t\t\tid: toolCall.id,\n\t\t\tname: toolCall.name,\n\t\t\targs: toolCall.args\n\t\t};\n\t\tif (_isObject(message.additional_kwargs) && _isArray(message.additional_kwargs.tool_outputs)) for (const toolOutput of message.additional_kwargs.tool_outputs) {\n\t\t\tif (_isContentBlock(toolOutput, \"web_search_call\")) {\n\t\t\t\tyield {\n\t\t\t\t\tid: toolOutput.id,\n\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\tname: \"web_search\",\n\t\t\t\t\targs: { query: toolOutput.query }\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(toolOutput, \"file_search_call\")) {\n\t\t\t\tyield {\n\t\t\t\t\tid: toolOutput.id,\n\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\tname: \"file_search\",\n\t\t\t\t\targs: { query: toolOutput.query }\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(toolOutput, \"computer_call\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: toolOutput\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(toolOutput, \"code_interpreter_call\")) {\n\t\t\t\tif (_isString(toolOutput.code)) yield {\n\t\t\t\t\tid: toolOutput.id,\n\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\tname: \"code_interpreter\",\n\t\t\t\t\targs: { code: toolOutput.code }\n\t\t\t\t};\n\t\t\t\tif (_isArray(toolOutput.outputs)) {\n\t\t\t\t\tconst returnCode = iife(() => {\n\t\t\t\t\t\tif (toolOutput.status === \"in_progress\") return void 0;\n\t\t\t\t\t\tif (toolOutput.status === \"completed\") return 0;\n\t\t\t\t\t\tif (toolOutput.status === \"incomplete\") return 127;\n\t\t\t\t\t\tif (toolOutput.status === \"interpreting\") return void 0;\n\t\t\t\t\t\tif (toolOutput.status === \"failed\") return 1;\n\t\t\t\t\t\treturn void 0;\n\t\t\t\t\t});\n\t\t\t\t\tfor (const output of toolOutput.outputs) if (_isContentBlock(output, \"logs\")) {\n\t\t\t\t\t\tyield {\n\t\t\t\t\t\t\ttype: \"server_tool_call_result\",\n\t\t\t\t\t\t\ttoolCallId: toolOutput.id ?? \"\",\n\t\t\t\t\t\t\tstatus: \"success\",\n\t\t\t\t\t\t\toutput: {\n\t\t\t\t\t\t\t\ttype: \"code_interpreter_output\",\n\t\t\t\t\t\t\t\treturnCode: returnCode ?? 0,\n\t\t\t\t\t\t\t\tstderr: [0, void 0].includes(returnCode) ? void 0 : String(output.logs),\n\t\t\t\t\t\t\t\tstdout: [0, void 0].includes(returnCode) ? String(output.logs) : void 0\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t};\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(toolOutput, \"mcp_call\")) {\n\t\t\t\tyield {\n\t\t\t\t\tid: toolOutput.id,\n\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\tname: \"mcp_call\",\n\t\t\t\t\targs: toolOutput.input\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(toolOutput, \"mcp_list_tools\")) {\n\t\t\t\tyield {\n\t\t\t\t\tid: toolOutput.id,\n\t\t\t\t\ttype: \"server_tool_call\",\n\t\t\t\t\tname: \"mcp_list_tools\",\n\t\t\t\t\targs: toolOutput.input\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(toolOutput, \"mcp_approval_request\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: toolOutput\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(toolOutput, \"image_generation_call\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: toolOutput\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (_isObject(toolOutput)) yield {\n\t\t\t\ttype: \"non_standard\",\n\t\t\t\tvalue: toolOutput\n\t\t\t};\n\t\t}\n\t}\n\treturn Array.from(iterateContent());\n}\n/**\n* Converts a ChatOpenAIResponses message chunk to an array of v1 standard content blocks.\n*\n* This function processes an AI message chunk containing OpenAI-specific content blocks\n* and converts them to the standardized v1 content block format. It handles both the\n* regular message content and tool call chunks that are specific to streaming responses.\n*\n* @param message - The AI message chunk containing OpenAI-formatted content blocks\n* @returns Array of content blocks in v1 standard format\n*\n* @example\n* ```typescript\n* const messageChunk = new AIMessageChunk({\n*   content: [{ type: \"text\", text: \"Hello\" }],\n*   tool_call_chunks: [\n*     { id: \"call_123\", name: \"calculator\", args: '{\"a\": 1' }\n*   ]\n* });\n*\n* const standardBlocks = convertToV1FromResponsesChunk(messageChunk);\n* // Returns:\n* // [\n* //   { type: \"text\", text: \"Hello\" },\n* //   { type: \"tool_call_chunk\", id: \"call_123\", name: \"calculator\", args: '{\"a\": 1' }\n* // ]\n* ```\n*/\nfunction convertToV1FromResponsesChunk(message) {\n\tfunction* iterateContent() {\n\t\tyield* convertToV1FromResponses(message);\n\t\tfor (const toolCallChunk of message.tool_call_chunks ?? []) yield {\n\t\t\ttype: \"tool_call_chunk\",\n\t\t\tid: toolCallChunk.id,\n\t\t\tname: toolCallChunk.name,\n\t\t\targs: toolCallChunk.args\n\t\t};\n\t}\n\treturn Array.from(iterateContent());\n}\nconst ChatOpenAITranslator = {\n\ttranslateContent: (message) => {\n\t\tif (typeof message.content === \"string\") return convertToV1FromChatCompletions(message);\n\t\treturn convertToV1FromResponses(message);\n\t},\n\ttranslateContentChunk: (message) => {\n\t\tif (typeof message.content === \"string\") return convertToV1FromChatCompletionsChunk(message);\n\t\treturn convertToV1FromResponsesChunk(message);\n\t}\n};\n\n//#endregion\nexport { ChatOpenAITranslator, convertToV1FromChatCompletionsInput };\n//# sourceMappingURL=openai.js.map","//#region src/messages/message.ts\n/**\n* Type guard to check if a value is a valid Message object.\n*\n* @param message - The value to check\n* @returns true if the value is a valid Message object, false otherwise\n*/\nfunction isMessage(message) {\n\treturn typeof message === \"object\" && message !== null && \"type\" in message && \"content\" in message && (typeof message.content === \"string\" || Array.isArray(message.content));\n}\n\n//#endregion\nexport { isMessage };\n//# sourceMappingURL=message.js.map","//#region src/messages/format.ts\nfunction convertToFormattedString(message, format = \"pretty\") {\n\tif (format === \"pretty\") return convertToPrettyString(message);\n\treturn JSON.stringify(message);\n}\nfunction convertToPrettyString(message) {\n\tconst lines = [];\n\tconst title = ` ${message.type.charAt(0).toUpperCase() + message.type.slice(1)} Message `;\n\tconst sepLen = Math.floor((80 - title.length) / 2);\n\tconst sep = \"=\".repeat(sepLen);\n\tconst secondSep = title.length % 2 === 0 ? sep : `${sep}=`;\n\tlines.push(`${sep}${title}${secondSep}`);\n\tif (message.type === \"ai\") {\n\t\tconst aiMessage = message;\n\t\tif (aiMessage.tool_calls && aiMessage.tool_calls.length > 0) {\n\t\t\tlines.push(\"Tool Calls:\");\n\t\t\tfor (const tc of aiMessage.tool_calls) {\n\t\t\t\tlines.push(`  ${tc.name} (${tc.id})`);\n\t\t\t\tlines.push(` Call ID: ${tc.id}`);\n\t\t\t\tlines.push(\"  Args:\");\n\t\t\t\tfor (const [key, value] of Object.entries(tc.args)) lines.push(`    ${key}: ${value}`);\n\t\t\t}\n\t\t}\n\t}\n\tif (message.type === \"tool\") {\n\t\tconst toolMessage = message;\n\t\tif (toolMessage.name) lines.push(`Name: ${toolMessage.name}`);\n\t}\n\tif (typeof message.content === \"string\" && message.content.trim()) {\n\t\tif (lines.length > 1) lines.push(\"\");\n\t\tlines.push(message.content);\n\t}\n\treturn lines.join(\"\\n\");\n}\n\n//#endregion\nexport { convertToFormattedString };\n//# sourceMappingURL=format.js.map","import { Serializable } from \"../load/serializable.js\";\nimport { isDataContentBlock } from \"./content/data.js\";\nimport { convertToV1FromAnthropicInput } from \"./block_translators/anthropic.js\";\nimport { convertToV1FromDataContent } from \"./block_translators/data.js\";\nimport { convertToV1FromChatCompletionsInput } from \"./block_translators/openai.js\";\nimport { isMessage } from \"./message.js\";\nimport { convertToFormattedString } from \"./format.js\";\n\n//#region src/messages/base.ts\n/** @internal */\nconst MESSAGE_SYMBOL = Symbol.for(\"langchain.message\");\nfunction mergeContent(firstContent, secondContent) {\n\tif (typeof firstContent === \"string\") {\n\t\tif (firstContent === \"\") return secondContent;\n\t\tif (typeof secondContent === \"string\") return firstContent + secondContent;\n\t\telse if (Array.isArray(secondContent) && secondContent.some((c) => isDataContentBlock(c))) return [{\n\t\t\ttype: \"text\",\n\t\t\tsource_type: \"text\",\n\t\t\ttext: firstContent\n\t\t}, ...secondContent];\n\t\telse return [{\n\t\t\ttype: \"text\",\n\t\t\ttext: firstContent\n\t\t}, ...secondContent];\n\t} else if (Array.isArray(secondContent)) return _mergeLists(firstContent, secondContent) ?? [...firstContent, ...secondContent];\n\telse if (secondContent === \"\") return firstContent;\n\telse if (Array.isArray(firstContent) && firstContent.some((c) => isDataContentBlock(c))) return [...firstContent, {\n\t\ttype: \"file\",\n\t\tsource_type: \"text\",\n\t\ttext: secondContent\n\t}];\n\telse return [...firstContent, {\n\t\ttype: \"text\",\n\t\ttext: secondContent\n\t}];\n}\n/**\n* 'Merge' two statuses. If either value passed is 'error', it will return 'error'. Else\n* it will return 'success'.\n*\n* @param {\"success\" | \"error\" | undefined} left The existing value to 'merge' with the new value.\n* @param {\"success\" | \"error\" | undefined} right The new value to 'merge' with the existing value\n* @returns {\"success\" | \"error\"} The 'merged' value.\n*/\nfunction _mergeStatus(left, right) {\n\tif (left === \"error\" || right === \"error\") return \"error\";\n\treturn \"success\";\n}\nfunction stringifyWithDepthLimit(obj, depthLimit) {\n\tfunction helper(obj$1, currentDepth) {\n\t\tif (typeof obj$1 !== \"object\" || obj$1 === null || obj$1 === void 0) return obj$1;\n\t\tif (currentDepth >= depthLimit) {\n\t\t\tif (Array.isArray(obj$1)) return \"[Array]\";\n\t\t\treturn \"[Object]\";\n\t\t}\n\t\tif (Array.isArray(obj$1)) return obj$1.map((item) => helper(item, currentDepth + 1));\n\t\tconst result = {};\n\t\tfor (const key of Object.keys(obj$1)) result[key] = helper(obj$1[key], currentDepth + 1);\n\t\treturn result;\n\t}\n\treturn JSON.stringify(helper(obj, 0), null, 2);\n}\n/**\n* Base class for all types of messages in a conversation. It includes\n* properties like `content`, `name`, and `additional_kwargs`. It also\n* includes methods like `toDict()` and `_getType()`.\n*/\nvar BaseMessage = class extends Serializable {\n\tlc_namespace = [\"langchain_core\", \"messages\"];\n\tlc_serializable = true;\n\tget lc_aliases() {\n\t\treturn {\n\t\t\tadditional_kwargs: \"additional_kwargs\",\n\t\t\tresponse_metadata: \"response_metadata\"\n\t\t};\n\t}\n\t[MESSAGE_SYMBOL] = true;\n\tid;\n\tname;\n\tcontent;\n\tadditional_kwargs;\n\tresponse_metadata;\n\t/**\n\t* @deprecated Use .getType() instead or import the proper typeguard.\n\t* For example:\n\t*\n\t* ```ts\n\t* import { isAIMessage } from \"@langchain/core/messages\";\n\t*\n\t* const message = new AIMessage(\"Hello!\");\n\t* isAIMessage(message); // true\n\t* ```\n\t*/\n\t_getType() {\n\t\treturn this.type;\n\t}\n\t/**\n\t* @deprecated Use .type instead\n\t* The type of the message.\n\t*/\n\tgetType() {\n\t\treturn this._getType();\n\t}\n\tconstructor(arg) {\n\t\tconst fields = typeof arg === \"string\" || Array.isArray(arg) ? { content: arg } : arg;\n\t\tif (!fields.additional_kwargs) fields.additional_kwargs = {};\n\t\tif (!fields.response_metadata) fields.response_metadata = {};\n\t\tsuper(fields);\n\t\tthis.name = fields.name;\n\t\tif (fields.content === void 0 && fields.contentBlocks !== void 0) {\n\t\t\tthis.content = fields.contentBlocks;\n\t\t\tthis.response_metadata = {\n\t\t\t\toutput_version: \"v1\",\n\t\t\t\t...fields.response_metadata\n\t\t\t};\n\t\t} else if (fields.content !== void 0) {\n\t\t\tthis.content = fields.content ?? [];\n\t\t\tthis.response_metadata = fields.response_metadata;\n\t\t} else {\n\t\t\tthis.content = [];\n\t\t\tthis.response_metadata = fields.response_metadata;\n\t\t}\n\t\tthis.additional_kwargs = fields.additional_kwargs;\n\t\tthis.id = fields.id;\n\t}\n\t/** Get text content of the message. */\n\tget text() {\n\t\tif (typeof this.content === \"string\") return this.content;\n\t\tif (!Array.isArray(this.content)) return \"\";\n\t\treturn this.content.map((c) => {\n\t\t\tif (typeof c === \"string\") return c;\n\t\t\tif (c.type === \"text\") return c.text;\n\t\t\treturn \"\";\n\t\t}).join(\"\");\n\t}\n\tget contentBlocks() {\n\t\tconst blocks = typeof this.content === \"string\" ? [{\n\t\t\ttype: \"text\",\n\t\t\ttext: this.content\n\t\t}] : this.content;\n\t\tconst parsingSteps = [\n\t\t\tconvertToV1FromDataContent,\n\t\t\tconvertToV1FromChatCompletionsInput,\n\t\t\tconvertToV1FromAnthropicInput\n\t\t];\n\t\tconst parsedBlocks = parsingSteps.reduce((blocks$1, step) => step(blocks$1), blocks);\n\t\treturn parsedBlocks;\n\t}\n\ttoDict() {\n\t\treturn {\n\t\t\ttype: this.getType(),\n\t\t\tdata: this.toJSON().kwargs\n\t\t};\n\t}\n\tstatic lc_name() {\n\t\treturn \"BaseMessage\";\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\tid: this.id,\n\t\t\tcontent: this.content,\n\t\t\tname: this.name,\n\t\t\tadditional_kwargs: this.additional_kwargs,\n\t\t\tresponse_metadata: this.response_metadata\n\t\t};\n\t}\n\tstatic isInstance(obj) {\n\t\treturn typeof obj === \"object\" && obj !== null && MESSAGE_SYMBOL in obj && obj[MESSAGE_SYMBOL] === true && isMessage(obj);\n\t}\n\t_updateId(value) {\n\t\tthis.id = value;\n\t\tthis.lc_kwargs.id = value;\n\t}\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.lc_name();\n\t}\n\t[Symbol.for(\"nodejs.util.inspect.custom\")](depth) {\n\t\tif (depth === null) return this;\n\t\tconst printable = stringifyWithDepthLimit(this._printableFields, Math.max(4, depth));\n\t\treturn `${this.constructor.lc_name()} ${printable}`;\n\t}\n\ttoFormattedString(format = \"pretty\") {\n\t\treturn convertToFormattedString(this, format);\n\t}\n};\nfunction isOpenAIToolCallArray(value) {\n\treturn Array.isArray(value) && value.every((v) => typeof v.index === \"number\");\n}\nfunction _mergeDicts(left = {}, right = {}) {\n\tconst merged = { ...left };\n\tfor (const [key, value] of Object.entries(right)) if (merged[key] == null) merged[key] = value;\n\telse if (value == null) continue;\n\telse if (typeof merged[key] !== typeof value || Array.isArray(merged[key]) !== Array.isArray(value)) throw new Error(`field[${key}] already exists in the message chunk, but with a different type.`);\n\telse if (typeof merged[key] === \"string\") if (key === \"type\") continue;\n\telse if ([\n\t\t\"id\",\n\t\t\"name\",\n\t\t\"output_version\",\n\t\t\"model_provider\"\n\t].includes(key)) merged[key] = value;\n\telse merged[key] += value;\n\telse if (typeof merged[key] === \"object\" && !Array.isArray(merged[key])) merged[key] = _mergeDicts(merged[key], value);\n\telse if (Array.isArray(merged[key])) merged[key] = _mergeLists(merged[key], value);\n\telse if (merged[key] === value) continue;\n\telse console.warn(`field[${key}] already exists in this message chunk and value has unsupported type.`);\n\treturn merged;\n}\nfunction _mergeLists(left, right) {\n\tif (left === void 0 && right === void 0) return void 0;\n\telse if (left === void 0 || right === void 0) return left || right;\n\telse {\n\t\tconst merged = [...left];\n\t\tfor (const item of right) if (typeof item === \"object\" && item !== null && \"index\" in item && typeof item.index === \"number\") {\n\t\t\tconst toMerge = merged.findIndex((leftItem) => {\n\t\t\t\tconst isObject = typeof leftItem === \"object\";\n\t\t\t\tconst indiciesMatch = \"index\" in leftItem && leftItem.index === item.index;\n\t\t\t\tconst idsMatch = \"id\" in leftItem && \"id\" in item && leftItem?.id === item?.id;\n\t\t\t\tconst eitherItemMissingID = !(\"id\" in leftItem) || !leftItem?.id || !(\"id\" in item) || !item?.id;\n\t\t\t\treturn isObject && indiciesMatch && (idsMatch || eitherItemMissingID);\n\t\t\t});\n\t\t\tif (toMerge !== -1 && typeof merged[toMerge] === \"object\" && merged[toMerge] !== null) merged[toMerge] = _mergeDicts(merged[toMerge], item);\n\t\t\telse merged.push(item);\n\t\t} else if (typeof item === \"object\" && item !== null && \"text\" in item && item.text === \"\") continue;\n\t\telse merged.push(item);\n\t\treturn merged;\n\t}\n}\nfunction _mergeObj(left, right) {\n\tif (!left && !right) throw new Error(\"Cannot merge two undefined objects.\");\n\tif (!left || !right) return left || right;\n\telse if (typeof left !== typeof right) throw new Error(`Cannot merge objects of different types.\\nLeft ${typeof left}\\nRight ${typeof right}`);\n\telse if (typeof left === \"string\" && typeof right === \"string\") return left + right;\n\telse if (Array.isArray(left) && Array.isArray(right)) return _mergeLists(left, right);\n\telse if (typeof left === \"object\" && typeof right === \"object\") return _mergeDicts(left, right);\n\telse if (left === right) return left;\n\telse throw new Error(`Can not merge objects of different types.\\nLeft ${left}\\nRight ${right}`);\n}\n/**\n* Represents a chunk of a message, which can be concatenated with other\n* message chunks. It includes a method `_merge_kwargs_dict()` for merging\n* additional keyword arguments from another `BaseMessageChunk` into this\n* one. It also overrides the `__add__()` method to support concatenation\n* of `BaseMessageChunk` instances.\n*/\nvar BaseMessageChunk = class extends BaseMessage {\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && \"concat\" in obj && typeof obj.concat === \"function\";\n\t}\n};\nfunction _isMessageFieldWithRole(x) {\n\treturn typeof x.role === \"string\";\n}\n/**\n* @deprecated Use {@link BaseMessage.isInstance} instead\n*/\nfunction isBaseMessage(messageLike) {\n\treturn typeof messageLike?._getType === \"function\";\n}\n/**\n* @deprecated Use {@link BaseMessageChunk.isInstance} instead\n*/\nfunction isBaseMessageChunk(messageLike) {\n\treturn isBaseMessage(messageLike) && typeof messageLike.concat === \"function\";\n}\n\n//#endregion\nexport { BaseMessage, BaseMessageChunk, _isMessageFieldWithRole, _mergeDicts, _mergeLists, _mergeObj, _mergeStatus, isBaseMessage, isBaseMessageChunk, isOpenAIToolCallArray, mergeContent };\n//# sourceMappingURL=base.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { BaseMessage, BaseMessageChunk, _mergeDicts, _mergeObj, _mergeStatus, mergeContent } from \"./base.js\";\n\n//#region src/messages/tool.ts\nvar tool_exports = {};\n__export(tool_exports, {\n\tToolMessage: () => ToolMessage,\n\tToolMessageChunk: () => ToolMessageChunk,\n\tdefaultToolCallParser: () => defaultToolCallParser,\n\tisDirectToolOutput: () => isDirectToolOutput,\n\tisToolMessage: () => isToolMessage,\n\tisToolMessageChunk: () => isToolMessageChunk\n});\nfunction isDirectToolOutput(x) {\n\treturn x != null && typeof x === \"object\" && \"lc_direct_tool_output\" in x && x.lc_direct_tool_output === true;\n}\n/**\n* Represents a tool message in a conversation.\n*/\nvar ToolMessage = class extends BaseMessage {\n\tstatic lc_name() {\n\t\treturn \"ToolMessage\";\n\t}\n\tget lc_aliases() {\n\t\treturn { tool_call_id: \"tool_call_id\" };\n\t}\n\tlc_direct_tool_output = true;\n\ttype = \"tool\";\n\t/**\n\t* Status of the tool invocation.\n\t* @version 0.2.19\n\t*/\n\tstatus;\n\ttool_call_id;\n\tmetadata;\n\t/**\n\t* Artifact of the Tool execution which is not meant to be sent to the model.\n\t*\n\t* Should only be specified if it is different from the message content, e.g. if only\n\t* a subset of the full tool output is being passed as message content but the full\n\t* output is needed in other parts of the code.\n\t*/\n\tartifact;\n\tconstructor(fields, tool_call_id, name) {\n\t\tconst toolMessageFields = typeof fields === \"string\" || Array.isArray(fields) ? {\n\t\t\tcontent: fields,\n\t\t\tname,\n\t\t\ttool_call_id\n\t\t} : fields;\n\t\tsuper(toolMessageFields);\n\t\tthis.tool_call_id = toolMessageFields.tool_call_id;\n\t\tthis.artifact = toolMessageFields.artifact;\n\t\tthis.status = toolMessageFields.status;\n\t\tthis.metadata = toolMessageFields.metadata;\n\t}\n\tstatic isInstance(message) {\n\t\treturn super.isInstance(message) && message.type === \"tool\";\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\t...super._printableFields,\n\t\t\ttool_call_id: this.tool_call_id,\n\t\t\tartifact: this.artifact\n\t\t};\n\t}\n};\n/**\n* Represents a chunk of a tool message, which can be concatenated\n* with other tool message chunks.\n*/\nvar ToolMessageChunk = class extends BaseMessageChunk {\n\ttype = \"tool\";\n\ttool_call_id;\n\t/**\n\t* Status of the tool invocation.\n\t* @version 0.2.19\n\t*/\n\tstatus;\n\t/**\n\t* Artifact of the Tool execution which is not meant to be sent to the model.\n\t*\n\t* Should only be specified if it is different from the message content, e.g. if only\n\t* a subset of the full tool output is being passed as message content but the full\n\t* output is needed in other parts of the code.\n\t*/\n\tartifact;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.tool_call_id = fields.tool_call_id;\n\t\tthis.artifact = fields.artifact;\n\t\tthis.status = fields.status;\n\t}\n\tstatic lc_name() {\n\t\treturn \"ToolMessageChunk\";\n\t}\n\tconcat(chunk) {\n\t\tconst Cls = this.constructor;\n\t\treturn new Cls({\n\t\t\tcontent: mergeContent(this.content, chunk.content),\n\t\t\tadditional_kwargs: _mergeDicts(this.additional_kwargs, chunk.additional_kwargs),\n\t\t\tresponse_metadata: _mergeDicts(this.response_metadata, chunk.response_metadata),\n\t\t\tartifact: _mergeObj(this.artifact, chunk.artifact),\n\t\t\ttool_call_id: this.tool_call_id,\n\t\t\tid: this.id ?? chunk.id,\n\t\t\tstatus: _mergeStatus(this.status, chunk.status)\n\t\t});\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\t...super._printableFields,\n\t\t\ttool_call_id: this.tool_call_id,\n\t\t\tartifact: this.artifact\n\t\t};\n\t}\n};\nfunction defaultToolCallParser(rawToolCalls) {\n\tconst toolCalls = [];\n\tconst invalidToolCalls = [];\n\tfor (const toolCall of rawToolCalls) if (!toolCall.function) continue;\n\telse {\n\t\tconst functionName = toolCall.function.name;\n\t\ttry {\n\t\t\tconst functionArgs = JSON.parse(toolCall.function.arguments);\n\t\t\ttoolCalls.push({\n\t\t\t\tname: functionName || \"\",\n\t\t\t\targs: functionArgs || {},\n\t\t\t\tid: toolCall.id\n\t\t\t});\n\t\t} catch {\n\t\t\tinvalidToolCalls.push({\n\t\t\t\tname: functionName,\n\t\t\t\targs: toolCall.function.arguments,\n\t\t\t\tid: toolCall.id,\n\t\t\t\terror: \"Malformed args.\"\n\t\t\t});\n\t\t}\n\t}\n\treturn [toolCalls, invalidToolCalls];\n}\n/**\n* @deprecated Use {@link ToolMessage.isInstance} instead\n*/\nfunction isToolMessage(x) {\n\treturn typeof x === \"object\" && x !== null && \"getType\" in x && typeof x.getType === \"function\" && x.getType() === \"tool\";\n}\n/**\n* @deprecated Use {@link ToolMessageChunk.isInstance} instead\n*/\nfunction isToolMessageChunk(x) {\n\treturn x._getType() === \"tool\";\n}\n\n//#endregion\nexport { ToolMessage, ToolMessageChunk, defaultToolCallParser, isDirectToolOutput, isToolMessage, isToolMessageChunk, tool_exports };\n//# sourceMappingURL=tool.js.map","//#region src/utils/json.ts\nfunction parseJsonMarkdown(s, parser = parsePartialJson) {\n\ts = s.trim();\n\tconst firstFenceIndex = s.indexOf(\"```\");\n\tif (firstFenceIndex === -1) return parser(s);\n\tlet contentAfterFence = s.substring(firstFenceIndex + 3);\n\tif (contentAfterFence.startsWith(\"json\\n\")) contentAfterFence = contentAfterFence.substring(5);\n\telse if (contentAfterFence.startsWith(\"json\")) contentAfterFence = contentAfterFence.substring(4);\n\telse if (contentAfterFence.startsWith(\"\\n\")) contentAfterFence = contentAfterFence.substring(1);\n\tconst closingFenceIndex = contentAfterFence.indexOf(\"```\");\n\tlet finalContent = contentAfterFence;\n\tif (closingFenceIndex !== -1) finalContent = contentAfterFence.substring(0, closingFenceIndex);\n\treturn parser(finalContent.trim());\n}\nfunction parsePartialJson(s) {\n\tif (typeof s === \"undefined\") return null;\n\ttry {\n\t\treturn JSON.parse(s);\n\t} catch {}\n\tlet new_s = \"\";\n\tconst stack = [];\n\tlet isInsideString = false;\n\tlet escaped = false;\n\tfor (let char of s) {\n\t\tif (isInsideString) if (char === \"\\\"\" && !escaped) isInsideString = false;\n\t\telse if (char === \"\\n\" && !escaped) char = \"\\\\n\";\n\t\telse if (char === \"\\\\\") escaped = !escaped;\n\t\telse escaped = false;\n\t\telse if (char === \"\\\"\") {\n\t\t\tisInsideString = true;\n\t\t\tescaped = false;\n\t\t} else if (char === \"{\") stack.push(\"}\");\n\t\telse if (char === \"[\") stack.push(\"]\");\n\t\telse if (char === \"}\" || char === \"]\") if (stack && stack[stack.length - 1] === char) stack.pop();\n\t\telse return null;\n\t\tnew_s += char;\n\t}\n\tif (isInsideString) new_s += \"\\\"\";\n\tfor (let i = stack.length - 1; i >= 0; i -= 1) new_s += stack[i];\n\ttry {\n\t\treturn JSON.parse(new_s);\n\t} catch {\n\t\treturn null;\n\t}\n}\n\n//#endregion\nexport { parseJsonMarkdown, parsePartialJson };\n//# sourceMappingURL=json.js.map","import { _isArray, _isBytesArray, _isContentBlock, _isNumber, _isObject, _isString, iife } from \"./utils.js\";\n\n//#region src/messages/block_translators/bedrock_converse.ts\nfunction convertFileFormatToMimeType(format) {\n\tswitch (format) {\n\t\tcase \"csv\": return \"text/csv\";\n\t\tcase \"doc\": return \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\";\n\t\tcase \"docx\": return \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\";\n\t\tcase \"html\": return \"text/html\";\n\t\tcase \"md\": return \"text/markdown\";\n\t\tcase \"pdf\": return \"application/pdf\";\n\t\tcase \"txt\": return \"text/plain\";\n\t\tcase \"xls\": return \"application/vnd.ms-excel\";\n\t\tcase \"xlsx\": return \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\";\n\t\tcase \"gif\": return \"image/gif\";\n\t\tcase \"jpeg\": return \"image/jpeg\";\n\t\tcase \"jpg\": return \"image/jpeg\";\n\t\tcase \"png\": return \"image/png\";\n\t\tcase \"webp\": return \"image/webp\";\n\t\tcase \"flv\": return \"video/flv\";\n\t\tcase \"mkv\": return \"video/mkv\";\n\t\tcase \"mov\": return \"video/mov\";\n\t\tcase \"mp4\": return \"video/mp4\";\n\t\tcase \"mpeg\": return \"video/mpeg\";\n\t\tcase \"mpg\": return \"video/mpg\";\n\t\tcase \"three_gp\": return \"video/three_gp\";\n\t\tcase \"webm\": return \"video/webm\";\n\t\tcase \"wmv\": return \"video/wmv\";\n\t\tdefault: return \"application/octet-stream\";\n\t}\n}\nfunction convertConverseDocumentBlock(block) {\n\tif (_isObject(block.document) && _isObject(block.document.source)) {\n\t\tconst format = _isObject(block.document) && _isString(block.document.format) ? block.document.format : \"\";\n\t\tconst mimeType = convertFileFormatToMimeType(format);\n\t\tif (_isObject(block.document.source)) {\n\t\t\tif (_isObject(block.document.source.s3Location) && _isString(block.document.source.s3Location.uri)) return {\n\t\t\t\ttype: \"file\",\n\t\t\t\tmimeType,\n\t\t\t\tfileId: block.document.source.s3Location.uri\n\t\t\t};\n\t\t\tif (_isBytesArray(block.document.source.bytes)) return {\n\t\t\t\ttype: \"file\",\n\t\t\t\tmimeType,\n\t\t\t\tdata: block.document.source.bytes\n\t\t\t};\n\t\t\tif (_isString(block.document.source.text)) return {\n\t\t\t\ttype: \"file\",\n\t\t\t\tmimeType,\n\t\t\t\tdata: Buffer.from(block.document.source.text).toString(\"base64\")\n\t\t\t};\n\t\t\tif (_isArray(block.document.source.content)) {\n\t\t\t\tconst data = block.document.source.content.reduce((acc, item) => {\n\t\t\t\t\tif (_isObject(item) && _isString(item.text)) return acc + item.text;\n\t\t\t\t\treturn acc;\n\t\t\t\t}, \"\");\n\t\t\t\treturn {\n\t\t\t\t\ttype: \"file\",\n\t\t\t\t\tmimeType,\n\t\t\t\t\tdata\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\treturn {\n\t\ttype: \"non_standard\",\n\t\tvalue: block\n\t};\n}\nfunction convertConverseImageBlock(block) {\n\tif (_isContentBlock(block, \"image\") && _isObject(block.image)) {\n\t\tconst format = _isObject(block.image) && _isString(block.image.format) ? block.image.format : \"\";\n\t\tconst mimeType = convertFileFormatToMimeType(format);\n\t\tif (_isObject(block.image.source)) {\n\t\t\tif (_isObject(block.image.source.s3Location) && _isString(block.image.source.s3Location.uri)) return {\n\t\t\t\ttype: \"image\",\n\t\t\t\tmimeType,\n\t\t\t\tfileId: block.image.source.s3Location.uri\n\t\t\t};\n\t\t\tif (_isBytesArray(block.image.source.bytes)) return {\n\t\t\t\ttype: \"image\",\n\t\t\t\tmimeType,\n\t\t\t\tdata: block.image.source.bytes\n\t\t\t};\n\t\t}\n\t}\n\treturn {\n\t\ttype: \"non_standard\",\n\t\tvalue: block\n\t};\n}\nfunction convertConverseVideoBlock(block) {\n\tif (_isContentBlock(block, \"video\") && _isObject(block.video)) {\n\t\tconst format = _isObject(block.video) && _isString(block.video.format) ? block.video.format : \"\";\n\t\tconst mimeType = convertFileFormatToMimeType(format);\n\t\tif (_isObject(block.video.source)) {\n\t\t\tif (_isObject(block.video.source.s3Location) && _isString(block.video.source.s3Location.uri)) return {\n\t\t\t\ttype: \"video\",\n\t\t\t\tmimeType,\n\t\t\t\tfileId: block.video.source.s3Location.uri\n\t\t\t};\n\t\t\tif (_isBytesArray(block.video.source.bytes)) return {\n\t\t\t\ttype: \"video\",\n\t\t\t\tmimeType,\n\t\t\t\tdata: block.video.source.bytes\n\t\t\t};\n\t\t}\n\t}\n\treturn {\n\t\ttype: \"non_standard\",\n\t\tvalue: block\n\t};\n}\nfunction convertToV1FromChatBedrockConverseMessage(message) {\n\tfunction* iterateContent() {\n\t\tconst content = typeof message.content === \"string\" ? [{\n\t\t\ttype: \"text\",\n\t\t\ttext: message.content\n\t\t}] : message.content;\n\t\tfor (const block of content) {\n\t\t\tif (_isContentBlock(block, \"cache_point\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"citations_content\") && _isObject(block.citationsContent)) {\n\t\t\t\tconst text = _isArray(block.citationsContent.content) ? block.citationsContent.content.reduce((acc, item) => {\n\t\t\t\t\tif (_isObject(item) && _isString(item.text)) return acc + item.text;\n\t\t\t\t\treturn acc;\n\t\t\t\t}, \"\") : \"\";\n\t\t\t\tconst annotations = _isArray(block.citationsContent.citations) ? block.citationsContent.citations.reduce((acc, item) => {\n\t\t\t\t\tif (_isObject(item)) {\n\t\t\t\t\t\tconst citedText = _isArray(item.sourceContent) ? item.sourceContent.reduce((acc$1, item$1) => {\n\t\t\t\t\t\t\tif (_isObject(item$1) && _isString(item$1.text)) return acc$1 + item$1.text;\n\t\t\t\t\t\t\treturn acc$1;\n\t\t\t\t\t\t}, \"\") : \"\";\n\t\t\t\t\t\tconst properties = iife(() => {\n\t\t\t\t\t\t\tif (_isObject(item.location)) {\n\t\t\t\t\t\t\t\tconst location = item.location.documentChar || item.location.documentPage || item.location.documentChunk;\n\t\t\t\t\t\t\t\tif (_isObject(location)) return {\n\t\t\t\t\t\t\t\t\tsource: _isNumber(location.documentIndex) ? location.documentIndex.toString() : void 0,\n\t\t\t\t\t\t\t\t\tstartIndex: _isNumber(location.start) ? location.start : void 0,\n\t\t\t\t\t\t\t\t\tendIndex: _isNumber(location.end) ? location.end : void 0\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn {};\n\t\t\t\t\t\t});\n\t\t\t\t\t\tacc.push({\n\t\t\t\t\t\t\ttype: \"citation\",\n\t\t\t\t\t\t\tcitedText,\n\t\t\t\t\t\t\t...properties\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t\treturn acc;\n\t\t\t\t}, []) : [];\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"text\",\n\t\t\t\t\ttext,\n\t\t\t\t\tannotations\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"document\") && _isObject(block.document)) {\n\t\t\t\tyield convertConverseDocumentBlock(block);\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"guard_content\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"image\") && _isObject(block.image)) {\n\t\t\t\tyield convertConverseImageBlock(block);\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"reasoning_content\") && _isString(block.reasoningText)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"reasoning\",\n\t\t\t\t\treasoning: block.reasoningText\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"text\") && _isString(block.text)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"text\",\n\t\t\t\t\ttext: block.text\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"tool_result\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"tool_call\")) continue;\n\t\t\telse if (_isContentBlock(block, \"video\") && _isObject(block.video)) {\n\t\t\t\tyield convertConverseVideoBlock(block);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tyield {\n\t\t\t\ttype: \"non_standard\",\n\t\t\t\tvalue: block\n\t\t\t};\n\t\t}\n\t}\n\treturn Array.from(iterateContent());\n}\nconst ChatBedrockConverseTranslator = {\n\ttranslateContent: convertToV1FromChatBedrockConverseMessage,\n\ttranslateContentChunk: convertToV1FromChatBedrockConverseMessage\n};\n\n//#endregion\nexport { ChatBedrockConverseTranslator };\n//# sourceMappingURL=bedrock_converse.js.map","import { _isContentBlock, _isObject, _isString } from \"./utils.js\";\n\n//#region src/messages/block_translators/google_genai.ts\nfunction convertToV1FromChatGoogleMessage(message) {\n\tfunction* iterateContent() {\n\t\tconst content = typeof message.content === \"string\" ? [{\n\t\t\ttype: \"text\",\n\t\t\ttext: message.content\n\t\t}] : message.content;\n\t\tfor (const block of content) {\n\t\t\tif (_isContentBlock(block, \"text\") && _isString(block.text)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"text\",\n\t\t\t\t\ttext: block.text\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"inlineData\") && _isObject(block.inlineData) && _isString(block.inlineData.mimeType) && _isString(block.inlineData.data)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"file\",\n\t\t\t\t\tmimeType: block.inlineData.mimeType,\n\t\t\t\t\tdata: block.inlineData.data\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"functionCall\") && _isObject(block.functionCall) && _isString(block.functionCall.name) && _isObject(block.functionCall.args)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"tool_call\",\n\t\t\t\t\tid: message.id,\n\t\t\t\t\tname: block.functionCall.name,\n\t\t\t\t\targs: block.functionCall.args\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"functionResponse\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"fileData\") && _isObject(block.fileData) && _isString(block.fileData.mimeType) && _isString(block.fileData.fileUri)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"file\",\n\t\t\t\t\tmimeType: block.fileData.mimeType,\n\t\t\t\t\tfileId: block.fileData.fileUri\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"executableCode\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"codeExecutionResult\")) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"non_standard\",\n\t\t\t\t\tvalue: block\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tyield {\n\t\t\t\ttype: \"non_standard\",\n\t\t\t\tvalue: block\n\t\t\t};\n\t\t}\n\t}\n\treturn Array.from(iterateContent());\n}\nconst ChatGoogleGenAITranslator = {\n\ttranslateContent: convertToV1FromChatGoogleMessage,\n\ttranslateContentChunk: convertToV1FromChatGoogleMessage\n};\n\n//#endregion\nexport { ChatGoogleGenAITranslator };\n//# sourceMappingURL=google_genai.js.map","import { _isArray, _isContentBlock, _isString, iife } from \"./utils.js\";\n\n//#region src/messages/block_translators/google_vertexai.ts\nfunction convertToV1FromChatVertexMessage(message) {\n\tfunction* iterateContent() {\n\t\tconst content = typeof message.content === \"string\" ? [{\n\t\t\ttype: \"text\",\n\t\t\ttext: message.content\n\t\t}] : message.content;\n\t\tfor (const block of content) {\n\t\t\tif (_isContentBlock(block, \"reasoning\") && _isString(block.reasoning)) {\n\t\t\t\tconst signature = iife(() => {\n\t\t\t\t\tconst reasoningIndex = content.indexOf(block);\n\t\t\t\t\tif (_isArray(message.additional_kwargs?.signatures) && reasoningIndex >= 0) return message.additional_kwargs.signatures.at(reasoningIndex);\n\t\t\t\t\treturn void 0;\n\t\t\t\t});\n\t\t\t\tif (_isString(signature)) yield {\n\t\t\t\t\ttype: \"reasoning\",\n\t\t\t\t\treasoning: block.reasoning,\n\t\t\t\t\tsignature\n\t\t\t\t};\n\t\t\t\telse yield {\n\t\t\t\t\ttype: \"reasoning\",\n\t\t\t\t\treasoning: block.reasoning\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"text\") && _isString(block.text)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"text\",\n\t\t\t\t\ttext: block.text\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"image_url\")) {\n\t\t\t\tif (_isString(block.image_url)) if (block.image_url.startsWith(\"data:\")) {\n\t\t\t\t\tconst dataUrlRegex = /^data:([^;]+);base64,(.+)$/;\n\t\t\t\t\tconst match = block.image_url.match(dataUrlRegex);\n\t\t\t\t\tif (match) yield {\n\t\t\t\t\t\ttype: \"image\",\n\t\t\t\t\t\tdata: match[2],\n\t\t\t\t\t\tmimeType: match[1]\n\t\t\t\t\t};\n\t\t\t\t\telse yield {\n\t\t\t\t\t\ttype: \"image\",\n\t\t\t\t\t\turl: block.image_url\n\t\t\t\t\t};\n\t\t\t\t} else yield {\n\t\t\t\t\ttype: \"image\",\n\t\t\t\t\turl: block.image_url\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t} else if (_isContentBlock(block, \"media\") && _isString(block.mimeType) && _isString(block.data)) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"file\",\n\t\t\t\t\tmimeType: block.mimeType,\n\t\t\t\t\tdata: block.data\n\t\t\t\t};\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tyield {\n\t\t\t\ttype: \"non_standard\",\n\t\t\t\tvalue: block\n\t\t\t};\n\t\t}\n\t}\n\treturn Array.from(iterateContent());\n}\nconst ChatVertexTranslator = {\n\ttranslateContent: convertToV1FromChatVertexMessage,\n\ttranslateContentChunk: convertToV1FromChatVertexMessage\n};\n\n//#endregion\nexport { ChatVertexTranslator };\n//# sourceMappingURL=google_vertexai.js.map","import { ChatAnthropicTranslator } from \"./anthropic.js\";\nimport { ChatOpenAITranslator } from \"./openai.js\";\nimport { ChatBedrockConverseTranslator } from \"./bedrock_converse.js\";\nimport { ChatGoogleGenAITranslator } from \"./google_genai.js\";\nimport { ChatVertexTranslator } from \"./google_vertexai.js\";\n\n//#region src/messages/block_translators/index.ts\nglobalThis.lc_block_translators_registry ??= new Map([\n\t[\"anthropic\", ChatAnthropicTranslator],\n\t[\"bedrock-converse\", ChatBedrockConverseTranslator],\n\t[\"google-genai\", ChatGoogleGenAITranslator],\n\t[\"google-vertexai\", ChatVertexTranslator],\n\t[\"openai\", ChatOpenAITranslator]\n]);\nfunction getTranslator(modelProvider) {\n\treturn globalThis.lc_block_translators_registry.get(modelProvider);\n}\n\n//#endregion\nexport { getTranslator };\n//# sourceMappingURL=index.js.map","import { _mergeDicts } from \"./base.js\";\n\n//#region src/messages/metadata.ts\nfunction mergeResponseMetadata(a, b) {\n\tconst output = _mergeDicts(a ?? {}, b ?? {});\n\treturn output;\n}\nfunction mergeModalitiesTokenDetails(a, b) {\n\tconst output = {};\n\tif (a?.audio !== void 0 || b?.audio !== void 0) output.audio = (a?.audio ?? 0) + (b?.audio ?? 0);\n\tif (a?.image !== void 0 || b?.image !== void 0) output.image = (a?.image ?? 0) + (b?.image ?? 0);\n\tif (a?.video !== void 0 || b?.video !== void 0) output.video = (a?.video ?? 0) + (b?.video ?? 0);\n\tif (a?.document !== void 0 || b?.document !== void 0) output.document = (a?.document ?? 0) + (b?.document ?? 0);\n\tif (a?.text !== void 0 || b?.text !== void 0) output.text = (a?.text ?? 0) + (b?.text ?? 0);\n\treturn output;\n}\nfunction mergeInputTokenDetails(a, b) {\n\tconst output = { ...mergeModalitiesTokenDetails(a, b) };\n\tif (a?.cache_read !== void 0 || b?.cache_read !== void 0) output.cache_read = (a?.cache_read ?? 0) + (b?.cache_read ?? 0);\n\tif (a?.cache_creation !== void 0 || b?.cache_creation !== void 0) output.cache_creation = (a?.cache_creation ?? 0) + (b?.cache_creation ?? 0);\n\treturn output;\n}\nfunction mergeOutputTokenDetails(a, b) {\n\tconst output = { ...mergeModalitiesTokenDetails(a, b) };\n\tif (a?.reasoning !== void 0 || b?.reasoning !== void 0) output.reasoning = (a?.reasoning ?? 0) + (b?.reasoning ?? 0);\n\treturn output;\n}\nfunction mergeUsageMetadata(a, b) {\n\treturn {\n\t\tinput_tokens: (a?.input_tokens ?? 0) + (b?.input_tokens ?? 0),\n\t\toutput_tokens: (a?.output_tokens ?? 0) + (b?.output_tokens ?? 0),\n\t\ttotal_tokens: (a?.total_tokens ?? 0) + (b?.total_tokens ?? 0),\n\t\tinput_token_details: mergeInputTokenDetails(a?.input_token_details, b?.input_token_details),\n\t\toutput_token_details: mergeOutputTokenDetails(a?.output_token_details, b?.output_token_details)\n\t};\n}\n\n//#endregion\nexport { mergeResponseMetadata, mergeUsageMetadata };\n//# sourceMappingURL=metadata.js.map","import { parsePartialJson } from \"../utils/json.js\";\nimport { BaseMessage, BaseMessageChunk, _mergeDicts, _mergeLists, mergeContent } from \"./base.js\";\nimport { getTranslator } from \"./block_translators/index.js\";\nimport { mergeResponseMetadata, mergeUsageMetadata } from \"./metadata.js\";\nimport { defaultToolCallParser } from \"./tool.js\";\n\n//#region src/messages/ai.ts\nvar AIMessage = class extends BaseMessage {\n\ttype = \"ai\";\n\ttool_calls = [];\n\tinvalid_tool_calls = [];\n\tusage_metadata;\n\tget lc_aliases() {\n\t\treturn {\n\t\t\t...super.lc_aliases,\n\t\t\ttool_calls: \"tool_calls\",\n\t\t\tinvalid_tool_calls: \"invalid_tool_calls\"\n\t\t};\n\t}\n\tconstructor(fields) {\n\t\tlet initParams;\n\t\tif (typeof fields === \"string\" || Array.isArray(fields)) initParams = {\n\t\t\tcontent: fields,\n\t\t\ttool_calls: [],\n\t\t\tinvalid_tool_calls: [],\n\t\t\tadditional_kwargs: {}\n\t\t};\n\t\telse {\n\t\t\tinitParams = fields;\n\t\t\tconst rawToolCalls = initParams.additional_kwargs?.tool_calls;\n\t\t\tconst toolCalls = initParams.tool_calls;\n\t\t\tif (!(rawToolCalls == null) && rawToolCalls.length > 0 && (toolCalls === void 0 || toolCalls.length === 0)) console.warn([\n\t\t\t\t\"New LangChain packages are available that more efficiently handle\",\n\t\t\t\t\"tool calling.\\n\\nPlease upgrade your packages to versions that set\",\n\t\t\t\t\"message tool calls. e.g., `pnpm install @langchain/anthropic`,\",\n\t\t\t\t\"pnpm install @langchain/openai`, etc.\"\n\t\t\t].join(\" \"));\n\t\t\ttry {\n\t\t\t\tif (!(rawToolCalls == null) && toolCalls === void 0) {\n\t\t\t\t\tconst [toolCalls$1, invalidToolCalls] = defaultToolCallParser(rawToolCalls);\n\t\t\t\t\tinitParams.tool_calls = toolCalls$1 ?? [];\n\t\t\t\t\tinitParams.invalid_tool_calls = invalidToolCalls ?? [];\n\t\t\t\t} else {\n\t\t\t\t\tinitParams.tool_calls = initParams.tool_calls ?? [];\n\t\t\t\t\tinitParams.invalid_tool_calls = initParams.invalid_tool_calls ?? [];\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tinitParams.tool_calls = [];\n\t\t\t\tinitParams.invalid_tool_calls = [];\n\t\t\t}\n\t\t\tif (initParams.response_metadata !== void 0 && \"output_version\" in initParams.response_metadata && initParams.response_metadata.output_version === \"v1\") {\n\t\t\t\tinitParams.contentBlocks = initParams.content;\n\t\t\t\tinitParams.content = void 0;\n\t\t\t}\n\t\t\tif (initParams.contentBlocks !== void 0) {\n\t\t\t\tinitParams.contentBlocks.push(...initParams.tool_calls.map((toolCall) => ({\n\t\t\t\t\ttype: \"tool_call\",\n\t\t\t\t\tid: toolCall.id,\n\t\t\t\t\tname: toolCall.name,\n\t\t\t\t\targs: toolCall.args\n\t\t\t\t})));\n\t\t\t\tconst missingToolCalls = initParams.contentBlocks.filter((block) => block.type === \"tool_call\").filter((block) => !initParams.tool_calls?.some((toolCall) => toolCall.id === block.id && toolCall.name === block.name));\n\t\t\t\tif (missingToolCalls.length > 0) initParams.tool_calls = missingToolCalls.map((block) => ({\n\t\t\t\t\ttype: \"tool_call\",\n\t\t\t\t\tid: block.id,\n\t\t\t\t\tname: block.name,\n\t\t\t\t\targs: block.args\n\t\t\t\t}));\n\t\t\t}\n\t\t}\n\t\tsuper(initParams);\n\t\tif (typeof initParams !== \"string\") {\n\t\t\tthis.tool_calls = initParams.tool_calls ?? this.tool_calls;\n\t\t\tthis.invalid_tool_calls = initParams.invalid_tool_calls ?? this.invalid_tool_calls;\n\t\t}\n\t\tthis.usage_metadata = initParams.usage_metadata;\n\t}\n\tstatic lc_name() {\n\t\treturn \"AIMessage\";\n\t}\n\tget contentBlocks() {\n\t\tif (this.response_metadata && \"output_version\" in this.response_metadata && this.response_metadata.output_version === \"v1\") return this.content;\n\t\tif (this.response_metadata && \"model_provider\" in this.response_metadata && typeof this.response_metadata.model_provider === \"string\") {\n\t\t\tconst translator = getTranslator(this.response_metadata.model_provider);\n\t\t\tif (translator) return translator.translateContent(this);\n\t\t}\n\t\tconst blocks = super.contentBlocks;\n\t\tif (this.tool_calls) {\n\t\t\tconst missingToolCalls = this.tool_calls.filter((block) => !blocks.some((b) => b.id === block.id && b.name === block.name));\n\t\t\tblocks.push(...missingToolCalls.map((block) => ({\n\t\t\t\t...block,\n\t\t\t\ttype: \"tool_call\",\n\t\t\t\tid: block.id,\n\t\t\t\tname: block.name,\n\t\t\t\targs: block.args\n\t\t\t})));\n\t\t}\n\t\treturn blocks;\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\t...super._printableFields,\n\t\t\ttool_calls: this.tool_calls,\n\t\t\tinvalid_tool_calls: this.invalid_tool_calls,\n\t\t\tusage_metadata: this.usage_metadata\n\t\t};\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"ai\";\n\t}\n};\n/**\n* @deprecated Use {@link AIMessage.isInstance} instead\n*/\nfunction isAIMessage(x) {\n\treturn x._getType() === \"ai\";\n}\n/**\n* @deprecated Use {@link AIMessageChunk.isInstance} instead\n*/\nfunction isAIMessageChunk(x) {\n\treturn x._getType() === \"ai\";\n}\n/**\n* Represents a chunk of an AI message, which can be concatenated with\n* other AI message chunks.\n*/\nvar AIMessageChunk = class extends BaseMessageChunk {\n\ttype = \"ai\";\n\ttool_calls = [];\n\tinvalid_tool_calls = [];\n\ttool_call_chunks = [];\n\tusage_metadata;\n\tconstructor(fields) {\n\t\tlet initParams;\n\t\tif (typeof fields === \"string\" || Array.isArray(fields)) initParams = {\n\t\t\tcontent: fields,\n\t\t\ttool_calls: [],\n\t\t\tinvalid_tool_calls: [],\n\t\t\ttool_call_chunks: []\n\t\t};\n\t\telse if (fields.tool_call_chunks === void 0 || fields.tool_call_chunks.length === 0) initParams = {\n\t\t\t...fields,\n\t\t\ttool_calls: fields.tool_calls ?? [],\n\t\t\tinvalid_tool_calls: [],\n\t\t\ttool_call_chunks: [],\n\t\t\tusage_metadata: fields.usage_metadata !== void 0 ? fields.usage_metadata : void 0\n\t\t};\n\t\telse {\n\t\t\tconst toolCallChunks = fields.tool_call_chunks ?? [];\n\t\t\tconst groupedToolCallChunks = toolCallChunks.reduce((acc, chunk) => {\n\t\t\t\tconst matchedChunkIndex = acc.findIndex(([match]) => {\n\t\t\t\t\tif (\"id\" in chunk && chunk.id && \"index\" in chunk && chunk.index !== void 0) return chunk.id === match.id && chunk.index === match.index;\n\t\t\t\t\tif (\"id\" in chunk && chunk.id) return chunk.id === match.id;\n\t\t\t\t\tif (\"index\" in chunk && chunk.index !== void 0) return chunk.index === match.index;\n\t\t\t\t\treturn false;\n\t\t\t\t});\n\t\t\t\tif (matchedChunkIndex !== -1) acc[matchedChunkIndex].push(chunk);\n\t\t\t\telse acc.push([chunk]);\n\t\t\t\treturn acc;\n\t\t\t}, []);\n\t\t\tconst toolCalls = [];\n\t\t\tconst invalidToolCalls = [];\n\t\t\tfor (const chunks of groupedToolCallChunks) {\n\t\t\t\tlet parsedArgs = null;\n\t\t\t\tconst name = chunks[0]?.name ?? \"\";\n\t\t\t\tconst joinedArgs = chunks.map((c) => c.args || \"\").join(\"\");\n\t\t\t\tconst argsStr = joinedArgs.length ? joinedArgs : \"{}\";\n\t\t\t\tconst id = chunks[0]?.id;\n\t\t\t\ttry {\n\t\t\t\t\tparsedArgs = parsePartialJson(argsStr);\n\t\t\t\t\tif (!id || parsedArgs === null || typeof parsedArgs !== \"object\" || Array.isArray(parsedArgs)) throw new Error(\"Malformed tool call chunk args.\");\n\t\t\t\t\ttoolCalls.push({\n\t\t\t\t\t\tname,\n\t\t\t\t\t\targs: parsedArgs,\n\t\t\t\t\t\tid,\n\t\t\t\t\t\ttype: \"tool_call\"\n\t\t\t\t\t});\n\t\t\t\t} catch {\n\t\t\t\t\tinvalidToolCalls.push({\n\t\t\t\t\t\tname,\n\t\t\t\t\t\targs: argsStr,\n\t\t\t\t\t\tid,\n\t\t\t\t\t\terror: \"Malformed args.\",\n\t\t\t\t\t\ttype: \"invalid_tool_call\"\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t\tinitParams = {\n\t\t\t\t...fields,\n\t\t\t\ttool_calls: toolCalls,\n\t\t\t\tinvalid_tool_calls: invalidToolCalls,\n\t\t\t\tusage_metadata: fields.usage_metadata !== void 0 ? fields.usage_metadata : void 0\n\t\t\t};\n\t\t}\n\t\tsuper(initParams);\n\t\tthis.tool_call_chunks = initParams.tool_call_chunks ?? this.tool_call_chunks;\n\t\tthis.tool_calls = initParams.tool_calls ?? this.tool_calls;\n\t\tthis.invalid_tool_calls = initParams.invalid_tool_calls ?? this.invalid_tool_calls;\n\t\tthis.usage_metadata = initParams.usage_metadata;\n\t}\n\tget lc_aliases() {\n\t\treturn {\n\t\t\t...super.lc_aliases,\n\t\t\ttool_calls: \"tool_calls\",\n\t\t\tinvalid_tool_calls: \"invalid_tool_calls\",\n\t\t\ttool_call_chunks: \"tool_call_chunks\"\n\t\t};\n\t}\n\tstatic lc_name() {\n\t\treturn \"AIMessageChunk\";\n\t}\n\tget contentBlocks() {\n\t\tif (this.response_metadata && \"output_version\" in this.response_metadata && this.response_metadata.output_version === \"v1\") return this.content;\n\t\tif (this.response_metadata && \"model_provider\" in this.response_metadata && typeof this.response_metadata.model_provider === \"string\") {\n\t\t\tconst translator = getTranslator(this.response_metadata.model_provider);\n\t\t\tif (translator) return translator.translateContent(this);\n\t\t}\n\t\tconst blocks = super.contentBlocks;\n\t\tif (this.tool_calls) {\n\t\t\tif (typeof this.content !== \"string\") {\n\t\t\t\tconst contentToolCalls = this.content.filter((block) => block.type === \"tool_call\").map((block) => block.id);\n\t\t\t\tfor (const toolCall of this.tool_calls) if (toolCall.id && !contentToolCalls.includes(toolCall.id)) blocks.push({\n\t\t\t\t\t...toolCall,\n\t\t\t\t\ttype: \"tool_call\",\n\t\t\t\t\tid: toolCall.id,\n\t\t\t\t\tname: toolCall.name,\n\t\t\t\t\targs: toolCall.args\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn blocks;\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\t...super._printableFields,\n\t\t\ttool_calls: this.tool_calls,\n\t\t\ttool_call_chunks: this.tool_call_chunks,\n\t\t\tinvalid_tool_calls: this.invalid_tool_calls,\n\t\t\tusage_metadata: this.usage_metadata\n\t\t};\n\t}\n\tconcat(chunk) {\n\t\tconst combinedFields = {\n\t\t\tcontent: mergeContent(this.content, chunk.content),\n\t\t\tadditional_kwargs: _mergeDicts(this.additional_kwargs, chunk.additional_kwargs),\n\t\t\tresponse_metadata: mergeResponseMetadata(this.response_metadata, chunk.response_metadata),\n\t\t\ttool_call_chunks: [],\n\t\t\tid: this.id ?? chunk.id\n\t\t};\n\t\tif (this.tool_call_chunks !== void 0 || chunk.tool_call_chunks !== void 0) {\n\t\t\tconst rawToolCalls = _mergeLists(this.tool_call_chunks, chunk.tool_call_chunks);\n\t\t\tif (rawToolCalls !== void 0 && rawToolCalls.length > 0) combinedFields.tool_call_chunks = rawToolCalls;\n\t\t}\n\t\tif (this.usage_metadata !== void 0 || chunk.usage_metadata !== void 0) combinedFields.usage_metadata = mergeUsageMetadata(this.usage_metadata, chunk.usage_metadata);\n\t\tconst Cls = this.constructor;\n\t\treturn new Cls(combinedFields);\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"ai\";\n\t}\n};\n\n//#endregion\nexport { AIMessage, AIMessageChunk, isAIMessage, isAIMessageChunk };\n//# sourceMappingURL=ai.js.map","import { BaseMessage, BaseMessageChunk, _mergeDicts, mergeContent } from \"./base.js\";\n\n//#region src/messages/chat.ts\n/**\n* Represents a chat message in a conversation.\n*/\nvar ChatMessage = class ChatMessage extends BaseMessage {\n\tstatic lc_name() {\n\t\treturn \"ChatMessage\";\n\t}\n\ttype = \"generic\";\n\trole;\n\tstatic _chatMessageClass() {\n\t\treturn ChatMessage;\n\t}\n\tconstructor(fields, role) {\n\t\tif (typeof fields === \"string\" || Array.isArray(fields)) fields = {\n\t\t\tcontent: fields,\n\t\t\trole\n\t\t};\n\t\tsuper(fields);\n\t\tthis.role = fields.role;\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"generic\";\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\t...super._printableFields,\n\t\t\trole: this.role\n\t\t};\n\t}\n};\n/**\n* Represents a chunk of a chat message, which can be concatenated with\n* other chat message chunks.\n*/\nvar ChatMessageChunk = class extends BaseMessageChunk {\n\tstatic lc_name() {\n\t\treturn \"ChatMessageChunk\";\n\t}\n\ttype = \"generic\";\n\trole;\n\tconstructor(fields, role) {\n\t\tif (typeof fields === \"string\" || Array.isArray(fields)) fields = {\n\t\t\tcontent: fields,\n\t\t\trole\n\t\t};\n\t\tsuper(fields);\n\t\tthis.role = fields.role;\n\t}\n\tconcat(chunk) {\n\t\tconst Cls = this.constructor;\n\t\treturn new Cls({\n\t\t\tcontent: mergeContent(this.content, chunk.content),\n\t\t\tadditional_kwargs: _mergeDicts(this.additional_kwargs, chunk.additional_kwargs),\n\t\t\tresponse_metadata: _mergeDicts(this.response_metadata, chunk.response_metadata),\n\t\t\trole: this.role,\n\t\t\tid: this.id ?? chunk.id\n\t\t});\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"generic\";\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\t...super._printableFields,\n\t\t\trole: this.role\n\t\t};\n\t}\n};\n/**\n* @deprecated Use {@link ChatMessage.isInstance} instead\n*/\nfunction isChatMessage(x) {\n\treturn x._getType() === \"generic\";\n}\n/**\n* @deprecated Use {@link ChatMessageChunk.isInstance} instead\n*/\nfunction isChatMessageChunk(x) {\n\treturn x._getType() === \"generic\";\n}\n\n//#endregion\nexport { ChatMessage, ChatMessageChunk, isChatMessage, isChatMessageChunk };\n//# sourceMappingURL=chat.js.map","import { BaseMessage, BaseMessageChunk, _mergeDicts, mergeContent } from \"./base.js\";\n\n//#region src/messages/function.ts\n/**\n* Represents a function message in a conversation.\n*/\nvar FunctionMessage = class extends BaseMessage {\n\tstatic lc_name() {\n\t\treturn \"FunctionMessage\";\n\t}\n\ttype = \"function\";\n\tname;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.name = fields.name;\n\t}\n};\n/**\n* Represents a chunk of a function message, which can be concatenated\n* with other function message chunks.\n*/\nvar FunctionMessageChunk = class extends BaseMessageChunk {\n\tstatic lc_name() {\n\t\treturn \"FunctionMessageChunk\";\n\t}\n\ttype = \"function\";\n\tconcat(chunk) {\n\t\tconst Cls = this.constructor;\n\t\treturn new Cls({\n\t\t\tcontent: mergeContent(this.content, chunk.content),\n\t\t\tadditional_kwargs: _mergeDicts(this.additional_kwargs, chunk.additional_kwargs),\n\t\t\tresponse_metadata: _mergeDicts(this.response_metadata, chunk.response_metadata),\n\t\t\tname: this.name ?? \"\",\n\t\t\tid: this.id ?? chunk.id\n\t\t});\n\t}\n};\nfunction isFunctionMessage(x) {\n\treturn x._getType() === \"function\";\n}\nfunction isFunctionMessageChunk(x) {\n\treturn x._getType() === \"function\";\n}\n\n//#endregion\nexport { FunctionMessage, FunctionMessageChunk, isFunctionMessage, isFunctionMessageChunk };\n//# sourceMappingURL=function.js.map","import { BaseMessage, BaseMessageChunk, _mergeDicts, mergeContent } from \"./base.js\";\n\n//#region src/messages/human.ts\n/**\n* Represents a human message in a conversation.\n*/\nvar HumanMessage = class extends BaseMessage {\n\tstatic lc_name() {\n\t\treturn \"HumanMessage\";\n\t}\n\ttype = \"human\";\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"human\";\n\t}\n};\n/**\n* Represents a chunk of a human message, which can be concatenated with\n* other human message chunks.\n*/\nvar HumanMessageChunk = class extends BaseMessageChunk {\n\tstatic lc_name() {\n\t\treturn \"HumanMessageChunk\";\n\t}\n\ttype = \"human\";\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t}\n\tconcat(chunk) {\n\t\tconst Cls = this.constructor;\n\t\treturn new Cls({\n\t\t\tcontent: mergeContent(this.content, chunk.content),\n\t\t\tadditional_kwargs: _mergeDicts(this.additional_kwargs, chunk.additional_kwargs),\n\t\t\tresponse_metadata: _mergeDicts(this.response_metadata, chunk.response_metadata),\n\t\t\tid: this.id ?? chunk.id\n\t\t});\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"human\";\n\t}\n};\n/**\n* @deprecated Use {@link HumanMessage.isInstance} instead\n*/\nfunction isHumanMessage(x) {\n\treturn x.getType() === \"human\";\n}\n/**\n* @deprecated Use {@link HumanMessageChunk.isInstance} instead\n*/\nfunction isHumanMessageChunk(x) {\n\treturn x.getType() === \"human\";\n}\n\n//#endregion\nexport { HumanMessage, HumanMessageChunk, isHumanMessage, isHumanMessageChunk };\n//# sourceMappingURL=human.js.map","import { BaseMessage, BaseMessageChunk, _mergeDicts, mergeContent } from \"./base.js\";\n\n//#region src/messages/system.ts\n/**\n* Represents a system message in a conversation.\n*/\nvar SystemMessage = class extends BaseMessage {\n\tstatic lc_name() {\n\t\treturn \"SystemMessage\";\n\t}\n\ttype = \"system\";\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"system\";\n\t}\n};\n/**\n* Represents a chunk of a system message, which can be concatenated with\n* other system message chunks.\n*/\nvar SystemMessageChunk = class extends BaseMessageChunk {\n\tstatic lc_name() {\n\t\treturn \"SystemMessageChunk\";\n\t}\n\ttype = \"system\";\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t}\n\tconcat(chunk) {\n\t\tconst Cls = this.constructor;\n\t\treturn new Cls({\n\t\t\tcontent: mergeContent(this.content, chunk.content),\n\t\t\tadditional_kwargs: _mergeDicts(this.additional_kwargs, chunk.additional_kwargs),\n\t\t\tresponse_metadata: _mergeDicts(this.response_metadata, chunk.response_metadata),\n\t\t\tid: this.id ?? chunk.id\n\t\t});\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"system\";\n\t}\n};\n/**\n* @deprecated Use {@link SystemMessage.isInstance} instead\n*/\nfunction isSystemMessage(x) {\n\treturn x._getType() === \"system\";\n}\n/**\n* @deprecated Use {@link SystemMessageChunk.isInstance} instead\n*/\nfunction isSystemMessageChunk(x) {\n\treturn x._getType() === \"system\";\n}\n\n//#endregion\nexport { SystemMessage, SystemMessageChunk, isSystemMessage, isSystemMessageChunk };\n//# sourceMappingURL=system.js.map","//#region src/errors/index.ts\nfunction addLangChainErrorFields(error, lc_error_code) {\n\terror.lc_error_code = lc_error_code;\n\terror.message = `${error.message}\\n\\nTroubleshooting URL: https://js.langchain.com/docs/troubleshooting/errors/${lc_error_code}/\\n`;\n\treturn error;\n}\n\n//#endregion\nexport { addLangChainErrorFields };\n//# sourceMappingURL=index.js.map","//#region src/tools/utils.ts\nfunction _isToolCall(toolCall) {\n\treturn !!(toolCall && typeof toolCall === \"object\" && \"type\" in toolCall && toolCall.type === \"tool_call\");\n}\nfunction _configHasToolCallId(config) {\n\treturn !!(config && typeof config === \"object\" && \"toolCall\" in config && config.toolCall != null && typeof config.toolCall === \"object\" && \"id\" in config.toolCall && typeof config.toolCall.id === \"string\");\n}\n/**\n* Custom error class used to handle exceptions related to tool input parsing.\n* It extends the built-in `Error` class and adds an optional `output`\n* property that can hold the output that caused the exception.\n*/\nvar ToolInputParsingException = class extends Error {\n\toutput;\n\tconstructor(message, output) {\n\t\tsuper(message);\n\t\tthis.output = output;\n\t}\n};\n\n//#endregion\nexport { ToolInputParsingException, _configHasToolCallId, _isToolCall };\n//# sourceMappingURL=utils.js.map","import { BaseMessage } from \"./base.js\";\n\n//#region src/messages/modifier.ts\n/**\n* Message responsible for deleting other messages.\n*/\nvar RemoveMessage = class extends BaseMessage {\n\ttype = \"remove\";\n\t/**\n\t* The ID of the message to remove.\n\t*/\n\tid;\n\tconstructor(fields) {\n\t\tsuper({\n\t\t\t...fields,\n\t\t\tcontent: []\n\t\t});\n\t\tthis.id = fields.id;\n\t}\n\tget _printableFields() {\n\t\treturn {\n\t\t\t...super._printableFields,\n\t\t\tid: this.id\n\t\t};\n\t}\n\tstatic isInstance(obj) {\n\t\treturn super.isInstance(obj) && obj.type === \"remove\";\n\t}\n};\n\n//#endregion\nexport { RemoveMessage };\n//# sourceMappingURL=modifier.js.map","import { _isMessageFieldWithRole, isBaseMessage } from \"./base.js\";\nimport { ToolMessage } from \"./tool.js\";\nimport { AIMessage, AIMessageChunk } from \"./ai.js\";\nimport { ChatMessage, ChatMessageChunk } from \"./chat.js\";\nimport { FunctionMessage, FunctionMessageChunk } from \"./function.js\";\nimport { HumanMessage, HumanMessageChunk } from \"./human.js\";\nimport { SystemMessage, SystemMessageChunk } from \"./system.js\";\nimport { addLangChainErrorFields } from \"../errors/index.js\";\nimport { _isToolCall } from \"../tools/utils.js\";\nimport { RemoveMessage } from \"./modifier.js\";\n\n//#region src/messages/utils.ts\n/**\n* Immediately-invoked function expression.\n*\n* @param fn - The function to execute\n* @returns The result of the function\n*/\nconst iife = (fn) => fn();\nfunction _coerceToolCall(toolCall) {\n\tif (_isToolCall(toolCall)) return toolCall;\n\telse if (typeof toolCall.id === \"string\" && toolCall.type === \"function\" && typeof toolCall.function === \"object\" && toolCall.function !== null && \"arguments\" in toolCall.function && typeof toolCall.function.arguments === \"string\" && \"name\" in toolCall.function && typeof toolCall.function.name === \"string\") return {\n\t\tid: toolCall.id,\n\t\targs: JSON.parse(toolCall.function.arguments),\n\t\tname: toolCall.function.name,\n\t\ttype: \"tool_call\"\n\t};\n\telse return toolCall;\n}\nfunction isSerializedConstructor(x) {\n\treturn typeof x === \"object\" && x != null && x.lc === 1 && Array.isArray(x.id) && x.kwargs != null && typeof x.kwargs === \"object\";\n}\nfunction _constructMessageFromParams(params) {\n\tlet type;\n\tlet rest;\n\tif (isSerializedConstructor(params)) {\n\t\tconst className = params.id.at(-1);\n\t\tif (className === \"HumanMessage\" || className === \"HumanMessageChunk\") type = \"user\";\n\t\telse if (className === \"AIMessage\" || className === \"AIMessageChunk\") type = \"assistant\";\n\t\telse if (className === \"SystemMessage\" || className === \"SystemMessageChunk\") type = \"system\";\n\t\telse if (className === \"FunctionMessage\" || className === \"FunctionMessageChunk\") type = \"function\";\n\t\telse if (className === \"ToolMessage\" || className === \"ToolMessageChunk\") type = \"tool\";\n\t\telse type = \"unknown\";\n\t\trest = params.kwargs;\n\t} else {\n\t\tconst { type: extractedType,...otherParams } = params;\n\t\ttype = extractedType;\n\t\trest = otherParams;\n\t}\n\tif (type === \"human\" || type === \"user\") return new HumanMessage(rest);\n\telse if (type === \"ai\" || type === \"assistant\") {\n\t\tconst { tool_calls: rawToolCalls,...other } = rest;\n\t\tif (!Array.isArray(rawToolCalls)) return new AIMessage(rest);\n\t\tconst tool_calls = rawToolCalls.map(_coerceToolCall);\n\t\treturn new AIMessage({\n\t\t\t...other,\n\t\t\ttool_calls\n\t\t});\n\t} else if (type === \"system\") return new SystemMessage(rest);\n\telse if (type === \"developer\") return new SystemMessage({\n\t\t...rest,\n\t\tadditional_kwargs: {\n\t\t\t...rest.additional_kwargs,\n\t\t\t__openai_role__: \"developer\"\n\t\t}\n\t});\n\telse if (type === \"tool\" && \"tool_call_id\" in rest) return new ToolMessage({\n\t\t...rest,\n\t\tcontent: rest.content,\n\t\ttool_call_id: rest.tool_call_id,\n\t\tname: rest.name\n\t});\n\telse if (type === \"remove\" && \"id\" in rest && typeof rest.id === \"string\") return new RemoveMessage({\n\t\t...rest,\n\t\tid: rest.id\n\t});\n\telse {\n\t\tconst error = addLangChainErrorFields(/* @__PURE__ */ new Error(`Unable to coerce message from array: only human, AI, system, developer, or tool message coercion is currently supported.\\n\\nReceived: ${JSON.stringify(params, null, 2)}`), \"MESSAGE_COERCION_FAILURE\");\n\t\tthrow error;\n\t}\n}\nfunction coerceMessageLikeToMessage(messageLike) {\n\tif (typeof messageLike === \"string\") return new HumanMessage(messageLike);\n\telse if (isBaseMessage(messageLike)) return messageLike;\n\tif (Array.isArray(messageLike)) {\n\t\tconst [type, content] = messageLike;\n\t\treturn _constructMessageFromParams({\n\t\t\ttype,\n\t\t\tcontent\n\t\t});\n\t} else if (_isMessageFieldWithRole(messageLike)) {\n\t\tconst { role: type,...rest } = messageLike;\n\t\treturn _constructMessageFromParams({\n\t\t\t...rest,\n\t\t\ttype\n\t\t});\n\t} else return _constructMessageFromParams(messageLike);\n}\n/**\n* This function is used by memory classes to get a string representation\n* of the chat message history, based on the message content and role.\n*/\nfunction getBufferString(messages, humanPrefix = \"Human\", aiPrefix = \"AI\") {\n\tconst string_messages = [];\n\tfor (const m of messages) {\n\t\tlet role;\n\t\tif (m._getType() === \"human\") role = humanPrefix;\n\t\telse if (m._getType() === \"ai\") role = aiPrefix;\n\t\telse if (m._getType() === \"system\") role = \"System\";\n\t\telse if (m._getType() === \"tool\") role = \"Tool\";\n\t\telse if (m._getType() === \"generic\") role = m.role;\n\t\telse throw new Error(`Got unsupported message type: ${m._getType()}`);\n\t\tconst nameStr = m.name ? `${m.name}, ` : \"\";\n\t\tconst readableContent = typeof m.content === \"string\" ? m.content : JSON.stringify(m.content, null, 2);\n\t\tstring_messages.push(`${role}: ${nameStr}${readableContent}`);\n\t}\n\treturn string_messages.join(\"\\n\");\n}\n/**\n* Maps messages from an older format (V1) to the current `StoredMessage`\n* format. If the message is already in the `StoredMessage` format, it is\n* returned as is. Otherwise, it transforms the V1 message into a\n* `StoredMessage`. This function is important for maintaining\n* compatibility with older message formats.\n*/\nfunction mapV1MessageToStoredMessage(message) {\n\tif (message.data !== void 0) return message;\n\telse {\n\t\tconst v1Message = message;\n\t\treturn {\n\t\t\ttype: v1Message.type,\n\t\t\tdata: {\n\t\t\t\tcontent: v1Message.text,\n\t\t\t\trole: v1Message.role,\n\t\t\t\tname: void 0,\n\t\t\t\ttool_call_id: void 0\n\t\t\t}\n\t\t};\n\t}\n}\nfunction mapStoredMessageToChatMessage(message) {\n\tconst storedMessage = mapV1MessageToStoredMessage(message);\n\tswitch (storedMessage.type) {\n\t\tcase \"human\": return new HumanMessage(storedMessage.data);\n\t\tcase \"ai\": return new AIMessage(storedMessage.data);\n\t\tcase \"system\": return new SystemMessage(storedMessage.data);\n\t\tcase \"function\":\n\t\t\tif (storedMessage.data.name === void 0) throw new Error(\"Name must be defined for function messages\");\n\t\t\treturn new FunctionMessage(storedMessage.data);\n\t\tcase \"tool\":\n\t\t\tif (storedMessage.data.tool_call_id === void 0) throw new Error(\"Tool call ID must be defined for tool messages\");\n\t\t\treturn new ToolMessage(storedMessage.data);\n\t\tcase \"generic\":\n\t\t\tif (storedMessage.data.role === void 0) throw new Error(\"Role must be defined for chat messages\");\n\t\t\treturn new ChatMessage(storedMessage.data);\n\t\tdefault: throw new Error(`Got unexpected type: ${storedMessage.type}`);\n\t}\n}\n/**\n* Transforms an array of `StoredMessage` instances into an array of\n* `BaseMessage` instances. It uses the `mapV1MessageToStoredMessage`\n* function to ensure all messages are in the `StoredMessage` format, then\n* creates new instances of the appropriate `BaseMessage` subclass based\n* on the type of each message. This function is used to prepare stored\n* messages for use in a chat context.\n*/\nfunction mapStoredMessagesToChatMessages(messages) {\n\treturn messages.map(mapStoredMessageToChatMessage);\n}\n/**\n* Transforms an array of `BaseMessage` instances into an array of\n* `StoredMessage` instances. It does this by calling the `toDict` method\n* on each `BaseMessage`, which returns a `StoredMessage`. This function\n* is used to prepare chat messages for storage.\n*/\nfunction mapChatMessagesToStoredMessages(messages) {\n\treturn messages.map((message) => message.toDict());\n}\nfunction convertToChunk(message) {\n\tconst type = message._getType();\n\tif (type === \"human\") return new HumanMessageChunk({ ...message });\n\telse if (type === \"ai\") {\n\t\tlet aiChunkFields = { ...message };\n\t\tif (\"tool_calls\" in aiChunkFields) aiChunkFields = {\n\t\t\t...aiChunkFields,\n\t\t\ttool_call_chunks: aiChunkFields.tool_calls?.map((tc) => ({\n\t\t\t\t...tc,\n\t\t\t\ttype: \"tool_call_chunk\",\n\t\t\t\tindex: void 0,\n\t\t\t\targs: JSON.stringify(tc.args)\n\t\t\t}))\n\t\t};\n\t\treturn new AIMessageChunk({ ...aiChunkFields });\n\t} else if (type === \"system\") return new SystemMessageChunk({ ...message });\n\telse if (type === \"function\") return new FunctionMessageChunk({ ...message });\n\telse if (ChatMessage.isInstance(message)) return new ChatMessageChunk({ ...message });\n\telse throw new Error(\"Unknown message type.\");\n}\n\n//#endregion\nexport { coerceMessageLikeToMessage, convertToChunk, getBufferString, iife, mapChatMessagesToStoredMessages, mapStoredMessageToChatMessage, mapStoredMessagesToChatMessages };\n//# sourceMappingURL=utils.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\n\n//#region src/utils/env.ts\nvar env_exports = {};\n__export(env_exports, {\n\tgetEnv: () => getEnv,\n\tgetEnvironmentVariable: () => getEnvironmentVariable,\n\tgetRuntimeEnvironment: () => getRuntimeEnvironment,\n\tisBrowser: () => isBrowser,\n\tisDeno: () => isDeno,\n\tisJsDom: () => isJsDom,\n\tisNode: () => isNode,\n\tisWebWorker: () => isWebWorker\n});\nconst isBrowser = () => typeof window !== \"undefined\" && typeof window.document !== \"undefined\";\nconst isWebWorker = () => typeof globalThis === \"object\" && globalThis.constructor && globalThis.constructor.name === \"DedicatedWorkerGlobalScope\";\nconst isJsDom = () => typeof window !== \"undefined\" && window.name === \"nodejs\" || typeof navigator !== \"undefined\" && navigator.userAgent.includes(\"jsdom\");\nconst isDeno = () => typeof Deno !== \"undefined\";\nconst isNode = () => typeof process !== \"undefined\" && typeof process.versions !== \"undefined\" && typeof process.versions.node !== \"undefined\" && !isDeno();\nconst getEnv = () => {\n\tlet env;\n\tif (isBrowser()) env = \"browser\";\n\telse if (isNode()) env = \"node\";\n\telse if (isWebWorker()) env = \"webworker\";\n\telse if (isJsDom()) env = \"jsdom\";\n\telse if (isDeno()) env = \"deno\";\n\telse env = \"other\";\n\treturn env;\n};\nlet runtimeEnvironment;\nfunction getRuntimeEnvironment() {\n\tif (runtimeEnvironment === void 0) {\n\t\tconst env = getEnv();\n\t\truntimeEnvironment = {\n\t\t\tlibrary: \"langchain-js\",\n\t\t\truntime: env\n\t\t};\n\t}\n\treturn runtimeEnvironment;\n}\nfunction getEnvironmentVariable(name) {\n\ttry {\n\t\tif (typeof process !== \"undefined\") return process.env?.[name];\n\t\telse if (isDeno()) return Deno?.env.get(name);\n\t\telse return void 0;\n\t} catch {\n\t\treturn void 0;\n\t}\n}\n\n//#endregion\nexport { env_exports, getEnv, getEnvironmentVariable, getRuntimeEnvironment, isBrowser, isDeno, isJsDom, isNode, isWebWorker };\n//# sourceMappingURL=env.js.map","import uuid from './dist/index.js';\nexport const v1 = uuid.v1;\nexport const v1ToV6 = uuid.v1ToV6;\nexport const v3 = uuid.v3;\nexport const v4 = uuid.v4;\nexport const v5 = uuid.v5;\nexport const v6 = uuid.v6;\nexport const v6ToV1 = uuid.v6ToV1;\nexport const v7 = uuid.v7;\nexport const NIL = uuid.NIL;\nexport const MAX = uuid.MAX;\nexport const version = uuid.version;\nexport const validate = uuid.validate;\nexport const stringify = uuid.stringify;\nexport const parse = uuid.parse;\n","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { Serializable, get_lc_unique_name } from \"../load/serializable.js\";\nimport { getEnvironmentVariable } from \"../utils/env.js\";\nimport * as uuid from \"uuid\";\n\n//#region src/callbacks/base.ts\nvar base_exports = {};\n__export(base_exports, {\n\tBaseCallbackHandler: () => BaseCallbackHandler,\n\tcallbackHandlerPrefersStreaming: () => callbackHandlerPrefersStreaming,\n\tisBaseCallbackHandler: () => isBaseCallbackHandler\n});\n/**\n* Abstract class that provides a set of optional methods that can be\n* overridden in derived classes to handle various events during the\n* execution of a LangChain application.\n*/\nvar BaseCallbackHandlerMethodsClass = class {};\nfunction callbackHandlerPrefersStreaming(x) {\n\treturn \"lc_prefer_streaming\" in x && x.lc_prefer_streaming;\n}\n/**\n* Abstract base class for creating callback handlers in the LangChain\n* framework. It provides a set of optional methods that can be overridden\n* in derived classes to handle various events during the execution of a\n* LangChain application.\n*/\nvar BaseCallbackHandler = class extends BaseCallbackHandlerMethodsClass {\n\tlc_serializable = false;\n\tget lc_namespace() {\n\t\treturn [\n\t\t\t\"langchain_core\",\n\t\t\t\"callbacks\",\n\t\t\tthis.name\n\t\t];\n\t}\n\tget lc_secrets() {\n\t\treturn void 0;\n\t}\n\tget lc_attributes() {\n\t\treturn void 0;\n\t}\n\tget lc_aliases() {\n\t\treturn void 0;\n\t}\n\tget lc_serializable_keys() {\n\t\treturn void 0;\n\t}\n\t/**\n\t* The name of the serializable. Override to provide an alias or\n\t* to preserve the serialized module name in minified environments.\n\t*\n\t* Implemented as a static method to support loading logic.\n\t*/\n\tstatic lc_name() {\n\t\treturn this.name;\n\t}\n\t/**\n\t* The final serialized identifier for the module.\n\t*/\n\tget lc_id() {\n\t\treturn [...this.lc_namespace, get_lc_unique_name(this.constructor)];\n\t}\n\tlc_kwargs;\n\tignoreLLM = false;\n\tignoreChain = false;\n\tignoreAgent = false;\n\tignoreRetriever = false;\n\tignoreCustomEvent = false;\n\traiseError = false;\n\tawaitHandlers = getEnvironmentVariable(\"LANGCHAIN_CALLBACKS_BACKGROUND\") === \"false\";\n\tconstructor(input) {\n\t\tsuper();\n\t\tthis.lc_kwargs = input || {};\n\t\tif (input) {\n\t\t\tthis.ignoreLLM = input.ignoreLLM ?? this.ignoreLLM;\n\t\t\tthis.ignoreChain = input.ignoreChain ?? this.ignoreChain;\n\t\t\tthis.ignoreAgent = input.ignoreAgent ?? this.ignoreAgent;\n\t\t\tthis.ignoreRetriever = input.ignoreRetriever ?? this.ignoreRetriever;\n\t\t\tthis.ignoreCustomEvent = input.ignoreCustomEvent ?? this.ignoreCustomEvent;\n\t\t\tthis.raiseError = input.raiseError ?? this.raiseError;\n\t\t\tthis.awaitHandlers = this.raiseError || (input._awaitHandler ?? this.awaitHandlers);\n\t\t}\n\t}\n\tcopy() {\n\t\treturn new this.constructor(this);\n\t}\n\ttoJSON() {\n\t\treturn Serializable.prototype.toJSON.call(this);\n\t}\n\ttoJSONNotImplemented() {\n\t\treturn Serializable.prototype.toJSONNotImplemented.call(this);\n\t}\n\tstatic fromMethods(methods) {\n\t\tclass Handler extends BaseCallbackHandler {\n\t\t\tname = uuid.v4();\n\t\t\tconstructor() {\n\t\t\t\tsuper();\n\t\t\t\tObject.assign(this, methods);\n\t\t\t}\n\t\t}\n\t\treturn new Handler();\n\t}\n};\nconst isBaseCallbackHandler = (x) => {\n\tconst callbackHandler = x;\n\treturn callbackHandler !== void 0 && typeof callbackHandler.copy === \"function\" && typeof callbackHandler.name === \"string\" && typeof callbackHandler.awaitHandlers === \"boolean\";\n};\n\n//#endregion\nexport { BaseCallbackHandler, base_exports, callbackHandlerPrefersStreaming, isBaseCallbackHandler };\n//# sourceMappingURL=base.js.map","import uuid from './dist/index.js';\nexport const v1 = uuid.v1;\nexport const v1ToV6 = uuid.v1ToV6;\nexport const v3 = uuid.v3;\nexport const v4 = uuid.v4;\nexport const v5 = uuid.v5;\nexport const v6 = uuid.v6;\nexport const v6ToV1 = uuid.v6ToV1;\nexport const v7 = uuid.v7;\nexport const NIL = uuid.NIL;\nexport const MAX = uuid.MAX;\nexport const version = uuid.version;\nexport const validate = uuid.validate;\nexport const stringify = uuid.stringify;\nexport const parse = uuid.parse;\n","// OpenTelemetry GenAI semantic convention attribute names\nexport const GEN_AI_OPERATION_NAME = \"gen_ai.operation.name\";\nexport const GEN_AI_SYSTEM = \"gen_ai.system\";\nexport const GEN_AI_REQUEST_MODEL = \"gen_ai.request.model\";\nexport const GEN_AI_RESPONSE_MODEL = \"gen_ai.response.model\";\nexport const GEN_AI_USAGE_INPUT_TOKENS = \"gen_ai.usage.input_tokens\";\nexport const GEN_AI_USAGE_OUTPUT_TOKENS = \"gen_ai.usage.output_tokens\";\nexport const GEN_AI_USAGE_TOTAL_TOKENS = \"gen_ai.usage.total_tokens\";\nexport const GEN_AI_REQUEST_MAX_TOKENS = \"gen_ai.request.max_tokens\";\nexport const GEN_AI_REQUEST_TEMPERATURE = \"gen_ai.request.temperature\";\nexport const GEN_AI_REQUEST_TOP_P = \"gen_ai.request.top_p\";\nexport const GEN_AI_REQUEST_FREQUENCY_PENALTY = \"gen_ai.request.frequency_penalty\";\nexport const GEN_AI_REQUEST_PRESENCE_PENALTY = \"gen_ai.request.presence_penalty\";\nexport const GEN_AI_RESPONSE_FINISH_REASONS = \"gen_ai.response.finish_reasons\";\nexport const GENAI_PROMPT = \"gen_ai.prompt\";\nexport const GENAI_COMPLETION = \"gen_ai.completion\";\nexport const GEN_AI_REQUEST_EXTRA_QUERY = \"gen_ai.request.extra_query\";\nexport const GEN_AI_REQUEST_EXTRA_BODY = \"gen_ai.request.extra_body\";\nexport const GEN_AI_SERIALIZED_NAME = \"gen_ai.serialized.name\";\nexport const GEN_AI_SERIALIZED_SIGNATURE = \"gen_ai.serialized.signature\";\nexport const GEN_AI_SERIALIZED_DOC = \"gen_ai.serialized.doc\";\nexport const GEN_AI_RESPONSE_ID = \"gen_ai.response.id\";\nexport const GEN_AI_RESPONSE_SERVICE_TIER = \"gen_ai.response.service_tier\";\nexport const GEN_AI_RESPONSE_SYSTEM_FINGERPRINT = \"gen_ai.response.system_fingerprint\";\nexport const GEN_AI_USAGE_INPUT_TOKEN_DETAILS = \"gen_ai.usage.input_token_details\";\nexport const GEN_AI_USAGE_OUTPUT_TOKEN_DETAILS = \"gen_ai.usage.output_token_details\";\n// LangSmith custom attributes\nexport const LANGSMITH_SESSION_ID = \"langsmith.trace.session_id\";\nexport const LANGSMITH_SESSION_NAME = \"langsmith.trace.session_name\";\nexport const LANGSMITH_RUN_TYPE = \"langsmith.span.kind\";\nexport const LANGSMITH_NAME = \"langsmith.trace.name\";\nexport const LANGSMITH_METADATA = \"langsmith.metadata\";\nexport const LANGSMITH_TAGS = \"langsmith.span.tags\";\nexport const LANGSMITH_RUNTIME = \"langsmith.span.runtime\";\nexport const LANGSMITH_REQUEST_STREAMING = \"langsmith.request.streaming\";\nexport const LANGSMITH_REQUEST_HEADERS = \"langsmith.request.headers\";\nexport const LANGSMITH_RUN_ID = \"langsmith.span.id\";\nexport const LANGSMITH_TRACE_ID = \"langsmith.trace.id\";\nexport const LANGSMITH_DOTTED_ORDER = \"langsmith.span.dotted_order\";\nexport const LANGSMITH_PARENT_RUN_ID = \"langsmith.span.parent_id\";\nexport const LANGSMITH_USAGE_METADATA = \"langsmith.usage_metadata\";\nexport const LANGSMITH_REFERENCE_EXAMPLE_ID = \"langsmith.reference_example_id\";\nexport const LANGSMITH_TRACEABLE = \"langsmith.traceable\";\nexport const LANGSMITH_IS_ROOT = \"langsmith.is_root\";\nexport const LANGSMITH_TRACEABLE_PARENT_OTEL_SPAN_ID = \"langsmith.traceable_parent_otel_span_id\";\n// GenAI event names\nexport const GEN_AI_SYSTEM_MESSAGE = \"gen_ai.system.message\";\nexport const GEN_AI_USER_MESSAGE = \"gen_ai.user.message\";\nexport const GEN_AI_ASSISTANT_MESSAGE = \"gen_ai.assistant.message\";\nexport const GEN_AI_CHOICE = \"gen_ai.choice\";\nexport const AI_SDK_LLM_OPERATIONS = [\n    \"ai.generateText.doGenerate\",\n    \"ai.streamText.doStream\",\n    \"ai.generateObject.doGenerate\",\n    \"ai.streamObject.doStream\",\n];\nexport const AI_SDK_TOOL_OPERATIONS = [\"ai.toolCall\"];\n","import { getLangSmithEnvironmentVariable } from \"../utils/env.js\";\n// Wrap the default fetch call due to issues with illegal invocations\n// in some environments:\n// https://stackoverflow.com/questions/69876859/why-does-bind-fix-failed-to-execute-fetch-on-window-illegal-invocation-err\n// @ts-expect-error Broad typing to support a range of fetch implementations\nconst DEFAULT_FETCH_IMPLEMENTATION = (...args) => fetch(...args);\nconst LANGSMITH_FETCH_IMPLEMENTATION_KEY = Symbol.for(\"ls:fetch_implementation\");\n/**\n * Overrides the fetch implementation used for LangSmith calls.\n * You should use this if you need to use an implementation of fetch\n * other than the default global (e.g. for dealing with proxies).\n * @param fetch The new fetch functino to use.\n */\nexport const overrideFetchImplementation = (fetch) => {\n    globalThis[LANGSMITH_FETCH_IMPLEMENTATION_KEY] = fetch;\n};\nexport const clearFetchImplementation = () => {\n    delete globalThis[LANGSMITH_FETCH_IMPLEMENTATION_KEY];\n};\nexport const _globalFetchImplementationIsNodeFetch = () => {\n    const fetchImpl = globalThis[LANGSMITH_FETCH_IMPLEMENTATION_KEY];\n    if (!fetchImpl)\n        return false;\n    // Check if the implementation has node-fetch specific properties\n    return (typeof fetchImpl === \"function\" &&\n        \"Headers\" in fetchImpl &&\n        \"Request\" in fetchImpl &&\n        \"Response\" in fetchImpl);\n};\n/**\n * @internal\n */\nexport const _getFetchImplementation = (debug) => {\n    return async (...args) => {\n        if (debug || getLangSmithEnvironmentVariable(\"DEBUG\") === \"true\") {\n            const [url, options] = args;\n            console.log(` ${options?.method || \"GET\"} ${url}`);\n        }\n        const res = await (globalThis[LANGSMITH_FETCH_IMPLEMENTATION_KEY] ??\n            DEFAULT_FETCH_IMPLEMENTATION)(...args);\n        if (debug || getLangSmithEnvironmentVariable(\"DEBUG\") === \"true\") {\n            console.log(` ${res.status} ${res.statusText} ${res.url}`);\n        }\n        return res;\n    };\n};\n","import { getEnvironmentVariable, getLangSmithEnvironmentVariable, } from \"./env.js\";\nexport const getDefaultProjectName = () => {\n    return (getLangSmithEnvironmentVariable(\"PROJECT\") ??\n        getEnvironmentVariable(\"LANGCHAIN_SESSION\") ?? // TODO: Deprecate\n        \"default\");\n};\n","export { Client, } from \"./client.js\";\nexport { RunTree } from \"./run_trees.js\";\nexport { overrideFetchImplementation } from \"./singletons/fetch.js\";\nexport { getDefaultProjectName } from \"./utils/project.js\";\n// Update using yarn bump-version\nexport const __version__ = \"0.3.79\";\n","// Inlined from https://github.com/flexdinesh/browser-or-node\nimport { __version__ } from \"../index.js\";\nlet globalEnv;\nexport const isBrowser = () => typeof window !== \"undefined\" && typeof window.document !== \"undefined\";\nexport const isWebWorker = () => typeof globalThis === \"object\" &&\n    globalThis.constructor &&\n    globalThis.constructor.name === \"DedicatedWorkerGlobalScope\";\nexport const isJsDom = () => (typeof window !== \"undefined\" && window.name === \"nodejs\") ||\n    (typeof navigator !== \"undefined\" && navigator.userAgent.includes(\"jsdom\"));\n// Supabase Edge Function provides a `Deno` global object\n// without `version` property\nexport const isDeno = () => typeof Deno !== \"undefined\";\n// Mark not-as-node if in Supabase Edge Function\nexport const isNode = () => typeof process !== \"undefined\" &&\n    typeof process.versions !== \"undefined\" &&\n    typeof process.versions.node !== \"undefined\" &&\n    !isDeno();\nexport const getEnv = () => {\n    if (globalEnv) {\n        return globalEnv;\n    }\n    // @ts-expect-error Bun types are not imported due to conflicts with Node types\n    if (typeof Bun !== \"undefined\") {\n        globalEnv = \"bun\";\n    }\n    else if (isBrowser()) {\n        globalEnv = \"browser\";\n    }\n    else if (isNode()) {\n        globalEnv = \"node\";\n    }\n    else if (isWebWorker()) {\n        globalEnv = \"webworker\";\n    }\n    else if (isJsDom()) {\n        globalEnv = \"jsdom\";\n    }\n    else if (isDeno()) {\n        globalEnv = \"deno\";\n    }\n    else {\n        globalEnv = \"other\";\n    }\n    return globalEnv;\n};\nlet runtimeEnvironment;\nexport function getRuntimeEnvironment() {\n    if (runtimeEnvironment === undefined) {\n        const env = getEnv();\n        const releaseEnv = getShas();\n        runtimeEnvironment = {\n            library: \"langsmith\",\n            runtime: env,\n            sdk: \"langsmith-js\",\n            sdk_version: __version__,\n            ...releaseEnv,\n        };\n    }\n    return runtimeEnvironment;\n}\n/**\n * Retrieves the LangSmith-specific metadata from the current runtime environment.\n *\n * @returns {Record<string, string>}\n *  - A record of LangSmith-specific metadata environment variables.\n */\nexport function getLangSmithEnvVarsMetadata() {\n    const allEnvVars = getLangSmithEnvironmentVariables();\n    const envVars = {};\n    const excluded = [\n        \"LANGCHAIN_API_KEY\",\n        \"LANGCHAIN_ENDPOINT\",\n        \"LANGCHAIN_TRACING_V2\",\n        \"LANGCHAIN_PROJECT\",\n        \"LANGCHAIN_SESSION\",\n        \"LANGSMITH_API_KEY\",\n        \"LANGSMITH_ENDPOINT\",\n        \"LANGSMITH_TRACING_V2\",\n        \"LANGSMITH_PROJECT\",\n        \"LANGSMITH_SESSION\",\n    ];\n    for (const [key, value] of Object.entries(allEnvVars)) {\n        if (typeof value === \"string\" &&\n            !excluded.includes(key) &&\n            !key.toLowerCase().includes(\"key\") &&\n            !key.toLowerCase().includes(\"secret\") &&\n            !key.toLowerCase().includes(\"token\")) {\n            if (key === \"LANGCHAIN_REVISION_ID\") {\n                envVars[\"revision_id\"] = value;\n            }\n            else {\n                envVars[key] = value;\n            }\n        }\n    }\n    return envVars;\n}\n/**\n * Retrieves only the LangChain/LangSmith-prefixed environment variables from the current runtime environment.\n * This is more efficient than copying all environment variables.\n *\n * @returns {Record<string, string>}\n *  - A record of LangChain/LangSmith environment variables.\n */\nexport function getLangSmithEnvironmentVariables() {\n    const envVars = {};\n    try {\n        // Check for Node.js environment\n        // eslint-disable-next-line no-process-env\n        if (typeof process !== \"undefined\" && process.env) {\n            // eslint-disable-next-line no-process-env\n            for (const [key, value] of Object.entries(process.env)) {\n                if ((key.startsWith(\"LANGCHAIN_\") || key.startsWith(\"LANGSMITH_\")) &&\n                    value != null) {\n                    if ((key.toLowerCase().includes(\"key\") ||\n                        key.toLowerCase().includes(\"secret\") ||\n                        key.toLowerCase().includes(\"token\")) &&\n                        typeof value === \"string\") {\n                        envVars[key] =\n                            value.slice(0, 2) +\n                                \"*\".repeat(value.length - 4) +\n                                value.slice(-2);\n                    }\n                    else {\n                        envVars[key] = value;\n                    }\n                }\n            }\n        }\n    }\n    catch (e) {\n        // Catch any errors that might occur while trying to access environment variables\n    }\n    return envVars;\n}\nexport function getEnvironmentVariable(name) {\n    // Certain Deno setups will throw an error if you try to access environment variables\n    // https://github.com/hwchase17/langchainjs/issues/1412\n    try {\n        return typeof process !== \"undefined\"\n            ? // eslint-disable-next-line no-process-env\n                process.env?.[name]\n            : undefined;\n    }\n    catch (e) {\n        return undefined;\n    }\n}\nexport function getLangSmithEnvironmentVariable(name) {\n    return (getEnvironmentVariable(`LANGSMITH_${name}`) ||\n        getEnvironmentVariable(`LANGCHAIN_${name}`));\n}\nexport function setEnvironmentVariable(name, value) {\n    if (typeof process !== \"undefined\") {\n        // eslint-disable-next-line no-process-env\n        process.env[name] = value;\n    }\n}\nlet cachedCommitSHAs;\n/**\n * Get the Git commit SHA from common environment variables\n * used by different CI/CD platforms.\n * @returns {string | undefined} The Git commit SHA or undefined if not found.\n */\nexport function getShas() {\n    if (cachedCommitSHAs !== undefined) {\n        return cachedCommitSHAs;\n    }\n    const common_release_envs = [\n        \"VERCEL_GIT_COMMIT_SHA\",\n        \"NEXT_PUBLIC_VERCEL_GIT_COMMIT_SHA\",\n        \"COMMIT_REF\",\n        \"RENDER_GIT_COMMIT\",\n        \"CI_COMMIT_SHA\",\n        \"CIRCLE_SHA1\",\n        \"CF_PAGES_COMMIT_SHA\",\n        \"REACT_APP_GIT_SHA\",\n        \"SOURCE_VERSION\",\n        \"GITHUB_SHA\",\n        \"TRAVIS_COMMIT\",\n        \"GIT_COMMIT\",\n        \"BUILD_VCS_NUMBER\",\n        \"bamboo_planRepository_revision\",\n        \"Build.SourceVersion\",\n        \"BITBUCKET_COMMIT\",\n        \"DRONE_COMMIT_SHA\",\n        \"SEMAPHORE_GIT_SHA\",\n        \"BUILDKITE_COMMIT\",\n    ];\n    const shas = {};\n    for (const env of common_release_envs) {\n        const envVar = getEnvironmentVariable(env);\n        if (envVar !== undefined) {\n            shas[env] = envVar;\n        }\n    }\n    cachedCommitSHAs = shas;\n    return shas;\n}\nexport function getOtelEnabled() {\n    return (getEnvironmentVariable(\"OTEL_ENABLED\") === \"true\" ||\n        getLangSmithEnvironmentVariable(\"OTEL_ENABLED\") === \"true\");\n}\n","// Should not import any OTEL packages to avoid pulling in optional deps.\nimport { getOtelEnabled } from \"../utils/env.js\";\nclass MockTracer {\n    constructor() {\n        Object.defineProperty(this, \"hasWarned\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n    }\n    startActiveSpan(_name, ...args) {\n        if (!this.hasWarned && getOtelEnabled()) {\n            console.warn(\"You have enabled OTEL export via the `OTEL_ENABLED` or `LANGSMITH_OTEL_ENABLED` environment variable, but have not initialized the required OTEL instances. \" +\n                'Please add:\\n```\\nimport { initializeOTEL } from \"langsmith/experimental/otel/setup\";\\ninitializeOTEL();\\n```\\nat the beginning of your code.');\n            this.hasWarned = true;\n        }\n        // Handle different overloads:\n        // startActiveSpan(name, fn)\n        // startActiveSpan(name, options, fn)\n        // startActiveSpan(name, options, context, fn)\n        let fn;\n        if (args.length === 1 && typeof args[0] === \"function\") {\n            fn = args[0];\n        }\n        else if (args.length === 2 && typeof args[1] === \"function\") {\n            fn = args[1];\n        }\n        else if (args.length === 3 && typeof args[2] === \"function\") {\n            fn = args[2];\n        }\n        if (typeof fn === \"function\") {\n            return fn();\n        }\n        return undefined;\n    }\n}\nclass MockOTELTrace {\n    constructor() {\n        Object.defineProperty(this, \"mockTracer\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: new MockTracer()\n        });\n    }\n    getTracer(_name, _version) {\n        return this.mockTracer;\n    }\n    getActiveSpan() {\n        return undefined;\n    }\n    setSpan(context, _span) {\n        return context;\n    }\n    getSpan(_context) {\n        return undefined;\n    }\n    setSpanContext(context, _spanContext) {\n        return context;\n    }\n    getTracerProvider() {\n        return undefined;\n    }\n    setGlobalTracerProvider(_tracerProvider) {\n        return false;\n    }\n}\nclass MockOTELContext {\n    active() {\n        return {};\n    }\n    with(_context, fn) {\n        return fn();\n    }\n}\nconst OTEL_TRACE_KEY = Symbol.for(\"ls:otel_trace\");\nconst OTEL_CONTEXT_KEY = Symbol.for(\"ls:otel_context\");\nconst OTEL_GET_DEFAULT_OTLP_TRACER_PROVIDER_KEY = Symbol.for(\"ls:otel_get_default_otlp_tracer_provider\");\nconst mockOTELTrace = new MockOTELTrace();\nconst mockOTELContext = new MockOTELContext();\nclass OTELProvider {\n    getTraceInstance() {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        return globalThis[OTEL_TRACE_KEY] ?? mockOTELTrace;\n    }\n    getContextInstance() {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        return globalThis[OTEL_CONTEXT_KEY] ?? mockOTELContext;\n    }\n    initializeGlobalInstances(otel) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        if (globalThis[OTEL_TRACE_KEY] === undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            globalThis[OTEL_TRACE_KEY] = otel.trace;\n        }\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        if (globalThis[OTEL_CONTEXT_KEY] === undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            globalThis[OTEL_CONTEXT_KEY] = otel.context;\n        }\n    }\n    setDefaultOTLPTracerComponents(components) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        globalThis[OTEL_GET_DEFAULT_OTLP_TRACER_PROVIDER_KEY] = components;\n    }\n    getDefaultOTLPTracerComponents() {\n        return (globalThis[OTEL_GET_DEFAULT_OTLP_TRACER_PROVIDER_KEY] ??\n            undefined);\n    }\n}\nexport const OTELProviderSingleton = new OTELProvider();\n/**\n * Get the current OTEL trace instance.\n * Returns a mock implementation if OTEL is not available.\n */\nexport function getOTELTrace() {\n    return OTELProviderSingleton.getTraceInstance();\n}\n/**\n * Get the current OTEL context instance.\n * Returns a mock implementation if OTEL is not available.\n */\nexport function getOTELContext() {\n    return OTELProviderSingleton.getContextInstance();\n}\n/**\n * Initialize the global OTEL instances.\n * Should be called once when OTEL packages are available.\n */\nexport function setOTELInstances(otel) {\n    OTELProviderSingleton.initializeGlobalInstances(otel);\n}\n/**\n * Set a getter function for the default OTLP tracer provider.\n * This allows lazy initialization of the tracer provider.\n */\nexport function setDefaultOTLPTracerComponents(components) {\n    OTELProviderSingleton.setDefaultOTLPTracerComponents(components);\n}\n/**\n * Get the default OTLP tracer provider instance.\n * Returns undefined if not set.\n */\nexport function getDefaultOTLPTracerComponents() {\n    return OTELProviderSingleton.getDefaultOTLPTracerComponents();\n}\n","import * as constants from \"./constants.js\";\nimport { getOTELTrace } from \"../../singletons/otel.js\";\nconst WELL_KNOWN_OPERATION_NAMES = {\n    llm: \"chat\",\n    tool: \"execute_tool\",\n    retriever: \"embeddings\",\n    embedding: \"embeddings\",\n    prompt: \"chat\",\n};\nfunction getOperationName(runType) {\n    return WELL_KNOWN_OPERATION_NAMES[runType] || runType;\n}\nexport class LangSmithToOTELTranslator {\n    constructor() {\n        Object.defineProperty(this, \"spans\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: new Map()\n        });\n    }\n    exportBatch(operations, otelContextMap) {\n        for (const op of operations) {\n            try {\n                if (!op.run) {\n                    continue;\n                }\n                if (op.operation === \"post\") {\n                    const span = this.createSpanForRun(op, op.run, otelContextMap.get(op.id));\n                    if (span && !op.run.end_time) {\n                        this.spans.set(op.id, span);\n                    }\n                }\n                else {\n                    this.updateSpanForRun(op, op.run);\n                }\n            }\n            catch (e) {\n                console.error(`Error processing operation ${op.id}:`, e);\n            }\n        }\n    }\n    createSpanForRun(op, runInfo, otelContext) {\n        const activeSpan = otelContext && getOTELTrace().getSpan(otelContext);\n        if (!activeSpan) {\n            return;\n        }\n        try {\n            return this.finishSpanSetup(activeSpan, runInfo, op);\n        }\n        catch (e) {\n            console.error(`Failed to create span for run ${op.id}:`, e);\n            return undefined;\n        }\n    }\n    finishSpanSetup(span, runInfo, op) {\n        // Set all attributes\n        this.setSpanAttributes(span, runInfo, op);\n        // Set status based on error\n        if (runInfo.error) {\n            span.setStatus({ code: 2 }); // ERROR status\n            span.recordException(new Error(runInfo.error));\n        }\n        else {\n            span.setStatus({ code: 1 }); // OK status\n        }\n        // End the span if end_time is present\n        if (runInfo.end_time) {\n            span.end(new Date(runInfo.end_time));\n        }\n        return span;\n    }\n    updateSpanForRun(op, runInfo) {\n        try {\n            const span = this.spans.get(op.id);\n            if (!span) {\n                console.debug(`No span found for run ${op.id} during update`);\n                return;\n            }\n            // Update attributes\n            this.setSpanAttributes(span, runInfo, op);\n            // Update status based on error\n            if (runInfo.error) {\n                span.setStatus({ code: 2 }); // ERROR status\n                span.recordException(new Error(runInfo.error));\n            }\n            else {\n                span.setStatus({ code: 1 }); // OK status\n            }\n            // End the span if end_time is present\n            const endTime = runInfo.end_time;\n            if (endTime) {\n                span.end(new Date(endTime));\n                this.spans.delete(op.id);\n            }\n        }\n        catch (e) {\n            console.error(`Failed to update span for run ${op.id}:`, e);\n        }\n    }\n    extractModelName(runInfo) {\n        // Try to get model name from metadata\n        if (runInfo.extra?.metadata) {\n            const metadata = runInfo.extra.metadata;\n            // First check for ls_model_name in metadata\n            if (metadata.ls_model_name) {\n                return metadata.ls_model_name;\n            }\n            // Then check invocation_params for model info\n            if (metadata.invocation_params) {\n                const invocationParams = metadata.invocation_params;\n                if (invocationParams.model) {\n                    return invocationParams.model;\n                }\n                else if (invocationParams.model_name) {\n                    return invocationParams.model_name;\n                }\n            }\n        }\n        return;\n    }\n    setSpanAttributes(span, runInfo, op) {\n        if (\"run_type\" in runInfo && runInfo.run_type) {\n            span.setAttribute(constants.LANGSMITH_RUN_TYPE, runInfo.run_type);\n            // Set GenAI attributes according to OTEL semantic conventions\n            const operationName = getOperationName(runInfo.run_type || \"chain\");\n            span.setAttribute(constants.GEN_AI_OPERATION_NAME, operationName);\n        }\n        if (\"name\" in runInfo && runInfo.name) {\n            span.setAttribute(constants.LANGSMITH_NAME, runInfo.name);\n        }\n        if (\"session_id\" in runInfo && runInfo.session_id) {\n            span.setAttribute(constants.LANGSMITH_SESSION_ID, runInfo.session_id);\n        }\n        if (\"session_name\" in runInfo && runInfo.session_name) {\n            span.setAttribute(constants.LANGSMITH_SESSION_NAME, runInfo.session_name);\n        }\n        // Set gen_ai.system\n        this.setGenAiSystem(span, runInfo);\n        // Set model name if available\n        const modelName = this.extractModelName(runInfo);\n        if (modelName) {\n            span.setAttribute(constants.GEN_AI_REQUEST_MODEL, modelName);\n        }\n        // Set token usage information\n        if (\"prompt_tokens\" in runInfo &&\n            typeof runInfo.prompt_tokens === \"number\") {\n            span.setAttribute(constants.GEN_AI_USAGE_INPUT_TOKENS, runInfo.prompt_tokens);\n        }\n        if (\"completion_tokens\" in runInfo &&\n            typeof runInfo.completion_tokens === \"number\") {\n            span.setAttribute(constants.GEN_AI_USAGE_OUTPUT_TOKENS, runInfo.completion_tokens);\n        }\n        if (\"total_tokens\" in runInfo && typeof runInfo.total_tokens === \"number\") {\n            span.setAttribute(constants.GEN_AI_USAGE_TOTAL_TOKENS, runInfo.total_tokens);\n        }\n        // Set other parameters from invocation_params\n        this.setInvocationParameters(span, runInfo);\n        // Set metadata and tags if available\n        const metadata = runInfo.extra?.metadata || {};\n        for (const [key, value] of Object.entries(metadata)) {\n            if (value !== null && value !== undefined) {\n                span.setAttribute(`${constants.LANGSMITH_METADATA}.${key}`, String(value));\n            }\n        }\n        const tags = runInfo.tags;\n        if (tags && Array.isArray(tags)) {\n            span.setAttribute(constants.LANGSMITH_TAGS, tags.join(\", \"));\n        }\n        else if (tags) {\n            span.setAttribute(constants.LANGSMITH_TAGS, String(tags));\n        }\n        // Support additional serialized attributes, if present\n        if (\"serialized\" in runInfo && typeof runInfo.serialized === \"object\") {\n            const serialized = runInfo.serialized;\n            if (serialized.name) {\n                span.setAttribute(constants.GEN_AI_SERIALIZED_NAME, String(serialized.name));\n            }\n            if (serialized.signature) {\n                span.setAttribute(constants.GEN_AI_SERIALIZED_SIGNATURE, String(serialized.signature));\n            }\n            if (serialized.doc) {\n                span.setAttribute(constants.GEN_AI_SERIALIZED_DOC, String(serialized.doc));\n            }\n        }\n        // Set inputs/outputs if available\n        this.setIOAttributes(span, op);\n    }\n    setGenAiSystem(span, runInfo) {\n        // Default to \"langchain\" if we can't determine the system\n        let system = \"langchain\";\n        // Extract model name to determine the system\n        const modelName = this.extractModelName(runInfo);\n        if (modelName) {\n            const modelLower = modelName.toLowerCase();\n            if (modelLower.includes(\"anthropic\") || modelLower.startsWith(\"claude\")) {\n                system = \"anthropic\";\n            }\n            else if (modelLower.includes(\"bedrock\")) {\n                system = \"aws.bedrock\";\n            }\n            else if (modelLower.includes(\"azure\") &&\n                modelLower.includes(\"openai\")) {\n                system = \"az.ai.openai\";\n            }\n            else if (modelLower.includes(\"azure\") &&\n                modelLower.includes(\"inference\")) {\n                system = \"az.ai.inference\";\n            }\n            else if (modelLower.includes(\"cohere\")) {\n                system = \"cohere\";\n            }\n            else if (modelLower.includes(\"deepseek\")) {\n                system = \"deepseek\";\n            }\n            else if (modelLower.includes(\"gemini\")) {\n                system = \"gemini\";\n            }\n            else if (modelLower.includes(\"groq\")) {\n                system = \"groq\";\n            }\n            else if (modelLower.includes(\"watson\") || modelLower.includes(\"ibm\")) {\n                system = \"ibm.watsonx.ai\";\n            }\n            else if (modelLower.includes(\"mistral\")) {\n                system = \"mistral_ai\";\n            }\n            else if (modelLower.includes(\"gpt\") || modelLower.includes(\"openai\")) {\n                system = \"openai\";\n            }\n            else if (modelLower.includes(\"perplexity\") ||\n                modelLower.includes(\"sonar\")) {\n                system = \"perplexity\";\n            }\n            else if (modelLower.includes(\"vertex\")) {\n                system = \"vertex_ai\";\n            }\n            else if (modelLower.includes(\"xai\") || modelLower.includes(\"grok\")) {\n                system = \"xai\";\n            }\n        }\n        span.setAttribute(constants.GEN_AI_SYSTEM, system);\n    }\n    setInvocationParameters(span, runInfo) {\n        if (!runInfo.extra?.metadata?.invocation_params) {\n            return;\n        }\n        const invocationParams = runInfo.extra.metadata.invocation_params;\n        // Set relevant invocation parameters\n        if (invocationParams.max_tokens !== undefined) {\n            span.setAttribute(constants.GEN_AI_REQUEST_MAX_TOKENS, invocationParams.max_tokens);\n        }\n        if (invocationParams.temperature !== undefined) {\n            span.setAttribute(constants.GEN_AI_REQUEST_TEMPERATURE, invocationParams.temperature);\n        }\n        if (invocationParams.top_p !== undefined) {\n            span.setAttribute(constants.GEN_AI_REQUEST_TOP_P, invocationParams.top_p);\n        }\n        if (invocationParams.frequency_penalty !== undefined) {\n            span.setAttribute(constants.GEN_AI_REQUEST_FREQUENCY_PENALTY, invocationParams.frequency_penalty);\n        }\n        if (invocationParams.presence_penalty !== undefined) {\n            span.setAttribute(constants.GEN_AI_REQUEST_PRESENCE_PENALTY, invocationParams.presence_penalty);\n        }\n    }\n    setIOAttributes(span, op) {\n        if (op.run.inputs) {\n            try {\n                const inputs = op.run.inputs;\n                if (typeof inputs === \"object\" && inputs !== null) {\n                    if (inputs.model && Array.isArray(inputs.messages)) {\n                        span.setAttribute(constants.GEN_AI_REQUEST_MODEL, inputs.model);\n                    }\n                    // Set additional request attributes if available\n                    if (inputs.stream !== undefined) {\n                        span.setAttribute(constants.LANGSMITH_REQUEST_STREAMING, inputs.stream);\n                    }\n                    if (inputs.extra_headers) {\n                        span.setAttribute(constants.LANGSMITH_REQUEST_HEADERS, JSON.stringify(inputs.extra_headers));\n                    }\n                    if (inputs.extra_query) {\n                        span.setAttribute(constants.GEN_AI_REQUEST_EXTRA_QUERY, JSON.stringify(inputs.extra_query));\n                    }\n                    if (inputs.extra_body) {\n                        span.setAttribute(constants.GEN_AI_REQUEST_EXTRA_BODY, JSON.stringify(inputs.extra_body));\n                    }\n                }\n                span.setAttribute(constants.GENAI_PROMPT, JSON.stringify(inputs));\n            }\n            catch (e) {\n                console.debug(`Failed to process inputs for run ${op.id}`, e);\n            }\n        }\n        if (op.run.outputs) {\n            try {\n                const outputs = op.run.outputs;\n                // Extract token usage from outputs (for LLM runs)\n                const tokenUsage = this.getUnifiedRunTokens(outputs);\n                if (tokenUsage) {\n                    span.setAttribute(constants.GEN_AI_USAGE_INPUT_TOKENS, tokenUsage[0]);\n                    span.setAttribute(constants.GEN_AI_USAGE_OUTPUT_TOKENS, tokenUsage[1]);\n                    span.setAttribute(constants.GEN_AI_USAGE_TOTAL_TOKENS, tokenUsage[0] + tokenUsage[1]);\n                }\n                if (outputs && typeof outputs === \"object\") {\n                    if (outputs.model) {\n                        span.setAttribute(constants.GEN_AI_RESPONSE_MODEL, String(outputs.model));\n                    }\n                    // Extract additional response attributes\n                    if (outputs.id) {\n                        span.setAttribute(constants.GEN_AI_RESPONSE_ID, outputs.id);\n                    }\n                    if (outputs.choices && Array.isArray(outputs.choices)) {\n                        const finishReasons = outputs.choices\n                            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                            .map((choice) => choice.finish_reason)\n                            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                            .filter((reason) => reason)\n                            .map(String);\n                        if (finishReasons.length > 0) {\n                            span.setAttribute(constants.GEN_AI_RESPONSE_FINISH_REASONS, finishReasons.join(\", \"));\n                        }\n                    }\n                    if (outputs.service_tier) {\n                        span.setAttribute(constants.GEN_AI_RESPONSE_SERVICE_TIER, outputs.service_tier);\n                    }\n                    if (outputs.system_fingerprint) {\n                        span.setAttribute(constants.GEN_AI_RESPONSE_SYSTEM_FINGERPRINT, outputs.system_fingerprint);\n                    }\n                    if (outputs.usage_metadata &&\n                        typeof outputs.usage_metadata === \"object\") {\n                        const usageMetadata = outputs.usage_metadata;\n                        if (usageMetadata.input_token_details) {\n                            span.setAttribute(constants.GEN_AI_USAGE_INPUT_TOKEN_DETAILS, JSON.stringify(usageMetadata.input_token_details));\n                        }\n                        if (usageMetadata.output_token_details) {\n                            span.setAttribute(constants.GEN_AI_USAGE_OUTPUT_TOKEN_DETAILS, JSON.stringify(usageMetadata.output_token_details));\n                        }\n                    }\n                }\n                span.setAttribute(constants.GENAI_COMPLETION, JSON.stringify(outputs));\n            }\n            catch (e) {\n                console.debug(`Failed to process outputs for run ${op.id}`, e);\n            }\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    getUnifiedRunTokens(outputs) {\n        if (!outputs) {\n            return null;\n        }\n        // Search in non-generations lists\n        let tokenUsage = this.extractUnifiedRunTokens(outputs.usage_metadata);\n        if (tokenUsage) {\n            return tokenUsage;\n        }\n        // Find if direct kwarg in outputs\n        const keys = Object.keys(outputs);\n        for (const key of keys) {\n            const haystack = outputs[key];\n            if (!haystack || typeof haystack !== \"object\") {\n                continue;\n            }\n            tokenUsage = this.extractUnifiedRunTokens(haystack.usage_metadata);\n            if (tokenUsage) {\n                return tokenUsage;\n            }\n            if (haystack.lc === 1 &&\n                haystack.kwargs &&\n                typeof haystack.kwargs === \"object\") {\n                tokenUsage = this.extractUnifiedRunTokens(haystack.kwargs.usage_metadata);\n                if (tokenUsage) {\n                    return tokenUsage;\n                }\n            }\n        }\n        // Find in generations\n        const generations = outputs.generations || [];\n        if (!Array.isArray(generations)) {\n            return null;\n        }\n        const flatGenerations = Array.isArray(generations[0])\n            ? generations.flat()\n            : generations;\n        for (const generation of flatGenerations) {\n            if (typeof generation === \"object\" &&\n                generation.message &&\n                typeof generation.message === \"object\" &&\n                generation.message.kwargs &&\n                typeof generation.message.kwargs === \"object\") {\n                tokenUsage = this.extractUnifiedRunTokens(generation.message.kwargs.usage_metadata);\n                if (tokenUsage) {\n                    return tokenUsage;\n                }\n            }\n        }\n        return null;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    extractUnifiedRunTokens(outputs) {\n        if (!outputs || typeof outputs !== \"object\") {\n            return null;\n        }\n        if (typeof outputs.input_tokens !== \"number\" ||\n            typeof outputs.output_tokens !== \"number\") {\n            return null;\n        }\n        return [outputs.input_tokens, outputs.output_tokens];\n    }\n}\n","import pRetry from \"p-retry\";\nimport PQueueMod from \"p-queue\";\nconst STATUS_RETRYABLE = [\n    429, // Too Many Requests\n    500, // Internal Server Error\n    502, // Bad Gateway\n    503, // Service Unavailable\n    504, // Gateway Timeout\n];\n/**\n * A class that can be used to make async calls with concurrency and retry logic.\n *\n * This is useful for making calls to any kind of \"expensive\" external resource,\n * be it because it's rate-limited, subject to network issues, etc.\n *\n * Concurrent calls are limited by the `maxConcurrency` parameter, which defaults\n * to `Infinity`. This means that by default, all calls will be made in parallel.\n *\n * Retries are limited by the `maxRetries` parameter, which defaults to 6. This\n * means that by default, each call will be retried up to 6 times, with an\n * exponential backoff between each attempt.\n */\nexport class AsyncCaller {\n    constructor(params) {\n        Object.defineProperty(this, \"maxConcurrency\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"maxRetries\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"queue\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"onFailedResponseHook\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.maxConcurrency = params.maxConcurrency ?? Infinity;\n        this.maxRetries = params.maxRetries ?? 6;\n        if (\"default\" in PQueueMod) {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            this.queue = new PQueueMod.default({\n                concurrency: this.maxConcurrency,\n            });\n        }\n        else {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            this.queue = new PQueueMod({ concurrency: this.maxConcurrency });\n        }\n        this.onFailedResponseHook = params?.onFailedResponseHook;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    call(callable, ...args) {\n        const onFailedResponseHook = this.onFailedResponseHook;\n        return this.queue.add(() => pRetry(() => callable(...args).catch((error) => {\n            // eslint-disable-next-line no-instanceof/no-instanceof\n            if (error instanceof Error) {\n                throw error;\n            }\n            else {\n                throw new Error(error);\n            }\n        }), {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            async onFailedAttempt(error) {\n                if (error.message.startsWith(\"Cancel\") ||\n                    error.message.startsWith(\"TimeoutError\") ||\n                    error.name === \"TimeoutError\" ||\n                    error.message.startsWith(\"AbortError\")) {\n                    throw error;\n                }\n                if (error?.code === \"ECONNABORTED\") {\n                    throw error;\n                }\n                const response = error?.response;\n                if (onFailedResponseHook) {\n                    const handled = await onFailedResponseHook(response);\n                    if (handled) {\n                        return;\n                    }\n                }\n                const status = response?.status ?? error?.status;\n                if (status) {\n                    if (!STATUS_RETRYABLE.includes(+status)) {\n                        throw error;\n                    }\n                }\n            },\n            retries: this.maxRetries,\n            randomize: true,\n        }), { throwOnTimeout: true });\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    callWithOptions(options, callable, ...args) {\n        // Note this doesn't cancel the underlying request,\n        // when available prefer to use the signal option of the underlying call\n        if (options.signal) {\n            return Promise.race([\n                this.call(callable, ...args),\n                new Promise((_, reject) => {\n                    options.signal?.addEventListener(\"abort\", () => {\n                        reject(new Error(\"AbortError\"));\n                    });\n                }),\n            ]);\n        }\n        return this.call(callable, ...args);\n    }\n}\n","export function isLangChainMessage(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nmessage) {\n    return typeof message?._getType === \"function\";\n}\nexport function convertLangChainMessageToExample(message) {\n    const converted = {\n        type: message._getType(),\n        data: { content: message.content },\n    };\n    // Check for presence of keys in additional_kwargs\n    if (message?.additional_kwargs &&\n        Object.keys(message.additional_kwargs).length > 0) {\n        converted.data.additional_kwargs = { ...message.additional_kwargs };\n    }\n    return converted;\n}\n","// Relaxed UUID validation regex (allows any valid UUID format including nil UUIDs)\nconst UUID_REGEX = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\nexport function assertUuid(str, which) {\n    // Use relaxed regex validation instead of strict uuid.validate()\n    // This allows edge cases like nil UUIDs or test UUIDs that might not pass strict validation\n    if (!UUID_REGEX.test(str)) {\n        const msg = which !== undefined\n            ? `Invalid UUID for ${which}: ${str}`\n            : `Invalid UUID: ${str}`;\n        throw new Error(msg);\n    }\n    return str;\n}\n","const warnedMessages = {};\nexport function warnOnce(message) {\n    if (!warnedMessages[message]) {\n        console.warn(message);\n        warnedMessages[message] = true;\n    }\n}\n","import { parse as parseVersion } from \"semver\";\nexport function isVersionGreaterOrEqual(current_version, target_version) {\n    const current = parseVersion(current_version);\n    const target = parseVersion(target_version);\n    if (!current || !target) {\n        throw new Error(\"Invalid version format.\");\n    }\n    return current.compare(target) >= 0;\n}\nexport function parsePromptIdentifier(identifier) {\n    if (!identifier ||\n        identifier.split(\"/\").length > 2 ||\n        identifier.startsWith(\"/\") ||\n        identifier.endsWith(\"/\") ||\n        identifier.split(\":\").length > 2) {\n        throw new Error(`Invalid identifier format: ${identifier}`);\n    }\n    const [ownerNamePart, commitPart] = identifier.split(\":\");\n    const commit = commitPart || \"latest\";\n    if (ownerNamePart.includes(\"/\")) {\n        const [owner, name] = ownerNamePart.split(\"/\", 2);\n        if (!owner || !name) {\n            throw new Error(`Invalid identifier format: ${identifier}`);\n        }\n        return [owner, name, commit];\n    }\n    else {\n        if (!ownerNamePart) {\n            throw new Error(`Invalid identifier format: ${identifier}`);\n        }\n        return [\"-\", ownerNamePart, commit];\n    }\n}\n","function getErrorStackTrace(e) {\n    if (typeof e !== \"object\" || e == null)\n        return undefined;\n    if (!(\"stack\" in e) || typeof e.stack !== \"string\")\n        return undefined;\n    let stack = e.stack;\n    const prevLine = `${e}`;\n    if (stack.startsWith(prevLine)) {\n        stack = stack.slice(prevLine.length);\n    }\n    if (stack.startsWith(\"\\n\")) {\n        stack = stack.slice(1);\n    }\n    return stack;\n}\nexport function printErrorStackTrace(e) {\n    const stack = getErrorStackTrace(e);\n    if (stack == null)\n        return;\n    console.error(stack);\n}\n/**\n * LangSmithConflictError\n *\n * Represents an error that occurs when there's a conflict during an operation,\n * typically corresponding to HTTP 409 status code responses.\n *\n * This error is thrown when an attempt to create or modify a resource conflicts\n * with the current state of the resource on the server. Common scenarios include:\n * - Attempting to create a resource that already exists\n * - Trying to update a resource that has been modified by another process\n * - Violating a uniqueness constraint in the data\n *\n * @extends Error\n *\n * @example\n * try {\n *   await createProject(\"existingProject\");\n * } catch (error) {\n *   if (error instanceof ConflictError) {\n *     console.log(\"A conflict occurred:\", error.message);\n *     // Handle the conflict, e.g., by suggesting a different project name\n *   } else {\n *     // Handle other types of errors\n *   }\n * }\n *\n * @property {string} name - Always set to 'ConflictError' for easy identification\n * @property {string} message - Detailed error message including server response\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409\n */\nexport class LangSmithConflictError extends Error {\n    constructor(message) {\n        super(message);\n        Object.defineProperty(this, \"status\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.name = \"LangSmithConflictError\";\n        this.status = 409;\n    }\n}\n/**\n * Throws an appropriate error based on the response status and body.\n *\n * @param response - The fetch Response object\n * @param context - Additional context to include in the error message (e.g., operation being performed)\n * @throws {LangSmithConflictError} When the response status is 409\n * @throws {Error} For all other non-ok responses\n */\nexport async function raiseForStatus(response, context, consumeOnSuccess) {\n    let errorBody;\n    if (response.ok) {\n        // consume the response body to release the connection\n        // https://undici.nodejs.org/#/?id=garbage-collection\n        if (consumeOnSuccess) {\n            errorBody = await response.text();\n        }\n        return;\n    }\n    if (response.status === 403) {\n        try {\n            const errorData = await response.json();\n            const errorCode = errorData?.error;\n            if (errorCode === \"org_scoped_key_requires_workspace\") {\n                errorBody =\n                    \"This API key is org-scoped and requires workspace specification. \" +\n                        \"Please provide 'workspaceId' parameter, \" +\n                        \"or set LANGSMITH_WORKSPACE_ID environment variable.\";\n            }\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        }\n        catch (e) {\n            const errorWithStatus = new Error(`${response.status} ${response.statusText}`);\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            errorWithStatus.status = response?.status;\n            throw errorWithStatus;\n        }\n    }\n    if (errorBody === undefined) {\n        try {\n            errorBody = await response.text();\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        }\n        catch (e) {\n            errorBody = \"\";\n        }\n    }\n    const fullMessage = `Failed to ${context}. Received status [${response.status}]: ${response.statusText}. Message: ${errorBody}`;\n    if (response.status === 409) {\n        throw new LangSmithConflictError(fullMessage);\n    }\n    const err = new Error(fullMessage);\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    err.status = response.status;\n    throw err;\n}\nconst ERR_CONFLICTING_ENDPOINTS = \"ERR_CONFLICTING_ENDPOINTS\";\nexport class ConflictingEndpointsError extends Error {\n    constructor() {\n        super(\"You cannot provide both LANGSMITH_ENDPOINT / LANGCHAIN_ENDPOINT \" +\n            \"and LANGSMITH_RUNS_ENDPOINTS.\");\n        Object.defineProperty(this, \"code\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: ERR_CONFLICTING_ENDPOINTS\n        });\n        this.name = \"ConflictingEndpointsError\"; // helpful in logs\n    }\n}\nexport function isConflictingEndpointsError(err) {\n    return (typeof err === \"object\" &&\n        err !== null &&\n        err.code === ERR_CONFLICTING_ENDPOINTS);\n}\n","/* eslint-disable */\n// @ts-nocheck\nimport { getLangSmithEnvironmentVariable } from \"../../utils/env.js\";\nvar LIMIT_REPLACE_NODE = \"[...]\";\nvar CIRCULAR_REPLACE_NODE = { result: \"[Circular]\" };\nvar arr = [];\nvar replacerStack = [];\nconst encoder = new TextEncoder();\nfunction defaultOptions() {\n    return {\n        depthLimit: Number.MAX_SAFE_INTEGER,\n        edgesLimit: Number.MAX_SAFE_INTEGER,\n    };\n}\nfunction encodeString(str) {\n    return encoder.encode(str);\n}\n// Shared function to handle well-known types\nfunction serializeWellKnownTypes(val) {\n    if (val && typeof val === \"object\" && val !== null) {\n        if (val instanceof Map) {\n            return Object.fromEntries(val);\n        }\n        else if (val instanceof Set) {\n            return Array.from(val);\n        }\n        else if (val instanceof Date) {\n            return val.toISOString();\n        }\n        else if (val instanceof RegExp) {\n            return val.toString();\n        }\n        else if (val instanceof Error) {\n            return {\n                name: val.name,\n                message: val.message,\n            };\n        }\n    }\n    else if (typeof val === \"bigint\") {\n        return val.toString();\n    }\n    return val;\n}\n// Default replacer function to handle well-known types\nfunction createDefaultReplacer(userReplacer) {\n    return function (key, val) {\n        // Apply user replacer first if provided\n        if (userReplacer) {\n            const userResult = userReplacer.call(this, key, val);\n            // If user replacer returned undefined, fall back to our serialization\n            if (userResult !== undefined) {\n                return userResult;\n            }\n        }\n        // Fall back to our well-known type handling\n        return serializeWellKnownTypes(val);\n    };\n}\n// Regular stringify\nexport function serialize(obj, errorContext, replacer, spacer, options) {\n    try {\n        const str = JSON.stringify(obj, createDefaultReplacer(replacer), spacer);\n        return encodeString(str);\n    }\n    catch (e) {\n        // Fall back to more complex stringify if circular reference\n        if (!e.message?.includes(\"Converting circular structure to JSON\")) {\n            console.warn(`[WARNING]: LangSmith received unserializable value.${errorContext ? `\\nContext: ${errorContext}` : \"\"}`);\n            return encodeString(\"[Unserializable]\");\n        }\n        getLangSmithEnvironmentVariable(\"SUPPRESS_CIRCULAR_JSON_WARNINGS\") !==\n            \"true\" &&\n            console.warn(`[WARNING]: LangSmith received circular JSON. This will decrease tracer performance. ${errorContext ? `\\nContext: ${errorContext}` : \"\"}`);\n        if (typeof options === \"undefined\") {\n            options = defaultOptions();\n        }\n        decirc(obj, \"\", 0, [], undefined, 0, options);\n        let res;\n        try {\n            if (replacerStack.length === 0) {\n                res = JSON.stringify(obj, replacer, spacer);\n            }\n            else {\n                res = JSON.stringify(obj, replaceGetterValues(replacer), spacer);\n            }\n        }\n        catch (_) {\n            return encodeString(\"[unable to serialize, circular reference is too complex to analyze]\");\n        }\n        finally {\n            while (arr.length !== 0) {\n                const part = arr.pop();\n                if (part.length === 4) {\n                    Object.defineProperty(part[0], part[1], part[3]);\n                }\n                else {\n                    part[0][part[1]] = part[2];\n                }\n            }\n        }\n        return encodeString(res);\n    }\n}\nfunction setReplace(replace, val, k, parent) {\n    var propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k);\n    if (propertyDescriptor.get !== undefined) {\n        if (propertyDescriptor.configurable) {\n            Object.defineProperty(parent, k, { value: replace });\n            arr.push([parent, k, val, propertyDescriptor]);\n        }\n        else {\n            replacerStack.push([val, k, replace]);\n        }\n    }\n    else {\n        parent[k] = replace;\n        arr.push([parent, k, val]);\n    }\n}\nfunction decirc(val, k, edgeIndex, stack, parent, depth, options) {\n    depth += 1;\n    var i;\n    if (typeof val === \"object\" && val !== null) {\n        for (i = 0; i < stack.length; i++) {\n            if (stack[i] === val) {\n                setReplace(CIRCULAR_REPLACE_NODE, val, k, parent);\n                return;\n            }\n        }\n        if (typeof options.depthLimit !== \"undefined\" &&\n            depth > options.depthLimit) {\n            setReplace(LIMIT_REPLACE_NODE, val, k, parent);\n            return;\n        }\n        if (typeof options.edgesLimit !== \"undefined\" &&\n            edgeIndex + 1 > options.edgesLimit) {\n            setReplace(LIMIT_REPLACE_NODE, val, k, parent);\n            return;\n        }\n        stack.push(val);\n        // Optimize for Arrays. Big arrays could kill the performance otherwise!\n        if (Array.isArray(val)) {\n            for (i = 0; i < val.length; i++) {\n                decirc(val[i], i, i, stack, val, depth, options);\n            }\n        }\n        else {\n            // Handle well-known types before Object.keys iteration\n            val = serializeWellKnownTypes(val);\n            var keys = Object.keys(val);\n            for (i = 0; i < keys.length; i++) {\n                var key = keys[i];\n                decirc(val[key], key, i, stack, val, depth, options);\n            }\n        }\n        stack.pop();\n    }\n}\n// Stable-stringify\nfunction compareFunction(a, b) {\n    if (a < b) {\n        return -1;\n    }\n    if (a > b) {\n        return 1;\n    }\n    return 0;\n}\nfunction deterministicStringify(obj, replacer, spacer, options) {\n    if (typeof options === \"undefined\") {\n        options = defaultOptions();\n    }\n    var tmp = deterministicDecirc(obj, \"\", 0, [], undefined, 0, options) || obj;\n    var res;\n    try {\n        if (replacerStack.length === 0) {\n            res = JSON.stringify(tmp, replacer, spacer);\n        }\n        else {\n            res = JSON.stringify(tmp, replaceGetterValues(replacer), spacer);\n        }\n    }\n    catch (_) {\n        return JSON.stringify(\"[unable to serialize, circular reference is too complex to analyze]\");\n    }\n    finally {\n        // Ensure that we restore the object as it was.\n        while (arr.length !== 0) {\n            var part = arr.pop();\n            if (part.length === 4) {\n                Object.defineProperty(part[0], part[1], part[3]);\n            }\n            else {\n                part[0][part[1]] = part[2];\n            }\n        }\n    }\n    return res;\n}\nfunction deterministicDecirc(val, k, edgeIndex, stack, parent, depth, options) {\n    depth += 1;\n    var i;\n    if (typeof val === \"object\" && val !== null) {\n        for (i = 0; i < stack.length; i++) {\n            if (stack[i] === val) {\n                setReplace(CIRCULAR_REPLACE_NODE, val, k, parent);\n                return;\n            }\n        }\n        try {\n            if (typeof val.toJSON === \"function\") {\n                return;\n            }\n        }\n        catch (_) {\n            return;\n        }\n        if (typeof options.depthLimit !== \"undefined\" &&\n            depth > options.depthLimit) {\n            setReplace(LIMIT_REPLACE_NODE, val, k, parent);\n            return;\n        }\n        if (typeof options.edgesLimit !== \"undefined\" &&\n            edgeIndex + 1 > options.edgesLimit) {\n            setReplace(LIMIT_REPLACE_NODE, val, k, parent);\n            return;\n        }\n        stack.push(val);\n        // Optimize for Arrays. Big arrays could kill the performance otherwise!\n        if (Array.isArray(val)) {\n            for (i = 0; i < val.length; i++) {\n                deterministicDecirc(val[i], i, i, stack, val, depth, options);\n            }\n        }\n        else {\n            // Handle well-known types before Object.keys iteration\n            val = serializeWellKnownTypes(val);\n            // Create a temporary object in the required way\n            var tmp = {};\n            var keys = Object.keys(val).sort(compareFunction);\n            for (i = 0; i < keys.length; i++) {\n                var key = keys[i];\n                deterministicDecirc(val[key], key, i, stack, val, depth, options);\n                tmp[key] = val[key];\n            }\n            if (typeof parent !== \"undefined\") {\n                arr.push([parent, k, val]);\n                parent[k] = tmp;\n            }\n            else {\n                return tmp;\n            }\n        }\n        stack.pop();\n    }\n}\n// wraps replacer function to handle values we couldn't replace\n// and mark them as replaced value\nfunction replaceGetterValues(replacer) {\n    replacer =\n        typeof replacer !== \"undefined\"\n            ? replacer\n            : function (k, v) {\n                return v;\n            };\n    return function (key, val) {\n        if (replacerStack.length > 0) {\n            for (var i = 0; i < replacerStack.length; i++) {\n                var part = replacerStack[i];\n                if (part[1] === key && part[0] === val) {\n                    val = part[2];\n                    replacerStack.splice(i, 1);\n                    break;\n                }\n            }\n        }\n        return replacer.call(this, key, val);\n    };\n}\n","import * as uuid from \"uuid\";\nimport { LangSmithToOTELTranslator, } from \"./experimental/otel/translator.js\";\nimport { getDefaultOTLPTracerComponents, getOTELTrace, getOTELContext, } from \"./singletons/otel.js\";\nimport { AsyncCaller } from \"./utils/async_caller.js\";\nimport { convertLangChainMessageToExample, isLangChainMessage, } from \"./utils/messages.js\";\nimport { getEnvironmentVariable, getLangSmithEnvVarsMetadata, getLangSmithEnvironmentVariable, getRuntimeEnvironment, getOtelEnabled, getEnv, } from \"./utils/env.js\";\nimport { __version__ } from \"./index.js\";\nimport { assertUuid } from \"./utils/_uuid.js\";\nimport { warnOnce } from \"./utils/warn.js\";\nimport { parsePromptIdentifier } from \"./utils/prompts.js\";\nimport { raiseForStatus } from \"./utils/error.js\";\nimport { _globalFetchImplementationIsNodeFetch, _getFetchImplementation, } from \"./singletons/fetch.js\";\nimport { serialize as serializePayloadForTracing } from \"./utils/fast-safe-stringify/index.js\";\nexport function mergeRuntimeEnvIntoRun(run, cachedEnvVars) {\n    const runtimeEnv = getRuntimeEnvironment();\n    const envVars = cachedEnvVars ?? getLangSmithEnvVarsMetadata();\n    const extra = run.extra ?? {};\n    const metadata = extra.metadata;\n    run.extra = {\n        ...extra,\n        runtime: {\n            ...runtimeEnv,\n            ...extra?.runtime,\n        },\n        metadata: {\n            ...envVars,\n            ...(envVars.revision_id || (\"revision_id\" in run && run.revision_id)\n                ? {\n                    revision_id: (\"revision_id\" in run ? run.revision_id : undefined) ??\n                        envVars.revision_id,\n                }\n                : {}),\n            ...metadata,\n        },\n    };\n    return run;\n}\nconst getTracingSamplingRate = (configRate) => {\n    const samplingRateStr = configRate?.toString() ??\n        getLangSmithEnvironmentVariable(\"TRACING_SAMPLING_RATE\");\n    if (samplingRateStr === undefined) {\n        return undefined;\n    }\n    const samplingRate = parseFloat(samplingRateStr);\n    if (samplingRate < 0 || samplingRate > 1) {\n        throw new Error(`LANGSMITH_TRACING_SAMPLING_RATE must be between 0 and 1 if set. Got: ${samplingRate}`);\n    }\n    return samplingRate;\n};\n// utility functions\nconst isLocalhost = (url) => {\n    const strippedUrl = url.replace(\"http://\", \"\").replace(\"https://\", \"\");\n    const hostname = strippedUrl.split(\"/\")[0].split(\":\")[0];\n    return (hostname === \"localhost\" || hostname === \"127.0.0.1\" || hostname === \"::1\");\n};\nasync function toArray(iterable) {\n    const result = [];\n    for await (const item of iterable) {\n        result.push(item);\n    }\n    return result;\n}\nfunction trimQuotes(str) {\n    if (str === undefined) {\n        return undefined;\n    }\n    return str\n        .trim()\n        .replace(/^\"(.*)\"$/, \"$1\")\n        .replace(/^'(.*)'$/, \"$1\");\n}\nconst handle429 = async (response) => {\n    if (response?.status === 429) {\n        const retryAfter = parseInt(response.headers.get(\"retry-after\") ?? \"10\", 10) * 1000;\n        if (retryAfter > 0) {\n            await new Promise((resolve) => setTimeout(resolve, retryAfter));\n            // Return directly after calling this check\n            return true;\n        }\n    }\n    // Fall back to existing status checks\n    return false;\n};\nfunction _formatFeedbackScore(score) {\n    if (typeof score === \"number\") {\n        // Truncate at 4 decimal places\n        return Number(score.toFixed(4));\n    }\n    return score;\n}\nexport class AutoBatchQueue {\n    constructor() {\n        Object.defineProperty(this, \"items\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: []\n        });\n        Object.defineProperty(this, \"sizeBytes\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n    }\n    peek() {\n        return this.items[0];\n    }\n    push(item) {\n        let itemPromiseResolve;\n        const itemPromise = new Promise((resolve) => {\n            // Setting itemPromiseResolve is synchronous with promise creation:\n            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/Promise\n            itemPromiseResolve = resolve;\n        });\n        const size = serializePayloadForTracing(item.item, `Serializing run with id: ${item.item.id}`).length;\n        this.items.push({\n            action: item.action,\n            payload: item.item,\n            otelContext: item.otelContext,\n            apiKey: item.apiKey,\n            apiUrl: item.apiUrl,\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            itemPromiseResolve: itemPromiseResolve,\n            itemPromise,\n            size,\n        });\n        this.sizeBytes += size;\n        return itemPromise;\n    }\n    pop({ upToSizeBytes, upToSize, }) {\n        if (upToSizeBytes < 1) {\n            throw new Error(\"Number of bytes to pop off may not be less than 1.\");\n        }\n        const popped = [];\n        let poppedSizeBytes = 0;\n        // Pop items until we reach or exceed the size limit\n        while (poppedSizeBytes + (this.peek()?.size ?? 0) < upToSizeBytes &&\n            this.items.length > 0 &&\n            popped.length < upToSize) {\n            const item = this.items.shift();\n            if (item) {\n                popped.push(item);\n                poppedSizeBytes += item.size;\n                this.sizeBytes -= item.size;\n            }\n        }\n        // If there is an item on the queue we were unable to pop,\n        // just return it as a single batch.\n        if (popped.length === 0 && this.items.length > 0) {\n            const item = this.items.shift();\n            popped.push(item);\n            poppedSizeBytes += item.size;\n            this.sizeBytes -= item.size;\n        }\n        return [\n            popped.map((it) => ({\n                action: it.action,\n                item: it.payload,\n                otelContext: it.otelContext,\n                apiKey: it.apiKey,\n                apiUrl: it.apiUrl,\n            })),\n            () => popped.forEach((it) => it.itemPromiseResolve()),\n        ];\n    }\n}\nexport const DEFAULT_UNCOMPRESSED_BATCH_SIZE_LIMIT_BYTES = 24 * 1024 * 1024;\nconst SERVER_INFO_REQUEST_TIMEOUT_MS = 10000;\n/** Maximum number of operations to batch in a single request. */\nconst DEFAULT_BATCH_SIZE_LIMIT = 100;\nconst DEFAULT_API_URL = \"https://api.smith.langchain.com\";\nexport class Client {\n    get _fetch() {\n        return this.fetchImplementation || _getFetchImplementation(this.debug);\n    }\n    constructor(config = {}) {\n        Object.defineProperty(this, \"apiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"apiUrl\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"webUrl\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"workspaceId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"caller\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"batchIngestCaller\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"timeout_ms\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"_tenantId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: null\n        });\n        Object.defineProperty(this, \"hideInputs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"hideOutputs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"tracingSampleRate\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"filteredPostUuids\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: new Set()\n        });\n        Object.defineProperty(this, \"autoBatchTracing\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"autoBatchQueue\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: new AutoBatchQueue()\n        });\n        Object.defineProperty(this, \"autoBatchTimeout\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"autoBatchAggregationDelayMs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 250\n        });\n        Object.defineProperty(this, \"batchSizeBytesLimit\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"batchSizeLimit\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"fetchOptions\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"settings\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"blockOnRootRunFinalization\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: getEnvironmentVariable(\"LANGSMITH_TRACING_BACKGROUND\") === \"false\"\n        });\n        Object.defineProperty(this, \"traceBatchConcurrency\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 5\n        });\n        Object.defineProperty(this, \"_serverInfo\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        Object.defineProperty(this, \"_getServerInfoPromise\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"manualFlushMode\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"langSmithToOTELTranslator\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"fetchImplementation\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"cachedLSEnvVarsForMetadata\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"multipartStreamingDisabled\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"debug\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: getEnvironmentVariable(\"LANGSMITH_DEBUG\") === \"true\"\n        });\n        const defaultConfig = Client.getDefaultClientConfig();\n        this.tracingSampleRate = getTracingSamplingRate(config.tracingSamplingRate);\n        this.apiUrl = trimQuotes(config.apiUrl ?? defaultConfig.apiUrl) ?? \"\";\n        if (this.apiUrl.endsWith(\"/\")) {\n            this.apiUrl = this.apiUrl.slice(0, -1);\n        }\n        this.apiKey = trimQuotes(config.apiKey ?? defaultConfig.apiKey);\n        this.webUrl = trimQuotes(config.webUrl ?? defaultConfig.webUrl);\n        if (this.webUrl?.endsWith(\"/\")) {\n            this.webUrl = this.webUrl.slice(0, -1);\n        }\n        this.workspaceId = trimQuotes(config.workspaceId ?? getLangSmithEnvironmentVariable(\"WORKSPACE_ID\"));\n        this.timeout_ms = config.timeout_ms ?? 90_000;\n        this.caller = new AsyncCaller({\n            ...(config.callerOptions ?? {}),\n            maxRetries: 4,\n            debug: config.debug ?? this.debug,\n        });\n        this.traceBatchConcurrency =\n            config.traceBatchConcurrency ?? this.traceBatchConcurrency;\n        if (this.traceBatchConcurrency < 1) {\n            throw new Error(\"Trace batch concurrency must be positive.\");\n        }\n        this.debug = config.debug ?? this.debug;\n        this.fetchImplementation = config.fetchImplementation;\n        this.batchIngestCaller = new AsyncCaller({\n            maxRetries: 2,\n            maxConcurrency: this.traceBatchConcurrency,\n            ...(config.callerOptions ?? {}),\n            onFailedResponseHook: handle429,\n            debug: config.debug ?? this.debug,\n        });\n        this.hideInputs =\n            config.hideInputs ?? config.anonymizer ?? defaultConfig.hideInputs;\n        this.hideOutputs =\n            config.hideOutputs ?? config.anonymizer ?? defaultConfig.hideOutputs;\n        this.autoBatchTracing = config.autoBatchTracing ?? this.autoBatchTracing;\n        this.blockOnRootRunFinalization =\n            config.blockOnRootRunFinalization ?? this.blockOnRootRunFinalization;\n        this.batchSizeBytesLimit = config.batchSizeBytesLimit;\n        this.batchSizeLimit = config.batchSizeLimit;\n        this.fetchOptions = config.fetchOptions || {};\n        this.manualFlushMode = config.manualFlushMode ?? this.manualFlushMode;\n        if (getOtelEnabled()) {\n            this.langSmithToOTELTranslator = new LangSmithToOTELTranslator();\n        }\n        // Cache metadata env vars once during construction to avoid repeatedly scanning process.env\n        this.cachedLSEnvVarsForMetadata = getLangSmithEnvVarsMetadata();\n    }\n    static getDefaultClientConfig() {\n        const apiKey = getLangSmithEnvironmentVariable(\"API_KEY\");\n        const apiUrl = getLangSmithEnvironmentVariable(\"ENDPOINT\") ?? DEFAULT_API_URL;\n        const hideInputs = getLangSmithEnvironmentVariable(\"HIDE_INPUTS\") === \"true\";\n        const hideOutputs = getLangSmithEnvironmentVariable(\"HIDE_OUTPUTS\") === \"true\";\n        return {\n            apiUrl: apiUrl,\n            apiKey: apiKey,\n            webUrl: undefined,\n            hideInputs: hideInputs,\n            hideOutputs: hideOutputs,\n        };\n    }\n    getHostUrl() {\n        if (this.webUrl) {\n            return this.webUrl;\n        }\n        else if (isLocalhost(this.apiUrl)) {\n            this.webUrl = \"http://localhost:3000\";\n            return this.webUrl;\n        }\n        else if (this.apiUrl.endsWith(\"/api/v1\")) {\n            this.webUrl = this.apiUrl.replace(\"/api/v1\", \"\");\n            return this.webUrl;\n        }\n        else if (this.apiUrl.includes(\"/api\") &&\n            !this.apiUrl.split(\".\", 1)[0].endsWith(\"api\")) {\n            this.webUrl = this.apiUrl.replace(\"/api\", \"\");\n            return this.webUrl;\n        }\n        else if (this.apiUrl.split(\".\", 1)[0].includes(\"dev\")) {\n            this.webUrl = \"https://dev.smith.langchain.com\";\n            return this.webUrl;\n        }\n        else if (this.apiUrl.split(\".\", 1)[0].includes(\"eu\")) {\n            this.webUrl = \"https://eu.smith.langchain.com\";\n            return this.webUrl;\n        }\n        else if (this.apiUrl.split(\".\", 1)[0].includes(\"beta\")) {\n            this.webUrl = \"https://beta.smith.langchain.com\";\n            return this.webUrl;\n        }\n        else {\n            this.webUrl = \"https://smith.langchain.com\";\n            return this.webUrl;\n        }\n    }\n    get headers() {\n        const headers = {\n            \"User-Agent\": `langsmith-js/${__version__}`,\n        };\n        if (this.apiKey) {\n            headers[\"x-api-key\"] = `${this.apiKey}`;\n        }\n        if (this.workspaceId) {\n            headers[\"x-tenant-id\"] = this.workspaceId;\n        }\n        return headers;\n    }\n    _getPlatformEndpointPath(path) {\n        // Check if apiUrl already ends with /v1 or /v1/ to avoid double /v1/v1/ paths\n        const needsV1Prefix = this.apiUrl.slice(-3) !== \"/v1\" && this.apiUrl.slice(-4) !== \"/v1/\";\n        return needsV1Prefix ? `/v1/platform/${path}` : `/platform/${path}`;\n    }\n    async processInputs(inputs) {\n        if (this.hideInputs === false) {\n            return inputs;\n        }\n        if (this.hideInputs === true) {\n            return {};\n        }\n        if (typeof this.hideInputs === \"function\") {\n            return this.hideInputs(inputs);\n        }\n        return inputs;\n    }\n    async processOutputs(outputs) {\n        if (this.hideOutputs === false) {\n            return outputs;\n        }\n        if (this.hideOutputs === true) {\n            return {};\n        }\n        if (typeof this.hideOutputs === \"function\") {\n            return this.hideOutputs(outputs);\n        }\n        return outputs;\n    }\n    async prepareRunCreateOrUpdateInputs(run) {\n        const runParams = { ...run };\n        if (runParams.inputs !== undefined) {\n            runParams.inputs = await this.processInputs(runParams.inputs);\n        }\n        if (runParams.outputs !== undefined) {\n            runParams.outputs = await this.processOutputs(runParams.outputs);\n        }\n        return runParams;\n    }\n    async _getResponse(path, queryParams) {\n        const paramsString = queryParams?.toString() ?? \"\";\n        const url = `${this.apiUrl}${path}?${paramsString}`;\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(url, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, `fetch ${path}`);\n            return res;\n        });\n        return response;\n    }\n    async _get(path, queryParams) {\n        const response = await this._getResponse(path, queryParams);\n        return response.json();\n    }\n    async *_getPaginated(path, queryParams = new URLSearchParams(), transform) {\n        let offset = Number(queryParams.get(\"offset\")) || 0;\n        const limit = Number(queryParams.get(\"limit\")) || 100;\n        while (true) {\n            queryParams.set(\"offset\", String(offset));\n            queryParams.set(\"limit\", String(limit));\n            const url = `${this.apiUrl}${path}?${queryParams}`;\n            const response = await this.caller.call(async () => {\n                const res = await this._fetch(url, {\n                    method: \"GET\",\n                    headers: this.headers,\n                    signal: AbortSignal.timeout(this.timeout_ms),\n                    ...this.fetchOptions,\n                });\n                await raiseForStatus(res, `fetch ${path}`);\n                return res;\n            });\n            const items = transform\n                ? transform(await response.json())\n                : await response.json();\n            if (items.length === 0) {\n                break;\n            }\n            yield items;\n            if (items.length < limit) {\n                break;\n            }\n            offset += items.length;\n        }\n    }\n    async *_getCursorPaginatedList(path, body = null, requestMethod = \"POST\", dataKey = \"runs\") {\n        const bodyParams = body ? { ...body } : {};\n        while (true) {\n            const body = JSON.stringify(bodyParams);\n            const response = await this.caller.call(async () => {\n                const res = await this._fetch(`${this.apiUrl}${path}`, {\n                    method: requestMethod,\n                    headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                    signal: AbortSignal.timeout(this.timeout_ms),\n                    ...this.fetchOptions,\n                    body,\n                });\n                await raiseForStatus(res, `fetch ${path}`);\n                return res;\n            });\n            const responseBody = await response.json();\n            if (!responseBody) {\n                break;\n            }\n            if (!responseBody[dataKey]) {\n                break;\n            }\n            yield responseBody[dataKey];\n            const cursors = responseBody.cursors;\n            if (!cursors) {\n                break;\n            }\n            if (!cursors.next) {\n                break;\n            }\n            bodyParams.cursor = cursors.next;\n        }\n    }\n    // Allows mocking for tests\n    _shouldSample() {\n        if (this.tracingSampleRate === undefined) {\n            return true;\n        }\n        return Math.random() < this.tracingSampleRate;\n    }\n    _filterForSampling(runs, patch = false) {\n        if (this.tracingSampleRate === undefined) {\n            return runs;\n        }\n        if (patch) {\n            const sampled = [];\n            for (const run of runs) {\n                if (!this.filteredPostUuids.has(run.trace_id)) {\n                    sampled.push(run);\n                }\n                else if (run.id === run.trace_id) {\n                    this.filteredPostUuids.delete(run.trace_id);\n                }\n            }\n            return sampled;\n        }\n        else {\n            // For new runs, sample at trace level to maintain consistency\n            const sampled = [];\n            for (const run of runs) {\n                const traceId = run.trace_id ?? run.id;\n                // If we've already made a decision about this trace, follow it\n                if (this.filteredPostUuids.has(traceId)) {\n                    continue;\n                }\n                // For new traces, apply sampling\n                if (run.id === traceId) {\n                    if (this._shouldSample()) {\n                        sampled.push(run);\n                    }\n                    else {\n                        this.filteredPostUuids.add(traceId);\n                    }\n                }\n                else {\n                    // Child runs follow their trace's sampling decision\n                    sampled.push(run);\n                }\n            }\n            return sampled;\n        }\n    }\n    async _getBatchSizeLimitBytes() {\n        const serverInfo = await this._ensureServerInfo();\n        return (this.batchSizeBytesLimit ??\n            serverInfo.batch_ingest_config?.size_limit_bytes ??\n            DEFAULT_UNCOMPRESSED_BATCH_SIZE_LIMIT_BYTES);\n    }\n    /**\n     * Get the maximum number of operations to batch in a single request.\n     */\n    async _getBatchSizeLimit() {\n        const serverInfo = await this._ensureServerInfo();\n        return (this.batchSizeLimit ??\n            serverInfo.batch_ingest_config?.size_limit ??\n            DEFAULT_BATCH_SIZE_LIMIT);\n    }\n    async _getDatasetExamplesMultiPartSupport() {\n        const serverInfo = await this._ensureServerInfo();\n        return (serverInfo.instance_flags?.dataset_examples_multipart_enabled ?? false);\n    }\n    drainAutoBatchQueue({ batchSizeLimitBytes, batchSizeLimit, }) {\n        const promises = [];\n        while (this.autoBatchQueue.items.length > 0) {\n            const [batch, done] = this.autoBatchQueue.pop({\n                upToSizeBytes: batchSizeLimitBytes,\n                upToSize: batchSizeLimit,\n            });\n            if (!batch.length) {\n                done();\n                break;\n            }\n            const batchesByDestination = batch.reduce((acc, item) => {\n                const apiUrl = item.apiUrl ?? this.apiUrl;\n                const apiKey = item.apiKey ?? this.apiKey;\n                const isDefault = item.apiKey === this.apiKey && item.apiUrl === this.apiUrl;\n                const batchKey = isDefault ? \"default\" : `${apiUrl}|${apiKey}`;\n                if (!acc[batchKey]) {\n                    acc[batchKey] = [];\n                }\n                acc[batchKey].push(item);\n                return acc;\n            }, {});\n            const batchPromises = [];\n            for (const [batchKey, batch] of Object.entries(batchesByDestination)) {\n                const batchPromise = this._processBatch(batch, {\n                    apiUrl: batchKey === \"default\" ? undefined : batchKey.split(\"|\")[0],\n                    apiKey: batchKey === \"default\" ? undefined : batchKey.split(\"|\")[1],\n                });\n                batchPromises.push(batchPromise);\n            }\n            // Wait for all batches to complete, then call the overall done callback\n            const allBatchesPromise = Promise.all(batchPromises).finally(done);\n            promises.push(allBatchesPromise);\n        }\n        return Promise.all(promises);\n    }\n    async _processBatch(batch, options) {\n        if (!batch.length) {\n            return;\n        }\n        try {\n            if (this.langSmithToOTELTranslator !== undefined) {\n                this._sendBatchToOTELTranslator(batch);\n            }\n            else {\n                const ingestParams = {\n                    runCreates: batch\n                        .filter((item) => item.action === \"create\")\n                        .map((item) => item.item),\n                    runUpdates: batch\n                        .filter((item) => item.action === \"update\")\n                        .map((item) => item.item),\n                };\n                const serverInfo = await this._ensureServerInfo();\n                if (serverInfo?.batch_ingest_config?.use_multipart_endpoint) {\n                    const useGzip = serverInfo?.instance_flags?.gzip_body_enabled;\n                    await this.multipartIngestRuns(ingestParams, { ...options, useGzip });\n                }\n                else {\n                    await this.batchIngestRuns(ingestParams, options);\n                }\n            }\n        }\n        catch (e) {\n            console.error(\"Error exporting batch:\", e);\n        }\n    }\n    _sendBatchToOTELTranslator(batch) {\n        if (this.langSmithToOTELTranslator !== undefined) {\n            const otelContextMap = new Map();\n            const operations = [];\n            for (const item of batch) {\n                if (item.item.id && item.otelContext) {\n                    otelContextMap.set(item.item.id, item.otelContext);\n                    if (item.action === \"create\") {\n                        operations.push({\n                            operation: \"post\",\n                            id: item.item.id,\n                            trace_id: item.item.trace_id ?? item.item.id,\n                            run: item.item,\n                        });\n                    }\n                    else {\n                        operations.push({\n                            operation: \"patch\",\n                            id: item.item.id,\n                            trace_id: item.item.trace_id ?? item.item.id,\n                            run: item.item,\n                        });\n                    }\n                }\n            }\n            this.langSmithToOTELTranslator.exportBatch(operations, otelContextMap);\n        }\n    }\n    async processRunOperation(item) {\n        clearTimeout(this.autoBatchTimeout);\n        this.autoBatchTimeout = undefined;\n        item.item = mergeRuntimeEnvIntoRun(item.item, this.cachedLSEnvVarsForMetadata);\n        const itemPromise = this.autoBatchQueue.push(item);\n        if (this.manualFlushMode) {\n            // Rely on manual flushing in serverless environments\n            return itemPromise;\n        }\n        const sizeLimitBytes = await this._getBatchSizeLimitBytes();\n        const sizeLimit = await this._getBatchSizeLimit();\n        if (this.autoBatchQueue.sizeBytes > sizeLimitBytes ||\n            this.autoBatchQueue.items.length > sizeLimit) {\n            void this.drainAutoBatchQueue({\n                batchSizeLimitBytes: sizeLimitBytes,\n                batchSizeLimit: sizeLimit,\n            });\n        }\n        if (this.autoBatchQueue.items.length > 0) {\n            this.autoBatchTimeout = setTimeout(() => {\n                this.autoBatchTimeout = undefined;\n                void this.drainAutoBatchQueue({\n                    batchSizeLimitBytes: sizeLimitBytes,\n                    batchSizeLimit: sizeLimit,\n                });\n            }, this.autoBatchAggregationDelayMs);\n        }\n        return itemPromise;\n    }\n    async _getServerInfo() {\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/info`, {\n                method: \"GET\",\n                headers: { Accept: \"application/json\" },\n                signal: AbortSignal.timeout(SERVER_INFO_REQUEST_TIMEOUT_MS),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"get server info\");\n            return res;\n        });\n        const json = await response.json();\n        if (this.debug) {\n            console.log(\"\\n=== LangSmith Server Configuration ===\\n\" +\n                JSON.stringify(json, null, 2) +\n                \"\\n\");\n        }\n        return json;\n    }\n    async _ensureServerInfo() {\n        if (this._getServerInfoPromise === undefined) {\n            this._getServerInfoPromise = (async () => {\n                if (this._serverInfo === undefined) {\n                    try {\n                        this._serverInfo = await this._getServerInfo();\n                    }\n                    catch (e) {\n                        console.warn(`[LANGSMITH]: Failed to fetch info on supported operations. Falling back to batch operations and default limits. Info: ${e.status ?? \"Unspecified status code\"} ${e.message}`);\n                    }\n                }\n                return this._serverInfo ?? {};\n            })();\n        }\n        return this._getServerInfoPromise.then((serverInfo) => {\n            if (this._serverInfo === undefined) {\n                this._getServerInfoPromise = undefined;\n            }\n            return serverInfo;\n        });\n    }\n    async _getSettings() {\n        if (!this.settings) {\n            this.settings = this._get(\"/settings\");\n        }\n        return await this.settings;\n    }\n    /**\n     * Flushes current queued traces.\n     */\n    async flush() {\n        const sizeLimitBytes = await this._getBatchSizeLimitBytes();\n        const sizeLimit = await this._getBatchSizeLimit();\n        await this.drainAutoBatchQueue({\n            batchSizeLimitBytes: sizeLimitBytes,\n            batchSizeLimit: sizeLimit,\n        });\n    }\n    _cloneCurrentOTELContext() {\n        const otel_trace = getOTELTrace();\n        const otel_context = getOTELContext();\n        if (this.langSmithToOTELTranslator !== undefined) {\n            const currentSpan = otel_trace.getActiveSpan();\n            if (currentSpan) {\n                return otel_trace.setSpan(otel_context.active(), currentSpan);\n            }\n        }\n        return undefined;\n    }\n    async createRun(run, options) {\n        if (!this._filterForSampling([run]).length) {\n            return;\n        }\n        const headers = {\n            ...this.headers,\n            \"Content-Type\": \"application/json\",\n        };\n        const session_name = run.project_name;\n        delete run.project_name;\n        const runCreate = await this.prepareRunCreateOrUpdateInputs({\n            session_name,\n            ...run,\n            start_time: run.start_time ?? Date.now(),\n        });\n        if (this.autoBatchTracing &&\n            runCreate.trace_id !== undefined &&\n            runCreate.dotted_order !== undefined) {\n            const otelContext = this._cloneCurrentOTELContext();\n            void this.processRunOperation({\n                action: \"create\",\n                item: runCreate,\n                otelContext,\n                apiKey: options?.apiKey,\n                apiUrl: options?.apiUrl,\n            }).catch(console.error);\n            return;\n        }\n        const mergedRunCreateParam = mergeRuntimeEnvIntoRun(runCreate, this.cachedLSEnvVarsForMetadata);\n        if (options?.apiKey !== undefined) {\n            headers[\"x-api-key\"] = options.apiKey;\n        }\n        if (options?.workspaceId !== undefined) {\n            headers[\"x-tenant-id\"] = options.workspaceId;\n        }\n        const body = serializePayloadForTracing(mergedRunCreateParam, `Creating run with id: ${mergedRunCreateParam.id}`);\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${options?.apiUrl ?? this.apiUrl}/runs`, {\n                method: \"POST\",\n                headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"create run\", true);\n            return res;\n        });\n    }\n    /**\n     * Batch ingest/upsert multiple runs in the Langsmith system.\n     * @param runs\n     */\n    async batchIngestRuns({ runCreates, runUpdates, }, options) {\n        if (runCreates === undefined && runUpdates === undefined) {\n            return;\n        }\n        let preparedCreateParams = await Promise.all(runCreates?.map((create) => this.prepareRunCreateOrUpdateInputs(create)) ?? []);\n        let preparedUpdateParams = await Promise.all(runUpdates?.map((update) => this.prepareRunCreateOrUpdateInputs(update)) ?? []);\n        if (preparedCreateParams.length > 0 && preparedUpdateParams.length > 0) {\n            const createById = preparedCreateParams.reduce((params, run) => {\n                if (!run.id) {\n                    return params;\n                }\n                params[run.id] = run;\n                return params;\n            }, {});\n            const standaloneUpdates = [];\n            for (const updateParam of preparedUpdateParams) {\n                if (updateParam.id !== undefined && createById[updateParam.id]) {\n                    createById[updateParam.id] = {\n                        ...createById[updateParam.id],\n                        ...updateParam,\n                    };\n                }\n                else {\n                    standaloneUpdates.push(updateParam);\n                }\n            }\n            preparedCreateParams = Object.values(createById);\n            preparedUpdateParams = standaloneUpdates;\n        }\n        const rawBatch = {\n            post: preparedCreateParams,\n            patch: preparedUpdateParams,\n        };\n        if (!rawBatch.post.length && !rawBatch.patch.length) {\n            return;\n        }\n        const batchChunks = {\n            post: [],\n            patch: [],\n        };\n        for (const k of [\"post\", \"patch\"]) {\n            const key = k;\n            const batchItems = rawBatch[key].reverse();\n            let batchItem = batchItems.pop();\n            while (batchItem !== undefined) {\n                // Type is wrong but this is a deprecated code path anyway\n                batchChunks[key].push(batchItem);\n                batchItem = batchItems.pop();\n            }\n        }\n        if (batchChunks.post.length > 0 || batchChunks.patch.length > 0) {\n            const runIds = batchChunks.post\n                .map((item) => item.id)\n                .concat(batchChunks.patch.map((item) => item.id))\n                .join(\",\");\n            await this._postBatchIngestRuns(serializePayloadForTracing(batchChunks, `Ingesting runs with ids: ${runIds}`), options);\n        }\n    }\n    async _postBatchIngestRuns(body, options) {\n        const headers = {\n            ...this.headers,\n            \"Content-Type\": \"application/json\",\n            Accept: \"application/json\",\n        };\n        if (options?.apiKey !== undefined) {\n            headers[\"x-api-key\"] = options.apiKey;\n        }\n        await this.batchIngestCaller.call(async () => {\n            const res = await this._fetch(`${options?.apiUrl ?? this.apiUrl}/runs/batch`, {\n                method: \"POST\",\n                headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"batch create run\", true);\n            return res;\n        });\n    }\n    /**\n     * Batch ingest/upsert multiple runs in the Langsmith system.\n     * @param runs\n     */\n    async multipartIngestRuns({ runCreates, runUpdates, }, options) {\n        if (runCreates === undefined && runUpdates === undefined) {\n            return;\n        }\n        // transform and convert to dicts\n        const allAttachments = {};\n        let preparedCreateParams = [];\n        for (const create of runCreates ?? []) {\n            const preparedCreate = await this.prepareRunCreateOrUpdateInputs(create);\n            if (preparedCreate.id !== undefined &&\n                preparedCreate.attachments !== undefined) {\n                allAttachments[preparedCreate.id] = preparedCreate.attachments;\n            }\n            delete preparedCreate.attachments;\n            preparedCreateParams.push(preparedCreate);\n        }\n        let preparedUpdateParams = [];\n        for (const update of runUpdates ?? []) {\n            preparedUpdateParams.push(await this.prepareRunCreateOrUpdateInputs(update));\n        }\n        // require trace_id and dotted_order\n        const invalidRunCreate = preparedCreateParams.find((runCreate) => {\n            return (runCreate.trace_id === undefined || runCreate.dotted_order === undefined);\n        });\n        if (invalidRunCreate !== undefined) {\n            throw new Error(`Multipart ingest requires \"trace_id\" and \"dotted_order\" to be set when creating a run`);\n        }\n        const invalidRunUpdate = preparedUpdateParams.find((runUpdate) => {\n            return (runUpdate.trace_id === undefined || runUpdate.dotted_order === undefined);\n        });\n        if (invalidRunUpdate !== undefined) {\n            throw new Error(`Multipart ingest requires \"trace_id\" and \"dotted_order\" to be set when updating a run`);\n        }\n        // combine post and patch dicts where possible\n        if (preparedCreateParams.length > 0 && preparedUpdateParams.length > 0) {\n            const createById = preparedCreateParams.reduce((params, run) => {\n                if (!run.id) {\n                    return params;\n                }\n                params[run.id] = run;\n                return params;\n            }, {});\n            const standaloneUpdates = [];\n            for (const updateParam of preparedUpdateParams) {\n                if (updateParam.id !== undefined && createById[updateParam.id]) {\n                    createById[updateParam.id] = {\n                        ...createById[updateParam.id],\n                        ...updateParam,\n                    };\n                }\n                else {\n                    standaloneUpdates.push(updateParam);\n                }\n            }\n            preparedCreateParams = Object.values(createById);\n            preparedUpdateParams = standaloneUpdates;\n        }\n        if (preparedCreateParams.length === 0 &&\n            preparedUpdateParams.length === 0) {\n            return;\n        }\n        // send the runs in multipart requests\n        const accumulatedContext = [];\n        const accumulatedParts = [];\n        for (const [method, payloads] of [\n            [\"post\", preparedCreateParams],\n            [\"patch\", preparedUpdateParams],\n        ]) {\n            for (const originalPayload of payloads) {\n                // collect fields to be sent as separate parts\n                const { inputs, outputs, events, extra, error, serialized, attachments, ...payload } = originalPayload;\n                const fields = { inputs, outputs, events, extra, error, serialized };\n                // encode the main run payload\n                const stringifiedPayload = serializePayloadForTracing(payload, `Serializing for multipart ingestion of run with id: ${payload.id}`);\n                accumulatedParts.push({\n                    name: `${method}.${payload.id}`,\n                    payload: new Blob([stringifiedPayload], {\n                        type: `application/json; length=${stringifiedPayload.length}`, // encoding=gzip\n                    }),\n                });\n                // encode the fields we collected\n                for (const [key, value] of Object.entries(fields)) {\n                    if (value === undefined) {\n                        continue;\n                    }\n                    const stringifiedValue = serializePayloadForTracing(value, `Serializing ${key} for multipart ingestion of run with id: ${payload.id}`);\n                    accumulatedParts.push({\n                        name: `${method}.${payload.id}.${key}`,\n                        payload: new Blob([stringifiedValue], {\n                            type: `application/json; length=${stringifiedValue.length}`,\n                        }),\n                    });\n                }\n                // encode the attachments\n                if (payload.id !== undefined) {\n                    const attachments = allAttachments[payload.id];\n                    if (attachments) {\n                        delete allAttachments[payload.id];\n                        for (const [name, attachment] of Object.entries(attachments)) {\n                            let contentType;\n                            let content;\n                            if (Array.isArray(attachment)) {\n                                [contentType, content] = attachment;\n                            }\n                            else {\n                                contentType = attachment.mimeType;\n                                content = attachment.data;\n                            }\n                            // Validate that the attachment name doesn't contain a '.'\n                            if (name.includes(\".\")) {\n                                console.warn(`Skipping attachment '${name}' for run ${payload.id}: Invalid attachment name. ` +\n                                    `Attachment names must not contain periods ('.'). Please rename the attachment and try again.`);\n                                continue;\n                            }\n                            accumulatedParts.push({\n                                name: `attachment.${payload.id}.${name}`,\n                                payload: new Blob([content], {\n                                    type: `${contentType}; length=${content.byteLength}`,\n                                }),\n                            });\n                        }\n                    }\n                }\n                // compute context\n                accumulatedContext.push(`trace=${payload.trace_id},id=${payload.id}`);\n            }\n        }\n        await this._sendMultipartRequest(accumulatedParts, accumulatedContext.join(\"; \"), options);\n    }\n    async _createNodeFetchBody(parts, boundary) {\n        // Create multipart form data manually using Blobs\n        const chunks = [];\n        for (const part of parts) {\n            // Add field boundary\n            chunks.push(new Blob([`--${boundary}\\r\\n`]));\n            chunks.push(new Blob([\n                `Content-Disposition: form-data; name=\"${part.name}\"\\r\\n`,\n                `Content-Type: ${part.payload.type}\\r\\n\\r\\n`,\n            ]));\n            chunks.push(part.payload);\n            chunks.push(new Blob([\"\\r\\n\"]));\n        }\n        // Add final boundary\n        chunks.push(new Blob([`--${boundary}--\\r\\n`]));\n        // Combine all chunks into a single Blob\n        const body = new Blob(chunks);\n        // Convert Blob to ArrayBuffer for compatibility\n        const arrayBuffer = await body.arrayBuffer();\n        return arrayBuffer;\n    }\n    async _createMultipartStream(parts, boundary) {\n        const encoder = new TextEncoder();\n        // Create a ReadableStream for streaming the multipart data\n        // Only do special handling if we're using node-fetch\n        const stream = new ReadableStream({\n            async start(controller) {\n                // Helper function to write a chunk to the stream\n                const writeChunk = async (chunk) => {\n                    if (typeof chunk === \"string\") {\n                        controller.enqueue(encoder.encode(chunk));\n                    }\n                    else {\n                        controller.enqueue(chunk);\n                    }\n                };\n                // Write each part to the stream\n                for (const part of parts) {\n                    // Write boundary and headers\n                    await writeChunk(`--${boundary}\\r\\n`);\n                    await writeChunk(`Content-Disposition: form-data; name=\"${part.name}\"\\r\\n`);\n                    await writeChunk(`Content-Type: ${part.payload.type}\\r\\n\\r\\n`);\n                    // Write the payload\n                    const payloadStream = part.payload.stream();\n                    const reader = payloadStream.getReader();\n                    try {\n                        let result;\n                        while (!(result = await reader.read()).done) {\n                            controller.enqueue(result.value);\n                        }\n                    }\n                    finally {\n                        reader.releaseLock();\n                    }\n                    await writeChunk(\"\\r\\n\");\n                }\n                // Write final boundary\n                await writeChunk(`--${boundary}--\\r\\n`);\n                controller.close();\n            },\n        });\n        return stream;\n    }\n    async _sendMultipartRequest(parts, context, options) {\n        // Create multipart form data boundary\n        const boundary = \"----LangSmithFormBoundary\" + Math.random().toString(36).slice(2);\n        const isNodeFetch = _globalFetchImplementationIsNodeFetch();\n        const buildBuffered = () => this._createNodeFetchBody(parts, boundary);\n        const buildStream = () => this._createMultipartStream(parts, boundary);\n        const sendWithRetry = async (bodyFactory) => {\n            return this.batchIngestCaller.call(async () => {\n                const body = await bodyFactory();\n                const headers = {\n                    ...this.headers,\n                    \"Content-Type\": `multipart/form-data; boundary=${boundary}`,\n                };\n                if (options?.apiKey !== undefined) {\n                    headers[\"x-api-key\"] = options.apiKey;\n                }\n                let transformedBody = body;\n                if (options?.useGzip &&\n                    typeof body === \"object\" &&\n                    \"pipeThrough\" in body) {\n                    transformedBody = body.pipeThrough(new CompressionStream(\"gzip\"));\n                    headers[\"Content-Encoding\"] = \"gzip\";\n                }\n                const response = await this._fetch(`${options?.apiUrl ?? this.apiUrl}/runs/multipart`, {\n                    method: \"POST\",\n                    headers,\n                    body: transformedBody,\n                    duplex: \"half\",\n                    signal: AbortSignal.timeout(this.timeout_ms),\n                    ...this.fetchOptions,\n                });\n                await raiseForStatus(response, `Failed to send multipart request`, true);\n                return response;\n            });\n        };\n        try {\n            let res;\n            let streamedAttempt = false;\n            // attempt stream only if not disabled and not using node-fetch or Bun\n            if (!isNodeFetch &&\n                !this.multipartStreamingDisabled &&\n                getEnv() !== \"bun\") {\n                streamedAttempt = true;\n                res = await sendWithRetry(buildStream);\n            }\n            else {\n                res = await sendWithRetry(buildBuffered);\n            }\n            // if stream fails, fallback to buffered body\n            if ((!this.multipartStreamingDisabled || streamedAttempt) &&\n                res.status === 422 &&\n                (options?.apiUrl ?? this.apiUrl) !== DEFAULT_API_URL) {\n                console.warn(`Streaming multipart upload to ${options?.apiUrl ?? this.apiUrl}/runs/multipart failed. ` +\n                    `This usually means the host does not support chunked uploads. ` +\n                    `Retrying with a buffered upload for operation \"${context}\".`);\n                // Disable streaming for future requests\n                this.multipartStreamingDisabled = true;\n                // retry with fully-buffered body\n                res = await sendWithRetry(buildBuffered);\n            }\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        }\n        catch (e) {\n            console.warn(`${e.message.trim()}\\n\\nContext: ${context}`);\n        }\n    }\n    async updateRun(runId, run, options) {\n        assertUuid(runId);\n        if (run.inputs) {\n            run.inputs = await this.processInputs(run.inputs);\n        }\n        if (run.outputs) {\n            run.outputs = await this.processOutputs(run.outputs);\n        }\n        // TODO: Untangle types\n        const data = { ...run, id: runId };\n        if (!this._filterForSampling([data], true).length) {\n            return;\n        }\n        if (this.autoBatchTracing &&\n            data.trace_id !== undefined &&\n            data.dotted_order !== undefined) {\n            const otelContext = this._cloneCurrentOTELContext();\n            if (run.end_time !== undefined &&\n                data.parent_run_id === undefined &&\n                this.blockOnRootRunFinalization &&\n                !this.manualFlushMode) {\n                // Trigger batches as soon as a root trace ends and wait to ensure trace finishes\n                // in serverless environments.\n                await this.processRunOperation({\n                    action: \"update\",\n                    item: data,\n                    otelContext,\n                    apiKey: options?.apiKey,\n                    apiUrl: options?.apiUrl,\n                }).catch(console.error);\n                return;\n            }\n            else {\n                void this.processRunOperation({\n                    action: \"update\",\n                    item: data,\n                    otelContext,\n                    apiKey: options?.apiKey,\n                    apiUrl: options?.apiUrl,\n                }).catch(console.error);\n            }\n            return;\n        }\n        const headers = {\n            ...this.headers,\n            \"Content-Type\": \"application/json\",\n        };\n        if (options?.apiKey !== undefined) {\n            headers[\"x-api-key\"] = options.apiKey;\n        }\n        if (options?.workspaceId !== undefined) {\n            headers[\"x-tenant-id\"] = options.workspaceId;\n        }\n        const body = serializePayloadForTracing(run, `Serializing payload to update run with id: ${runId}`);\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${options?.apiUrl ?? this.apiUrl}/runs/${runId}`, {\n                method: \"PATCH\",\n                headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update run\", true);\n            return res;\n        });\n    }\n    async readRun(runId, { loadChildRuns } = { loadChildRuns: false }) {\n        assertUuid(runId);\n        let run = await this._get(`/runs/${runId}`);\n        if (loadChildRuns) {\n            run = await this._loadChildRuns(run);\n        }\n        return run;\n    }\n    async getRunUrl({ runId, run, projectOpts, }) {\n        if (run !== undefined) {\n            let sessionId;\n            if (run.session_id) {\n                sessionId = run.session_id;\n            }\n            else if (projectOpts?.projectName) {\n                sessionId = (await this.readProject({ projectName: projectOpts?.projectName })).id;\n            }\n            else if (projectOpts?.projectId) {\n                sessionId = projectOpts?.projectId;\n            }\n            else {\n                const project = await this.readProject({\n                    projectName: getLangSmithEnvironmentVariable(\"PROJECT\") || \"default\",\n                });\n                sessionId = project.id;\n            }\n            const tenantId = await this._getTenantId();\n            return `${this.getHostUrl()}/o/${tenantId}/projects/p/${sessionId}/r/${run.id}?poll=true`;\n        }\n        else if (runId !== undefined) {\n            const run_ = await this.readRun(runId);\n            if (!run_.app_path) {\n                throw new Error(`Run ${runId} has no app_path`);\n            }\n            const baseUrl = this.getHostUrl();\n            return `${baseUrl}${run_.app_path}`;\n        }\n        else {\n            throw new Error(\"Must provide either runId or run\");\n        }\n    }\n    async _loadChildRuns(run) {\n        const childRuns = await toArray(this.listRuns({\n            isRoot: false,\n            projectId: run.session_id,\n            traceId: run.trace_id,\n        }));\n        const treemap = {};\n        const runs = {};\n        // TODO: make dotted order required when the migration finishes\n        childRuns.sort((a, b) => (a?.dotted_order ?? \"\").localeCompare(b?.dotted_order ?? \"\"));\n        for (const childRun of childRuns) {\n            if (childRun.parent_run_id === null ||\n                childRun.parent_run_id === undefined) {\n                throw new Error(`Child run ${childRun.id} has no parent`);\n            }\n            if (childRun.dotted_order?.startsWith(run.dotted_order ?? \"\") &&\n                childRun.id !== run.id) {\n                if (!(childRun.parent_run_id in treemap)) {\n                    treemap[childRun.parent_run_id] = [];\n                }\n                treemap[childRun.parent_run_id].push(childRun);\n                runs[childRun.id] = childRun;\n            }\n        }\n        run.child_runs = treemap[run.id] || [];\n        for (const runId in treemap) {\n            if (runId !== run.id) {\n                runs[runId].child_runs = treemap[runId];\n            }\n        }\n        return run;\n    }\n    /**\n     * List runs from the LangSmith server.\n     * @param projectId - The ID of the project to filter by.\n     * @param projectName - The name of the project to filter by.\n     * @param parentRunId - The ID of the parent run to filter by.\n     * @param traceId - The ID of the trace to filter by.\n     * @param referenceExampleId - The ID of the reference example to filter by.\n     * @param startTime - The start time to filter by.\n     * @param isRoot - Indicates whether to only return root runs.\n     * @param runType - The run type to filter by.\n     * @param error - Indicates whether to filter by error runs.\n     * @param id - The ID of the run to filter by.\n     * @param query - The query string to filter by.\n     * @param filter - The filter string to apply to the run spans.\n     * @param traceFilter - The filter string to apply on the root run of the trace.\n     * @param treeFilter - The filter string to apply on other runs in the trace.\n     * @param limit - The maximum number of runs to retrieve.\n     * @returns {AsyncIterable<Run>} - The runs.\n     *\n     * @example\n     * // List all runs in a project\n     * const projectRuns = client.listRuns({ projectName: \"<your_project>\" });\n     *\n     * @example\n     * // List LLM and Chat runs in the last 24 hours\n     * const todaysLLMRuns = client.listRuns({\n     *   projectName: \"<your_project>\",\n     *   start_time: new Date(Date.now() - 24 * 60 * 60 * 1000),\n     *   run_type: \"llm\",\n     * });\n     *\n     * @example\n     * // List traces in a project\n     * const rootRuns = client.listRuns({\n     *   projectName: \"<your_project>\",\n     *   execution_order: 1,\n     * });\n     *\n     * @example\n     * // List runs without errors\n     * const correctRuns = client.listRuns({\n     *   projectName: \"<your_project>\",\n     *   error: false,\n     * });\n     *\n     * @example\n     * // List runs by run ID\n     * const runIds = [\n     *   \"a36092d2-4ad5-4fb4-9c0d-0dba9a2ed836\",\n     *   \"9398e6be-964f-4aa4-8ae9-ad78cd4b7074\",\n     * ];\n     * const selectedRuns = client.listRuns({ run_ids: runIds });\n     *\n     * @example\n     * // List all \"chain\" type runs that took more than 10 seconds and had `total_tokens` greater than 5000\n     * const chainRuns = client.listRuns({\n     *   projectName: \"<your_project>\",\n     *   filter: 'and(eq(run_type, \"chain\"), gt(latency, 10), gt(total_tokens, 5000))',\n     * });\n     *\n     * @example\n     * // List all runs called \"extractor\" whose root of the trace was assigned feedback \"user_score\" score of 1\n     * const goodExtractorRuns = client.listRuns({\n     *   projectName: \"<your_project>\",\n     *   filter: 'eq(name, \"extractor\")',\n     *   traceFilter: 'and(eq(feedback_key, \"user_score\"), eq(feedback_score, 1))',\n     * });\n     *\n     * @example\n     * // List all runs that started after a specific timestamp and either have \"error\" not equal to null or a \"Correctness\" feedback score equal to 0\n     * const complexRuns = client.listRuns({\n     *   projectName: \"<your_project>\",\n     *   filter: 'and(gt(start_time, \"2023-07-15T12:34:56Z\"), or(neq(error, null), and(eq(feedback_key, \"Correctness\"), eq(feedback_score, 0.0))))',\n     * });\n     *\n     * @example\n     * // List all runs where `tags` include \"experimental\" or \"beta\" and `latency` is greater than 2 seconds\n     * const taggedRuns = client.listRuns({\n     *   projectName: \"<your_project>\",\n     *   filter: 'and(or(has(tags, \"experimental\"), has(tags, \"beta\")), gt(latency, 2))',\n     * });\n     */\n    async *listRuns(props) {\n        const { projectId, projectName, parentRunId, traceId, referenceExampleId, startTime, executionOrder, isRoot, runType, error, id, query, filter, traceFilter, treeFilter, limit, select, order, } = props;\n        let projectIds = [];\n        if (projectId) {\n            projectIds = Array.isArray(projectId) ? projectId : [projectId];\n        }\n        if (projectName) {\n            const projectNames = Array.isArray(projectName)\n                ? projectName\n                : [projectName];\n            const projectIds_ = await Promise.all(projectNames.map((name) => this.readProject({ projectName: name }).then((project) => project.id)));\n            projectIds.push(...projectIds_);\n        }\n        const default_select = [\n            \"app_path\",\n            \"completion_cost\",\n            \"completion_tokens\",\n            \"dotted_order\",\n            \"end_time\",\n            \"error\",\n            \"events\",\n            \"extra\",\n            \"feedback_stats\",\n            \"first_token_time\",\n            \"id\",\n            \"inputs\",\n            \"name\",\n            \"outputs\",\n            \"parent_run_id\",\n            \"parent_run_ids\",\n            \"prompt_cost\",\n            \"prompt_tokens\",\n            \"reference_example_id\",\n            \"run_type\",\n            \"session_id\",\n            \"start_time\",\n            \"status\",\n            \"tags\",\n            \"total_cost\",\n            \"total_tokens\",\n            \"trace_id\",\n        ];\n        const body = {\n            session: projectIds.length ? projectIds : null,\n            run_type: runType,\n            reference_example: referenceExampleId,\n            query,\n            filter,\n            trace_filter: traceFilter,\n            tree_filter: treeFilter,\n            execution_order: executionOrder,\n            parent_run: parentRunId,\n            start_time: startTime ? startTime.toISOString() : null,\n            error,\n            id,\n            limit,\n            trace: traceId,\n            select: select ? select : default_select,\n            is_root: isRoot,\n            order,\n        };\n        if (body.select.includes(\"child_run_ids\")) {\n            warnOnce(\"Deprecated: 'child_run_ids' in the listRuns select parameter is deprecated and will be removed in a future version.\");\n        }\n        let runsYielded = 0;\n        for await (const runs of this._getCursorPaginatedList(\"/runs/query\", body)) {\n            if (limit) {\n                if (runsYielded >= limit) {\n                    break;\n                }\n                if (runs.length + runsYielded > limit) {\n                    const newRuns = runs.slice(0, limit - runsYielded);\n                    yield* newRuns;\n                    break;\n                }\n                runsYielded += runs.length;\n                yield* runs;\n            }\n            else {\n                yield* runs;\n            }\n        }\n    }\n    async *listGroupRuns(props) {\n        const { projectId, projectName, groupBy, filter, startTime, endTime, limit, offset, } = props;\n        const sessionId = projectId || (await this.readProject({ projectName })).id;\n        const baseBody = {\n            session_id: sessionId,\n            group_by: groupBy,\n            filter,\n            start_time: startTime ? startTime.toISOString() : null,\n            end_time: endTime ? endTime.toISOString() : null,\n            limit: Number(limit) || 100,\n        };\n        let currentOffset = Number(offset) || 0;\n        const path = \"/runs/group\";\n        const url = `${this.apiUrl}${path}`;\n        while (true) {\n            const currentBody = {\n                ...baseBody,\n                offset: currentOffset,\n            };\n            // Remove undefined values from the payload\n            const filteredPayload = Object.fromEntries(Object.entries(currentBody).filter(([_, value]) => value !== undefined));\n            const body = JSON.stringify(filteredPayload);\n            const response = await this.caller.call(async () => {\n                const res = await this._fetch(url, {\n                    method: \"POST\",\n                    headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                    signal: AbortSignal.timeout(this.timeout_ms),\n                    ...this.fetchOptions,\n                    body,\n                });\n                await raiseForStatus(res, `Failed to fetch ${path}`);\n                return res;\n            });\n            const items = await response.json();\n            const { groups, total } = items;\n            if (groups.length === 0) {\n                break;\n            }\n            for (const thread of groups) {\n                yield thread;\n            }\n            currentOffset += groups.length;\n            if (currentOffset >= total) {\n                break;\n            }\n        }\n    }\n    async getRunStats({ id, trace, parentRun, runType, projectNames, projectIds, referenceExampleIds, startTime, endTime, error, query, filter, traceFilter, treeFilter, isRoot, dataSourceType, }) {\n        let projectIds_ = projectIds || [];\n        if (projectNames) {\n            projectIds_ = [\n                ...(projectIds || []),\n                ...(await Promise.all(projectNames.map((name) => this.readProject({ projectName: name }).then((project) => project.id)))),\n            ];\n        }\n        const payload = {\n            id,\n            trace,\n            parent_run: parentRun,\n            run_type: runType,\n            session: projectIds_,\n            reference_example: referenceExampleIds,\n            start_time: startTime,\n            end_time: endTime,\n            error,\n            query,\n            filter,\n            trace_filter: traceFilter,\n            tree_filter: treeFilter,\n            is_root: isRoot,\n            data_source_type: dataSourceType,\n        };\n        // Remove undefined values from the payload\n        const filteredPayload = Object.fromEntries(Object.entries(payload).filter(([_, value]) => value !== undefined));\n        const body = JSON.stringify(filteredPayload);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/runs/stats`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"get run stats\");\n            return res;\n        });\n        const result = await response.json();\n        return result;\n    }\n    async shareRun(runId, { shareId } = {}) {\n        const data = {\n            run_id: runId,\n            share_token: shareId || uuid.v4(),\n        };\n        assertUuid(runId);\n        const body = JSON.stringify(data);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/runs/${runId}/share`, {\n                method: \"PUT\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"share run\");\n            return res;\n        });\n        const result = await response.json();\n        if (result === null || !(\"share_token\" in result)) {\n            throw new Error(\"Invalid response from server\");\n        }\n        return `${this.getHostUrl()}/public/${result[\"share_token\"]}/r`;\n    }\n    async unshareRun(runId) {\n        assertUuid(runId);\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/runs/${runId}/share`, {\n                method: \"DELETE\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"unshare run\", true);\n            return res;\n        });\n    }\n    async readRunSharedLink(runId) {\n        assertUuid(runId);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/runs/${runId}/share`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"read run shared link\");\n            return res;\n        });\n        const result = await response.json();\n        if (result === null || !(\"share_token\" in result)) {\n            return undefined;\n        }\n        return `${this.getHostUrl()}/public/${result[\"share_token\"]}/r`;\n    }\n    async listSharedRuns(shareToken, { runIds, } = {}) {\n        const queryParams = new URLSearchParams({\n            share_token: shareToken,\n        });\n        if (runIds !== undefined) {\n            for (const runId of runIds) {\n                queryParams.append(\"id\", runId);\n            }\n        }\n        assertUuid(shareToken);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/public/${shareToken}/runs${queryParams}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"list shared runs\");\n            return res;\n        });\n        const runs = await response.json();\n        return runs;\n    }\n    async readDatasetSharedSchema(datasetId, datasetName) {\n        if (!datasetId && !datasetName) {\n            throw new Error(\"Either datasetId or datasetName must be given\");\n        }\n        if (!datasetId) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId = dataset.id;\n        }\n        assertUuid(datasetId);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${datasetId}/share`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"read dataset shared schema\");\n            return res;\n        });\n        const shareSchema = await response.json();\n        shareSchema.url = `${this.getHostUrl()}/public/${shareSchema.share_token}/d`;\n        return shareSchema;\n    }\n    async shareDataset(datasetId, datasetName) {\n        if (!datasetId && !datasetName) {\n            throw new Error(\"Either datasetId or datasetName must be given\");\n        }\n        if (!datasetId) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId = dataset.id;\n        }\n        const data = {\n            dataset_id: datasetId,\n        };\n        assertUuid(datasetId);\n        const body = JSON.stringify(data);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${datasetId}/share`, {\n                method: \"PUT\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"share dataset\");\n            return res;\n        });\n        const shareSchema = await response.json();\n        shareSchema.url = `${this.getHostUrl()}/public/${shareSchema.share_token}/d`;\n        return shareSchema;\n    }\n    async unshareDataset(datasetId) {\n        assertUuid(datasetId);\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${datasetId}/share`, {\n                method: \"DELETE\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"unshare dataset\", true);\n            return res;\n        });\n    }\n    async readSharedDataset(shareToken) {\n        assertUuid(shareToken);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/public/${shareToken}/datasets`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"read shared dataset\");\n            return res;\n        });\n        const dataset = await response.json();\n        return dataset;\n    }\n    /**\n     * Get shared examples.\n     *\n     * @param {string} shareToken The share token to get examples for. A share token is the UUID (or LangSmith URL, including UUID) generated when explicitly marking an example as public.\n     * @param {Object} [options] Additional options for listing the examples.\n     * @param {string[] | undefined} [options.exampleIds] A list of example IDs to filter by.\n     * @returns {Promise<Example[]>} The shared examples.\n     */\n    async listSharedExamples(shareToken, options) {\n        const params = {};\n        if (options?.exampleIds) {\n            params.id = options.exampleIds;\n        }\n        const urlParams = new URLSearchParams();\n        Object.entries(params).forEach(([key, value]) => {\n            if (Array.isArray(value)) {\n                value.forEach((v) => urlParams.append(key, v));\n            }\n            else {\n                urlParams.append(key, value);\n            }\n        });\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/public/${shareToken}/examples?${urlParams.toString()}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"list shared examples\");\n            return res;\n        });\n        const result = await response.json();\n        if (!response.ok) {\n            if (\"detail\" in result) {\n                throw new Error(`Failed to list shared examples.\\nStatus: ${response.status}\\nMessage: ${Array.isArray(result.detail)\n                    ? result.detail.join(\"\\n\")\n                    : \"Unspecified error\"}`);\n            }\n            throw new Error(`Failed to list shared examples: ${response.status} ${response.statusText}`);\n        }\n        return result.map((example) => ({\n            ...example,\n            _hostUrl: this.getHostUrl(),\n        }));\n    }\n    async createProject({ projectName, description = null, metadata = null, upsert = false, projectExtra = null, referenceDatasetId = null, }) {\n        const upsert_ = upsert ? `?upsert=true` : \"\";\n        const endpoint = `${this.apiUrl}/sessions${upsert_}`;\n        const extra = projectExtra || {};\n        if (metadata) {\n            extra[\"metadata\"] = metadata;\n        }\n        const body = {\n            name: projectName,\n            extra,\n            description,\n        };\n        if (referenceDatasetId !== null) {\n            body[\"reference_dataset_id\"] = referenceDatasetId;\n        }\n        const serializedBody = JSON.stringify(body);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(endpoint, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: serializedBody,\n            });\n            await raiseForStatus(res, \"create project\");\n            return res;\n        });\n        const result = await response.json();\n        return result;\n    }\n    async updateProject(projectId, { name = null, description = null, metadata = null, projectExtra = null, endTime = null, }) {\n        const endpoint = `${this.apiUrl}/sessions/${projectId}`;\n        let extra = projectExtra;\n        if (metadata) {\n            extra = { ...(extra || {}), metadata };\n        }\n        const body = JSON.stringify({\n            name,\n            extra,\n            description,\n            end_time: endTime ? new Date(endTime).toISOString() : null,\n        });\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(endpoint, {\n                method: \"PATCH\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update project\");\n            return res;\n        });\n        const result = await response.json();\n        return result;\n    }\n    async hasProject({ projectId, projectName, }) {\n        // TODO: Add a head request\n        let path = \"/sessions\";\n        const params = new URLSearchParams();\n        if (projectId !== undefined && projectName !== undefined) {\n            throw new Error(\"Must provide either projectName or projectId, not both\");\n        }\n        else if (projectId !== undefined) {\n            assertUuid(projectId);\n            path += `/${projectId}`;\n        }\n        else if (projectName !== undefined) {\n            params.append(\"name\", projectName);\n        }\n        else {\n            throw new Error(\"Must provide projectName or projectId\");\n        }\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}${path}?${params}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"has project\");\n            return res;\n        });\n        // consume the response body to release the connection\n        // https://undici.nodejs.org/#/?id=garbage-collection\n        try {\n            const result = await response.json();\n            if (!response.ok) {\n                return false;\n            }\n            // If it's OK and we're querying by name, need to check the list is not empty\n            if (Array.isArray(result)) {\n                return result.length > 0;\n            }\n            // projectId querying\n            return true;\n        }\n        catch (e) {\n            return false;\n        }\n    }\n    async readProject({ projectId, projectName, includeStats, }) {\n        let path = \"/sessions\";\n        const params = new URLSearchParams();\n        if (projectId !== undefined && projectName !== undefined) {\n            throw new Error(\"Must provide either projectName or projectId, not both\");\n        }\n        else if (projectId !== undefined) {\n            assertUuid(projectId);\n            path += `/${projectId}`;\n        }\n        else if (projectName !== undefined) {\n            params.append(\"name\", projectName);\n        }\n        else {\n            throw new Error(\"Must provide projectName or projectId\");\n        }\n        if (includeStats !== undefined) {\n            params.append(\"include_stats\", includeStats.toString());\n        }\n        const response = await this._get(path, params);\n        let result;\n        if (Array.isArray(response)) {\n            if (response.length === 0) {\n                throw new Error(`Project[id=${projectId}, name=${projectName}] not found`);\n            }\n            result = response[0];\n        }\n        else {\n            result = response;\n        }\n        return result;\n    }\n    async getProjectUrl({ projectId, projectName, }) {\n        if (projectId === undefined && projectName === undefined) {\n            throw new Error(\"Must provide either projectName or projectId\");\n        }\n        const project = await this.readProject({ projectId, projectName });\n        const tenantId = await this._getTenantId();\n        return `${this.getHostUrl()}/o/${tenantId}/projects/p/${project.id}`;\n    }\n    async getDatasetUrl({ datasetId, datasetName, }) {\n        if (datasetId === undefined && datasetName === undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        const dataset = await this.readDataset({ datasetId, datasetName });\n        const tenantId = await this._getTenantId();\n        return `${this.getHostUrl()}/o/${tenantId}/datasets/${dataset.id}`;\n    }\n    async _getTenantId() {\n        if (this._tenantId !== null) {\n            return this._tenantId;\n        }\n        const queryParams = new URLSearchParams({ limit: \"1\" });\n        for await (const projects of this._getPaginated(\"/sessions\", queryParams)) {\n            this._tenantId = projects[0].tenant_id;\n            return projects[0].tenant_id;\n        }\n        throw new Error(\"No projects found to resolve tenant.\");\n    }\n    async *listProjects({ projectIds, name, nameContains, referenceDatasetId, referenceDatasetName, includeStats, datasetVersion, referenceFree, metadata, } = {}) {\n        const params = new URLSearchParams();\n        if (projectIds !== undefined) {\n            for (const projectId of projectIds) {\n                params.append(\"id\", projectId);\n            }\n        }\n        if (name !== undefined) {\n            params.append(\"name\", name);\n        }\n        if (nameContains !== undefined) {\n            params.append(\"name_contains\", nameContains);\n        }\n        if (referenceDatasetId !== undefined) {\n            params.append(\"reference_dataset\", referenceDatasetId);\n        }\n        else if (referenceDatasetName !== undefined) {\n            const dataset = await this.readDataset({\n                datasetName: referenceDatasetName,\n            });\n            params.append(\"reference_dataset\", dataset.id);\n        }\n        if (includeStats !== undefined) {\n            params.append(\"include_stats\", includeStats.toString());\n        }\n        if (datasetVersion !== undefined) {\n            params.append(\"dataset_version\", datasetVersion);\n        }\n        if (referenceFree !== undefined) {\n            params.append(\"reference_free\", referenceFree.toString());\n        }\n        if (metadata !== undefined) {\n            params.append(\"metadata\", JSON.stringify(metadata));\n        }\n        for await (const projects of this._getPaginated(\"/sessions\", params)) {\n            yield* projects;\n        }\n    }\n    async deleteProject({ projectId, projectName, }) {\n        let projectId_;\n        if (projectId === undefined && projectName === undefined) {\n            throw new Error(\"Must provide projectName or projectId\");\n        }\n        else if (projectId !== undefined && projectName !== undefined) {\n            throw new Error(\"Must provide either projectName or projectId, not both\");\n        }\n        else if (projectId === undefined) {\n            projectId_ = (await this.readProject({ projectName })).id;\n        }\n        else {\n            projectId_ = projectId;\n        }\n        assertUuid(projectId_);\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/sessions/${projectId_}`, {\n                method: \"DELETE\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, `delete session ${projectId_} (${projectName})`, true);\n            return res;\n        });\n    }\n    async uploadCsv({ csvFile, fileName, inputKeys, outputKeys, description, dataType, name, }) {\n        const url = `${this.apiUrl}/datasets/upload`;\n        const formData = new FormData();\n        formData.append(\"file\", csvFile, fileName);\n        inputKeys.forEach((key) => {\n            formData.append(\"input_keys\", key);\n        });\n        outputKeys.forEach((key) => {\n            formData.append(\"output_keys\", key);\n        });\n        if (description) {\n            formData.append(\"description\", description);\n        }\n        if (dataType) {\n            formData.append(\"data_type\", dataType);\n        }\n        if (name) {\n            formData.append(\"name\", name);\n        }\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(url, {\n                method: \"POST\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: formData,\n            });\n            await raiseForStatus(res, \"upload CSV\");\n            return res;\n        });\n        const result = await response.json();\n        return result;\n    }\n    async createDataset(name, { description, dataType, inputsSchema, outputsSchema, metadata, } = {}) {\n        const body = {\n            name,\n            description,\n            extra: metadata ? { metadata } : undefined,\n        };\n        if (dataType) {\n            body.data_type = dataType;\n        }\n        if (inputsSchema) {\n            body.inputs_schema_definition = inputsSchema;\n        }\n        if (outputsSchema) {\n            body.outputs_schema_definition = outputsSchema;\n        }\n        const serializedBody = JSON.stringify(body);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: serializedBody,\n            });\n            await raiseForStatus(res, \"create dataset\");\n            return res;\n        });\n        const result = await response.json();\n        return result;\n    }\n    async readDataset({ datasetId, datasetName, }) {\n        let path = \"/datasets\";\n        // limit to 1 result\n        const params = new URLSearchParams({ limit: \"1\" });\n        if (datasetId && datasetName) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetId) {\n            assertUuid(datasetId);\n            path += `/${datasetId}`;\n        }\n        else if (datasetName) {\n            params.append(\"name\", datasetName);\n        }\n        else {\n            throw new Error(\"Must provide datasetName or datasetId\");\n        }\n        const response = await this._get(path, params);\n        let result;\n        if (Array.isArray(response)) {\n            if (response.length === 0) {\n                throw new Error(`Dataset[id=${datasetId}, name=${datasetName}] not found`);\n            }\n            result = response[0];\n        }\n        else {\n            result = response;\n        }\n        return result;\n    }\n    async hasDataset({ datasetId, datasetName, }) {\n        try {\n            await this.readDataset({ datasetId, datasetName });\n            return true;\n        }\n        catch (e) {\n            if (\n            // eslint-disable-next-line no-instanceof/no-instanceof\n            e instanceof Error &&\n                e.message.toLocaleLowerCase().includes(\"not found\")) {\n                return false;\n            }\n            throw e;\n        }\n    }\n    async diffDatasetVersions({ datasetId, datasetName, fromVersion, toVersion, }) {\n        let datasetId_ = datasetId;\n        if (datasetId_ === undefined && datasetName === undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        else if (datasetId_ !== undefined && datasetName !== undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetId_ === undefined) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId_ = dataset.id;\n        }\n        const urlParams = new URLSearchParams({\n            from_version: typeof fromVersion === \"string\"\n                ? fromVersion\n                : fromVersion.toISOString(),\n            to_version: typeof toVersion === \"string\" ? toVersion : toVersion.toISOString(),\n        });\n        const response = await this._get(`/datasets/${datasetId_}/versions/diff`, urlParams);\n        return response;\n    }\n    async readDatasetOpenaiFinetuning({ datasetId, datasetName, }) {\n        const path = \"/datasets\";\n        if (datasetId !== undefined) {\n            // do nothing\n        }\n        else if (datasetName !== undefined) {\n            datasetId = (await this.readDataset({ datasetName })).id;\n        }\n        else {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        const response = await this._getResponse(`${path}/${datasetId}/openai_ft`);\n        const datasetText = await response.text();\n        const dataset = datasetText\n            .trim()\n            .split(\"\\n\")\n            .map((line) => JSON.parse(line));\n        return dataset;\n    }\n    async *listDatasets({ limit = 100, offset = 0, datasetIds, datasetName, datasetNameContains, metadata, } = {}) {\n        const path = \"/datasets\";\n        const params = new URLSearchParams({\n            limit: limit.toString(),\n            offset: offset.toString(),\n        });\n        if (datasetIds !== undefined) {\n            for (const id_ of datasetIds) {\n                params.append(\"id\", id_);\n            }\n        }\n        if (datasetName !== undefined) {\n            params.append(\"name\", datasetName);\n        }\n        if (datasetNameContains !== undefined) {\n            params.append(\"name_contains\", datasetNameContains);\n        }\n        if (metadata !== undefined) {\n            params.append(\"metadata\", JSON.stringify(metadata));\n        }\n        for await (const datasets of this._getPaginated(path, params)) {\n            yield* datasets;\n        }\n    }\n    /**\n     * Update a dataset\n     * @param props The dataset details to update\n     * @returns The updated dataset\n     */\n    async updateDataset(props) {\n        const { datasetId, datasetName, ...update } = props;\n        if (!datasetId && !datasetName) {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        const _datasetId = datasetId ?? (await this.readDataset({ datasetName })).id;\n        assertUuid(_datasetId);\n        const body = JSON.stringify(update);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${_datasetId}`, {\n                method: \"PATCH\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update dataset\");\n            return res;\n        });\n        return (await response.json());\n    }\n    /**\n     * Updates a tag on a dataset.\n     *\n     * If the tag is already assigned to a different version of this dataset,\n     * the tag will be moved to the new version. The as_of parameter is used to\n     * determine which version of the dataset to apply the new tags to.\n     *\n     * It must be an exact version of the dataset to succeed. You can\n     * use the \"readDatasetVersion\" method to find the exact version\n     * to apply the tags to.\n     * @param params.datasetId The ID of the dataset to update. Must be provided if \"datasetName\" is not provided.\n     * @param params.datasetName The name of the dataset to update. Must be provided if \"datasetId\" is not provided.\n     * @param params.asOf The timestamp of the dataset to apply the new tags to.\n     * @param params.tag The new tag to apply to the dataset.\n     */\n    async updateDatasetTag(props) {\n        const { datasetId, datasetName, asOf, tag } = props;\n        if (!datasetId && !datasetName) {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        const _datasetId = datasetId ?? (await this.readDataset({ datasetName })).id;\n        assertUuid(_datasetId);\n        const body = JSON.stringify({\n            as_of: typeof asOf === \"string\" ? asOf : asOf.toISOString(),\n            tag,\n        });\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${_datasetId}/tags`, {\n                method: \"PUT\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update dataset tags\", true);\n            return res;\n        });\n    }\n    async deleteDataset({ datasetId, datasetName, }) {\n        let path = \"/datasets\";\n        let datasetId_ = datasetId;\n        if (datasetId !== undefined && datasetName !== undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetName !== undefined) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId_ = dataset.id;\n        }\n        if (datasetId_ !== undefined) {\n            assertUuid(datasetId_);\n            path += `/${datasetId_}`;\n        }\n        else {\n            throw new Error(\"Must provide datasetName or datasetId\");\n        }\n        await this.caller.call(async () => {\n            const res = await this._fetch(this.apiUrl + path, {\n                method: \"DELETE\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, `delete ${path}`, true);\n            return res;\n        });\n    }\n    async indexDataset({ datasetId, datasetName, tag, }) {\n        let datasetId_ = datasetId;\n        if (!datasetId_ && !datasetName) {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        else if (datasetId_ && datasetName) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (!datasetId_) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId_ = dataset.id;\n        }\n        assertUuid(datasetId_);\n        const data = {\n            tag: tag,\n        };\n        const body = JSON.stringify(data);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${datasetId_}/index`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"index dataset\");\n            return res;\n        });\n        await response.json();\n    }\n    /**\n     * Lets you run a similarity search query on a dataset.\n     *\n     * Requires the dataset to be indexed. Please see the `indexDataset` method to set up indexing.\n     *\n     * @param inputs      The input on which to run the similarity search. Must have the\n     *                    same schema as the dataset.\n     *\n     * @param datasetId   The dataset to search for similar examples.\n     *\n     * @param limit       The maximum number of examples to return. Will return the top `limit` most\n     *                    similar examples in order of most similar to least similar. If no similar\n     *                    examples are found, random examples will be returned.\n     *\n     * @param filter      A filter string to apply to the search. Only examples will be returned that\n     *                    match the filter string. Some examples of filters\n     *\n     *                    - eq(metadata.mykey, \"value\")\n     *                    - and(neq(metadata.my.nested.key, \"value\"), neq(metadata.mykey, \"value\"))\n     *                    - or(eq(metadata.mykey, \"value\"), eq(metadata.mykey, \"othervalue\"))\n     *\n     * @returns           A list of similar examples.\n     *\n     *\n     * @example\n     * dataset_id = \"123e4567-e89b-12d3-a456-426614174000\"\n     * inputs = {\"text\": \"How many people live in Berlin?\"}\n     * limit = 5\n     * examples = await client.similarExamples(inputs, dataset_id, limit)\n     */\n    async similarExamples(inputs, datasetId, limit, { filter, } = {}) {\n        const data = {\n            limit: limit,\n            inputs: inputs,\n        };\n        if (filter !== undefined) {\n            data[\"filter\"] = filter;\n        }\n        assertUuid(datasetId);\n        const body = JSON.stringify(data);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${datasetId}/search`, {\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                method: \"POST\",\n                body,\n            });\n            await raiseForStatus(res, \"fetch similar examples\");\n            return res;\n        });\n        const result = await response.json();\n        return result[\"examples\"];\n    }\n    async createExample(inputsOrUpdate, outputs, options) {\n        if (isExampleCreate(inputsOrUpdate)) {\n            if (outputs !== undefined || options !== undefined) {\n                throw new Error(\"Cannot provide outputs or options when using ExampleCreate object\");\n            }\n        }\n        let datasetId_ = outputs ? options?.datasetId : inputsOrUpdate.dataset_id;\n        const datasetName_ = outputs\n            ? options?.datasetName\n            : inputsOrUpdate.dataset_name;\n        if (datasetId_ === undefined && datasetName_ === undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        else if (datasetId_ !== undefined && datasetName_ !== undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetId_ === undefined) {\n            const dataset = await this.readDataset({ datasetName: datasetName_ });\n            datasetId_ = dataset.id;\n        }\n        const createdAt_ = (outputs ? options?.createdAt : inputsOrUpdate.created_at) || new Date();\n        let data;\n        if (!isExampleCreate(inputsOrUpdate)) {\n            data = {\n                inputs: inputsOrUpdate,\n                outputs,\n                created_at: createdAt_?.toISOString(),\n                id: options?.exampleId,\n                metadata: options?.metadata,\n                split: options?.split,\n                source_run_id: options?.sourceRunId,\n                use_source_run_io: options?.useSourceRunIO,\n                use_source_run_attachments: options?.useSourceRunAttachments,\n                attachments: options?.attachments,\n            };\n        }\n        else {\n            data = inputsOrUpdate;\n        }\n        const response = await this._uploadExamplesMultipart(datasetId_, [data]);\n        const example = await this.readExample(response.example_ids?.[0] ?? uuid.v4());\n        return example;\n    }\n    async createExamples(propsOrUploads) {\n        if (Array.isArray(propsOrUploads)) {\n            if (propsOrUploads.length === 0) {\n                return [];\n            }\n            const uploads = propsOrUploads;\n            let datasetId_ = uploads[0].dataset_id;\n            const datasetName_ = uploads[0].dataset_name;\n            if (datasetId_ === undefined && datasetName_ === undefined) {\n                throw new Error(\"Must provide either datasetName or datasetId\");\n            }\n            else if (datasetId_ !== undefined && datasetName_ !== undefined) {\n                throw new Error(\"Must provide either datasetName or datasetId, not both\");\n            }\n            else if (datasetId_ === undefined) {\n                const dataset = await this.readDataset({ datasetName: datasetName_ });\n                datasetId_ = dataset.id;\n            }\n            const response = await this._uploadExamplesMultipart(datasetId_, uploads);\n            const examples = await Promise.all(response.example_ids.map((id) => this.readExample(id)));\n            return examples;\n        }\n        const { inputs, outputs, metadata, splits, sourceRunIds, useSourceRunIOs, useSourceRunAttachments, attachments, exampleIds, datasetId, datasetName, } = propsOrUploads;\n        if (inputs === undefined) {\n            throw new Error(\"Must provide inputs when using legacy parameters\");\n        }\n        let datasetId_ = datasetId;\n        const datasetName_ = datasetName;\n        if (datasetId_ === undefined && datasetName_ === undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId\");\n        }\n        else if (datasetId_ !== undefined && datasetName_ !== undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetId_ === undefined) {\n            const dataset = await this.readDataset({ datasetName: datasetName_ });\n            datasetId_ = dataset.id;\n        }\n        const formattedExamples = inputs.map((input, idx) => {\n            return {\n                dataset_id: datasetId_,\n                inputs: input,\n                outputs: outputs?.[idx],\n                metadata: metadata?.[idx],\n                split: splits?.[idx],\n                id: exampleIds?.[idx],\n                attachments: attachments?.[idx],\n                source_run_id: sourceRunIds?.[idx],\n                use_source_run_io: useSourceRunIOs?.[idx],\n                use_source_run_attachments: useSourceRunAttachments?.[idx],\n            };\n        });\n        const response = await this._uploadExamplesMultipart(datasetId_, formattedExamples);\n        const examples = await Promise.all(response.example_ids.map((id) => this.readExample(id)));\n        return examples;\n    }\n    async createLLMExample(input, generation, options) {\n        return this.createExample({ input }, { output: generation }, options);\n    }\n    async createChatExample(input, generations, options) {\n        const finalInput = input.map((message) => {\n            if (isLangChainMessage(message)) {\n                return convertLangChainMessageToExample(message);\n            }\n            return message;\n        });\n        const finalOutput = isLangChainMessage(generations)\n            ? convertLangChainMessageToExample(generations)\n            : generations;\n        return this.createExample({ input: finalInput }, { output: finalOutput }, options);\n    }\n    async readExample(exampleId) {\n        assertUuid(exampleId);\n        const path = `/examples/${exampleId}`;\n        const rawExample = await this._get(path);\n        const { attachment_urls, ...rest } = rawExample;\n        const example = rest;\n        if (attachment_urls) {\n            example.attachments = Object.entries(attachment_urls).reduce((acc, [key, value]) => {\n                acc[key.slice(\"attachment.\".length)] = {\n                    presigned_url: value.presigned_url,\n                    mime_type: value.mime_type,\n                };\n                return acc;\n            }, {});\n        }\n        return example;\n    }\n    async *listExamples({ datasetId, datasetName, exampleIds, asOf, splits, inlineS3Urls, metadata, limit, offset, filter, includeAttachments, } = {}) {\n        let datasetId_;\n        if (datasetId !== undefined && datasetName !== undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetId !== undefined) {\n            datasetId_ = datasetId;\n        }\n        else if (datasetName !== undefined) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId_ = dataset.id;\n        }\n        else {\n            throw new Error(\"Must provide a datasetName or datasetId\");\n        }\n        const params = new URLSearchParams({ dataset: datasetId_ });\n        const dataset_version = asOf\n            ? typeof asOf === \"string\"\n                ? asOf\n                : asOf?.toISOString()\n            : undefined;\n        if (dataset_version) {\n            params.append(\"as_of\", dataset_version);\n        }\n        const inlineS3Urls_ = inlineS3Urls ?? true;\n        params.append(\"inline_s3_urls\", inlineS3Urls_.toString());\n        if (exampleIds !== undefined) {\n            for (const id_ of exampleIds) {\n                params.append(\"id\", id_);\n            }\n        }\n        if (splits !== undefined) {\n            for (const split of splits) {\n                params.append(\"splits\", split);\n            }\n        }\n        if (metadata !== undefined) {\n            const serializedMetadata = JSON.stringify(metadata);\n            params.append(\"metadata\", serializedMetadata);\n        }\n        if (limit !== undefined) {\n            params.append(\"limit\", limit.toString());\n        }\n        if (offset !== undefined) {\n            params.append(\"offset\", offset.toString());\n        }\n        if (filter !== undefined) {\n            params.append(\"filter\", filter);\n        }\n        if (includeAttachments === true) {\n            [\"attachment_urls\", \"outputs\", \"metadata\"].forEach((field) => params.append(\"select\", field));\n        }\n        let i = 0;\n        for await (const rawExamples of this._getPaginated(\"/examples\", params)) {\n            for (const rawExample of rawExamples) {\n                const { attachment_urls, ...rest } = rawExample;\n                const example = rest;\n                if (attachment_urls) {\n                    example.attachments = Object.entries(attachment_urls).reduce((acc, [key, value]) => {\n                        acc[key.slice(\"attachment.\".length)] = {\n                            presigned_url: value.presigned_url,\n                            mime_type: value.mime_type || undefined,\n                        };\n                        return acc;\n                    }, {});\n                }\n                yield example;\n                i++;\n            }\n            if (limit !== undefined && i >= limit) {\n                break;\n            }\n        }\n    }\n    async deleteExample(exampleId) {\n        assertUuid(exampleId);\n        const path = `/examples/${exampleId}`;\n        await this.caller.call(async () => {\n            const res = await this._fetch(this.apiUrl + path, {\n                method: \"DELETE\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, `delete ${path}`, true);\n            return res;\n        });\n    }\n    async updateExample(exampleIdOrUpdate, update) {\n        let exampleId;\n        if (update) {\n            exampleId = exampleIdOrUpdate;\n        }\n        else {\n            exampleId = exampleIdOrUpdate.id;\n        }\n        assertUuid(exampleId);\n        let updateToUse;\n        if (update) {\n            updateToUse = { id: exampleId, ...update };\n        }\n        else {\n            updateToUse = exampleIdOrUpdate;\n        }\n        let datasetId;\n        if (updateToUse.dataset_id !== undefined) {\n            datasetId = updateToUse.dataset_id;\n        }\n        else {\n            const example = await this.readExample(exampleId);\n            datasetId = example.dataset_id;\n        }\n        return this._updateExamplesMultipart(datasetId, [updateToUse]);\n    }\n    async updateExamples(update) {\n        // We will naively get dataset id from first example and assume it works for all\n        let datasetId;\n        if (update[0].dataset_id === undefined) {\n            const example = await this.readExample(update[0].id);\n            datasetId = example.dataset_id;\n        }\n        else {\n            datasetId = update[0].dataset_id;\n        }\n        return this._updateExamplesMultipart(datasetId, update);\n    }\n    /**\n     * Get dataset version by closest date or exact tag.\n     *\n     * Use this to resolve the nearest version to a given timestamp or for a given tag.\n     *\n     * @param options The options for getting the dataset version\n     * @param options.datasetId The ID of the dataset\n     * @param options.datasetName The name of the dataset\n     * @param options.asOf The timestamp of the dataset to retrieve\n     * @param options.tag The tag of the dataset to retrieve\n     * @returns The dataset version\n     */\n    async readDatasetVersion({ datasetId, datasetName, asOf, tag, }) {\n        let resolvedDatasetId;\n        if (!datasetId) {\n            const dataset = await this.readDataset({ datasetName });\n            resolvedDatasetId = dataset.id;\n        }\n        else {\n            resolvedDatasetId = datasetId;\n        }\n        assertUuid(resolvedDatasetId);\n        if ((asOf && tag) || (!asOf && !tag)) {\n            throw new Error(\"Exactly one of asOf and tag must be specified.\");\n        }\n        const params = new URLSearchParams();\n        if (asOf !== undefined) {\n            params.append(\"as_of\", typeof asOf === \"string\" ? asOf : asOf.toISOString());\n        }\n        if (tag !== undefined) {\n            params.append(\"tag\", tag);\n        }\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${resolvedDatasetId}/version?${params.toString()}`, {\n                method: \"GET\",\n                headers: { ...this.headers },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"read dataset version\");\n            return res;\n        });\n        return await response.json();\n    }\n    async listDatasetSplits({ datasetId, datasetName, asOf, }) {\n        let datasetId_;\n        if (datasetId === undefined && datasetName === undefined) {\n            throw new Error(\"Must provide dataset name or ID\");\n        }\n        else if (datasetId !== undefined && datasetName !== undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetId === undefined) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId_ = dataset.id;\n        }\n        else {\n            datasetId_ = datasetId;\n        }\n        assertUuid(datasetId_);\n        const params = new URLSearchParams();\n        const dataset_version = asOf\n            ? typeof asOf === \"string\"\n                ? asOf\n                : asOf?.toISOString()\n            : undefined;\n        if (dataset_version) {\n            params.append(\"as_of\", dataset_version);\n        }\n        const response = await this._get(`/datasets/${datasetId_}/splits`, params);\n        return response;\n    }\n    async updateDatasetSplits({ datasetId, datasetName, splitName, exampleIds, remove = false, }) {\n        let datasetId_;\n        if (datasetId === undefined && datasetName === undefined) {\n            throw new Error(\"Must provide dataset name or ID\");\n        }\n        else if (datasetId !== undefined && datasetName !== undefined) {\n            throw new Error(\"Must provide either datasetName or datasetId, not both\");\n        }\n        else if (datasetId === undefined) {\n            const dataset = await this.readDataset({ datasetName });\n            datasetId_ = dataset.id;\n        }\n        else {\n            datasetId_ = datasetId;\n        }\n        assertUuid(datasetId_);\n        const data = {\n            split_name: splitName,\n            examples: exampleIds.map((id) => {\n                assertUuid(id);\n                return id;\n            }),\n            remove,\n        };\n        const body = JSON.stringify(data);\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/${datasetId_}/splits`, {\n                method: \"PUT\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update dataset splits\", true);\n            return res;\n        });\n    }\n    /**\n     * @deprecated This method is deprecated and will be removed in future LangSmith versions, use `evaluate` from `langsmith/evaluation` instead.\n     */\n    async evaluateRun(run, evaluator, { sourceInfo, loadChildRuns, referenceExample, } = { loadChildRuns: false }) {\n        warnOnce(\"This method is deprecated and will be removed in future LangSmith versions, use `evaluate` from `langsmith/evaluation` instead.\");\n        let run_;\n        if (typeof run === \"string\") {\n            run_ = await this.readRun(run, { loadChildRuns });\n        }\n        else if (typeof run === \"object\" && \"id\" in run) {\n            run_ = run;\n        }\n        else {\n            throw new Error(`Invalid run type: ${typeof run}`);\n        }\n        if (run_.reference_example_id !== null &&\n            run_.reference_example_id !== undefined) {\n            referenceExample = await this.readExample(run_.reference_example_id);\n        }\n        const feedbackResult = await evaluator.evaluateRun(run_, referenceExample);\n        const [_, feedbacks] = await this._logEvaluationFeedback(feedbackResult, run_, sourceInfo);\n        return feedbacks[0];\n    }\n    async createFeedback(runId, key, { score, value, correction, comment, sourceInfo, feedbackSourceType = \"api\", sourceRunId, feedbackId, feedbackConfig, projectId, comparativeExperimentId, }) {\n        if (!runId && !projectId) {\n            throw new Error(\"One of runId or projectId must be provided\");\n        }\n        if (runId && projectId) {\n            throw new Error(\"Only one of runId or projectId can be provided\");\n        }\n        const feedback_source = {\n            type: feedbackSourceType ?? \"api\",\n            metadata: sourceInfo ?? {},\n        };\n        if (sourceRunId !== undefined &&\n            feedback_source?.metadata !== undefined &&\n            !feedback_source.metadata[\"__run\"]) {\n            feedback_source.metadata[\"__run\"] = { run_id: sourceRunId };\n        }\n        if (feedback_source?.metadata !== undefined &&\n            feedback_source.metadata[\"__run\"]?.run_id !== undefined) {\n            assertUuid(feedback_source.metadata[\"__run\"].run_id);\n        }\n        const feedback = {\n            id: feedbackId ?? uuid.v4(),\n            run_id: runId,\n            key,\n            score: _formatFeedbackScore(score),\n            value,\n            correction,\n            comment,\n            feedback_source: feedback_source,\n            comparative_experiment_id: comparativeExperimentId,\n            feedbackConfig,\n            session_id: projectId,\n        };\n        const body = JSON.stringify(feedback);\n        const url = `${this.apiUrl}/feedback`;\n        await this.caller.call(async () => {\n            const res = await this._fetch(url, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"create feedback\", true);\n            return res;\n        });\n        return feedback;\n    }\n    async updateFeedback(feedbackId, { score, value, correction, comment, }) {\n        const feedbackUpdate = {};\n        if (score !== undefined && score !== null) {\n            feedbackUpdate[\"score\"] = _formatFeedbackScore(score);\n        }\n        if (value !== undefined && value !== null) {\n            feedbackUpdate[\"value\"] = value;\n        }\n        if (correction !== undefined && correction !== null) {\n            feedbackUpdate[\"correction\"] = correction;\n        }\n        if (comment !== undefined && comment !== null) {\n            feedbackUpdate[\"comment\"] = comment;\n        }\n        assertUuid(feedbackId);\n        const body = JSON.stringify(feedbackUpdate);\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/feedback/${feedbackId}`, {\n                method: \"PATCH\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update feedback\", true);\n            return res;\n        });\n    }\n    async readFeedback(feedbackId) {\n        assertUuid(feedbackId);\n        const path = `/feedback/${feedbackId}`;\n        const response = await this._get(path);\n        return response;\n    }\n    async deleteFeedback(feedbackId) {\n        assertUuid(feedbackId);\n        const path = `/feedback/${feedbackId}`;\n        await this.caller.call(async () => {\n            const res = await this._fetch(this.apiUrl + path, {\n                method: \"DELETE\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, `delete ${path}`, true);\n            return res;\n        });\n    }\n    async *listFeedback({ runIds, feedbackKeys, feedbackSourceTypes, } = {}) {\n        const queryParams = new URLSearchParams();\n        if (runIds) {\n            for (const runId of runIds) {\n                assertUuid(runId);\n                queryParams.append(\"run\", runId);\n            }\n        }\n        if (feedbackKeys) {\n            for (const key of feedbackKeys) {\n                queryParams.append(\"key\", key);\n            }\n        }\n        if (feedbackSourceTypes) {\n            for (const type of feedbackSourceTypes) {\n                queryParams.append(\"source\", type);\n            }\n        }\n        for await (const feedbacks of this._getPaginated(\"/feedback\", queryParams)) {\n            yield* feedbacks;\n        }\n    }\n    /**\n     * Creates a presigned feedback token and URL.\n     *\n     * The token can be used to authorize feedback metrics without\n     * needing an API key. This is useful for giving browser-based\n     * applications the ability to submit feedback without needing\n     * to expose an API key.\n     *\n     * @param runId The ID of the run.\n     * @param feedbackKey The feedback key.\n     * @param options Additional options for the token.\n     * @param options.expiration The expiration time for the token.\n     *\n     * @returns A promise that resolves to a FeedbackIngestToken.\n     */\n    async createPresignedFeedbackToken(runId, feedbackKey, { expiration, feedbackConfig, } = {}) {\n        const body = {\n            run_id: runId,\n            feedback_key: feedbackKey,\n            feedback_config: feedbackConfig,\n        };\n        if (expiration) {\n            if (typeof expiration === \"string\") {\n                body[\"expires_at\"] = expiration;\n            }\n            else if (expiration?.hours || expiration?.minutes || expiration?.days) {\n                body[\"expires_in\"] = expiration;\n            }\n        }\n        else {\n            body[\"expires_in\"] = {\n                hours: 3,\n            };\n        }\n        const serializedBody = JSON.stringify(body);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/feedback/tokens`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: serializedBody,\n            });\n            await raiseForStatus(res, \"create presigned feedback token\");\n            return res;\n        });\n        return await response.json();\n    }\n    async createComparativeExperiment({ name, experimentIds, referenceDatasetId, createdAt, description, metadata, id, }) {\n        if (experimentIds.length === 0) {\n            throw new Error(\"At least one experiment is required\");\n        }\n        if (!referenceDatasetId) {\n            referenceDatasetId = (await this.readProject({\n                projectId: experimentIds[0],\n            })).reference_dataset_id;\n        }\n        if (!referenceDatasetId == null) {\n            throw new Error(\"A reference dataset is required\");\n        }\n        const body = {\n            id,\n            name,\n            experiment_ids: experimentIds,\n            reference_dataset_id: referenceDatasetId,\n            description,\n            created_at: (createdAt ?? new Date())?.toISOString(),\n            extra: {},\n        };\n        if (metadata)\n            body.extra[\"metadata\"] = metadata;\n        const serializedBody = JSON.stringify(body);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/datasets/comparative`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: serializedBody,\n            });\n            await raiseForStatus(res, \"create comparative experiment\");\n            return res;\n        });\n        return response.json();\n    }\n    /**\n     * Retrieves a list of presigned feedback tokens for a given run ID.\n     * @param runId The ID of the run.\n     * @returns An async iterable of FeedbackIngestToken objects.\n     */\n    async *listPresignedFeedbackTokens(runId) {\n        assertUuid(runId);\n        const params = new URLSearchParams({ run_id: runId });\n        for await (const tokens of this._getPaginated(\"/feedback/tokens\", params)) {\n            yield* tokens;\n        }\n    }\n    _selectEvalResults(results) {\n        let results_;\n        if (\"results\" in results) {\n            results_ = results.results;\n        }\n        else if (Array.isArray(results)) {\n            results_ = results;\n        }\n        else {\n            results_ = [results];\n        }\n        return results_;\n    }\n    async _logEvaluationFeedback(evaluatorResponse, run, sourceInfo) {\n        const evalResults = this._selectEvalResults(evaluatorResponse);\n        const feedbacks = [];\n        for (const res of evalResults) {\n            let sourceInfo_ = sourceInfo || {};\n            if (res.evaluatorInfo) {\n                sourceInfo_ = { ...res.evaluatorInfo, ...sourceInfo_ };\n            }\n            let runId_ = null;\n            if (res.targetRunId) {\n                runId_ = res.targetRunId;\n            }\n            else if (run) {\n                runId_ = run.id;\n            }\n            feedbacks.push(await this.createFeedback(runId_, res.key, {\n                score: res.score,\n                value: res.value,\n                comment: res.comment,\n                correction: res.correction,\n                sourceInfo: sourceInfo_,\n                sourceRunId: res.sourceRunId,\n                feedbackConfig: res.feedbackConfig,\n                feedbackSourceType: \"model\",\n            }));\n        }\n        return [evalResults, feedbacks];\n    }\n    async logEvaluationFeedback(evaluatorResponse, run, sourceInfo) {\n        const [results] = await this._logEvaluationFeedback(evaluatorResponse, run, sourceInfo);\n        return results;\n    }\n    /**\n     * API for managing annotation queues\n     */\n    /**\n     * List the annotation queues on the LangSmith API.\n     * @param options - The options for listing annotation queues\n     * @param options.queueIds - The IDs of the queues to filter by\n     * @param options.name - The name of the queue to filter by\n     * @param options.nameContains - The substring that the queue name should contain\n     * @param options.limit - The maximum number of queues to return\n     * @returns An iterator of AnnotationQueue objects\n     */\n    async *listAnnotationQueues(options = {}) {\n        const { queueIds, name, nameContains, limit } = options;\n        const params = new URLSearchParams();\n        if (queueIds) {\n            queueIds.forEach((id, i) => {\n                assertUuid(id, `queueIds[${i}]`);\n                params.append(\"ids\", id);\n            });\n        }\n        if (name)\n            params.append(\"name\", name);\n        if (nameContains)\n            params.append(\"name_contains\", nameContains);\n        params.append(\"limit\", (limit !== undefined ? Math.min(limit, 100) : 100).toString());\n        let count = 0;\n        for await (const queues of this._getPaginated(\"/annotation-queues\", params)) {\n            yield* queues;\n            count++;\n            if (limit !== undefined && count >= limit)\n                break;\n        }\n    }\n    /**\n     * Create an annotation queue on the LangSmith API.\n     * @param options - The options for creating an annotation queue\n     * @param options.name - The name of the annotation queue\n     * @param options.description - The description of the annotation queue\n     * @param options.queueId - The ID of the annotation queue\n     * @returns The created AnnotationQueue object\n     */\n    async createAnnotationQueue(options) {\n        const { name, description, queueId, rubricInstructions } = options;\n        const body = {\n            name,\n            description,\n            id: queueId || uuid.v4(),\n            rubric_instructions: rubricInstructions,\n        };\n        const serializedBody = JSON.stringify(Object.fromEntries(Object.entries(body).filter(([_, v]) => v !== undefined)));\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/annotation-queues`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: serializedBody,\n            });\n            await raiseForStatus(res, \"create annotation queue\");\n            return res;\n        });\n        return response.json();\n    }\n    /**\n     * Read an annotation queue with the specified queue ID.\n     * @param queueId - The ID of the annotation queue to read\n     * @returns The AnnotationQueueWithDetails object\n     */\n    async readAnnotationQueue(queueId) {\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/annotation-queues/${assertUuid(queueId, \"queueId\")}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"read annotation queue\");\n            return res;\n        });\n        return response.json();\n    }\n    /**\n     * Update an annotation queue with the specified queue ID.\n     * @param queueId - The ID of the annotation queue to update\n     * @param options - The options for updating the annotation queue\n     * @param options.name - The new name for the annotation queue\n     * @param options.description - The new description for the annotation queue\n     */\n    async updateAnnotationQueue(queueId, options) {\n        const { name, description, rubricInstructions } = options;\n        const body = JSON.stringify({\n            name,\n            description,\n            rubric_instructions: rubricInstructions,\n        });\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/annotation-queues/${assertUuid(queueId, \"queueId\")}`, {\n                method: \"PATCH\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update annotation queue\", true);\n            return res;\n        });\n    }\n    /**\n     * Delete an annotation queue with the specified queue ID.\n     * @param queueId - The ID of the annotation queue to delete\n     */\n    async deleteAnnotationQueue(queueId) {\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/annotation-queues/${assertUuid(queueId, \"queueId\")}`, {\n                method: \"DELETE\",\n                headers: { ...this.headers, Accept: \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"delete annotation queue\", true);\n            return res;\n        });\n    }\n    /**\n     * Add runs to an annotation queue with the specified queue ID.\n     * @param queueId - The ID of the annotation queue\n     * @param runIds - The IDs of the runs to be added to the annotation queue\n     */\n    async addRunsToAnnotationQueue(queueId, runIds) {\n        const body = JSON.stringify(runIds.map((id, i) => assertUuid(id, `runIds[${i}]`).toString()));\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/annotation-queues/${assertUuid(queueId, \"queueId\")}/runs`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"add runs to annotation queue\", true);\n            return res;\n        });\n    }\n    /**\n     * Get a run from an annotation queue at the specified index.\n     * @param queueId - The ID of the annotation queue\n     * @param index - The index of the run to retrieve\n     * @returns A Promise that resolves to a RunWithAnnotationQueueInfo object\n     * @throws {Error} If the run is not found at the given index or for other API-related errors\n     */\n    async getRunFromAnnotationQueue(queueId, index) {\n        const baseUrl = `/annotation-queues/${assertUuid(queueId, \"queueId\")}/run`;\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}${baseUrl}/${index}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"get run from annotation queue\");\n            return res;\n        });\n        return response.json();\n    }\n    /**\n     * Delete a run from an an annotation queue.\n     * @param queueId - The ID of the annotation queue to delete the run from\n     * @param queueRunId - The ID of the run to delete from the annotation queue\n     */\n    async deleteRunFromAnnotationQueue(queueId, queueRunId) {\n        await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/annotation-queues/${assertUuid(queueId, \"queueId\")}/runs/${assertUuid(queueRunId, \"queueRunId\")}`, {\n                method: \"DELETE\",\n                headers: { ...this.headers, Accept: \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"delete run from annotation queue\", true);\n            return res;\n        });\n    }\n    /**\n     * Get the size of an annotation queue.\n     * @param queueId - The ID of the annotation queue\n     */\n    async getSizeFromAnnotationQueue(queueId) {\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/annotation-queues/${assertUuid(queueId, \"queueId\")}/size`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"get size from annotation queue\");\n            return res;\n        });\n        return response.json();\n    }\n    async _currentTenantIsOwner(owner) {\n        const settings = await this._getSettings();\n        return owner == \"-\" || settings.tenant_handle === owner;\n    }\n    async _ownerConflictError(action, owner) {\n        const settings = await this._getSettings();\n        return new Error(`Cannot ${action} for another tenant.\\n\n      Current tenant: ${settings.tenant_handle}\\n\n      Requested tenant: ${owner}`);\n    }\n    async _getLatestCommitHash(promptOwnerAndName) {\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/commits/${promptOwnerAndName}/?limit=${1}&offset=${0}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"get latest commit hash\");\n            return res;\n        });\n        const json = await response.json();\n        if (json.commits.length === 0) {\n            return undefined;\n        }\n        return json.commits[0].commit_hash;\n    }\n    async _likeOrUnlikePrompt(promptIdentifier, like) {\n        const [owner, promptName, _] = parsePromptIdentifier(promptIdentifier);\n        const body = JSON.stringify({ like: like });\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/likes/${owner}/${promptName}`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, `${like ? \"like\" : \"unlike\"} prompt`);\n            return res;\n        });\n        return response.json();\n    }\n    async _getPromptUrl(promptIdentifier) {\n        const [owner, promptName, commitHash] = parsePromptIdentifier(promptIdentifier);\n        if (!(await this._currentTenantIsOwner(owner))) {\n            if (commitHash !== \"latest\") {\n                return `${this.getHostUrl()}/hub/${owner}/${promptName}/${commitHash.substring(0, 8)}`;\n            }\n            else {\n                return `${this.getHostUrl()}/hub/${owner}/${promptName}`;\n            }\n        }\n        else {\n            const settings = await this._getSettings();\n            if (commitHash !== \"latest\") {\n                return `${this.getHostUrl()}/prompts/${promptName}/${commitHash.substring(0, 8)}?organizationId=${settings.id}`;\n            }\n            else {\n                return `${this.getHostUrl()}/prompts/${promptName}?organizationId=${settings.id}`;\n            }\n        }\n    }\n    async promptExists(promptIdentifier) {\n        const prompt = await this.getPrompt(promptIdentifier);\n        return !!prompt;\n    }\n    async likePrompt(promptIdentifier) {\n        return this._likeOrUnlikePrompt(promptIdentifier, true);\n    }\n    async unlikePrompt(promptIdentifier) {\n        return this._likeOrUnlikePrompt(promptIdentifier, false);\n    }\n    async *listCommits(promptOwnerAndName) {\n        for await (const commits of this._getPaginated(`/commits/${promptOwnerAndName}/`, new URLSearchParams(), (res) => res.commits)) {\n            yield* commits;\n        }\n    }\n    async *listPrompts(options) {\n        const params = new URLSearchParams();\n        params.append(\"sort_field\", options?.sortField ?? \"updated_at\");\n        params.append(\"sort_direction\", \"desc\");\n        params.append(\"is_archived\", (!!options?.isArchived).toString());\n        if (options?.isPublic !== undefined) {\n            params.append(\"is_public\", options.isPublic.toString());\n        }\n        if (options?.query) {\n            params.append(\"query\", options.query);\n        }\n        for await (const prompts of this._getPaginated(\"/repos\", params, (res) => res.repos)) {\n            yield* prompts;\n        }\n    }\n    async getPrompt(promptIdentifier) {\n        const [owner, promptName, _] = parsePromptIdentifier(promptIdentifier);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/repos/${owner}/${promptName}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            if (res?.status === 404) {\n                return null;\n            }\n            await raiseForStatus(res, \"get prompt\");\n            return res;\n        });\n        const result = await response?.json();\n        if (result?.repo) {\n            return result.repo;\n        }\n        else {\n            return null;\n        }\n    }\n    async createPrompt(promptIdentifier, options) {\n        const settings = await this._getSettings();\n        if (options?.isPublic && !settings.tenant_handle) {\n            throw new Error(`Cannot create a public prompt without first\\n\n        creating a LangChain Hub handle.\n        You can add a handle by creating a public prompt at:\\n\n        https://smith.langchain.com/prompts`);\n        }\n        const [owner, promptName, _] = parsePromptIdentifier(promptIdentifier);\n        if (!(await this._currentTenantIsOwner(owner))) {\n            throw await this._ownerConflictError(\"create a prompt\", owner);\n        }\n        const data = {\n            repo_handle: promptName,\n            ...(options?.description && { description: options.description }),\n            ...(options?.readme && { readme: options.readme }),\n            ...(options?.tags && { tags: options.tags }),\n            is_public: !!options?.isPublic,\n        };\n        const body = JSON.stringify(data);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/repos/`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"create prompt\");\n            return res;\n        });\n        const { repo } = await response.json();\n        return repo;\n    }\n    async createCommit(promptIdentifier, object, options) {\n        if (!(await this.promptExists(promptIdentifier))) {\n            throw new Error(\"Prompt does not exist, you must create it first.\");\n        }\n        const [owner, promptName, _] = parsePromptIdentifier(promptIdentifier);\n        const resolvedParentCommitHash = options?.parentCommitHash === \"latest\" || !options?.parentCommitHash\n            ? await this._getLatestCommitHash(`${owner}/${promptName}`)\n            : options?.parentCommitHash;\n        const payload = {\n            manifest: JSON.parse(JSON.stringify(object)),\n            parent_commit: resolvedParentCommitHash,\n        };\n        const body = JSON.stringify(payload);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/commits/${owner}/${promptName}`, {\n                method: \"POST\",\n                headers: { ...this.headers, \"Content-Type\": \"application/json\" },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"create commit\");\n            return res;\n        });\n        const result = await response.json();\n        return this._getPromptUrl(`${owner}/${promptName}${result.commit_hash ? `:${result.commit_hash}` : \"\"}`);\n    }\n    /**\n     * Update examples with attachments using multipart form data.\n     * @param updates List of ExampleUpdateWithAttachments objects to upsert\n     * @returns Promise with the update response\n     */\n    async updateExamplesMultipart(datasetId, updates = []) {\n        return this._updateExamplesMultipart(datasetId, updates);\n    }\n    async _updateExamplesMultipart(datasetId, updates = []) {\n        if (!(await this._getDatasetExamplesMultiPartSupport())) {\n            throw new Error(\"Your LangSmith deployment does not allow using the multipart examples endpoint, please upgrade your deployment to the latest version.\");\n        }\n        const formData = new FormData();\n        for (const example of updates) {\n            const exampleId = example.id;\n            // Prepare the main example body\n            const exampleBody = {\n                ...(example.metadata && { metadata: example.metadata }),\n                ...(example.split && { split: example.split }),\n            };\n            // Add main example data\n            const stringifiedExample = serializePayloadForTracing(exampleBody, `Serializing body for example with id: ${exampleId}`);\n            const exampleBlob = new Blob([stringifiedExample], {\n                type: \"application/json\",\n            });\n            formData.append(exampleId, exampleBlob);\n            // Add inputs if present\n            if (example.inputs) {\n                const stringifiedInputs = serializePayloadForTracing(example.inputs, `Serializing inputs for example with id: ${exampleId}`);\n                const inputsBlob = new Blob([stringifiedInputs], {\n                    type: \"application/json\",\n                });\n                formData.append(`${exampleId}.inputs`, inputsBlob);\n            }\n            // Add outputs if present\n            if (example.outputs) {\n                const stringifiedOutputs = serializePayloadForTracing(example.outputs, `Serializing outputs whle updating example with id: ${exampleId}`);\n                const outputsBlob = new Blob([stringifiedOutputs], {\n                    type: \"application/json\",\n                });\n                formData.append(`${exampleId}.outputs`, outputsBlob);\n            }\n            // Add attachments if present\n            if (example.attachments) {\n                for (const [name, attachment] of Object.entries(example.attachments)) {\n                    let mimeType;\n                    let data;\n                    if (Array.isArray(attachment)) {\n                        [mimeType, data] = attachment;\n                    }\n                    else {\n                        mimeType = attachment.mimeType;\n                        data = attachment.data;\n                    }\n                    const attachmentBlob = new Blob([data], {\n                        type: `${mimeType}; length=${data.byteLength}`,\n                    });\n                    formData.append(`${exampleId}.attachment.${name}`, attachmentBlob);\n                }\n            }\n            if (example.attachments_operations) {\n                const stringifiedAttachmentsOperations = serializePayloadForTracing(example.attachments_operations, `Serializing attachments while updating example with id: ${exampleId}`);\n                const attachmentsOperationsBlob = new Blob([stringifiedAttachmentsOperations], {\n                    type: \"application/json\",\n                });\n                formData.append(`${exampleId}.attachments_operations`, attachmentsOperationsBlob);\n            }\n        }\n        const datasetIdToUse = datasetId ?? updates[0]?.dataset_id;\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}${this._getPlatformEndpointPath(`datasets/${datasetIdToUse}/examples`)}`, {\n                method: \"PATCH\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: formData,\n            });\n            await raiseForStatus(res, \"update examples\");\n            return res;\n        });\n        return response.json();\n    }\n    /**\n     * Upload examples with attachments using multipart form data.\n     * @param uploads List of ExampleUploadWithAttachments objects to upload\n     * @returns Promise with the upload response\n     * @deprecated This method is deprecated and will be removed in future LangSmith versions, please use `createExamples` instead\n     */\n    async uploadExamplesMultipart(datasetId, uploads = []) {\n        return this._uploadExamplesMultipart(datasetId, uploads);\n    }\n    async _uploadExamplesMultipart(datasetId, uploads = []) {\n        if (!(await this._getDatasetExamplesMultiPartSupport())) {\n            throw new Error(\"Your LangSmith deployment does not allow using the multipart examples endpoint, please upgrade your deployment to the latest version.\");\n        }\n        const formData = new FormData();\n        for (const example of uploads) {\n            const exampleId = (example.id ?? uuid.v4()).toString();\n            // Prepare the main example body\n            const exampleBody = {\n                created_at: example.created_at,\n                ...(example.metadata && { metadata: example.metadata }),\n                ...(example.split && { split: example.split }),\n                ...(example.source_run_id && { source_run_id: example.source_run_id }),\n                ...(example.use_source_run_io && {\n                    use_source_run_io: example.use_source_run_io,\n                }),\n                ...(example.use_source_run_attachments && {\n                    use_source_run_attachments: example.use_source_run_attachments,\n                }),\n            };\n            // Add main example data\n            const stringifiedExample = serializePayloadForTracing(exampleBody, `Serializing body for uploaded example with id: ${exampleId}`);\n            const exampleBlob = new Blob([stringifiedExample], {\n                type: \"application/json\",\n            });\n            formData.append(exampleId, exampleBlob);\n            // Add inputs if present\n            if (example.inputs) {\n                const stringifiedInputs = serializePayloadForTracing(example.inputs, `Serializing inputs for uploaded example with id: ${exampleId}`);\n                const inputsBlob = new Blob([stringifiedInputs], {\n                    type: \"application/json\",\n                });\n                formData.append(`${exampleId}.inputs`, inputsBlob);\n            }\n            // Add outputs if present\n            if (example.outputs) {\n                const stringifiedOutputs = serializePayloadForTracing(example.outputs, `Serializing outputs for uploaded example with id: ${exampleId}`);\n                const outputsBlob = new Blob([stringifiedOutputs], {\n                    type: \"application/json\",\n                });\n                formData.append(`${exampleId}.outputs`, outputsBlob);\n            }\n            // Add attachments if present\n            if (example.attachments) {\n                for (const [name, attachment] of Object.entries(example.attachments)) {\n                    let mimeType;\n                    let data;\n                    if (Array.isArray(attachment)) {\n                        [mimeType, data] = attachment;\n                    }\n                    else {\n                        mimeType = attachment.mimeType;\n                        data = attachment.data;\n                    }\n                    const attachmentBlob = new Blob([data], {\n                        type: `${mimeType}; length=${data.byteLength}`,\n                    });\n                    formData.append(`${exampleId}.attachment.${name}`, attachmentBlob);\n                }\n            }\n        }\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}${this._getPlatformEndpointPath(`datasets/${datasetId}/examples`)}`, {\n                method: \"POST\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body: formData,\n            });\n            await raiseForStatus(res, \"upload examples\");\n            return res;\n        });\n        return response.json();\n    }\n    async updatePrompt(promptIdentifier, options) {\n        if (!(await this.promptExists(promptIdentifier))) {\n            throw new Error(\"Prompt does not exist, you must create it first.\");\n        }\n        const [owner, promptName] = parsePromptIdentifier(promptIdentifier);\n        if (!(await this._currentTenantIsOwner(owner))) {\n            throw await this._ownerConflictError(\"update a prompt\", owner);\n        }\n        const payload = {};\n        if (options?.description !== undefined)\n            payload.description = options.description;\n        if (options?.readme !== undefined)\n            payload.readme = options.readme;\n        if (options?.tags !== undefined)\n            payload.tags = options.tags;\n        if (options?.isPublic !== undefined)\n            payload.is_public = options.isPublic;\n        if (options?.isArchived !== undefined)\n            payload.is_archived = options.isArchived;\n        // Check if payload is empty\n        if (Object.keys(payload).length === 0) {\n            throw new Error(\"No valid update options provided\");\n        }\n        const body = JSON.stringify(payload);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/repos/${owner}/${promptName}`, {\n                method: \"PATCH\",\n                headers: {\n                    ...this.headers,\n                    \"Content-Type\": \"application/json\",\n                },\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n                body,\n            });\n            await raiseForStatus(res, \"update prompt\");\n            return res;\n        });\n        return response.json();\n    }\n    async deletePrompt(promptIdentifier) {\n        if (!(await this.promptExists(promptIdentifier))) {\n            throw new Error(\"Prompt does not exist, you must create it first.\");\n        }\n        const [owner, promptName, _] = parsePromptIdentifier(promptIdentifier);\n        if (!(await this._currentTenantIsOwner(owner))) {\n            throw await this._ownerConflictError(\"delete a prompt\", owner);\n        }\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/repos/${owner}/${promptName}`, {\n                method: \"DELETE\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"delete prompt\");\n            return res;\n        });\n        return response.json();\n    }\n    async pullPromptCommit(promptIdentifier, options) {\n        const [owner, promptName, commitHash] = parsePromptIdentifier(promptIdentifier);\n        const response = await this.caller.call(async () => {\n            const res = await this._fetch(`${this.apiUrl}/commits/${owner}/${promptName}/${commitHash}${options?.includeModel ? \"?include_model=true\" : \"\"}`, {\n                method: \"GET\",\n                headers: this.headers,\n                signal: AbortSignal.timeout(this.timeout_ms),\n                ...this.fetchOptions,\n            });\n            await raiseForStatus(res, \"pull prompt commit\");\n            return res;\n        });\n        const result = await response.json();\n        return {\n            owner,\n            repo: promptName,\n            commit_hash: result.commit_hash,\n            manifest: result.manifest,\n            examples: result.examples,\n        };\n    }\n    /**\n     * This method should not be used directly, use `import { pull } from \"langchain/hub\"` instead.\n     * Using this method directly returns the JSON string of the prompt rather than a LangChain object.\n     * @private\n     */\n    async _pullPrompt(promptIdentifier, options) {\n        const promptObject = await this.pullPromptCommit(promptIdentifier, {\n            includeModel: options?.includeModel,\n        });\n        const prompt = JSON.stringify(promptObject.manifest);\n        return prompt;\n    }\n    async pushPrompt(promptIdentifier, options) {\n        // Create or update prompt metadata\n        if (await this.promptExists(promptIdentifier)) {\n            if (options && Object.keys(options).some((key) => key !== \"object\")) {\n                await this.updatePrompt(promptIdentifier, {\n                    description: options?.description,\n                    readme: options?.readme,\n                    tags: options?.tags,\n                    isPublic: options?.isPublic,\n                });\n            }\n        }\n        else {\n            await this.createPrompt(promptIdentifier, {\n                description: options?.description,\n                readme: options?.readme,\n                tags: options?.tags,\n                isPublic: options?.isPublic,\n            });\n        }\n        if (!options?.object) {\n            return await this._getPromptUrl(promptIdentifier);\n        }\n        // Create a commit with the new manifest\n        const url = await this.createCommit(promptIdentifier, options?.object, {\n            parentCommitHash: options?.parentCommitHash,\n        });\n        return url;\n    }\n    /**\n     * Clone a public dataset to your own langsmith tenant.\n     * This operation is idempotent. If you already have a dataset with the given name,\n     * this function will do nothing.\n  \n     * @param {string} tokenOrUrl The token of the public dataset to clone.\n     * @param {Object} [options] Additional options for cloning the dataset.\n     * @param {string} [options.sourceApiUrl] The URL of the langsmith server where the data is hosted. Defaults to the API URL of your current client.\n     * @param {string} [options.datasetName] The name of the dataset to create in your tenant. Defaults to the name of the public dataset.\n     * @returns {Promise<void>}\n     */\n    async clonePublicDataset(tokenOrUrl, options = {}) {\n        const { sourceApiUrl = this.apiUrl, datasetName } = options;\n        const [parsedApiUrl, tokenUuid] = this.parseTokenOrUrl(tokenOrUrl, sourceApiUrl);\n        const sourceClient = new Client({\n            apiUrl: parsedApiUrl,\n            // Placeholder API key not needed anymore in most cases, but\n            // some private deployments may have API key-based rate limiting\n            // that would cause this to fail if we provide no value.\n            apiKey: \"placeholder\",\n        });\n        const ds = await sourceClient.readSharedDataset(tokenUuid);\n        const finalDatasetName = datasetName || ds.name;\n        try {\n            if (await this.hasDataset({ datasetId: finalDatasetName })) {\n                console.log(`Dataset ${finalDatasetName} already exists in your tenant. Skipping.`);\n                return;\n            }\n        }\n        catch (_) {\n            // `.hasDataset` will throw an error if the dataset does not exist.\n            // no-op in that case\n        }\n        // Fetch examples first, then create the dataset\n        const examples = await sourceClient.listSharedExamples(tokenUuid);\n        const dataset = await this.createDataset(finalDatasetName, {\n            description: ds.description,\n            dataType: ds.data_type || \"kv\",\n            inputsSchema: ds.inputs_schema_definition ?? undefined,\n            outputsSchema: ds.outputs_schema_definition ?? undefined,\n        });\n        try {\n            await this.createExamples({\n                inputs: examples.map((e) => e.inputs),\n                outputs: examples.flatMap((e) => (e.outputs ? [e.outputs] : [])),\n                datasetId: dataset.id,\n            });\n        }\n        catch (e) {\n            console.error(`An error occurred while creating dataset ${finalDatasetName}. ` +\n                \"You should delete it manually.\");\n            throw e;\n        }\n    }\n    parseTokenOrUrl(urlOrToken, apiUrl, numParts = 2, kind = \"dataset\") {\n        // Try parsing as UUID\n        try {\n            assertUuid(urlOrToken); // Will throw if it's not a UUID.\n            return [apiUrl, urlOrToken];\n        }\n        catch (_) {\n            // no-op if it's not a uuid\n        }\n        // Parse as URL\n        try {\n            const parsedUrl = new URL(urlOrToken);\n            const pathParts = parsedUrl.pathname\n                .split(\"/\")\n                .filter((part) => part !== \"\");\n            if (pathParts.length >= numParts) {\n                const tokenUuid = pathParts[pathParts.length - numParts];\n                return [apiUrl, tokenUuid];\n            }\n            else {\n                throw new Error(`Invalid public ${kind} URL: ${urlOrToken}`);\n            }\n        }\n        catch (error) {\n            throw new Error(`Invalid public ${kind} URL or token: ${urlOrToken}`);\n        }\n    }\n    /**\n     * Awaits all pending trace batches. Useful for environments where\n     * you need to be sure that all tracing requests finish before execution ends,\n     * such as serverless environments.\n     *\n     * @example\n     * ```\n     * import { Client } from \"langsmith\";\n     *\n     * const client = new Client();\n     *\n     * try {\n     *   // Tracing happens here\n     *   ...\n     * } finally {\n     *   await client.awaitPendingTraceBatches();\n     * }\n     * ```\n     *\n     * @returns A promise that resolves once all currently pending traces have sent.\n     */\n    async awaitPendingTraceBatches() {\n        if (this.manualFlushMode) {\n            console.warn(\"[WARNING]: When tracing in manual flush mode, you must call `await client.flush()` manually to submit trace batches.\");\n            return Promise.resolve();\n        }\n        await Promise.all([\n            ...this.autoBatchQueue.items.map(({ itemPromise }) => itemPromise),\n            this.batchIngestCaller.queue.onIdle(),\n        ]);\n        if (this.langSmithToOTELTranslator !== undefined) {\n            await getDefaultOTLPTracerComponents()?.DEFAULT_LANGSMITH_SPAN_PROCESSOR?.forceFlush();\n        }\n    }\n}\nfunction isExampleCreate(input) {\n    return \"dataset_id\" in input || \"dataset_name\" in input;\n}\n","import { getLangSmithEnvironmentVariable } from \"./utils/env.js\";\nexport const isTracingEnabled = (tracingEnabled) => {\n    if (tracingEnabled !== undefined) {\n        return tracingEnabled;\n    }\n    const envVars = [\"TRACING_V2\", \"TRACING\"];\n    return !!envVars.find((envVar) => getLangSmithEnvironmentVariable(envVar) === \"true\");\n};\n","export const _LC_CONTEXT_VARIABLES_KEY = Symbol.for(\"lc:context_variables\");\n","import * as uuid from \"uuid\";\nimport { Client } from \"./client.js\";\nimport { isTracingEnabled } from \"./env.js\";\nimport { isConflictingEndpointsError, ConflictingEndpointsError, } from \"./utils/error.js\";\nimport { _LC_CONTEXT_VARIABLES_KEY } from \"./singletons/constants.js\";\nimport { getEnvironmentVariable, getRuntimeEnvironment, } from \"./utils/env.js\";\nimport { getDefaultProjectName } from \"./utils/project.js\";\nimport { getLangSmithEnvironmentVariable } from \"./utils/env.js\";\nimport { warnOnce } from \"./utils/warn.js\";\nfunction stripNonAlphanumeric(input) {\n    return input.replace(/[-:.]/g, \"\");\n}\nexport function convertToDottedOrderFormat(epoch, runId, executionOrder = 1) {\n    // Date only has millisecond precision, so we use the microseconds to break\n    // possible ties, avoiding incorrect run order\n    const paddedOrder = executionOrder.toFixed(0).slice(0, 3).padStart(3, \"0\");\n    const microsecondPrecisionDatestring = `${new Date(epoch)\n        .toISOString()\n        .slice(0, -1)}${paddedOrder}Z`;\n    return {\n        dottedOrder: stripNonAlphanumeric(microsecondPrecisionDatestring) + runId,\n        microsecondPrecisionDatestring,\n    };\n}\n/**\n * Baggage header information\n */\nclass Baggage {\n    constructor(metadata, tags, project_name, replicas) {\n        Object.defineProperty(this, \"metadata\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"tags\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"project_name\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"replicas\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.metadata = metadata;\n        this.tags = tags;\n        this.project_name = project_name;\n        this.replicas = replicas;\n    }\n    static fromHeader(value) {\n        const items = value.split(\",\");\n        let metadata = {};\n        let tags = [];\n        let project_name;\n        let replicas;\n        for (const item of items) {\n            const [key, uriValue] = item.split(\"=\");\n            const value = decodeURIComponent(uriValue);\n            if (key === \"langsmith-metadata\") {\n                metadata = JSON.parse(value);\n            }\n            else if (key === \"langsmith-tags\") {\n                tags = value.split(\",\");\n            }\n            else if (key === \"langsmith-project\") {\n                project_name = value;\n            }\n            else if (key === \"langsmith-replicas\") {\n                replicas = JSON.parse(value);\n            }\n        }\n        return new Baggage(metadata, tags, project_name, replicas);\n    }\n    toHeader() {\n        const items = [];\n        if (this.metadata && Object.keys(this.metadata).length > 0) {\n            items.push(`langsmith-metadata=${encodeURIComponent(JSON.stringify(this.metadata))}`);\n        }\n        if (this.tags && this.tags.length > 0) {\n            items.push(`langsmith-tags=${encodeURIComponent(this.tags.join(\",\"))}`);\n        }\n        if (this.project_name) {\n            items.push(`langsmith-project=${encodeURIComponent(this.project_name)}`);\n        }\n        return items.join(\",\");\n    }\n}\nexport class RunTree {\n    constructor(originalConfig) {\n        Object.defineProperty(this, \"id\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"name\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"run_type\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"project_name\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"parent_run\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"parent_run_id\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"child_runs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"start_time\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"end_time\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"extra\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"tags\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"error\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"serialized\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"inputs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"outputs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"reference_example_id\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"events\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"trace_id\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"dotted_order\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"tracingEnabled\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"execution_order\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"child_execution_order\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        /**\n         * Attachments associated with the run.\n         * Each entry is a tuple of [mime_type, bytes]\n         */\n        Object.defineProperty(this, \"attachments\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        /**\n         * Projects to replicate this run to with optional updates.\n         */\n        Object.defineProperty(this, \"replicas\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"_serialized_start_time\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        // If you pass in a run tree directly, return a shallow clone\n        if (isRunTree(originalConfig)) {\n            Object.assign(this, { ...originalConfig });\n            return;\n        }\n        const defaultConfig = RunTree.getDefaultConfig();\n        const { metadata, ...config } = originalConfig;\n        const client = config.client ?? RunTree.getSharedClient();\n        const dedupedMetadata = {\n            ...metadata,\n            ...config?.extra?.metadata,\n        };\n        config.extra = { ...config.extra, metadata: dedupedMetadata };\n        if (\"id\" in config && config.id == null) {\n            delete config.id;\n        }\n        Object.assign(this, { ...defaultConfig, ...config, client });\n        if (!this.trace_id) {\n            if (this.parent_run) {\n                this.trace_id = this.parent_run.trace_id ?? this.id;\n            }\n            else {\n                this.trace_id = this.id;\n            }\n        }\n        this.replicas = _ensureWriteReplicas(this.replicas);\n        this.execution_order ??= 1;\n        this.child_execution_order ??= 1;\n        if (!this.dotted_order) {\n            const { dottedOrder, microsecondPrecisionDatestring } = convertToDottedOrderFormat(this.start_time, this.id, this.execution_order);\n            if (this.parent_run) {\n                this.dotted_order = this.parent_run.dotted_order + \".\" + dottedOrder;\n            }\n            else {\n                this.dotted_order = dottedOrder;\n            }\n            this._serialized_start_time = microsecondPrecisionDatestring;\n        }\n    }\n    set metadata(metadata) {\n        this.extra = {\n            ...this.extra,\n            metadata: {\n                ...this.extra?.metadata,\n                ...metadata,\n            },\n        };\n    }\n    get metadata() {\n        return this.extra?.metadata;\n    }\n    static getDefaultConfig() {\n        return {\n            id: uuid.v4(),\n            run_type: \"chain\",\n            project_name: getDefaultProjectName(),\n            child_runs: [],\n            api_url: getEnvironmentVariable(\"LANGCHAIN_ENDPOINT\") ?? \"http://localhost:1984\",\n            api_key: getEnvironmentVariable(\"LANGCHAIN_API_KEY\"),\n            caller_options: {},\n            start_time: Date.now(),\n            serialized: {},\n            inputs: {},\n            extra: {},\n        };\n    }\n    static getSharedClient() {\n        if (!RunTree.sharedClient) {\n            RunTree.sharedClient = new Client();\n        }\n        return RunTree.sharedClient;\n    }\n    createChild(config) {\n        const child_execution_order = this.child_execution_order + 1;\n        const child = new RunTree({\n            ...config,\n            parent_run: this,\n            project_name: this.project_name,\n            replicas: this.replicas,\n            client: this.client,\n            tracingEnabled: this.tracingEnabled,\n            execution_order: child_execution_order,\n            child_execution_order: child_execution_order,\n        });\n        // Copy context vars over into the new run tree.\n        if (_LC_CONTEXT_VARIABLES_KEY in this) {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            child[_LC_CONTEXT_VARIABLES_KEY] =\n                this[_LC_CONTEXT_VARIABLES_KEY];\n        }\n        const LC_CHILD = Symbol.for(\"lc:child_config\");\n        const presentConfig = config.extra?.[LC_CHILD] ??\n            this.extra[LC_CHILD];\n        // tracing for LangChain is defined by the _parentRunId and runMap of the tracer\n        if (isRunnableConfigLike(presentConfig)) {\n            const newConfig = { ...presentConfig };\n            const callbacks = isCallbackManagerLike(newConfig.callbacks)\n                ? newConfig.callbacks.copy?.()\n                : undefined;\n            if (callbacks) {\n                // update the parent run id\n                Object.assign(callbacks, { _parentRunId: child.id });\n                // only populate if we're in a newer LC.JS version\n                callbacks.handlers\n                    ?.find(isLangChainTracerLike)\n                    ?.updateFromRunTree?.(child);\n                newConfig.callbacks = callbacks;\n            }\n            child.extra[LC_CHILD] = newConfig;\n        }\n        // propagate child_execution_order upwards\n        const visited = new Set();\n        let current = this;\n        while (current != null && !visited.has(current.id)) {\n            visited.add(current.id);\n            current.child_execution_order = Math.max(current.child_execution_order, child_execution_order);\n            current = current.parent_run;\n        }\n        this.child_runs.push(child);\n        return child;\n    }\n    async end(outputs, error, endTime = Date.now(), metadata) {\n        this.outputs = this.outputs ?? outputs;\n        this.error = this.error ?? error;\n        this.end_time = this.end_time ?? endTime;\n        if (metadata && Object.keys(metadata).length > 0) {\n            this.extra = this.extra\n                ? { ...this.extra, metadata: { ...this.extra.metadata, ...metadata } }\n                : { metadata };\n        }\n    }\n    _convertToCreate(run, runtimeEnv, excludeChildRuns = true) {\n        const runExtra = run.extra ?? {};\n        // Avoid overwriting the runtime environment if it's already set\n        if (runExtra?.runtime?.library === undefined) {\n            if (!runExtra.runtime) {\n                runExtra.runtime = {};\n            }\n            if (runtimeEnv) {\n                for (const [k, v] of Object.entries(runtimeEnv)) {\n                    if (!runExtra.runtime[k]) {\n                        runExtra.runtime[k] = v;\n                    }\n                }\n            }\n        }\n        let child_runs;\n        let parent_run_id;\n        if (!excludeChildRuns) {\n            child_runs = run.child_runs.map((child_run) => this._convertToCreate(child_run, runtimeEnv, excludeChildRuns));\n            parent_run_id = undefined;\n        }\n        else {\n            parent_run_id = run.parent_run?.id ?? run.parent_run_id;\n            child_runs = [];\n        }\n        return {\n            id: run.id,\n            name: run.name,\n            start_time: run._serialized_start_time ?? run.start_time,\n            end_time: run.end_time,\n            run_type: run.run_type,\n            reference_example_id: run.reference_example_id,\n            extra: runExtra,\n            serialized: run.serialized,\n            error: run.error,\n            inputs: run.inputs,\n            outputs: run.outputs,\n            session_name: run.project_name,\n            child_runs: child_runs,\n            parent_run_id: parent_run_id,\n            trace_id: run.trace_id,\n            dotted_order: run.dotted_order,\n            tags: run.tags,\n            attachments: run.attachments,\n            events: run.events,\n        };\n    }\n    _remapForProject(projectName, runtimeEnv, excludeChildRuns = true) {\n        const baseRun = this._convertToCreate(this, runtimeEnv, excludeChildRuns);\n        if (projectName === this.project_name) {\n            return baseRun;\n        }\n        // Create a deterministic UUID mapping for this project\n        const createRemappedId = (originalId) => {\n            return uuid.v5(`${originalId}:${projectName}`, uuid.v5.DNS);\n        };\n        // Remap the current run's ID\n        const newId = createRemappedId(baseRun.id);\n        const newTraceId = baseRun.trace_id\n            ? createRemappedId(baseRun.trace_id)\n            : undefined;\n        const newParentRunId = baseRun.parent_run_id\n            ? createRemappedId(baseRun.parent_run_id)\n            : undefined;\n        let newDottedOrder;\n        if (baseRun.dotted_order) {\n            const segments = _parseDottedOrder(baseRun.dotted_order);\n            const rebuilt = [];\n            // Process all segments except the last one\n            for (let i = 0; i < segments.length - 1; i++) {\n                const [timestamp, segmentId] = segments[i];\n                const remappedId = createRemappedId(segmentId);\n                rebuilt.push(timestamp.toISOString().replace(/[-:]/g, \"\").replace(\".\", \"\") +\n                    remappedId);\n            }\n            // Process the last segment with the new run ID\n            const [lastTimestamp] = segments[segments.length - 1];\n            rebuilt.push(lastTimestamp.toISOString().replace(/[-:]/g, \"\").replace(\".\", \"\") +\n                newId);\n            newDottedOrder = rebuilt.join(\".\");\n        }\n        else {\n            newDottedOrder = undefined;\n        }\n        const remappedRun = {\n            ...baseRun,\n            id: newId,\n            trace_id: newTraceId,\n            parent_run_id: newParentRunId,\n            dotted_order: newDottedOrder,\n            session_name: projectName,\n        };\n        return remappedRun;\n    }\n    async postRun(excludeChildRuns = true) {\n        try {\n            const runtimeEnv = getRuntimeEnvironment();\n            if (this.replicas && this.replicas.length > 0) {\n                for (const { projectName, apiKey, apiUrl, workspaceId } of this\n                    .replicas) {\n                    const runCreate = this._remapForProject(projectName ?? this.project_name, runtimeEnv, true);\n                    await this.client.createRun(runCreate, {\n                        apiKey,\n                        apiUrl,\n                        workspaceId,\n                    });\n                }\n            }\n            else {\n                const runCreate = this._convertToCreate(this, runtimeEnv, excludeChildRuns);\n                await this.client.createRun(runCreate);\n            }\n            if (!excludeChildRuns) {\n                warnOnce(\"Posting with excludeChildRuns=false is deprecated and will be removed in a future version.\");\n                for (const childRun of this.child_runs) {\n                    await childRun.postRun(false);\n                }\n            }\n        }\n        catch (error) {\n            console.error(`Error in postRun for run ${this.id}:`, error);\n        }\n    }\n    async patchRun(options) {\n        if (this.replicas && this.replicas.length > 0) {\n            for (const { projectName, apiKey, apiUrl, workspaceId, updates } of this\n                .replicas) {\n                const runData = this._remapForProject(projectName ?? this.project_name);\n                const updatePayload = {\n                    id: runData.id,\n                    outputs: runData.outputs,\n                    error: runData.error,\n                    parent_run_id: runData.parent_run_id,\n                    session_name: runData.session_name,\n                    reference_example_id: runData.reference_example_id,\n                    end_time: runData.end_time,\n                    dotted_order: runData.dotted_order,\n                    trace_id: runData.trace_id,\n                    events: runData.events,\n                    tags: runData.tags,\n                    extra: runData.extra,\n                    attachments: this.attachments,\n                    ...updates,\n                };\n                // Important that inputs is not a key in the run update\n                // if excluded because it will overwrite the run create if the\n                // two operations are merged during batching\n                if (!options?.excludeInputs) {\n                    updatePayload.inputs = runData.inputs;\n                }\n                await this.client.updateRun(runData.id, updatePayload, {\n                    apiKey,\n                    apiUrl,\n                    workspaceId,\n                });\n            }\n        }\n        else {\n            try {\n                const runUpdate = {\n                    end_time: this.end_time,\n                    error: this.error,\n                    outputs: this.outputs,\n                    parent_run_id: this.parent_run?.id ?? this.parent_run_id,\n                    reference_example_id: this.reference_example_id,\n                    extra: this.extra,\n                    events: this.events,\n                    dotted_order: this.dotted_order,\n                    trace_id: this.trace_id,\n                    tags: this.tags,\n                    attachments: this.attachments,\n                    session_name: this.project_name,\n                };\n                // Important that inputs is not a key in the run update\n                // if excluded because it will overwrite the run create if the\n                // two operations are merged during batching\n                if (!options?.excludeInputs) {\n                    runUpdate.inputs = this.inputs;\n                }\n                await this.client.updateRun(this.id, runUpdate);\n            }\n            catch (error) {\n                console.error(`Error in patchRun for run ${this.id}`, error);\n            }\n        }\n    }\n    toJSON() {\n        return this._convertToCreate(this, undefined, false);\n    }\n    /**\n     * Add an event to the run tree.\n     * @param event - A single event or string to add\n     */\n    addEvent(event) {\n        if (!this.events) {\n            this.events = [];\n        }\n        if (typeof event === \"string\") {\n            this.events.push({\n                name: \"event\",\n                time: new Date().toISOString(),\n                message: event,\n            });\n        }\n        else {\n            this.events.push({\n                ...event,\n                time: event.time ?? new Date().toISOString(),\n            });\n        }\n    }\n    static fromRunnableConfig(parentConfig, props) {\n        // We only handle the callback manager case for now\n        const callbackManager = parentConfig?.callbacks;\n        let parentRun;\n        let projectName;\n        let client;\n        let tracingEnabled = isTracingEnabled();\n        if (callbackManager) {\n            const parentRunId = callbackManager?.getParentRunId?.() ?? \"\";\n            const langChainTracer = callbackManager?.handlers?.find((handler) => handler?.name == \"langchain_tracer\");\n            parentRun = langChainTracer?.getRun?.(parentRunId);\n            projectName = langChainTracer?.projectName;\n            client = langChainTracer?.client;\n            tracingEnabled = tracingEnabled || !!langChainTracer;\n        }\n        if (!parentRun) {\n            return new RunTree({\n                ...props,\n                client,\n                tracingEnabled,\n                project_name: projectName,\n            });\n        }\n        const parentRunTree = new RunTree({\n            name: parentRun.name,\n            id: parentRun.id,\n            trace_id: parentRun.trace_id,\n            dotted_order: parentRun.dotted_order,\n            client,\n            tracingEnabled,\n            project_name: projectName,\n            tags: [\n                ...new Set((parentRun?.tags ?? []).concat(parentConfig?.tags ?? [])),\n            ],\n            extra: {\n                metadata: {\n                    ...parentRun?.extra?.metadata,\n                    ...parentConfig?.metadata,\n                },\n            },\n        });\n        return parentRunTree.createChild(props);\n    }\n    static fromDottedOrder(dottedOrder) {\n        return this.fromHeaders({ \"langsmith-trace\": dottedOrder });\n    }\n    static fromHeaders(headers, inheritArgs) {\n        const rawHeaders = \"get\" in headers && typeof headers.get === \"function\"\n            ? {\n                \"langsmith-trace\": headers.get(\"langsmith-trace\"),\n                baggage: headers.get(\"baggage\"),\n            }\n            : headers;\n        const headerTrace = rawHeaders[\"langsmith-trace\"];\n        if (!headerTrace || typeof headerTrace !== \"string\")\n            return undefined;\n        const parentDottedOrder = headerTrace.trim();\n        const parsedDottedOrder = parentDottedOrder.split(\".\").map((part) => {\n            const [strTime, uuid] = part.split(\"Z\");\n            return { strTime, time: Date.parse(strTime + \"Z\"), uuid };\n        });\n        const traceId = parsedDottedOrder[0].uuid;\n        const config = {\n            ...inheritArgs,\n            name: inheritArgs?.[\"name\"] ?? \"parent\",\n            run_type: inheritArgs?.[\"run_type\"] ?? \"chain\",\n            start_time: inheritArgs?.[\"start_time\"] ?? Date.now(),\n            id: parsedDottedOrder.at(-1)?.uuid,\n            trace_id: traceId,\n            dotted_order: parentDottedOrder,\n        };\n        if (rawHeaders[\"baggage\"] && typeof rawHeaders[\"baggage\"] === \"string\") {\n            const baggage = Baggage.fromHeader(rawHeaders[\"baggage\"]);\n            config.metadata = baggage.metadata;\n            config.tags = baggage.tags;\n            config.project_name = baggage.project_name;\n            config.replicas = baggage.replicas;\n        }\n        return new RunTree(config);\n    }\n    toHeaders(headers) {\n        const result = {\n            \"langsmith-trace\": this.dotted_order,\n            baggage: new Baggage(this.extra?.metadata, this.tags, this.project_name, this.replicas).toHeader(),\n        };\n        if (headers) {\n            for (const [key, value] of Object.entries(result)) {\n                headers.set(key, value);\n            }\n        }\n        return result;\n    }\n}\nObject.defineProperty(RunTree, \"sharedClient\", {\n    enumerable: true,\n    configurable: true,\n    writable: true,\n    value: null\n});\nexport function isRunTree(x) {\n    return (x != null &&\n        typeof x.createChild === \"function\" &&\n        typeof x.postRun === \"function\");\n}\nfunction isLangChainTracerLike(x) {\n    return (typeof x === \"object\" &&\n        x != null &&\n        typeof x.name === \"string\" &&\n        x.name === \"langchain_tracer\");\n}\nfunction containsLangChainTracerLike(x) {\n    return (Array.isArray(x) && x.some((callback) => isLangChainTracerLike(callback)));\n}\nfunction isCallbackManagerLike(x) {\n    return (typeof x === \"object\" &&\n        x != null &&\n        Array.isArray(x.handlers));\n}\nexport function isRunnableConfigLike(x) {\n    // Check that it's an object with a callbacks arg\n    // that has either a CallbackManagerLike object with a langchain tracer within it\n    // or an array with a LangChainTracerLike object within it\n    return (x != null &&\n        typeof x.callbacks === \"object\" &&\n        // Callback manager with a langchain tracer\n        (containsLangChainTracerLike(x.callbacks?.handlers) ||\n            // Or it's an array with a LangChainTracerLike object within it\n            containsLangChainTracerLike(x.callbacks)));\n}\nfunction _parseDottedOrder(dottedOrder) {\n    const parts = dottedOrder.split(\".\");\n    return parts.map((part) => {\n        const timestampStr = part.slice(0, -36);\n        const uuidStr = part.slice(-36);\n        // Parse timestamp: \"%Y%m%dT%H%M%S%fZ\" format\n        // Example: \"20231215T143045123456Z\"\n        const year = parseInt(timestampStr.slice(0, 4));\n        const month = parseInt(timestampStr.slice(4, 6)) - 1; // JS months are 0-indexed\n        const day = parseInt(timestampStr.slice(6, 8));\n        const hour = parseInt(timestampStr.slice(9, 11));\n        const minute = parseInt(timestampStr.slice(11, 13));\n        const second = parseInt(timestampStr.slice(13, 15));\n        const microsecond = parseInt(timestampStr.slice(15, 21));\n        const timestamp = new Date(year, month, day, hour, minute, second, microsecond / 1000);\n        return [timestamp, uuidStr];\n    });\n}\nfunction _getWriteReplicasFromEnv() {\n    const envVar = getEnvironmentVariable(\"LANGSMITH_RUNS_ENDPOINTS\");\n    if (!envVar)\n        return [];\n    try {\n        const parsed = JSON.parse(envVar);\n        if (Array.isArray(parsed)) {\n            const replicas = [];\n            for (const item of parsed) {\n                if (typeof item !== \"object\" || item === null) {\n                    console.warn(`Invalid item type in LANGSMITH_RUNS_ENDPOINTS: ` +\n                        `expected object, got ${typeof item}`);\n                    continue;\n                }\n                if (typeof item.api_url !== \"string\") {\n                    console.warn(`Invalid api_url type in LANGSMITH_RUNS_ENDPOINTS: ` +\n                        `expected string, got ${typeof item.api_url}`);\n                    continue;\n                }\n                if (typeof item.api_key !== \"string\") {\n                    console.warn(`Invalid api_key type in LANGSMITH_RUNS_ENDPOINTS: ` +\n                        `expected string, got ${typeof item.api_key}`);\n                    continue;\n                }\n                replicas.push({\n                    apiUrl: item.api_url.replace(/\\/$/, \"\"),\n                    apiKey: item.api_key,\n                });\n            }\n            return replicas;\n        }\n        else if (typeof parsed === \"object\" && parsed !== null) {\n            _checkEndpointEnvUnset(parsed);\n            const replicas = [];\n            for (const [url, key] of Object.entries(parsed)) {\n                const cleanUrl = url.replace(/\\/$/, \"\");\n                if (typeof key === \"string\") {\n                    replicas.push({\n                        apiUrl: cleanUrl,\n                        apiKey: key,\n                    });\n                }\n                else {\n                    console.warn(`Invalid value type in LANGSMITH_RUNS_ENDPOINTS for URL ${url}: ` +\n                        `expected string, got ${typeof key}`);\n                    continue;\n                }\n            }\n            return replicas;\n        }\n        else {\n            console.warn(\"Invalid LANGSMITH_RUNS_ENDPOINTS  must be valid JSON array of \" +\n                `objects with api_url and api_key properties, or object mapping url->apiKey, got ${typeof parsed}`);\n            return [];\n        }\n    }\n    catch (e) {\n        if (isConflictingEndpointsError(e)) {\n            throw e;\n        }\n        console.warn(\"Invalid LANGSMITH_RUNS_ENDPOINTS  must be valid JSON array of \" +\n            \"objects with api_url and api_key properties, or object mapping url->apiKey\");\n        return [];\n    }\n}\nfunction _ensureWriteReplicas(replicas) {\n    // If null -> fetch from env\n    if (replicas) {\n        return replicas.map((replica) => {\n            if (Array.isArray(replica)) {\n                return {\n                    projectName: replica[0],\n                    updates: replica[1],\n                };\n            }\n            return replica;\n        });\n    }\n    return _getWriteReplicasFromEnv();\n}\nfunction _checkEndpointEnvUnset(parsed) {\n    if (Object.keys(parsed).length > 0 &&\n        getLangSmithEnvironmentVariable(\"ENDPOINT\")) {\n        throw new ConflictingEndpointsError();\n    }\n}\n","export * from './dist/run_trees.js'","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { getRuntimeEnvironment } from \"../utils/env.js\";\nimport { BaseCallbackHandler } from \"../callbacks/base.js\";\nimport { RunTree, convertToDottedOrderFormat } from \"langsmith/run_trees\";\n\n//#region src/tracers/base.ts\nvar base_exports = {};\n__export(base_exports, {\n\tBaseTracer: () => BaseTracer,\n\tisBaseTracer: () => isBaseTracer\n});\nconst convertRunTreeToRun = (runTree) => {\n\tif (!runTree) return void 0;\n\trunTree.events = runTree.events ?? [];\n\trunTree.child_runs = runTree.child_runs ?? [];\n\treturn runTree;\n};\nfunction convertRunToRunTree(run, parentRun) {\n\tif (!run) return void 0;\n\treturn new RunTree({\n\t\t...run,\n\t\tstart_time: run._serialized_start_time ?? run.start_time,\n\t\tparent_run: convertRunToRunTree(parentRun),\n\t\tchild_runs: run.child_runs.map((r) => convertRunToRunTree(r)).filter((r) => r !== void 0),\n\t\textra: {\n\t\t\t...run.extra,\n\t\t\truntime: getRuntimeEnvironment()\n\t\t},\n\t\ttracingEnabled: false\n\t});\n}\nfunction _coerceToDict(value, defaultKey) {\n\treturn value && !Array.isArray(value) && typeof value === \"object\" ? value : { [defaultKey]: value };\n}\nfunction isBaseTracer(x) {\n\treturn typeof x._addRunToRunMap === \"function\";\n}\nvar BaseTracer = class extends BaseCallbackHandler {\n\t/** @deprecated Use `runTreeMap` instead. */\n\trunMap = /* @__PURE__ */ new Map();\n\trunTreeMap = /* @__PURE__ */ new Map();\n\tusesRunTreeMap = false;\n\tconstructor(_fields) {\n\t\tsuper(...arguments);\n\t}\n\tcopy() {\n\t\treturn this;\n\t}\n\tgetRunById(runId) {\n\t\tif (runId === void 0) return void 0;\n\t\treturn this.usesRunTreeMap ? convertRunTreeToRun(this.runTreeMap.get(runId)) : this.runMap.get(runId);\n\t}\n\tstringifyError(error) {\n\t\tif (error instanceof Error) return error.message + (error?.stack ? `\\n\\n${error.stack}` : \"\");\n\t\tif (typeof error === \"string\") return error;\n\t\treturn `${error}`;\n\t}\n\t_addChildRun(parentRun, childRun) {\n\t\tparentRun.child_runs.push(childRun);\n\t}\n\t_addRunToRunMap(run) {\n\t\tconst { dottedOrder: currentDottedOrder, microsecondPrecisionDatestring } = convertToDottedOrderFormat(new Date(run.start_time).getTime(), run.id, run.execution_order);\n\t\tconst storedRun = { ...run };\n\t\tconst parentRun = this.getRunById(storedRun.parent_run_id);\n\t\tif (storedRun.parent_run_id !== void 0) {\n\t\t\tif (parentRun) {\n\t\t\t\tthis._addChildRun(parentRun, storedRun);\n\t\t\t\tparentRun.child_execution_order = Math.max(parentRun.child_execution_order, storedRun.child_execution_order);\n\t\t\t\tstoredRun.trace_id = parentRun.trace_id;\n\t\t\t\tif (parentRun.dotted_order !== void 0) {\n\t\t\t\t\tstoredRun.dotted_order = [parentRun.dotted_order, currentDottedOrder].join(\".\");\n\t\t\t\t\tstoredRun._serialized_start_time = microsecondPrecisionDatestring;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tstoredRun.trace_id = storedRun.id;\n\t\t\tstoredRun.dotted_order = currentDottedOrder;\n\t\t\tstoredRun._serialized_start_time = microsecondPrecisionDatestring;\n\t\t}\n\t\tif (this.usesRunTreeMap) {\n\t\t\tconst runTree = convertRunToRunTree(storedRun, parentRun);\n\t\t\tif (runTree !== void 0) this.runTreeMap.set(storedRun.id, runTree);\n\t\t} else this.runMap.set(storedRun.id, storedRun);\n\t\treturn storedRun;\n\t}\n\tasync _endTrace(run) {\n\t\tconst parentRun = run.parent_run_id !== void 0 && this.getRunById(run.parent_run_id);\n\t\tif (parentRun) parentRun.child_execution_order = Math.max(parentRun.child_execution_order, run.child_execution_order);\n\t\telse await this.persistRun(run);\n\t\tawait this.onRunUpdate?.(run);\n\t\tif (this.usesRunTreeMap) this.runTreeMap.delete(run.id);\n\t\telse this.runMap.delete(run.id);\n\t}\n\t_getExecutionOrder(parentRunId) {\n\t\tconst parentRun = parentRunId !== void 0 && this.getRunById(parentRunId);\n\t\tif (!parentRun) return 1;\n\t\treturn parentRun.child_execution_order + 1;\n\t}\n\t/**\n\t* Create and add a run to the run map for LLM start events.\n\t* This must sometimes be done synchronously to avoid race conditions\n\t* when callbacks are backgrounded, so we expose it as a separate method here.\n\t*/\n\t_createRunForLLMStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, name) {\n\t\tconst execution_order = this._getExecutionOrder(parentRunId);\n\t\tconst start_time = Date.now();\n\t\tconst finalExtraParams = metadata ? {\n\t\t\t...extraParams,\n\t\t\tmetadata\n\t\t} : extraParams;\n\t\tconst run = {\n\t\t\tid: runId,\n\t\t\tname: name ?? llm.id[llm.id.length - 1],\n\t\t\tparent_run_id: parentRunId,\n\t\t\tstart_time,\n\t\t\tserialized: llm,\n\t\t\tevents: [{\n\t\t\t\tname: \"start\",\n\t\t\t\ttime: new Date(start_time).toISOString()\n\t\t\t}],\n\t\t\tinputs: { prompts },\n\t\t\texecution_order,\n\t\t\tchild_runs: [],\n\t\t\tchild_execution_order: execution_order,\n\t\t\trun_type: \"llm\",\n\t\t\textra: finalExtraParams ?? {},\n\t\t\ttags: tags || []\n\t\t};\n\t\treturn this._addRunToRunMap(run);\n\t}\n\tasync handleLLMStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, name) {\n\t\tconst run = this.getRunById(runId) ?? this._createRunForLLMStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, name);\n\t\tawait this.onRunCreate?.(run);\n\t\tawait this.onLLMStart?.(run);\n\t\treturn run;\n\t}\n\t/**\n\t* Create and add a run to the run map for chat model start events.\n\t* This must sometimes be done synchronously to avoid race conditions\n\t* when callbacks are backgrounded, so we expose it as a separate method here.\n\t*/\n\t_createRunForChatModelStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, name) {\n\t\tconst execution_order = this._getExecutionOrder(parentRunId);\n\t\tconst start_time = Date.now();\n\t\tconst finalExtraParams = metadata ? {\n\t\t\t...extraParams,\n\t\t\tmetadata\n\t\t} : extraParams;\n\t\tconst run = {\n\t\t\tid: runId,\n\t\t\tname: name ?? llm.id[llm.id.length - 1],\n\t\t\tparent_run_id: parentRunId,\n\t\t\tstart_time,\n\t\t\tserialized: llm,\n\t\t\tevents: [{\n\t\t\t\tname: \"start\",\n\t\t\t\ttime: new Date(start_time).toISOString()\n\t\t\t}],\n\t\t\tinputs: { messages },\n\t\t\texecution_order,\n\t\t\tchild_runs: [],\n\t\t\tchild_execution_order: execution_order,\n\t\t\trun_type: \"llm\",\n\t\t\textra: finalExtraParams ?? {},\n\t\t\ttags: tags || []\n\t\t};\n\t\treturn this._addRunToRunMap(run);\n\t}\n\tasync handleChatModelStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, name) {\n\t\tconst run = this.getRunById(runId) ?? this._createRunForChatModelStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, name);\n\t\tawait this.onRunCreate?.(run);\n\t\tawait this.onLLMStart?.(run);\n\t\treturn run;\n\t}\n\tasync handleLLMEnd(output, runId, _parentRunId, _tags, extraParams) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"llm\") throw new Error(\"No LLM run to end.\");\n\t\trun.end_time = Date.now();\n\t\trun.outputs = output;\n\t\trun.events.push({\n\t\t\tname: \"end\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\trun.extra = {\n\t\t\t...run.extra,\n\t\t\t...extraParams\n\t\t};\n\t\tawait this.onLLMEnd?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\tasync handleLLMError(error, runId, _parentRunId, _tags, extraParams) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"llm\") throw new Error(\"No LLM run to end.\");\n\t\trun.end_time = Date.now();\n\t\trun.error = this.stringifyError(error);\n\t\trun.events.push({\n\t\t\tname: \"error\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\trun.extra = {\n\t\t\t...run.extra,\n\t\t\t...extraParams\n\t\t};\n\t\tawait this.onLLMError?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\t/**\n\t* Create and add a run to the run map for chain start events.\n\t* This must sometimes be done synchronously to avoid race conditions\n\t* when callbacks are backgrounded, so we expose it as a separate method here.\n\t*/\n\t_createRunForChainStart(chain, inputs, runId, parentRunId, tags, metadata, runType, name) {\n\t\tconst execution_order = this._getExecutionOrder(parentRunId);\n\t\tconst start_time = Date.now();\n\t\tconst run = {\n\t\t\tid: runId,\n\t\t\tname: name ?? chain.id[chain.id.length - 1],\n\t\t\tparent_run_id: parentRunId,\n\t\t\tstart_time,\n\t\t\tserialized: chain,\n\t\t\tevents: [{\n\t\t\t\tname: \"start\",\n\t\t\t\ttime: new Date(start_time).toISOString()\n\t\t\t}],\n\t\t\tinputs,\n\t\t\texecution_order,\n\t\t\tchild_execution_order: execution_order,\n\t\t\trun_type: runType ?? \"chain\",\n\t\t\tchild_runs: [],\n\t\t\textra: metadata ? { metadata } : {},\n\t\t\ttags: tags || []\n\t\t};\n\t\treturn this._addRunToRunMap(run);\n\t}\n\tasync handleChainStart(chain, inputs, runId, parentRunId, tags, metadata, runType, name) {\n\t\tconst run = this.getRunById(runId) ?? this._createRunForChainStart(chain, inputs, runId, parentRunId, tags, metadata, runType, name);\n\t\tawait this.onRunCreate?.(run);\n\t\tawait this.onChainStart?.(run);\n\t\treturn run;\n\t}\n\tasync handleChainEnd(outputs, runId, _parentRunId, _tags, kwargs) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run) throw new Error(\"No chain run to end.\");\n\t\trun.end_time = Date.now();\n\t\trun.outputs = _coerceToDict(outputs, \"output\");\n\t\trun.events.push({\n\t\t\tname: \"end\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\tif (kwargs?.inputs !== void 0) run.inputs = _coerceToDict(kwargs.inputs, \"input\");\n\t\tawait this.onChainEnd?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\tasync handleChainError(error, runId, _parentRunId, _tags, kwargs) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run) throw new Error(\"No chain run to end.\");\n\t\trun.end_time = Date.now();\n\t\trun.error = this.stringifyError(error);\n\t\trun.events.push({\n\t\t\tname: \"error\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\tif (kwargs?.inputs !== void 0) run.inputs = _coerceToDict(kwargs.inputs, \"input\");\n\t\tawait this.onChainError?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\t/**\n\t* Create and add a run to the run map for tool start events.\n\t* This must sometimes be done synchronously to avoid race conditions\n\t* when callbacks are backgrounded, so we expose it as a separate method here.\n\t*/\n\t_createRunForToolStart(tool, input, runId, parentRunId, tags, metadata, name) {\n\t\tconst execution_order = this._getExecutionOrder(parentRunId);\n\t\tconst start_time = Date.now();\n\t\tconst run = {\n\t\t\tid: runId,\n\t\t\tname: name ?? tool.id[tool.id.length - 1],\n\t\t\tparent_run_id: parentRunId,\n\t\t\tstart_time,\n\t\t\tserialized: tool,\n\t\t\tevents: [{\n\t\t\t\tname: \"start\",\n\t\t\t\ttime: new Date(start_time).toISOString()\n\t\t\t}],\n\t\t\tinputs: { input },\n\t\t\texecution_order,\n\t\t\tchild_execution_order: execution_order,\n\t\t\trun_type: \"tool\",\n\t\t\tchild_runs: [],\n\t\t\textra: metadata ? { metadata } : {},\n\t\t\ttags: tags || []\n\t\t};\n\t\treturn this._addRunToRunMap(run);\n\t}\n\tasync handleToolStart(tool, input, runId, parentRunId, tags, metadata, name) {\n\t\tconst run = this.getRunById(runId) ?? this._createRunForToolStart(tool, input, runId, parentRunId, tags, metadata, name);\n\t\tawait this.onRunCreate?.(run);\n\t\tawait this.onToolStart?.(run);\n\t\treturn run;\n\t}\n\tasync handleToolEnd(output, runId) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"tool\") throw new Error(\"No tool run to end\");\n\t\trun.end_time = Date.now();\n\t\trun.outputs = { output };\n\t\trun.events.push({\n\t\t\tname: \"end\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\tawait this.onToolEnd?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\tasync handleToolError(error, runId) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"tool\") throw new Error(\"No tool run to end\");\n\t\trun.end_time = Date.now();\n\t\trun.error = this.stringifyError(error);\n\t\trun.events.push({\n\t\t\tname: \"error\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\tawait this.onToolError?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\tasync handleAgentAction(action, runId) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"chain\") return;\n\t\tconst agentRun = run;\n\t\tagentRun.actions = agentRun.actions || [];\n\t\tagentRun.actions.push(action);\n\t\tagentRun.events.push({\n\t\t\tname: \"agent_action\",\n\t\t\ttime: (/* @__PURE__ */ new Date()).toISOString(),\n\t\t\tkwargs: { action }\n\t\t});\n\t\tawait this.onAgentAction?.(run);\n\t}\n\tasync handleAgentEnd(action, runId) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"chain\") return;\n\t\trun.events.push({\n\t\t\tname: \"agent_end\",\n\t\t\ttime: (/* @__PURE__ */ new Date()).toISOString(),\n\t\t\tkwargs: { action }\n\t\t});\n\t\tawait this.onAgentEnd?.(run);\n\t}\n\t/**\n\t* Create and add a run to the run map for retriever start events.\n\t* This must sometimes be done synchronously to avoid race conditions\n\t* when callbacks are backgrounded, so we expose it as a separate method here.\n\t*/\n\t_createRunForRetrieverStart(retriever, query, runId, parentRunId, tags, metadata, name) {\n\t\tconst execution_order = this._getExecutionOrder(parentRunId);\n\t\tconst start_time = Date.now();\n\t\tconst run = {\n\t\t\tid: runId,\n\t\t\tname: name ?? retriever.id[retriever.id.length - 1],\n\t\t\tparent_run_id: parentRunId,\n\t\t\tstart_time,\n\t\t\tserialized: retriever,\n\t\t\tevents: [{\n\t\t\t\tname: \"start\",\n\t\t\t\ttime: new Date(start_time).toISOString()\n\t\t\t}],\n\t\t\tinputs: { query },\n\t\t\texecution_order,\n\t\t\tchild_execution_order: execution_order,\n\t\t\trun_type: \"retriever\",\n\t\t\tchild_runs: [],\n\t\t\textra: metadata ? { metadata } : {},\n\t\t\ttags: tags || []\n\t\t};\n\t\treturn this._addRunToRunMap(run);\n\t}\n\tasync handleRetrieverStart(retriever, query, runId, parentRunId, tags, metadata, name) {\n\t\tconst run = this.getRunById(runId) ?? this._createRunForRetrieverStart(retriever, query, runId, parentRunId, tags, metadata, name);\n\t\tawait this.onRunCreate?.(run);\n\t\tawait this.onRetrieverStart?.(run);\n\t\treturn run;\n\t}\n\tasync handleRetrieverEnd(documents, runId) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"retriever\") throw new Error(\"No retriever run to end\");\n\t\trun.end_time = Date.now();\n\t\trun.outputs = { documents };\n\t\trun.events.push({\n\t\t\tname: \"end\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\tawait this.onRetrieverEnd?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\tasync handleRetrieverError(error, runId) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"retriever\") throw new Error(\"No retriever run to end\");\n\t\trun.end_time = Date.now();\n\t\trun.error = this.stringifyError(error);\n\t\trun.events.push({\n\t\t\tname: \"error\",\n\t\t\ttime: new Date(run.end_time).toISOString()\n\t\t});\n\t\tawait this.onRetrieverError?.(run);\n\t\tawait this._endTrace(run);\n\t\treturn run;\n\t}\n\tasync handleText(text, runId) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"chain\") return;\n\t\trun.events.push({\n\t\t\tname: \"text\",\n\t\t\ttime: (/* @__PURE__ */ new Date()).toISOString(),\n\t\t\tkwargs: { text }\n\t\t});\n\t\tawait this.onText?.(run);\n\t}\n\tasync handleLLMNewToken(token, idx, runId, _parentRunId, _tags, fields) {\n\t\tconst run = this.getRunById(runId);\n\t\tif (!run || run?.run_type !== \"llm\") throw new Error(`Invalid \"runId\" provided to \"handleLLMNewToken\" callback.`);\n\t\trun.events.push({\n\t\t\tname: \"new_token\",\n\t\t\ttime: (/* @__PURE__ */ new Date()).toISOString(),\n\t\t\tkwargs: {\n\t\t\t\ttoken,\n\t\t\t\tidx,\n\t\t\t\tchunk: fields?.chunk\n\t\t\t}\n\t\t});\n\t\tawait this.onLLMNewToken?.(run, token, { chunk: fields?.chunk });\n\t\treturn run;\n\t}\n};\n\n//#endregion\nexport { BaseTracer, base_exports, isBaseTracer };\n//# sourceMappingURL=base.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { BaseTracer } from \"./base.js\";\nimport styles from \"ansi-styles\";\n\n//#region src/tracers/console.ts\nvar console_exports = {};\n__export(console_exports, { ConsoleCallbackHandler: () => ConsoleCallbackHandler });\nfunction wrap(style, text) {\n\treturn `${style.open}${text}${style.close}`;\n}\nfunction tryJsonStringify(obj, fallback) {\n\ttry {\n\t\treturn JSON.stringify(obj, null, 2);\n\t} catch {\n\t\treturn fallback;\n\t}\n}\nfunction formatKVMapItem(value) {\n\tif (typeof value === \"string\") return value.trim();\n\tif (value === null || value === void 0) return value;\n\treturn tryJsonStringify(value, value.toString());\n}\nfunction elapsed(run) {\n\tif (!run.end_time) return \"\";\n\tconst elapsed$1 = run.end_time - run.start_time;\n\tif (elapsed$1 < 1e3) return `${elapsed$1}ms`;\n\treturn `${(elapsed$1 / 1e3).toFixed(2)}s`;\n}\nconst { color } = styles;\n/**\n* A tracer that logs all events to the console. It extends from the\n* `BaseTracer` class and overrides its methods to provide custom logging\n* functionality.\n* @example\n* ```typescript\n*\n* const llm = new ChatAnthropic({\n*   temperature: 0,\n*   tags: [\"example\", \"callbacks\", \"constructor\"],\n*   callbacks: [new ConsoleCallbackHandler()],\n* });\n*\n* ```\n*/\nvar ConsoleCallbackHandler = class extends BaseTracer {\n\tname = \"console_callback_handler\";\n\t/**\n\t* Method used to persist the run. In this case, it simply returns a\n\t* resolved promise as there's no persistence logic.\n\t* @param _run The run to persist.\n\t* @returns A resolved promise.\n\t*/\n\tpersistRun(_run) {\n\t\treturn Promise.resolve();\n\t}\n\t/**\n\t* Method used to get all the parent runs of a given run.\n\t* @param run The run whose parents are to be retrieved.\n\t* @returns An array of parent runs.\n\t*/\n\tgetParents(run) {\n\t\tconst parents = [];\n\t\tlet currentRun = run;\n\t\twhile (currentRun.parent_run_id) {\n\t\t\tconst parent = this.runMap.get(currentRun.parent_run_id);\n\t\t\tif (parent) {\n\t\t\t\tparents.push(parent);\n\t\t\t\tcurrentRun = parent;\n\t\t\t} else break;\n\t\t}\n\t\treturn parents;\n\t}\n\t/**\n\t* Method used to get a string representation of the run's lineage, which\n\t* is used in logging.\n\t* @param run The run whose lineage is to be retrieved.\n\t* @returns A string representation of the run's lineage.\n\t*/\n\tgetBreadcrumbs(run) {\n\t\tconst parents = this.getParents(run).reverse();\n\t\tconst string = [...parents, run].map((parent, i, arr) => {\n\t\t\tconst name = `${parent.execution_order}:${parent.run_type}:${parent.name}`;\n\t\t\treturn i === arr.length - 1 ? wrap(styles.bold, name) : name;\n\t\t}).join(\" > \");\n\t\treturn wrap(color.grey, string);\n\t}\n\t/**\n\t* Method used to log the start of a chain run.\n\t* @param run The chain run that has started.\n\t* @returns void\n\t*/\n\tonChainStart(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.green, \"[chain/start]\")} [${crumbs}] Entering Chain run with input: ${tryJsonStringify(run.inputs, \"[inputs]\")}`);\n\t}\n\t/**\n\t* Method used to log the end of a chain run.\n\t* @param run The chain run that has ended.\n\t* @returns void\n\t*/\n\tonChainEnd(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.cyan, \"[chain/end]\")} [${crumbs}] [${elapsed(run)}] Exiting Chain run with output: ${tryJsonStringify(run.outputs, \"[outputs]\")}`);\n\t}\n\t/**\n\t* Method used to log any errors of a chain run.\n\t* @param run The chain run that has errored.\n\t* @returns void\n\t*/\n\tonChainError(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.red, \"[chain/error]\")} [${crumbs}] [${elapsed(run)}] Chain run errored with error: ${tryJsonStringify(run.error, \"[error]\")}`);\n\t}\n\t/**\n\t* Method used to log the start of an LLM run.\n\t* @param run The LLM run that has started.\n\t* @returns void\n\t*/\n\tonLLMStart(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconst inputs = \"prompts\" in run.inputs ? { prompts: run.inputs.prompts.map((p) => p.trim()) } : run.inputs;\n\t\tconsole.log(`${wrap(color.green, \"[llm/start]\")} [${crumbs}] Entering LLM run with input: ${tryJsonStringify(inputs, \"[inputs]\")}`);\n\t}\n\t/**\n\t* Method used to log the end of an LLM run.\n\t* @param run The LLM run that has ended.\n\t* @returns void\n\t*/\n\tonLLMEnd(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.cyan, \"[llm/end]\")} [${crumbs}] [${elapsed(run)}] Exiting LLM run with output: ${tryJsonStringify(run.outputs, \"[response]\")}`);\n\t}\n\t/**\n\t* Method used to log any errors of an LLM run.\n\t* @param run The LLM run that has errored.\n\t* @returns void\n\t*/\n\tonLLMError(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.red, \"[llm/error]\")} [${crumbs}] [${elapsed(run)}] LLM run errored with error: ${tryJsonStringify(run.error, \"[error]\")}`);\n\t}\n\t/**\n\t* Method used to log the start of a tool run.\n\t* @param run The tool run that has started.\n\t* @returns void\n\t*/\n\tonToolStart(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.green, \"[tool/start]\")} [${crumbs}] Entering Tool run with input: \"${formatKVMapItem(run.inputs.input)}\"`);\n\t}\n\t/**\n\t* Method used to log the end of a tool run.\n\t* @param run The tool run that has ended.\n\t* @returns void\n\t*/\n\tonToolEnd(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.cyan, \"[tool/end]\")} [${crumbs}] [${elapsed(run)}] Exiting Tool run with output: \"${formatKVMapItem(run.outputs?.output)}\"`);\n\t}\n\t/**\n\t* Method used to log any errors of a tool run.\n\t* @param run The tool run that has errored.\n\t* @returns void\n\t*/\n\tonToolError(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.red, \"[tool/error]\")} [${crumbs}] [${elapsed(run)}] Tool run errored with error: ${tryJsonStringify(run.error, \"[error]\")}`);\n\t}\n\t/**\n\t* Method used to log the start of a retriever run.\n\t* @param run The retriever run that has started.\n\t* @returns void\n\t*/\n\tonRetrieverStart(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.green, \"[retriever/start]\")} [${crumbs}] Entering Retriever run with input: ${tryJsonStringify(run.inputs, \"[inputs]\")}`);\n\t}\n\t/**\n\t* Method used to log the end of a retriever run.\n\t* @param run The retriever run that has ended.\n\t* @returns void\n\t*/\n\tonRetrieverEnd(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.cyan, \"[retriever/end]\")} [${crumbs}] [${elapsed(run)}] Exiting Retriever run with output: ${tryJsonStringify(run.outputs, \"[outputs]\")}`);\n\t}\n\t/**\n\t* Method used to log any errors of a retriever run.\n\t* @param run The retriever run that has errored.\n\t* @returns void\n\t*/\n\tonRetrieverError(run) {\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.red, \"[retriever/error]\")} [${crumbs}] [${elapsed(run)}] Retriever run errored with error: ${tryJsonStringify(run.error, \"[error]\")}`);\n\t}\n\t/**\n\t* Method used to log the action selected by the agent.\n\t* @param run The run in which the agent action occurred.\n\t* @returns void\n\t*/\n\tonAgentAction(run) {\n\t\tconst agentRun = run;\n\t\tconst crumbs = this.getBreadcrumbs(run);\n\t\tconsole.log(`${wrap(color.blue, \"[agent/action]\")} [${crumbs}] Agent selected action: ${tryJsonStringify(agentRun.actions[agentRun.actions.length - 1], \"[action]\")}`);\n\t}\n};\n\n//#endregion\nexport { ConsoleCallbackHandler, console_exports };\n//# sourceMappingURL=console.js.map","export * from './dist/index.js'","import { getEnvironmentVariable } from \"../utils/env.js\";\nimport { Client } from \"langsmith\";\n\n//#region src/singletons/tracer.ts\nlet client;\nconst getDefaultLangChainClientSingleton = () => {\n\tif (client === void 0) {\n\t\tconst clientParams = getEnvironmentVariable(\"LANGCHAIN_CALLBACKS_BACKGROUND\") === \"false\" ? { blockOnRootRunFinalization: true } : {};\n\t\tclient = new Client(clientParams);\n\t}\n\treturn client;\n};\n\n//#endregion\nexport { getDefaultLangChainClientSingleton };\n//# sourceMappingURL=tracer.js.map","class MockAsyncLocalStorage {\n    getStore() {\n        return undefined;\n    }\n    run(_, callback) {\n        return callback();\n    }\n}\nconst TRACING_ALS_KEY = Symbol.for(\"ls:tracing_async_local_storage\");\nconst mockAsyncLocalStorage = new MockAsyncLocalStorage();\nclass AsyncLocalStorageProvider {\n    getInstance() {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        return globalThis[TRACING_ALS_KEY] ?? mockAsyncLocalStorage;\n    }\n    initializeGlobalInstance(instance) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        if (globalThis[TRACING_ALS_KEY] === undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            globalThis[TRACING_ALS_KEY] = instance;\n        }\n    }\n}\nexport const AsyncLocalStorageProviderSingleton = new AsyncLocalStorageProvider();\nexport function getCurrentRunTree(permitAbsentRunTree = false) {\n    const runTree = AsyncLocalStorageProviderSingleton.getInstance().getStore();\n    if (!permitAbsentRunTree && runTree === undefined) {\n        throw new Error(\"Could not get the current run tree.\\n\\nPlease make sure you are calling this method within a traceable function and that tracing is enabled.\");\n    }\n    return runTree;\n}\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport function withRunTree(runTree, fn) {\n    const storage = AsyncLocalStorageProviderSingleton.getInstance();\n    return new Promise((resolve, reject) => {\n        storage.run(runTree, () => void Promise.resolve(fn()).then(resolve).catch(reject));\n    });\n}\nexport const ROOT = Symbol.for(\"langsmith:traceable:root\");\nexport function isTraceableFunction(x\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n) {\n    return typeof x === \"function\" && \"langsmith:traceable\" in x;\n}\n","export * from '../dist/singletons/traceable.js'","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { BaseTracer } from \"./base.js\";\nimport { getDefaultLangChainClientSingleton } from \"../singletons/tracer.js\";\nimport { getCurrentRunTree } from \"langsmith/singletons/traceable\";\nimport { RunTree } from \"langsmith/run_trees\";\nimport { getDefaultProjectName } from \"langsmith\";\n\n//#region src/tracers/tracer_langchain.ts\nvar tracer_langchain_exports = {};\n__export(tracer_langchain_exports, { LangChainTracer: () => LangChainTracer });\nvar LangChainTracer = class LangChainTracer extends BaseTracer {\n\tname = \"langchain_tracer\";\n\tprojectName;\n\texampleId;\n\tclient;\n\treplicas;\n\tusesRunTreeMap = true;\n\tconstructor(fields = {}) {\n\t\tsuper(fields);\n\t\tconst { exampleId, projectName, client, replicas } = fields;\n\t\tthis.projectName = projectName ?? getDefaultProjectName();\n\t\tthis.replicas = replicas;\n\t\tthis.exampleId = exampleId;\n\t\tthis.client = client ?? getDefaultLangChainClientSingleton();\n\t\tconst traceableTree = LangChainTracer.getTraceableRunTree();\n\t\tif (traceableTree) this.updateFromRunTree(traceableTree);\n\t}\n\tasync persistRun(_run) {}\n\tasync onRunCreate(run) {\n\t\tconst runTree = this.getRunTreeWithTracingConfig(run.id);\n\t\tawait runTree?.postRun();\n\t}\n\tasync onRunUpdate(run) {\n\t\tconst runTree = this.getRunTreeWithTracingConfig(run.id);\n\t\tawait runTree?.patchRun();\n\t}\n\tgetRun(id) {\n\t\treturn this.runTreeMap.get(id);\n\t}\n\tupdateFromRunTree(runTree) {\n\t\tthis.runTreeMap.set(runTree.id, runTree);\n\t\tlet rootRun = runTree;\n\t\tconst visited = /* @__PURE__ */ new Set();\n\t\twhile (rootRun.parent_run) {\n\t\t\tif (visited.has(rootRun.id)) break;\n\t\t\tvisited.add(rootRun.id);\n\t\t\tif (!rootRun.parent_run) break;\n\t\t\trootRun = rootRun.parent_run;\n\t\t}\n\t\tvisited.clear();\n\t\tconst queue = [rootRun];\n\t\twhile (queue.length > 0) {\n\t\t\tconst current = queue.shift();\n\t\t\tif (!current || visited.has(current.id)) continue;\n\t\t\tvisited.add(current.id);\n\t\t\tthis.runTreeMap.set(current.id, current);\n\t\t\tif (current.child_runs) queue.push(...current.child_runs);\n\t\t}\n\t\tthis.client = runTree.client ?? this.client;\n\t\tthis.replicas = runTree.replicas ?? this.replicas;\n\t\tthis.projectName = runTree.project_name ?? this.projectName;\n\t\tthis.exampleId = runTree.reference_example_id ?? this.exampleId;\n\t}\n\tgetRunTreeWithTracingConfig(id) {\n\t\tconst runTree = this.runTreeMap.get(id);\n\t\tif (!runTree) return void 0;\n\t\treturn new RunTree({\n\t\t\t...runTree,\n\t\t\tclient: this.client,\n\t\t\tproject_name: this.projectName,\n\t\t\treplicas: this.replicas,\n\t\t\treference_example_id: this.exampleId,\n\t\t\ttracingEnabled: true\n\t\t});\n\t}\n\tstatic getTraceableRunTree() {\n\t\ttry {\n\t\t\treturn getCurrentRunTree(true);\n\t\t} catch {\n\t\t\treturn void 0;\n\t\t}\n\t}\n};\n\n//#endregion\nexport { LangChainTracer, tracer_langchain_exports };\n//# sourceMappingURL=tracer_langchain.js.map","import { getDefaultLangChainClientSingleton } from \"./tracer.js\";\nimport { getGlobalAsyncLocalStorageInstance } from \"./async_local_storage/globals.js\";\nimport PQueueMod from \"p-queue\";\n\n//#region src/singletons/callbacks.ts\nlet queue;\n/**\n* Creates a queue using the p-queue library. The queue is configured to\n* auto-start and has a concurrency of 1, meaning it will process tasks\n* one at a time.\n*/\nfunction createQueue() {\n\tconst PQueue = \"default\" in PQueueMod ? PQueueMod.default : PQueueMod;\n\treturn new PQueue({\n\t\tautoStart: true,\n\t\tconcurrency: 1\n\t});\n}\nfunction getQueue() {\n\tif (typeof queue === \"undefined\") queue = createQueue();\n\treturn queue;\n}\n/**\n* Consume a promise, either adding it to the queue or waiting for it to resolve\n* @param promiseFn Promise to consume\n* @param wait Whether to wait for the promise to resolve or resolve immediately\n*/\nasync function consumeCallback(promiseFn, wait) {\n\tif (wait === true) {\n\t\tconst asyncLocalStorageInstance = getGlobalAsyncLocalStorageInstance();\n\t\tif (asyncLocalStorageInstance !== void 0) await asyncLocalStorageInstance.run(void 0, async () => promiseFn());\n\t\telse await promiseFn();\n\t} else {\n\t\tqueue = getQueue();\n\t\tqueue.add(async () => {\n\t\t\tconst asyncLocalStorageInstance = getGlobalAsyncLocalStorageInstance();\n\t\t\tif (asyncLocalStorageInstance !== void 0) await asyncLocalStorageInstance.run(void 0, async () => promiseFn());\n\t\t\telse await promiseFn();\n\t\t});\n\t}\n}\n/**\n* Waits for all promises in the queue to resolve. If the queue is\n* undefined, it immediately resolves a promise.\n*/\nasync function awaitAllCallbacks() {\n\tconst defaultClient = getDefaultLangChainClientSingleton();\n\tawait Promise.allSettled([typeof queue !== \"undefined\" ? queue.onIdle() : Promise.resolve(), defaultClient.awaitPendingTraceBatches()]);\n}\n\n//#endregion\nexport { awaitAllCallbacks, consumeCallback };\n//# sourceMappingURL=callbacks.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { awaitAllCallbacks, consumeCallback } from \"../singletons/callbacks.js\";\n\n//#region src/callbacks/promises.ts\nvar promises_exports = {};\n__export(promises_exports, {\n\tawaitAllCallbacks: () => awaitAllCallbacks,\n\tconsumeCallback: () => consumeCallback\n});\n\n//#endregion\nexport { awaitAllCallbacks, consumeCallback, promises_exports };\n//# sourceMappingURL=promises.js.map","import { getEnvironmentVariable } from \"./env.js\";\n\n//#region src/utils/callbacks.ts\nconst isTracingEnabled = (tracingEnabled) => {\n\tif (tracingEnabled !== void 0) return tracingEnabled;\n\tconst envVars = [\n\t\t\"LANGSMITH_TRACING_V2\",\n\t\t\"LANGCHAIN_TRACING_V2\",\n\t\t\"LANGSMITH_TRACING\",\n\t\t\"LANGCHAIN_TRACING\"\n\t];\n\treturn !!envVars.find((envVar) => getEnvironmentVariable(envVar) === \"true\");\n};\n\n//#endregion\nexport { isTracingEnabled };\n//# sourceMappingURL=callbacks.js.map","import { _CONTEXT_VARIABLES_KEY, getGlobalAsyncLocalStorageInstance } from \"./globals.js\";\nimport { RunTree, isRunTree } from \"langsmith/run_trees\";\n\n//#region src/singletons/async_local_storage/context.ts\n/**\n* Set a context variable. Context variables are scoped to any\n* child runnables called by the current runnable, or globally if set outside\n* of any runnable.\n*\n* @remarks\n* This function is only supported in environments that support AsyncLocalStorage,\n* including Node.js, Deno, and Cloudflare Workers.\n*\n* @example\n* ```ts\n* import { RunnableLambda } from \"@langchain/core/runnables\";\n* import {\n*   getContextVariable,\n*   setContextVariable\n* } from \"@langchain/core/context\";\n*\n* const nested = RunnableLambda.from(() => {\n*   // \"bar\" because it was set by a parent\n*   console.log(getContextVariable(\"foo\"));\n*\n*   // Override to \"baz\", but only for child runnables\n*   setContextVariable(\"foo\", \"baz\");\n*\n*   // Now \"baz\", but only for child runnables\n*   return getContextVariable(\"foo\");\n* });\n*\n* const runnable = RunnableLambda.from(async () => {\n*   // Set a context variable named \"foo\"\n*   setContextVariable(\"foo\", \"bar\");\n*\n*   const res = await nested.invoke({});\n*\n*   // Still \"bar\" since child changes do not affect parents\n*   console.log(getContextVariable(\"foo\"));\n*\n*   return res;\n* });\n*\n* // undefined, because context variable has not been set yet\n* console.log(getContextVariable(\"foo\"));\n*\n* // Final return value is \"baz\"\n* const result = await runnable.invoke({});\n* ```\n*\n* @param name The name of the context variable.\n* @param value The value to set.\n*/\nfunction setContextVariable(name, value) {\n\tconst asyncLocalStorageInstance = getGlobalAsyncLocalStorageInstance();\n\tif (asyncLocalStorageInstance === void 0) throw new Error(`Internal error: Global shared async local storage instance has not been initialized.`);\n\tconst runTree = asyncLocalStorageInstance.getStore();\n\tconst contextVars = { ...runTree?.[_CONTEXT_VARIABLES_KEY] };\n\tcontextVars[name] = value;\n\tlet newValue = {};\n\tif (isRunTree(runTree)) newValue = new RunTree(runTree);\n\tnewValue[_CONTEXT_VARIABLES_KEY] = contextVars;\n\tasyncLocalStorageInstance.enterWith(newValue);\n}\n/**\n* Get the value of a previously set context variable. Context variables\n* are scoped to any child runnables called by the current runnable,\n* or globally if set outside of any runnable.\n*\n* @remarks\n* This function is only supported in environments that support AsyncLocalStorage,\n* including Node.js, Deno, and Cloudflare Workers.\n*\n* @example\n* ```ts\n* import { RunnableLambda } from \"@langchain/core/runnables\";\n* import {\n*   getContextVariable,\n*   setContextVariable\n* } from \"@langchain/core/context\";\n*\n* const nested = RunnableLambda.from(() => {\n*   // \"bar\" because it was set by a parent\n*   console.log(getContextVariable(\"foo\"));\n*\n*   // Override to \"baz\", but only for child runnables\n*   setContextVariable(\"foo\", \"baz\");\n*\n*   // Now \"baz\", but only for child runnables\n*   return getContextVariable(\"foo\");\n* });\n*\n* const runnable = RunnableLambda.from(async () => {\n*   // Set a context variable named \"foo\"\n*   setContextVariable(\"foo\", \"bar\");\n*\n*   const res = await nested.invoke({});\n*\n*   // Still \"bar\" since child changes do not affect parents\n*   console.log(getContextVariable(\"foo\"));\n*\n*   return res;\n* });\n*\n* // undefined, because context variable has not been set yet\n* console.log(getContextVariable(\"foo\"));\n*\n* // Final return value is \"baz\"\n* const result = await runnable.invoke({});\n* ```\n*\n* @param name The name of the context variable.\n*/\nfunction getContextVariable(name) {\n\tconst asyncLocalStorageInstance = getGlobalAsyncLocalStorageInstance();\n\tif (asyncLocalStorageInstance === void 0) return void 0;\n\tconst runTree = asyncLocalStorageInstance.getStore();\n\treturn runTree?.[_CONTEXT_VARIABLES_KEY]?.[name];\n}\nconst LC_CONFIGURE_HOOKS_KEY = Symbol(\"lc:configure_hooks\");\nconst _getConfigureHooks = () => getContextVariable(LC_CONFIGURE_HOOKS_KEY) || [];\n/**\n* Register a callback configure hook to automatically add callback handlers to all runs.\n*\n* There are two ways to use this:\n*\n* 1. Using a context variable:\n*    - Set `contextVar` to specify the variable name\n*    - Use `setContextVariable()` to store your handler instance\n*\n* 2. Using an environment variable:\n*    - Set both `envVar` and `handlerClass`\n*    - The handler will be instantiated when the env var is set to \"true\".\n*\n* @example\n* ```typescript\n* // Method 1: Using context variable\n* import {\n*   registerConfigureHook,\n*   setContextVariable\n* } from \"@langchain/core/context\";\n*\n* const tracer = new MyCallbackHandler();\n* registerConfigureHook({\n*   contextVar: \"my_tracer\",\n* });\n* setContextVariable(\"my_tracer\", tracer);\n*\n* // ...run code here\n*\n* // Method 2: Using environment variable\n* registerConfigureHook({\n*   handlerClass: MyCallbackHandler,\n*   envVar: \"MY_TRACER_ENABLED\",\n* });\n* process.env.MY_TRACER_ENABLED = \"true\";\n*\n* // ...run code here\n* ```\n*\n* @param config Configuration object for the hook\n* @param config.contextVar Name of the context variable containing the handler instance\n* @param config.inheritable Whether child runs should inherit this handler\n* @param config.handlerClass Optional callback handler class (required if using envVar)\n* @param config.envVar Optional environment variable name to control handler activation\n*/\nconst registerConfigureHook = (config) => {\n\tif (config.envVar && !config.handlerClass) throw new Error(\"If envVar is set, handlerClass must also be set to a non-None value.\");\n\tsetContextVariable(LC_CONFIGURE_HOOKS_KEY, [..._getConfigureHooks(), config]);\n};\n\n//#endregion\nexport { _getConfigureHooks, getContextVariable, registerConfigureHook, setContextVariable };\n//# sourceMappingURL=context.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { getBufferString } from \"../messages/utils.js\";\nimport { getEnvironmentVariable } from \"../utils/env.js\";\nimport { BaseCallbackHandler, isBaseCallbackHandler } from \"./base.js\";\nimport { isBaseTracer } from \"../tracers/base.js\";\nimport { ConsoleCallbackHandler } from \"../tracers/console.js\";\nimport { LangChainTracer } from \"../tracers/tracer_langchain.js\";\nimport { consumeCallback } from \"../singletons/callbacks.js\";\nimport \"./promises.js\";\nimport { isTracingEnabled } from \"../utils/callbacks.js\";\nimport { _getConfigureHooks, getContextVariable } from \"../singletons/async_local_storage/context.js\";\nimport { v4 } from \"uuid\";\n\n//#region src/callbacks/manager.ts\nvar manager_exports = {};\n__export(manager_exports, {\n\tBaseCallbackManager: () => BaseCallbackManager,\n\tBaseRunManager: () => BaseRunManager,\n\tCallbackManager: () => CallbackManager,\n\tCallbackManagerForChainRun: () => CallbackManagerForChainRun,\n\tCallbackManagerForLLMRun: () => CallbackManagerForLLMRun,\n\tCallbackManagerForRetrieverRun: () => CallbackManagerForRetrieverRun,\n\tCallbackManagerForToolRun: () => CallbackManagerForToolRun,\n\tensureHandler: () => ensureHandler,\n\tparseCallbackConfigArg: () => parseCallbackConfigArg\n});\nfunction parseCallbackConfigArg(arg) {\n\tif (!arg) return {};\n\telse if (Array.isArray(arg) || \"name\" in arg) return { callbacks: arg };\n\telse return arg;\n}\n/**\n* Manage callbacks from different components of LangChain.\n*/\nvar BaseCallbackManager = class {\n\tsetHandler(handler) {\n\t\treturn this.setHandlers([handler]);\n\t}\n};\n/**\n* Base class for run manager in LangChain.\n*/\nvar BaseRunManager = class {\n\tconstructor(runId, handlers, inheritableHandlers, tags, inheritableTags, metadata, inheritableMetadata, _parentRunId) {\n\t\tthis.runId = runId;\n\t\tthis.handlers = handlers;\n\t\tthis.inheritableHandlers = inheritableHandlers;\n\t\tthis.tags = tags;\n\t\tthis.inheritableTags = inheritableTags;\n\t\tthis.metadata = metadata;\n\t\tthis.inheritableMetadata = inheritableMetadata;\n\t\tthis._parentRunId = _parentRunId;\n\t}\n\tget parentRunId() {\n\t\treturn this._parentRunId;\n\t}\n\tasync handleText(text) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\ttry {\n\t\t\t\tawait handler.handleText?.(text, this.runId, this._parentRunId, this.tags);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleText: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleCustomEvent(eventName, data, _runId, _tags, _metadata) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\ttry {\n\t\t\t\tawait handler.handleCustomEvent?.(eventName, data, this.runId, this.tags, this.metadata);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleCustomEvent: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n};\n/**\n* Manages callbacks for retriever runs.\n*/\nvar CallbackManagerForRetrieverRun = class extends BaseRunManager {\n\tgetChild(tag) {\n\t\tconst manager = new CallbackManager(this.runId);\n\t\tmanager.setHandlers(this.inheritableHandlers);\n\t\tmanager.addTags(this.inheritableTags);\n\t\tmanager.addMetadata(this.inheritableMetadata);\n\t\tif (tag) manager.addTags([tag], false);\n\t\treturn manager;\n\t}\n\tasync handleRetrieverEnd(documents) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreRetriever) try {\n\t\t\t\tawait handler.handleRetrieverEnd?.(documents, this.runId, this._parentRunId, this.tags);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleRetriever`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleRetrieverError(err) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreRetriever) try {\n\t\t\t\tawait handler.handleRetrieverError?.(err, this.runId, this._parentRunId, this.tags);\n\t\t\t} catch (error) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleRetrieverError: ${error}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n};\nvar CallbackManagerForLLMRun = class extends BaseRunManager {\n\tasync handleLLMNewToken(token, idx, _runId, _parentRunId, _tags, fields) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreLLM) try {\n\t\t\t\tawait handler.handleLLMNewToken?.(token, idx ?? {\n\t\t\t\t\tprompt: 0,\n\t\t\t\t\tcompletion: 0\n\t\t\t\t}, this.runId, this._parentRunId, this.tags, fields);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleLLMNewToken: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleLLMError(err, _runId, _parentRunId, _tags, extraParams) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreLLM) try {\n\t\t\t\tawait handler.handleLLMError?.(err, this.runId, this._parentRunId, this.tags, extraParams);\n\t\t\t} catch (err$1) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleLLMError: ${err$1}`);\n\t\t\t\tif (handler.raiseError) throw err$1;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleLLMEnd(output, _runId, _parentRunId, _tags, extraParams) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreLLM) try {\n\t\t\t\tawait handler.handleLLMEnd?.(output, this.runId, this._parentRunId, this.tags, extraParams);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleLLMEnd: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n};\nvar CallbackManagerForChainRun = class extends BaseRunManager {\n\tgetChild(tag) {\n\t\tconst manager = new CallbackManager(this.runId);\n\t\tmanager.setHandlers(this.inheritableHandlers);\n\t\tmanager.addTags(this.inheritableTags);\n\t\tmanager.addMetadata(this.inheritableMetadata);\n\t\tif (tag) manager.addTags([tag], false);\n\t\treturn manager;\n\t}\n\tasync handleChainError(err, _runId, _parentRunId, _tags, kwargs) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreChain) try {\n\t\t\t\tawait handler.handleChainError?.(err, this.runId, this._parentRunId, this.tags, kwargs);\n\t\t\t} catch (err$1) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleChainError: ${err$1}`);\n\t\t\t\tif (handler.raiseError) throw err$1;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleChainEnd(output, _runId, _parentRunId, _tags, kwargs) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreChain) try {\n\t\t\t\tawait handler.handleChainEnd?.(output, this.runId, this._parentRunId, this.tags, kwargs);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleChainEnd: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleAgentAction(action) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreAgent) try {\n\t\t\t\tawait handler.handleAgentAction?.(action, this.runId, this._parentRunId, this.tags);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleAgentAction: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleAgentEnd(action) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreAgent) try {\n\t\t\t\tawait handler.handleAgentEnd?.(action, this.runId, this._parentRunId, this.tags);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleAgentEnd: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n};\nvar CallbackManagerForToolRun = class extends BaseRunManager {\n\tgetChild(tag) {\n\t\tconst manager = new CallbackManager(this.runId);\n\t\tmanager.setHandlers(this.inheritableHandlers);\n\t\tmanager.addTags(this.inheritableTags);\n\t\tmanager.addMetadata(this.inheritableMetadata);\n\t\tif (tag) manager.addTags([tag], false);\n\t\treturn manager;\n\t}\n\tasync handleToolError(err) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreAgent) try {\n\t\t\t\tawait handler.handleToolError?.(err, this.runId, this._parentRunId, this.tags);\n\t\t\t} catch (err$1) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleToolError: ${err$1}`);\n\t\t\t\tif (handler.raiseError) throw err$1;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\tasync handleToolEnd(output) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreAgent) try {\n\t\t\t\tawait handler.handleToolEnd?.(output, this.runId, this._parentRunId, this.tags);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleToolEnd: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n};\n/**\n* @example\n* ```typescript\n* const prompt = PromptTemplate.fromTemplate(\"What is the answer to {question}?\");\n*\n* // Example of using LLMChain with OpenAI and a simple prompt\n* const chain = new LLMChain({\n*   llm: new ChatOpenAI({ model: \"gpt-4o-mini\", temperature: 0.9 }),\n*   prompt,\n* });\n*\n* // Running the chain with a single question\n* const result = await chain.call({\n*   question: \"What is the airspeed velocity of an unladen swallow?\",\n* });\n* console.log(\"The answer is:\", result);\n* ```\n*/\nvar CallbackManager = class CallbackManager extends BaseCallbackManager {\n\thandlers = [];\n\tinheritableHandlers = [];\n\ttags = [];\n\tinheritableTags = [];\n\tmetadata = {};\n\tinheritableMetadata = {};\n\tname = \"callback_manager\";\n\t_parentRunId;\n\tconstructor(parentRunId, options) {\n\t\tsuper();\n\t\tthis.handlers = options?.handlers ?? this.handlers;\n\t\tthis.inheritableHandlers = options?.inheritableHandlers ?? this.inheritableHandlers;\n\t\tthis.tags = options?.tags ?? this.tags;\n\t\tthis.inheritableTags = options?.inheritableTags ?? this.inheritableTags;\n\t\tthis.metadata = options?.metadata ?? this.metadata;\n\t\tthis.inheritableMetadata = options?.inheritableMetadata ?? this.inheritableMetadata;\n\t\tthis._parentRunId = parentRunId;\n\t}\n\t/**\n\t* Gets the parent run ID, if any.\n\t*\n\t* @returns The parent run ID.\n\t*/\n\tgetParentRunId() {\n\t\treturn this._parentRunId;\n\t}\n\tasync handleLLMStart(llm, prompts, runId = void 0, _parentRunId = void 0, extraParams = void 0, _tags = void 0, _metadata = void 0, runName = void 0) {\n\t\treturn Promise.all(prompts.map(async (prompt, idx) => {\n\t\t\tconst runId_ = idx === 0 && runId ? runId : v4();\n\t\t\tawait Promise.all(this.handlers.map((handler) => {\n\t\t\t\tif (handler.ignoreLLM) return;\n\t\t\t\tif (isBaseTracer(handler)) handler._createRunForLLMStart(llm, [prompt], runId_, this._parentRunId, extraParams, this.tags, this.metadata, runName);\n\t\t\t\treturn consumeCallback(async () => {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tawait handler.handleLLMStart?.(llm, [prompt], runId_, this._parentRunId, extraParams, this.tags, this.metadata, runName);\n\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleLLMStart: ${err}`);\n\t\t\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t\t\t}\n\t\t\t\t}, handler.awaitHandlers);\n\t\t\t}));\n\t\t\treturn new CallbackManagerForLLMRun(runId_, this.handlers, this.inheritableHandlers, this.tags, this.inheritableTags, this.metadata, this.inheritableMetadata, this._parentRunId);\n\t\t}));\n\t}\n\tasync handleChatModelStart(llm, messages, runId = void 0, _parentRunId = void 0, extraParams = void 0, _tags = void 0, _metadata = void 0, runName = void 0) {\n\t\treturn Promise.all(messages.map(async (messageGroup, idx) => {\n\t\t\tconst runId_ = idx === 0 && runId ? runId : v4();\n\t\t\tawait Promise.all(this.handlers.map((handler) => {\n\t\t\t\tif (handler.ignoreLLM) return;\n\t\t\t\tif (isBaseTracer(handler)) handler._createRunForChatModelStart(llm, [messageGroup], runId_, this._parentRunId, extraParams, this.tags, this.metadata, runName);\n\t\t\t\treturn consumeCallback(async () => {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tif (handler.handleChatModelStart) await handler.handleChatModelStart?.(llm, [messageGroup], runId_, this._parentRunId, extraParams, this.tags, this.metadata, runName);\n\t\t\t\t\t\telse if (handler.handleLLMStart) {\n\t\t\t\t\t\t\tconst messageString = getBufferString(messageGroup);\n\t\t\t\t\t\t\tawait handler.handleLLMStart?.(llm, [messageString], runId_, this._parentRunId, extraParams, this.tags, this.metadata, runName);\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleLLMStart: ${err}`);\n\t\t\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t\t\t}\n\t\t\t\t}, handler.awaitHandlers);\n\t\t\t}));\n\t\t\treturn new CallbackManagerForLLMRun(runId_, this.handlers, this.inheritableHandlers, this.tags, this.inheritableTags, this.metadata, this.inheritableMetadata, this._parentRunId);\n\t\t}));\n\t}\n\tasync handleChainStart(chain, inputs, runId = v4(), runType = void 0, _tags = void 0, _metadata = void 0, runName = void 0) {\n\t\tawait Promise.all(this.handlers.map((handler) => {\n\t\t\tif (handler.ignoreChain) return;\n\t\t\tif (isBaseTracer(handler)) handler._createRunForChainStart(chain, inputs, runId, this._parentRunId, this.tags, this.metadata, runType, runName);\n\t\t\treturn consumeCallback(async () => {\n\t\t\t\ttry {\n\t\t\t\t\tawait handler.handleChainStart?.(chain, inputs, runId, this._parentRunId, this.tags, this.metadata, runType, runName);\n\t\t\t\t} catch (err) {\n\t\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleChainStart: ${err}`);\n\t\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t\t}\n\t\t\t}, handler.awaitHandlers);\n\t\t}));\n\t\treturn new CallbackManagerForChainRun(runId, this.handlers, this.inheritableHandlers, this.tags, this.inheritableTags, this.metadata, this.inheritableMetadata, this._parentRunId);\n\t}\n\tasync handleToolStart(tool, input, runId = v4(), _parentRunId = void 0, _tags = void 0, _metadata = void 0, runName = void 0) {\n\t\tawait Promise.all(this.handlers.map((handler) => {\n\t\t\tif (handler.ignoreAgent) return;\n\t\t\tif (isBaseTracer(handler)) handler._createRunForToolStart(tool, input, runId, this._parentRunId, this.tags, this.metadata, runName);\n\t\t\treturn consumeCallback(async () => {\n\t\t\t\ttry {\n\t\t\t\t\tawait handler.handleToolStart?.(tool, input, runId, this._parentRunId, this.tags, this.metadata, runName);\n\t\t\t\t} catch (err) {\n\t\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleToolStart: ${err}`);\n\t\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t\t}\n\t\t\t}, handler.awaitHandlers);\n\t\t}));\n\t\treturn new CallbackManagerForToolRun(runId, this.handlers, this.inheritableHandlers, this.tags, this.inheritableTags, this.metadata, this.inheritableMetadata, this._parentRunId);\n\t}\n\tasync handleRetrieverStart(retriever, query, runId = v4(), _parentRunId = void 0, _tags = void 0, _metadata = void 0, runName = void 0) {\n\t\tawait Promise.all(this.handlers.map((handler) => {\n\t\t\tif (handler.ignoreRetriever) return;\n\t\t\tif (isBaseTracer(handler)) handler._createRunForRetrieverStart(retriever, query, runId, this._parentRunId, this.tags, this.metadata, runName);\n\t\t\treturn consumeCallback(async () => {\n\t\t\t\ttry {\n\t\t\t\t\tawait handler.handleRetrieverStart?.(retriever, query, runId, this._parentRunId, this.tags, this.metadata, runName);\n\t\t\t\t} catch (err) {\n\t\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleRetrieverStart: ${err}`);\n\t\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t\t}\n\t\t\t}, handler.awaitHandlers);\n\t\t}));\n\t\treturn new CallbackManagerForRetrieverRun(runId, this.handlers, this.inheritableHandlers, this.tags, this.inheritableTags, this.metadata, this.inheritableMetadata, this._parentRunId);\n\t}\n\tasync handleCustomEvent(eventName, data, runId, _tags, _metadata) {\n\t\tawait Promise.all(this.handlers.map((handler) => consumeCallback(async () => {\n\t\t\tif (!handler.ignoreCustomEvent) try {\n\t\t\t\tawait handler.handleCustomEvent?.(eventName, data, runId, this.tags, this.metadata);\n\t\t\t} catch (err) {\n\t\t\t\tconst logFunction = handler.raiseError ? console.error : console.warn;\n\t\t\t\tlogFunction(`Error in handler ${handler.constructor.name}, handleCustomEvent: ${err}`);\n\t\t\t\tif (handler.raiseError) throw err;\n\t\t\t}\n\t\t}, handler.awaitHandlers)));\n\t}\n\taddHandler(handler, inherit = true) {\n\t\tthis.handlers.push(handler);\n\t\tif (inherit) this.inheritableHandlers.push(handler);\n\t}\n\tremoveHandler(handler) {\n\t\tthis.handlers = this.handlers.filter((_handler) => _handler !== handler);\n\t\tthis.inheritableHandlers = this.inheritableHandlers.filter((_handler) => _handler !== handler);\n\t}\n\tsetHandlers(handlers, inherit = true) {\n\t\tthis.handlers = [];\n\t\tthis.inheritableHandlers = [];\n\t\tfor (const handler of handlers) this.addHandler(handler, inherit);\n\t}\n\taddTags(tags, inherit = true) {\n\t\tthis.removeTags(tags);\n\t\tthis.tags.push(...tags);\n\t\tif (inherit) this.inheritableTags.push(...tags);\n\t}\n\tremoveTags(tags) {\n\t\tthis.tags = this.tags.filter((tag) => !tags.includes(tag));\n\t\tthis.inheritableTags = this.inheritableTags.filter((tag) => !tags.includes(tag));\n\t}\n\taddMetadata(metadata, inherit = true) {\n\t\tthis.metadata = {\n\t\t\t...this.metadata,\n\t\t\t...metadata\n\t\t};\n\t\tif (inherit) this.inheritableMetadata = {\n\t\t\t...this.inheritableMetadata,\n\t\t\t...metadata\n\t\t};\n\t}\n\tremoveMetadata(metadata) {\n\t\tfor (const key of Object.keys(metadata)) {\n\t\t\tdelete this.metadata[key];\n\t\t\tdelete this.inheritableMetadata[key];\n\t\t}\n\t}\n\tcopy(additionalHandlers = [], inherit = true) {\n\t\tconst manager = new CallbackManager(this._parentRunId);\n\t\tfor (const handler of this.handlers) {\n\t\t\tconst inheritable = this.inheritableHandlers.includes(handler);\n\t\t\tmanager.addHandler(handler, inheritable);\n\t\t}\n\t\tfor (const tag of this.tags) {\n\t\t\tconst inheritable = this.inheritableTags.includes(tag);\n\t\t\tmanager.addTags([tag], inheritable);\n\t\t}\n\t\tfor (const key of Object.keys(this.metadata)) {\n\t\t\tconst inheritable = Object.keys(this.inheritableMetadata).includes(key);\n\t\t\tmanager.addMetadata({ [key]: this.metadata[key] }, inheritable);\n\t\t}\n\t\tfor (const handler of additionalHandlers) {\n\t\t\tif (manager.handlers.filter((h) => h.name === \"console_callback_handler\").some((h) => h.name === handler.name)) continue;\n\t\t\tmanager.addHandler(handler, inherit);\n\t\t}\n\t\treturn manager;\n\t}\n\tstatic fromHandlers(handlers) {\n\t\tclass Handler extends BaseCallbackHandler {\n\t\t\tname = v4();\n\t\t\tconstructor() {\n\t\t\t\tsuper();\n\t\t\t\tObject.assign(this, handlers);\n\t\t\t}\n\t\t}\n\t\tconst manager = new this();\n\t\tmanager.addHandler(new Handler());\n\t\treturn manager;\n\t}\n\tstatic configure(inheritableHandlers, localHandlers, inheritableTags, localTags, inheritableMetadata, localMetadata, options) {\n\t\treturn this._configureSync(inheritableHandlers, localHandlers, inheritableTags, localTags, inheritableMetadata, localMetadata, options);\n\t}\n\tstatic _configureSync(inheritableHandlers, localHandlers, inheritableTags, localTags, inheritableMetadata, localMetadata, options) {\n\t\tlet callbackManager;\n\t\tif (inheritableHandlers || localHandlers) {\n\t\t\tif (Array.isArray(inheritableHandlers) || !inheritableHandlers) {\n\t\t\t\tcallbackManager = new CallbackManager();\n\t\t\t\tcallbackManager.setHandlers(inheritableHandlers?.map(ensureHandler) ?? [], true);\n\t\t\t} else callbackManager = inheritableHandlers;\n\t\t\tcallbackManager = callbackManager.copy(Array.isArray(localHandlers) ? localHandlers.map(ensureHandler) : localHandlers?.handlers, false);\n\t\t}\n\t\tconst verboseEnabled = getEnvironmentVariable(\"LANGCHAIN_VERBOSE\") === \"true\" || options?.verbose;\n\t\tconst tracingV2Enabled = LangChainTracer.getTraceableRunTree()?.tracingEnabled || isTracingEnabled();\n\t\tconst tracingEnabled = tracingV2Enabled || (getEnvironmentVariable(\"LANGCHAIN_TRACING\") ?? false);\n\t\tif (verboseEnabled || tracingEnabled) {\n\t\t\tif (!callbackManager) callbackManager = new CallbackManager();\n\t\t\tif (verboseEnabled && !callbackManager.handlers.some((handler) => handler.name === ConsoleCallbackHandler.prototype.name)) {\n\t\t\t\tconst consoleHandler = new ConsoleCallbackHandler();\n\t\t\t\tcallbackManager.addHandler(consoleHandler, true);\n\t\t\t}\n\t\t\tif (tracingEnabled && !callbackManager.handlers.some((handler) => handler.name === \"langchain_tracer\")) {\n\t\t\t\tif (tracingV2Enabled) {\n\t\t\t\t\tconst tracerV2 = new LangChainTracer();\n\t\t\t\t\tcallbackManager.addHandler(tracerV2, true);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (tracingV2Enabled) {\n\t\t\t\tconst implicitRunTree = LangChainTracer.getTraceableRunTree();\n\t\t\t\tif (implicitRunTree && callbackManager._parentRunId === void 0) {\n\t\t\t\t\tcallbackManager._parentRunId = implicitRunTree.id;\n\t\t\t\t\tconst tracerV2 = callbackManager.handlers.find((handler) => handler.name === \"langchain_tracer\");\n\t\t\t\t\ttracerV2?.updateFromRunTree(implicitRunTree);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (const { contextVar, inheritable = true, handlerClass, envVar } of _getConfigureHooks()) {\n\t\t\tconst createIfNotInContext = envVar && getEnvironmentVariable(envVar) === \"true\" && handlerClass;\n\t\t\tlet handler;\n\t\t\tconst contextVarValue = contextVar !== void 0 ? getContextVariable(contextVar) : void 0;\n\t\t\tif (contextVarValue && isBaseCallbackHandler(contextVarValue)) handler = contextVarValue;\n\t\t\telse if (createIfNotInContext) handler = new handlerClass({});\n\t\t\tif (handler !== void 0) {\n\t\t\t\tif (!callbackManager) callbackManager = new CallbackManager();\n\t\t\t\tif (!callbackManager.handlers.some((h) => h.name === handler.name)) callbackManager.addHandler(handler, inheritable);\n\t\t\t}\n\t\t}\n\t\tif (inheritableTags || localTags) {\n\t\t\tif (callbackManager) {\n\t\t\t\tcallbackManager.addTags(inheritableTags ?? []);\n\t\t\t\tcallbackManager.addTags(localTags ?? [], false);\n\t\t\t}\n\t\t}\n\t\tif (inheritableMetadata || localMetadata) {\n\t\t\tif (callbackManager) {\n\t\t\t\tcallbackManager.addMetadata(inheritableMetadata ?? {});\n\t\t\t\tcallbackManager.addMetadata(localMetadata ?? {}, false);\n\t\t\t}\n\t\t}\n\t\treturn callbackManager;\n\t}\n};\nfunction ensureHandler(handler) {\n\tif (\"name\" in handler) return handler;\n\treturn BaseCallbackHandler.fromMethods(handler);\n}\n\n//#endregion\nexport { BaseCallbackManager, BaseRunManager, CallbackManager, CallbackManagerForChainRun, CallbackManagerForLLMRun, CallbackManagerForRetrieverRun, CallbackManagerForToolRun, ensureHandler, manager_exports, parseCallbackConfigArg };\n//# sourceMappingURL=manager.js.map","import { _CONTEXT_VARIABLES_KEY, getGlobalAsyncLocalStorageInstance, setGlobalAsyncLocalStorageInstance } from \"./globals.js\";\nimport { CallbackManager } from \"../../callbacks/manager.js\";\nimport { RunTree } from \"langsmith\";\n\n//#region src/singletons/async_local_storage/index.ts\nvar MockAsyncLocalStorage = class {\n\tgetStore() {\n\t\treturn void 0;\n\t}\n\trun(_store, callback) {\n\t\treturn callback();\n\t}\n\tenterWith(_store) {\n\t\treturn void 0;\n\t}\n};\nconst mockAsyncLocalStorage = new MockAsyncLocalStorage();\nconst LC_CHILD_KEY = Symbol.for(\"lc:child_config\");\nvar AsyncLocalStorageProvider = class {\n\tgetInstance() {\n\t\treturn getGlobalAsyncLocalStorageInstance() ?? mockAsyncLocalStorage;\n\t}\n\tgetRunnableConfig() {\n\t\tconst storage = this.getInstance();\n\t\treturn storage.getStore()?.extra?.[LC_CHILD_KEY];\n\t}\n\trunWithConfig(config, callback, avoidCreatingRootRunTree) {\n\t\tconst callbackManager = CallbackManager._configureSync(config?.callbacks, void 0, config?.tags, void 0, config?.metadata);\n\t\tconst storage = this.getInstance();\n\t\tconst previousValue = storage.getStore();\n\t\tconst parentRunId = callbackManager?.getParentRunId();\n\t\tconst langChainTracer = callbackManager?.handlers?.find((handler) => handler?.name === \"langchain_tracer\");\n\t\tlet runTree;\n\t\tif (langChainTracer && parentRunId) runTree = langChainTracer.getRunTreeWithTracingConfig(parentRunId);\n\t\telse if (!avoidCreatingRootRunTree) runTree = new RunTree({\n\t\t\tname: \"<runnable_lambda>\",\n\t\t\ttracingEnabled: false\n\t\t});\n\t\tif (runTree) runTree.extra = {\n\t\t\t...runTree.extra,\n\t\t\t[LC_CHILD_KEY]: config\n\t\t};\n\t\tif (previousValue !== void 0 && previousValue[_CONTEXT_VARIABLES_KEY] !== void 0) {\n\t\t\tif (runTree === void 0) runTree = {};\n\t\t\trunTree[_CONTEXT_VARIABLES_KEY] = previousValue[_CONTEXT_VARIABLES_KEY];\n\t\t}\n\t\treturn storage.run(runTree, callback);\n\t}\n\tinitializeGlobalInstance(instance) {\n\t\tif (getGlobalAsyncLocalStorageInstance() === void 0) setGlobalAsyncLocalStorageInstance(instance);\n\t}\n};\nconst AsyncLocalStorageProviderSingleton = new AsyncLocalStorageProvider();\n\n//#endregion\nexport { AsyncLocalStorageProviderSingleton, MockAsyncLocalStorage };\n//# sourceMappingURL=index.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { _CONTEXT_VARIABLES_KEY } from \"./async_local_storage/globals.js\";\nimport { AsyncLocalStorageProviderSingleton, MockAsyncLocalStorage } from \"./async_local_storage/index.js\";\n\n//#region src/singletons/index.ts\nvar singletons_exports = {};\n__export(singletons_exports, {\n\tAsyncLocalStorageProviderSingleton: () => AsyncLocalStorageProviderSingleton,\n\tMockAsyncLocalStorage: () => MockAsyncLocalStorage,\n\t_CONTEXT_VARIABLES_KEY: () => _CONTEXT_VARIABLES_KEY\n});\n\n//#endregion\nexport { AsyncLocalStorageProviderSingleton, MockAsyncLocalStorage, _CONTEXT_VARIABLES_KEY, singletons_exports };\n//# sourceMappingURL=index.js.map","const __WEBPACK_NAMESPACE_OBJECT__ = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:async_hooks\");","import { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\nimport { AsyncLocalStorage } from \"node:async_hooks\";\n\n//#region src/setup/async_local_storage.ts\nfunction initializeAsyncLocalStorageSingleton() {\n\tAsyncLocalStorageProviderSingleton.initializeGlobalInstance(new AsyncLocalStorage());\n}\n\n//#endregion\nexport { initializeAsyncLocalStorageSingleton };\n//# sourceMappingURL=async_local_storage.js.map","//#region src/errors.ts\n/** @category Errors */\nvar BaseLangGraphError = class extends Error {\n\tlc_error_code;\n\tconstructor(message, fields) {\n\t\tlet finalMessage = message ?? \"\";\n\t\tif (fields?.lc_error_code) finalMessage = `${finalMessage}\\n\\nTroubleshooting URL: https://docs.langchain.com/oss/javascript/langgraph/${fields.lc_error_code}/\\n`;\n\t\tsuper(finalMessage);\n\t\tthis.lc_error_code = fields?.lc_error_code;\n\t}\n};\nvar GraphBubbleUp = class extends BaseLangGraphError {\n\tget is_bubble_up() {\n\t\treturn true;\n\t}\n};\nvar GraphRecursionError = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"GraphRecursionError\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"GraphRecursionError\";\n\t}\n};\nvar GraphValueError = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"GraphValueError\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"GraphValueError\";\n\t}\n};\nvar GraphInterrupt = class extends GraphBubbleUp {\n\tinterrupts;\n\tconstructor(interrupts, fields) {\n\t\tsuper(JSON.stringify(interrupts, null, 2), fields);\n\t\tthis.name = \"GraphInterrupt\";\n\t\tthis.interrupts = interrupts ?? [];\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"GraphInterrupt\";\n\t}\n};\n/** Raised by a node to interrupt execution. */\nvar NodeInterrupt = class extends GraphInterrupt {\n\tconstructor(message, fields) {\n\t\tsuper([{ value: message }], fields);\n\t\tthis.name = \"NodeInterrupt\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"NodeInterrupt\";\n\t}\n};\nvar ParentCommand = class extends GraphBubbleUp {\n\tcommand;\n\tconstructor(command) {\n\t\tsuper();\n\t\tthis.name = \"ParentCommand\";\n\t\tthis.command = command;\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"ParentCommand\";\n\t}\n};\nfunction isParentCommand(e) {\n\treturn e !== void 0 && e.name === ParentCommand.unminifiable_name;\n}\nfunction isGraphBubbleUp(e) {\n\treturn e !== void 0 && e.is_bubble_up === true;\n}\nfunction isGraphInterrupt(e) {\n\treturn e !== void 0 && [GraphInterrupt.unminifiable_name, NodeInterrupt.unminifiable_name].includes(e.name);\n}\nvar EmptyInputError = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"EmptyInputError\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"EmptyInputError\";\n\t}\n};\nvar EmptyChannelError = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"EmptyChannelError\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"EmptyChannelError\";\n\t}\n};\nvar InvalidUpdateError = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"InvalidUpdateError\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"InvalidUpdateError\";\n\t}\n};\n/**\n* @deprecated This exception type is no longer thrown.\n*/\nvar MultipleSubgraphsError = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"MultipleSubgraphError\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"MultipleSubgraphError\";\n\t}\n};\nvar UnreachableNodeError = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"UnreachableNodeError\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"UnreachableNodeError\";\n\t}\n};\n/**\n* Exception raised when an error occurs in the remote graph.\n*/\nvar RemoteException = class extends BaseLangGraphError {\n\tconstructor(message, fields) {\n\t\tsuper(message, fields);\n\t\tthis.name = \"RemoteException\";\n\t}\n\tstatic get unminifiable_name() {\n\t\treturn \"RemoteException\";\n\t}\n};\n/**\n* Used for subgraph detection.\n*/\nconst getSubgraphsSeenSet = () => {\n\tif (globalThis[Symbol.for(\"LG_CHECKPOINT_SEEN_NS_SET\")] === void 0) globalThis[Symbol.for(\"LG_CHECKPOINT_SEEN_NS_SET\")] = /* @__PURE__ */ new Set();\n\treturn globalThis[Symbol.for(\"LG_CHECKPOINT_SEEN_NS_SET\")];\n};\n\n//#endregion\nexport { BaseLangGraphError, EmptyChannelError, EmptyInputError, GraphBubbleUp, GraphInterrupt, GraphRecursionError, GraphValueError, InvalidUpdateError, MultipleSubgraphsError, NodeInterrupt, ParentCommand, RemoteException, UnreachableNodeError, getSubgraphsSeenSet, isGraphBubbleUp, isGraphInterrupt, isParentCommand };\n//# sourceMappingURL=errors.js.map","import uuid from './dist/index.js';\nexport const v1 = uuid.v1;\nexport const v1ToV6 = uuid.v1ToV6;\nexport const v3 = uuid.v3;\nexport const v4 = uuid.v4;\nexport const v5 = uuid.v5;\nexport const v6 = uuid.v6;\nexport const v6ToV1 = uuid.v6ToV1;\nexport const v7 = uuid.v7;\nexport const NIL = uuid.NIL;\nexport const MAX = uuid.MAX;\nexport const version = uuid.version;\nexport const validate = uuid.validate;\nexport const stringify = uuid.stringify;\nexport const parse = uuid.parse;\n","import { v5, v6 } from \"uuid\";\n\n//#region src/id.ts\nfunction uuid6(clockseq) {\n\treturn v6({ clockseq });\n}\nfunction uuid5(name, namespace) {\n\tconst namespaceBytes = namespace.replace(/-/g, \"\").match(/.{2}/g).map((byte) => parseInt(byte, 16));\n\treturn v5(name, new Uint8Array(namespaceBytes));\n}\n\n//#endregion\nexport { uuid5, uuid6 };\n//# sourceMappingURL=id.js.map","//#region src/serde/types.ts\nconst TASKS = \"__pregel_tasks\";\nconst ERROR = \"__error__\";\nconst SCHEDULED = \"__scheduled__\";\nconst INTERRUPT = \"__interrupt__\";\nconst RESUME = \"__resume__\";\n\n//#endregion\nexport { ERROR, INTERRUPT, RESUME, SCHEDULED, TASKS };\n//# sourceMappingURL=types.js.map","//#region src/serde/utils/fast-safe-stringify/index.ts\nvar LIMIT_REPLACE_NODE = \"[...]\";\nvar CIRCULAR_REPLACE_NODE = \"[Circular]\";\nvar arr = [];\nvar replacerStack = [];\nfunction defaultOptions() {\n\treturn {\n\t\tdepthLimit: Number.MAX_SAFE_INTEGER,\n\t\tedgesLimit: Number.MAX_SAFE_INTEGER\n\t};\n}\nfunction stringify(obj, replacer, spacer, options) {\n\tif (typeof options === \"undefined\") options = defaultOptions();\n\tdecirc(obj, \"\", 0, [], void 0, 0, options);\n\tvar res;\n\ttry {\n\t\tif (replacerStack.length === 0) res = JSON.stringify(obj, replacer, spacer);\n\t\telse res = JSON.stringify(obj, replaceGetterValues(replacer), spacer);\n\t} catch (_) {\n\t\treturn JSON.stringify(\"[unable to serialize, circular reference is too complex to analyze]\");\n\t} finally {\n\t\twhile (arr.length !== 0) {\n\t\t\tvar part = arr.pop();\n\t\t\tif (part.length === 4) Object.defineProperty(part[0], part[1], part[3]);\n\t\t\telse part[0][part[1]] = part[2];\n\t\t}\n\t}\n\treturn res;\n}\nfunction setReplace(replace, val, k, parent) {\n\tvar propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k);\n\tif (propertyDescriptor.get !== void 0) if (propertyDescriptor.configurable) {\n\t\tObject.defineProperty(parent, k, { value: replace });\n\t\tarr.push([\n\t\t\tparent,\n\t\t\tk,\n\t\t\tval,\n\t\t\tpropertyDescriptor\n\t\t]);\n\t} else replacerStack.push([\n\t\tval,\n\t\tk,\n\t\treplace\n\t]);\n\telse {\n\t\tparent[k] = replace;\n\t\tarr.push([\n\t\t\tparent,\n\t\t\tk,\n\t\t\tval\n\t\t]);\n\t}\n}\nfunction decirc(val, k, edgeIndex, stack, parent, depth, options) {\n\tdepth += 1;\n\tvar i;\n\tif (typeof val === \"object\" && val !== null) {\n\t\tfor (i = 0; i < stack.length; i++) if (stack[i] === val) {\n\t\t\tsetReplace(CIRCULAR_REPLACE_NODE, val, k, parent);\n\t\t\treturn;\n\t\t}\n\t\tif (typeof options.depthLimit !== \"undefined\" && depth > options.depthLimit) {\n\t\t\tsetReplace(LIMIT_REPLACE_NODE, val, k, parent);\n\t\t\treturn;\n\t\t}\n\t\tif (typeof options.edgesLimit !== \"undefined\" && edgeIndex + 1 > options.edgesLimit) {\n\t\t\tsetReplace(LIMIT_REPLACE_NODE, val, k, parent);\n\t\t\treturn;\n\t\t}\n\t\tstack.push(val);\n\t\tif (Array.isArray(val)) for (i = 0; i < val.length; i++) decirc(val[i], i, i, stack, val, depth, options);\n\t\telse {\n\t\t\tvar keys = Object.keys(val);\n\t\t\tfor (i = 0; i < keys.length; i++) {\n\t\t\t\tvar key = keys[i];\n\t\t\t\tdecirc(val[key], key, i, stack, val, depth, options);\n\t\t\t}\n\t\t}\n\t\tstack.pop();\n\t}\n}\nfunction replaceGetterValues(replacer) {\n\treplacer = typeof replacer !== \"undefined\" ? replacer : function(k, v) {\n\t\treturn v;\n\t};\n\treturn function(key, val) {\n\t\tif (replacerStack.length > 0) for (var i = 0; i < replacerStack.length; i++) {\n\t\t\tvar part = replacerStack[i];\n\t\t\tif (part[1] === key && part[0] === val) {\n\t\t\t\tval = part[2];\n\t\t\t\treplacerStack.splice(i, 1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\treturn replacer.call(this, key, val);\n\t};\n}\n\n//#endregion\nexport { stringify };\n//# sourceMappingURL=index.js.map","//#region src/load/import_constants.ts\nconst optionalImportEntrypoints = [];\n\n//#endregion\nexport { optionalImportEntrypoints };\n//# sourceMappingURL=import_constants.js.map","//#region src/agents.ts\nvar agents_exports = {};\n\n//#endregion\nexport { agents_exports };\n//# sourceMappingURL=agents.js.map","import { CallbackManager, ensureHandler } from \"../callbacks/manager.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"../singletons/async_local_storage/index.js\";\nimport \"../singletons/index.js\";\n\n//#region src/runnables/config.ts\nconst DEFAULT_RECURSION_LIMIT = 25;\nasync function getCallbackManagerForConfig(config) {\n\treturn CallbackManager._configureSync(config?.callbacks, void 0, config?.tags, void 0, config?.metadata);\n}\nfunction mergeConfigs(...configs) {\n\tconst copy = {};\n\tfor (const options of configs.filter((c) => !!c)) for (const key of Object.keys(options)) if (key === \"metadata\") copy[key] = {\n\t\t...copy[key],\n\t\t...options[key]\n\t};\n\telse if (key === \"tags\") {\n\t\tconst baseKeys = copy[key] ?? [];\n\t\tcopy[key] = [...new Set(baseKeys.concat(options[key] ?? []))];\n\t} else if (key === \"configurable\") copy[key] = {\n\t\t...copy[key],\n\t\t...options[key]\n\t};\n\telse if (key === \"timeout\") {\n\t\tif (copy.timeout === void 0) copy.timeout = options.timeout;\n\t\telse if (options.timeout !== void 0) copy.timeout = Math.min(copy.timeout, options.timeout);\n\t} else if (key === \"signal\") {\n\t\tif (copy.signal === void 0) copy.signal = options.signal;\n\t\telse if (options.signal !== void 0) if (\"any\" in AbortSignal) copy.signal = AbortSignal.any([copy.signal, options.signal]);\n\t\telse copy.signal = options.signal;\n\t} else if (key === \"callbacks\") {\n\t\tconst baseCallbacks = copy.callbacks;\n\t\tconst providedCallbacks = options.callbacks;\n\t\tif (Array.isArray(providedCallbacks)) if (!baseCallbacks) copy.callbacks = providedCallbacks;\n\t\telse if (Array.isArray(baseCallbacks)) copy.callbacks = baseCallbacks.concat(providedCallbacks);\n\t\telse {\n\t\t\tconst manager = baseCallbacks.copy();\n\t\t\tfor (const callback of providedCallbacks) manager.addHandler(ensureHandler(callback), true);\n\t\t\tcopy.callbacks = manager;\n\t\t}\n\t\telse if (providedCallbacks) if (!baseCallbacks) copy.callbacks = providedCallbacks;\n\t\telse if (Array.isArray(baseCallbacks)) {\n\t\t\tconst manager = providedCallbacks.copy();\n\t\t\tfor (const callback of baseCallbacks) manager.addHandler(ensureHandler(callback), true);\n\t\t\tcopy.callbacks = manager;\n\t\t} else copy.callbacks = new CallbackManager(providedCallbacks._parentRunId, {\n\t\t\thandlers: baseCallbacks.handlers.concat(providedCallbacks.handlers),\n\t\t\tinheritableHandlers: baseCallbacks.inheritableHandlers.concat(providedCallbacks.inheritableHandlers),\n\t\t\ttags: Array.from(new Set(baseCallbacks.tags.concat(providedCallbacks.tags))),\n\t\t\tinheritableTags: Array.from(new Set(baseCallbacks.inheritableTags.concat(providedCallbacks.inheritableTags))),\n\t\t\tmetadata: {\n\t\t\t\t...baseCallbacks.metadata,\n\t\t\t\t...providedCallbacks.metadata\n\t\t\t}\n\t\t});\n\t} else {\n\t\tconst typedKey = key;\n\t\tcopy[typedKey] = options[typedKey] ?? copy[typedKey];\n\t}\n\treturn copy;\n}\nconst PRIMITIVES = new Set([\n\t\"string\",\n\t\"number\",\n\t\"boolean\"\n]);\n/**\n* Ensure that a passed config is an object with all required keys present.\n*/\nfunction ensureConfig(config) {\n\tconst implicitConfig = AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tlet empty = {\n\t\ttags: [],\n\t\tmetadata: {},\n\t\trecursionLimit: 25,\n\t\trunId: void 0\n\t};\n\tif (implicitConfig) {\n\t\tconst { runId, runName,...rest } = implicitConfig;\n\t\tempty = Object.entries(rest).reduce((currentConfig, [key, value]) => {\n\t\t\tif (value !== void 0) currentConfig[key] = value;\n\t\t\treturn currentConfig;\n\t\t}, empty);\n\t}\n\tif (config) empty = Object.entries(config).reduce((currentConfig, [key, value]) => {\n\t\tif (value !== void 0) currentConfig[key] = value;\n\t\treturn currentConfig;\n\t}, empty);\n\tif (empty?.configurable) {\n\t\tfor (const key of Object.keys(empty.configurable)) if (PRIMITIVES.has(typeof empty.configurable[key]) && !empty.metadata?.[key]) {\n\t\t\tif (!empty.metadata) empty.metadata = {};\n\t\t\tempty.metadata[key] = empty.configurable[key];\n\t\t}\n\t}\n\tif (empty.timeout !== void 0) {\n\t\tif (empty.timeout <= 0) throw new Error(\"Timeout must be a positive number\");\n\t\tconst timeoutSignal = AbortSignal.timeout(empty.timeout);\n\t\tif (empty.signal !== void 0) {\n\t\t\tif (\"any\" in AbortSignal) empty.signal = AbortSignal.any([empty.signal, timeoutSignal]);\n\t\t} else empty.signal = timeoutSignal;\n\t\tdelete empty.timeout;\n\t}\n\treturn empty;\n}\n/**\n* Helper function that patches runnable configs with updated properties.\n*/\nfunction patchConfig(config = {}, { callbacks, maxConcurrency, recursionLimit, runName, configurable, runId } = {}) {\n\tconst newConfig = ensureConfig(config);\n\tif (callbacks !== void 0) {\n\t\t/**\n\t\t* If we're replacing callbacks we need to unset runName\n\t\t* since that should apply only to the same run as the original callbacks\n\t\t*/\n\t\tdelete newConfig.runName;\n\t\tnewConfig.callbacks = callbacks;\n\t}\n\tif (recursionLimit !== void 0) newConfig.recursionLimit = recursionLimit;\n\tif (maxConcurrency !== void 0) newConfig.maxConcurrency = maxConcurrency;\n\tif (runName !== void 0) newConfig.runName = runName;\n\tif (configurable !== void 0) newConfig.configurable = {\n\t\t...newConfig.configurable,\n\t\t...configurable\n\t};\n\tif (runId !== void 0) delete newConfig.runId;\n\treturn newConfig;\n}\nfunction pickRunnableConfigKeys(config) {\n\treturn config ? {\n\t\tconfigurable: config.configurable,\n\t\trecursionLimit: config.recursionLimit,\n\t\tcallbacks: config.callbacks,\n\t\ttags: config.tags,\n\t\tmetadata: config.metadata,\n\t\tmaxConcurrency: config.maxConcurrency,\n\t\ttimeout: config.timeout,\n\t\tsignal: config.signal\n\t} : void 0;\n}\n\n//#endregion\nexport { DEFAULT_RECURSION_LIMIT, ensureConfig, getCallbackManagerForConfig, mergeConfigs, patchConfig, pickRunnableConfigKeys };\n//# sourceMappingURL=config.js.map","//#region src/utils/signal.ts\n/**\n* Race a promise with an abort signal. If the signal is aborted, the promise will\n* be rejected with the error from the signal. If the promise is rejected, the signal will be aborted.\n*\n* @param promise - The promise to race.\n* @param signal - The abort signal.\n* @returns The result of the promise.\n*/\nasync function raceWithSignal(promise, signal) {\n\tif (signal === void 0) return promise;\n\tlet listener;\n\treturn Promise.race([promise.catch((err) => {\n\t\tif (!signal?.aborted) throw err;\n\t\telse return void 0;\n\t}), new Promise((_, reject) => {\n\t\tlistener = () => {\n\t\t\treject(getAbortSignalError(signal));\n\t\t};\n\t\tsignal.addEventListener(\"abort\", listener);\n\t\tif (signal.aborted) reject(getAbortSignalError(signal));\n\t})]).finally(() => signal.removeEventListener(\"abort\", listener));\n}\n/**\n* Get the error from an abort signal. Since you can set the reason to anything,\n* we have to do some type gymnastics to get a proper error message.\n*\n* @param signal - The abort signal.\n* @returns The error from the abort signal.\n*/\nfunction getAbortSignalError(signal) {\n\tif (signal?.reason instanceof Error) return signal.reason;\n\tif (typeof signal?.reason === \"string\") return new Error(signal.reason);\n\treturn /* @__PURE__ */ new Error(\"Aborted\");\n}\n\n//#endregion\nexport { getAbortSignalError, raceWithSignal };\n//# sourceMappingURL=signal.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"../singletons/async_local_storage/index.js\";\nimport \"../singletons/index.js\";\nimport { pickRunnableConfigKeys } from \"../runnables/config.js\";\nimport { raceWithSignal } from \"./signal.js\";\n\n//#region src/utils/stream.ts\nvar stream_exports = {};\n__export(stream_exports, {\n\tAsyncGeneratorWithSetup: () => AsyncGeneratorWithSetup,\n\tIterableReadableStream: () => IterableReadableStream,\n\tatee: () => atee,\n\tconcat: () => concat,\n\tpipeGeneratorWithSetup: () => pipeGeneratorWithSetup\n});\nvar IterableReadableStream = class IterableReadableStream extends ReadableStream {\n\treader;\n\tensureReader() {\n\t\tif (!this.reader) this.reader = this.getReader();\n\t}\n\tasync next() {\n\t\tthis.ensureReader();\n\t\ttry {\n\t\t\tconst result = await this.reader.read();\n\t\t\tif (result.done) {\n\t\t\t\tthis.reader.releaseLock();\n\t\t\t\treturn {\n\t\t\t\t\tdone: true,\n\t\t\t\t\tvalue: void 0\n\t\t\t\t};\n\t\t\t} else return {\n\t\t\t\tdone: false,\n\t\t\t\tvalue: result.value\n\t\t\t};\n\t\t} catch (e) {\n\t\t\tthis.reader.releaseLock();\n\t\t\tthrow e;\n\t\t}\n\t}\n\tasync return() {\n\t\tthis.ensureReader();\n\t\tif (this.locked) {\n\t\t\tconst cancelPromise = this.reader.cancel();\n\t\t\tthis.reader.releaseLock();\n\t\t\tawait cancelPromise;\n\t\t}\n\t\treturn {\n\t\t\tdone: true,\n\t\t\tvalue: void 0\n\t\t};\n\t}\n\tasync throw(e) {\n\t\tthis.ensureReader();\n\t\tif (this.locked) {\n\t\t\tconst cancelPromise = this.reader.cancel();\n\t\t\tthis.reader.releaseLock();\n\t\t\tawait cancelPromise;\n\t\t}\n\t\tthrow e;\n\t}\n\t[Symbol.asyncIterator]() {\n\t\treturn this;\n\t}\n\tasync [Symbol.asyncDispose]() {\n\t\tawait this.return();\n\t}\n\tstatic fromReadableStream(stream) {\n\t\tconst reader = stream.getReader();\n\t\treturn new IterableReadableStream({\n\t\t\tstart(controller) {\n\t\t\t\treturn pump();\n\t\t\t\tfunction pump() {\n\t\t\t\t\treturn reader.read().then(({ done, value }) => {\n\t\t\t\t\t\tif (done) {\n\t\t\t\t\t\t\tcontroller.close();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontroller.enqueue(value);\n\t\t\t\t\t\treturn pump();\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t},\n\t\t\tcancel() {\n\t\t\t\treader.releaseLock();\n\t\t\t}\n\t\t});\n\t}\n\tstatic fromAsyncGenerator(generator) {\n\t\treturn new IterableReadableStream({\n\t\t\tasync pull(controller) {\n\t\t\t\tconst { value, done } = await generator.next();\n\t\t\t\tif (done) controller.close();\n\t\t\t\tcontroller.enqueue(value);\n\t\t\t},\n\t\t\tasync cancel(reason) {\n\t\t\t\tawait generator.return(reason);\n\t\t\t}\n\t\t});\n\t}\n};\nfunction atee(iter, length = 2) {\n\tconst buffers = Array.from({ length }, () => []);\n\treturn buffers.map(async function* makeIter(buffer) {\n\t\twhile (true) if (buffer.length === 0) {\n\t\t\tconst result = await iter.next();\n\t\t\tfor (const buffer$1 of buffers) buffer$1.push(result);\n\t\t} else if (buffer[0].done) return;\n\t\telse yield buffer.shift().value;\n\t});\n}\nfunction concat(first, second) {\n\tif (Array.isArray(first) && Array.isArray(second)) return first.concat(second);\n\telse if (typeof first === \"string\" && typeof second === \"string\") return first + second;\n\telse if (typeof first === \"number\" && typeof second === \"number\") return first + second;\n\telse if (\"concat\" in first && typeof first.concat === \"function\") return first.concat(second);\n\telse if (typeof first === \"object\" && typeof second === \"object\") {\n\t\tconst chunk = { ...first };\n\t\tfor (const [key, value] of Object.entries(second)) if (key in chunk && !Array.isArray(chunk[key])) chunk[key] = concat(chunk[key], value);\n\t\telse chunk[key] = value;\n\t\treturn chunk;\n\t} else throw new Error(`Cannot concat ${typeof first} and ${typeof second}`);\n}\nvar AsyncGeneratorWithSetup = class {\n\tgenerator;\n\tsetup;\n\tconfig;\n\tsignal;\n\tfirstResult;\n\tfirstResultUsed = false;\n\tconstructor(params) {\n\t\tthis.generator = params.generator;\n\t\tthis.config = params.config;\n\t\tthis.signal = params.signal ?? this.config?.signal;\n\t\tthis.setup = new Promise((resolve, reject) => {\n\t\t\tAsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(params.config), async () => {\n\t\t\t\tthis.firstResult = params.generator.next();\n\t\t\t\tif (params.startSetup) this.firstResult.then(params.startSetup).then(resolve, reject);\n\t\t\t\telse this.firstResult.then((_result) => resolve(void 0), reject);\n\t\t\t}, true);\n\t\t});\n\t}\n\tasync next(...args) {\n\t\tthis.signal?.throwIfAborted();\n\t\tif (!this.firstResultUsed) {\n\t\t\tthis.firstResultUsed = true;\n\t\t\treturn this.firstResult;\n\t\t}\n\t\treturn AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(this.config), this.signal ? async () => {\n\t\t\treturn raceWithSignal(this.generator.next(...args), this.signal);\n\t\t} : async () => {\n\t\t\treturn this.generator.next(...args);\n\t\t}, true);\n\t}\n\tasync return(value) {\n\t\treturn this.generator.return(value);\n\t}\n\tasync throw(e) {\n\t\treturn this.generator.throw(e);\n\t}\n\t[Symbol.asyncIterator]() {\n\t\treturn this;\n\t}\n\tasync [Symbol.asyncDispose]() {\n\t\tawait this.return();\n\t}\n};\nasync function pipeGeneratorWithSetup(to, generator, startSetup, signal, ...args) {\n\tconst gen = new AsyncGeneratorWithSetup({\n\t\tgenerator,\n\t\tstartSetup,\n\t\tsignal\n\t});\n\tconst setup = await gen.setup;\n\treturn {\n\t\toutput: to(gen, setup, ...args),\n\t\tsetup\n\t};\n}\n\n//#endregion\nexport { AsyncGeneratorWithSetup, IterableReadableStream, atee, concat, pipeGeneratorWithSetup, stream_exports };\n//# sourceMappingURL=stream.js.map","//#region src/utils/fast-json-patch/src/helpers.ts\n/*!\n* https://github.com/Starcounter-Jack/JSON-Patch\n* (c) 2017-2022 Joachim Wester\n* MIT licensed\n*/\nconst _hasOwnProperty = Object.prototype.hasOwnProperty;\nfunction hasOwnProperty(obj, key) {\n\treturn _hasOwnProperty.call(obj, key);\n}\nfunction _objectKeys(obj) {\n\tif (Array.isArray(obj)) {\n\t\tconst keys$1 = new Array(obj.length);\n\t\tfor (let k = 0; k < keys$1.length; k++) keys$1[k] = \"\" + k;\n\t\treturn keys$1;\n\t}\n\tif (Object.keys) return Object.keys(obj);\n\tlet keys = [];\n\tfor (let i in obj) if (hasOwnProperty(obj, i)) keys.push(i);\n\treturn keys;\n}\n/**\n* Deeply clone the object.\n* https://jsperf.com/deep-copy-vs-json-stringify-json-parse/25 (recursiveDeepCopy)\n* @param  {any} obj value to clone\n* @return {any} cloned obj\n*/\nfunction _deepClone(obj) {\n\tswitch (typeof obj) {\n\t\tcase \"object\": return JSON.parse(JSON.stringify(obj));\n\t\tcase \"undefined\": return null;\n\t\tdefault: return obj;\n\t}\n}\nfunction isInteger(str) {\n\tlet i = 0;\n\tconst len = str.length;\n\tlet charCode;\n\twhile (i < len) {\n\t\tcharCode = str.charCodeAt(i);\n\t\tif (charCode >= 48 && charCode <= 57) {\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\t\treturn false;\n\t}\n\treturn true;\n}\n/**\n* Escapes a json pointer path\n* @param path The raw pointer\n* @return the Escaped path\n*/\nfunction escapePathComponent(path) {\n\tif (path.indexOf(\"/\") === -1 && path.indexOf(\"~\") === -1) return path;\n\treturn path.replace(/~/g, \"~0\").replace(/\\//g, \"~1\");\n}\n/**\n* Unescapes a json pointer path\n* @param path The escaped pointer\n* @return The unescaped path\n*/\nfunction unescapePathComponent(path) {\n\treturn path.replace(/~1/g, \"/\").replace(/~0/g, \"~\");\n}\n/**\n* Recursively checks whether an object has any undefined values inside.\n*/\nfunction hasUndefined(obj) {\n\tif (obj === void 0) return true;\n\tif (obj) {\n\t\tif (Array.isArray(obj)) {\n\t\t\tfor (let i$1 = 0, len = obj.length; i$1 < len; i$1++) if (hasUndefined(obj[i$1])) return true;\n\t\t} else if (typeof obj === \"object\") {\n\t\t\tconst objKeys = _objectKeys(obj);\n\t\t\tconst objKeysLength = objKeys.length;\n\t\t\tfor (var i = 0; i < objKeysLength; i++) if (hasUndefined(obj[objKeys[i]])) return true;\n\t\t}\n\t}\n\treturn false;\n}\nfunction patchErrorMessageFormatter(message, args) {\n\tconst messageParts = [message];\n\tfor (const key in args) {\n\t\tconst value = typeof args[key] === \"object\" ? JSON.stringify(args[key], null, 2) : args[key];\n\t\tif (typeof value !== \"undefined\") messageParts.push(`${key}: ${value}`);\n\t}\n\treturn messageParts.join(\"\\n\");\n}\nvar PatchError = class extends Error {\n\tconstructor(message, name, index, operation, tree) {\n\t\tsuper(patchErrorMessageFormatter(message, {\n\t\t\tname,\n\t\t\tindex,\n\t\t\toperation,\n\t\t\ttree\n\t\t}));\n\t\tthis.name = name;\n\t\tthis.index = index;\n\t\tthis.operation = operation;\n\t\tthis.tree = tree;\n\t\tObject.setPrototypeOf(this, new.target.prototype);\n\t\tthis.message = patchErrorMessageFormatter(message, {\n\t\t\tname,\n\t\t\tindex,\n\t\t\toperation,\n\t\t\ttree\n\t\t});\n\t}\n};\n\n//#endregion\nexport { PatchError, _deepClone, _objectKeys, escapePathComponent, hasOwnProperty, hasUndefined, isInteger, unescapePathComponent };\n//# sourceMappingURL=helpers.js.map","import { __export } from \"../../../_virtual/rolldown_runtime.js\";\nimport { PatchError, _deepClone, hasUndefined, isInteger, unescapePathComponent } from \"./helpers.js\";\n\n//#region src/utils/fast-json-patch/src/core.ts\nvar core_exports = {};\n__export(core_exports, {\n\tJsonPatchError: () => JsonPatchError,\n\t_areEquals: () => _areEquals,\n\tapplyOperation: () => applyOperation,\n\tapplyPatch: () => applyPatch,\n\tapplyReducer: () => applyReducer,\n\tdeepClone: () => deepClone,\n\tgetValueByPointer: () => getValueByPointer,\n\tvalidate: () => validate,\n\tvalidator: () => validator\n});\nconst JsonPatchError = PatchError;\nconst deepClone = _deepClone;\nconst objOps = {\n\tadd: function(obj, key, document) {\n\t\tobj[key] = this.value;\n\t\treturn { newDocument: document };\n\t},\n\tremove: function(obj, key, document) {\n\t\tvar removed = obj[key];\n\t\tdelete obj[key];\n\t\treturn {\n\t\t\tnewDocument: document,\n\t\t\tremoved\n\t\t};\n\t},\n\treplace: function(obj, key, document) {\n\t\tvar removed = obj[key];\n\t\tobj[key] = this.value;\n\t\treturn {\n\t\t\tnewDocument: document,\n\t\t\tremoved\n\t\t};\n\t},\n\tmove: function(obj, key, document) {\n\t\tlet removed = getValueByPointer(document, this.path);\n\t\tif (removed) removed = _deepClone(removed);\n\t\tconst originalValue = applyOperation(document, {\n\t\t\top: \"remove\",\n\t\t\tpath: this.from\n\t\t}).removed;\n\t\tapplyOperation(document, {\n\t\t\top: \"add\",\n\t\t\tpath: this.path,\n\t\t\tvalue: originalValue\n\t\t});\n\t\treturn {\n\t\t\tnewDocument: document,\n\t\t\tremoved\n\t\t};\n\t},\n\tcopy: function(obj, key, document) {\n\t\tconst valueToCopy = getValueByPointer(document, this.from);\n\t\tapplyOperation(document, {\n\t\t\top: \"add\",\n\t\t\tpath: this.path,\n\t\t\tvalue: _deepClone(valueToCopy)\n\t\t});\n\t\treturn { newDocument: document };\n\t},\n\ttest: function(obj, key, document) {\n\t\treturn {\n\t\t\tnewDocument: document,\n\t\t\ttest: _areEquals(obj[key], this.value)\n\t\t};\n\t},\n\t_get: function(obj, key, document) {\n\t\tthis.value = obj[key];\n\t\treturn { newDocument: document };\n\t}\n};\nvar arrOps = {\n\tadd: function(arr, i, document) {\n\t\tif (isInteger(i)) arr.splice(i, 0, this.value);\n\t\telse arr[i] = this.value;\n\t\treturn {\n\t\t\tnewDocument: document,\n\t\t\tindex: i\n\t\t};\n\t},\n\tremove: function(arr, i, document) {\n\t\tvar removedList = arr.splice(i, 1);\n\t\treturn {\n\t\t\tnewDocument: document,\n\t\t\tremoved: removedList[0]\n\t\t};\n\t},\n\treplace: function(arr, i, document) {\n\t\tvar removed = arr[i];\n\t\tarr[i] = this.value;\n\t\treturn {\n\t\t\tnewDocument: document,\n\t\t\tremoved\n\t\t};\n\t},\n\tmove: objOps.move,\n\tcopy: objOps.copy,\n\ttest: objOps.test,\n\t_get: objOps._get\n};\n/**\n* Retrieves a value from a JSON document by a JSON pointer.\n* Returns the value.\n*\n* @param document The document to get the value from\n* @param pointer an escaped JSON pointer\n* @return The retrieved value\n*/\nfunction getValueByPointer(document, pointer) {\n\tif (pointer == \"\") return document;\n\tvar getOriginalDestination = {\n\t\top: \"_get\",\n\t\tpath: pointer\n\t};\n\tapplyOperation(document, getOriginalDestination);\n\treturn getOriginalDestination.value;\n}\n/**\n* Apply a single JSON Patch Operation on a JSON document.\n* Returns the {newDocument, result} of the operation.\n* It modifies the `document` and `operation` objects - it gets the values by reference.\n* If you would like to avoid touching your values, clone them:\n* `jsonpatch.applyOperation(document, jsonpatch._deepClone(operation))`.\n*\n* @param document The document to patch\n* @param operation The operation to apply\n* @param validateOperation `false` is without validation, `true` to use default jsonpatch's validation, or you can pass a `validateOperation` callback to be used for validation.\n* @param mutateDocument Whether to mutate the original document or clone it before applying\n* @param banPrototypeModifications Whether to ban modifications to `__proto__`, defaults to `true`.\n* @return `{newDocument, result}` after the operation\n*/\nfunction applyOperation(document, operation, validateOperation = false, mutateDocument = true, banPrototypeModifications = true, index = 0) {\n\tif (validateOperation) if (typeof validateOperation == \"function\") validateOperation(operation, 0, document, operation.path);\n\telse validator(operation, 0);\n\tif (operation.path === \"\") {\n\t\tlet returnValue = { newDocument: document };\n\t\tif (operation.op === \"add\") {\n\t\t\treturnValue.newDocument = operation.value;\n\t\t\treturn returnValue;\n\t\t} else if (operation.op === \"replace\") {\n\t\t\treturnValue.newDocument = operation.value;\n\t\t\treturnValue.removed = document;\n\t\t\treturn returnValue;\n\t\t} else if (operation.op === \"move\" || operation.op === \"copy\") {\n\t\t\treturnValue.newDocument = getValueByPointer(document, operation.from);\n\t\t\tif (operation.op === \"move\") returnValue.removed = document;\n\t\t\treturn returnValue;\n\t\t} else if (operation.op === \"test\") {\n\t\t\treturnValue.test = _areEquals(document, operation.value);\n\t\t\tif (returnValue.test === false) throw new JsonPatchError(\"Test operation failed\", \"TEST_OPERATION_FAILED\", index, operation, document);\n\t\t\treturnValue.newDocument = document;\n\t\t\treturn returnValue;\n\t\t} else if (operation.op === \"remove\") {\n\t\t\treturnValue.removed = document;\n\t\t\treturnValue.newDocument = null;\n\t\t\treturn returnValue;\n\t\t} else if (operation.op === \"_get\") {\n\t\t\toperation.value = document;\n\t\t\treturn returnValue;\n\t\t} else if (validateOperation) throw new JsonPatchError(\"Operation `op` property is not one of operations defined in RFC-6902\", \"OPERATION_OP_INVALID\", index, operation, document);\n\t\telse return returnValue;\n\t} else {\n\t\tif (!mutateDocument) document = _deepClone(document);\n\t\tconst path = operation.path || \"\";\n\t\tconst keys = path.split(\"/\");\n\t\tlet obj = document;\n\t\tlet t = 1;\n\t\tlet len = keys.length;\n\t\tlet existingPathFragment = void 0;\n\t\tlet key;\n\t\tlet validateFunction;\n\t\tif (typeof validateOperation == \"function\") validateFunction = validateOperation;\n\t\telse validateFunction = validator;\n\t\twhile (true) {\n\t\t\tkey = keys[t];\n\t\t\tif (key && key.indexOf(\"~\") != -1) key = unescapePathComponent(key);\n\t\t\tif (banPrototypeModifications && (key == \"__proto__\" || key == \"prototype\" && t > 0 && keys[t - 1] == \"constructor\")) throw new TypeError(\"JSON-Patch: modifying `__proto__` or `constructor/prototype` prop is banned for security reasons, if this was on purpose, please set `banPrototypeModifications` flag false and pass it to this function. More info in fast-json-patch README\");\n\t\t\tif (validateOperation) {\n\t\t\t\tif (existingPathFragment === void 0) {\n\t\t\t\t\tif (obj[key] === void 0) existingPathFragment = keys.slice(0, t).join(\"/\");\n\t\t\t\t\telse if (t == len - 1) existingPathFragment = operation.path;\n\t\t\t\t\tif (existingPathFragment !== void 0) validateFunction(operation, 0, document, existingPathFragment);\n\t\t\t\t}\n\t\t\t}\n\t\t\tt++;\n\t\t\tif (Array.isArray(obj)) {\n\t\t\t\tif (key === \"-\") key = obj.length;\n\t\t\t\telse if (validateOperation && !isInteger(key)) throw new JsonPatchError(\"Expected an unsigned base-10 integer value, making the new referenced value the array element with the zero-based index\", \"OPERATION_PATH_ILLEGAL_ARRAY_INDEX\", index, operation, document);\n\t\t\t\telse if (isInteger(key)) key = ~~key;\n\t\t\t\tif (t >= len) {\n\t\t\t\t\tif (validateOperation && operation.op === \"add\" && key > obj.length) throw new JsonPatchError(\"The specified index MUST NOT be greater than the number of elements in the array\", \"OPERATION_VALUE_OUT_OF_BOUNDS\", index, operation, document);\n\t\t\t\t\tconst returnValue = arrOps[operation.op].call(operation, obj, key, document);\n\t\t\t\t\tif (returnValue.test === false) throw new JsonPatchError(\"Test operation failed\", \"TEST_OPERATION_FAILED\", index, operation, document);\n\t\t\t\t\treturn returnValue;\n\t\t\t\t}\n\t\t\t} else if (t >= len) {\n\t\t\t\tconst returnValue = objOps[operation.op].call(operation, obj, key, document);\n\t\t\t\tif (returnValue.test === false) throw new JsonPatchError(\"Test operation failed\", \"TEST_OPERATION_FAILED\", index, operation, document);\n\t\t\t\treturn returnValue;\n\t\t\t}\n\t\t\tobj = obj[key];\n\t\t\tif (validateOperation && t < len && (!obj || typeof obj !== \"object\")) throw new JsonPatchError(\"Cannot perform operation at the desired path\", \"OPERATION_PATH_UNRESOLVABLE\", index, operation, document);\n\t\t}\n\t}\n}\n/**\n* Apply a full JSON Patch array on a JSON document.\n* Returns the {newDocument, result} of the patch.\n* It modifies the `document` object and `patch` - it gets the values by reference.\n* If you would like to avoid touching your values, clone them:\n* `jsonpatch.applyPatch(document, jsonpatch._deepClone(patch))`.\n*\n* @param document The document to patch\n* @param patch The patch to apply\n* @param validateOperation `false` is without validation, `true` to use default jsonpatch's validation, or you can pass a `validateOperation` callback to be used for validation.\n* @param mutateDocument Whether to mutate the original document or clone it before applying\n* @param banPrototypeModifications Whether to ban modifications to `__proto__`, defaults to `true`.\n* @return An array of `{newDocument, result}` after the patch\n*/\nfunction applyPatch(document, patch, validateOperation, mutateDocument = true, banPrototypeModifications = true) {\n\tif (validateOperation) {\n\t\tif (!Array.isArray(patch)) throw new JsonPatchError(\"Patch sequence must be an array\", \"SEQUENCE_NOT_AN_ARRAY\");\n\t}\n\tif (!mutateDocument) document = _deepClone(document);\n\tconst results = new Array(patch.length);\n\tfor (let i = 0, length = patch.length; i < length; i++) {\n\t\tresults[i] = applyOperation(document, patch[i], validateOperation, true, banPrototypeModifications, i);\n\t\tdocument = results[i].newDocument;\n\t}\n\tresults.newDocument = document;\n\treturn results;\n}\n/**\n* Apply a single JSON Patch Operation on a JSON document.\n* Returns the updated document.\n* Suitable as a reducer.\n*\n* @param document The document to patch\n* @param operation The operation to apply\n* @return The updated document\n*/\nfunction applyReducer(document, operation, index) {\n\tconst operationResult = applyOperation(document, operation);\n\tif (operationResult.test === false) throw new JsonPatchError(\"Test operation failed\", \"TEST_OPERATION_FAILED\", index, operation, document);\n\treturn operationResult.newDocument;\n}\n/**\n* Validates a single operation. Called from `jsonpatch.validate`. Throws `JsonPatchError` in case of an error.\n* @param {object} operation - operation object (patch)\n* @param {number} index - index of operation in the sequence\n* @param {object} [document] - object where the operation is supposed to be applied\n* @param {string} [existingPathFragment] - comes along with `document`\n*/\nfunction validator(operation, index, document, existingPathFragment) {\n\tif (typeof operation !== \"object\" || operation === null || Array.isArray(operation)) throw new JsonPatchError(\"Operation is not an object\", \"OPERATION_NOT_AN_OBJECT\", index, operation, document);\n\telse if (!objOps[operation.op]) throw new JsonPatchError(\"Operation `op` property is not one of operations defined in RFC-6902\", \"OPERATION_OP_INVALID\", index, operation, document);\n\telse if (typeof operation.path !== \"string\") throw new JsonPatchError(\"Operation `path` property is not a string\", \"OPERATION_PATH_INVALID\", index, operation, document);\n\telse if (operation.path.indexOf(\"/\") !== 0 && operation.path.length > 0) throw new JsonPatchError(\"Operation `path` property must start with \\\"/\\\"\", \"OPERATION_PATH_INVALID\", index, operation, document);\n\telse if ((operation.op === \"move\" || operation.op === \"copy\") && typeof operation.from !== \"string\") throw new JsonPatchError(\"Operation `from` property is not present (applicable in `move` and `copy` operations)\", \"OPERATION_FROM_REQUIRED\", index, operation, document);\n\telse if ((operation.op === \"add\" || operation.op === \"replace\" || operation.op === \"test\") && operation.value === void 0) throw new JsonPatchError(\"Operation `value` property is not present (applicable in `add`, `replace` and `test` operations)\", \"OPERATION_VALUE_REQUIRED\", index, operation, document);\n\telse if ((operation.op === \"add\" || operation.op === \"replace\" || operation.op === \"test\") && hasUndefined(operation.value)) throw new JsonPatchError(\"Operation `value` property is not present (applicable in `add`, `replace` and `test` operations)\", \"OPERATION_VALUE_CANNOT_CONTAIN_UNDEFINED\", index, operation, document);\n\telse if (document) {\n\t\tif (operation.op == \"add\") {\n\t\t\tvar pathLen = operation.path.split(\"/\").length;\n\t\t\tvar existingPathLen = existingPathFragment.split(\"/\").length;\n\t\t\tif (pathLen !== existingPathLen + 1 && pathLen !== existingPathLen) throw new JsonPatchError(\"Cannot perform an `add` operation at the desired path\", \"OPERATION_PATH_CANNOT_ADD\", index, operation, document);\n\t\t} else if (operation.op === \"replace\" || operation.op === \"remove\" || operation.op === \"_get\") {\n\t\t\tif (operation.path !== existingPathFragment) throw new JsonPatchError(\"Cannot perform the operation at a path that does not exist\", \"OPERATION_PATH_UNRESOLVABLE\", index, operation, document);\n\t\t} else if (operation.op === \"move\" || operation.op === \"copy\") {\n\t\t\tvar existingValue = {\n\t\t\t\top: \"_get\",\n\t\t\t\tpath: operation.from,\n\t\t\t\tvalue: void 0\n\t\t\t};\n\t\t\tvar error = validate([existingValue], document);\n\t\t\tif (error && error.name === \"OPERATION_PATH_UNRESOLVABLE\") throw new JsonPatchError(\"Cannot perform the operation from a path that does not exist\", \"OPERATION_FROM_UNRESOLVABLE\", index, operation, document);\n\t\t}\n\t}\n}\n/**\n* Validates a sequence of operations. If `document` parameter is provided, the sequence is additionally validated against the object document.\n* If error is encountered, returns a JsonPatchError object\n* @param sequence\n* @param document\n* @returns {JsonPatchError|undefined}\n*/\nfunction validate(sequence, document, externalValidator) {\n\ttry {\n\t\tif (!Array.isArray(sequence)) throw new JsonPatchError(\"Patch sequence must be an array\", \"SEQUENCE_NOT_AN_ARRAY\");\n\t\tif (document) applyPatch(_deepClone(document), _deepClone(sequence), externalValidator || true);\n\t\telse {\n\t\t\texternalValidator = externalValidator || validator;\n\t\t\tfor (var i = 0; i < sequence.length; i++) externalValidator(sequence[i], i, document, void 0);\n\t\t}\n\t} catch (e) {\n\t\tif (e instanceof JsonPatchError) return e;\n\t\telse throw e;\n\t}\n}\nfunction _areEquals(a, b) {\n\tif (a === b) return true;\n\tif (a && b && typeof a == \"object\" && typeof b == \"object\") {\n\t\tvar arrA = Array.isArray(a), arrB = Array.isArray(b), i, length, key;\n\t\tif (arrA && arrB) {\n\t\t\tlength = a.length;\n\t\t\tif (length != b.length) return false;\n\t\t\tfor (i = length; i-- !== 0;) if (!_areEquals(a[i], b[i])) return false;\n\t\t\treturn true;\n\t\t}\n\t\tif (arrA != arrB) return false;\n\t\tvar keys = Object.keys(a);\n\t\tlength = keys.length;\n\t\tif (length !== Object.keys(b).length) return false;\n\t\tfor (i = length; i-- !== 0;) if (!b.hasOwnProperty(keys[i])) return false;\n\t\tfor (i = length; i-- !== 0;) {\n\t\t\tkey = keys[i];\n\t\t\tif (!_areEquals(a[key], b[key])) return false;\n\t\t}\n\t\treturn true;\n\t}\n\treturn a !== a && b !== b;\n}\n\n//#endregion\nexport { _areEquals, applyOperation, applyPatch, applyReducer, core_exports, getValueByPointer, validate, validator };\n//# sourceMappingURL=core.js.map","import { _deepClone, _objectKeys, escapePathComponent, hasOwnProperty } from \"./helpers.js\";\nimport \"./core.js\";\n\n//#region src/utils/fast-json-patch/src/duplex.ts\nfunction _generate(mirror, obj, patches, path, invertible) {\n\tif (obj === mirror) return;\n\tif (typeof obj.toJSON === \"function\") obj = obj.toJSON();\n\tvar newKeys = _objectKeys(obj);\n\tvar oldKeys = _objectKeys(mirror);\n\tvar changed = false;\n\tvar deleted = false;\n\tfor (var t = oldKeys.length - 1; t >= 0; t--) {\n\t\tvar key = oldKeys[t];\n\t\tvar oldVal = mirror[key];\n\t\tif (hasOwnProperty(obj, key) && !(obj[key] === void 0 && oldVal !== void 0 && Array.isArray(obj) === false)) {\n\t\t\tvar newVal = obj[key];\n\t\t\tif (typeof oldVal == \"object\" && oldVal != null && typeof newVal == \"object\" && newVal != null && Array.isArray(oldVal) === Array.isArray(newVal)) _generate(oldVal, newVal, patches, path + \"/\" + escapePathComponent(key), invertible);\n\t\t\telse if (oldVal !== newVal) {\n\t\t\t\tchanged = true;\n\t\t\t\tif (invertible) patches.push({\n\t\t\t\t\top: \"test\",\n\t\t\t\t\tpath: path + \"/\" + escapePathComponent(key),\n\t\t\t\t\tvalue: _deepClone(oldVal)\n\t\t\t\t});\n\t\t\t\tpatches.push({\n\t\t\t\t\top: \"replace\",\n\t\t\t\t\tpath: path + \"/\" + escapePathComponent(key),\n\t\t\t\t\tvalue: _deepClone(newVal)\n\t\t\t\t});\n\t\t\t}\n\t\t} else if (Array.isArray(mirror) === Array.isArray(obj)) {\n\t\t\tif (invertible) patches.push({\n\t\t\t\top: \"test\",\n\t\t\t\tpath: path + \"/\" + escapePathComponent(key),\n\t\t\t\tvalue: _deepClone(oldVal)\n\t\t\t});\n\t\t\tpatches.push({\n\t\t\t\top: \"remove\",\n\t\t\t\tpath: path + \"/\" + escapePathComponent(key)\n\t\t\t});\n\t\t\tdeleted = true;\n\t\t} else {\n\t\t\tif (invertible) patches.push({\n\t\t\t\top: \"test\",\n\t\t\t\tpath,\n\t\t\t\tvalue: mirror\n\t\t\t});\n\t\t\tpatches.push({\n\t\t\t\top: \"replace\",\n\t\t\t\tpath,\n\t\t\t\tvalue: obj\n\t\t\t});\n\t\t\tchanged = true;\n\t\t}\n\t}\n\tif (!deleted && newKeys.length == oldKeys.length) return;\n\tfor (var t = 0; t < newKeys.length; t++) {\n\t\tvar key = newKeys[t];\n\t\tif (!hasOwnProperty(mirror, key) && obj[key] !== void 0) patches.push({\n\t\t\top: \"add\",\n\t\t\tpath: path + \"/\" + escapePathComponent(key),\n\t\t\tvalue: _deepClone(obj[key])\n\t\t});\n\t}\n}\n/**\n* Create an array of patches from the differences in two objects\n*/\nfunction compare(tree1, tree2, invertible = false) {\n\tvar patches = [];\n\t_generate(tree1, tree2, patches, \"\", invertible);\n\treturn patches;\n}\n\n//#endregion\nexport { compare };\n//# sourceMappingURL=duplex.js.map","import { PatchError, _deepClone, escapePathComponent, unescapePathComponent } from \"./src/helpers.js\";\nimport { _areEquals, applyOperation, applyPatch, applyReducer, core_exports, getValueByPointer, validate, validator } from \"./src/core.js\";\nimport { compare } from \"./src/duplex.js\";\n\n//#region src/utils/fast-json-patch/index.ts\nvar fast_json_patch_default = {\n\t...core_exports,\n\tJsonPatchError: PatchError,\n\tdeepClone: _deepClone,\n\tescapePathComponent,\n\tunescapePathComponent\n};\n\n//#endregion\n//# sourceMappingURL=index.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { AIMessageChunk } from \"../messages/ai.js\";\nimport { applyPatch } from \"../utils/fast-json-patch/src/core.js\";\nimport \"../utils/fast-json-patch/index.js\";\nimport { BaseTracer } from \"./base.js\";\nimport { IterableReadableStream } from \"../utils/stream.js\";\n\n//#region src/tracers/log_stream.ts\nvar log_stream_exports = {};\n__export(log_stream_exports, {\n\tLogStreamCallbackHandler: () => LogStreamCallbackHandler,\n\tRunLog: () => RunLog,\n\tRunLogPatch: () => RunLogPatch,\n\tisLogStreamHandler: () => isLogStreamHandler\n});\n/**\n* List of jsonpatch JSONPatchOperations, which describe how to create the run state\n* from an empty dict. This is the minimal representation of the log, designed to\n* be serialized as JSON and sent over the wire to reconstruct the log on the other\n* side. Reconstruction of the state can be done with any jsonpatch-compliant library,\n* see https://jsonpatch.com for more information.\n*/\nvar RunLogPatch = class {\n\tops;\n\tconstructor(fields) {\n\t\tthis.ops = fields.ops ?? [];\n\t}\n\tconcat(other) {\n\t\tconst ops = this.ops.concat(other.ops);\n\t\tconst states = applyPatch({}, ops);\n\t\treturn new RunLog({\n\t\t\tops,\n\t\t\tstate: states[states.length - 1].newDocument\n\t\t});\n\t}\n};\nvar RunLog = class RunLog extends RunLogPatch {\n\tstate;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.state = fields.state;\n\t}\n\tconcat(other) {\n\t\tconst ops = this.ops.concat(other.ops);\n\t\tconst states = applyPatch(this.state, other.ops);\n\t\treturn new RunLog({\n\t\t\tops,\n\t\t\tstate: states[states.length - 1].newDocument\n\t\t});\n\t}\n\tstatic fromRunLogPatch(patch) {\n\t\tconst states = applyPatch({}, patch.ops);\n\t\treturn new RunLog({\n\t\t\tops: patch.ops,\n\t\t\tstate: states[states.length - 1].newDocument\n\t\t});\n\t}\n};\nconst isLogStreamHandler = (handler) => handler.name === \"log_stream_tracer\";\n/**\n* Extract standardized inputs from a run.\n*\n* Standardizes the inputs based on the type of the runnable used.\n*\n* @param run - Run object\n* @param schemaFormat - The schema format to use.\n*\n* @returns Valid inputs are only dict. By conventions, inputs always represented\n* invocation using named arguments.\n* A null means that the input is not yet known!\n*/\nasync function _getStandardizedInputs(run, schemaFormat) {\n\tif (schemaFormat === \"original\") throw new Error(\"Do not assign inputs with original schema drop the key for now. When inputs are added to streamLog they should be added with standardized schema for streaming events.\");\n\tconst { inputs } = run;\n\tif ([\n\t\t\"retriever\",\n\t\t\"llm\",\n\t\t\"prompt\"\n\t].includes(run.run_type)) return inputs;\n\tif (Object.keys(inputs).length === 1 && inputs?.input === \"\") return void 0;\n\treturn inputs.input;\n}\nasync function _getStandardizedOutputs(run, schemaFormat) {\n\tconst { outputs } = run;\n\tif (schemaFormat === \"original\") return outputs;\n\tif ([\n\t\t\"retriever\",\n\t\t\"llm\",\n\t\t\"prompt\"\n\t].includes(run.run_type)) return outputs;\n\tif (outputs !== void 0 && Object.keys(outputs).length === 1 && outputs?.output !== void 0) return outputs.output;\n\treturn outputs;\n}\nfunction isChatGenerationChunk(x) {\n\treturn x !== void 0 && x.message !== void 0;\n}\n/**\n* Class that extends the `BaseTracer` class from the\n* `langchain.callbacks.tracers.base` module. It represents a callback\n* handler that logs the execution of runs and emits `RunLog` instances to a\n* `RunLogStream`.\n*/\nvar LogStreamCallbackHandler = class extends BaseTracer {\n\tautoClose = true;\n\tincludeNames;\n\tincludeTypes;\n\tincludeTags;\n\texcludeNames;\n\texcludeTypes;\n\texcludeTags;\n\t_schemaFormat = \"original\";\n\trootId;\n\tkeyMapByRunId = {};\n\tcounterMapByRunName = {};\n\ttransformStream;\n\twriter;\n\treceiveStream;\n\tname = \"log_stream_tracer\";\n\tlc_prefer_streaming = true;\n\tconstructor(fields) {\n\t\tsuper({\n\t\t\t_awaitHandler: true,\n\t\t\t...fields\n\t\t});\n\t\tthis.autoClose = fields?.autoClose ?? true;\n\t\tthis.includeNames = fields?.includeNames;\n\t\tthis.includeTypes = fields?.includeTypes;\n\t\tthis.includeTags = fields?.includeTags;\n\t\tthis.excludeNames = fields?.excludeNames;\n\t\tthis.excludeTypes = fields?.excludeTypes;\n\t\tthis.excludeTags = fields?.excludeTags;\n\t\tthis._schemaFormat = fields?._schemaFormat ?? this._schemaFormat;\n\t\tthis.transformStream = new TransformStream();\n\t\tthis.writer = this.transformStream.writable.getWriter();\n\t\tthis.receiveStream = IterableReadableStream.fromReadableStream(this.transformStream.readable);\n\t}\n\t[Symbol.asyncIterator]() {\n\t\treturn this.receiveStream;\n\t}\n\tasync persistRun(_run) {}\n\t_includeRun(run) {\n\t\tif (run.id === this.rootId) return false;\n\t\tconst runTags = run.tags ?? [];\n\t\tlet include = this.includeNames === void 0 && this.includeTags === void 0 && this.includeTypes === void 0;\n\t\tif (this.includeNames !== void 0) include = include || this.includeNames.includes(run.name);\n\t\tif (this.includeTypes !== void 0) include = include || this.includeTypes.includes(run.run_type);\n\t\tif (this.includeTags !== void 0) include = include || runTags.find((tag) => this.includeTags?.includes(tag)) !== void 0;\n\t\tif (this.excludeNames !== void 0) include = include && !this.excludeNames.includes(run.name);\n\t\tif (this.excludeTypes !== void 0) include = include && !this.excludeTypes.includes(run.run_type);\n\t\tif (this.excludeTags !== void 0) include = include && runTags.every((tag) => !this.excludeTags?.includes(tag));\n\t\treturn include;\n\t}\n\tasync *tapOutputIterable(runId, output) {\n\t\tfor await (const chunk of output) {\n\t\t\tif (runId !== this.rootId) {\n\t\t\t\tconst key = this.keyMapByRunId[runId];\n\t\t\t\tif (key) await this.writer.write(new RunLogPatch({ ops: [{\n\t\t\t\t\top: \"add\",\n\t\t\t\t\tpath: `/logs/${key}/streamed_output/-`,\n\t\t\t\t\tvalue: chunk\n\t\t\t\t}] }));\n\t\t\t}\n\t\t\tyield chunk;\n\t\t}\n\t}\n\tasync onRunCreate(run) {\n\t\tif (this.rootId === void 0) {\n\t\t\tthis.rootId = run.id;\n\t\t\tawait this.writer.write(new RunLogPatch({ ops: [{\n\t\t\t\top: \"replace\",\n\t\t\t\tpath: \"\",\n\t\t\t\tvalue: {\n\t\t\t\t\tid: run.id,\n\t\t\t\t\tname: run.name,\n\t\t\t\t\ttype: run.run_type,\n\t\t\t\t\tstreamed_output: [],\n\t\t\t\t\tfinal_output: void 0,\n\t\t\t\t\tlogs: {}\n\t\t\t\t}\n\t\t\t}] }));\n\t\t}\n\t\tif (!this._includeRun(run)) return;\n\t\tif (this.counterMapByRunName[run.name] === void 0) this.counterMapByRunName[run.name] = 0;\n\t\tthis.counterMapByRunName[run.name] += 1;\n\t\tconst count = this.counterMapByRunName[run.name];\n\t\tthis.keyMapByRunId[run.id] = count === 1 ? run.name : `${run.name}:${count}`;\n\t\tconst logEntry = {\n\t\t\tid: run.id,\n\t\t\tname: run.name,\n\t\t\ttype: run.run_type,\n\t\t\ttags: run.tags ?? [],\n\t\t\tmetadata: run.extra?.metadata ?? {},\n\t\t\tstart_time: new Date(run.start_time).toISOString(),\n\t\t\tstreamed_output: [],\n\t\t\tstreamed_output_str: [],\n\t\t\tfinal_output: void 0,\n\t\t\tend_time: void 0\n\t\t};\n\t\tif (this._schemaFormat === \"streaming_events\") logEntry.inputs = await _getStandardizedInputs(run, this._schemaFormat);\n\t\tawait this.writer.write(new RunLogPatch({ ops: [{\n\t\t\top: \"add\",\n\t\t\tpath: `/logs/${this.keyMapByRunId[run.id]}`,\n\t\t\tvalue: logEntry\n\t\t}] }));\n\t}\n\tasync onRunUpdate(run) {\n\t\ttry {\n\t\t\tconst runName = this.keyMapByRunId[run.id];\n\t\t\tif (runName === void 0) return;\n\t\t\tconst ops = [];\n\t\t\tif (this._schemaFormat === \"streaming_events\") ops.push({\n\t\t\t\top: \"replace\",\n\t\t\t\tpath: `/logs/${runName}/inputs`,\n\t\t\t\tvalue: await _getStandardizedInputs(run, this._schemaFormat)\n\t\t\t});\n\t\t\tops.push({\n\t\t\t\top: \"add\",\n\t\t\t\tpath: `/logs/${runName}/final_output`,\n\t\t\t\tvalue: await _getStandardizedOutputs(run, this._schemaFormat)\n\t\t\t});\n\t\t\tif (run.end_time !== void 0) ops.push({\n\t\t\t\top: \"add\",\n\t\t\t\tpath: `/logs/${runName}/end_time`,\n\t\t\t\tvalue: new Date(run.end_time).toISOString()\n\t\t\t});\n\t\t\tconst patch = new RunLogPatch({ ops });\n\t\t\tawait this.writer.write(patch);\n\t\t} finally {\n\t\t\tif (run.id === this.rootId) {\n\t\t\t\tconst patch = new RunLogPatch({ ops: [{\n\t\t\t\t\top: \"replace\",\n\t\t\t\t\tpath: \"/final_output\",\n\t\t\t\t\tvalue: await _getStandardizedOutputs(run, this._schemaFormat)\n\t\t\t\t}] });\n\t\t\t\tawait this.writer.write(patch);\n\t\t\t\tif (this.autoClose) await this.writer.close();\n\t\t\t}\n\t\t}\n\t}\n\tasync onLLMNewToken(run, token, kwargs) {\n\t\tconst runName = this.keyMapByRunId[run.id];\n\t\tif (runName === void 0) return;\n\t\tconst isChatModel = run.inputs.messages !== void 0;\n\t\tlet streamedOutputValue;\n\t\tif (isChatModel) if (isChatGenerationChunk(kwargs?.chunk)) streamedOutputValue = kwargs?.chunk;\n\t\telse streamedOutputValue = new AIMessageChunk({\n\t\t\tid: `run-${run.id}`,\n\t\t\tcontent: token\n\t\t});\n\t\telse streamedOutputValue = token;\n\t\tconst patch = new RunLogPatch({ ops: [{\n\t\t\top: \"add\",\n\t\t\tpath: `/logs/${runName}/streamed_output_str/-`,\n\t\t\tvalue: token\n\t\t}, {\n\t\t\top: \"add\",\n\t\t\tpath: `/logs/${runName}/streamed_output/-`,\n\t\t\tvalue: streamedOutputValue\n\t\t}] });\n\t\tawait this.writer.write(patch);\n\t}\n};\n\n//#endregion\nexport { LogStreamCallbackHandler, RunLog, RunLogPatch, isLogStreamHandler, log_stream_exports };\n//# sourceMappingURL=log_stream.js.map","import { __export } from \"./_virtual/rolldown_runtime.js\";\n\n//#region src/outputs.ts\nvar outputs_exports = {};\n__export(outputs_exports, {\n\tChatGenerationChunk: () => ChatGenerationChunk,\n\tGenerationChunk: () => GenerationChunk,\n\tRUN_KEY: () => RUN_KEY\n});\nconst RUN_KEY = \"__run\";\n/**\n* Chunk of a single generation. Used for streaming.\n*/\nvar GenerationChunk = class GenerationChunk {\n\ttext;\n\tgenerationInfo;\n\tconstructor(fields) {\n\t\tthis.text = fields.text;\n\t\tthis.generationInfo = fields.generationInfo;\n\t}\n\tconcat(chunk) {\n\t\treturn new GenerationChunk({\n\t\t\ttext: this.text + chunk.text,\n\t\t\tgenerationInfo: {\n\t\t\t\t...this.generationInfo,\n\t\t\t\t...chunk.generationInfo\n\t\t\t}\n\t\t});\n\t}\n};\nvar ChatGenerationChunk = class ChatGenerationChunk extends GenerationChunk {\n\tmessage;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.message = fields.message;\n\t}\n\tconcat(chunk) {\n\t\treturn new ChatGenerationChunk({\n\t\t\ttext: this.text + chunk.text,\n\t\t\tgenerationInfo: {\n\t\t\t\t...this.generationInfo,\n\t\t\t\t...chunk.generationInfo\n\t\t\t},\n\t\t\tmessage: this.message.concat(chunk.message)\n\t\t});\n\t}\n};\n\n//#endregion\nexport { ChatGenerationChunk, GenerationChunk, RUN_KEY, outputs_exports };\n//# sourceMappingURL=outputs.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { getAbortSignalError } from \"./signal.js\";\nimport pRetry from \"p-retry\";\nimport PQueueMod from \"p-queue\";\n\n//#region src/utils/async_caller.ts\nvar async_caller_exports = {};\n__export(async_caller_exports, { AsyncCaller: () => AsyncCaller });\nconst STATUS_NO_RETRY = [\n\t400,\n\t401,\n\t402,\n\t403,\n\t404,\n\t405,\n\t406,\n\t407,\n\t409\n];\nconst defaultFailedAttemptHandler = (error) => {\n\tif (error.message.startsWith(\"Cancel\") || error.message.startsWith(\"AbortError\") || error.name === \"AbortError\") throw error;\n\tif (error?.code === \"ECONNABORTED\") throw error;\n\tconst status = error?.response?.status ?? error?.status;\n\tif (status && STATUS_NO_RETRY.includes(+status)) throw error;\n\tif (error?.error?.code === \"insufficient_quota\") {\n\t\tconst err = new Error(error?.message);\n\t\terr.name = \"InsufficientQuotaError\";\n\t\tthrow err;\n\t}\n};\n/**\n* A class that can be used to make async calls with concurrency and retry logic.\n*\n* This is useful for making calls to any kind of \"expensive\" external resource,\n* be it because it's rate-limited, subject to network issues, etc.\n*\n* Concurrent calls are limited by the `maxConcurrency` parameter, which defaults\n* to `Infinity`. This means that by default, all calls will be made in parallel.\n*\n* Retries are limited by the `maxRetries` parameter, which defaults to 6. This\n* means that by default, each call will be retried up to 6 times, with an\n* exponential backoff between each attempt.\n*/\nvar AsyncCaller = class {\n\tmaxConcurrency;\n\tmaxRetries;\n\tonFailedAttempt;\n\tqueue;\n\tconstructor(params) {\n\t\tthis.maxConcurrency = params.maxConcurrency ?? Infinity;\n\t\tthis.maxRetries = params.maxRetries ?? 6;\n\t\tthis.onFailedAttempt = params.onFailedAttempt ?? defaultFailedAttemptHandler;\n\t\tconst PQueue = \"default\" in PQueueMod ? PQueueMod.default : PQueueMod;\n\t\tthis.queue = new PQueue({ concurrency: this.maxConcurrency });\n\t}\n\tcall(callable, ...args) {\n\t\treturn this.queue.add(() => pRetry(() => callable(...args).catch((error) => {\n\t\t\tif (error instanceof Error) throw error;\n\t\t\telse throw new Error(error);\n\t\t}), {\n\t\t\tonFailedAttempt: this.onFailedAttempt,\n\t\t\tretries: this.maxRetries,\n\t\t\trandomize: true\n\t\t}), { throwOnTimeout: true });\n\t}\n\tcallWithOptions(options, callable, ...args) {\n\t\tif (options.signal) return Promise.race([this.call(callable, ...args), new Promise((_, reject) => {\n\t\t\toptions.signal?.addEventListener(\"abort\", () => {\n\t\t\t\treject(getAbortSignalError(options.signal));\n\t\t\t});\n\t\t})]);\n\t\treturn this.call(callable, ...args);\n\t}\n\tfetch(...args) {\n\t\treturn this.call(() => fetch(...args).then((res) => res.ok ? res : Promise.reject(res)));\n\t}\n};\n\n//#endregion\nexport { AsyncCaller, async_caller_exports };\n//# sourceMappingURL=async_caller.js.map","/** A special constant with type `never` */\nexport const NEVER = Object.freeze({\n    status: \"aborted\",\n});\nexport /*@__NO_SIDE_EFFECTS__*/ function $constructor(name, initializer, params) {\n    function init(inst, def) {\n        var _a;\n        Object.defineProperty(inst, \"_zod\", {\n            value: inst._zod ?? {},\n            enumerable: false,\n        });\n        (_a = inst._zod).traits ?? (_a.traits = new Set());\n        inst._zod.traits.add(name);\n        initializer(inst, def);\n        // support prototype modifications\n        for (const k in _.prototype) {\n            if (!(k in inst))\n                Object.defineProperty(inst, k, { value: _.prototype[k].bind(inst) });\n        }\n        inst._zod.constr = _;\n        inst._zod.def = def;\n    }\n    // doesn't work if Parent has a constructor with arguments\n    const Parent = params?.Parent ?? Object;\n    class Definition extends Parent {\n    }\n    Object.defineProperty(Definition, \"name\", { value: name });\n    function _(def) {\n        var _a;\n        const inst = params?.Parent ? new Definition() : this;\n        init(inst, def);\n        (_a = inst._zod).deferred ?? (_a.deferred = []);\n        for (const fn of inst._zod.deferred) {\n            fn();\n        }\n        return inst;\n    }\n    Object.defineProperty(_, \"init\", { value: init });\n    Object.defineProperty(_, Symbol.hasInstance, {\n        value: (inst) => {\n            if (params?.Parent && inst instanceof params.Parent)\n                return true;\n            return inst?._zod?.traits?.has(name);\n        },\n    });\n    Object.defineProperty(_, \"name\", { value: name });\n    return _;\n}\n//////////////////////////////   UTILITIES   ///////////////////////////////////////\nexport const $brand = Symbol(\"zod_brand\");\nexport class $ZodAsyncError extends Error {\n    constructor() {\n        super(`Encountered Promise during synchronous parse. Use .parseAsync() instead.`);\n    }\n}\nexport const globalConfig = {};\nexport function config(newConfig) {\n    if (newConfig)\n        Object.assign(globalConfig, newConfig);\n    return globalConfig;\n}\n","// functions\nexport function assertEqual(val) {\n    return val;\n}\nexport function assertNotEqual(val) {\n    return val;\n}\nexport function assertIs(_arg) { }\nexport function assertNever(_x) {\n    throw new Error();\n}\nexport function assert(_) { }\nexport function getEnumValues(entries) {\n    const numericValues = Object.values(entries).filter((v) => typeof v === \"number\");\n    const values = Object.entries(entries)\n        .filter(([k, _]) => numericValues.indexOf(+k) === -1)\n        .map(([_, v]) => v);\n    return values;\n}\nexport function joinValues(array, separator = \"|\") {\n    return array.map((val) => stringifyPrimitive(val)).join(separator);\n}\nexport function jsonStringifyReplacer(_, value) {\n    if (typeof value === \"bigint\")\n        return value.toString();\n    return value;\n}\nexport function cached(getter) {\n    const set = false;\n    return {\n        get value() {\n            if (!set) {\n                const value = getter();\n                Object.defineProperty(this, \"value\", { value });\n                return value;\n            }\n            throw new Error(\"cached value already set\");\n        },\n    };\n}\nexport function nullish(input) {\n    return input === null || input === undefined;\n}\nexport function cleanRegex(source) {\n    const start = source.startsWith(\"^\") ? 1 : 0;\n    const end = source.endsWith(\"$\") ? source.length - 1 : source.length;\n    return source.slice(start, end);\n}\nexport function floatSafeRemainder(val, step) {\n    const valDecCount = (val.toString().split(\".\")[1] || \"\").length;\n    const stepDecCount = (step.toString().split(\".\")[1] || \"\").length;\n    const decCount = valDecCount > stepDecCount ? valDecCount : stepDecCount;\n    const valInt = Number.parseInt(val.toFixed(decCount).replace(\".\", \"\"));\n    const stepInt = Number.parseInt(step.toFixed(decCount).replace(\".\", \"\"));\n    return (valInt % stepInt) / 10 ** decCount;\n}\nexport function defineLazy(object, key, getter) {\n    const set = false;\n    Object.defineProperty(object, key, {\n        get() {\n            if (!set) {\n                const value = getter();\n                object[key] = value;\n                return value;\n            }\n            throw new Error(\"cached value already set\");\n        },\n        set(v) {\n            Object.defineProperty(object, key, {\n                value: v,\n                // configurable: true,\n            });\n            // object[key] = v;\n        },\n        configurable: true,\n    });\n}\nexport function assignProp(target, prop, value) {\n    Object.defineProperty(target, prop, {\n        value,\n        writable: true,\n        enumerable: true,\n        configurable: true,\n    });\n}\nexport function getElementAtPath(obj, path) {\n    if (!path)\n        return obj;\n    return path.reduce((acc, key) => acc?.[key], obj);\n}\nexport function promiseAllObject(promisesObj) {\n    const keys = Object.keys(promisesObj);\n    const promises = keys.map((key) => promisesObj[key]);\n    return Promise.all(promises).then((results) => {\n        const resolvedObj = {};\n        for (let i = 0; i < keys.length; i++) {\n            resolvedObj[keys[i]] = results[i];\n        }\n        return resolvedObj;\n    });\n}\nexport function randomString(length = 10) {\n    const chars = \"abcdefghijklmnopqrstuvwxyz\";\n    let str = \"\";\n    for (let i = 0; i < length; i++) {\n        str += chars[Math.floor(Math.random() * chars.length)];\n    }\n    return str;\n}\nexport function esc(str) {\n    return JSON.stringify(str);\n}\nexport const captureStackTrace = Error.captureStackTrace\n    ? Error.captureStackTrace\n    : (..._args) => { };\nexport function isObject(data) {\n    return typeof data === \"object\" && data !== null && !Array.isArray(data);\n}\nexport const allowsEval = cached(() => {\n    if (typeof navigator !== \"undefined\" && navigator?.userAgent?.includes(\"Cloudflare\")) {\n        return false;\n    }\n    try {\n        const F = Function;\n        new F(\"\");\n        return true;\n    }\n    catch (_) {\n        return false;\n    }\n});\nexport function isPlainObject(o) {\n    if (isObject(o) === false)\n        return false;\n    // modified constructor\n    const ctor = o.constructor;\n    if (ctor === undefined)\n        return true;\n    // modified prototype\n    const prot = ctor.prototype;\n    if (isObject(prot) === false)\n        return false;\n    // ctor doesn't have static `isPrototypeOf`\n    if (Object.prototype.hasOwnProperty.call(prot, \"isPrototypeOf\") === false) {\n        return false;\n    }\n    return true;\n}\nexport function numKeys(data) {\n    let keyCount = 0;\n    for (const key in data) {\n        if (Object.prototype.hasOwnProperty.call(data, key)) {\n            keyCount++;\n        }\n    }\n    return keyCount;\n}\nexport const getParsedType = (data) => {\n    const t = typeof data;\n    switch (t) {\n        case \"undefined\":\n            return \"undefined\";\n        case \"string\":\n            return \"string\";\n        case \"number\":\n            return Number.isNaN(data) ? \"nan\" : \"number\";\n        case \"boolean\":\n            return \"boolean\";\n        case \"function\":\n            return \"function\";\n        case \"bigint\":\n            return \"bigint\";\n        case \"symbol\":\n            return \"symbol\";\n        case \"object\":\n            if (Array.isArray(data)) {\n                return \"array\";\n            }\n            if (data === null) {\n                return \"null\";\n            }\n            if (data.then && typeof data.then === \"function\" && data.catch && typeof data.catch === \"function\") {\n                return \"promise\";\n            }\n            if (typeof Map !== \"undefined\" && data instanceof Map) {\n                return \"map\";\n            }\n            if (typeof Set !== \"undefined\" && data instanceof Set) {\n                return \"set\";\n            }\n            if (typeof Date !== \"undefined\" && data instanceof Date) {\n                return \"date\";\n            }\n            if (typeof File !== \"undefined\" && data instanceof File) {\n                return \"file\";\n            }\n            return \"object\";\n        default:\n            throw new Error(`Unknown data type: ${t}`);\n    }\n};\nexport const propertyKeyTypes = new Set([\"string\", \"number\", \"symbol\"]);\nexport const primitiveTypes = new Set([\"string\", \"number\", \"bigint\", \"boolean\", \"symbol\", \"undefined\"]);\nexport function escapeRegex(str) {\n    return str.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\n}\n// zod-specific utils\nexport function clone(inst, def, params) {\n    const cl = new inst._zod.constr(def ?? inst._zod.def);\n    if (!def || params?.parent)\n        cl._zod.parent = inst;\n    return cl;\n}\nexport function normalizeParams(_params) {\n    const params = _params;\n    if (!params)\n        return {};\n    if (typeof params === \"string\")\n        return { error: () => params };\n    if (params?.message !== undefined) {\n        if (params?.error !== undefined)\n            throw new Error(\"Cannot specify both `message` and `error` params\");\n        params.error = params.message;\n    }\n    delete params.message;\n    if (typeof params.error === \"string\")\n        return { ...params, error: () => params.error };\n    return params;\n}\nexport function createTransparentProxy(getter) {\n    let target;\n    return new Proxy({}, {\n        get(_, prop, receiver) {\n            target ?? (target = getter());\n            return Reflect.get(target, prop, receiver);\n        },\n        set(_, prop, value, receiver) {\n            target ?? (target = getter());\n            return Reflect.set(target, prop, value, receiver);\n        },\n        has(_, prop) {\n            target ?? (target = getter());\n            return Reflect.has(target, prop);\n        },\n        deleteProperty(_, prop) {\n            target ?? (target = getter());\n            return Reflect.deleteProperty(target, prop);\n        },\n        ownKeys(_) {\n            target ?? (target = getter());\n            return Reflect.ownKeys(target);\n        },\n        getOwnPropertyDescriptor(_, prop) {\n            target ?? (target = getter());\n            return Reflect.getOwnPropertyDescriptor(target, prop);\n        },\n        defineProperty(_, prop, descriptor) {\n            target ?? (target = getter());\n            return Reflect.defineProperty(target, prop, descriptor);\n        },\n    });\n}\nexport function stringifyPrimitive(value) {\n    if (typeof value === \"bigint\")\n        return value.toString() + \"n\";\n    if (typeof value === \"string\")\n        return `\"${value}\"`;\n    return `${value}`;\n}\nexport function optionalKeys(shape) {\n    return Object.keys(shape).filter((k) => {\n        return shape[k]._zod.optin === \"optional\" && shape[k]._zod.optout === \"optional\";\n    });\n}\nexport const NUMBER_FORMAT_RANGES = {\n    safeint: [Number.MIN_SAFE_INTEGER, Number.MAX_SAFE_INTEGER],\n    int32: [-2147483648, 2147483647],\n    uint32: [0, 4294967295],\n    float32: [-3.4028234663852886e38, 3.4028234663852886e38],\n    float64: [-Number.MAX_VALUE, Number.MAX_VALUE],\n};\nexport const BIGINT_FORMAT_RANGES = {\n    int64: [/* @__PURE__*/ BigInt(\"-9223372036854775808\"), /* @__PURE__*/ BigInt(\"9223372036854775807\")],\n    uint64: [/* @__PURE__*/ BigInt(0), /* @__PURE__*/ BigInt(\"18446744073709551615\")],\n};\nexport function pick(schema, mask) {\n    const newShape = {};\n    const currDef = schema._zod.def; //.shape;\n    for (const key in mask) {\n        if (!(key in currDef.shape)) {\n            throw new Error(`Unrecognized key: \"${key}\"`);\n        }\n        if (!mask[key])\n            continue;\n        // pick key\n        newShape[key] = currDef.shape[key];\n    }\n    return clone(schema, {\n        ...schema._zod.def,\n        shape: newShape,\n        checks: [],\n    });\n}\nexport function omit(schema, mask) {\n    const newShape = { ...schema._zod.def.shape };\n    const currDef = schema._zod.def; //.shape;\n    for (const key in mask) {\n        if (!(key in currDef.shape)) {\n            throw new Error(`Unrecognized key: \"${key}\"`);\n        }\n        if (!mask[key])\n            continue;\n        delete newShape[key];\n    }\n    return clone(schema, {\n        ...schema._zod.def,\n        shape: newShape,\n        checks: [],\n    });\n}\nexport function extend(schema, shape) {\n    if (!isPlainObject(shape)) {\n        throw new Error(\"Invalid input to extend: expected a plain object\");\n    }\n    const def = {\n        ...schema._zod.def,\n        get shape() {\n            const _shape = { ...schema._zod.def.shape, ...shape };\n            assignProp(this, \"shape\", _shape); // self-caching\n            return _shape;\n        },\n        checks: [], // delete existing checks\n    };\n    return clone(schema, def);\n}\nexport function merge(a, b) {\n    return clone(a, {\n        ...a._zod.def,\n        get shape() {\n            const _shape = { ...a._zod.def.shape, ...b._zod.def.shape };\n            assignProp(this, \"shape\", _shape); // self-caching\n            return _shape;\n        },\n        catchall: b._zod.def.catchall,\n        checks: [], // delete existing checks\n    });\n}\nexport function partial(Class, schema, mask) {\n    const oldShape = schema._zod.def.shape;\n    const shape = { ...oldShape };\n    if (mask) {\n        for (const key in mask) {\n            if (!(key in oldShape)) {\n                throw new Error(`Unrecognized key: \"${key}\"`);\n            }\n            if (!mask[key])\n                continue;\n            // if (oldShape[key]!._zod.optin === \"optional\") continue;\n            shape[key] = Class\n                ? new Class({\n                    type: \"optional\",\n                    innerType: oldShape[key],\n                })\n                : oldShape[key];\n        }\n    }\n    else {\n        for (const key in oldShape) {\n            // if (oldShape[key]!._zod.optin === \"optional\") continue;\n            shape[key] = Class\n                ? new Class({\n                    type: \"optional\",\n                    innerType: oldShape[key],\n                })\n                : oldShape[key];\n        }\n    }\n    return clone(schema, {\n        ...schema._zod.def,\n        shape,\n        checks: [],\n    });\n}\nexport function required(Class, schema, mask) {\n    const oldShape = schema._zod.def.shape;\n    const shape = { ...oldShape };\n    if (mask) {\n        for (const key in mask) {\n            if (!(key in shape)) {\n                throw new Error(`Unrecognized key: \"${key}\"`);\n            }\n            if (!mask[key])\n                continue;\n            // overwrite with non-optional\n            shape[key] = new Class({\n                type: \"nonoptional\",\n                innerType: oldShape[key],\n            });\n        }\n    }\n    else {\n        for (const key in oldShape) {\n            // overwrite with non-optional\n            shape[key] = new Class({\n                type: \"nonoptional\",\n                innerType: oldShape[key],\n            });\n        }\n    }\n    return clone(schema, {\n        ...schema._zod.def,\n        shape,\n        // optional: [],\n        checks: [],\n    });\n}\nexport function aborted(x, startIndex = 0) {\n    for (let i = startIndex; i < x.issues.length; i++) {\n        if (x.issues[i]?.continue !== true)\n            return true;\n    }\n    return false;\n}\nexport function prefixIssues(path, issues) {\n    return issues.map((iss) => {\n        var _a;\n        (_a = iss).path ?? (_a.path = []);\n        iss.path.unshift(path);\n        return iss;\n    });\n}\nexport function unwrapMessage(message) {\n    return typeof message === \"string\" ? message : message?.message;\n}\nexport function finalizeIssue(iss, ctx, config) {\n    const full = { ...iss, path: iss.path ?? [] };\n    // for backwards compatibility\n    if (!iss.message) {\n        const message = unwrapMessage(iss.inst?._zod.def?.error?.(iss)) ??\n            unwrapMessage(ctx?.error?.(iss)) ??\n            unwrapMessage(config.customError?.(iss)) ??\n            unwrapMessage(config.localeError?.(iss)) ??\n            \"Invalid input\";\n        full.message = message;\n    }\n    // delete (full as any).def;\n    delete full.inst;\n    delete full.continue;\n    if (!ctx?.reportInput) {\n        delete full.input;\n    }\n    return full;\n}\nexport function getSizableOrigin(input) {\n    if (input instanceof Set)\n        return \"set\";\n    if (input instanceof Map)\n        return \"map\";\n    if (input instanceof File)\n        return \"file\";\n    return \"unknown\";\n}\nexport function getLengthableOrigin(input) {\n    if (Array.isArray(input))\n        return \"array\";\n    if (typeof input === \"string\")\n        return \"string\";\n    return \"unknown\";\n}\nexport function issue(...args) {\n    const [iss, input, inst] = args;\n    if (typeof iss === \"string\") {\n        return {\n            message: iss,\n            code: \"custom\",\n            input,\n            inst,\n        };\n    }\n    return { ...iss };\n}\nexport function cleanEnum(obj) {\n    return Object.entries(obj)\n        .filter(([k, _]) => {\n        // return true if NaN, meaning it's not a number, thus a string key\n        return Number.isNaN(Number.parseInt(k, 10));\n    })\n        .map((el) => el[1]);\n}\n// instanceof\nexport class Class {\n    constructor(..._args) { }\n}\n","import { $constructor } from \"./core.js\";\nimport * as util from \"./util.js\";\nconst initializer = (inst, def) => {\n    inst.name = \"$ZodError\";\n    Object.defineProperty(inst, \"_zod\", {\n        value: inst._zod,\n        enumerable: false,\n    });\n    Object.defineProperty(inst, \"issues\", {\n        value: def,\n        enumerable: false,\n    });\n    Object.defineProperty(inst, \"message\", {\n        get() {\n            return JSON.stringify(def, util.jsonStringifyReplacer, 2);\n        },\n        enumerable: true,\n        // configurable: false,\n    });\n    Object.defineProperty(inst, \"toString\", {\n        value: () => inst.message,\n        enumerable: false,\n    });\n};\nexport const $ZodError = $constructor(\"$ZodError\", initializer);\nexport const $ZodRealError = $constructor(\"$ZodError\", initializer, { Parent: Error });\nexport function flattenError(error, mapper = (issue) => issue.message) {\n    const fieldErrors = {};\n    const formErrors = [];\n    for (const sub of error.issues) {\n        if (sub.path.length > 0) {\n            fieldErrors[sub.path[0]] = fieldErrors[sub.path[0]] || [];\n            fieldErrors[sub.path[0]].push(mapper(sub));\n        }\n        else {\n            formErrors.push(mapper(sub));\n        }\n    }\n    return { formErrors, fieldErrors };\n}\nexport function formatError(error, _mapper) {\n    const mapper = _mapper ||\n        function (issue) {\n            return issue.message;\n        };\n    const fieldErrors = { _errors: [] };\n    const processError = (error) => {\n        for (const issue of error.issues) {\n            if (issue.code === \"invalid_union\" && issue.errors.length) {\n                issue.errors.map((issues) => processError({ issues }));\n            }\n            else if (issue.code === \"invalid_key\") {\n                processError({ issues: issue.issues });\n            }\n            else if (issue.code === \"invalid_element\") {\n                processError({ issues: issue.issues });\n            }\n            else if (issue.path.length === 0) {\n                fieldErrors._errors.push(mapper(issue));\n            }\n            else {\n                let curr = fieldErrors;\n                let i = 0;\n                while (i < issue.path.length) {\n                    const el = issue.path[i];\n                    const terminal = i === issue.path.length - 1;\n                    if (!terminal) {\n                        curr[el] = curr[el] || { _errors: [] };\n                    }\n                    else {\n                        curr[el] = curr[el] || { _errors: [] };\n                        curr[el]._errors.push(mapper(issue));\n                    }\n                    curr = curr[el];\n                    i++;\n                }\n            }\n        }\n    };\n    processError(error);\n    return fieldErrors;\n}\nexport function treeifyError(error, _mapper) {\n    const mapper = _mapper ||\n        function (issue) {\n            return issue.message;\n        };\n    const result = { errors: [] };\n    const processError = (error, path = []) => {\n        var _a, _b;\n        for (const issue of error.issues) {\n            if (issue.code === \"invalid_union\" && issue.errors.length) {\n                // regular union error\n                issue.errors.map((issues) => processError({ issues }, issue.path));\n            }\n            else if (issue.code === \"invalid_key\") {\n                processError({ issues: issue.issues }, issue.path);\n            }\n            else if (issue.code === \"invalid_element\") {\n                processError({ issues: issue.issues }, issue.path);\n            }\n            else {\n                const fullpath = [...path, ...issue.path];\n                if (fullpath.length === 0) {\n                    result.errors.push(mapper(issue));\n                    continue;\n                }\n                let curr = result;\n                let i = 0;\n                while (i < fullpath.length) {\n                    const el = fullpath[i];\n                    const terminal = i === fullpath.length - 1;\n                    if (typeof el === \"string\") {\n                        curr.properties ?? (curr.properties = {});\n                        (_a = curr.properties)[el] ?? (_a[el] = { errors: [] });\n                        curr = curr.properties[el];\n                    }\n                    else {\n                        curr.items ?? (curr.items = []);\n                        (_b = curr.items)[el] ?? (_b[el] = { errors: [] });\n                        curr = curr.items[el];\n                    }\n                    if (terminal) {\n                        curr.errors.push(mapper(issue));\n                    }\n                    i++;\n                }\n            }\n        }\n    };\n    processError(error);\n    return result;\n}\n/** Format a ZodError as a human-readable string in the following form.\n *\n * From\n *\n * ```ts\n * ZodError {\n *   issues: [\n *     {\n *       expected: 'string',\n *       code: 'invalid_type',\n *       path: [ 'username' ],\n *       message: 'Invalid input: expected string'\n *     },\n *     {\n *       expected: 'number',\n *       code: 'invalid_type',\n *       path: [ 'favoriteNumbers', 1 ],\n *       message: 'Invalid input: expected number'\n *     }\n *   ];\n * }\n * ```\n *\n * to\n *\n * ```\n * username\n *    Expected number, received string at \"username\n * favoriteNumbers[0]\n *    Invalid input: expected number\n * ```\n */\nexport function toDotPath(path) {\n    const segs = [];\n    for (const seg of path) {\n        if (typeof seg === \"number\")\n            segs.push(`[${seg}]`);\n        else if (typeof seg === \"symbol\")\n            segs.push(`[${JSON.stringify(String(seg))}]`);\n        else if (/[^\\w$]/.test(seg))\n            segs.push(`[${JSON.stringify(seg)}]`);\n        else {\n            if (segs.length)\n                segs.push(\".\");\n            segs.push(seg);\n        }\n    }\n    return segs.join(\"\");\n}\nexport function prettifyError(error) {\n    const lines = [];\n    // sort by path length\n    const issues = [...error.issues].sort((a, b) => a.path.length - b.path.length);\n    // Process each issue\n    for (const issue of issues) {\n        lines.push(` ${issue.message}`);\n        if (issue.path?.length)\n            lines.push(`   at ${toDotPath(issue.path)}`);\n    }\n    // Convert Map to formatted string\n    return lines.join(\"\\n\");\n}\n","import * as core from \"./core.js\";\nimport * as errors from \"./errors.js\";\nimport * as util from \"./util.js\";\nexport const _parse = (_Err) => (schema, value, _ctx, _params) => {\n    const ctx = _ctx ? Object.assign(_ctx, { async: false }) : { async: false };\n    const result = schema._zod.run({ value, issues: [] }, ctx);\n    if (result instanceof Promise) {\n        throw new core.$ZodAsyncError();\n    }\n    if (result.issues.length) {\n        const e = new (_params?.Err ?? _Err)(result.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config())));\n        util.captureStackTrace(e, _params?.callee);\n        throw e;\n    }\n    return result.value;\n};\nexport const parse = /* @__PURE__*/ _parse(errors.$ZodRealError);\nexport const _parseAsync = (_Err) => async (schema, value, _ctx, params) => {\n    const ctx = _ctx ? Object.assign(_ctx, { async: true }) : { async: true };\n    let result = schema._zod.run({ value, issues: [] }, ctx);\n    if (result instanceof Promise)\n        result = await result;\n    if (result.issues.length) {\n        const e = new (params?.Err ?? _Err)(result.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config())));\n        util.captureStackTrace(e, params?.callee);\n        throw e;\n    }\n    return result.value;\n};\nexport const parseAsync = /* @__PURE__*/ _parseAsync(errors.$ZodRealError);\nexport const _safeParse = (_Err) => (schema, value, _ctx) => {\n    const ctx = _ctx ? { ..._ctx, async: false } : { async: false };\n    const result = schema._zod.run({ value, issues: [] }, ctx);\n    if (result instanceof Promise) {\n        throw new core.$ZodAsyncError();\n    }\n    return result.issues.length\n        ? {\n            success: false,\n            error: new (_Err ?? errors.$ZodError)(result.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config()))),\n        }\n        : { success: true, data: result.value };\n};\nexport const safeParse = /* @__PURE__*/ _safeParse(errors.$ZodRealError);\nexport const _safeParseAsync = (_Err) => async (schema, value, _ctx) => {\n    const ctx = _ctx ? Object.assign(_ctx, { async: true }) : { async: true };\n    let result = schema._zod.run({ value, issues: [] }, ctx);\n    if (result instanceof Promise)\n        result = await result;\n    return result.issues.length\n        ? {\n            success: false,\n            error: new _Err(result.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config()))),\n        }\n        : { success: true, data: result.value };\n};\nexport const safeParseAsync = /* @__PURE__*/ _safeParseAsync(errors.$ZodRealError);\n","export const $output = Symbol(\"ZodOutput\");\nexport const $input = Symbol(\"ZodInput\");\nexport class $ZodRegistry {\n    constructor() {\n        this._map = new Map();\n        this._idmap = new Map();\n    }\n    add(schema, ..._meta) {\n        const meta = _meta[0];\n        this._map.set(schema, meta);\n        if (meta && typeof meta === \"object\" && \"id\" in meta) {\n            if (this._idmap.has(meta.id)) {\n                throw new Error(`ID ${meta.id} already exists in the registry`);\n            }\n            this._idmap.set(meta.id, schema);\n        }\n        return this;\n    }\n    clear() {\n        this._map = new Map();\n        this._idmap = new Map();\n        return this;\n    }\n    remove(schema) {\n        const meta = this._map.get(schema);\n        if (meta && typeof meta === \"object\" && \"id\" in meta) {\n            this._idmap.delete(meta.id);\n        }\n        this._map.delete(schema);\n        return this;\n    }\n    get(schema) {\n        // return this._map.get(schema) as any;\n        // inherit metadata\n        const p = schema._zod.parent;\n        if (p) {\n            const pm = { ...(this.get(p) ?? {}) };\n            delete pm.id; // do not inherit id\n            return { ...pm, ...this._map.get(schema) };\n        }\n        return this._map.get(schema);\n    }\n    has(schema) {\n        return this._map.has(schema);\n    }\n}\n// registries\nexport function registry() {\n    return new $ZodRegistry();\n}\nexport const globalRegistry = /*@__PURE__*/ registry();\n","// import { $ZodType } from \"./schemas.js\";\nimport * as core from \"./core.js\";\nimport * as regexes from \"./regexes.js\";\nimport * as util from \"./util.js\";\nexport const $ZodCheck = /*@__PURE__*/ core.$constructor(\"$ZodCheck\", (inst, def) => {\n    var _a;\n    inst._zod ?? (inst._zod = {});\n    inst._zod.def = def;\n    (_a = inst._zod).onattach ?? (_a.onattach = []);\n});\nconst numericOriginMap = {\n    number: \"number\",\n    bigint: \"bigint\",\n    object: \"date\",\n};\nexport const $ZodCheckLessThan = /*@__PURE__*/ core.$constructor(\"$ZodCheckLessThan\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    const origin = numericOriginMap[typeof def.value];\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        const curr = (def.inclusive ? bag.maximum : bag.exclusiveMaximum) ?? Number.POSITIVE_INFINITY;\n        if (def.value < curr) {\n            if (def.inclusive)\n                bag.maximum = def.value;\n            else\n                bag.exclusiveMaximum = def.value;\n        }\n    });\n    inst._zod.check = (payload) => {\n        if (def.inclusive ? payload.value <= def.value : payload.value < def.value) {\n            return;\n        }\n        payload.issues.push({\n            origin,\n            code: \"too_big\",\n            maximum: def.value,\n            input: payload.value,\n            inclusive: def.inclusive,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckGreaterThan = /*@__PURE__*/ core.$constructor(\"$ZodCheckGreaterThan\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    const origin = numericOriginMap[typeof def.value];\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        const curr = (def.inclusive ? bag.minimum : bag.exclusiveMinimum) ?? Number.NEGATIVE_INFINITY;\n        if (def.value > curr) {\n            if (def.inclusive)\n                bag.minimum = def.value;\n            else\n                bag.exclusiveMinimum = def.value;\n        }\n    });\n    inst._zod.check = (payload) => {\n        if (def.inclusive ? payload.value >= def.value : payload.value > def.value) {\n            return;\n        }\n        payload.issues.push({\n            origin,\n            code: \"too_small\",\n            minimum: def.value,\n            input: payload.value,\n            inclusive: def.inclusive,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckMultipleOf = \n/*@__PURE__*/ core.$constructor(\"$ZodCheckMultipleOf\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    inst._zod.onattach.push((inst) => {\n        var _a;\n        (_a = inst._zod.bag).multipleOf ?? (_a.multipleOf = def.value);\n    });\n    inst._zod.check = (payload) => {\n        if (typeof payload.value !== typeof def.value)\n            throw new Error(\"Cannot mix number and bigint in multiple_of check.\");\n        const isMultiple = typeof payload.value === \"bigint\"\n            ? payload.value % def.value === BigInt(0)\n            : util.floatSafeRemainder(payload.value, def.value) === 0;\n        if (isMultiple)\n            return;\n        payload.issues.push({\n            origin: typeof payload.value,\n            code: \"not_multiple_of\",\n            divisor: def.value,\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckNumberFormat = /*@__PURE__*/ core.$constructor(\"$ZodCheckNumberFormat\", (inst, def) => {\n    $ZodCheck.init(inst, def); // no format checks\n    def.format = def.format || \"float64\";\n    const isInt = def.format?.includes(\"int\");\n    const origin = isInt ? \"int\" : \"number\";\n    const [minimum, maximum] = util.NUMBER_FORMAT_RANGES[def.format];\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.format = def.format;\n        bag.minimum = minimum;\n        bag.maximum = maximum;\n        if (isInt)\n            bag.pattern = regexes.integer;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        if (isInt) {\n            if (!Number.isInteger(input)) {\n                // invalid_format issue\n                // payload.issues.push({\n                //   expected: def.format,\n                //   format: def.format,\n                //   code: \"invalid_format\",\n                //   input,\n                //   inst,\n                // });\n                // invalid_type issue\n                payload.issues.push({\n                    expected: origin,\n                    format: def.format,\n                    code: \"invalid_type\",\n                    input,\n                    inst,\n                });\n                return;\n                // not_multiple_of issue\n                // payload.issues.push({\n                //   code: \"not_multiple_of\",\n                //   origin: \"number\",\n                //   input,\n                //   inst,\n                //   divisor: 1,\n                // });\n            }\n            if (!Number.isSafeInteger(input)) {\n                if (input > 0) {\n                    // too_big\n                    payload.issues.push({\n                        input,\n                        code: \"too_big\",\n                        maximum: Number.MAX_SAFE_INTEGER,\n                        note: \"Integers must be within the safe integer range.\",\n                        inst,\n                        origin,\n                        continue: !def.abort,\n                    });\n                }\n                else {\n                    // too_small\n                    payload.issues.push({\n                        input,\n                        code: \"too_small\",\n                        minimum: Number.MIN_SAFE_INTEGER,\n                        note: \"Integers must be within the safe integer range.\",\n                        inst,\n                        origin,\n                        continue: !def.abort,\n                    });\n                }\n                return;\n            }\n        }\n        if (input < minimum) {\n            payload.issues.push({\n                origin: \"number\",\n                input,\n                code: \"too_small\",\n                minimum,\n                inclusive: true,\n                inst,\n                continue: !def.abort,\n            });\n        }\n        if (input > maximum) {\n            payload.issues.push({\n                origin: \"number\",\n                input,\n                code: \"too_big\",\n                maximum,\n                inst,\n            });\n        }\n    };\n});\nexport const $ZodCheckBigIntFormat = /*@__PURE__*/ core.$constructor(\"$ZodCheckBigIntFormat\", (inst, def) => {\n    $ZodCheck.init(inst, def); // no format checks\n    const [minimum, maximum] = util.BIGINT_FORMAT_RANGES[def.format];\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.format = def.format;\n        bag.minimum = minimum;\n        bag.maximum = maximum;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        if (input < minimum) {\n            payload.issues.push({\n                origin: \"bigint\",\n                input,\n                code: \"too_small\",\n                minimum: minimum,\n                inclusive: true,\n                inst,\n                continue: !def.abort,\n            });\n        }\n        if (input > maximum) {\n            payload.issues.push({\n                origin: \"bigint\",\n                input,\n                code: \"too_big\",\n                maximum,\n                inst,\n            });\n        }\n    };\n});\nexport const $ZodCheckMaxSize = /*@__PURE__*/ core.$constructor(\"$ZodCheckMaxSize\", (inst, def) => {\n    var _a;\n    $ZodCheck.init(inst, def);\n    (_a = inst._zod.def).when ?? (_a.when = (payload) => {\n        const val = payload.value;\n        return !util.nullish(val) && val.size !== undefined;\n    });\n    inst._zod.onattach.push((inst) => {\n        const curr = (inst._zod.bag.maximum ?? Number.POSITIVE_INFINITY);\n        if (def.maximum < curr)\n            inst._zod.bag.maximum = def.maximum;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        const size = input.size;\n        if (size <= def.maximum)\n            return;\n        payload.issues.push({\n            origin: util.getSizableOrigin(input),\n            code: \"too_big\",\n            maximum: def.maximum,\n            input,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckMinSize = /*@__PURE__*/ core.$constructor(\"$ZodCheckMinSize\", (inst, def) => {\n    var _a;\n    $ZodCheck.init(inst, def);\n    (_a = inst._zod.def).when ?? (_a.when = (payload) => {\n        const val = payload.value;\n        return !util.nullish(val) && val.size !== undefined;\n    });\n    inst._zod.onattach.push((inst) => {\n        const curr = (inst._zod.bag.minimum ?? Number.NEGATIVE_INFINITY);\n        if (def.minimum > curr)\n            inst._zod.bag.minimum = def.minimum;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        const size = input.size;\n        if (size >= def.minimum)\n            return;\n        payload.issues.push({\n            origin: util.getSizableOrigin(input),\n            code: \"too_small\",\n            minimum: def.minimum,\n            input,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckSizeEquals = /*@__PURE__*/ core.$constructor(\"$ZodCheckSizeEquals\", (inst, def) => {\n    var _a;\n    $ZodCheck.init(inst, def);\n    (_a = inst._zod.def).when ?? (_a.when = (payload) => {\n        const val = payload.value;\n        return !util.nullish(val) && val.size !== undefined;\n    });\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.minimum = def.size;\n        bag.maximum = def.size;\n        bag.size = def.size;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        const size = input.size;\n        if (size === def.size)\n            return;\n        const tooBig = size > def.size;\n        payload.issues.push({\n            origin: util.getSizableOrigin(input),\n            ...(tooBig ? { code: \"too_big\", maximum: def.size } : { code: \"too_small\", minimum: def.size }),\n            inclusive: true,\n            exact: true,\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckMaxLength = /*@__PURE__*/ core.$constructor(\"$ZodCheckMaxLength\", (inst, def) => {\n    var _a;\n    $ZodCheck.init(inst, def);\n    (_a = inst._zod.def).when ?? (_a.when = (payload) => {\n        const val = payload.value;\n        return !util.nullish(val) && val.length !== undefined;\n    });\n    inst._zod.onattach.push((inst) => {\n        const curr = (inst._zod.bag.maximum ?? Number.POSITIVE_INFINITY);\n        if (def.maximum < curr)\n            inst._zod.bag.maximum = def.maximum;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        const length = input.length;\n        if (length <= def.maximum)\n            return;\n        const origin = util.getLengthableOrigin(input);\n        payload.issues.push({\n            origin,\n            code: \"too_big\",\n            maximum: def.maximum,\n            inclusive: true,\n            input,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckMinLength = /*@__PURE__*/ core.$constructor(\"$ZodCheckMinLength\", (inst, def) => {\n    var _a;\n    $ZodCheck.init(inst, def);\n    (_a = inst._zod.def).when ?? (_a.when = (payload) => {\n        const val = payload.value;\n        return !util.nullish(val) && val.length !== undefined;\n    });\n    inst._zod.onattach.push((inst) => {\n        const curr = (inst._zod.bag.minimum ?? Number.NEGATIVE_INFINITY);\n        if (def.minimum > curr)\n            inst._zod.bag.minimum = def.minimum;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        const length = input.length;\n        if (length >= def.minimum)\n            return;\n        const origin = util.getLengthableOrigin(input);\n        payload.issues.push({\n            origin,\n            code: \"too_small\",\n            minimum: def.minimum,\n            inclusive: true,\n            input,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckLengthEquals = /*@__PURE__*/ core.$constructor(\"$ZodCheckLengthEquals\", (inst, def) => {\n    var _a;\n    $ZodCheck.init(inst, def);\n    (_a = inst._zod.def).when ?? (_a.when = (payload) => {\n        const val = payload.value;\n        return !util.nullish(val) && val.length !== undefined;\n    });\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.minimum = def.length;\n        bag.maximum = def.length;\n        bag.length = def.length;\n    });\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        const length = input.length;\n        if (length === def.length)\n            return;\n        const origin = util.getLengthableOrigin(input);\n        const tooBig = length > def.length;\n        payload.issues.push({\n            origin,\n            ...(tooBig ? { code: \"too_big\", maximum: def.length } : { code: \"too_small\", minimum: def.length }),\n            inclusive: true,\n            exact: true,\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckStringFormat = /*@__PURE__*/ core.$constructor(\"$ZodCheckStringFormat\", (inst, def) => {\n    var _a, _b;\n    $ZodCheck.init(inst, def);\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.format = def.format;\n        if (def.pattern) {\n            bag.patterns ?? (bag.patterns = new Set());\n            bag.patterns.add(def.pattern);\n        }\n    });\n    if (def.pattern)\n        (_a = inst._zod).check ?? (_a.check = (payload) => {\n            def.pattern.lastIndex = 0;\n            if (def.pattern.test(payload.value))\n                return;\n            payload.issues.push({\n                origin: \"string\",\n                code: \"invalid_format\",\n                format: def.format,\n                input: payload.value,\n                ...(def.pattern ? { pattern: def.pattern.toString() } : {}),\n                inst,\n                continue: !def.abort,\n            });\n        });\n    else\n        (_b = inst._zod).check ?? (_b.check = () => { });\n});\nexport const $ZodCheckRegex = /*@__PURE__*/ core.$constructor(\"$ZodCheckRegex\", (inst, def) => {\n    $ZodCheckStringFormat.init(inst, def);\n    inst._zod.check = (payload) => {\n        def.pattern.lastIndex = 0;\n        if (def.pattern.test(payload.value))\n            return;\n        payload.issues.push({\n            origin: \"string\",\n            code: \"invalid_format\",\n            format: \"regex\",\n            input: payload.value,\n            pattern: def.pattern.toString(),\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckLowerCase = /*@__PURE__*/ core.$constructor(\"$ZodCheckLowerCase\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.lowercase);\n    $ZodCheckStringFormat.init(inst, def);\n});\nexport const $ZodCheckUpperCase = /*@__PURE__*/ core.$constructor(\"$ZodCheckUpperCase\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.uppercase);\n    $ZodCheckStringFormat.init(inst, def);\n});\nexport const $ZodCheckIncludes = /*@__PURE__*/ core.$constructor(\"$ZodCheckIncludes\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    const escapedRegex = util.escapeRegex(def.includes);\n    const pattern = new RegExp(typeof def.position === \"number\" ? `^.{${def.position}}${escapedRegex}` : escapedRegex);\n    def.pattern = pattern;\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.patterns ?? (bag.patterns = new Set());\n        bag.patterns.add(pattern);\n    });\n    inst._zod.check = (payload) => {\n        if (payload.value.includes(def.includes, def.position))\n            return;\n        payload.issues.push({\n            origin: \"string\",\n            code: \"invalid_format\",\n            format: \"includes\",\n            includes: def.includes,\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckStartsWith = /*@__PURE__*/ core.$constructor(\"$ZodCheckStartsWith\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    const pattern = new RegExp(`^${util.escapeRegex(def.prefix)}.*`);\n    def.pattern ?? (def.pattern = pattern);\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.patterns ?? (bag.patterns = new Set());\n        bag.patterns.add(pattern);\n    });\n    inst._zod.check = (payload) => {\n        if (payload.value.startsWith(def.prefix))\n            return;\n        payload.issues.push({\n            origin: \"string\",\n            code: \"invalid_format\",\n            format: \"starts_with\",\n            prefix: def.prefix,\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCheckEndsWith = /*@__PURE__*/ core.$constructor(\"$ZodCheckEndsWith\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    const pattern = new RegExp(`.*${util.escapeRegex(def.suffix)}$`);\n    def.pattern ?? (def.pattern = pattern);\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.patterns ?? (bag.patterns = new Set());\n        bag.patterns.add(pattern);\n    });\n    inst._zod.check = (payload) => {\n        if (payload.value.endsWith(def.suffix))\n            return;\n        payload.issues.push({\n            origin: \"string\",\n            code: \"invalid_format\",\n            format: \"ends_with\",\n            suffix: def.suffix,\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\n///////////////////////////////////\n/////    $ZodCheckProperty    /////\n///////////////////////////////////\nfunction handleCheckPropertyResult(result, payload, property) {\n    if (result.issues.length) {\n        payload.issues.push(...util.prefixIssues(property, result.issues));\n    }\n}\nexport const $ZodCheckProperty = /*@__PURE__*/ core.$constructor(\"$ZodCheckProperty\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    inst._zod.check = (payload) => {\n        const result = def.schema._zod.run({\n            value: payload.value[def.property],\n            issues: [],\n        }, {});\n        if (result instanceof Promise) {\n            return result.then((result) => handleCheckPropertyResult(result, payload, def.property));\n        }\n        handleCheckPropertyResult(result, payload, def.property);\n        return;\n    };\n});\nexport const $ZodCheckMimeType = /*@__PURE__*/ core.$constructor(\"$ZodCheckMimeType\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    const mimeSet = new Set(def.mime);\n    inst._zod.onattach.push((inst) => {\n        inst._zod.bag.mime = def.mime;\n    });\n    inst._zod.check = (payload) => {\n        if (mimeSet.has(payload.value.type))\n            return;\n        payload.issues.push({\n            code: \"invalid_value\",\n            values: def.mime,\n            input: payload.value.type,\n            inst,\n        });\n    };\n});\nexport const $ZodCheckOverwrite = /*@__PURE__*/ core.$constructor(\"$ZodCheckOverwrite\", (inst, def) => {\n    $ZodCheck.init(inst, def);\n    inst._zod.check = (payload) => {\n        payload.value = def.tx(payload.value);\n    };\n});\n","export const version = {\n    major: 4,\n    minor: 0,\n    patch: 0,\n};\n","import * as checks from \"./checks.js\";\nimport * as core from \"./core.js\";\nimport { Doc } from \"./doc.js\";\nimport { safeParse, safeParseAsync } from \"./parse.js\";\nimport * as regexes from \"./regexes.js\";\nimport * as util from \"./util.js\";\nimport { version } from \"./versions.js\";\nexport const $ZodType = /*@__PURE__*/ core.$constructor(\"$ZodType\", (inst, def) => {\n    var _a;\n    inst ?? (inst = {});\n    inst._zod.def = def; // set _def property\n    inst._zod.bag = inst._zod.bag || {}; // initialize _bag object\n    inst._zod.version = version;\n    const checks = [...(inst._zod.def.checks ?? [])];\n    // if inst is itself a checks.$ZodCheck, run it as a check\n    if (inst._zod.traits.has(\"$ZodCheck\")) {\n        checks.unshift(inst);\n    }\n    //\n    for (const ch of checks) {\n        for (const fn of ch._zod.onattach) {\n            fn(inst);\n        }\n    }\n    if (checks.length === 0) {\n        // deferred initializer\n        // inst._zod.parse is not yet defined\n        (_a = inst._zod).deferred ?? (_a.deferred = []);\n        inst._zod.deferred?.push(() => {\n            inst._zod.run = inst._zod.parse;\n        });\n    }\n    else {\n        const runChecks = (payload, checks, ctx) => {\n            let isAborted = util.aborted(payload);\n            let asyncResult;\n            for (const ch of checks) {\n                if (ch._zod.def.when) {\n                    const shouldRun = ch._zod.def.when(payload);\n                    if (!shouldRun)\n                        continue;\n                }\n                else if (isAborted) {\n                    continue;\n                }\n                const currLen = payload.issues.length;\n                const _ = ch._zod.check(payload);\n                if (_ instanceof Promise && ctx?.async === false) {\n                    throw new core.$ZodAsyncError();\n                }\n                if (asyncResult || _ instanceof Promise) {\n                    asyncResult = (asyncResult ?? Promise.resolve()).then(async () => {\n                        await _;\n                        const nextLen = payload.issues.length;\n                        if (nextLen === currLen)\n                            return;\n                        if (!isAborted)\n                            isAborted = util.aborted(payload, currLen);\n                    });\n                }\n                else {\n                    const nextLen = payload.issues.length;\n                    if (nextLen === currLen)\n                        continue;\n                    if (!isAborted)\n                        isAborted = util.aborted(payload, currLen);\n                }\n            }\n            if (asyncResult) {\n                return asyncResult.then(() => {\n                    return payload;\n                });\n            }\n            return payload;\n        };\n        inst._zod.run = (payload, ctx) => {\n            const result = inst._zod.parse(payload, ctx);\n            if (result instanceof Promise) {\n                if (ctx.async === false)\n                    throw new core.$ZodAsyncError();\n                return result.then((result) => runChecks(result, checks, ctx));\n            }\n            return runChecks(result, checks, ctx);\n        };\n    }\n    inst[\"~standard\"] = {\n        validate: (value) => {\n            try {\n                const r = safeParse(inst, value);\n                return r.success ? { value: r.data } : { issues: r.error?.issues };\n            }\n            catch (_) {\n                return safeParseAsync(inst, value).then((r) => (r.success ? { value: r.data } : { issues: r.error?.issues }));\n            }\n        },\n        vendor: \"zod\",\n        version: 1,\n    };\n});\nexport { clone } from \"./util.js\";\nexport const $ZodString = /*@__PURE__*/ core.$constructor(\"$ZodString\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.pattern = [...(inst?._zod.bag?.patterns ?? [])].pop() ?? regexes.string(inst._zod.bag);\n    inst._zod.parse = (payload, _) => {\n        if (def.coerce)\n            try {\n                payload.value = String(payload.value);\n            }\n            catch (_) { }\n        if (typeof payload.value === \"string\")\n            return payload;\n        payload.issues.push({\n            expected: \"string\",\n            code: \"invalid_type\",\n            input: payload.value,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodStringFormat = /*@__PURE__*/ core.$constructor(\"$ZodStringFormat\", (inst, def) => {\n    // check initialization must come first\n    checks.$ZodCheckStringFormat.init(inst, def);\n    $ZodString.init(inst, def);\n});\nexport const $ZodGUID = /*@__PURE__*/ core.$constructor(\"$ZodGUID\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.guid);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodUUID = /*@__PURE__*/ core.$constructor(\"$ZodUUID\", (inst, def) => {\n    if (def.version) {\n        const versionMap = {\n            v1: 1,\n            v2: 2,\n            v3: 3,\n            v4: 4,\n            v5: 5,\n            v6: 6,\n            v7: 7,\n            v8: 8,\n        };\n        const v = versionMap[def.version];\n        if (v === undefined)\n            throw new Error(`Invalid UUID version: \"${def.version}\"`);\n        def.pattern ?? (def.pattern = regexes.uuid(v));\n    }\n    else\n        def.pattern ?? (def.pattern = regexes.uuid());\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodEmail = /*@__PURE__*/ core.$constructor(\"$ZodEmail\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.email);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodURL = /*@__PURE__*/ core.$constructor(\"$ZodURL\", (inst, def) => {\n    $ZodStringFormat.init(inst, def);\n    inst._zod.check = (payload) => {\n        try {\n            const orig = payload.value;\n            const url = new URL(orig);\n            const href = url.href;\n            if (def.hostname) {\n                def.hostname.lastIndex = 0;\n                if (!def.hostname.test(url.hostname)) {\n                    payload.issues.push({\n                        code: \"invalid_format\",\n                        format: \"url\",\n                        note: \"Invalid hostname\",\n                        pattern: regexes.hostname.source,\n                        input: payload.value,\n                        inst,\n                        continue: !def.abort,\n                    });\n                }\n            }\n            if (def.protocol) {\n                def.protocol.lastIndex = 0;\n                if (!def.protocol.test(url.protocol.endsWith(\":\") ? url.protocol.slice(0, -1) : url.protocol)) {\n                    payload.issues.push({\n                        code: \"invalid_format\",\n                        format: \"url\",\n                        note: \"Invalid protocol\",\n                        pattern: def.protocol.source,\n                        input: payload.value,\n                        inst,\n                        continue: !def.abort,\n                    });\n                }\n            }\n            // payload.value = url.href;\n            if (!orig.endsWith(\"/\") && href.endsWith(\"/\")) {\n                payload.value = href.slice(0, -1);\n            }\n            else {\n                payload.value = href;\n            }\n            return;\n        }\n        catch (_) {\n            payload.issues.push({\n                code: \"invalid_format\",\n                format: \"url\",\n                input: payload.value,\n                inst,\n                continue: !def.abort,\n            });\n        }\n    };\n});\nexport const $ZodEmoji = /*@__PURE__*/ core.$constructor(\"$ZodEmoji\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.emoji());\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodNanoID = /*@__PURE__*/ core.$constructor(\"$ZodNanoID\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.nanoid);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodCUID = /*@__PURE__*/ core.$constructor(\"$ZodCUID\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.cuid);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodCUID2 = /*@__PURE__*/ core.$constructor(\"$ZodCUID2\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.cuid2);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodULID = /*@__PURE__*/ core.$constructor(\"$ZodULID\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.ulid);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodXID = /*@__PURE__*/ core.$constructor(\"$ZodXID\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.xid);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodKSUID = /*@__PURE__*/ core.$constructor(\"$ZodKSUID\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.ksuid);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodISODateTime = /*@__PURE__*/ core.$constructor(\"$ZodISODateTime\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.datetime(def));\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodISODate = /*@__PURE__*/ core.$constructor(\"$ZodISODate\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.date);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodISOTime = /*@__PURE__*/ core.$constructor(\"$ZodISOTime\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.time(def));\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodISODuration = /*@__PURE__*/ core.$constructor(\"$ZodISODuration\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.duration);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodIPv4 = /*@__PURE__*/ core.$constructor(\"$ZodIPv4\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.ipv4);\n    $ZodStringFormat.init(inst, def);\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.format = `ipv4`;\n    });\n});\nexport const $ZodIPv6 = /*@__PURE__*/ core.$constructor(\"$ZodIPv6\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.ipv6);\n    $ZodStringFormat.init(inst, def);\n    inst._zod.onattach.push((inst) => {\n        const bag = inst._zod.bag;\n        bag.format = `ipv6`;\n    });\n    inst._zod.check = (payload) => {\n        try {\n            new URL(`http://[${payload.value}]`);\n            // return;\n        }\n        catch {\n            payload.issues.push({\n                code: \"invalid_format\",\n                format: \"ipv6\",\n                input: payload.value,\n                inst,\n                continue: !def.abort,\n            });\n        }\n    };\n});\nexport const $ZodCIDRv4 = /*@__PURE__*/ core.$constructor(\"$ZodCIDRv4\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.cidrv4);\n    $ZodStringFormat.init(inst, def);\n});\nexport const $ZodCIDRv6 = /*@__PURE__*/ core.$constructor(\"$ZodCIDRv6\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.cidrv6); // not used for validation\n    $ZodStringFormat.init(inst, def);\n    inst._zod.check = (payload) => {\n        const [address, prefix] = payload.value.split(\"/\");\n        try {\n            if (!prefix)\n                throw new Error();\n            const prefixNum = Number(prefix);\n            if (`${prefixNum}` !== prefix)\n                throw new Error();\n            if (prefixNum < 0 || prefixNum > 128)\n                throw new Error();\n            new URL(`http://[${address}]`);\n        }\n        catch {\n            payload.issues.push({\n                code: \"invalid_format\",\n                format: \"cidrv6\",\n                input: payload.value,\n                inst,\n                continue: !def.abort,\n            });\n        }\n    };\n});\n//////////////////////////////   ZodBase64   //////////////////////////////\nexport function isValidBase64(data) {\n    if (data === \"\")\n        return true;\n    if (data.length % 4 !== 0)\n        return false;\n    try {\n        atob(data);\n        return true;\n    }\n    catch {\n        return false;\n    }\n}\nexport const $ZodBase64 = /*@__PURE__*/ core.$constructor(\"$ZodBase64\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.base64);\n    $ZodStringFormat.init(inst, def);\n    inst._zod.onattach.push((inst) => {\n        inst._zod.bag.contentEncoding = \"base64\";\n    });\n    inst._zod.check = (payload) => {\n        if (isValidBase64(payload.value))\n            return;\n        payload.issues.push({\n            code: \"invalid_format\",\n            format: \"base64\",\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\n//////////////////////////////   ZodBase64   //////////////////////////////\nexport function isValidBase64URL(data) {\n    if (!regexes.base64url.test(data))\n        return false;\n    const base64 = data.replace(/[-_]/g, (c) => (c === \"-\" ? \"+\" : \"/\"));\n    const padded = base64.padEnd(Math.ceil(base64.length / 4) * 4, \"=\");\n    return isValidBase64(padded);\n}\nexport const $ZodBase64URL = /*@__PURE__*/ core.$constructor(\"$ZodBase64URL\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.base64url);\n    $ZodStringFormat.init(inst, def);\n    inst._zod.onattach.push((inst) => {\n        inst._zod.bag.contentEncoding = \"base64url\";\n    });\n    inst._zod.check = (payload) => {\n        if (isValidBase64URL(payload.value))\n            return;\n        payload.issues.push({\n            code: \"invalid_format\",\n            format: \"base64url\",\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodE164 = /*@__PURE__*/ core.$constructor(\"$ZodE164\", (inst, def) => {\n    def.pattern ?? (def.pattern = regexes.e164);\n    $ZodStringFormat.init(inst, def);\n});\n//////////////////////////////   ZodJWT   //////////////////////////////\nexport function isValidJWT(token, algorithm = null) {\n    try {\n        const tokensParts = token.split(\".\");\n        if (tokensParts.length !== 3)\n            return false;\n        const [header] = tokensParts;\n        if (!header)\n            return false;\n        const parsedHeader = JSON.parse(atob(header));\n        if (\"typ\" in parsedHeader && parsedHeader?.typ !== \"JWT\")\n            return false;\n        if (!parsedHeader.alg)\n            return false;\n        if (algorithm && (!(\"alg\" in parsedHeader) || parsedHeader.alg !== algorithm))\n            return false;\n        return true;\n    }\n    catch {\n        return false;\n    }\n}\nexport const $ZodJWT = /*@__PURE__*/ core.$constructor(\"$ZodJWT\", (inst, def) => {\n    $ZodStringFormat.init(inst, def);\n    inst._zod.check = (payload) => {\n        if (isValidJWT(payload.value, def.alg))\n            return;\n        payload.issues.push({\n            code: \"invalid_format\",\n            format: \"jwt\",\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodCustomStringFormat = /*@__PURE__*/ core.$constructor(\"$ZodCustomStringFormat\", (inst, def) => {\n    $ZodStringFormat.init(inst, def);\n    inst._zod.check = (payload) => {\n        if (def.fn(payload.value))\n            return;\n        payload.issues.push({\n            code: \"invalid_format\",\n            format: def.format,\n            input: payload.value,\n            inst,\n            continue: !def.abort,\n        });\n    };\n});\nexport const $ZodNumber = /*@__PURE__*/ core.$constructor(\"$ZodNumber\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.pattern = inst._zod.bag.pattern ?? regexes.number;\n    inst._zod.parse = (payload, _ctx) => {\n        if (def.coerce)\n            try {\n                payload.value = Number(payload.value);\n            }\n            catch (_) { }\n        const input = payload.value;\n        if (typeof input === \"number\" && !Number.isNaN(input) && Number.isFinite(input)) {\n            return payload;\n        }\n        const received = typeof input === \"number\"\n            ? Number.isNaN(input)\n                ? \"NaN\"\n                : !Number.isFinite(input)\n                    ? \"Infinity\"\n                    : undefined\n            : undefined;\n        payload.issues.push({\n            expected: \"number\",\n            code: \"invalid_type\",\n            input,\n            inst,\n            ...(received ? { received } : {}),\n        });\n        return payload;\n    };\n});\nexport const $ZodNumberFormat = /*@__PURE__*/ core.$constructor(\"$ZodNumber\", (inst, def) => {\n    checks.$ZodCheckNumberFormat.init(inst, def);\n    $ZodNumber.init(inst, def); // no format checksp\n});\nexport const $ZodBoolean = /*@__PURE__*/ core.$constructor(\"$ZodBoolean\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.pattern = regexes.boolean;\n    inst._zod.parse = (payload, _ctx) => {\n        if (def.coerce)\n            try {\n                payload.value = Boolean(payload.value);\n            }\n            catch (_) { }\n        const input = payload.value;\n        if (typeof input === \"boolean\")\n            return payload;\n        payload.issues.push({\n            expected: \"boolean\",\n            code: \"invalid_type\",\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodBigInt = /*@__PURE__*/ core.$constructor(\"$ZodBigInt\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.pattern = regexes.bigint;\n    inst._zod.parse = (payload, _ctx) => {\n        if (def.coerce)\n            try {\n                payload.value = BigInt(payload.value);\n            }\n            catch (_) { }\n        if (typeof payload.value === \"bigint\")\n            return payload;\n        payload.issues.push({\n            expected: \"bigint\",\n            code: \"invalid_type\",\n            input: payload.value,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodBigIntFormat = /*@__PURE__*/ core.$constructor(\"$ZodBigInt\", (inst, def) => {\n    checks.$ZodCheckBigIntFormat.init(inst, def);\n    $ZodBigInt.init(inst, def); // no format checks\n});\nexport const $ZodSymbol = /*@__PURE__*/ core.$constructor(\"$ZodSymbol\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        const input = payload.value;\n        if (typeof input === \"symbol\")\n            return payload;\n        payload.issues.push({\n            expected: \"symbol\",\n            code: \"invalid_type\",\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodUndefined = /*@__PURE__*/ core.$constructor(\"$ZodUndefined\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.pattern = regexes.undefined;\n    inst._zod.values = new Set([undefined]);\n    inst._zod.optin = \"optional\";\n    inst._zod.optout = \"optional\";\n    inst._zod.parse = (payload, _ctx) => {\n        const input = payload.value;\n        if (typeof input === \"undefined\")\n            return payload;\n        payload.issues.push({\n            expected: \"undefined\",\n            code: \"invalid_type\",\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodNull = /*@__PURE__*/ core.$constructor(\"$ZodNull\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.pattern = regexes.null;\n    inst._zod.values = new Set([null]);\n    inst._zod.parse = (payload, _ctx) => {\n        const input = payload.value;\n        if (input === null)\n            return payload;\n        payload.issues.push({\n            expected: \"null\",\n            code: \"invalid_type\",\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodAny = /*@__PURE__*/ core.$constructor(\"$ZodAny\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload) => payload;\n});\nexport const $ZodUnknown = /*@__PURE__*/ core.$constructor(\"$ZodUnknown\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload) => payload;\n});\nexport const $ZodNever = /*@__PURE__*/ core.$constructor(\"$ZodNever\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        payload.issues.push({\n            expected: \"never\",\n            code: \"invalid_type\",\n            input: payload.value,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodVoid = /*@__PURE__*/ core.$constructor(\"$ZodVoid\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        const input = payload.value;\n        if (typeof input === \"undefined\")\n            return payload;\n        payload.issues.push({\n            expected: \"void\",\n            code: \"invalid_type\",\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodDate = /*@__PURE__*/ core.$constructor(\"$ZodDate\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        if (def.coerce) {\n            try {\n                payload.value = new Date(payload.value);\n            }\n            catch (_err) { }\n        }\n        const input = payload.value;\n        const isDate = input instanceof Date;\n        const isValidDate = isDate && !Number.isNaN(input.getTime());\n        if (isValidDate)\n            return payload;\n        payload.issues.push({\n            expected: \"date\",\n            code: \"invalid_type\",\n            input,\n            ...(isDate ? { received: \"Invalid Date\" } : {}),\n            inst,\n        });\n        return payload;\n    };\n});\nfunction handleArrayResult(result, final, index) {\n    if (result.issues.length) {\n        final.issues.push(...util.prefixIssues(index, result.issues));\n    }\n    final.value[index] = result.value;\n}\nexport const $ZodArray = /*@__PURE__*/ core.$constructor(\"$ZodArray\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, ctx) => {\n        const input = payload.value;\n        if (!Array.isArray(input)) {\n            payload.issues.push({\n                expected: \"array\",\n                code: \"invalid_type\",\n                input,\n                inst,\n            });\n            return payload;\n        }\n        payload.value = Array(input.length);\n        const proms = [];\n        for (let i = 0; i < input.length; i++) {\n            const item = input[i];\n            const result = def.element._zod.run({\n                value: item,\n                issues: [],\n            }, ctx);\n            if (result instanceof Promise) {\n                proms.push(result.then((result) => handleArrayResult(result, payload, i)));\n            }\n            else {\n                handleArrayResult(result, payload, i);\n            }\n        }\n        if (proms.length) {\n            return Promise.all(proms).then(() => payload);\n        }\n        return payload; //handleArrayResultsAsync(parseResults, final);\n    };\n});\nfunction handleObjectResult(result, final, key) {\n    // if(isOptional)\n    if (result.issues.length) {\n        final.issues.push(...util.prefixIssues(key, result.issues));\n    }\n    final.value[key] = result.value;\n}\nfunction handleOptionalObjectResult(result, final, key, input) {\n    if (result.issues.length) {\n        // validation failed against value schema\n        if (input[key] === undefined) {\n            // if input was undefined, ignore the error\n            if (key in input) {\n                final.value[key] = undefined;\n            }\n            else {\n                final.value[key] = result.value;\n            }\n        }\n        else {\n            final.issues.push(...util.prefixIssues(key, result.issues));\n        }\n    }\n    else if (result.value === undefined) {\n        // validation returned `undefined`\n        if (key in input)\n            final.value[key] = undefined;\n    }\n    else {\n        // non-undefined value\n        final.value[key] = result.value;\n    }\n}\nexport const $ZodObject = /*@__PURE__*/ core.$constructor(\"$ZodObject\", (inst, def) => {\n    // requires cast because technically $ZodObject doesn't extend\n    $ZodType.init(inst, def);\n    const _normalized = util.cached(() => {\n        const keys = Object.keys(def.shape);\n        for (const k of keys) {\n            if (!(def.shape[k] instanceof $ZodType)) {\n                throw new Error(`Invalid element at key \"${k}\": expected a Zod schema`);\n            }\n        }\n        const okeys = util.optionalKeys(def.shape);\n        return {\n            shape: def.shape,\n            keys,\n            keySet: new Set(keys),\n            numKeys: keys.length,\n            optionalKeys: new Set(okeys),\n        };\n    });\n    util.defineLazy(inst._zod, \"propValues\", () => {\n        const shape = def.shape;\n        const propValues = {};\n        for (const key in shape) {\n            const field = shape[key]._zod;\n            if (field.values) {\n                propValues[key] ?? (propValues[key] = new Set());\n                for (const v of field.values)\n                    propValues[key].add(v);\n            }\n        }\n        return propValues;\n    });\n    const generateFastpass = (shape) => {\n        const doc = new Doc([\"shape\", \"payload\", \"ctx\"]);\n        const normalized = _normalized.value;\n        const parseStr = (key) => {\n            const k = util.esc(key);\n            return `shape[${k}]._zod.run({ value: input[${k}], issues: [] }, ctx)`;\n        };\n        doc.write(`const input = payload.value;`);\n        const ids = Object.create(null);\n        let counter = 0;\n        for (const key of normalized.keys) {\n            ids[key] = `key_${counter++}`;\n        }\n        // A: preserve key order {\n        doc.write(`const newResult = {}`);\n        for (const key of normalized.keys) {\n            if (normalized.optionalKeys.has(key)) {\n                const id = ids[key];\n                doc.write(`const ${id} = ${parseStr(key)};`);\n                const k = util.esc(key);\n                doc.write(`\n        if (${id}.issues.length) {\n          if (input[${k}] === undefined) {\n            if (${k} in input) {\n              newResult[${k}] = undefined;\n            }\n          } else {\n            payload.issues = payload.issues.concat(\n              ${id}.issues.map((iss) => ({\n                ...iss,\n                path: iss.path ? [${k}, ...iss.path] : [${k}],\n              }))\n            );\n          }\n        } else if (${id}.value === undefined) {\n          if (${k} in input) newResult[${k}] = undefined;\n        } else {\n          newResult[${k}] = ${id}.value;\n        }\n        `);\n            }\n            else {\n                const id = ids[key];\n                //  const id = ids[key];\n                doc.write(`const ${id} = ${parseStr(key)};`);\n                doc.write(`\n          if (${id}.issues.length) payload.issues = payload.issues.concat(${id}.issues.map(iss => ({\n            ...iss,\n            path: iss.path ? [${util.esc(key)}, ...iss.path] : [${util.esc(key)}]\n          })));`);\n                doc.write(`newResult[${util.esc(key)}] = ${id}.value`);\n            }\n        }\n        doc.write(`payload.value = newResult;`);\n        doc.write(`return payload;`);\n        const fn = doc.compile();\n        return (payload, ctx) => fn(shape, payload, ctx);\n    };\n    let fastpass;\n    const isObject = util.isObject;\n    const jit = !core.globalConfig.jitless;\n    const allowsEval = util.allowsEval;\n    const fastEnabled = jit && allowsEval.value; // && !def.catchall;\n    const catchall = def.catchall;\n    let value;\n    inst._zod.parse = (payload, ctx) => {\n        value ?? (value = _normalized.value);\n        const input = payload.value;\n        if (!isObject(input)) {\n            payload.issues.push({\n                expected: \"object\",\n                code: \"invalid_type\",\n                input,\n                inst,\n            });\n            return payload;\n        }\n        const proms = [];\n        if (jit && fastEnabled && ctx?.async === false && ctx.jitless !== true) {\n            // always synchronous\n            if (!fastpass)\n                fastpass = generateFastpass(def.shape);\n            payload = fastpass(payload, ctx);\n        }\n        else {\n            payload.value = {};\n            const shape = value.shape;\n            for (const key of value.keys) {\n                const el = shape[key];\n                // do not add omitted optional keys\n                // if (!(key in input)) {\n                //   if (optionalKeys.has(key)) continue;\n                //   payload.issues.push({\n                //     code: \"invalid_type\",\n                //     path: [key],\n                //     expected: \"nonoptional\",\n                //     note: `Missing required key: \"${key}\"`,\n                //     input,\n                //     inst,\n                //   });\n                // }\n                const r = el._zod.run({ value: input[key], issues: [] }, ctx);\n                const isOptional = el._zod.optin === \"optional\" && el._zod.optout === \"optional\";\n                if (r instanceof Promise) {\n                    proms.push(r.then((r) => isOptional ? handleOptionalObjectResult(r, payload, key, input) : handleObjectResult(r, payload, key)));\n                }\n                else if (isOptional) {\n                    handleOptionalObjectResult(r, payload, key, input);\n                }\n                else {\n                    handleObjectResult(r, payload, key);\n                }\n            }\n        }\n        if (!catchall) {\n            // return payload;\n            return proms.length ? Promise.all(proms).then(() => payload) : payload;\n        }\n        const unrecognized = [];\n        // iterate over input keys\n        const keySet = value.keySet;\n        const _catchall = catchall._zod;\n        const t = _catchall.def.type;\n        for (const key of Object.keys(input)) {\n            if (keySet.has(key))\n                continue;\n            if (t === \"never\") {\n                unrecognized.push(key);\n                continue;\n            }\n            const r = _catchall.run({ value: input[key], issues: [] }, ctx);\n            if (r instanceof Promise) {\n                proms.push(r.then((r) => handleObjectResult(r, payload, key)));\n            }\n            else {\n                handleObjectResult(r, payload, key);\n            }\n        }\n        if (unrecognized.length) {\n            payload.issues.push({\n                code: \"unrecognized_keys\",\n                keys: unrecognized,\n                input,\n                inst,\n            });\n        }\n        if (!proms.length)\n            return payload;\n        return Promise.all(proms).then(() => {\n            return payload;\n        });\n    };\n});\nfunction handleUnionResults(results, final, inst, ctx) {\n    for (const result of results) {\n        if (result.issues.length === 0) {\n            final.value = result.value;\n            return final;\n        }\n    }\n    final.issues.push({\n        code: \"invalid_union\",\n        input: final.value,\n        inst,\n        errors: results.map((result) => result.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config()))),\n    });\n    return final;\n}\nexport const $ZodUnion = /*@__PURE__*/ core.$constructor(\"$ZodUnion\", (inst, def) => {\n    $ZodType.init(inst, def);\n    util.defineLazy(inst._zod, \"optin\", () => def.options.some((o) => o._zod.optin === \"optional\") ? \"optional\" : undefined);\n    util.defineLazy(inst._zod, \"optout\", () => def.options.some((o) => o._zod.optout === \"optional\") ? \"optional\" : undefined);\n    util.defineLazy(inst._zod, \"values\", () => {\n        if (def.options.every((o) => o._zod.values)) {\n            return new Set(def.options.flatMap((option) => Array.from(option._zod.values)));\n        }\n        return undefined;\n    });\n    util.defineLazy(inst._zod, \"pattern\", () => {\n        if (def.options.every((o) => o._zod.pattern)) {\n            const patterns = def.options.map((o) => o._zod.pattern);\n            return new RegExp(`^(${patterns.map((p) => util.cleanRegex(p.source)).join(\"|\")})$`);\n        }\n        return undefined;\n    });\n    inst._zod.parse = (payload, ctx) => {\n        let async = false;\n        const results = [];\n        for (const option of def.options) {\n            const result = option._zod.run({\n                value: payload.value,\n                issues: [],\n            }, ctx);\n            if (result instanceof Promise) {\n                results.push(result);\n                async = true;\n            }\n            else {\n                if (result.issues.length === 0)\n                    return result;\n                results.push(result);\n            }\n        }\n        if (!async)\n            return handleUnionResults(results, payload, inst, ctx);\n        return Promise.all(results).then((results) => {\n            return handleUnionResults(results, payload, inst, ctx);\n        });\n    };\n});\nexport const $ZodDiscriminatedUnion = \n/*@__PURE__*/\ncore.$constructor(\"$ZodDiscriminatedUnion\", (inst, def) => {\n    $ZodUnion.init(inst, def);\n    const _super = inst._zod.parse;\n    util.defineLazy(inst._zod, \"propValues\", () => {\n        const propValues = {};\n        for (const option of def.options) {\n            const pv = option._zod.propValues;\n            if (!pv || Object.keys(pv).length === 0)\n                throw new Error(`Invalid discriminated union option at index \"${def.options.indexOf(option)}\"`);\n            for (const [k, v] of Object.entries(pv)) {\n                if (!propValues[k])\n                    propValues[k] = new Set();\n                for (const val of v) {\n                    propValues[k].add(val);\n                }\n            }\n        }\n        return propValues;\n    });\n    const disc = util.cached(() => {\n        const opts = def.options;\n        const map = new Map();\n        for (const o of opts) {\n            const values = o._zod.propValues[def.discriminator];\n            if (!values || values.size === 0)\n                throw new Error(`Invalid discriminated union option at index \"${def.options.indexOf(o)}\"`);\n            for (const v of values) {\n                if (map.has(v)) {\n                    throw new Error(`Duplicate discriminator value \"${String(v)}\"`);\n                }\n                map.set(v, o);\n            }\n        }\n        return map;\n    });\n    inst._zod.parse = (payload, ctx) => {\n        const input = payload.value;\n        if (!util.isObject(input)) {\n            payload.issues.push({\n                code: \"invalid_type\",\n                expected: \"object\",\n                input,\n                inst,\n            });\n            return payload;\n        }\n        const opt = disc.value.get(input?.[def.discriminator]);\n        if (opt) {\n            return opt._zod.run(payload, ctx);\n        }\n        if (def.unionFallback) {\n            return _super(payload, ctx);\n        }\n        // no matching discriminator\n        payload.issues.push({\n            code: \"invalid_union\",\n            errors: [],\n            note: \"No matching discriminator\",\n            input,\n            path: [def.discriminator],\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodIntersection = /*@__PURE__*/ core.$constructor(\"$ZodIntersection\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, ctx) => {\n        const input = payload.value;\n        const left = def.left._zod.run({ value: input, issues: [] }, ctx);\n        const right = def.right._zod.run({ value: input, issues: [] }, ctx);\n        const async = left instanceof Promise || right instanceof Promise;\n        if (async) {\n            return Promise.all([left, right]).then(([left, right]) => {\n                return handleIntersectionResults(payload, left, right);\n            });\n        }\n        return handleIntersectionResults(payload, left, right);\n    };\n});\nfunction mergeValues(a, b) {\n    // const aType = parse.t(a);\n    // const bType = parse.t(b);\n    if (a === b) {\n        return { valid: true, data: a };\n    }\n    if (a instanceof Date && b instanceof Date && +a === +b) {\n        return { valid: true, data: a };\n    }\n    if (util.isPlainObject(a) && util.isPlainObject(b)) {\n        const bKeys = Object.keys(b);\n        const sharedKeys = Object.keys(a).filter((key) => bKeys.indexOf(key) !== -1);\n        const newObj = { ...a, ...b };\n        for (const key of sharedKeys) {\n            const sharedValue = mergeValues(a[key], b[key]);\n            if (!sharedValue.valid) {\n                return {\n                    valid: false,\n                    mergeErrorPath: [key, ...sharedValue.mergeErrorPath],\n                };\n            }\n            newObj[key] = sharedValue.data;\n        }\n        return { valid: true, data: newObj };\n    }\n    if (Array.isArray(a) && Array.isArray(b)) {\n        if (a.length !== b.length) {\n            return { valid: false, mergeErrorPath: [] };\n        }\n        const newArray = [];\n        for (let index = 0; index < a.length; index++) {\n            const itemA = a[index];\n            const itemB = b[index];\n            const sharedValue = mergeValues(itemA, itemB);\n            if (!sharedValue.valid) {\n                return {\n                    valid: false,\n                    mergeErrorPath: [index, ...sharedValue.mergeErrorPath],\n                };\n            }\n            newArray.push(sharedValue.data);\n        }\n        return { valid: true, data: newArray };\n    }\n    return { valid: false, mergeErrorPath: [] };\n}\nfunction handleIntersectionResults(result, left, right) {\n    if (left.issues.length) {\n        result.issues.push(...left.issues);\n    }\n    if (right.issues.length) {\n        result.issues.push(...right.issues);\n    }\n    if (util.aborted(result))\n        return result;\n    const merged = mergeValues(left.value, right.value);\n    if (!merged.valid) {\n        throw new Error(`Unmergable intersection. Error path: ` + `${JSON.stringify(merged.mergeErrorPath)}`);\n    }\n    result.value = merged.data;\n    return result;\n}\nexport const $ZodTuple = /*@__PURE__*/ core.$constructor(\"$ZodTuple\", (inst, def) => {\n    $ZodType.init(inst, def);\n    const items = def.items;\n    const optStart = items.length - [...items].reverse().findIndex((item) => item._zod.optin !== \"optional\");\n    inst._zod.parse = (payload, ctx) => {\n        const input = payload.value;\n        if (!Array.isArray(input)) {\n            payload.issues.push({\n                input,\n                inst,\n                expected: \"tuple\",\n                code: \"invalid_type\",\n            });\n            return payload;\n        }\n        payload.value = [];\n        const proms = [];\n        if (!def.rest) {\n            const tooBig = input.length > items.length;\n            const tooSmall = input.length < optStart - 1;\n            if (tooBig || tooSmall) {\n                payload.issues.push({\n                    input,\n                    inst,\n                    origin: \"array\",\n                    ...(tooBig ? { code: \"too_big\", maximum: items.length } : { code: \"too_small\", minimum: items.length }),\n                });\n                return payload;\n            }\n        }\n        let i = -1;\n        for (const item of items) {\n            i++;\n            if (i >= input.length)\n                if (i >= optStart)\n                    continue;\n            const result = item._zod.run({\n                value: input[i],\n                issues: [],\n            }, ctx);\n            if (result instanceof Promise) {\n                proms.push(result.then((result) => handleTupleResult(result, payload, i)));\n            }\n            else {\n                handleTupleResult(result, payload, i);\n            }\n        }\n        if (def.rest) {\n            const rest = input.slice(items.length);\n            for (const el of rest) {\n                i++;\n                const result = def.rest._zod.run({\n                    value: el,\n                    issues: [],\n                }, ctx);\n                if (result instanceof Promise) {\n                    proms.push(result.then((result) => handleTupleResult(result, payload, i)));\n                }\n                else {\n                    handleTupleResult(result, payload, i);\n                }\n            }\n        }\n        if (proms.length)\n            return Promise.all(proms).then(() => payload);\n        return payload;\n    };\n});\nfunction handleTupleResult(result, final, index) {\n    if (result.issues.length) {\n        final.issues.push(...util.prefixIssues(index, result.issues));\n    }\n    final.value[index] = result.value;\n}\nexport const $ZodRecord = /*@__PURE__*/ core.$constructor(\"$ZodRecord\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, ctx) => {\n        const input = payload.value;\n        if (!util.isPlainObject(input)) {\n            payload.issues.push({\n                expected: \"record\",\n                code: \"invalid_type\",\n                input,\n                inst,\n            });\n            return payload;\n        }\n        const proms = [];\n        if (def.keyType._zod.values) {\n            const values = def.keyType._zod.values;\n            payload.value = {};\n            for (const key of values) {\n                if (typeof key === \"string\" || typeof key === \"number\" || typeof key === \"symbol\") {\n                    const result = def.valueType._zod.run({ value: input[key], issues: [] }, ctx);\n                    if (result instanceof Promise) {\n                        proms.push(result.then((result) => {\n                            if (result.issues.length) {\n                                payload.issues.push(...util.prefixIssues(key, result.issues));\n                            }\n                            payload.value[key] = result.value;\n                        }));\n                    }\n                    else {\n                        if (result.issues.length) {\n                            payload.issues.push(...util.prefixIssues(key, result.issues));\n                        }\n                        payload.value[key] = result.value;\n                    }\n                }\n            }\n            let unrecognized;\n            for (const key in input) {\n                if (!values.has(key)) {\n                    unrecognized = unrecognized ?? [];\n                    unrecognized.push(key);\n                }\n            }\n            if (unrecognized && unrecognized.length > 0) {\n                payload.issues.push({\n                    code: \"unrecognized_keys\",\n                    input,\n                    inst,\n                    keys: unrecognized,\n                });\n            }\n        }\n        else {\n            payload.value = {};\n            for (const key of Reflect.ownKeys(input)) {\n                if (key === \"__proto__\")\n                    continue;\n                const keyResult = def.keyType._zod.run({ value: key, issues: [] }, ctx);\n                if (keyResult instanceof Promise) {\n                    throw new Error(\"Async schemas not supported in object keys currently\");\n                }\n                if (keyResult.issues.length) {\n                    payload.issues.push({\n                        origin: \"record\",\n                        code: \"invalid_key\",\n                        issues: keyResult.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config())),\n                        input: key,\n                        path: [key],\n                        inst,\n                    });\n                    payload.value[keyResult.value] = keyResult.value;\n                    continue;\n                }\n                const result = def.valueType._zod.run({ value: input[key], issues: [] }, ctx);\n                if (result instanceof Promise) {\n                    proms.push(result.then((result) => {\n                        if (result.issues.length) {\n                            payload.issues.push(...util.prefixIssues(key, result.issues));\n                        }\n                        payload.value[keyResult.value] = result.value;\n                    }));\n                }\n                else {\n                    if (result.issues.length) {\n                        payload.issues.push(...util.prefixIssues(key, result.issues));\n                    }\n                    payload.value[keyResult.value] = result.value;\n                }\n            }\n        }\n        if (proms.length) {\n            return Promise.all(proms).then(() => payload);\n        }\n        return payload;\n    };\n});\nexport const $ZodMap = /*@__PURE__*/ core.$constructor(\"$ZodMap\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, ctx) => {\n        const input = payload.value;\n        if (!(input instanceof Map)) {\n            payload.issues.push({\n                expected: \"map\",\n                code: \"invalid_type\",\n                input,\n                inst,\n            });\n            return payload;\n        }\n        const proms = [];\n        payload.value = new Map();\n        for (const [key, value] of input) {\n            const keyResult = def.keyType._zod.run({ value: key, issues: [] }, ctx);\n            const valueResult = def.valueType._zod.run({ value: value, issues: [] }, ctx);\n            if (keyResult instanceof Promise || valueResult instanceof Promise) {\n                proms.push(Promise.all([keyResult, valueResult]).then(([keyResult, valueResult]) => {\n                    handleMapResult(keyResult, valueResult, payload, key, input, inst, ctx);\n                }));\n            }\n            else {\n                handleMapResult(keyResult, valueResult, payload, key, input, inst, ctx);\n            }\n        }\n        if (proms.length)\n            return Promise.all(proms).then(() => payload);\n        return payload;\n    };\n});\nfunction handleMapResult(keyResult, valueResult, final, key, input, inst, ctx) {\n    if (keyResult.issues.length) {\n        if (util.propertyKeyTypes.has(typeof key)) {\n            final.issues.push(...util.prefixIssues(key, keyResult.issues));\n        }\n        else {\n            final.issues.push({\n                origin: \"map\",\n                code: \"invalid_key\",\n                input,\n                inst,\n                issues: keyResult.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config())),\n            });\n        }\n    }\n    if (valueResult.issues.length) {\n        if (util.propertyKeyTypes.has(typeof key)) {\n            final.issues.push(...util.prefixIssues(key, valueResult.issues));\n        }\n        else {\n            final.issues.push({\n                origin: \"map\",\n                code: \"invalid_element\",\n                input,\n                inst,\n                key: key,\n                issues: valueResult.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config())),\n            });\n        }\n    }\n    final.value.set(keyResult.value, valueResult.value);\n}\nexport const $ZodSet = /*@__PURE__*/ core.$constructor(\"$ZodSet\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, ctx) => {\n        const input = payload.value;\n        if (!(input instanceof Set)) {\n            payload.issues.push({\n                input,\n                inst,\n                expected: \"set\",\n                code: \"invalid_type\",\n            });\n            return payload;\n        }\n        const proms = [];\n        payload.value = new Set();\n        for (const item of input) {\n            const result = def.valueType._zod.run({ value: item, issues: [] }, ctx);\n            if (result instanceof Promise) {\n                proms.push(result.then((result) => handleSetResult(result, payload)));\n            }\n            else\n                handleSetResult(result, payload);\n        }\n        if (proms.length)\n            return Promise.all(proms).then(() => payload);\n        return payload;\n    };\n});\nfunction handleSetResult(result, final) {\n    if (result.issues.length) {\n        final.issues.push(...result.issues);\n    }\n    final.value.add(result.value);\n}\nexport const $ZodEnum = /*@__PURE__*/ core.$constructor(\"$ZodEnum\", (inst, def) => {\n    $ZodType.init(inst, def);\n    const values = util.getEnumValues(def.entries);\n    inst._zod.values = new Set(values);\n    inst._zod.pattern = new RegExp(`^(${values\n        .filter((k) => util.propertyKeyTypes.has(typeof k))\n        .map((o) => (typeof o === \"string\" ? util.escapeRegex(o) : o.toString()))\n        .join(\"|\")})$`);\n    inst._zod.parse = (payload, _ctx) => {\n        const input = payload.value;\n        if (inst._zod.values.has(input)) {\n            return payload;\n        }\n        payload.issues.push({\n            code: \"invalid_value\",\n            values,\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodLiteral = /*@__PURE__*/ core.$constructor(\"$ZodLiteral\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.values = new Set(def.values);\n    inst._zod.pattern = new RegExp(`^(${def.values\n        .map((o) => (typeof o === \"string\" ? util.escapeRegex(o) : o ? o.toString() : String(o)))\n        .join(\"|\")})$`);\n    inst._zod.parse = (payload, _ctx) => {\n        const input = payload.value;\n        if (inst._zod.values.has(input)) {\n            return payload;\n        }\n        payload.issues.push({\n            code: \"invalid_value\",\n            values: def.values,\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodFile = /*@__PURE__*/ core.$constructor(\"$ZodFile\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        const input = payload.value;\n        if (input instanceof File)\n            return payload;\n        payload.issues.push({\n            expected: \"file\",\n            code: \"invalid_type\",\n            input,\n            inst,\n        });\n        return payload;\n    };\n});\nexport const $ZodTransform = /*@__PURE__*/ core.$constructor(\"$ZodTransform\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        const _out = def.transform(payload.value, payload);\n        if (_ctx.async) {\n            const output = _out instanceof Promise ? _out : Promise.resolve(_out);\n            return output.then((output) => {\n                payload.value = output;\n                return payload;\n            });\n        }\n        if (_out instanceof Promise) {\n            throw new core.$ZodAsyncError();\n        }\n        payload.value = _out;\n        return payload;\n    };\n});\nexport const $ZodOptional = /*@__PURE__*/ core.$constructor(\"$ZodOptional\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.optin = \"optional\";\n    inst._zod.optout = \"optional\";\n    util.defineLazy(inst._zod, \"values\", () => {\n        return def.innerType._zod.values ? new Set([...def.innerType._zod.values, undefined]) : undefined;\n    });\n    util.defineLazy(inst._zod, \"pattern\", () => {\n        const pattern = def.innerType._zod.pattern;\n        return pattern ? new RegExp(`^(${util.cleanRegex(pattern.source)})?$`) : undefined;\n    });\n    inst._zod.parse = (payload, ctx) => {\n        if (def.innerType._zod.optin === \"optional\") {\n            return def.innerType._zod.run(payload, ctx);\n        }\n        if (payload.value === undefined) {\n            return payload;\n        }\n        return def.innerType._zod.run(payload, ctx);\n    };\n});\nexport const $ZodNullable = /*@__PURE__*/ core.$constructor(\"$ZodNullable\", (inst, def) => {\n    $ZodType.init(inst, def);\n    util.defineLazy(inst._zod, \"optin\", () => def.innerType._zod.optin);\n    util.defineLazy(inst._zod, \"optout\", () => def.innerType._zod.optout);\n    util.defineLazy(inst._zod, \"pattern\", () => {\n        const pattern = def.innerType._zod.pattern;\n        return pattern ? new RegExp(`^(${util.cleanRegex(pattern.source)}|null)$`) : undefined;\n    });\n    util.defineLazy(inst._zod, \"values\", () => {\n        return def.innerType._zod.values ? new Set([...def.innerType._zod.values, null]) : undefined;\n    });\n    inst._zod.parse = (payload, ctx) => {\n        if (payload.value === null)\n            return payload;\n        return def.innerType._zod.run(payload, ctx);\n    };\n});\nexport const $ZodDefault = /*@__PURE__*/ core.$constructor(\"$ZodDefault\", (inst, def) => {\n    $ZodType.init(inst, def);\n    // inst._zod.qin = \"true\";\n    inst._zod.optin = \"optional\";\n    util.defineLazy(inst._zod, \"values\", () => def.innerType._zod.values);\n    inst._zod.parse = (payload, ctx) => {\n        if (payload.value === undefined) {\n            payload.value = def.defaultValue;\n            /**\n             * $ZodDefault always returns the default value immediately.\n             * It doesn't pass the default value into the validator (\"prefault\"). There's no reason to pass the default value through validation. The validity of the default is enforced by TypeScript statically. Otherwise, it's the responsibility of the user to ensure the default is valid. In the case of pipes with divergent in/out types, you can specify the default on the `in` schema of your ZodPipe to set a \"prefault\" for the pipe.   */\n            return payload;\n        }\n        const result = def.innerType._zod.run(payload, ctx);\n        if (result instanceof Promise) {\n            return result.then((result) => handleDefaultResult(result, def));\n        }\n        return handleDefaultResult(result, def);\n    };\n});\nfunction handleDefaultResult(payload, def) {\n    if (payload.value === undefined) {\n        payload.value = def.defaultValue;\n    }\n    return payload;\n}\nexport const $ZodPrefault = /*@__PURE__*/ core.$constructor(\"$ZodPrefault\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.optin = \"optional\";\n    util.defineLazy(inst._zod, \"values\", () => def.innerType._zod.values);\n    inst._zod.parse = (payload, ctx) => {\n        if (payload.value === undefined) {\n            payload.value = def.defaultValue;\n        }\n        return def.innerType._zod.run(payload, ctx);\n    };\n});\nexport const $ZodNonOptional = /*@__PURE__*/ core.$constructor(\"$ZodNonOptional\", (inst, def) => {\n    $ZodType.init(inst, def);\n    util.defineLazy(inst._zod, \"values\", () => {\n        const v = def.innerType._zod.values;\n        return v ? new Set([...v].filter((x) => x !== undefined)) : undefined;\n    });\n    inst._zod.parse = (payload, ctx) => {\n        const result = def.innerType._zod.run(payload, ctx);\n        if (result instanceof Promise) {\n            return result.then((result) => handleNonOptionalResult(result, inst));\n        }\n        return handleNonOptionalResult(result, inst);\n    };\n});\nfunction handleNonOptionalResult(payload, inst) {\n    if (!payload.issues.length && payload.value === undefined) {\n        payload.issues.push({\n            code: \"invalid_type\",\n            expected: \"nonoptional\",\n            input: payload.value,\n            inst,\n        });\n    }\n    return payload;\n}\nexport const $ZodSuccess = /*@__PURE__*/ core.$constructor(\"$ZodSuccess\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, ctx) => {\n        const result = def.innerType._zod.run(payload, ctx);\n        if (result instanceof Promise) {\n            return result.then((result) => {\n                payload.value = result.issues.length === 0;\n                return payload;\n            });\n        }\n        payload.value = result.issues.length === 0;\n        return payload;\n    };\n});\nexport const $ZodCatch = /*@__PURE__*/ core.$constructor(\"$ZodCatch\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.optin = \"optional\";\n    util.defineLazy(inst._zod, \"optout\", () => def.innerType._zod.optout);\n    util.defineLazy(inst._zod, \"values\", () => def.innerType._zod.values);\n    inst._zod.parse = (payload, ctx) => {\n        const result = def.innerType._zod.run(payload, ctx);\n        if (result instanceof Promise) {\n            return result.then((result) => {\n                payload.value = result.value;\n                if (result.issues.length) {\n                    payload.value = def.catchValue({\n                        ...payload,\n                        error: {\n                            issues: result.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config())),\n                        },\n                        input: payload.value,\n                    });\n                    payload.issues = [];\n                }\n                return payload;\n            });\n        }\n        payload.value = result.value;\n        if (result.issues.length) {\n            payload.value = def.catchValue({\n                ...payload,\n                error: {\n                    issues: result.issues.map((iss) => util.finalizeIssue(iss, ctx, core.config())),\n                },\n                input: payload.value,\n            });\n            payload.issues = [];\n        }\n        return payload;\n    };\n});\nexport const $ZodNaN = /*@__PURE__*/ core.$constructor(\"$ZodNaN\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        if (typeof payload.value !== \"number\" || !Number.isNaN(payload.value)) {\n            payload.issues.push({\n                input: payload.value,\n                inst,\n                expected: \"nan\",\n                code: \"invalid_type\",\n            });\n            return payload;\n        }\n        return payload;\n    };\n});\nexport const $ZodPipe = /*@__PURE__*/ core.$constructor(\"$ZodPipe\", (inst, def) => {\n    $ZodType.init(inst, def);\n    util.defineLazy(inst._zod, \"values\", () => def.in._zod.values);\n    util.defineLazy(inst._zod, \"optin\", () => def.in._zod.optin);\n    util.defineLazy(inst._zod, \"optout\", () => def.out._zod.optout);\n    inst._zod.parse = (payload, ctx) => {\n        const left = def.in._zod.run(payload, ctx);\n        if (left instanceof Promise) {\n            return left.then((left) => handlePipeResult(left, def, ctx));\n        }\n        return handlePipeResult(left, def, ctx);\n    };\n});\nfunction handlePipeResult(left, def, ctx) {\n    if (util.aborted(left)) {\n        return left;\n    }\n    return def.out._zod.run({ value: left.value, issues: left.issues }, ctx);\n}\nexport const $ZodReadonly = /*@__PURE__*/ core.$constructor(\"$ZodReadonly\", (inst, def) => {\n    $ZodType.init(inst, def);\n    util.defineLazy(inst._zod, \"propValues\", () => def.innerType._zod.propValues);\n    util.defineLazy(inst._zod, \"values\", () => def.innerType._zod.values);\n    util.defineLazy(inst._zod, \"optin\", () => def.innerType._zod.optin);\n    util.defineLazy(inst._zod, \"optout\", () => def.innerType._zod.optout);\n    inst._zod.parse = (payload, ctx) => {\n        const result = def.innerType._zod.run(payload, ctx);\n        if (result instanceof Promise) {\n            return result.then(handleReadonlyResult);\n        }\n        return handleReadonlyResult(result);\n    };\n});\nfunction handleReadonlyResult(payload) {\n    payload.value = Object.freeze(payload.value);\n    return payload;\n}\nexport const $ZodTemplateLiteral = /*@__PURE__*/ core.$constructor(\"$ZodTemplateLiteral\", (inst, def) => {\n    $ZodType.init(inst, def);\n    const regexParts = [];\n    for (const part of def.parts) {\n        if (part instanceof $ZodType) {\n            if (!part._zod.pattern) {\n                // if (!source)\n                throw new Error(`Invalid template literal part, no pattern found: ${[...part._zod.traits].shift()}`);\n            }\n            const source = part._zod.pattern instanceof RegExp ? part._zod.pattern.source : part._zod.pattern;\n            if (!source)\n                throw new Error(`Invalid template literal part: ${part._zod.traits}`);\n            const start = source.startsWith(\"^\") ? 1 : 0;\n            const end = source.endsWith(\"$\") ? source.length - 1 : source.length;\n            regexParts.push(source.slice(start, end));\n        }\n        else if (part === null || util.primitiveTypes.has(typeof part)) {\n            regexParts.push(util.escapeRegex(`${part}`));\n        }\n        else {\n            throw new Error(`Invalid template literal part: ${part}`);\n        }\n    }\n    inst._zod.pattern = new RegExp(`^${regexParts.join(\"\")}$`);\n    inst._zod.parse = (payload, _ctx) => {\n        if (typeof payload.value !== \"string\") {\n            payload.issues.push({\n                input: payload.value,\n                inst,\n                expected: \"template_literal\",\n                code: \"invalid_type\",\n            });\n            return payload;\n        }\n        inst._zod.pattern.lastIndex = 0;\n        if (!inst._zod.pattern.test(payload.value)) {\n            payload.issues.push({\n                input: payload.value,\n                inst,\n                code: \"invalid_format\",\n                format: \"template_literal\",\n                pattern: inst._zod.pattern.source,\n            });\n            return payload;\n        }\n        return payload;\n    };\n});\nexport const $ZodPromise = /*@__PURE__*/ core.$constructor(\"$ZodPromise\", (inst, def) => {\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, ctx) => {\n        return Promise.resolve(payload.value).then((inner) => def.innerType._zod.run({ value: inner, issues: [] }, ctx));\n    };\n});\nexport const $ZodLazy = /*@__PURE__*/ core.$constructor(\"$ZodLazy\", (inst, def) => {\n    $ZodType.init(inst, def);\n    util.defineLazy(inst._zod, \"innerType\", () => def.getter());\n    util.defineLazy(inst._zod, \"pattern\", () => inst._zod.innerType._zod.pattern);\n    util.defineLazy(inst._zod, \"propValues\", () => inst._zod.innerType._zod.propValues);\n    util.defineLazy(inst._zod, \"optin\", () => inst._zod.innerType._zod.optin);\n    util.defineLazy(inst._zod, \"optout\", () => inst._zod.innerType._zod.optout);\n    inst._zod.parse = (payload, ctx) => {\n        const inner = inst._zod.innerType;\n        return inner._zod.run(payload, ctx);\n    };\n});\nexport const $ZodCustom = /*@__PURE__*/ core.$constructor(\"$ZodCustom\", (inst, def) => {\n    checks.$ZodCheck.init(inst, def);\n    $ZodType.init(inst, def);\n    inst._zod.parse = (payload, _) => {\n        return payload;\n    };\n    inst._zod.check = (payload) => {\n        const input = payload.value;\n        const r = def.fn(input);\n        if (r instanceof Promise) {\n            return r.then((r) => handleRefineResult(r, payload, input, inst));\n        }\n        handleRefineResult(r, payload, input, inst);\n        return;\n    };\n});\nfunction handleRefineResult(result, payload, input, inst) {\n    if (!result) {\n        const _iss = {\n            code: \"custom\",\n            input,\n            inst, // incorporates params.error into issue reporting\n            path: [...(inst._zod.def.path ?? [])], // incorporates params.error into issue reporting\n            continue: !inst._zod.def.abort,\n            // params: inst._zod.def.params,\n        };\n        if (inst._zod.def.params)\n            _iss.params = inst._zod.def.params;\n        payload.issues.push(util.issue(_iss));\n    }\n}\n","import * as checks from \"./checks.js\";\nimport * as schemas from \"./schemas.js\";\nimport * as util from \"./util.js\";\nexport function _string(Class, params) {\n    return new Class({\n        type: \"string\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _coercedString(Class, params) {\n    return new Class({\n        type: \"string\",\n        coerce: true,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _email(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"email\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _guid(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"guid\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _uuid(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"uuid\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _uuidv4(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"uuid\",\n        check: \"string_format\",\n        abort: false,\n        version: \"v4\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _uuidv6(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"uuid\",\n        check: \"string_format\",\n        abort: false,\n        version: \"v6\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _uuidv7(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"uuid\",\n        check: \"string_format\",\n        abort: false,\n        version: \"v7\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _url(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"url\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _emoji(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"emoji\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _nanoid(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"nanoid\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _cuid(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"cuid\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _cuid2(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"cuid2\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _ulid(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"ulid\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _xid(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"xid\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _ksuid(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"ksuid\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _ipv4(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"ipv4\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _ipv6(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"ipv6\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _cidrv4(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"cidrv4\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _cidrv6(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"cidrv6\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _base64(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"base64\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _base64url(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"base64url\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _e164(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"e164\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _jwt(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"jwt\",\n        check: \"string_format\",\n        abort: false,\n        ...util.normalizeParams(params),\n    });\n}\nexport const TimePrecision = {\n    Any: null,\n    Minute: -1,\n    Second: 0,\n    Millisecond: 3,\n    Microsecond: 6,\n};\nexport function _isoDateTime(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"datetime\",\n        check: \"string_format\",\n        offset: false,\n        local: false,\n        precision: null,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _isoDate(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"date\",\n        check: \"string_format\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _isoTime(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"time\",\n        check: \"string_format\",\n        precision: null,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _isoDuration(Class, params) {\n    return new Class({\n        type: \"string\",\n        format: \"duration\",\n        check: \"string_format\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _number(Class, params) {\n    return new Class({\n        type: \"number\",\n        checks: [],\n        ...util.normalizeParams(params),\n    });\n}\nexport function _coercedNumber(Class, params) {\n    return new Class({\n        type: \"number\",\n        coerce: true,\n        checks: [],\n        ...util.normalizeParams(params),\n    });\n}\nexport function _int(Class, params) {\n    return new Class({\n        type: \"number\",\n        check: \"number_format\",\n        abort: false,\n        format: \"safeint\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _float32(Class, params) {\n    return new Class({\n        type: \"number\",\n        check: \"number_format\",\n        abort: false,\n        format: \"float32\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _float64(Class, params) {\n    return new Class({\n        type: \"number\",\n        check: \"number_format\",\n        abort: false,\n        format: \"float64\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _int32(Class, params) {\n    return new Class({\n        type: \"number\",\n        check: \"number_format\",\n        abort: false,\n        format: \"int32\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _uint32(Class, params) {\n    return new Class({\n        type: \"number\",\n        check: \"number_format\",\n        abort: false,\n        format: \"uint32\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _boolean(Class, params) {\n    return new Class({\n        type: \"boolean\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _coercedBoolean(Class, params) {\n    return new Class({\n        type: \"boolean\",\n        coerce: true,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _bigint(Class, params) {\n    return new Class({\n        type: \"bigint\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _coercedBigint(Class, params) {\n    return new Class({\n        type: \"bigint\",\n        coerce: true,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _int64(Class, params) {\n    return new Class({\n        type: \"bigint\",\n        check: \"bigint_format\",\n        abort: false,\n        format: \"int64\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _uint64(Class, params) {\n    return new Class({\n        type: \"bigint\",\n        check: \"bigint_format\",\n        abort: false,\n        format: \"uint64\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _symbol(Class, params) {\n    return new Class({\n        type: \"symbol\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _undefined(Class, params) {\n    return new Class({\n        type: \"undefined\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _null(Class, params) {\n    return new Class({\n        type: \"null\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _any(Class) {\n    return new Class({\n        type: \"any\",\n    });\n}\nexport function _unknown(Class) {\n    return new Class({\n        type: \"unknown\",\n    });\n}\nexport function _never(Class, params) {\n    return new Class({\n        type: \"never\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _void(Class, params) {\n    return new Class({\n        type: \"void\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _date(Class, params) {\n    return new Class({\n        type: \"date\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _coercedDate(Class, params) {\n    return new Class({\n        type: \"date\",\n        coerce: true,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _nan(Class, params) {\n    return new Class({\n        type: \"nan\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _lt(value, params) {\n    return new checks.$ZodCheckLessThan({\n        check: \"less_than\",\n        ...util.normalizeParams(params),\n        value,\n        inclusive: false,\n    });\n}\nexport function _lte(value, params) {\n    return new checks.$ZodCheckLessThan({\n        check: \"less_than\",\n        ...util.normalizeParams(params),\n        value,\n        inclusive: true,\n    });\n}\nexport { \n/** @deprecated Use `z.lte()` instead. */\n_lte as _max, };\nexport function _gt(value, params) {\n    return new checks.$ZodCheckGreaterThan({\n        check: \"greater_than\",\n        ...util.normalizeParams(params),\n        value,\n        inclusive: false,\n    });\n}\nexport function _gte(value, params) {\n    return new checks.$ZodCheckGreaterThan({\n        check: \"greater_than\",\n        ...util.normalizeParams(params),\n        value,\n        inclusive: true,\n    });\n}\nexport { \n/** @deprecated Use `z.gte()` instead. */\n_gte as _min, };\nexport function _positive(params) {\n    return _gt(0, params);\n}\n// negative\nexport function _negative(params) {\n    return _lt(0, params);\n}\n// nonpositive\nexport function _nonpositive(params) {\n    return _lte(0, params);\n}\n// nonnegative\nexport function _nonnegative(params) {\n    return _gte(0, params);\n}\nexport function _multipleOf(value, params) {\n    return new checks.$ZodCheckMultipleOf({\n        check: \"multiple_of\",\n        ...util.normalizeParams(params),\n        value,\n    });\n}\nexport function _maxSize(maximum, params) {\n    return new checks.$ZodCheckMaxSize({\n        check: \"max_size\",\n        ...util.normalizeParams(params),\n        maximum,\n    });\n}\nexport function _minSize(minimum, params) {\n    return new checks.$ZodCheckMinSize({\n        check: \"min_size\",\n        ...util.normalizeParams(params),\n        minimum,\n    });\n}\nexport function _size(size, params) {\n    return new checks.$ZodCheckSizeEquals({\n        check: \"size_equals\",\n        ...util.normalizeParams(params),\n        size,\n    });\n}\nexport function _maxLength(maximum, params) {\n    const ch = new checks.$ZodCheckMaxLength({\n        check: \"max_length\",\n        ...util.normalizeParams(params),\n        maximum,\n    });\n    return ch;\n}\nexport function _minLength(minimum, params) {\n    return new checks.$ZodCheckMinLength({\n        check: \"min_length\",\n        ...util.normalizeParams(params),\n        minimum,\n    });\n}\nexport function _length(length, params) {\n    return new checks.$ZodCheckLengthEquals({\n        check: \"length_equals\",\n        ...util.normalizeParams(params),\n        length,\n    });\n}\nexport function _regex(pattern, params) {\n    return new checks.$ZodCheckRegex({\n        check: \"string_format\",\n        format: \"regex\",\n        ...util.normalizeParams(params),\n        pattern,\n    });\n}\nexport function _lowercase(params) {\n    return new checks.$ZodCheckLowerCase({\n        check: \"string_format\",\n        format: \"lowercase\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _uppercase(params) {\n    return new checks.$ZodCheckUpperCase({\n        check: \"string_format\",\n        format: \"uppercase\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _includes(includes, params) {\n    return new checks.$ZodCheckIncludes({\n        check: \"string_format\",\n        format: \"includes\",\n        ...util.normalizeParams(params),\n        includes,\n    });\n}\nexport function _startsWith(prefix, params) {\n    return new checks.$ZodCheckStartsWith({\n        check: \"string_format\",\n        format: \"starts_with\",\n        ...util.normalizeParams(params),\n        prefix,\n    });\n}\nexport function _endsWith(suffix, params) {\n    return new checks.$ZodCheckEndsWith({\n        check: \"string_format\",\n        format: \"ends_with\",\n        ...util.normalizeParams(params),\n        suffix,\n    });\n}\nexport function _property(property, schema, params) {\n    return new checks.$ZodCheckProperty({\n        check: \"property\",\n        property,\n        schema,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _mime(types, params) {\n    return new checks.$ZodCheckMimeType({\n        check: \"mime_type\",\n        mime: types,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _overwrite(tx) {\n    return new checks.$ZodCheckOverwrite({\n        check: \"overwrite\",\n        tx,\n    });\n}\n// normalize\nexport function _normalize(form) {\n    return _overwrite((input) => input.normalize(form));\n}\n// trim\nexport function _trim() {\n    return _overwrite((input) => input.trim());\n}\n// toLowerCase\nexport function _toLowerCase() {\n    return _overwrite((input) => input.toLowerCase());\n}\n// toUpperCase\nexport function _toUpperCase() {\n    return _overwrite((input) => input.toUpperCase());\n}\nexport function _array(Class, element, params) {\n    return new Class({\n        type: \"array\",\n        element,\n        // get element() {\n        //   return element;\n        // },\n        ...util.normalizeParams(params),\n    });\n}\nexport function _union(Class, options, params) {\n    return new Class({\n        type: \"union\",\n        options,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _discriminatedUnion(Class, discriminator, options, params) {\n    return new Class({\n        type: \"union\",\n        options,\n        discriminator,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _intersection(Class, left, right) {\n    return new Class({\n        type: \"intersection\",\n        left,\n        right,\n    });\n}\n// export function _tuple(\n//   Class: util.SchemaClass<schemas.$ZodTuple>,\n//   items: [],\n//   params?: string | $ZodTupleParams\n// ): schemas.$ZodTuple<[], null>;\nexport function _tuple(Class, items, _paramsOrRest, _params) {\n    const hasRest = _paramsOrRest instanceof schemas.$ZodType;\n    const params = hasRest ? _params : _paramsOrRest;\n    const rest = hasRest ? _paramsOrRest : null;\n    return new Class({\n        type: \"tuple\",\n        items,\n        rest,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _record(Class, keyType, valueType, params) {\n    return new Class({\n        type: \"record\",\n        keyType,\n        valueType,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _map(Class, keyType, valueType, params) {\n    return new Class({\n        type: \"map\",\n        keyType,\n        valueType,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _set(Class, valueType, params) {\n    return new Class({\n        type: \"set\",\n        valueType,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _enum(Class, values, params) {\n    const entries = Array.isArray(values) ? Object.fromEntries(values.map((v) => [v, v])) : values;\n    // if (Array.isArray(values)) {\n    //   for (const value of values) {\n    //     entries[value] = value;\n    //   }\n    // } else {\n    //   Object.assign(entries, values);\n    // }\n    // const entries: util.EnumLike = {};\n    // for (const val of values) {\n    //   entries[val] = val;\n    // }\n    return new Class({\n        type: \"enum\",\n        entries,\n        ...util.normalizeParams(params),\n    });\n}\n/** @deprecated This API has been merged into `z.enum()`. Use `z.enum()` instead.\n *\n * ```ts\n * enum Colors { red, green, blue }\n * z.enum(Colors);\n * ```\n */\nexport function _nativeEnum(Class, entries, params) {\n    return new Class({\n        type: \"enum\",\n        entries,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _literal(Class, value, params) {\n    return new Class({\n        type: \"literal\",\n        values: Array.isArray(value) ? value : [value],\n        ...util.normalizeParams(params),\n    });\n}\nexport function _file(Class, params) {\n    return new Class({\n        type: \"file\",\n        ...util.normalizeParams(params),\n    });\n}\nexport function _transform(Class, fn) {\n    return new Class({\n        type: \"transform\",\n        transform: fn,\n    });\n}\nexport function _optional(Class, innerType) {\n    return new Class({\n        type: \"optional\",\n        innerType,\n    });\n}\nexport function _nullable(Class, innerType) {\n    return new Class({\n        type: \"nullable\",\n        innerType,\n    });\n}\nexport function _default(Class, innerType, defaultValue) {\n    return new Class({\n        type: \"default\",\n        innerType,\n        get defaultValue() {\n            return typeof defaultValue === \"function\" ? defaultValue() : defaultValue;\n        },\n    });\n}\nexport function _nonoptional(Class, innerType, params) {\n    return new Class({\n        type: \"nonoptional\",\n        innerType,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _success(Class, innerType) {\n    return new Class({\n        type: \"success\",\n        innerType,\n    });\n}\nexport function _catch(Class, innerType, catchValue) {\n    return new Class({\n        type: \"catch\",\n        innerType,\n        catchValue: (typeof catchValue === \"function\" ? catchValue : () => catchValue),\n    });\n}\nexport function _pipe(Class, in_, out) {\n    return new Class({\n        type: \"pipe\",\n        in: in_,\n        out,\n    });\n}\nexport function _readonly(Class, innerType) {\n    return new Class({\n        type: \"readonly\",\n        innerType,\n    });\n}\nexport function _templateLiteral(Class, parts, params) {\n    return new Class({\n        type: \"template_literal\",\n        parts,\n        ...util.normalizeParams(params),\n    });\n}\nexport function _lazy(Class, getter) {\n    return new Class({\n        type: \"lazy\",\n        getter,\n    });\n}\nexport function _promise(Class, innerType) {\n    return new Class({\n        type: \"promise\",\n        innerType,\n    });\n}\nexport function _custom(Class, fn, _params) {\n    const norm = util.normalizeParams(_params);\n    norm.abort ?? (norm.abort = true); // default to abort:false\n    const schema = new Class({\n        type: \"custom\",\n        check: \"custom\",\n        fn: fn,\n        ...norm,\n    });\n    return schema;\n}\n// export function _refine<T>(\n//   Class: util.SchemaClass<schemas.$ZodCustom>,\n//   fn: (arg: NoInfer<T>) => util.MaybeAsync<unknown>,\n//   _params: string | $ZodCustomParams = {}\n// ): checks.$ZodCheck<T> {\n//   return _custom(Class, fn, _params);\n// }\n// same as _custom but defaults to abort:false\nexport function _refine(Class, fn, _params) {\n    const schema = new Class({\n        type: \"custom\",\n        check: \"custom\",\n        fn: fn,\n        ...util.normalizeParams(_params),\n    });\n    return schema;\n}\nexport function _stringbool(Classes, _params) {\n    const params = util.normalizeParams(_params);\n    let truthyArray = params.truthy ?? [\"true\", \"1\", \"yes\", \"on\", \"y\", \"enabled\"];\n    let falsyArray = params.falsy ?? [\"false\", \"0\", \"no\", \"off\", \"n\", \"disabled\"];\n    if (params.case !== \"sensitive\") {\n        truthyArray = truthyArray.map((v) => (typeof v === \"string\" ? v.toLowerCase() : v));\n        falsyArray = falsyArray.map((v) => (typeof v === \"string\" ? v.toLowerCase() : v));\n    }\n    const truthySet = new Set(truthyArray);\n    const falsySet = new Set(falsyArray);\n    const _Pipe = Classes.Pipe ?? schemas.$ZodPipe;\n    const _Boolean = Classes.Boolean ?? schemas.$ZodBoolean;\n    const _String = Classes.String ?? schemas.$ZodString;\n    const _Transform = Classes.Transform ?? schemas.$ZodTransform;\n    const tx = new _Transform({\n        type: \"transform\",\n        transform: (input, payload) => {\n            let data = input;\n            if (params.case !== \"sensitive\")\n                data = data.toLowerCase();\n            if (truthySet.has(data)) {\n                return true;\n            }\n            else if (falsySet.has(data)) {\n                return false;\n            }\n            else {\n                payload.issues.push({\n                    code: \"invalid_value\",\n                    expected: \"stringbool\",\n                    values: [...truthySet, ...falsySet],\n                    input: payload.value,\n                    inst: tx,\n                });\n                return {};\n            }\n        },\n        error: params.error,\n    });\n    // params.error;\n    const innerPipe = new _Pipe({\n        type: \"pipe\",\n        in: new _String({ type: \"string\", error: params.error }),\n        out: tx,\n        error: params.error,\n    });\n    const outerPipe = new _Pipe({\n        type: \"pipe\",\n        in: innerPipe,\n        out: new _Boolean({\n            type: \"boolean\",\n            error: params.error,\n        }),\n        error: params.error,\n    });\n    return outerPipe;\n}\nexport function _stringFormat(Class, format, fnOrRegex, _params = {}) {\n    const params = util.normalizeParams(_params);\n    const def = {\n        ...util.normalizeParams(_params),\n        check: \"string_format\",\n        type: \"string\",\n        format,\n        fn: typeof fnOrRegex === \"function\" ? fnOrRegex : (val) => fnOrRegex.test(val),\n        ...params,\n    };\n    if (fnOrRegex instanceof RegExp) {\n        def.pattern = fnOrRegex;\n    }\n    const inst = new Class(def);\n    return inst;\n}\n","import { $ZodNever, $ZodOptional, $ZodUnknown, _never, _unknown, clone, globalRegistry, parse, parseAsync, util } from \"zod/v4/core\";\n\n//#region src/utils/types/zod.ts\nfunction isZodSchemaV4(schema) {\n\tif (typeof schema !== \"object\" || schema === null) return false;\n\tconst obj = schema;\n\tif (!(\"_zod\" in obj)) return false;\n\tconst zod = obj._zod;\n\treturn typeof zod === \"object\" && zod !== null && \"def\" in zod;\n}\nfunction isZodSchemaV3(schema) {\n\tif (typeof schema !== \"object\" || schema === null) return false;\n\tconst obj = schema;\n\tif (!(\"_def\" in obj) || \"_zod\" in obj) return false;\n\tconst def = obj._def;\n\treturn typeof def === \"object\" && def != null && \"typeName\" in def;\n}\n/** Backward compatible isZodSchema for Zod 3 */\nfunction isZodSchema(schema) {\n\tif (isZodSchemaV4(schema)) console.warn(\"[WARNING] Attempting to use Zod 4 schema in a context where Zod 3 schema is expected. This may cause unexpected behavior.\");\n\treturn isZodSchemaV3(schema);\n}\n/**\n* Given either a Zod schema, or plain object, determine if the input is a Zod schema.\n*\n* @param {unknown} input\n* @returns {boolean} Whether or not the provided input is a Zod schema.\n*/\nfunction isInteropZodSchema(input) {\n\tif (!input) return false;\n\tif (typeof input !== \"object\") return false;\n\tif (Array.isArray(input)) return false;\n\tif (isZodSchemaV4(input) || isZodSchemaV3(input)) return true;\n\treturn false;\n}\nfunction isZodLiteralV3(obj) {\n\tif (typeof obj === \"object\" && obj !== null && \"_def\" in obj && typeof obj._def === \"object\" && obj._def !== null && \"typeName\" in obj._def && obj._def.typeName === \"ZodLiteral\") return true;\n\treturn false;\n}\nfunction isZodLiteralV4(obj) {\n\tif (!isZodSchemaV4(obj)) return false;\n\tif (typeof obj === \"object\" && obj !== null && \"_zod\" in obj && typeof obj._zod === \"object\" && obj._zod !== null && \"def\" in obj._zod && typeof obj._zod.def === \"object\" && obj._zod.def !== null && \"type\" in obj._zod.def && obj._zod.def.type === \"literal\") return true;\n\treturn false;\n}\n/**\n* Determines if the provided value is an InteropZodLiteral (Zod v3 or v4 literal schema).\n*\n* @param obj The value to check.\n* @returns {boolean} True if the value is a Zod v3 or v4 literal schema, false otherwise.\n*/\nfunction isInteropZodLiteral(obj) {\n\tif (isZodLiteralV3(obj)) return true;\n\tif (isZodLiteralV4(obj)) return true;\n\treturn false;\n}\n/**\n* Asynchronously parses the input using the provided Zod schema (v3 or v4) and returns a safe parse result.\n* This function handles both Zod v3 and v4 schemas, returning a result object indicating success or failure.\n*\n* @template T - The expected output type of the schema.\n* @param {InteropZodType<T>} schema - The Zod schema (v3 or v4) to use for parsing.\n* @param {unknown} input - The input value to parse.\n* @returns {Promise<InteropZodSafeParseResult<T>>} A promise that resolves to a safe parse result object.\n* @throws {Error} If the schema is not a recognized Zod v3 or v4 schema.\n*/\nasync function interopSafeParseAsync(schema, input) {\n\tif (isZodSchemaV4(schema)) try {\n\t\tconst data = await parseAsync(schema, input);\n\t\treturn {\n\t\t\tsuccess: true,\n\t\t\tdata\n\t\t};\n\t} catch (error) {\n\t\treturn {\n\t\t\tsuccess: false,\n\t\t\terror\n\t\t};\n\t}\n\tif (isZodSchemaV3(schema)) return await schema.safeParseAsync(input);\n\tthrow new Error(\"Schema must be an instance of z3.ZodType or z4.$ZodType\");\n}\n/**\n* Asynchronously parses the input using the provided Zod schema (v3 or v4) and returns the parsed value.\n* Throws an error if parsing fails or if the schema is not a recognized Zod v3 or v4 schema.\n*\n* @template T - The expected output type of the schema.\n* @param {InteropZodType<T>} schema - The Zod schema (v3 or v4) to use for parsing.\n* @param {unknown} input - The input value to parse.\n* @returns {Promise<T>} A promise that resolves to the parsed value.\n* @throws {Error} If parsing fails or the schema is not a recognized Zod v3 or v4 schema.\n*/\nasync function interopParseAsync(schema, input) {\n\tif (isZodSchemaV4(schema)) return await parseAsync(schema, input);\n\tif (isZodSchemaV3(schema)) return await schema.parseAsync(input);\n\tthrow new Error(\"Schema must be an instance of z3.ZodType or z4.$ZodType\");\n}\n/**\n* Safely parses the input using the provided Zod schema (v3 or v4) and returns a result object\n* indicating success or failure. This function is compatible with both Zod v3 and v4 schemas.\n*\n* @template T - The expected output type of the schema.\n* @param {InteropZodType<T>} schema - The Zod schema (v3 or v4) to use for parsing.\n* @param {unknown} input - The input value to parse.\n* @returns {InteropZodSafeParseResult<T>} An object with either the parsed data (on success)\n*   or the error (on failure).\n* @throws {Error} If the schema is not a recognized Zod v3 or v4 schema.\n*/\nfunction interopSafeParse(schema, input) {\n\tif (isZodSchemaV4(schema)) try {\n\t\tconst data = parse(schema, input);\n\t\treturn {\n\t\t\tsuccess: true,\n\t\t\tdata\n\t\t};\n\t} catch (error) {\n\t\treturn {\n\t\t\tsuccess: false,\n\t\t\terror\n\t\t};\n\t}\n\tif (isZodSchemaV3(schema)) return schema.safeParse(input);\n\tthrow new Error(\"Schema must be an instance of z3.ZodType or z4.$ZodType\");\n}\n/**\n* Parses the input using the provided Zod schema (v3 or v4) and returns the parsed value.\n* Throws an error if parsing fails or if the schema is not a recognized Zod v3 or v4 schema.\n*\n* @template T - The expected output type of the schema.\n* @param {InteropZodType<T>} schema - The Zod schema (v3 or v4) to use for parsing.\n* @param {unknown} input - The input value to parse.\n* @returns {T} The parsed value.\n* @throws {Error} If parsing fails or the schema is not a recognized Zod v3 or v4 schema.\n*/\nfunction interopParse(schema, input) {\n\tif (isZodSchemaV4(schema)) return parse(schema, input);\n\tif (isZodSchemaV3(schema)) return schema.parse(input);\n\tthrow new Error(\"Schema must be an instance of z3.ZodType or z4.$ZodType\");\n}\n/**\n* Retrieves the description from a schema definition (v3, v4, or plain object), if available.\n*\n* @param {unknown} schema - The schema to extract the description from.\n* @returns {string | undefined} The description of the schema, or undefined if not present.\n*/\nfunction getSchemaDescription(schema) {\n\tif (isZodSchemaV4(schema)) return globalRegistry.get(schema)?.description;\n\tif (isZodSchemaV3(schema)) return schema.description;\n\tif (\"description\" in schema && typeof schema.description === \"string\") return schema.description;\n\treturn void 0;\n}\n/**\n* Determines if the provided Zod schema is \"shapeless\".\n* A shapeless schema is one that does not define any object shape,\n* such as ZodString, ZodNumber, ZodBoolean, ZodAny, etc.\n* For ZodObject, it must have no shape keys to be considered shapeless.\n* ZodRecord schemas are considered shapeless since they define dynamic\n* key-value mappings without fixed keys.\n*\n* @param schema The Zod schema to check.\n* @returns {boolean} True if the schema is shapeless, false otherwise.\n*/\nfunction isShapelessZodSchema(schema) {\n\tif (!isInteropZodSchema(schema)) return false;\n\tif (isZodSchemaV3(schema)) {\n\t\tconst def = schema._def;\n\t\tif (def.typeName === \"ZodObject\") {\n\t\t\tconst obj = schema;\n\t\t\treturn !obj.shape || Object.keys(obj.shape).length === 0;\n\t\t}\n\t\tif (def.typeName === \"ZodRecord\") return true;\n\t}\n\tif (isZodSchemaV4(schema)) {\n\t\tconst def = schema._zod.def;\n\t\tif (def.type === \"object\") {\n\t\t\tconst obj = schema;\n\t\t\treturn !obj.shape || Object.keys(obj.shape).length === 0;\n\t\t}\n\t\tif (def.type === \"record\") return true;\n\t}\n\tif (typeof schema === \"object\" && schema !== null && !(\"shape\" in schema)) return true;\n\treturn false;\n}\n/**\n* Determines if the provided Zod schema should be treated as a simple string schema\n* that maps to DynamicTool. This aligns with the type-level constraint of\n* InteropZodType<string | undefined> which only matches basic string schemas.\n* If the provided schema is just z.string(), we can make the determination that\n* the tool is just a generic string tool that doesn't require any input validation.\n*\n* This function only returns true for basic ZodString schemas, including:\n* - Basic string schemas (z.string())\n* - String schemas with validations (z.string().min(1), z.string().email(), etc.)\n*\n* This function returns false for everything else, including:\n* - String schemas with defaults (z.string().default(\"value\"))\n* - Branded string schemas (z.string().brand<\"UserId\">())\n* - String schemas with catch operations (z.string().catch(\"default\"))\n* - Optional/nullable string schemas (z.string().optional())\n* - Transformed schemas (z.string().transform() or z.object().transform())\n* - Object or record schemas, even if they're empty\n* - Any other schema type\n*\n* @param schema The Zod schema to check.\n* @returns {boolean} True if the schema is a basic ZodString, false otherwise.\n*/\nfunction isSimpleStringZodSchema(schema) {\n\tif (!isInteropZodSchema(schema)) return false;\n\tif (isZodSchemaV3(schema)) {\n\t\tconst def = schema._def;\n\t\treturn def.typeName === \"ZodString\";\n\t}\n\tif (isZodSchemaV4(schema)) {\n\t\tconst def = schema._zod.def;\n\t\treturn def.type === \"string\";\n\t}\n\treturn false;\n}\nfunction isZodObjectV3(obj) {\n\tif (typeof obj === \"object\" && obj !== null && \"_def\" in obj && typeof obj._def === \"object\" && obj._def !== null && \"typeName\" in obj._def && obj._def.typeName === \"ZodObject\") return true;\n\treturn false;\n}\nfunction isZodObjectV4(obj) {\n\tif (!isZodSchemaV4(obj)) return false;\n\tif (typeof obj === \"object\" && obj !== null && \"_zod\" in obj && typeof obj._zod === \"object\" && obj._zod !== null && \"def\" in obj._zod && typeof obj._zod.def === \"object\" && obj._zod.def !== null && \"type\" in obj._zod.def && obj._zod.def.type === \"object\") return true;\n\treturn false;\n}\nfunction isZodArrayV4(obj) {\n\tif (!isZodSchemaV4(obj)) return false;\n\tif (typeof obj === \"object\" && obj !== null && \"_zod\" in obj && typeof obj._zod === \"object\" && obj._zod !== null && \"def\" in obj._zod && typeof obj._zod.def === \"object\" && obj._zod.def !== null && \"type\" in obj._zod.def && obj._zod.def.type === \"array\") return true;\n\treturn false;\n}\n/**\n* Determines if the provided value is an InteropZodObject (Zod v3 or v4 object schema).\n*\n* @param obj The value to check.\n* @returns {boolean} True if the value is a Zod v3 or v4 object schema, false otherwise.\n*/\nfunction isInteropZodObject(obj) {\n\tif (isZodObjectV3(obj)) return true;\n\tif (isZodObjectV4(obj)) return true;\n\treturn false;\n}\n/**\n* Retrieves the shape (fields) of a Zod object schema, supporting both Zod v3 and v4.\n*\n* @template T - The type of the Zod object schema.\n* @param {T} schema - The Zod object schema instance (either v3 or v4).\n* @returns {InteropZodObjectShape<T>} The shape of the object schema.\n* @throws {Error} If the schema is not a Zod v3 or v4 object.\n*/\nfunction getInteropZodObjectShape(schema) {\n\tif (isZodSchemaV3(schema)) return schema.shape;\n\tif (isZodSchemaV4(schema)) return schema._zod.def.shape;\n\tthrow new Error(\"Schema must be an instance of z3.ZodObject or z4.$ZodObject\");\n}\n/**\n* Extends a Zod object schema with additional fields, supporting both Zod v3 and v4.\n*\n* @template T - The type of the Zod object schema.\n* @param {T} schema - The Zod object schema instance (either v3 or v4).\n* @param {InteropZodObjectShape} extension - The fields to add to the schema.\n* @returns {InteropZodObject} The extended Zod object schema.\n* @throws {Error} If the schema is not a Zod v3 or v4 object.\n*/\nfunction extendInteropZodObject(schema, extension) {\n\tif (isZodSchemaV3(schema)) return schema.extend(extension);\n\tif (isZodSchemaV4(schema)) return util.extend(schema, extension);\n\tthrow new Error(\"Schema must be an instance of z3.ZodObject or z4.$ZodObject\");\n}\n/**\n* Returns a partial version of a Zod object schema, making all fields optional.\n* Supports both Zod v3 and v4.\n*\n* @template T - The type of the Zod object schema.\n* @param {T} schema - The Zod object schema instance (either v3 or v4).\n* @returns {InteropZodObject} The partial Zod object schema.\n* @throws {Error} If the schema is not a Zod v3 or v4 object.\n*/\nfunction interopZodObjectPartial(schema) {\n\tif (isZodSchemaV3(schema)) return schema.partial();\n\tif (isZodSchemaV4(schema)) return util.partial($ZodOptional, schema, void 0);\n\tthrow new Error(\"Schema must be an instance of z3.ZodObject or z4.$ZodObject\");\n}\n/**\n* Returns a strict version of a Zod object schema, disallowing unknown keys.\n* Supports both Zod v3 and v4 object schemas. If `recursive` is true, applies strictness\n* recursively to all nested object schemas and arrays of object schemas.\n*\n* @template T - The type of the Zod object schema.\n* @param {T} schema - The Zod object schema instance (either v3 or v4).\n* @param {boolean} [recursive=false] - Whether to apply strictness recursively to nested objects/arrays.\n* @returns {InteropZodObject} The strict Zod object schema.\n* @throws {Error} If the schema is not a Zod v3 or v4 object.\n*/\nfunction interopZodObjectStrict(schema, recursive = false) {\n\tif (isZodSchemaV3(schema)) return schema.strict();\n\tif (isZodObjectV4(schema)) {\n\t\tconst outputShape = schema._zod.def.shape;\n\t\tif (recursive) for (const [key, keySchema] of Object.entries(schema._zod.def.shape)) {\n\t\t\tif (isZodObjectV4(keySchema)) {\n\t\t\t\tconst outputSchema = interopZodObjectStrict(keySchema, recursive);\n\t\t\t\toutputShape[key] = outputSchema;\n\t\t\t} else if (isZodArrayV4(keySchema)) {\n\t\t\t\tlet elementSchema = keySchema._zod.def.element;\n\t\t\t\tif (isZodObjectV4(elementSchema)) elementSchema = interopZodObjectStrict(elementSchema, recursive);\n\t\t\t\toutputShape[key] = clone(keySchema, {\n\t\t\t\t\t...keySchema._zod.def,\n\t\t\t\t\telement: elementSchema\n\t\t\t\t});\n\t\t\t} else outputShape[key] = keySchema;\n\t\t\tconst meta$1 = globalRegistry.get(keySchema);\n\t\t\tif (meta$1) globalRegistry.add(outputShape[key], meta$1);\n\t\t}\n\t\tconst modifiedSchema = clone(schema, {\n\t\t\t...schema._zod.def,\n\t\t\tshape: outputShape,\n\t\t\tcatchall: _never($ZodNever)\n\t\t});\n\t\tconst meta = globalRegistry.get(schema);\n\t\tif (meta) globalRegistry.add(modifiedSchema, meta);\n\t\treturn modifiedSchema;\n\t}\n\tthrow new Error(\"Schema must be an instance of z3.ZodObject or z4.$ZodObject\");\n}\n/**\n* Returns a passthrough version of a Zod object schema, allowing unknown keys.\n* Supports both Zod v3 and v4 object schemas. If `recursive` is true, applies passthrough\n* recursively to all nested object schemas and arrays of object schemas.\n*\n* @template T - The type of the Zod object schema.\n* @param {T} schema - The Zod object schema instance (either v3 or v4).\n* @param {boolean} [recursive=false] - Whether to apply passthrough recursively to nested objects/arrays.\n* @returns {InteropZodObject} The passthrough Zod object schema.\n* @throws {Error} If the schema is not a Zod v3 or v4 object.\n*/\nfunction interopZodObjectPassthrough(schema, recursive = false) {\n\tif (isZodObjectV3(schema)) return schema.passthrough();\n\tif (isZodObjectV4(schema)) {\n\t\tconst outputShape = schema._zod.def.shape;\n\t\tif (recursive) for (const [key, keySchema] of Object.entries(schema._zod.def.shape)) {\n\t\t\tif (isZodObjectV4(keySchema)) {\n\t\t\t\tconst outputSchema = interopZodObjectPassthrough(keySchema, recursive);\n\t\t\t\toutputShape[key] = outputSchema;\n\t\t\t} else if (isZodArrayV4(keySchema)) {\n\t\t\t\tlet elementSchema = keySchema._zod.def.element;\n\t\t\t\tif (isZodObjectV4(elementSchema)) elementSchema = interopZodObjectPassthrough(elementSchema, recursive);\n\t\t\t\toutputShape[key] = clone(keySchema, {\n\t\t\t\t\t...keySchema._zod.def,\n\t\t\t\t\telement: elementSchema\n\t\t\t\t});\n\t\t\t} else outputShape[key] = keySchema;\n\t\t\tconst meta$1 = globalRegistry.get(keySchema);\n\t\t\tif (meta$1) globalRegistry.add(outputShape[key], meta$1);\n\t\t}\n\t\tconst modifiedSchema = clone(schema, {\n\t\t\t...schema._zod.def,\n\t\t\tshape: outputShape,\n\t\t\tcatchall: _unknown($ZodUnknown)\n\t\t});\n\t\tconst meta = globalRegistry.get(schema);\n\t\tif (meta) globalRegistry.add(modifiedSchema, meta);\n\t\treturn modifiedSchema;\n\t}\n\tthrow new Error(\"Schema must be an instance of z3.ZodObject or z4.$ZodObject\");\n}\n/**\n* Returns a getter function for the default value of a Zod schema, if one is defined.\n* Supports both Zod v3 and v4 schemas. If the schema has a default value,\n* the returned function will return that value when called. If no default is defined,\n* returns undefined.\n*\n* @template T - The type of the Zod schema.\n* @param {T} schema - The Zod schema instance (either v3 or v4).\n* @returns {(() => InferInteropZodOutput<T>) | undefined} A function that returns the default value, or undefined if no default is set.\n*/\nfunction getInteropZodDefaultGetter(schema) {\n\tif (isZodSchemaV3(schema)) try {\n\t\tconst defaultValue = schema.parse(void 0);\n\t\treturn () => defaultValue;\n\t} catch {\n\t\treturn void 0;\n\t}\n\tif (isZodSchemaV4(schema)) try {\n\t\tconst defaultValue = parse(schema, void 0);\n\t\treturn () => defaultValue;\n\t} catch {\n\t\treturn void 0;\n\t}\n\treturn void 0;\n}\nfunction isZodTransformV3(schema) {\n\treturn isZodSchemaV3(schema) && \"typeName\" in schema._def && schema._def.typeName === \"ZodEffects\";\n}\nfunction isZodTransformV4(schema) {\n\treturn isZodSchemaV4(schema) && schema._zod.def.type === \"pipe\";\n}\n/**\n* Returns the input type of a Zod transform schema, for both v3 and v4.\n* If the schema is not a transform, returns undefined. If `recursive` is true,\n* recursively processes nested object schemas and arrays of object schemas.\n*\n* @param schema - The Zod schema instance (v3 or v4)\n* @param {boolean} [recursive=false] - Whether to recursively process nested objects/arrays.\n* @returns The input Zod schema of the transform, or undefined if not a transform\n*/\nfunction interopZodTransformInputSchema(schema, recursive = false) {\n\tif (isZodSchemaV3(schema)) {\n\t\tif (isZodTransformV3(schema)) return interopZodTransformInputSchema(schema._def.schema, recursive);\n\t\treturn schema;\n\t}\n\tif (isZodSchemaV4(schema)) {\n\t\tlet outputSchema = schema;\n\t\tif (isZodTransformV4(schema)) outputSchema = interopZodTransformInputSchema(schema._zod.def.in, recursive);\n\t\tif (recursive) {\n\t\t\tif (isZodObjectV4(outputSchema)) {\n\t\t\t\tconst outputShape = outputSchema._zod.def.shape;\n\t\t\t\tfor (const [key, keySchema] of Object.entries(outputSchema._zod.def.shape)) outputShape[key] = interopZodTransformInputSchema(keySchema, recursive);\n\t\t\t\toutputSchema = clone(outputSchema, {\n\t\t\t\t\t...outputSchema._zod.def,\n\t\t\t\t\tshape: outputShape\n\t\t\t\t});\n\t\t\t} else if (isZodArrayV4(outputSchema)) {\n\t\t\t\tconst elementSchema = interopZodTransformInputSchema(outputSchema._zod.def.element, recursive);\n\t\t\t\toutputSchema = clone(outputSchema, {\n\t\t\t\t\t...outputSchema._zod.def,\n\t\t\t\t\telement: elementSchema\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\tconst meta = globalRegistry.get(schema);\n\t\tif (meta) globalRegistry.add(outputSchema, meta);\n\t\treturn outputSchema;\n\t}\n\tthrow new Error(\"Schema must be an instance of z3.ZodType or z4.$ZodType\");\n}\n/**\n* Creates a modified version of a Zod object schema where fields matching a predicate are made optional.\n* Supports both Zod v3 and v4 schemas and preserves the original schema version.\n*\n* @template T - The type of the Zod object schema.\n* @param {T} schema - The Zod object schema instance (either v3 or v4).\n* @param {(key: string, value: InteropZodType) => boolean} predicate - Function to determine which fields should be optional.\n* @returns {InteropZodObject} The modified Zod object schema.\n* @throws {Error} If the schema is not a Zod v3 or v4 object.\n*/\nfunction interopZodObjectMakeFieldsOptional(schema, predicate) {\n\tif (isZodSchemaV3(schema)) {\n\t\tconst shape = getInteropZodObjectShape(schema);\n\t\tconst modifiedShape = {};\n\t\tfor (const [key, value] of Object.entries(shape)) if (predicate(key, value)) modifiedShape[key] = value.optional();\n\t\telse modifiedShape[key] = value;\n\t\treturn schema.extend(modifiedShape);\n\t}\n\tif (isZodSchemaV4(schema)) {\n\t\tconst shape = getInteropZodObjectShape(schema);\n\t\tconst outputShape = { ...schema._zod.def.shape };\n\t\tfor (const [key, value] of Object.entries(shape)) if (predicate(key, value)) outputShape[key] = new $ZodOptional({\n\t\t\ttype: \"optional\",\n\t\t\tinnerType: value\n\t\t});\n\t\tconst modifiedSchema = clone(schema, {\n\t\t\t...schema._zod.def,\n\t\t\tshape: outputShape\n\t\t});\n\t\tconst meta = globalRegistry.get(schema);\n\t\tif (meta) globalRegistry.add(modifiedSchema, meta);\n\t\treturn modifiedSchema;\n\t}\n\tthrow new Error(\"Schema must be an instance of z3.ZodObject or z4.$ZodObject\");\n}\n\n//#endregion\nexport { extendInteropZodObject, getInteropZodDefaultGetter, getInteropZodObjectShape, getSchemaDescription, interopParse, interopParseAsync, interopSafeParse, interopSafeParseAsync, interopZodObjectMakeFieldsOptional, interopZodObjectPartial, interopZodObjectPassthrough, interopZodObjectStrict, interopZodTransformInputSchema, isInteropZodLiteral, isInteropZodObject, isInteropZodSchema, isShapelessZodSchema, isSimpleStringZodSchema, isZodArrayV4, isZodLiteralV3, isZodLiteralV4, isZodObjectV3, isZodObjectV4, isZodSchema, isZodSchemaV3, isZodSchemaV4 };\n//# sourceMappingURL=zod.js.map","//#region src/utils/zod-to-json-schema/Options.ts\nconst ignoreOverride = Symbol(\"Let zodToJsonSchema decide on which parser to use\");\nconst defaultOptions = {\n\tname: void 0,\n\t$refStrategy: \"root\",\n\tbasePath: [\"#\"],\n\teffectStrategy: \"input\",\n\tpipeStrategy: \"all\",\n\tdateStrategy: \"format:date-time\",\n\tmapStrategy: \"entries\",\n\tremoveAdditionalStrategy: \"passthrough\",\n\tallowedAdditionalProperties: true,\n\trejectedAdditionalProperties: false,\n\tdefinitionPath: \"definitions\",\n\ttarget: \"jsonSchema7\",\n\tstrictUnions: false,\n\tdefinitions: {},\n\terrorMessages: false,\n\tmarkdownDescription: false,\n\tpatternStrategy: \"escape\",\n\tapplyRegexFlags: false,\n\temailStrategy: \"format:email\",\n\tbase64Strategy: \"contentEncoding:base64\",\n\tnameStrategy: \"ref\",\n\topenAiAnyTypeName: \"OpenAiAnyType\"\n};\nconst getDefaultOptions = (options) => typeof options === \"string\" ? {\n\t...defaultOptions,\n\tname: options\n} : {\n\t...defaultOptions,\n\t...options\n};\n\n//#endregion\nexport { defaultOptions, getDefaultOptions, ignoreOverride };\n//# sourceMappingURL=Options.js.map","import { getDefaultOptions } from \"./Options.js\";\n\n//#region src/utils/zod-to-json-schema/Refs.ts\nconst getRefs = (options) => {\n\tconst _options = getDefaultOptions(options);\n\tconst currentPath = _options.name !== void 0 ? [\n\t\t..._options.basePath,\n\t\t_options.definitionPath,\n\t\t_options.name\n\t] : _options.basePath;\n\treturn {\n\t\t..._options,\n\t\tflags: { hasReferencedOpenAiAnyType: false },\n\t\tcurrentPath,\n\t\tpropertyPath: void 0,\n\t\tseen: new Map(Object.entries(_options.definitions).map(([name, def]) => [def._def, {\n\t\t\tdef: def._def,\n\t\t\tpath: [\n\t\t\t\t..._options.basePath,\n\t\t\t\t_options.definitionPath,\n\t\t\t\tname\n\t\t\t],\n\t\t\tjsonSchema: void 0\n\t\t}]))\n\t};\n};\n\n//#endregion\nexport { getRefs };\n//# sourceMappingURL=Refs.js.map","//#region src/utils/zod-to-json-schema/getRelativePath.ts\nconst getRelativePath = (pathA, pathB) => {\n\tlet i = 0;\n\tfor (; i < pathA.length && i < pathB.length; i++) if (pathA[i] !== pathB[i]) break;\n\treturn [(pathA.length - i).toString(), ...pathB.slice(i)].join(\"/\");\n};\n\n//#endregion\nexport { getRelativePath };\n//# sourceMappingURL=getRelativePath.js.map","import { getRelativePath } from \"../getRelativePath.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/any.ts\nfunction parseAnyDef(refs) {\n\tif (refs.target !== \"openAi\") return {};\n\tconst anyDefinitionPath = [\n\t\t...refs.basePath,\n\t\trefs.definitionPath,\n\t\trefs.openAiAnyTypeName\n\t];\n\trefs.flags.hasReferencedOpenAiAnyType = true;\n\treturn { $ref: refs.$refStrategy === \"relative\" ? getRelativePath(anyDefinitionPath, refs.currentPath) : anyDefinitionPath.join(\"/\") };\n}\n\n//#endregion\nexport { parseAnyDef };\n//# sourceMappingURL=any.js.map","//#region src/utils/zod-to-json-schema/errorMessages.ts\nfunction addErrorMessage(res, key, errorMessage, refs) {\n\tif (!refs?.errorMessages) return;\n\tif (errorMessage) res.errorMessage = {\n\t\t...res.errorMessage,\n\t\t[key]: errorMessage\n\t};\n}\nfunction setResponseValueAndErrors(res, key, value, errorMessage, refs) {\n\tres[key] = value;\n\taddErrorMessage(res, key, errorMessage, refs);\n}\n\n//#endregion\nexport { addErrorMessage, setResponseValueAndErrors };\n//# sourceMappingURL=errorMessages.js.map","export var util;\n(function (util) {\n    util.assertEqual = (_) => { };\n    function assertIs(_arg) { }\n    util.assertIs = assertIs;\n    function assertNever(_x) {\n        throw new Error();\n    }\n    util.assertNever = assertNever;\n    util.arrayToEnum = (items) => {\n        const obj = {};\n        for (const item of items) {\n            obj[item] = item;\n        }\n        return obj;\n    };\n    util.getValidEnumValues = (obj) => {\n        const validKeys = util.objectKeys(obj).filter((k) => typeof obj[obj[k]] !== \"number\");\n        const filtered = {};\n        for (const k of validKeys) {\n            filtered[k] = obj[k];\n        }\n        return util.objectValues(filtered);\n    };\n    util.objectValues = (obj) => {\n        return util.objectKeys(obj).map(function (e) {\n            return obj[e];\n        });\n    };\n    util.objectKeys = typeof Object.keys === \"function\" // eslint-disable-line ban/ban\n        ? (obj) => Object.keys(obj) // eslint-disable-line ban/ban\n        : (object) => {\n            const keys = [];\n            for (const key in object) {\n                if (Object.prototype.hasOwnProperty.call(object, key)) {\n                    keys.push(key);\n                }\n            }\n            return keys;\n        };\n    util.find = (arr, checker) => {\n        for (const item of arr) {\n            if (checker(item))\n                return item;\n        }\n        return undefined;\n    };\n    util.isInteger = typeof Number.isInteger === \"function\"\n        ? (val) => Number.isInteger(val) // eslint-disable-line ban/ban\n        : (val) => typeof val === \"number\" && Number.isFinite(val) && Math.floor(val) === val;\n    function joinValues(array, separator = \" | \") {\n        return array.map((val) => (typeof val === \"string\" ? `'${val}'` : val)).join(separator);\n    }\n    util.joinValues = joinValues;\n    util.jsonStringifyReplacer = (_, value) => {\n        if (typeof value === \"bigint\") {\n            return value.toString();\n        }\n        return value;\n    };\n})(util || (util = {}));\nexport var objectUtil;\n(function (objectUtil) {\n    objectUtil.mergeShapes = (first, second) => {\n        return {\n            ...first,\n            ...second, // second overwrites first\n        };\n    };\n})(objectUtil || (objectUtil = {}));\nexport const ZodParsedType = util.arrayToEnum([\n    \"string\",\n    \"nan\",\n    \"number\",\n    \"integer\",\n    \"float\",\n    \"boolean\",\n    \"date\",\n    \"bigint\",\n    \"symbol\",\n    \"function\",\n    \"undefined\",\n    \"null\",\n    \"array\",\n    \"object\",\n    \"unknown\",\n    \"promise\",\n    \"void\",\n    \"never\",\n    \"map\",\n    \"set\",\n]);\nexport const getParsedType = (data) => {\n    const t = typeof data;\n    switch (t) {\n        case \"undefined\":\n            return ZodParsedType.undefined;\n        case \"string\":\n            return ZodParsedType.string;\n        case \"number\":\n            return Number.isNaN(data) ? ZodParsedType.nan : ZodParsedType.number;\n        case \"boolean\":\n            return ZodParsedType.boolean;\n        case \"function\":\n            return ZodParsedType.function;\n        case \"bigint\":\n            return ZodParsedType.bigint;\n        case \"symbol\":\n            return ZodParsedType.symbol;\n        case \"object\":\n            if (Array.isArray(data)) {\n                return ZodParsedType.array;\n            }\n            if (data === null) {\n                return ZodParsedType.null;\n            }\n            if (data.then && typeof data.then === \"function\" && data.catch && typeof data.catch === \"function\") {\n                return ZodParsedType.promise;\n            }\n            if (typeof Map !== \"undefined\" && data instanceof Map) {\n                return ZodParsedType.map;\n            }\n            if (typeof Set !== \"undefined\" && data instanceof Set) {\n                return ZodParsedType.set;\n            }\n            if (typeof Date !== \"undefined\" && data instanceof Date) {\n                return ZodParsedType.date;\n            }\n            return ZodParsedType.object;\n        default:\n            return ZodParsedType.unknown;\n    }\n};\n","import { util } from \"./helpers/util.js\";\nexport const ZodIssueCode = util.arrayToEnum([\n    \"invalid_type\",\n    \"invalid_literal\",\n    \"custom\",\n    \"invalid_union\",\n    \"invalid_union_discriminator\",\n    \"invalid_enum_value\",\n    \"unrecognized_keys\",\n    \"invalid_arguments\",\n    \"invalid_return_type\",\n    \"invalid_date\",\n    \"invalid_string\",\n    \"too_small\",\n    \"too_big\",\n    \"invalid_intersection_types\",\n    \"not_multiple_of\",\n    \"not_finite\",\n]);\nexport const quotelessJson = (obj) => {\n    const json = JSON.stringify(obj, null, 2);\n    return json.replace(/\"([^\"]+)\":/g, \"$1:\");\n};\nexport class ZodError extends Error {\n    get errors() {\n        return this.issues;\n    }\n    constructor(issues) {\n        super();\n        this.issues = [];\n        this.addIssue = (sub) => {\n            this.issues = [...this.issues, sub];\n        };\n        this.addIssues = (subs = []) => {\n            this.issues = [...this.issues, ...subs];\n        };\n        const actualProto = new.target.prototype;\n        if (Object.setPrototypeOf) {\n            // eslint-disable-next-line ban/ban\n            Object.setPrototypeOf(this, actualProto);\n        }\n        else {\n            this.__proto__ = actualProto;\n        }\n        this.name = \"ZodError\";\n        this.issues = issues;\n    }\n    format(_mapper) {\n        const mapper = _mapper ||\n            function (issue) {\n                return issue.message;\n            };\n        const fieldErrors = { _errors: [] };\n        const processError = (error) => {\n            for (const issue of error.issues) {\n                if (issue.code === \"invalid_union\") {\n                    issue.unionErrors.map(processError);\n                }\n                else if (issue.code === \"invalid_return_type\") {\n                    processError(issue.returnTypeError);\n                }\n                else if (issue.code === \"invalid_arguments\") {\n                    processError(issue.argumentsError);\n                }\n                else if (issue.path.length === 0) {\n                    fieldErrors._errors.push(mapper(issue));\n                }\n                else {\n                    let curr = fieldErrors;\n                    let i = 0;\n                    while (i < issue.path.length) {\n                        const el = issue.path[i];\n                        const terminal = i === issue.path.length - 1;\n                        if (!terminal) {\n                            curr[el] = curr[el] || { _errors: [] };\n                            // if (typeof el === \"string\") {\n                            //   curr[el] = curr[el] || { _errors: [] };\n                            // } else if (typeof el === \"number\") {\n                            //   const errorArray: any = [];\n                            //   errorArray._errors = [];\n                            //   curr[el] = curr[el] || errorArray;\n                            // }\n                        }\n                        else {\n                            curr[el] = curr[el] || { _errors: [] };\n                            curr[el]._errors.push(mapper(issue));\n                        }\n                        curr = curr[el];\n                        i++;\n                    }\n                }\n            }\n        };\n        processError(this);\n        return fieldErrors;\n    }\n    static assert(value) {\n        if (!(value instanceof ZodError)) {\n            throw new Error(`Not a ZodError: ${value}`);\n        }\n    }\n    toString() {\n        return this.message;\n    }\n    get message() {\n        return JSON.stringify(this.issues, util.jsonStringifyReplacer, 2);\n    }\n    get isEmpty() {\n        return this.issues.length === 0;\n    }\n    flatten(mapper = (issue) => issue.message) {\n        const fieldErrors = {};\n        const formErrors = [];\n        for (const sub of this.issues) {\n            if (sub.path.length > 0) {\n                const firstEl = sub.path[0];\n                fieldErrors[firstEl] = fieldErrors[firstEl] || [];\n                fieldErrors[firstEl].push(mapper(sub));\n            }\n            else {\n                formErrors.push(mapper(sub));\n            }\n        }\n        return { formErrors, fieldErrors };\n    }\n    get formErrors() {\n        return this.flatten();\n    }\n}\nZodError.create = (issues) => {\n    const error = new ZodError(issues);\n    return error;\n};\n","import { ZodIssueCode } from \"../ZodError.js\";\nimport { util, ZodParsedType } from \"../helpers/util.js\";\nconst errorMap = (issue, _ctx) => {\n    let message;\n    switch (issue.code) {\n        case ZodIssueCode.invalid_type:\n            if (issue.received === ZodParsedType.undefined) {\n                message = \"Required\";\n            }\n            else {\n                message = `Expected ${issue.expected}, received ${issue.received}`;\n            }\n            break;\n        case ZodIssueCode.invalid_literal:\n            message = `Invalid literal value, expected ${JSON.stringify(issue.expected, util.jsonStringifyReplacer)}`;\n            break;\n        case ZodIssueCode.unrecognized_keys:\n            message = `Unrecognized key(s) in object: ${util.joinValues(issue.keys, \", \")}`;\n            break;\n        case ZodIssueCode.invalid_union:\n            message = `Invalid input`;\n            break;\n        case ZodIssueCode.invalid_union_discriminator:\n            message = `Invalid discriminator value. Expected ${util.joinValues(issue.options)}`;\n            break;\n        case ZodIssueCode.invalid_enum_value:\n            message = `Invalid enum value. Expected ${util.joinValues(issue.options)}, received '${issue.received}'`;\n            break;\n        case ZodIssueCode.invalid_arguments:\n            message = `Invalid function arguments`;\n            break;\n        case ZodIssueCode.invalid_return_type:\n            message = `Invalid function return type`;\n            break;\n        case ZodIssueCode.invalid_date:\n            message = `Invalid date`;\n            break;\n        case ZodIssueCode.invalid_string:\n            if (typeof issue.validation === \"object\") {\n                if (\"includes\" in issue.validation) {\n                    message = `Invalid input: must include \"${issue.validation.includes}\"`;\n                    if (typeof issue.validation.position === \"number\") {\n                        message = `${message} at one or more positions greater than or equal to ${issue.validation.position}`;\n                    }\n                }\n                else if (\"startsWith\" in issue.validation) {\n                    message = `Invalid input: must start with \"${issue.validation.startsWith}\"`;\n                }\n                else if (\"endsWith\" in issue.validation) {\n                    message = `Invalid input: must end with \"${issue.validation.endsWith}\"`;\n                }\n                else {\n                    util.assertNever(issue.validation);\n                }\n            }\n            else if (issue.validation !== \"regex\") {\n                message = `Invalid ${issue.validation}`;\n            }\n            else {\n                message = \"Invalid\";\n            }\n            break;\n        case ZodIssueCode.too_small:\n            if (issue.type === \"array\")\n                message = `Array must contain ${issue.exact ? \"exactly\" : issue.inclusive ? `at least` : `more than`} ${issue.minimum} element(s)`;\n            else if (issue.type === \"string\")\n                message = `String must contain ${issue.exact ? \"exactly\" : issue.inclusive ? `at least` : `over`} ${issue.minimum} character(s)`;\n            else if (issue.type === \"number\")\n                message = `Number must be ${issue.exact ? `exactly equal to ` : issue.inclusive ? `greater than or equal to ` : `greater than `}${issue.minimum}`;\n            else if (issue.type === \"bigint\")\n                message = `Number must be ${issue.exact ? `exactly equal to ` : issue.inclusive ? `greater than or equal to ` : `greater than `}${issue.minimum}`;\n            else if (issue.type === \"date\")\n                message = `Date must be ${issue.exact ? `exactly equal to ` : issue.inclusive ? `greater than or equal to ` : `greater than `}${new Date(Number(issue.minimum))}`;\n            else\n                message = \"Invalid input\";\n            break;\n        case ZodIssueCode.too_big:\n            if (issue.type === \"array\")\n                message = `Array must contain ${issue.exact ? `exactly` : issue.inclusive ? `at most` : `less than`} ${issue.maximum} element(s)`;\n            else if (issue.type === \"string\")\n                message = `String must contain ${issue.exact ? `exactly` : issue.inclusive ? `at most` : `under`} ${issue.maximum} character(s)`;\n            else if (issue.type === \"number\")\n                message = `Number must be ${issue.exact ? `exactly` : issue.inclusive ? `less than or equal to` : `less than`} ${issue.maximum}`;\n            else if (issue.type === \"bigint\")\n                message = `BigInt must be ${issue.exact ? `exactly` : issue.inclusive ? `less than or equal to` : `less than`} ${issue.maximum}`;\n            else if (issue.type === \"date\")\n                message = `Date must be ${issue.exact ? `exactly` : issue.inclusive ? `smaller than or equal to` : `smaller than`} ${new Date(Number(issue.maximum))}`;\n            else\n                message = \"Invalid input\";\n            break;\n        case ZodIssueCode.custom:\n            message = `Invalid input`;\n            break;\n        case ZodIssueCode.invalid_intersection_types:\n            message = `Intersection results could not be merged`;\n            break;\n        case ZodIssueCode.not_multiple_of:\n            message = `Number must be a multiple of ${issue.multipleOf}`;\n            break;\n        case ZodIssueCode.not_finite:\n            message = \"Number must be finite\";\n            break;\n        default:\n            message = _ctx.defaultError;\n            util.assertNever(issue);\n    }\n    return { message };\n};\nexport default errorMap;\n","import defaultErrorMap from \"./locales/en.js\";\nlet overrideErrorMap = defaultErrorMap;\nexport { defaultErrorMap };\nexport function setErrorMap(map) {\n    overrideErrorMap = map;\n}\nexport function getErrorMap() {\n    return overrideErrorMap;\n}\n","export var errorUtil;\n(function (errorUtil) {\n    errorUtil.errToObj = (message) => typeof message === \"string\" ? { message } : message || {};\n    // biome-ignore lint:\n    errorUtil.toString = (message) => typeof message === \"string\" ? message : message?.message;\n})(errorUtil || (errorUtil = {}));\n","import { getErrorMap } from \"../errors.js\";\nimport defaultErrorMap from \"../locales/en.js\";\nexport const makeIssue = (params) => {\n    const { data, path, errorMaps, issueData } = params;\n    const fullPath = [...path, ...(issueData.path || [])];\n    const fullIssue = {\n        ...issueData,\n        path: fullPath,\n    };\n    if (issueData.message !== undefined) {\n        return {\n            ...issueData,\n            path: fullPath,\n            message: issueData.message,\n        };\n    }\n    let errorMessage = \"\";\n    const maps = errorMaps\n        .filter((m) => !!m)\n        .slice()\n        .reverse();\n    for (const map of maps) {\n        errorMessage = map(fullIssue, { data, defaultError: errorMessage }).message;\n    }\n    return {\n        ...issueData,\n        path: fullPath,\n        message: errorMessage,\n    };\n};\nexport const EMPTY_PATH = [];\nexport function addIssueToContext(ctx, issueData) {\n    const overrideMap = getErrorMap();\n    const issue = makeIssue({\n        issueData: issueData,\n        data: ctx.data,\n        path: ctx.path,\n        errorMaps: [\n            ctx.common.contextualErrorMap, // contextual error map is first priority\n            ctx.schemaErrorMap, // then schema-bound map if available\n            overrideMap, // then global override map\n            overrideMap === defaultErrorMap ? undefined : defaultErrorMap, // then global default map\n        ].filter((x) => !!x),\n    });\n    ctx.common.issues.push(issue);\n}\nexport class ParseStatus {\n    constructor() {\n        this.value = \"valid\";\n    }\n    dirty() {\n        if (this.value === \"valid\")\n            this.value = \"dirty\";\n    }\n    abort() {\n        if (this.value !== \"aborted\")\n            this.value = \"aborted\";\n    }\n    static mergeArray(status, results) {\n        const arrayValue = [];\n        for (const s of results) {\n            if (s.status === \"aborted\")\n                return INVALID;\n            if (s.status === \"dirty\")\n                status.dirty();\n            arrayValue.push(s.value);\n        }\n        return { status: status.value, value: arrayValue };\n    }\n    static async mergeObjectAsync(status, pairs) {\n        const syncPairs = [];\n        for (const pair of pairs) {\n            const key = await pair.key;\n            const value = await pair.value;\n            syncPairs.push({\n                key,\n                value,\n            });\n        }\n        return ParseStatus.mergeObjectSync(status, syncPairs);\n    }\n    static mergeObjectSync(status, pairs) {\n        const finalObject = {};\n        for (const pair of pairs) {\n            const { key, value } = pair;\n            if (key.status === \"aborted\")\n                return INVALID;\n            if (value.status === \"aborted\")\n                return INVALID;\n            if (key.status === \"dirty\")\n                status.dirty();\n            if (value.status === \"dirty\")\n                status.dirty();\n            if (key.value !== \"__proto__\" && (typeof value.value !== \"undefined\" || pair.alwaysSet)) {\n                finalObject[key.value] = value.value;\n            }\n        }\n        return { status: status.value, value: finalObject };\n    }\n}\nexport const INVALID = Object.freeze({\n    status: \"aborted\",\n});\nexport const DIRTY = (value) => ({ status: \"dirty\", value });\nexport const OK = (value) => ({ status: \"valid\", value });\nexport const isAborted = (x) => x.status === \"aborted\";\nexport const isDirty = (x) => x.status === \"dirty\";\nexport const isValid = (x) => x.status === \"valid\";\nexport const isAsync = (x) => typeof Promise !== \"undefined\" && x instanceof Promise;\n","import { ZodError, ZodIssueCode, } from \"./ZodError.js\";\nimport { defaultErrorMap, getErrorMap } from \"./errors.js\";\nimport { errorUtil } from \"./helpers/errorUtil.js\";\nimport { DIRTY, INVALID, OK, ParseStatus, addIssueToContext, isAborted, isAsync, isDirty, isValid, makeIssue, } from \"./helpers/parseUtil.js\";\nimport { util, ZodParsedType, getParsedType } from \"./helpers/util.js\";\nclass ParseInputLazyPath {\n    constructor(parent, value, path, key) {\n        this._cachedPath = [];\n        this.parent = parent;\n        this.data = value;\n        this._path = path;\n        this._key = key;\n    }\n    get path() {\n        if (!this._cachedPath.length) {\n            if (Array.isArray(this._key)) {\n                this._cachedPath.push(...this._path, ...this._key);\n            }\n            else {\n                this._cachedPath.push(...this._path, this._key);\n            }\n        }\n        return this._cachedPath;\n    }\n}\nconst handleResult = (ctx, result) => {\n    if (isValid(result)) {\n        return { success: true, data: result.value };\n    }\n    else {\n        if (!ctx.common.issues.length) {\n            throw new Error(\"Validation failed but no issues detected.\");\n        }\n        return {\n            success: false,\n            get error() {\n                if (this._error)\n                    return this._error;\n                const error = new ZodError(ctx.common.issues);\n                this._error = error;\n                return this._error;\n            },\n        };\n    }\n};\nfunction processCreateParams(params) {\n    if (!params)\n        return {};\n    const { errorMap, invalid_type_error, required_error, description } = params;\n    if (errorMap && (invalid_type_error || required_error)) {\n        throw new Error(`Can't use \"invalid_type_error\" or \"required_error\" in conjunction with custom error map.`);\n    }\n    if (errorMap)\n        return { errorMap: errorMap, description };\n    const customMap = (iss, ctx) => {\n        const { message } = params;\n        if (iss.code === \"invalid_enum_value\") {\n            return { message: message ?? ctx.defaultError };\n        }\n        if (typeof ctx.data === \"undefined\") {\n            return { message: message ?? required_error ?? ctx.defaultError };\n        }\n        if (iss.code !== \"invalid_type\")\n            return { message: ctx.defaultError };\n        return { message: message ?? invalid_type_error ?? ctx.defaultError };\n    };\n    return { errorMap: customMap, description };\n}\nexport class ZodType {\n    get description() {\n        return this._def.description;\n    }\n    _getType(input) {\n        return getParsedType(input.data);\n    }\n    _getOrReturnCtx(input, ctx) {\n        return (ctx || {\n            common: input.parent.common,\n            data: input.data,\n            parsedType: getParsedType(input.data),\n            schemaErrorMap: this._def.errorMap,\n            path: input.path,\n            parent: input.parent,\n        });\n    }\n    _processInputParams(input) {\n        return {\n            status: new ParseStatus(),\n            ctx: {\n                common: input.parent.common,\n                data: input.data,\n                parsedType: getParsedType(input.data),\n                schemaErrorMap: this._def.errorMap,\n                path: input.path,\n                parent: input.parent,\n            },\n        };\n    }\n    _parseSync(input) {\n        const result = this._parse(input);\n        if (isAsync(result)) {\n            throw new Error(\"Synchronous parse encountered promise.\");\n        }\n        return result;\n    }\n    _parseAsync(input) {\n        const result = this._parse(input);\n        return Promise.resolve(result);\n    }\n    parse(data, params) {\n        const result = this.safeParse(data, params);\n        if (result.success)\n            return result.data;\n        throw result.error;\n    }\n    safeParse(data, params) {\n        const ctx = {\n            common: {\n                issues: [],\n                async: params?.async ?? false,\n                contextualErrorMap: params?.errorMap,\n            },\n            path: params?.path || [],\n            schemaErrorMap: this._def.errorMap,\n            parent: null,\n            data,\n            parsedType: getParsedType(data),\n        };\n        const result = this._parseSync({ data, path: ctx.path, parent: ctx });\n        return handleResult(ctx, result);\n    }\n    \"~validate\"(data) {\n        const ctx = {\n            common: {\n                issues: [],\n                async: !!this[\"~standard\"].async,\n            },\n            path: [],\n            schemaErrorMap: this._def.errorMap,\n            parent: null,\n            data,\n            parsedType: getParsedType(data),\n        };\n        if (!this[\"~standard\"].async) {\n            try {\n                const result = this._parseSync({ data, path: [], parent: ctx });\n                return isValid(result)\n                    ? {\n                        value: result.value,\n                    }\n                    : {\n                        issues: ctx.common.issues,\n                    };\n            }\n            catch (err) {\n                if (err?.message?.toLowerCase()?.includes(\"encountered\")) {\n                    this[\"~standard\"].async = true;\n                }\n                ctx.common = {\n                    issues: [],\n                    async: true,\n                };\n            }\n        }\n        return this._parseAsync({ data, path: [], parent: ctx }).then((result) => isValid(result)\n            ? {\n                value: result.value,\n            }\n            : {\n                issues: ctx.common.issues,\n            });\n    }\n    async parseAsync(data, params) {\n        const result = await this.safeParseAsync(data, params);\n        if (result.success)\n            return result.data;\n        throw result.error;\n    }\n    async safeParseAsync(data, params) {\n        const ctx = {\n            common: {\n                issues: [],\n                contextualErrorMap: params?.errorMap,\n                async: true,\n            },\n            path: params?.path || [],\n            schemaErrorMap: this._def.errorMap,\n            parent: null,\n            data,\n            parsedType: getParsedType(data),\n        };\n        const maybeAsyncResult = this._parse({ data, path: ctx.path, parent: ctx });\n        const result = await (isAsync(maybeAsyncResult) ? maybeAsyncResult : Promise.resolve(maybeAsyncResult));\n        return handleResult(ctx, result);\n    }\n    refine(check, message) {\n        const getIssueProperties = (val) => {\n            if (typeof message === \"string\" || typeof message === \"undefined\") {\n                return { message };\n            }\n            else if (typeof message === \"function\") {\n                return message(val);\n            }\n            else {\n                return message;\n            }\n        };\n        return this._refinement((val, ctx) => {\n            const result = check(val);\n            const setError = () => ctx.addIssue({\n                code: ZodIssueCode.custom,\n                ...getIssueProperties(val),\n            });\n            if (typeof Promise !== \"undefined\" && result instanceof Promise) {\n                return result.then((data) => {\n                    if (!data) {\n                        setError();\n                        return false;\n                    }\n                    else {\n                        return true;\n                    }\n                });\n            }\n            if (!result) {\n                setError();\n                return false;\n            }\n            else {\n                return true;\n            }\n        });\n    }\n    refinement(check, refinementData) {\n        return this._refinement((val, ctx) => {\n            if (!check(val)) {\n                ctx.addIssue(typeof refinementData === \"function\" ? refinementData(val, ctx) : refinementData);\n                return false;\n            }\n            else {\n                return true;\n            }\n        });\n    }\n    _refinement(refinement) {\n        return new ZodEffects({\n            schema: this,\n            typeName: ZodFirstPartyTypeKind.ZodEffects,\n            effect: { type: \"refinement\", refinement },\n        });\n    }\n    superRefine(refinement) {\n        return this._refinement(refinement);\n    }\n    constructor(def) {\n        /** Alias of safeParseAsync */\n        this.spa = this.safeParseAsync;\n        this._def = def;\n        this.parse = this.parse.bind(this);\n        this.safeParse = this.safeParse.bind(this);\n        this.parseAsync = this.parseAsync.bind(this);\n        this.safeParseAsync = this.safeParseAsync.bind(this);\n        this.spa = this.spa.bind(this);\n        this.refine = this.refine.bind(this);\n        this.refinement = this.refinement.bind(this);\n        this.superRefine = this.superRefine.bind(this);\n        this.optional = this.optional.bind(this);\n        this.nullable = this.nullable.bind(this);\n        this.nullish = this.nullish.bind(this);\n        this.array = this.array.bind(this);\n        this.promise = this.promise.bind(this);\n        this.or = this.or.bind(this);\n        this.and = this.and.bind(this);\n        this.transform = this.transform.bind(this);\n        this.brand = this.brand.bind(this);\n        this.default = this.default.bind(this);\n        this.catch = this.catch.bind(this);\n        this.describe = this.describe.bind(this);\n        this.pipe = this.pipe.bind(this);\n        this.readonly = this.readonly.bind(this);\n        this.isNullable = this.isNullable.bind(this);\n        this.isOptional = this.isOptional.bind(this);\n        this[\"~standard\"] = {\n            version: 1,\n            vendor: \"zod\",\n            validate: (data) => this[\"~validate\"](data),\n        };\n    }\n    optional() {\n        return ZodOptional.create(this, this._def);\n    }\n    nullable() {\n        return ZodNullable.create(this, this._def);\n    }\n    nullish() {\n        return this.nullable().optional();\n    }\n    array() {\n        return ZodArray.create(this);\n    }\n    promise() {\n        return ZodPromise.create(this, this._def);\n    }\n    or(option) {\n        return ZodUnion.create([this, option], this._def);\n    }\n    and(incoming) {\n        return ZodIntersection.create(this, incoming, this._def);\n    }\n    transform(transform) {\n        return new ZodEffects({\n            ...processCreateParams(this._def),\n            schema: this,\n            typeName: ZodFirstPartyTypeKind.ZodEffects,\n            effect: { type: \"transform\", transform },\n        });\n    }\n    default(def) {\n        const defaultValueFunc = typeof def === \"function\" ? def : () => def;\n        return new ZodDefault({\n            ...processCreateParams(this._def),\n            innerType: this,\n            defaultValue: defaultValueFunc,\n            typeName: ZodFirstPartyTypeKind.ZodDefault,\n        });\n    }\n    brand() {\n        return new ZodBranded({\n            typeName: ZodFirstPartyTypeKind.ZodBranded,\n            type: this,\n            ...processCreateParams(this._def),\n        });\n    }\n    catch(def) {\n        const catchValueFunc = typeof def === \"function\" ? def : () => def;\n        return new ZodCatch({\n            ...processCreateParams(this._def),\n            innerType: this,\n            catchValue: catchValueFunc,\n            typeName: ZodFirstPartyTypeKind.ZodCatch,\n        });\n    }\n    describe(description) {\n        const This = this.constructor;\n        return new This({\n            ...this._def,\n            description,\n        });\n    }\n    pipe(target) {\n        return ZodPipeline.create(this, target);\n    }\n    readonly() {\n        return ZodReadonly.create(this);\n    }\n    isOptional() {\n        return this.safeParse(undefined).success;\n    }\n    isNullable() {\n        return this.safeParse(null).success;\n    }\n}\nconst cuidRegex = /^c[^\\s-]{8,}$/i;\nconst cuid2Regex = /^[0-9a-z]+$/;\nconst ulidRegex = /^[0-9A-HJKMNP-TV-Z]{26}$/i;\n// const uuidRegex =\n//   /^([a-f0-9]{8}-[a-f0-9]{4}-[1-5][a-f0-9]{3}-[a-f0-9]{4}-[a-f0-9]{12}|00000000-0000-0000-0000-000000000000)$/i;\nconst uuidRegex = /^[0-9a-fA-F]{8}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{12}$/i;\nconst nanoidRegex = /^[a-z0-9_-]{21}$/i;\nconst jwtRegex = /^[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]*$/;\nconst durationRegex = /^[-+]?P(?!$)(?:(?:[-+]?\\d+Y)|(?:[-+]?\\d+[.,]\\d+Y$))?(?:(?:[-+]?\\d+M)|(?:[-+]?\\d+[.,]\\d+M$))?(?:(?:[-+]?\\d+W)|(?:[-+]?\\d+[.,]\\d+W$))?(?:(?:[-+]?\\d+D)|(?:[-+]?\\d+[.,]\\d+D$))?(?:T(?=[\\d+-])(?:(?:[-+]?\\d+H)|(?:[-+]?\\d+[.,]\\d+H$))?(?:(?:[-+]?\\d+M)|(?:[-+]?\\d+[.,]\\d+M$))?(?:[-+]?\\d+(?:[.,]\\d+)?S)?)??$/;\n// from https://stackoverflow.com/a/46181/1550155\n// old version: too slow, didn't support unicode\n// const emailRegex = /^((([a-z]|\\d|[!#\\$%&'\\*\\+\\-\\/=\\?\\^_`{\\|}~]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])+(\\.([a-z]|\\d|[!#\\$%&'\\*\\+\\-\\/=\\?\\^_`{\\|}~]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])+)*)|((\\x22)((((\\x20|\\x09)*(\\x0d\\x0a))?(\\x20|\\x09)+)?(([\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f]|\\x21|[\\x23-\\x5b]|[\\x5d-\\x7e]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])|(\\\\([\\x01-\\x09\\x0b\\x0c\\x0d-\\x7f]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF]))))*(((\\x20|\\x09)*(\\x0d\\x0a))?(\\x20|\\x09)+)?(\\x22)))@((([a-z]|\\d|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])|(([a-z]|\\d|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])([a-z]|\\d|-|\\.|_|~|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])*([a-z]|\\d|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])))\\.)+(([a-z]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])|(([a-z]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])([a-z]|\\d|-|\\.|_|~|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])*([a-z]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])))$/i;\n//old email regex\n// const emailRegex = /^(([^<>()[\\].,;:\\s@\"]+(\\.[^<>()[\\].,;:\\s@\"]+)*)|(\".+\"))@((?!-)([^<>()[\\].,;:\\s@\"]+\\.)+[^<>()[\\].,;:\\s@\"]{1,})[^-<>()[\\].,;:\\s@\"]$/i;\n// eslint-disable-next-line\n// const emailRegex =\n//   /^(([^<>()[\\]\\\\.,;:\\s@\\\"]+(\\.[^<>()[\\]\\\\.,;:\\s@\\\"]+)*)|(\\\".+\\\"))@((\\[(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\\])|(\\[IPv6:(([a-f0-9]{1,4}:){7}|::([a-f0-9]{1,4}:){0,6}|([a-f0-9]{1,4}:){1}:([a-f0-9]{1,4}:){0,5}|([a-f0-9]{1,4}:){2}:([a-f0-9]{1,4}:){0,4}|([a-f0-9]{1,4}:){3}:([a-f0-9]{1,4}:){0,3}|([a-f0-9]{1,4}:){4}:([a-f0-9]{1,4}:){0,2}|([a-f0-9]{1,4}:){5}:([a-f0-9]{1,4}:){0,1})([a-f0-9]{1,4}|(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2})))\\])|([A-Za-z0-9]([A-Za-z0-9-]*[A-Za-z0-9])*(\\.[A-Za-z]{2,})+))$/;\n// const emailRegex =\n//   /^[a-zA-Z0-9\\.\\!\\#\\$\\%\\&\\'\\*\\+\\/\\=\\?\\^\\_\\`\\{\\|\\}\\~\\-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$/;\n// const emailRegex =\n//   /^(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])$/i;\nconst emailRegex = /^(?!\\.)(?!.*\\.\\.)([A-Z0-9_'+\\-\\.]*)[A-Z0-9_+-]@([A-Z0-9][A-Z0-9\\-]*\\.)+[A-Z]{2,}$/i;\n// const emailRegex =\n//   /^[a-z0-9.!#$%&*+/=?^_`{|}~-]+@[a-z0-9-]+(?:\\.[a-z0-9\\-]+)*$/i;\n// from https://thekevinscott.com/emojis-in-javascript/#writing-a-regular-expression\nconst _emojiRegex = `^(\\\\p{Extended_Pictographic}|\\\\p{Emoji_Component})+$`;\nlet emojiRegex;\n// faster, simpler, safer\nconst ipv4Regex = /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$/;\nconst ipv4CidrRegex = /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\/(3[0-2]|[12]?[0-9])$/;\n// const ipv6Regex =\n// /^(([a-f0-9]{1,4}:){7}|::([a-f0-9]{1,4}:){0,6}|([a-f0-9]{1,4}:){1}:([a-f0-9]{1,4}:){0,5}|([a-f0-9]{1,4}:){2}:([a-f0-9]{1,4}:){0,4}|([a-f0-9]{1,4}:){3}:([a-f0-9]{1,4}:){0,3}|([a-f0-9]{1,4}:){4}:([a-f0-9]{1,4}:){0,2}|([a-f0-9]{1,4}:){5}:([a-f0-9]{1,4}:){0,1})([a-f0-9]{1,4}|(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2})))$/;\nconst ipv6Regex = /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))$/;\nconst ipv6CidrRegex = /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\\/(12[0-8]|1[01][0-9]|[1-9]?[0-9])$/;\n// https://stackoverflow.com/questions/7860392/determine-if-string-is-in-base64-using-javascript\nconst base64Regex = /^([0-9a-zA-Z+/]{4})*(([0-9a-zA-Z+/]{2}==)|([0-9a-zA-Z+/]{3}=))?$/;\n// https://base64.guru/standards/base64url\nconst base64urlRegex = /^([0-9a-zA-Z-_]{4})*(([0-9a-zA-Z-_]{2}(==)?)|([0-9a-zA-Z-_]{3}(=)?))?$/;\n// simple\n// const dateRegexSource = `\\\\d{4}-\\\\d{2}-\\\\d{2}`;\n// no leap year validation\n// const dateRegexSource = `\\\\d{4}-((0[13578]|10|12)-31|(0[13-9]|1[0-2])-30|(0[1-9]|1[0-2])-(0[1-9]|1\\\\d|2\\\\d))`;\n// with leap year validation\nconst dateRegexSource = `((\\\\d\\\\d[2468][048]|\\\\d\\\\d[13579][26]|\\\\d\\\\d0[48]|[02468][048]00|[13579][26]00)-02-29|\\\\d{4}-((0[13578]|1[02])-(0[1-9]|[12]\\\\d|3[01])|(0[469]|11)-(0[1-9]|[12]\\\\d|30)|(02)-(0[1-9]|1\\\\d|2[0-8])))`;\nconst dateRegex = new RegExp(`^${dateRegexSource}$`);\nfunction timeRegexSource(args) {\n    let secondsRegexSource = `[0-5]\\\\d`;\n    if (args.precision) {\n        secondsRegexSource = `${secondsRegexSource}\\\\.\\\\d{${args.precision}}`;\n    }\n    else if (args.precision == null) {\n        secondsRegexSource = `${secondsRegexSource}(\\\\.\\\\d+)?`;\n    }\n    const secondsQuantifier = args.precision ? \"+\" : \"?\"; // require seconds if precision is nonzero\n    return `([01]\\\\d|2[0-3]):[0-5]\\\\d(:${secondsRegexSource})${secondsQuantifier}`;\n}\nfunction timeRegex(args) {\n    return new RegExp(`^${timeRegexSource(args)}$`);\n}\n// Adapted from https://stackoverflow.com/a/3143231\nexport function datetimeRegex(args) {\n    let regex = `${dateRegexSource}T${timeRegexSource(args)}`;\n    const opts = [];\n    opts.push(args.local ? `Z?` : `Z`);\n    if (args.offset)\n        opts.push(`([+-]\\\\d{2}:?\\\\d{2})`);\n    regex = `${regex}(${opts.join(\"|\")})`;\n    return new RegExp(`^${regex}$`);\n}\nfunction isValidIP(ip, version) {\n    if ((version === \"v4\" || !version) && ipv4Regex.test(ip)) {\n        return true;\n    }\n    if ((version === \"v6\" || !version) && ipv6Regex.test(ip)) {\n        return true;\n    }\n    return false;\n}\nfunction isValidJWT(jwt, alg) {\n    if (!jwtRegex.test(jwt))\n        return false;\n    try {\n        const [header] = jwt.split(\".\");\n        if (!header)\n            return false;\n        // Convert base64url to base64\n        const base64 = header\n            .replace(/-/g, \"+\")\n            .replace(/_/g, \"/\")\n            .padEnd(header.length + ((4 - (header.length % 4)) % 4), \"=\");\n        const decoded = JSON.parse(atob(base64));\n        if (typeof decoded !== \"object\" || decoded === null)\n            return false;\n        if (\"typ\" in decoded && decoded?.typ !== \"JWT\")\n            return false;\n        if (!decoded.alg)\n            return false;\n        if (alg && decoded.alg !== alg)\n            return false;\n        return true;\n    }\n    catch {\n        return false;\n    }\n}\nfunction isValidCidr(ip, version) {\n    if ((version === \"v4\" || !version) && ipv4CidrRegex.test(ip)) {\n        return true;\n    }\n    if ((version === \"v6\" || !version) && ipv6CidrRegex.test(ip)) {\n        return true;\n    }\n    return false;\n}\nexport class ZodString extends ZodType {\n    _parse(input) {\n        if (this._def.coerce) {\n            input.data = String(input.data);\n        }\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.string) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.string,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        const status = new ParseStatus();\n        let ctx = undefined;\n        for (const check of this._def.checks) {\n            if (check.kind === \"min\") {\n                if (input.data.length < check.value) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_small,\n                        minimum: check.value,\n                        type: \"string\",\n                        inclusive: true,\n                        exact: false,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"max\") {\n                if (input.data.length > check.value) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_big,\n                        maximum: check.value,\n                        type: \"string\",\n                        inclusive: true,\n                        exact: false,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"length\") {\n                const tooBig = input.data.length > check.value;\n                const tooSmall = input.data.length < check.value;\n                if (tooBig || tooSmall) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    if (tooBig) {\n                        addIssueToContext(ctx, {\n                            code: ZodIssueCode.too_big,\n                            maximum: check.value,\n                            type: \"string\",\n                            inclusive: true,\n                            exact: true,\n                            message: check.message,\n                        });\n                    }\n                    else if (tooSmall) {\n                        addIssueToContext(ctx, {\n                            code: ZodIssueCode.too_small,\n                            minimum: check.value,\n                            type: \"string\",\n                            inclusive: true,\n                            exact: true,\n                            message: check.message,\n                        });\n                    }\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"email\") {\n                if (!emailRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"email\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"emoji\") {\n                if (!emojiRegex) {\n                    emojiRegex = new RegExp(_emojiRegex, \"u\");\n                }\n                if (!emojiRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"emoji\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"uuid\") {\n                if (!uuidRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"uuid\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"nanoid\") {\n                if (!nanoidRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"nanoid\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"cuid\") {\n                if (!cuidRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"cuid\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"cuid2\") {\n                if (!cuid2Regex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"cuid2\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"ulid\") {\n                if (!ulidRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"ulid\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"url\") {\n                try {\n                    new URL(input.data);\n                }\n                catch {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"url\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"regex\") {\n                check.regex.lastIndex = 0;\n                const testResult = check.regex.test(input.data);\n                if (!testResult) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"regex\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"trim\") {\n                input.data = input.data.trim();\n            }\n            else if (check.kind === \"includes\") {\n                if (!input.data.includes(check.value, check.position)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.invalid_string,\n                        validation: { includes: check.value, position: check.position },\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"toLowerCase\") {\n                input.data = input.data.toLowerCase();\n            }\n            else if (check.kind === \"toUpperCase\") {\n                input.data = input.data.toUpperCase();\n            }\n            else if (check.kind === \"startsWith\") {\n                if (!input.data.startsWith(check.value)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.invalid_string,\n                        validation: { startsWith: check.value },\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"endsWith\") {\n                if (!input.data.endsWith(check.value)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.invalid_string,\n                        validation: { endsWith: check.value },\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"datetime\") {\n                const regex = datetimeRegex(check);\n                if (!regex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.invalid_string,\n                        validation: \"datetime\",\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"date\") {\n                const regex = dateRegex;\n                if (!regex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.invalid_string,\n                        validation: \"date\",\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"time\") {\n                const regex = timeRegex(check);\n                if (!regex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.invalid_string,\n                        validation: \"time\",\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"duration\") {\n                if (!durationRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"duration\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"ip\") {\n                if (!isValidIP(input.data, check.version)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"ip\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"jwt\") {\n                if (!isValidJWT(input.data, check.alg)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"jwt\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"cidr\") {\n                if (!isValidCidr(input.data, check.version)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"cidr\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"base64\") {\n                if (!base64Regex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"base64\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"base64url\") {\n                if (!base64urlRegex.test(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        validation: \"base64url\",\n                        code: ZodIssueCode.invalid_string,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else {\n                util.assertNever(check);\n            }\n        }\n        return { status: status.value, value: input.data };\n    }\n    _regex(regex, validation, message) {\n        return this.refinement((data) => regex.test(data), {\n            validation,\n            code: ZodIssueCode.invalid_string,\n            ...errorUtil.errToObj(message),\n        });\n    }\n    _addCheck(check) {\n        return new ZodString({\n            ...this._def,\n            checks: [...this._def.checks, check],\n        });\n    }\n    email(message) {\n        return this._addCheck({ kind: \"email\", ...errorUtil.errToObj(message) });\n    }\n    url(message) {\n        return this._addCheck({ kind: \"url\", ...errorUtil.errToObj(message) });\n    }\n    emoji(message) {\n        return this._addCheck({ kind: \"emoji\", ...errorUtil.errToObj(message) });\n    }\n    uuid(message) {\n        return this._addCheck({ kind: \"uuid\", ...errorUtil.errToObj(message) });\n    }\n    nanoid(message) {\n        return this._addCheck({ kind: \"nanoid\", ...errorUtil.errToObj(message) });\n    }\n    cuid(message) {\n        return this._addCheck({ kind: \"cuid\", ...errorUtil.errToObj(message) });\n    }\n    cuid2(message) {\n        return this._addCheck({ kind: \"cuid2\", ...errorUtil.errToObj(message) });\n    }\n    ulid(message) {\n        return this._addCheck({ kind: \"ulid\", ...errorUtil.errToObj(message) });\n    }\n    base64(message) {\n        return this._addCheck({ kind: \"base64\", ...errorUtil.errToObj(message) });\n    }\n    base64url(message) {\n        // base64url encoding is a modification of base64 that can safely be used in URLs and filenames\n        return this._addCheck({\n            kind: \"base64url\",\n            ...errorUtil.errToObj(message),\n        });\n    }\n    jwt(options) {\n        return this._addCheck({ kind: \"jwt\", ...errorUtil.errToObj(options) });\n    }\n    ip(options) {\n        return this._addCheck({ kind: \"ip\", ...errorUtil.errToObj(options) });\n    }\n    cidr(options) {\n        return this._addCheck({ kind: \"cidr\", ...errorUtil.errToObj(options) });\n    }\n    datetime(options) {\n        if (typeof options === \"string\") {\n            return this._addCheck({\n                kind: \"datetime\",\n                precision: null,\n                offset: false,\n                local: false,\n                message: options,\n            });\n        }\n        return this._addCheck({\n            kind: \"datetime\",\n            precision: typeof options?.precision === \"undefined\" ? null : options?.precision,\n            offset: options?.offset ?? false,\n            local: options?.local ?? false,\n            ...errorUtil.errToObj(options?.message),\n        });\n    }\n    date(message) {\n        return this._addCheck({ kind: \"date\", message });\n    }\n    time(options) {\n        if (typeof options === \"string\") {\n            return this._addCheck({\n                kind: \"time\",\n                precision: null,\n                message: options,\n            });\n        }\n        return this._addCheck({\n            kind: \"time\",\n            precision: typeof options?.precision === \"undefined\" ? null : options?.precision,\n            ...errorUtil.errToObj(options?.message),\n        });\n    }\n    duration(message) {\n        return this._addCheck({ kind: \"duration\", ...errorUtil.errToObj(message) });\n    }\n    regex(regex, message) {\n        return this._addCheck({\n            kind: \"regex\",\n            regex: regex,\n            ...errorUtil.errToObj(message),\n        });\n    }\n    includes(value, options) {\n        return this._addCheck({\n            kind: \"includes\",\n            value: value,\n            position: options?.position,\n            ...errorUtil.errToObj(options?.message),\n        });\n    }\n    startsWith(value, message) {\n        return this._addCheck({\n            kind: \"startsWith\",\n            value: value,\n            ...errorUtil.errToObj(message),\n        });\n    }\n    endsWith(value, message) {\n        return this._addCheck({\n            kind: \"endsWith\",\n            value: value,\n            ...errorUtil.errToObj(message),\n        });\n    }\n    min(minLength, message) {\n        return this._addCheck({\n            kind: \"min\",\n            value: minLength,\n            ...errorUtil.errToObj(message),\n        });\n    }\n    max(maxLength, message) {\n        return this._addCheck({\n            kind: \"max\",\n            value: maxLength,\n            ...errorUtil.errToObj(message),\n        });\n    }\n    length(len, message) {\n        return this._addCheck({\n            kind: \"length\",\n            value: len,\n            ...errorUtil.errToObj(message),\n        });\n    }\n    /**\n     * Equivalent to `.min(1)`\n     */\n    nonempty(message) {\n        return this.min(1, errorUtil.errToObj(message));\n    }\n    trim() {\n        return new ZodString({\n            ...this._def,\n            checks: [...this._def.checks, { kind: \"trim\" }],\n        });\n    }\n    toLowerCase() {\n        return new ZodString({\n            ...this._def,\n            checks: [...this._def.checks, { kind: \"toLowerCase\" }],\n        });\n    }\n    toUpperCase() {\n        return new ZodString({\n            ...this._def,\n            checks: [...this._def.checks, { kind: \"toUpperCase\" }],\n        });\n    }\n    get isDatetime() {\n        return !!this._def.checks.find((ch) => ch.kind === \"datetime\");\n    }\n    get isDate() {\n        return !!this._def.checks.find((ch) => ch.kind === \"date\");\n    }\n    get isTime() {\n        return !!this._def.checks.find((ch) => ch.kind === \"time\");\n    }\n    get isDuration() {\n        return !!this._def.checks.find((ch) => ch.kind === \"duration\");\n    }\n    get isEmail() {\n        return !!this._def.checks.find((ch) => ch.kind === \"email\");\n    }\n    get isURL() {\n        return !!this._def.checks.find((ch) => ch.kind === \"url\");\n    }\n    get isEmoji() {\n        return !!this._def.checks.find((ch) => ch.kind === \"emoji\");\n    }\n    get isUUID() {\n        return !!this._def.checks.find((ch) => ch.kind === \"uuid\");\n    }\n    get isNANOID() {\n        return !!this._def.checks.find((ch) => ch.kind === \"nanoid\");\n    }\n    get isCUID() {\n        return !!this._def.checks.find((ch) => ch.kind === \"cuid\");\n    }\n    get isCUID2() {\n        return !!this._def.checks.find((ch) => ch.kind === \"cuid2\");\n    }\n    get isULID() {\n        return !!this._def.checks.find((ch) => ch.kind === \"ulid\");\n    }\n    get isIP() {\n        return !!this._def.checks.find((ch) => ch.kind === \"ip\");\n    }\n    get isCIDR() {\n        return !!this._def.checks.find((ch) => ch.kind === \"cidr\");\n    }\n    get isBase64() {\n        return !!this._def.checks.find((ch) => ch.kind === \"base64\");\n    }\n    get isBase64url() {\n        // base64url encoding is a modification of base64 that can safely be used in URLs and filenames\n        return !!this._def.checks.find((ch) => ch.kind === \"base64url\");\n    }\n    get minLength() {\n        let min = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"min\") {\n                if (min === null || ch.value > min)\n                    min = ch.value;\n            }\n        }\n        return min;\n    }\n    get maxLength() {\n        let max = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"max\") {\n                if (max === null || ch.value < max)\n                    max = ch.value;\n            }\n        }\n        return max;\n    }\n}\nZodString.create = (params) => {\n    return new ZodString({\n        checks: [],\n        typeName: ZodFirstPartyTypeKind.ZodString,\n        coerce: params?.coerce ?? false,\n        ...processCreateParams(params),\n    });\n};\n// https://stackoverflow.com/questions/3966484/why-does-modulus-operator-return-fractional-number-in-javascript/31711034#31711034\nfunction floatSafeRemainder(val, step) {\n    const valDecCount = (val.toString().split(\".\")[1] || \"\").length;\n    const stepDecCount = (step.toString().split(\".\")[1] || \"\").length;\n    const decCount = valDecCount > stepDecCount ? valDecCount : stepDecCount;\n    const valInt = Number.parseInt(val.toFixed(decCount).replace(\".\", \"\"));\n    const stepInt = Number.parseInt(step.toFixed(decCount).replace(\".\", \"\"));\n    return (valInt % stepInt) / 10 ** decCount;\n}\nexport class ZodNumber extends ZodType {\n    constructor() {\n        super(...arguments);\n        this.min = this.gte;\n        this.max = this.lte;\n        this.step = this.multipleOf;\n    }\n    _parse(input) {\n        if (this._def.coerce) {\n            input.data = Number(input.data);\n        }\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.number) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.number,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        let ctx = undefined;\n        const status = new ParseStatus();\n        for (const check of this._def.checks) {\n            if (check.kind === \"int\") {\n                if (!util.isInteger(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.invalid_type,\n                        expected: \"integer\",\n                        received: \"float\",\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"min\") {\n                const tooSmall = check.inclusive ? input.data < check.value : input.data <= check.value;\n                if (tooSmall) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_small,\n                        minimum: check.value,\n                        type: \"number\",\n                        inclusive: check.inclusive,\n                        exact: false,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"max\") {\n                const tooBig = check.inclusive ? input.data > check.value : input.data >= check.value;\n                if (tooBig) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_big,\n                        maximum: check.value,\n                        type: \"number\",\n                        inclusive: check.inclusive,\n                        exact: false,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"multipleOf\") {\n                if (floatSafeRemainder(input.data, check.value) !== 0) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.not_multiple_of,\n                        multipleOf: check.value,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"finite\") {\n                if (!Number.isFinite(input.data)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.not_finite,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else {\n                util.assertNever(check);\n            }\n        }\n        return { status: status.value, value: input.data };\n    }\n    gte(value, message) {\n        return this.setLimit(\"min\", value, true, errorUtil.toString(message));\n    }\n    gt(value, message) {\n        return this.setLimit(\"min\", value, false, errorUtil.toString(message));\n    }\n    lte(value, message) {\n        return this.setLimit(\"max\", value, true, errorUtil.toString(message));\n    }\n    lt(value, message) {\n        return this.setLimit(\"max\", value, false, errorUtil.toString(message));\n    }\n    setLimit(kind, value, inclusive, message) {\n        return new ZodNumber({\n            ...this._def,\n            checks: [\n                ...this._def.checks,\n                {\n                    kind,\n                    value,\n                    inclusive,\n                    message: errorUtil.toString(message),\n                },\n            ],\n        });\n    }\n    _addCheck(check) {\n        return new ZodNumber({\n            ...this._def,\n            checks: [...this._def.checks, check],\n        });\n    }\n    int(message) {\n        return this._addCheck({\n            kind: \"int\",\n            message: errorUtil.toString(message),\n        });\n    }\n    positive(message) {\n        return this._addCheck({\n            kind: \"min\",\n            value: 0,\n            inclusive: false,\n            message: errorUtil.toString(message),\n        });\n    }\n    negative(message) {\n        return this._addCheck({\n            kind: \"max\",\n            value: 0,\n            inclusive: false,\n            message: errorUtil.toString(message),\n        });\n    }\n    nonpositive(message) {\n        return this._addCheck({\n            kind: \"max\",\n            value: 0,\n            inclusive: true,\n            message: errorUtil.toString(message),\n        });\n    }\n    nonnegative(message) {\n        return this._addCheck({\n            kind: \"min\",\n            value: 0,\n            inclusive: true,\n            message: errorUtil.toString(message),\n        });\n    }\n    multipleOf(value, message) {\n        return this._addCheck({\n            kind: \"multipleOf\",\n            value: value,\n            message: errorUtil.toString(message),\n        });\n    }\n    finite(message) {\n        return this._addCheck({\n            kind: \"finite\",\n            message: errorUtil.toString(message),\n        });\n    }\n    safe(message) {\n        return this._addCheck({\n            kind: \"min\",\n            inclusive: true,\n            value: Number.MIN_SAFE_INTEGER,\n            message: errorUtil.toString(message),\n        })._addCheck({\n            kind: \"max\",\n            inclusive: true,\n            value: Number.MAX_SAFE_INTEGER,\n            message: errorUtil.toString(message),\n        });\n    }\n    get minValue() {\n        let min = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"min\") {\n                if (min === null || ch.value > min)\n                    min = ch.value;\n            }\n        }\n        return min;\n    }\n    get maxValue() {\n        let max = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"max\") {\n                if (max === null || ch.value < max)\n                    max = ch.value;\n            }\n        }\n        return max;\n    }\n    get isInt() {\n        return !!this._def.checks.find((ch) => ch.kind === \"int\" || (ch.kind === \"multipleOf\" && util.isInteger(ch.value)));\n    }\n    get isFinite() {\n        let max = null;\n        let min = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"finite\" || ch.kind === \"int\" || ch.kind === \"multipleOf\") {\n                return true;\n            }\n            else if (ch.kind === \"min\") {\n                if (min === null || ch.value > min)\n                    min = ch.value;\n            }\n            else if (ch.kind === \"max\") {\n                if (max === null || ch.value < max)\n                    max = ch.value;\n            }\n        }\n        return Number.isFinite(min) && Number.isFinite(max);\n    }\n}\nZodNumber.create = (params) => {\n    return new ZodNumber({\n        checks: [],\n        typeName: ZodFirstPartyTypeKind.ZodNumber,\n        coerce: params?.coerce || false,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodBigInt extends ZodType {\n    constructor() {\n        super(...arguments);\n        this.min = this.gte;\n        this.max = this.lte;\n    }\n    _parse(input) {\n        if (this._def.coerce) {\n            try {\n                input.data = BigInt(input.data);\n            }\n            catch {\n                return this._getInvalidInput(input);\n            }\n        }\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.bigint) {\n            return this._getInvalidInput(input);\n        }\n        let ctx = undefined;\n        const status = new ParseStatus();\n        for (const check of this._def.checks) {\n            if (check.kind === \"min\") {\n                const tooSmall = check.inclusive ? input.data < check.value : input.data <= check.value;\n                if (tooSmall) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_small,\n                        type: \"bigint\",\n                        minimum: check.value,\n                        inclusive: check.inclusive,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"max\") {\n                const tooBig = check.inclusive ? input.data > check.value : input.data >= check.value;\n                if (tooBig) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_big,\n                        type: \"bigint\",\n                        maximum: check.value,\n                        inclusive: check.inclusive,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"multipleOf\") {\n                if (input.data % check.value !== BigInt(0)) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.not_multiple_of,\n                        multipleOf: check.value,\n                        message: check.message,\n                    });\n                    status.dirty();\n                }\n            }\n            else {\n                util.assertNever(check);\n            }\n        }\n        return { status: status.value, value: input.data };\n    }\n    _getInvalidInput(input) {\n        const ctx = this._getOrReturnCtx(input);\n        addIssueToContext(ctx, {\n            code: ZodIssueCode.invalid_type,\n            expected: ZodParsedType.bigint,\n            received: ctx.parsedType,\n        });\n        return INVALID;\n    }\n    gte(value, message) {\n        return this.setLimit(\"min\", value, true, errorUtil.toString(message));\n    }\n    gt(value, message) {\n        return this.setLimit(\"min\", value, false, errorUtil.toString(message));\n    }\n    lte(value, message) {\n        return this.setLimit(\"max\", value, true, errorUtil.toString(message));\n    }\n    lt(value, message) {\n        return this.setLimit(\"max\", value, false, errorUtil.toString(message));\n    }\n    setLimit(kind, value, inclusive, message) {\n        return new ZodBigInt({\n            ...this._def,\n            checks: [\n                ...this._def.checks,\n                {\n                    kind,\n                    value,\n                    inclusive,\n                    message: errorUtil.toString(message),\n                },\n            ],\n        });\n    }\n    _addCheck(check) {\n        return new ZodBigInt({\n            ...this._def,\n            checks: [...this._def.checks, check],\n        });\n    }\n    positive(message) {\n        return this._addCheck({\n            kind: \"min\",\n            value: BigInt(0),\n            inclusive: false,\n            message: errorUtil.toString(message),\n        });\n    }\n    negative(message) {\n        return this._addCheck({\n            kind: \"max\",\n            value: BigInt(0),\n            inclusive: false,\n            message: errorUtil.toString(message),\n        });\n    }\n    nonpositive(message) {\n        return this._addCheck({\n            kind: \"max\",\n            value: BigInt(0),\n            inclusive: true,\n            message: errorUtil.toString(message),\n        });\n    }\n    nonnegative(message) {\n        return this._addCheck({\n            kind: \"min\",\n            value: BigInt(0),\n            inclusive: true,\n            message: errorUtil.toString(message),\n        });\n    }\n    multipleOf(value, message) {\n        return this._addCheck({\n            kind: \"multipleOf\",\n            value,\n            message: errorUtil.toString(message),\n        });\n    }\n    get minValue() {\n        let min = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"min\") {\n                if (min === null || ch.value > min)\n                    min = ch.value;\n            }\n        }\n        return min;\n    }\n    get maxValue() {\n        let max = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"max\") {\n                if (max === null || ch.value < max)\n                    max = ch.value;\n            }\n        }\n        return max;\n    }\n}\nZodBigInt.create = (params) => {\n    return new ZodBigInt({\n        checks: [],\n        typeName: ZodFirstPartyTypeKind.ZodBigInt,\n        coerce: params?.coerce ?? false,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodBoolean extends ZodType {\n    _parse(input) {\n        if (this._def.coerce) {\n            input.data = Boolean(input.data);\n        }\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.boolean) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.boolean,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        return OK(input.data);\n    }\n}\nZodBoolean.create = (params) => {\n    return new ZodBoolean({\n        typeName: ZodFirstPartyTypeKind.ZodBoolean,\n        coerce: params?.coerce || false,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodDate extends ZodType {\n    _parse(input) {\n        if (this._def.coerce) {\n            input.data = new Date(input.data);\n        }\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.date) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.date,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        if (Number.isNaN(input.data.getTime())) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_date,\n            });\n            return INVALID;\n        }\n        const status = new ParseStatus();\n        let ctx = undefined;\n        for (const check of this._def.checks) {\n            if (check.kind === \"min\") {\n                if (input.data.getTime() < check.value) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_small,\n                        message: check.message,\n                        inclusive: true,\n                        exact: false,\n                        minimum: check.value,\n                        type: \"date\",\n                    });\n                    status.dirty();\n                }\n            }\n            else if (check.kind === \"max\") {\n                if (input.data.getTime() > check.value) {\n                    ctx = this._getOrReturnCtx(input, ctx);\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.too_big,\n                        message: check.message,\n                        inclusive: true,\n                        exact: false,\n                        maximum: check.value,\n                        type: \"date\",\n                    });\n                    status.dirty();\n                }\n            }\n            else {\n                util.assertNever(check);\n            }\n        }\n        return {\n            status: status.value,\n            value: new Date(input.data.getTime()),\n        };\n    }\n    _addCheck(check) {\n        return new ZodDate({\n            ...this._def,\n            checks: [...this._def.checks, check],\n        });\n    }\n    min(minDate, message) {\n        return this._addCheck({\n            kind: \"min\",\n            value: minDate.getTime(),\n            message: errorUtil.toString(message),\n        });\n    }\n    max(maxDate, message) {\n        return this._addCheck({\n            kind: \"max\",\n            value: maxDate.getTime(),\n            message: errorUtil.toString(message),\n        });\n    }\n    get minDate() {\n        let min = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"min\") {\n                if (min === null || ch.value > min)\n                    min = ch.value;\n            }\n        }\n        return min != null ? new Date(min) : null;\n    }\n    get maxDate() {\n        let max = null;\n        for (const ch of this._def.checks) {\n            if (ch.kind === \"max\") {\n                if (max === null || ch.value < max)\n                    max = ch.value;\n            }\n        }\n        return max != null ? new Date(max) : null;\n    }\n}\nZodDate.create = (params) => {\n    return new ZodDate({\n        checks: [],\n        coerce: params?.coerce || false,\n        typeName: ZodFirstPartyTypeKind.ZodDate,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodSymbol extends ZodType {\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.symbol) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.symbol,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        return OK(input.data);\n    }\n}\nZodSymbol.create = (params) => {\n    return new ZodSymbol({\n        typeName: ZodFirstPartyTypeKind.ZodSymbol,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodUndefined extends ZodType {\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.undefined) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.undefined,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        return OK(input.data);\n    }\n}\nZodUndefined.create = (params) => {\n    return new ZodUndefined({\n        typeName: ZodFirstPartyTypeKind.ZodUndefined,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodNull extends ZodType {\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.null) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.null,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        return OK(input.data);\n    }\n}\nZodNull.create = (params) => {\n    return new ZodNull({\n        typeName: ZodFirstPartyTypeKind.ZodNull,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodAny extends ZodType {\n    constructor() {\n        super(...arguments);\n        // to prevent instances of other classes from extending ZodAny. this causes issues with catchall in ZodObject.\n        this._any = true;\n    }\n    _parse(input) {\n        return OK(input.data);\n    }\n}\nZodAny.create = (params) => {\n    return new ZodAny({\n        typeName: ZodFirstPartyTypeKind.ZodAny,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodUnknown extends ZodType {\n    constructor() {\n        super(...arguments);\n        // required\n        this._unknown = true;\n    }\n    _parse(input) {\n        return OK(input.data);\n    }\n}\nZodUnknown.create = (params) => {\n    return new ZodUnknown({\n        typeName: ZodFirstPartyTypeKind.ZodUnknown,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodNever extends ZodType {\n    _parse(input) {\n        const ctx = this._getOrReturnCtx(input);\n        addIssueToContext(ctx, {\n            code: ZodIssueCode.invalid_type,\n            expected: ZodParsedType.never,\n            received: ctx.parsedType,\n        });\n        return INVALID;\n    }\n}\nZodNever.create = (params) => {\n    return new ZodNever({\n        typeName: ZodFirstPartyTypeKind.ZodNever,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodVoid extends ZodType {\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.undefined) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.void,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        return OK(input.data);\n    }\n}\nZodVoid.create = (params) => {\n    return new ZodVoid({\n        typeName: ZodFirstPartyTypeKind.ZodVoid,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodArray extends ZodType {\n    _parse(input) {\n        const { ctx, status } = this._processInputParams(input);\n        const def = this._def;\n        if (ctx.parsedType !== ZodParsedType.array) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.array,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        if (def.exactLength !== null) {\n            const tooBig = ctx.data.length > def.exactLength.value;\n            const tooSmall = ctx.data.length < def.exactLength.value;\n            if (tooBig || tooSmall) {\n                addIssueToContext(ctx, {\n                    code: tooBig ? ZodIssueCode.too_big : ZodIssueCode.too_small,\n                    minimum: (tooSmall ? def.exactLength.value : undefined),\n                    maximum: (tooBig ? def.exactLength.value : undefined),\n                    type: \"array\",\n                    inclusive: true,\n                    exact: true,\n                    message: def.exactLength.message,\n                });\n                status.dirty();\n            }\n        }\n        if (def.minLength !== null) {\n            if (ctx.data.length < def.minLength.value) {\n                addIssueToContext(ctx, {\n                    code: ZodIssueCode.too_small,\n                    minimum: def.minLength.value,\n                    type: \"array\",\n                    inclusive: true,\n                    exact: false,\n                    message: def.minLength.message,\n                });\n                status.dirty();\n            }\n        }\n        if (def.maxLength !== null) {\n            if (ctx.data.length > def.maxLength.value) {\n                addIssueToContext(ctx, {\n                    code: ZodIssueCode.too_big,\n                    maximum: def.maxLength.value,\n                    type: \"array\",\n                    inclusive: true,\n                    exact: false,\n                    message: def.maxLength.message,\n                });\n                status.dirty();\n            }\n        }\n        if (ctx.common.async) {\n            return Promise.all([...ctx.data].map((item, i) => {\n                return def.type._parseAsync(new ParseInputLazyPath(ctx, item, ctx.path, i));\n            })).then((result) => {\n                return ParseStatus.mergeArray(status, result);\n            });\n        }\n        const result = [...ctx.data].map((item, i) => {\n            return def.type._parseSync(new ParseInputLazyPath(ctx, item, ctx.path, i));\n        });\n        return ParseStatus.mergeArray(status, result);\n    }\n    get element() {\n        return this._def.type;\n    }\n    min(minLength, message) {\n        return new ZodArray({\n            ...this._def,\n            minLength: { value: minLength, message: errorUtil.toString(message) },\n        });\n    }\n    max(maxLength, message) {\n        return new ZodArray({\n            ...this._def,\n            maxLength: { value: maxLength, message: errorUtil.toString(message) },\n        });\n    }\n    length(len, message) {\n        return new ZodArray({\n            ...this._def,\n            exactLength: { value: len, message: errorUtil.toString(message) },\n        });\n    }\n    nonempty(message) {\n        return this.min(1, message);\n    }\n}\nZodArray.create = (schema, params) => {\n    return new ZodArray({\n        type: schema,\n        minLength: null,\n        maxLength: null,\n        exactLength: null,\n        typeName: ZodFirstPartyTypeKind.ZodArray,\n        ...processCreateParams(params),\n    });\n};\nfunction deepPartialify(schema) {\n    if (schema instanceof ZodObject) {\n        const newShape = {};\n        for (const key in schema.shape) {\n            const fieldSchema = schema.shape[key];\n            newShape[key] = ZodOptional.create(deepPartialify(fieldSchema));\n        }\n        return new ZodObject({\n            ...schema._def,\n            shape: () => newShape,\n        });\n    }\n    else if (schema instanceof ZodArray) {\n        return new ZodArray({\n            ...schema._def,\n            type: deepPartialify(schema.element),\n        });\n    }\n    else if (schema instanceof ZodOptional) {\n        return ZodOptional.create(deepPartialify(schema.unwrap()));\n    }\n    else if (schema instanceof ZodNullable) {\n        return ZodNullable.create(deepPartialify(schema.unwrap()));\n    }\n    else if (schema instanceof ZodTuple) {\n        return ZodTuple.create(schema.items.map((item) => deepPartialify(item)));\n    }\n    else {\n        return schema;\n    }\n}\nexport class ZodObject extends ZodType {\n    constructor() {\n        super(...arguments);\n        this._cached = null;\n        /**\n         * @deprecated In most cases, this is no longer needed - unknown properties are now silently stripped.\n         * If you want to pass through unknown properties, use `.passthrough()` instead.\n         */\n        this.nonstrict = this.passthrough;\n        // extend<\n        //   Augmentation extends ZodRawShape,\n        //   NewOutput extends util.flatten<{\n        //     [k in keyof Augmentation | keyof Output]: k extends keyof Augmentation\n        //       ? Augmentation[k][\"_output\"]\n        //       : k extends keyof Output\n        //       ? Output[k]\n        //       : never;\n        //   }>,\n        //   NewInput extends util.flatten<{\n        //     [k in keyof Augmentation | keyof Input]: k extends keyof Augmentation\n        //       ? Augmentation[k][\"_input\"]\n        //       : k extends keyof Input\n        //       ? Input[k]\n        //       : never;\n        //   }>\n        // >(\n        //   augmentation: Augmentation\n        // ): ZodObject<\n        //   extendShape<T, Augmentation>,\n        //   UnknownKeys,\n        //   Catchall,\n        //   NewOutput,\n        //   NewInput\n        // > {\n        //   return new ZodObject({\n        //     ...this._def,\n        //     shape: () => ({\n        //       ...this._def.shape(),\n        //       ...augmentation,\n        //     }),\n        //   }) as any;\n        // }\n        /**\n         * @deprecated Use `.extend` instead\n         *  */\n        this.augment = this.extend;\n    }\n    _getCached() {\n        if (this._cached !== null)\n            return this._cached;\n        const shape = this._def.shape();\n        const keys = util.objectKeys(shape);\n        this._cached = { shape, keys };\n        return this._cached;\n    }\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.object) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.object,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        const { status, ctx } = this._processInputParams(input);\n        const { shape, keys: shapeKeys } = this._getCached();\n        const extraKeys = [];\n        if (!(this._def.catchall instanceof ZodNever && this._def.unknownKeys === \"strip\")) {\n            for (const key in ctx.data) {\n                if (!shapeKeys.includes(key)) {\n                    extraKeys.push(key);\n                }\n            }\n        }\n        const pairs = [];\n        for (const key of shapeKeys) {\n            const keyValidator = shape[key];\n            const value = ctx.data[key];\n            pairs.push({\n                key: { status: \"valid\", value: key },\n                value: keyValidator._parse(new ParseInputLazyPath(ctx, value, ctx.path, key)),\n                alwaysSet: key in ctx.data,\n            });\n        }\n        if (this._def.catchall instanceof ZodNever) {\n            const unknownKeys = this._def.unknownKeys;\n            if (unknownKeys === \"passthrough\") {\n                for (const key of extraKeys) {\n                    pairs.push({\n                        key: { status: \"valid\", value: key },\n                        value: { status: \"valid\", value: ctx.data[key] },\n                    });\n                }\n            }\n            else if (unknownKeys === \"strict\") {\n                if (extraKeys.length > 0) {\n                    addIssueToContext(ctx, {\n                        code: ZodIssueCode.unrecognized_keys,\n                        keys: extraKeys,\n                    });\n                    status.dirty();\n                }\n            }\n            else if (unknownKeys === \"strip\") {\n            }\n            else {\n                throw new Error(`Internal ZodObject error: invalid unknownKeys value.`);\n            }\n        }\n        else {\n            // run catchall validation\n            const catchall = this._def.catchall;\n            for (const key of extraKeys) {\n                const value = ctx.data[key];\n                pairs.push({\n                    key: { status: \"valid\", value: key },\n                    value: catchall._parse(new ParseInputLazyPath(ctx, value, ctx.path, key) //, ctx.child(key), value, getParsedType(value)\n                    ),\n                    alwaysSet: key in ctx.data,\n                });\n            }\n        }\n        if (ctx.common.async) {\n            return Promise.resolve()\n                .then(async () => {\n                const syncPairs = [];\n                for (const pair of pairs) {\n                    const key = await pair.key;\n                    const value = await pair.value;\n                    syncPairs.push({\n                        key,\n                        value,\n                        alwaysSet: pair.alwaysSet,\n                    });\n                }\n                return syncPairs;\n            })\n                .then((syncPairs) => {\n                return ParseStatus.mergeObjectSync(status, syncPairs);\n            });\n        }\n        else {\n            return ParseStatus.mergeObjectSync(status, pairs);\n        }\n    }\n    get shape() {\n        return this._def.shape();\n    }\n    strict(message) {\n        errorUtil.errToObj;\n        return new ZodObject({\n            ...this._def,\n            unknownKeys: \"strict\",\n            ...(message !== undefined\n                ? {\n                    errorMap: (issue, ctx) => {\n                        const defaultError = this._def.errorMap?.(issue, ctx).message ?? ctx.defaultError;\n                        if (issue.code === \"unrecognized_keys\")\n                            return {\n                                message: errorUtil.errToObj(message).message ?? defaultError,\n                            };\n                        return {\n                            message: defaultError,\n                        };\n                    },\n                }\n                : {}),\n        });\n    }\n    strip() {\n        return new ZodObject({\n            ...this._def,\n            unknownKeys: \"strip\",\n        });\n    }\n    passthrough() {\n        return new ZodObject({\n            ...this._def,\n            unknownKeys: \"passthrough\",\n        });\n    }\n    // const AugmentFactory =\n    //   <Def extends ZodObjectDef>(def: Def) =>\n    //   <Augmentation extends ZodRawShape>(\n    //     augmentation: Augmentation\n    //   ): ZodObject<\n    //     extendShape<ReturnType<Def[\"shape\"]>, Augmentation>,\n    //     Def[\"unknownKeys\"],\n    //     Def[\"catchall\"]\n    //   > => {\n    //     return new ZodObject({\n    //       ...def,\n    //       shape: () => ({\n    //         ...def.shape(),\n    //         ...augmentation,\n    //       }),\n    //     }) as any;\n    //   };\n    extend(augmentation) {\n        return new ZodObject({\n            ...this._def,\n            shape: () => ({\n                ...this._def.shape(),\n                ...augmentation,\n            }),\n        });\n    }\n    /**\n     * Prior to zod@1.0.12 there was a bug in the\n     * inferred type of merged objects. Please\n     * upgrade if you are experiencing issues.\n     */\n    merge(merging) {\n        const merged = new ZodObject({\n            unknownKeys: merging._def.unknownKeys,\n            catchall: merging._def.catchall,\n            shape: () => ({\n                ...this._def.shape(),\n                ...merging._def.shape(),\n            }),\n            typeName: ZodFirstPartyTypeKind.ZodObject,\n        });\n        return merged;\n    }\n    // merge<\n    //   Incoming extends AnyZodObject,\n    //   Augmentation extends Incoming[\"shape\"],\n    //   NewOutput extends {\n    //     [k in keyof Augmentation | keyof Output]: k extends keyof Augmentation\n    //       ? Augmentation[k][\"_output\"]\n    //       : k extends keyof Output\n    //       ? Output[k]\n    //       : never;\n    //   },\n    //   NewInput extends {\n    //     [k in keyof Augmentation | keyof Input]: k extends keyof Augmentation\n    //       ? Augmentation[k][\"_input\"]\n    //       : k extends keyof Input\n    //       ? Input[k]\n    //       : never;\n    //   }\n    // >(\n    //   merging: Incoming\n    // ): ZodObject<\n    //   extendShape<T, ReturnType<Incoming[\"_def\"][\"shape\"]>>,\n    //   Incoming[\"_def\"][\"unknownKeys\"],\n    //   Incoming[\"_def\"][\"catchall\"],\n    //   NewOutput,\n    //   NewInput\n    // > {\n    //   const merged: any = new ZodObject({\n    //     unknownKeys: merging._def.unknownKeys,\n    //     catchall: merging._def.catchall,\n    //     shape: () =>\n    //       objectUtil.mergeShapes(this._def.shape(), merging._def.shape()),\n    //     typeName: ZodFirstPartyTypeKind.ZodObject,\n    //   }) as any;\n    //   return merged;\n    // }\n    setKey(key, schema) {\n        return this.augment({ [key]: schema });\n    }\n    // merge<Incoming extends AnyZodObject>(\n    //   merging: Incoming\n    // ): //ZodObject<T & Incoming[\"_shape\"], UnknownKeys, Catchall> = (merging) => {\n    // ZodObject<\n    //   extendShape<T, ReturnType<Incoming[\"_def\"][\"shape\"]>>,\n    //   Incoming[\"_def\"][\"unknownKeys\"],\n    //   Incoming[\"_def\"][\"catchall\"]\n    // > {\n    //   // const mergedShape = objectUtil.mergeShapes(\n    //   //   this._def.shape(),\n    //   //   merging._def.shape()\n    //   // );\n    //   const merged: any = new ZodObject({\n    //     unknownKeys: merging._def.unknownKeys,\n    //     catchall: merging._def.catchall,\n    //     shape: () =>\n    //       objectUtil.mergeShapes(this._def.shape(), merging._def.shape()),\n    //     typeName: ZodFirstPartyTypeKind.ZodObject,\n    //   }) as any;\n    //   return merged;\n    // }\n    catchall(index) {\n        return new ZodObject({\n            ...this._def,\n            catchall: index,\n        });\n    }\n    pick(mask) {\n        const shape = {};\n        for (const key of util.objectKeys(mask)) {\n            if (mask[key] && this.shape[key]) {\n                shape[key] = this.shape[key];\n            }\n        }\n        return new ZodObject({\n            ...this._def,\n            shape: () => shape,\n        });\n    }\n    omit(mask) {\n        const shape = {};\n        for (const key of util.objectKeys(this.shape)) {\n            if (!mask[key]) {\n                shape[key] = this.shape[key];\n            }\n        }\n        return new ZodObject({\n            ...this._def,\n            shape: () => shape,\n        });\n    }\n    /**\n     * @deprecated\n     */\n    deepPartial() {\n        return deepPartialify(this);\n    }\n    partial(mask) {\n        const newShape = {};\n        for (const key of util.objectKeys(this.shape)) {\n            const fieldSchema = this.shape[key];\n            if (mask && !mask[key]) {\n                newShape[key] = fieldSchema;\n            }\n            else {\n                newShape[key] = fieldSchema.optional();\n            }\n        }\n        return new ZodObject({\n            ...this._def,\n            shape: () => newShape,\n        });\n    }\n    required(mask) {\n        const newShape = {};\n        for (const key of util.objectKeys(this.shape)) {\n            if (mask && !mask[key]) {\n                newShape[key] = this.shape[key];\n            }\n            else {\n                const fieldSchema = this.shape[key];\n                let newField = fieldSchema;\n                while (newField instanceof ZodOptional) {\n                    newField = newField._def.innerType;\n                }\n                newShape[key] = newField;\n            }\n        }\n        return new ZodObject({\n            ...this._def,\n            shape: () => newShape,\n        });\n    }\n    keyof() {\n        return createZodEnum(util.objectKeys(this.shape));\n    }\n}\nZodObject.create = (shape, params) => {\n    return new ZodObject({\n        shape: () => shape,\n        unknownKeys: \"strip\",\n        catchall: ZodNever.create(),\n        typeName: ZodFirstPartyTypeKind.ZodObject,\n        ...processCreateParams(params),\n    });\n};\nZodObject.strictCreate = (shape, params) => {\n    return new ZodObject({\n        shape: () => shape,\n        unknownKeys: \"strict\",\n        catchall: ZodNever.create(),\n        typeName: ZodFirstPartyTypeKind.ZodObject,\n        ...processCreateParams(params),\n    });\n};\nZodObject.lazycreate = (shape, params) => {\n    return new ZodObject({\n        shape,\n        unknownKeys: \"strip\",\n        catchall: ZodNever.create(),\n        typeName: ZodFirstPartyTypeKind.ZodObject,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodUnion extends ZodType {\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        const options = this._def.options;\n        function handleResults(results) {\n            // return first issue-free validation if it exists\n            for (const result of results) {\n                if (result.result.status === \"valid\") {\n                    return result.result;\n                }\n            }\n            for (const result of results) {\n                if (result.result.status === \"dirty\") {\n                    // add issues from dirty option\n                    ctx.common.issues.push(...result.ctx.common.issues);\n                    return result.result;\n                }\n            }\n            // return invalid\n            const unionErrors = results.map((result) => new ZodError(result.ctx.common.issues));\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_union,\n                unionErrors,\n            });\n            return INVALID;\n        }\n        if (ctx.common.async) {\n            return Promise.all(options.map(async (option) => {\n                const childCtx = {\n                    ...ctx,\n                    common: {\n                        ...ctx.common,\n                        issues: [],\n                    },\n                    parent: null,\n                };\n                return {\n                    result: await option._parseAsync({\n                        data: ctx.data,\n                        path: ctx.path,\n                        parent: childCtx,\n                    }),\n                    ctx: childCtx,\n                };\n            })).then(handleResults);\n        }\n        else {\n            let dirty = undefined;\n            const issues = [];\n            for (const option of options) {\n                const childCtx = {\n                    ...ctx,\n                    common: {\n                        ...ctx.common,\n                        issues: [],\n                    },\n                    parent: null,\n                };\n                const result = option._parseSync({\n                    data: ctx.data,\n                    path: ctx.path,\n                    parent: childCtx,\n                });\n                if (result.status === \"valid\") {\n                    return result;\n                }\n                else if (result.status === \"dirty\" && !dirty) {\n                    dirty = { result, ctx: childCtx };\n                }\n                if (childCtx.common.issues.length) {\n                    issues.push(childCtx.common.issues);\n                }\n            }\n            if (dirty) {\n                ctx.common.issues.push(...dirty.ctx.common.issues);\n                return dirty.result;\n            }\n            const unionErrors = issues.map((issues) => new ZodError(issues));\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_union,\n                unionErrors,\n            });\n            return INVALID;\n        }\n    }\n    get options() {\n        return this._def.options;\n    }\n}\nZodUnion.create = (types, params) => {\n    return new ZodUnion({\n        options: types,\n        typeName: ZodFirstPartyTypeKind.ZodUnion,\n        ...processCreateParams(params),\n    });\n};\n/////////////////////////////////////////////////////\n/////////////////////////////////////////////////////\n//////////                                 //////////\n//////////      ZodDiscriminatedUnion      //////////\n//////////                                 //////////\n/////////////////////////////////////////////////////\n/////////////////////////////////////////////////////\nconst getDiscriminator = (type) => {\n    if (type instanceof ZodLazy) {\n        return getDiscriminator(type.schema);\n    }\n    else if (type instanceof ZodEffects) {\n        return getDiscriminator(type.innerType());\n    }\n    else if (type instanceof ZodLiteral) {\n        return [type.value];\n    }\n    else if (type instanceof ZodEnum) {\n        return type.options;\n    }\n    else if (type instanceof ZodNativeEnum) {\n        // eslint-disable-next-line ban/ban\n        return util.objectValues(type.enum);\n    }\n    else if (type instanceof ZodDefault) {\n        return getDiscriminator(type._def.innerType);\n    }\n    else if (type instanceof ZodUndefined) {\n        return [undefined];\n    }\n    else if (type instanceof ZodNull) {\n        return [null];\n    }\n    else if (type instanceof ZodOptional) {\n        return [undefined, ...getDiscriminator(type.unwrap())];\n    }\n    else if (type instanceof ZodNullable) {\n        return [null, ...getDiscriminator(type.unwrap())];\n    }\n    else if (type instanceof ZodBranded) {\n        return getDiscriminator(type.unwrap());\n    }\n    else if (type instanceof ZodReadonly) {\n        return getDiscriminator(type.unwrap());\n    }\n    else if (type instanceof ZodCatch) {\n        return getDiscriminator(type._def.innerType);\n    }\n    else {\n        return [];\n    }\n};\nexport class ZodDiscriminatedUnion extends ZodType {\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        if (ctx.parsedType !== ZodParsedType.object) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.object,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        const discriminator = this.discriminator;\n        const discriminatorValue = ctx.data[discriminator];\n        const option = this.optionsMap.get(discriminatorValue);\n        if (!option) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_union_discriminator,\n                options: Array.from(this.optionsMap.keys()),\n                path: [discriminator],\n            });\n            return INVALID;\n        }\n        if (ctx.common.async) {\n            return option._parseAsync({\n                data: ctx.data,\n                path: ctx.path,\n                parent: ctx,\n            });\n        }\n        else {\n            return option._parseSync({\n                data: ctx.data,\n                path: ctx.path,\n                parent: ctx,\n            });\n        }\n    }\n    get discriminator() {\n        return this._def.discriminator;\n    }\n    get options() {\n        return this._def.options;\n    }\n    get optionsMap() {\n        return this._def.optionsMap;\n    }\n    /**\n     * The constructor of the discriminated union schema. Its behaviour is very similar to that of the normal z.union() constructor.\n     * However, it only allows a union of objects, all of which need to share a discriminator property. This property must\n     * have a different value for each object in the union.\n     * @param discriminator the name of the discriminator property\n     * @param types an array of object schemas\n     * @param params\n     */\n    static create(discriminator, options, params) {\n        // Get all the valid discriminator values\n        const optionsMap = new Map();\n        // try {\n        for (const type of options) {\n            const discriminatorValues = getDiscriminator(type.shape[discriminator]);\n            if (!discriminatorValues.length) {\n                throw new Error(`A discriminator value for key \\`${discriminator}\\` could not be extracted from all schema options`);\n            }\n            for (const value of discriminatorValues) {\n                if (optionsMap.has(value)) {\n                    throw new Error(`Discriminator property ${String(discriminator)} has duplicate value ${String(value)}`);\n                }\n                optionsMap.set(value, type);\n            }\n        }\n        return new ZodDiscriminatedUnion({\n            typeName: ZodFirstPartyTypeKind.ZodDiscriminatedUnion,\n            discriminator,\n            options,\n            optionsMap,\n            ...processCreateParams(params),\n        });\n    }\n}\nfunction mergeValues(a, b) {\n    const aType = getParsedType(a);\n    const bType = getParsedType(b);\n    if (a === b) {\n        return { valid: true, data: a };\n    }\n    else if (aType === ZodParsedType.object && bType === ZodParsedType.object) {\n        const bKeys = util.objectKeys(b);\n        const sharedKeys = util.objectKeys(a).filter((key) => bKeys.indexOf(key) !== -1);\n        const newObj = { ...a, ...b };\n        for (const key of sharedKeys) {\n            const sharedValue = mergeValues(a[key], b[key]);\n            if (!sharedValue.valid) {\n                return { valid: false };\n            }\n            newObj[key] = sharedValue.data;\n        }\n        return { valid: true, data: newObj };\n    }\n    else if (aType === ZodParsedType.array && bType === ZodParsedType.array) {\n        if (a.length !== b.length) {\n            return { valid: false };\n        }\n        const newArray = [];\n        for (let index = 0; index < a.length; index++) {\n            const itemA = a[index];\n            const itemB = b[index];\n            const sharedValue = mergeValues(itemA, itemB);\n            if (!sharedValue.valid) {\n                return { valid: false };\n            }\n            newArray.push(sharedValue.data);\n        }\n        return { valid: true, data: newArray };\n    }\n    else if (aType === ZodParsedType.date && bType === ZodParsedType.date && +a === +b) {\n        return { valid: true, data: a };\n    }\n    else {\n        return { valid: false };\n    }\n}\nexport class ZodIntersection extends ZodType {\n    _parse(input) {\n        const { status, ctx } = this._processInputParams(input);\n        const handleParsed = (parsedLeft, parsedRight) => {\n            if (isAborted(parsedLeft) || isAborted(parsedRight)) {\n                return INVALID;\n            }\n            const merged = mergeValues(parsedLeft.value, parsedRight.value);\n            if (!merged.valid) {\n                addIssueToContext(ctx, {\n                    code: ZodIssueCode.invalid_intersection_types,\n                });\n                return INVALID;\n            }\n            if (isDirty(parsedLeft) || isDirty(parsedRight)) {\n                status.dirty();\n            }\n            return { status: status.value, value: merged.data };\n        };\n        if (ctx.common.async) {\n            return Promise.all([\n                this._def.left._parseAsync({\n                    data: ctx.data,\n                    path: ctx.path,\n                    parent: ctx,\n                }),\n                this._def.right._parseAsync({\n                    data: ctx.data,\n                    path: ctx.path,\n                    parent: ctx,\n                }),\n            ]).then(([left, right]) => handleParsed(left, right));\n        }\n        else {\n            return handleParsed(this._def.left._parseSync({\n                data: ctx.data,\n                path: ctx.path,\n                parent: ctx,\n            }), this._def.right._parseSync({\n                data: ctx.data,\n                path: ctx.path,\n                parent: ctx,\n            }));\n        }\n    }\n}\nZodIntersection.create = (left, right, params) => {\n    return new ZodIntersection({\n        left: left,\n        right: right,\n        typeName: ZodFirstPartyTypeKind.ZodIntersection,\n        ...processCreateParams(params),\n    });\n};\n// type ZodTupleItems = [ZodTypeAny, ...ZodTypeAny[]];\nexport class ZodTuple extends ZodType {\n    _parse(input) {\n        const { status, ctx } = this._processInputParams(input);\n        if (ctx.parsedType !== ZodParsedType.array) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.array,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        if (ctx.data.length < this._def.items.length) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.too_small,\n                minimum: this._def.items.length,\n                inclusive: true,\n                exact: false,\n                type: \"array\",\n            });\n            return INVALID;\n        }\n        const rest = this._def.rest;\n        if (!rest && ctx.data.length > this._def.items.length) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.too_big,\n                maximum: this._def.items.length,\n                inclusive: true,\n                exact: false,\n                type: \"array\",\n            });\n            status.dirty();\n        }\n        const items = [...ctx.data]\n            .map((item, itemIndex) => {\n            const schema = this._def.items[itemIndex] || this._def.rest;\n            if (!schema)\n                return null;\n            return schema._parse(new ParseInputLazyPath(ctx, item, ctx.path, itemIndex));\n        })\n            .filter((x) => !!x); // filter nulls\n        if (ctx.common.async) {\n            return Promise.all(items).then((results) => {\n                return ParseStatus.mergeArray(status, results);\n            });\n        }\n        else {\n            return ParseStatus.mergeArray(status, items);\n        }\n    }\n    get items() {\n        return this._def.items;\n    }\n    rest(rest) {\n        return new ZodTuple({\n            ...this._def,\n            rest,\n        });\n    }\n}\nZodTuple.create = (schemas, params) => {\n    if (!Array.isArray(schemas)) {\n        throw new Error(\"You must pass an array of schemas to z.tuple([ ... ])\");\n    }\n    return new ZodTuple({\n        items: schemas,\n        typeName: ZodFirstPartyTypeKind.ZodTuple,\n        rest: null,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodRecord extends ZodType {\n    get keySchema() {\n        return this._def.keyType;\n    }\n    get valueSchema() {\n        return this._def.valueType;\n    }\n    _parse(input) {\n        const { status, ctx } = this._processInputParams(input);\n        if (ctx.parsedType !== ZodParsedType.object) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.object,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        const pairs = [];\n        const keyType = this._def.keyType;\n        const valueType = this._def.valueType;\n        for (const key in ctx.data) {\n            pairs.push({\n                key: keyType._parse(new ParseInputLazyPath(ctx, key, ctx.path, key)),\n                value: valueType._parse(new ParseInputLazyPath(ctx, ctx.data[key], ctx.path, key)),\n                alwaysSet: key in ctx.data,\n            });\n        }\n        if (ctx.common.async) {\n            return ParseStatus.mergeObjectAsync(status, pairs);\n        }\n        else {\n            return ParseStatus.mergeObjectSync(status, pairs);\n        }\n    }\n    get element() {\n        return this._def.valueType;\n    }\n    static create(first, second, third) {\n        if (second instanceof ZodType) {\n            return new ZodRecord({\n                keyType: first,\n                valueType: second,\n                typeName: ZodFirstPartyTypeKind.ZodRecord,\n                ...processCreateParams(third),\n            });\n        }\n        return new ZodRecord({\n            keyType: ZodString.create(),\n            valueType: first,\n            typeName: ZodFirstPartyTypeKind.ZodRecord,\n            ...processCreateParams(second),\n        });\n    }\n}\nexport class ZodMap extends ZodType {\n    get keySchema() {\n        return this._def.keyType;\n    }\n    get valueSchema() {\n        return this._def.valueType;\n    }\n    _parse(input) {\n        const { status, ctx } = this._processInputParams(input);\n        if (ctx.parsedType !== ZodParsedType.map) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.map,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        const keyType = this._def.keyType;\n        const valueType = this._def.valueType;\n        const pairs = [...ctx.data.entries()].map(([key, value], index) => {\n            return {\n                key: keyType._parse(new ParseInputLazyPath(ctx, key, ctx.path, [index, \"key\"])),\n                value: valueType._parse(new ParseInputLazyPath(ctx, value, ctx.path, [index, \"value\"])),\n            };\n        });\n        if (ctx.common.async) {\n            const finalMap = new Map();\n            return Promise.resolve().then(async () => {\n                for (const pair of pairs) {\n                    const key = await pair.key;\n                    const value = await pair.value;\n                    if (key.status === \"aborted\" || value.status === \"aborted\") {\n                        return INVALID;\n                    }\n                    if (key.status === \"dirty\" || value.status === \"dirty\") {\n                        status.dirty();\n                    }\n                    finalMap.set(key.value, value.value);\n                }\n                return { status: status.value, value: finalMap };\n            });\n        }\n        else {\n            const finalMap = new Map();\n            for (const pair of pairs) {\n                const key = pair.key;\n                const value = pair.value;\n                if (key.status === \"aborted\" || value.status === \"aborted\") {\n                    return INVALID;\n                }\n                if (key.status === \"dirty\" || value.status === \"dirty\") {\n                    status.dirty();\n                }\n                finalMap.set(key.value, value.value);\n            }\n            return { status: status.value, value: finalMap };\n        }\n    }\n}\nZodMap.create = (keyType, valueType, params) => {\n    return new ZodMap({\n        valueType,\n        keyType,\n        typeName: ZodFirstPartyTypeKind.ZodMap,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodSet extends ZodType {\n    _parse(input) {\n        const { status, ctx } = this._processInputParams(input);\n        if (ctx.parsedType !== ZodParsedType.set) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.set,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        const def = this._def;\n        if (def.minSize !== null) {\n            if (ctx.data.size < def.minSize.value) {\n                addIssueToContext(ctx, {\n                    code: ZodIssueCode.too_small,\n                    minimum: def.minSize.value,\n                    type: \"set\",\n                    inclusive: true,\n                    exact: false,\n                    message: def.minSize.message,\n                });\n                status.dirty();\n            }\n        }\n        if (def.maxSize !== null) {\n            if (ctx.data.size > def.maxSize.value) {\n                addIssueToContext(ctx, {\n                    code: ZodIssueCode.too_big,\n                    maximum: def.maxSize.value,\n                    type: \"set\",\n                    inclusive: true,\n                    exact: false,\n                    message: def.maxSize.message,\n                });\n                status.dirty();\n            }\n        }\n        const valueType = this._def.valueType;\n        function finalizeSet(elements) {\n            const parsedSet = new Set();\n            for (const element of elements) {\n                if (element.status === \"aborted\")\n                    return INVALID;\n                if (element.status === \"dirty\")\n                    status.dirty();\n                parsedSet.add(element.value);\n            }\n            return { status: status.value, value: parsedSet };\n        }\n        const elements = [...ctx.data.values()].map((item, i) => valueType._parse(new ParseInputLazyPath(ctx, item, ctx.path, i)));\n        if (ctx.common.async) {\n            return Promise.all(elements).then((elements) => finalizeSet(elements));\n        }\n        else {\n            return finalizeSet(elements);\n        }\n    }\n    min(minSize, message) {\n        return new ZodSet({\n            ...this._def,\n            minSize: { value: minSize, message: errorUtil.toString(message) },\n        });\n    }\n    max(maxSize, message) {\n        return new ZodSet({\n            ...this._def,\n            maxSize: { value: maxSize, message: errorUtil.toString(message) },\n        });\n    }\n    size(size, message) {\n        return this.min(size, message).max(size, message);\n    }\n    nonempty(message) {\n        return this.min(1, message);\n    }\n}\nZodSet.create = (valueType, params) => {\n    return new ZodSet({\n        valueType,\n        minSize: null,\n        maxSize: null,\n        typeName: ZodFirstPartyTypeKind.ZodSet,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodFunction extends ZodType {\n    constructor() {\n        super(...arguments);\n        this.validate = this.implement;\n    }\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        if (ctx.parsedType !== ZodParsedType.function) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.function,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        function makeArgsIssue(args, error) {\n            return makeIssue({\n                data: args,\n                path: ctx.path,\n                errorMaps: [ctx.common.contextualErrorMap, ctx.schemaErrorMap, getErrorMap(), defaultErrorMap].filter((x) => !!x),\n                issueData: {\n                    code: ZodIssueCode.invalid_arguments,\n                    argumentsError: error,\n                },\n            });\n        }\n        function makeReturnsIssue(returns, error) {\n            return makeIssue({\n                data: returns,\n                path: ctx.path,\n                errorMaps: [ctx.common.contextualErrorMap, ctx.schemaErrorMap, getErrorMap(), defaultErrorMap].filter((x) => !!x),\n                issueData: {\n                    code: ZodIssueCode.invalid_return_type,\n                    returnTypeError: error,\n                },\n            });\n        }\n        const params = { errorMap: ctx.common.contextualErrorMap };\n        const fn = ctx.data;\n        if (this._def.returns instanceof ZodPromise) {\n            // Would love a way to avoid disabling this rule, but we need\n            // an alias (using an arrow function was what caused 2651).\n            // eslint-disable-next-line @typescript-eslint/no-this-alias\n            const me = this;\n            return OK(async function (...args) {\n                const error = new ZodError([]);\n                const parsedArgs = await me._def.args.parseAsync(args, params).catch((e) => {\n                    error.addIssue(makeArgsIssue(args, e));\n                    throw error;\n                });\n                const result = await Reflect.apply(fn, this, parsedArgs);\n                const parsedReturns = await me._def.returns._def.type\n                    .parseAsync(result, params)\n                    .catch((e) => {\n                    error.addIssue(makeReturnsIssue(result, e));\n                    throw error;\n                });\n                return parsedReturns;\n            });\n        }\n        else {\n            // Would love a way to avoid disabling this rule, but we need\n            // an alias (using an arrow function was what caused 2651).\n            // eslint-disable-next-line @typescript-eslint/no-this-alias\n            const me = this;\n            return OK(function (...args) {\n                const parsedArgs = me._def.args.safeParse(args, params);\n                if (!parsedArgs.success) {\n                    throw new ZodError([makeArgsIssue(args, parsedArgs.error)]);\n                }\n                const result = Reflect.apply(fn, this, parsedArgs.data);\n                const parsedReturns = me._def.returns.safeParse(result, params);\n                if (!parsedReturns.success) {\n                    throw new ZodError([makeReturnsIssue(result, parsedReturns.error)]);\n                }\n                return parsedReturns.data;\n            });\n        }\n    }\n    parameters() {\n        return this._def.args;\n    }\n    returnType() {\n        return this._def.returns;\n    }\n    args(...items) {\n        return new ZodFunction({\n            ...this._def,\n            args: ZodTuple.create(items).rest(ZodUnknown.create()),\n        });\n    }\n    returns(returnType) {\n        return new ZodFunction({\n            ...this._def,\n            returns: returnType,\n        });\n    }\n    implement(func) {\n        const validatedFunc = this.parse(func);\n        return validatedFunc;\n    }\n    strictImplement(func) {\n        const validatedFunc = this.parse(func);\n        return validatedFunc;\n    }\n    static create(args, returns, params) {\n        return new ZodFunction({\n            args: (args ? args : ZodTuple.create([]).rest(ZodUnknown.create())),\n            returns: returns || ZodUnknown.create(),\n            typeName: ZodFirstPartyTypeKind.ZodFunction,\n            ...processCreateParams(params),\n        });\n    }\n}\nexport class ZodLazy extends ZodType {\n    get schema() {\n        return this._def.getter();\n    }\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        const lazySchema = this._def.getter();\n        return lazySchema._parse({ data: ctx.data, path: ctx.path, parent: ctx });\n    }\n}\nZodLazy.create = (getter, params) => {\n    return new ZodLazy({\n        getter: getter,\n        typeName: ZodFirstPartyTypeKind.ZodLazy,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodLiteral extends ZodType {\n    _parse(input) {\n        if (input.data !== this._def.value) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                received: ctx.data,\n                code: ZodIssueCode.invalid_literal,\n                expected: this._def.value,\n            });\n            return INVALID;\n        }\n        return { status: \"valid\", value: input.data };\n    }\n    get value() {\n        return this._def.value;\n    }\n}\nZodLiteral.create = (value, params) => {\n    return new ZodLiteral({\n        value: value,\n        typeName: ZodFirstPartyTypeKind.ZodLiteral,\n        ...processCreateParams(params),\n    });\n};\nfunction createZodEnum(values, params) {\n    return new ZodEnum({\n        values,\n        typeName: ZodFirstPartyTypeKind.ZodEnum,\n        ...processCreateParams(params),\n    });\n}\nexport class ZodEnum extends ZodType {\n    _parse(input) {\n        if (typeof input.data !== \"string\") {\n            const ctx = this._getOrReturnCtx(input);\n            const expectedValues = this._def.values;\n            addIssueToContext(ctx, {\n                expected: util.joinValues(expectedValues),\n                received: ctx.parsedType,\n                code: ZodIssueCode.invalid_type,\n            });\n            return INVALID;\n        }\n        if (!this._cache) {\n            this._cache = new Set(this._def.values);\n        }\n        if (!this._cache.has(input.data)) {\n            const ctx = this._getOrReturnCtx(input);\n            const expectedValues = this._def.values;\n            addIssueToContext(ctx, {\n                received: ctx.data,\n                code: ZodIssueCode.invalid_enum_value,\n                options: expectedValues,\n            });\n            return INVALID;\n        }\n        return OK(input.data);\n    }\n    get options() {\n        return this._def.values;\n    }\n    get enum() {\n        const enumValues = {};\n        for (const val of this._def.values) {\n            enumValues[val] = val;\n        }\n        return enumValues;\n    }\n    get Values() {\n        const enumValues = {};\n        for (const val of this._def.values) {\n            enumValues[val] = val;\n        }\n        return enumValues;\n    }\n    get Enum() {\n        const enumValues = {};\n        for (const val of this._def.values) {\n            enumValues[val] = val;\n        }\n        return enumValues;\n    }\n    extract(values, newDef = this._def) {\n        return ZodEnum.create(values, {\n            ...this._def,\n            ...newDef,\n        });\n    }\n    exclude(values, newDef = this._def) {\n        return ZodEnum.create(this.options.filter((opt) => !values.includes(opt)), {\n            ...this._def,\n            ...newDef,\n        });\n    }\n}\nZodEnum.create = createZodEnum;\nexport class ZodNativeEnum extends ZodType {\n    _parse(input) {\n        const nativeEnumValues = util.getValidEnumValues(this._def.values);\n        const ctx = this._getOrReturnCtx(input);\n        if (ctx.parsedType !== ZodParsedType.string && ctx.parsedType !== ZodParsedType.number) {\n            const expectedValues = util.objectValues(nativeEnumValues);\n            addIssueToContext(ctx, {\n                expected: util.joinValues(expectedValues),\n                received: ctx.parsedType,\n                code: ZodIssueCode.invalid_type,\n            });\n            return INVALID;\n        }\n        if (!this._cache) {\n            this._cache = new Set(util.getValidEnumValues(this._def.values));\n        }\n        if (!this._cache.has(input.data)) {\n            const expectedValues = util.objectValues(nativeEnumValues);\n            addIssueToContext(ctx, {\n                received: ctx.data,\n                code: ZodIssueCode.invalid_enum_value,\n                options: expectedValues,\n            });\n            return INVALID;\n        }\n        return OK(input.data);\n    }\n    get enum() {\n        return this._def.values;\n    }\n}\nZodNativeEnum.create = (values, params) => {\n    return new ZodNativeEnum({\n        values: values,\n        typeName: ZodFirstPartyTypeKind.ZodNativeEnum,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodPromise extends ZodType {\n    unwrap() {\n        return this._def.type;\n    }\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        if (ctx.parsedType !== ZodParsedType.promise && ctx.common.async === false) {\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.promise,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        const promisified = ctx.parsedType === ZodParsedType.promise ? ctx.data : Promise.resolve(ctx.data);\n        return OK(promisified.then((data) => {\n            return this._def.type.parseAsync(data, {\n                path: ctx.path,\n                errorMap: ctx.common.contextualErrorMap,\n            });\n        }));\n    }\n}\nZodPromise.create = (schema, params) => {\n    return new ZodPromise({\n        type: schema,\n        typeName: ZodFirstPartyTypeKind.ZodPromise,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodEffects extends ZodType {\n    innerType() {\n        return this._def.schema;\n    }\n    sourceType() {\n        return this._def.schema._def.typeName === ZodFirstPartyTypeKind.ZodEffects\n            ? this._def.schema.sourceType()\n            : this._def.schema;\n    }\n    _parse(input) {\n        const { status, ctx } = this._processInputParams(input);\n        const effect = this._def.effect || null;\n        const checkCtx = {\n            addIssue: (arg) => {\n                addIssueToContext(ctx, arg);\n                if (arg.fatal) {\n                    status.abort();\n                }\n                else {\n                    status.dirty();\n                }\n            },\n            get path() {\n                return ctx.path;\n            },\n        };\n        checkCtx.addIssue = checkCtx.addIssue.bind(checkCtx);\n        if (effect.type === \"preprocess\") {\n            const processed = effect.transform(ctx.data, checkCtx);\n            if (ctx.common.async) {\n                return Promise.resolve(processed).then(async (processed) => {\n                    if (status.value === \"aborted\")\n                        return INVALID;\n                    const result = await this._def.schema._parseAsync({\n                        data: processed,\n                        path: ctx.path,\n                        parent: ctx,\n                    });\n                    if (result.status === \"aborted\")\n                        return INVALID;\n                    if (result.status === \"dirty\")\n                        return DIRTY(result.value);\n                    if (status.value === \"dirty\")\n                        return DIRTY(result.value);\n                    return result;\n                });\n            }\n            else {\n                if (status.value === \"aborted\")\n                    return INVALID;\n                const result = this._def.schema._parseSync({\n                    data: processed,\n                    path: ctx.path,\n                    parent: ctx,\n                });\n                if (result.status === \"aborted\")\n                    return INVALID;\n                if (result.status === \"dirty\")\n                    return DIRTY(result.value);\n                if (status.value === \"dirty\")\n                    return DIRTY(result.value);\n                return result;\n            }\n        }\n        if (effect.type === \"refinement\") {\n            const executeRefinement = (acc) => {\n                const result = effect.refinement(acc, checkCtx);\n                if (ctx.common.async) {\n                    return Promise.resolve(result);\n                }\n                if (result instanceof Promise) {\n                    throw new Error(\"Async refinement encountered during synchronous parse operation. Use .parseAsync instead.\");\n                }\n                return acc;\n            };\n            if (ctx.common.async === false) {\n                const inner = this._def.schema._parseSync({\n                    data: ctx.data,\n                    path: ctx.path,\n                    parent: ctx,\n                });\n                if (inner.status === \"aborted\")\n                    return INVALID;\n                if (inner.status === \"dirty\")\n                    status.dirty();\n                // return value is ignored\n                executeRefinement(inner.value);\n                return { status: status.value, value: inner.value };\n            }\n            else {\n                return this._def.schema._parseAsync({ data: ctx.data, path: ctx.path, parent: ctx }).then((inner) => {\n                    if (inner.status === \"aborted\")\n                        return INVALID;\n                    if (inner.status === \"dirty\")\n                        status.dirty();\n                    return executeRefinement(inner.value).then(() => {\n                        return { status: status.value, value: inner.value };\n                    });\n                });\n            }\n        }\n        if (effect.type === \"transform\") {\n            if (ctx.common.async === false) {\n                const base = this._def.schema._parseSync({\n                    data: ctx.data,\n                    path: ctx.path,\n                    parent: ctx,\n                });\n                if (!isValid(base))\n                    return INVALID;\n                const result = effect.transform(base.value, checkCtx);\n                if (result instanceof Promise) {\n                    throw new Error(`Asynchronous transform encountered during synchronous parse operation. Use .parseAsync instead.`);\n                }\n                return { status: status.value, value: result };\n            }\n            else {\n                return this._def.schema._parseAsync({ data: ctx.data, path: ctx.path, parent: ctx }).then((base) => {\n                    if (!isValid(base))\n                        return INVALID;\n                    return Promise.resolve(effect.transform(base.value, checkCtx)).then((result) => ({\n                        status: status.value,\n                        value: result,\n                    }));\n                });\n            }\n        }\n        util.assertNever(effect);\n    }\n}\nZodEffects.create = (schema, effect, params) => {\n    return new ZodEffects({\n        schema,\n        typeName: ZodFirstPartyTypeKind.ZodEffects,\n        effect,\n        ...processCreateParams(params),\n    });\n};\nZodEffects.createWithPreprocess = (preprocess, schema, params) => {\n    return new ZodEffects({\n        schema,\n        effect: { type: \"preprocess\", transform: preprocess },\n        typeName: ZodFirstPartyTypeKind.ZodEffects,\n        ...processCreateParams(params),\n    });\n};\nexport { ZodEffects as ZodTransformer };\nexport class ZodOptional extends ZodType {\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType === ZodParsedType.undefined) {\n            return OK(undefined);\n        }\n        return this._def.innerType._parse(input);\n    }\n    unwrap() {\n        return this._def.innerType;\n    }\n}\nZodOptional.create = (type, params) => {\n    return new ZodOptional({\n        innerType: type,\n        typeName: ZodFirstPartyTypeKind.ZodOptional,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodNullable extends ZodType {\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType === ZodParsedType.null) {\n            return OK(null);\n        }\n        return this._def.innerType._parse(input);\n    }\n    unwrap() {\n        return this._def.innerType;\n    }\n}\nZodNullable.create = (type, params) => {\n    return new ZodNullable({\n        innerType: type,\n        typeName: ZodFirstPartyTypeKind.ZodNullable,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodDefault extends ZodType {\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        let data = ctx.data;\n        if (ctx.parsedType === ZodParsedType.undefined) {\n            data = this._def.defaultValue();\n        }\n        return this._def.innerType._parse({\n            data,\n            path: ctx.path,\n            parent: ctx,\n        });\n    }\n    removeDefault() {\n        return this._def.innerType;\n    }\n}\nZodDefault.create = (type, params) => {\n    return new ZodDefault({\n        innerType: type,\n        typeName: ZodFirstPartyTypeKind.ZodDefault,\n        defaultValue: typeof params.default === \"function\" ? params.default : () => params.default,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodCatch extends ZodType {\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        // newCtx is used to not collect issues from inner types in ctx\n        const newCtx = {\n            ...ctx,\n            common: {\n                ...ctx.common,\n                issues: [],\n            },\n        };\n        const result = this._def.innerType._parse({\n            data: newCtx.data,\n            path: newCtx.path,\n            parent: {\n                ...newCtx,\n            },\n        });\n        if (isAsync(result)) {\n            return result.then((result) => {\n                return {\n                    status: \"valid\",\n                    value: result.status === \"valid\"\n                        ? result.value\n                        : this._def.catchValue({\n                            get error() {\n                                return new ZodError(newCtx.common.issues);\n                            },\n                            input: newCtx.data,\n                        }),\n                };\n            });\n        }\n        else {\n            return {\n                status: \"valid\",\n                value: result.status === \"valid\"\n                    ? result.value\n                    : this._def.catchValue({\n                        get error() {\n                            return new ZodError(newCtx.common.issues);\n                        },\n                        input: newCtx.data,\n                    }),\n            };\n        }\n    }\n    removeCatch() {\n        return this._def.innerType;\n    }\n}\nZodCatch.create = (type, params) => {\n    return new ZodCatch({\n        innerType: type,\n        typeName: ZodFirstPartyTypeKind.ZodCatch,\n        catchValue: typeof params.catch === \"function\" ? params.catch : () => params.catch,\n        ...processCreateParams(params),\n    });\n};\nexport class ZodNaN extends ZodType {\n    _parse(input) {\n        const parsedType = this._getType(input);\n        if (parsedType !== ZodParsedType.nan) {\n            const ctx = this._getOrReturnCtx(input);\n            addIssueToContext(ctx, {\n                code: ZodIssueCode.invalid_type,\n                expected: ZodParsedType.nan,\n                received: ctx.parsedType,\n            });\n            return INVALID;\n        }\n        return { status: \"valid\", value: input.data };\n    }\n}\nZodNaN.create = (params) => {\n    return new ZodNaN({\n        typeName: ZodFirstPartyTypeKind.ZodNaN,\n        ...processCreateParams(params),\n    });\n};\nexport const BRAND = Symbol(\"zod_brand\");\nexport class ZodBranded extends ZodType {\n    _parse(input) {\n        const { ctx } = this._processInputParams(input);\n        const data = ctx.data;\n        return this._def.type._parse({\n            data,\n            path: ctx.path,\n            parent: ctx,\n        });\n    }\n    unwrap() {\n        return this._def.type;\n    }\n}\nexport class ZodPipeline extends ZodType {\n    _parse(input) {\n        const { status, ctx } = this._processInputParams(input);\n        if (ctx.common.async) {\n            const handleAsync = async () => {\n                const inResult = await this._def.in._parseAsync({\n                    data: ctx.data,\n                    path: ctx.path,\n                    parent: ctx,\n                });\n                if (inResult.status === \"aborted\")\n                    return INVALID;\n                if (inResult.status === \"dirty\") {\n                    status.dirty();\n                    return DIRTY(inResult.value);\n                }\n                else {\n                    return this._def.out._parseAsync({\n                        data: inResult.value,\n                        path: ctx.path,\n                        parent: ctx,\n                    });\n                }\n            };\n            return handleAsync();\n        }\n        else {\n            const inResult = this._def.in._parseSync({\n                data: ctx.data,\n                path: ctx.path,\n                parent: ctx,\n            });\n            if (inResult.status === \"aborted\")\n                return INVALID;\n            if (inResult.status === \"dirty\") {\n                status.dirty();\n                return {\n                    status: \"dirty\",\n                    value: inResult.value,\n                };\n            }\n            else {\n                return this._def.out._parseSync({\n                    data: inResult.value,\n                    path: ctx.path,\n                    parent: ctx,\n                });\n            }\n        }\n    }\n    static create(a, b) {\n        return new ZodPipeline({\n            in: a,\n            out: b,\n            typeName: ZodFirstPartyTypeKind.ZodPipeline,\n        });\n    }\n}\nexport class ZodReadonly extends ZodType {\n    _parse(input) {\n        const result = this._def.innerType._parse(input);\n        const freeze = (data) => {\n            if (isValid(data)) {\n                data.value = Object.freeze(data.value);\n            }\n            return data;\n        };\n        return isAsync(result) ? result.then((data) => freeze(data)) : freeze(result);\n    }\n    unwrap() {\n        return this._def.innerType;\n    }\n}\nZodReadonly.create = (type, params) => {\n    return new ZodReadonly({\n        innerType: type,\n        typeName: ZodFirstPartyTypeKind.ZodReadonly,\n        ...processCreateParams(params),\n    });\n};\n////////////////////////////////////////\n////////////////////////////////////////\n//////////                    //////////\n//////////      z.custom      //////////\n//////////                    //////////\n////////////////////////////////////////\n////////////////////////////////////////\nfunction cleanParams(params, data) {\n    const p = typeof params === \"function\" ? params(data) : typeof params === \"string\" ? { message: params } : params;\n    const p2 = typeof p === \"string\" ? { message: p } : p;\n    return p2;\n}\nexport function custom(check, _params = {}, \n/**\n * @deprecated\n *\n * Pass `fatal` into the params object instead:\n *\n * ```ts\n * z.string().custom((val) => val.length > 5, { fatal: false })\n * ```\n *\n */\nfatal) {\n    if (check)\n        return ZodAny.create().superRefine((data, ctx) => {\n            const r = check(data);\n            if (r instanceof Promise) {\n                return r.then((r) => {\n                    if (!r) {\n                        const params = cleanParams(_params, data);\n                        const _fatal = params.fatal ?? fatal ?? true;\n                        ctx.addIssue({ code: \"custom\", ...params, fatal: _fatal });\n                    }\n                });\n            }\n            if (!r) {\n                const params = cleanParams(_params, data);\n                const _fatal = params.fatal ?? fatal ?? true;\n                ctx.addIssue({ code: \"custom\", ...params, fatal: _fatal });\n            }\n            return;\n        });\n    return ZodAny.create();\n}\nexport { ZodType as Schema, ZodType as ZodSchema };\nexport const late = {\n    object: ZodObject.lazycreate,\n};\nexport var ZodFirstPartyTypeKind;\n(function (ZodFirstPartyTypeKind) {\n    ZodFirstPartyTypeKind[\"ZodString\"] = \"ZodString\";\n    ZodFirstPartyTypeKind[\"ZodNumber\"] = \"ZodNumber\";\n    ZodFirstPartyTypeKind[\"ZodNaN\"] = \"ZodNaN\";\n    ZodFirstPartyTypeKind[\"ZodBigInt\"] = \"ZodBigInt\";\n    ZodFirstPartyTypeKind[\"ZodBoolean\"] = \"ZodBoolean\";\n    ZodFirstPartyTypeKind[\"ZodDate\"] = \"ZodDate\";\n    ZodFirstPartyTypeKind[\"ZodSymbol\"] = \"ZodSymbol\";\n    ZodFirstPartyTypeKind[\"ZodUndefined\"] = \"ZodUndefined\";\n    ZodFirstPartyTypeKind[\"ZodNull\"] = \"ZodNull\";\n    ZodFirstPartyTypeKind[\"ZodAny\"] = \"ZodAny\";\n    ZodFirstPartyTypeKind[\"ZodUnknown\"] = \"ZodUnknown\";\n    ZodFirstPartyTypeKind[\"ZodNever\"] = \"ZodNever\";\n    ZodFirstPartyTypeKind[\"ZodVoid\"] = \"ZodVoid\";\n    ZodFirstPartyTypeKind[\"ZodArray\"] = \"ZodArray\";\n    ZodFirstPartyTypeKind[\"ZodObject\"] = \"ZodObject\";\n    ZodFirstPartyTypeKind[\"ZodUnion\"] = \"ZodUnion\";\n    ZodFirstPartyTypeKind[\"ZodDiscriminatedUnion\"] = \"ZodDiscriminatedUnion\";\n    ZodFirstPartyTypeKind[\"ZodIntersection\"] = \"ZodIntersection\";\n    ZodFirstPartyTypeKind[\"ZodTuple\"] = \"ZodTuple\";\n    ZodFirstPartyTypeKind[\"ZodRecord\"] = \"ZodRecord\";\n    ZodFirstPartyTypeKind[\"ZodMap\"] = \"ZodMap\";\n    ZodFirstPartyTypeKind[\"ZodSet\"] = \"ZodSet\";\n    ZodFirstPartyTypeKind[\"ZodFunction\"] = \"ZodFunction\";\n    ZodFirstPartyTypeKind[\"ZodLazy\"] = \"ZodLazy\";\n    ZodFirstPartyTypeKind[\"ZodLiteral\"] = \"ZodLiteral\";\n    ZodFirstPartyTypeKind[\"ZodEnum\"] = \"ZodEnum\";\n    ZodFirstPartyTypeKind[\"ZodEffects\"] = \"ZodEffects\";\n    ZodFirstPartyTypeKind[\"ZodNativeEnum\"] = \"ZodNativeEnum\";\n    ZodFirstPartyTypeKind[\"ZodOptional\"] = \"ZodOptional\";\n    ZodFirstPartyTypeKind[\"ZodNullable\"] = \"ZodNullable\";\n    ZodFirstPartyTypeKind[\"ZodDefault\"] = \"ZodDefault\";\n    ZodFirstPartyTypeKind[\"ZodCatch\"] = \"ZodCatch\";\n    ZodFirstPartyTypeKind[\"ZodPromise\"] = \"ZodPromise\";\n    ZodFirstPartyTypeKind[\"ZodBranded\"] = \"ZodBranded\";\n    ZodFirstPartyTypeKind[\"ZodPipeline\"] = \"ZodPipeline\";\n    ZodFirstPartyTypeKind[\"ZodReadonly\"] = \"ZodReadonly\";\n})(ZodFirstPartyTypeKind || (ZodFirstPartyTypeKind = {}));\n// requires TS 4.4+\nclass Class {\n    constructor(..._) { }\n}\nconst instanceOfType = (\n// const instanceOfType = <T extends new (...args: any[]) => any>(\ncls, params = {\n    message: `Input not instance of ${cls.name}`,\n}) => custom((data) => data instanceof cls, params);\nconst stringType = ZodString.create;\nconst numberType = ZodNumber.create;\nconst nanType = ZodNaN.create;\nconst bigIntType = ZodBigInt.create;\nconst booleanType = ZodBoolean.create;\nconst dateType = ZodDate.create;\nconst symbolType = ZodSymbol.create;\nconst undefinedType = ZodUndefined.create;\nconst nullType = ZodNull.create;\nconst anyType = ZodAny.create;\nconst unknownType = ZodUnknown.create;\nconst neverType = ZodNever.create;\nconst voidType = ZodVoid.create;\nconst arrayType = ZodArray.create;\nconst objectType = ZodObject.create;\nconst strictObjectType = ZodObject.strictCreate;\nconst unionType = ZodUnion.create;\nconst discriminatedUnionType = ZodDiscriminatedUnion.create;\nconst intersectionType = ZodIntersection.create;\nconst tupleType = ZodTuple.create;\nconst recordType = ZodRecord.create;\nconst mapType = ZodMap.create;\nconst setType = ZodSet.create;\nconst functionType = ZodFunction.create;\nconst lazyType = ZodLazy.create;\nconst literalType = ZodLiteral.create;\nconst enumType = ZodEnum.create;\nconst nativeEnumType = ZodNativeEnum.create;\nconst promiseType = ZodPromise.create;\nconst effectsType = ZodEffects.create;\nconst optionalType = ZodOptional.create;\nconst nullableType = ZodNullable.create;\nconst preprocessType = ZodEffects.createWithPreprocess;\nconst pipelineType = ZodPipeline.create;\nconst ostring = () => stringType().optional();\nconst onumber = () => numberType().optional();\nconst oboolean = () => booleanType().optional();\nexport const coerce = {\n    string: ((arg) => ZodString.create({ ...arg, coerce: true })),\n    number: ((arg) => ZodNumber.create({ ...arg, coerce: true })),\n    boolean: ((arg) => ZodBoolean.create({\n        ...arg,\n        coerce: true,\n    })),\n    bigint: ((arg) => ZodBigInt.create({ ...arg, coerce: true })),\n    date: ((arg) => ZodDate.create({ ...arg, coerce: true })),\n};\nexport { anyType as any, arrayType as array, bigIntType as bigint, booleanType as boolean, dateType as date, discriminatedUnionType as discriminatedUnion, effectsType as effect, enumType as enum, functionType as function, instanceOfType as instanceof, intersectionType as intersection, lazyType as lazy, literalType as literal, mapType as map, nanType as nan, nativeEnumType as nativeEnum, neverType as never, nullType as null, nullableType as nullable, numberType as number, objectType as object, oboolean, onumber, optionalType as optional, ostring, pipelineType as pipeline, preprocessType as preprocess, promiseType as promise, recordType as record, setType as set, strictObjectType as strictObject, stringType as string, symbolType as symbol, effectsType as transformer, tupleType as tuple, undefinedType as undefined, unionType as union, unknownType as unknown, voidType as void, };\nexport const NEVER = INVALID;\n","import { setResponseValueAndErrors } from \"../errorMessages.js\";\nimport { parseDef } from \"../parseDef.js\";\nimport { ZodFirstPartyTypeKind } from \"zod/v3\";\n\n//#region src/utils/zod-to-json-schema/parsers/array.ts\nfunction parseArrayDef(def, refs) {\n\tconst res = { type: \"array\" };\n\tif (def.type?._def && def.type?._def?.typeName !== ZodFirstPartyTypeKind.ZodAny) res.items = parseDef(def.type._def, {\n\t\t...refs,\n\t\tcurrentPath: [...refs.currentPath, \"items\"]\n\t});\n\tif (def.minLength) setResponseValueAndErrors(res, \"minItems\", def.minLength.value, def.minLength.message, refs);\n\tif (def.maxLength) setResponseValueAndErrors(res, \"maxItems\", def.maxLength.value, def.maxLength.message, refs);\n\tif (def.exactLength) {\n\t\tsetResponseValueAndErrors(res, \"minItems\", def.exactLength.value, def.exactLength.message, refs);\n\t\tsetResponseValueAndErrors(res, \"maxItems\", def.exactLength.value, def.exactLength.message, refs);\n\t}\n\treturn res;\n}\n\n//#endregion\nexport { parseArrayDef };\n//# sourceMappingURL=array.js.map","import { setResponseValueAndErrors } from \"../errorMessages.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/bigint.ts\nfunction parseBigintDef(def, refs) {\n\tconst res = {\n\t\ttype: \"integer\",\n\t\tformat: \"int64\"\n\t};\n\tif (!def.checks) return res;\n\tfor (const check of def.checks) switch (check.kind) {\n\t\tcase \"min\":\n\t\t\tif (refs.target === \"jsonSchema7\") if (check.inclusive) setResponseValueAndErrors(res, \"minimum\", check.value, check.message, refs);\n\t\t\telse setResponseValueAndErrors(res, \"exclusiveMinimum\", check.value, check.message, refs);\n\t\t\telse {\n\t\t\t\tif (!check.inclusive) res.exclusiveMinimum = true;\n\t\t\t\tsetResponseValueAndErrors(res, \"minimum\", check.value, check.message, refs);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase \"max\":\n\t\t\tif (refs.target === \"jsonSchema7\") if (check.inclusive) setResponseValueAndErrors(res, \"maximum\", check.value, check.message, refs);\n\t\t\telse setResponseValueAndErrors(res, \"exclusiveMaximum\", check.value, check.message, refs);\n\t\t\telse {\n\t\t\t\tif (!check.inclusive) res.exclusiveMaximum = true;\n\t\t\t\tsetResponseValueAndErrors(res, \"maximum\", check.value, check.message, refs);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase \"multipleOf\":\n\t\t\tsetResponseValueAndErrors(res, \"multipleOf\", check.value, check.message, refs);\n\t\t\tbreak;\n\t}\n\treturn res;\n}\n\n//#endregion\nexport { parseBigintDef };\n//# sourceMappingURL=bigint.js.map","//#region src/utils/zod-to-json-schema/parsers/boolean.ts\nfunction parseBooleanDef() {\n\treturn { type: \"boolean\" };\n}\n\n//#endregion\nexport { parseBooleanDef };\n//# sourceMappingURL=boolean.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/branded.ts\nfunction parseBrandedDef(_def, refs) {\n\treturn parseDef(_def.type._def, refs);\n}\n\n//#endregion\nexport { parseBrandedDef };\n//# sourceMappingURL=branded.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/catch.ts\nconst parseCatchDef = (def, refs) => {\n\treturn parseDef(def.innerType._def, refs);\n};\n\n//#endregion\nexport { parseCatchDef };\n//# sourceMappingURL=catch.js.map","import { setResponseValueAndErrors } from \"../errorMessages.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/date.ts\nfunction parseDateDef(def, refs, overrideDateStrategy) {\n\tconst strategy = overrideDateStrategy ?? refs.dateStrategy;\n\tif (Array.isArray(strategy)) return { anyOf: strategy.map((item) => parseDateDef(def, refs, item)) };\n\tswitch (strategy) {\n\t\tcase \"string\":\n\t\tcase \"format:date-time\": return {\n\t\t\ttype: \"string\",\n\t\t\tformat: \"date-time\"\n\t\t};\n\t\tcase \"format:date\": return {\n\t\t\ttype: \"string\",\n\t\t\tformat: \"date\"\n\t\t};\n\t\tcase \"integer\": return integerDateParser(def, refs);\n\t}\n}\nconst integerDateParser = (def, refs) => {\n\tconst res = {\n\t\ttype: \"integer\",\n\t\tformat: \"unix-time\"\n\t};\n\tif (refs.target === \"openApi3\") return res;\n\tfor (const check of def.checks) switch (check.kind) {\n\t\tcase \"min\":\n\t\t\tsetResponseValueAndErrors(res, \"minimum\", check.value, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"max\":\n\t\t\tsetResponseValueAndErrors(res, \"maximum\", check.value, check.message, refs);\n\t\t\tbreak;\n\t}\n\treturn res;\n};\n\n//#endregion\nexport { parseDateDef };\n//# sourceMappingURL=date.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/default.ts\nfunction parseDefaultDef(_def, refs) {\n\treturn {\n\t\t...parseDef(_def.innerType._def, refs),\n\t\tdefault: _def.defaultValue()\n\t};\n}\n\n//#endregion\nexport { parseDefaultDef };\n//# sourceMappingURL=default.js.map","import { parseAnyDef } from \"./any.js\";\nimport { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/effects.ts\nfunction parseEffectsDef(_def, refs) {\n\treturn refs.effectStrategy === \"input\" ? parseDef(_def.schema._def, refs) : parseAnyDef(refs);\n}\n\n//#endregion\nexport { parseEffectsDef };\n//# sourceMappingURL=effects.js.map","//#region src/utils/zod-to-json-schema/parsers/enum.ts\nfunction parseEnumDef(def) {\n\treturn {\n\t\ttype: \"string\",\n\t\tenum: Array.from(def.values)\n\t};\n}\n\n//#endregion\nexport { parseEnumDef };\n//# sourceMappingURL=enum.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/intersection.ts\nconst isJsonSchema7AllOfType = (type) => {\n\tif (\"type\" in type && type.type === \"string\") return false;\n\treturn \"allOf\" in type;\n};\nfunction parseIntersectionDef(def, refs) {\n\tconst allOf = [parseDef(def.left._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"allOf\",\n\t\t\t\"0\"\n\t\t]\n\t}), parseDef(def.right._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"allOf\",\n\t\t\t\"1\"\n\t\t]\n\t})].filter((x) => !!x);\n\tlet unevaluatedProperties = refs.target === \"jsonSchema2019-09\" ? { unevaluatedProperties: false } : void 0;\n\tconst mergedAllOf = [];\n\tallOf.forEach((schema) => {\n\t\tif (isJsonSchema7AllOfType(schema)) {\n\t\t\tmergedAllOf.push(...schema.allOf);\n\t\t\tif (schema.unevaluatedProperties === void 0) unevaluatedProperties = void 0;\n\t\t} else {\n\t\t\tlet nestedSchema = schema;\n\t\t\tif (\"additionalProperties\" in schema && schema.additionalProperties === false) {\n\t\t\t\tconst { additionalProperties,...rest } = schema;\n\t\t\t\tnestedSchema = rest;\n\t\t\t} else unevaluatedProperties = void 0;\n\t\t\tmergedAllOf.push(nestedSchema);\n\t\t}\n\t});\n\treturn mergedAllOf.length ? {\n\t\tallOf: mergedAllOf,\n\t\t...unevaluatedProperties\n\t} : void 0;\n}\n\n//#endregion\nexport { parseIntersectionDef };\n//# sourceMappingURL=intersection.js.map","//#region src/utils/zod-to-json-schema/parsers/literal.ts\nfunction parseLiteralDef(def, refs) {\n\tconst parsedType = typeof def.value;\n\tif (parsedType !== \"bigint\" && parsedType !== \"number\" && parsedType !== \"boolean\" && parsedType !== \"string\") return { type: Array.isArray(def.value) ? \"array\" : \"object\" };\n\tif (refs.target === \"openApi3\") return {\n\t\ttype: parsedType === \"bigint\" ? \"integer\" : parsedType,\n\t\tenum: [def.value]\n\t};\n\treturn {\n\t\ttype: parsedType === \"bigint\" ? \"integer\" : parsedType,\n\t\tconst: def.value\n\t};\n}\n\n//#endregion\nexport { parseLiteralDef };\n//# sourceMappingURL=literal.js.map","import { setResponseValueAndErrors } from \"../errorMessages.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/string.ts\nlet emojiRegex = void 0;\n/**\n* Generated from the regular expressions found here as of 2024-05-22:\n* https://github.com/colinhacks/zod/blob/master/src/types.ts.\n*\n* Expressions with /i flag have been changed accordingly.\n*/\nconst zodPatterns = {\n\tcuid: /^[cC][^\\s-]{8,}$/,\n\tcuid2: /^[0-9a-z]+$/,\n\tulid: /^[0-9A-HJKMNP-TV-Z]{26}$/,\n\temail: /^(?!\\.)(?!.*\\.\\.)([a-zA-Z0-9_'+\\-\\.]*)[a-zA-Z0-9_+-]@([a-zA-Z0-9][a-zA-Z0-9\\-]*\\.)+[a-zA-Z]{2,}$/,\n\temoji: () => {\n\t\tif (emojiRegex === void 0) emojiRegex = RegExp(\"^(\\\\p{Extended_Pictographic}|\\\\p{Emoji_Component})+$\", \"u\");\n\t\treturn emojiRegex;\n\t},\n\tuuid: /^[0-9a-fA-F]{8}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{12}$/,\n\tipv4: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$/,\n\tipv4Cidr: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\/(3[0-2]|[12]?[0-9])$/,\n\tipv6: /^(([a-f0-9]{1,4}:){7}|::([a-f0-9]{1,4}:){0,6}|([a-f0-9]{1,4}:){1}:([a-f0-9]{1,4}:){0,5}|([a-f0-9]{1,4}:){2}:([a-f0-9]{1,4}:){0,4}|([a-f0-9]{1,4}:){3}:([a-f0-9]{1,4}:){0,3}|([a-f0-9]{1,4}:){4}:([a-f0-9]{1,4}:){0,2}|([a-f0-9]{1,4}:){5}:([a-f0-9]{1,4}:){0,1})([a-f0-9]{1,4}|(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2})))$/,\n\tipv6Cidr: /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\\/(12[0-8]|1[01][0-9]|[1-9]?[0-9])$/,\n\tbase64: /^([0-9a-zA-Z+/]{4})*(([0-9a-zA-Z+/]{2}==)|([0-9a-zA-Z+/]{3}=))?$/,\n\tbase64url: /^([0-9a-zA-Z-_]{4})*(([0-9a-zA-Z-_]{2}(==)?)|([0-9a-zA-Z-_]{3}(=)?))?$/,\n\tnanoid: /^[a-zA-Z0-9_-]{21}$/,\n\tjwt: /^[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]*$/\n};\nfunction parseStringDef(def, refs) {\n\tconst res = { type: \"string\" };\n\tif (def.checks) for (const check of def.checks) switch (check.kind) {\n\t\tcase \"min\":\n\t\t\tsetResponseValueAndErrors(res, \"minLength\", typeof res.minLength === \"number\" ? Math.max(res.minLength, check.value) : check.value, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"max\":\n\t\t\tsetResponseValueAndErrors(res, \"maxLength\", typeof res.maxLength === \"number\" ? Math.min(res.maxLength, check.value) : check.value, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"email\":\n\t\t\tswitch (refs.emailStrategy) {\n\t\t\t\tcase \"format:email\":\n\t\t\t\t\taddFormat(res, \"email\", check.message, refs);\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"format:idn-email\":\n\t\t\t\t\taddFormat(res, \"idn-email\", check.message, refs);\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"pattern:zod\":\n\t\t\t\t\taddPattern(res, zodPatterns.email, check.message, refs);\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase \"url\":\n\t\t\taddFormat(res, \"uri\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"uuid\":\n\t\t\taddFormat(res, \"uuid\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"regex\":\n\t\t\taddPattern(res, check.regex, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"cuid\":\n\t\t\taddPattern(res, zodPatterns.cuid, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"cuid2\":\n\t\t\taddPattern(res, zodPatterns.cuid2, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"startsWith\":\n\t\t\taddPattern(res, RegExp(`^${escapeLiteralCheckValue(check.value, refs)}`), check.message, refs);\n\t\t\tbreak;\n\t\tcase \"endsWith\":\n\t\t\taddPattern(res, RegExp(`${escapeLiteralCheckValue(check.value, refs)}$`), check.message, refs);\n\t\t\tbreak;\n\t\tcase \"datetime\":\n\t\t\taddFormat(res, \"date-time\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"date\":\n\t\t\taddFormat(res, \"date\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"time\":\n\t\t\taddFormat(res, \"time\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"duration\":\n\t\t\taddFormat(res, \"duration\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"length\":\n\t\t\tsetResponseValueAndErrors(res, \"minLength\", typeof res.minLength === \"number\" ? Math.max(res.minLength, check.value) : check.value, check.message, refs);\n\t\t\tsetResponseValueAndErrors(res, \"maxLength\", typeof res.maxLength === \"number\" ? Math.min(res.maxLength, check.value) : check.value, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"includes\":\n\t\t\taddPattern(res, RegExp(escapeLiteralCheckValue(check.value, refs)), check.message, refs);\n\t\t\tbreak;\n\t\tcase \"ip\":\n\t\t\tif (check.version !== \"v6\") addFormat(res, \"ipv4\", check.message, refs);\n\t\t\tif (check.version !== \"v4\") addFormat(res, \"ipv6\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"base64url\":\n\t\t\taddPattern(res, zodPatterns.base64url, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"jwt\":\n\t\t\taddPattern(res, zodPatterns.jwt, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"cidr\":\n\t\t\tif (check.version !== \"v6\") addPattern(res, zodPatterns.ipv4Cidr, check.message, refs);\n\t\t\tif (check.version !== \"v4\") addPattern(res, zodPatterns.ipv6Cidr, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"emoji\":\n\t\t\taddPattern(res, zodPatterns.emoji(), check.message, refs);\n\t\t\tbreak;\n\t\tcase \"ulid\":\n\t\t\taddPattern(res, zodPatterns.ulid, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"base64\":\n\t\t\tswitch (refs.base64Strategy) {\n\t\t\t\tcase \"format:binary\":\n\t\t\t\t\taddFormat(res, \"binary\", check.message, refs);\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"contentEncoding:base64\":\n\t\t\t\t\tsetResponseValueAndErrors(res, \"contentEncoding\", \"base64\", check.message, refs);\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"pattern:zod\":\n\t\t\t\t\taddPattern(res, zodPatterns.base64, check.message, refs);\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase \"nanoid\":\n\t\t\taddPattern(res, zodPatterns.nanoid, check.message, refs);\n\t\t\tbreak;\n\t\tcase \"toLowerCase\":\n\t\tcase \"toUpperCase\":\n\t\tcase \"trim\": break;\n\t\tdefault:\n /* c8 ignore next */\n\t\t((_) => {})(check);\n\t}\n\treturn res;\n}\nfunction escapeLiteralCheckValue(literal, refs) {\n\treturn refs.patternStrategy === \"escape\" ? escapeNonAlphaNumeric(literal) : literal;\n}\nconst ALPHA_NUMERIC = /* @__PURE__ */ new Set(\"ABCDEFGHIJKLMNOPQRSTUVXYZabcdefghijklmnopqrstuvxyz0123456789\");\nfunction escapeNonAlphaNumeric(source) {\n\tlet result = \"\";\n\tfor (let i = 0; i < source.length; i++) {\n\t\tif (!ALPHA_NUMERIC.has(source[i])) result += \"\\\\\";\n\t\tresult += source[i];\n\t}\n\treturn result;\n}\nfunction addFormat(schema, value, message, refs) {\n\tif (schema.format || schema.anyOf?.some((x) => x.format)) {\n\t\tif (!schema.anyOf) schema.anyOf = [];\n\t\tif (schema.format) {\n\t\t\tschema.anyOf.push({\n\t\t\t\tformat: schema.format,\n\t\t\t\t...schema.errorMessage && refs.errorMessages && { errorMessage: { format: schema.errorMessage.format } }\n\t\t\t});\n\t\t\tdelete schema.format;\n\t\t\tif (schema.errorMessage) {\n\t\t\t\tdelete schema.errorMessage.format;\n\t\t\t\tif (Object.keys(schema.errorMessage).length === 0) delete schema.errorMessage;\n\t\t\t}\n\t\t}\n\t\tschema.anyOf.push({\n\t\t\tformat: value,\n\t\t\t...message && refs.errorMessages && { errorMessage: { format: message } }\n\t\t});\n\t} else setResponseValueAndErrors(schema, \"format\", value, message, refs);\n}\nfunction addPattern(schema, regex, message, refs) {\n\tif (schema.pattern || schema.allOf?.some((x) => x.pattern)) {\n\t\tif (!schema.allOf) schema.allOf = [];\n\t\tif (schema.pattern) {\n\t\t\tschema.allOf.push({\n\t\t\t\tpattern: schema.pattern,\n\t\t\t\t...schema.errorMessage && refs.errorMessages && { errorMessage: { pattern: schema.errorMessage.pattern } }\n\t\t\t});\n\t\t\tdelete schema.pattern;\n\t\t\tif (schema.errorMessage) {\n\t\t\t\tdelete schema.errorMessage.pattern;\n\t\t\t\tif (Object.keys(schema.errorMessage).length === 0) delete schema.errorMessage;\n\t\t\t}\n\t\t}\n\t\tschema.allOf.push({\n\t\t\tpattern: stringifyRegExpWithFlags(regex, refs),\n\t\t\t...message && refs.errorMessages && { errorMessage: { pattern: message } }\n\t\t});\n\t} else setResponseValueAndErrors(schema, \"pattern\", stringifyRegExpWithFlags(regex, refs), message, refs);\n}\nfunction stringifyRegExpWithFlags(regex, refs) {\n\tif (!refs.applyRegexFlags || !regex.flags) return regex.source;\n\tconst flags = {\n\t\ti: regex.flags.includes(\"i\"),\n\t\tm: regex.flags.includes(\"m\"),\n\t\ts: regex.flags.includes(\"s\")\n\t};\n\tconst source = flags.i ? regex.source.toLowerCase() : regex.source;\n\tlet pattern = \"\";\n\tlet isEscaped = false;\n\tlet inCharGroup = false;\n\tlet inCharRange = false;\n\tfor (let i = 0; i < source.length; i++) {\n\t\tif (isEscaped) {\n\t\t\tpattern += source[i];\n\t\t\tisEscaped = false;\n\t\t\tcontinue;\n\t\t}\n\t\tif (flags.i) {\n\t\t\tif (inCharGroup) {\n\t\t\t\tif (source[i].match(/[a-z]/)) {\n\t\t\t\t\tif (inCharRange) {\n\t\t\t\t\t\tpattern += source[i];\n\t\t\t\t\t\tpattern += `${source[i - 2]}-${source[i]}`.toUpperCase();\n\t\t\t\t\t\tinCharRange = false;\n\t\t\t\t\t} else if (source[i + 1] === \"-\" && source[i + 2]?.match(/[a-z]/)) {\n\t\t\t\t\t\tpattern += source[i];\n\t\t\t\t\t\tinCharRange = true;\n\t\t\t\t\t} else pattern += `${source[i]}${source[i].toUpperCase()}`;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t} else if (source[i].match(/[a-z]/)) {\n\t\t\t\tpattern += `[${source[i]}${source[i].toUpperCase()}]`;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (flags.m) {\n\t\t\tif (source[i] === \"^\") {\n\t\t\t\tpattern += `(^|(?<=[\\r\\n]))`;\n\t\t\t\tcontinue;\n\t\t\t} else if (source[i] === \"$\") {\n\t\t\t\tpattern += `($|(?=[\\r\\n]))`;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (flags.s && source[i] === \".\") {\n\t\t\tpattern += inCharGroup ? `${source[i]}\\r\\n` : `[${source[i]}\\r\\n]`;\n\t\t\tcontinue;\n\t\t}\n\t\tpattern += source[i];\n\t\tif (source[i] === \"\\\\\") isEscaped = true;\n\t\telse if (inCharGroup && source[i] === \"]\") inCharGroup = false;\n\t\telse if (!inCharGroup && source[i] === \"[\") inCharGroup = true;\n\t}\n\ttry {\n\t\tnew RegExp(pattern);\n\t} catch {\n\t\tconsole.warn(`Could not convert regex pattern at ${refs.currentPath.join(\"/\")} to a flag-independent form! Falling back to the flag-ignorant source`);\n\t\treturn regex.source;\n\t}\n\treturn pattern;\n}\n\n//#endregion\nexport { parseStringDef, zodPatterns };\n//# sourceMappingURL=string.js.map","import { parseAnyDef } from \"./any.js\";\nimport { parseBrandedDef } from \"./branded.js\";\nimport { parseStringDef } from \"./string.js\";\nimport { parseDef } from \"../parseDef.js\";\nimport { ZodFirstPartyTypeKind } from \"zod/v3\";\n\n//#region src/utils/zod-to-json-schema/parsers/record.ts\nfunction parseRecordDef(def, refs) {\n\tif (refs.target === \"openAi\") console.warn(\"Warning: OpenAI may not support records in schemas! Try an array of key-value pairs instead.\");\n\tif (refs.target === \"openApi3\" && def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodEnum) return {\n\t\ttype: \"object\",\n\t\trequired: def.keyType._def.values,\n\t\tproperties: def.keyType._def.values.reduce((acc, key) => ({\n\t\t\t...acc,\n\t\t\t[key]: parseDef(def.valueType._def, {\n\t\t\t\t...refs,\n\t\t\t\tcurrentPath: [\n\t\t\t\t\t...refs.currentPath,\n\t\t\t\t\t\"properties\",\n\t\t\t\t\tkey\n\t\t\t\t]\n\t\t\t}) ?? parseAnyDef(refs)\n\t\t}), {}),\n\t\tadditionalProperties: refs.rejectedAdditionalProperties\n\t};\n\tconst schema = {\n\t\ttype: \"object\",\n\t\tadditionalProperties: parseDef(def.valueType._def, {\n\t\t\t...refs,\n\t\t\tcurrentPath: [...refs.currentPath, \"additionalProperties\"]\n\t\t}) ?? refs.allowedAdditionalProperties\n\t};\n\tif (refs.target === \"openApi3\") return schema;\n\tif (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodString && def.keyType._def.checks?.length) {\n\t\tconst { type,...keyType } = parseStringDef(def.keyType._def, refs);\n\t\treturn {\n\t\t\t...schema,\n\t\t\tpropertyNames: keyType\n\t\t};\n\t} else if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodEnum) return {\n\t\t...schema,\n\t\tpropertyNames: { enum: def.keyType._def.values }\n\t};\n\telse if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodBranded && def.keyType._def.type._def.typeName === ZodFirstPartyTypeKind.ZodString && def.keyType._def.type._def.checks?.length) {\n\t\tconst { type,...keyType } = parseBrandedDef(def.keyType._def, refs);\n\t\treturn {\n\t\t\t...schema,\n\t\t\tpropertyNames: keyType\n\t\t};\n\t}\n\treturn schema;\n}\n\n//#endregion\nexport { parseRecordDef };\n//# sourceMappingURL=record.js.map","import { parseAnyDef } from \"./any.js\";\nimport { parseRecordDef } from \"./record.js\";\nimport { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/map.ts\nfunction parseMapDef(def, refs) {\n\tif (refs.mapStrategy === \"record\") return parseRecordDef(def, refs);\n\tconst keys = parseDef(def.keyType._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"items\",\n\t\t\t\"items\",\n\t\t\t\"0\"\n\t\t]\n\t}) || parseAnyDef(refs);\n\tconst values = parseDef(def.valueType._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"items\",\n\t\t\t\"items\",\n\t\t\t\"1\"\n\t\t]\n\t}) || parseAnyDef(refs);\n\treturn {\n\t\ttype: \"array\",\n\t\tmaxItems: 125,\n\t\titems: {\n\t\t\ttype: \"array\",\n\t\t\titems: [keys, values],\n\t\t\tminItems: 2,\n\t\t\tmaxItems: 2\n\t\t}\n\t};\n}\n\n//#endregion\nexport { parseMapDef };\n//# sourceMappingURL=map.js.map","//#region src/utils/zod-to-json-schema/parsers/nativeEnum.ts\nfunction parseNativeEnumDef(def) {\n\tconst object = def.values;\n\tconst actualKeys = Object.keys(def.values).filter((key) => {\n\t\treturn typeof object[object[key]] !== \"number\";\n\t});\n\tconst actualValues = actualKeys.map((key) => object[key]);\n\tconst parsedTypes = Array.from(new Set(actualValues.map((values) => typeof values)));\n\treturn {\n\t\ttype: parsedTypes.length === 1 ? parsedTypes[0] === \"string\" ? \"string\" : \"number\" : [\"string\", \"number\"],\n\t\tenum: actualValues\n\t};\n}\n\n//#endregion\nexport { parseNativeEnumDef };\n//# sourceMappingURL=nativeEnum.js.map","import { parseAnyDef } from \"./any.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/never.ts\nfunction parseNeverDef(refs) {\n\treturn refs.target === \"openAi\" ? void 0 : { not: parseAnyDef({\n\t\t...refs,\n\t\tcurrentPath: [...refs.currentPath, \"not\"]\n\t}) };\n}\n\n//#endregion\nexport { parseNeverDef };\n//# sourceMappingURL=never.js.map","//#region src/utils/zod-to-json-schema/parsers/null.ts\nfunction parseNullDef(refs) {\n\treturn refs.target === \"openApi3\" ? {\n\t\tenum: [\"null\"],\n\t\tnullable: true\n\t} : { type: \"null\" };\n}\n\n//#endregion\nexport { parseNullDef };\n//# sourceMappingURL=null.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/union.ts\nconst primitiveMappings = {\n\tZodString: \"string\",\n\tZodNumber: \"number\",\n\tZodBigInt: \"integer\",\n\tZodBoolean: \"boolean\",\n\tZodNull: \"null\"\n};\nfunction parseUnionDef(def, refs) {\n\tif (refs.target === \"openApi3\") return asAnyOf(def, refs);\n\tconst options = def.options instanceof Map ? Array.from(def.options.values()) : def.options;\n\tif (options.every((x) => x._def.typeName in primitiveMappings && (!x._def.checks || !x._def.checks.length))) {\n\t\tconst types = options.reduce((types$1, x) => {\n\t\t\tconst type = primitiveMappings[x._def.typeName];\n\t\t\treturn type && !types$1.includes(type) ? [...types$1, type] : types$1;\n\t\t}, []);\n\t\treturn { type: types.length > 1 ? types : types[0] };\n\t} else if (options.every((x) => x._def.typeName === \"ZodLiteral\" && !x.description)) {\n\t\tconst types = options.reduce((acc, x) => {\n\t\t\tconst type = typeof x._def.value;\n\t\t\tswitch (type) {\n\t\t\t\tcase \"string\":\n\t\t\t\tcase \"number\":\n\t\t\t\tcase \"boolean\": return [...acc, type];\n\t\t\t\tcase \"bigint\": return [...acc, \"integer\"];\n\t\t\t\tcase \"object\":\n\t\t\t\t\tif (x._def.value === null) return [...acc, \"null\"];\n\t\t\t\t\treturn acc;\n\t\t\t\tcase \"symbol\":\n\t\t\t\tcase \"undefined\":\n\t\t\t\tcase \"function\":\n\t\t\t\tdefault: return acc;\n\t\t\t}\n\t\t}, []);\n\t\tif (types.length === options.length) {\n\t\t\tconst uniqueTypes = types.filter((x, i, a) => a.indexOf(x) === i);\n\t\t\treturn {\n\t\t\t\ttype: uniqueTypes.length > 1 ? uniqueTypes : uniqueTypes[0],\n\t\t\t\tenum: options.reduce((acc, x) => {\n\t\t\t\t\treturn acc.includes(x._def.value) ? acc : [...acc, x._def.value];\n\t\t\t\t}, [])\n\t\t\t};\n\t\t}\n\t} else if (options.every((x) => x._def.typeName === \"ZodEnum\")) return {\n\t\ttype: \"string\",\n\t\tenum: options.reduce((acc, x) => [...acc, ...x._def.values.filter((x$1) => !acc.includes(x$1))], [])\n\t};\n\treturn asAnyOf(def, refs);\n}\nconst asAnyOf = (def, refs) => {\n\tconst anyOf = (def.options instanceof Map ? Array.from(def.options.values()) : def.options).map((x, i) => parseDef(x._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"anyOf\",\n\t\t\t`${i}`\n\t\t]\n\t})).filter((x) => !!x && (!refs.strictUnions || typeof x === \"object\" && Object.keys(x).length > 0));\n\treturn anyOf.length ? { anyOf } : void 0;\n};\n\n//#endregion\nexport { parseUnionDef, primitiveMappings };\n//# sourceMappingURL=union.js.map","import { primitiveMappings } from \"./union.js\";\nimport { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/nullable.ts\nfunction parseNullableDef(def, refs) {\n\tif ([\n\t\t\"ZodString\",\n\t\t\"ZodNumber\",\n\t\t\"ZodBigInt\",\n\t\t\"ZodBoolean\",\n\t\t\"ZodNull\"\n\t].includes(def.innerType._def.typeName) && (!def.innerType._def.checks || !def.innerType._def.checks.length)) {\n\t\tif (refs.target === \"openApi3\") return {\n\t\t\ttype: primitiveMappings[def.innerType._def.typeName],\n\t\t\tnullable: true\n\t\t};\n\t\treturn { type: [primitiveMappings[def.innerType._def.typeName], \"null\"] };\n\t}\n\tif (refs.target === \"openApi3\") {\n\t\tconst base$1 = parseDef(def.innerType._def, {\n\t\t\t...refs,\n\t\t\tcurrentPath: [...refs.currentPath]\n\t\t});\n\t\tif (base$1 && \"$ref\" in base$1) return {\n\t\t\tallOf: [base$1],\n\t\t\tnullable: true\n\t\t};\n\t\treturn base$1 && {\n\t\t\t...base$1,\n\t\t\tnullable: true\n\t\t};\n\t}\n\tconst base = parseDef(def.innerType._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"anyOf\",\n\t\t\t\"0\"\n\t\t]\n\t});\n\treturn base && { anyOf: [base, { type: \"null\" }] };\n}\n\n//#endregion\nexport { parseNullableDef };\n//# sourceMappingURL=nullable.js.map","import { addErrorMessage, setResponseValueAndErrors } from \"../errorMessages.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/number.ts\nfunction parseNumberDef(def, refs) {\n\tconst res = { type: \"number\" };\n\tif (!def.checks) return res;\n\tfor (const check of def.checks) switch (check.kind) {\n\t\tcase \"int\":\n\t\t\tres.type = \"integer\";\n\t\t\taddErrorMessage(res, \"type\", check.message, refs);\n\t\t\tbreak;\n\t\tcase \"min\":\n\t\t\tif (refs.target === \"jsonSchema7\") if (check.inclusive) setResponseValueAndErrors(res, \"minimum\", check.value, check.message, refs);\n\t\t\telse setResponseValueAndErrors(res, \"exclusiveMinimum\", check.value, check.message, refs);\n\t\t\telse {\n\t\t\t\tif (!check.inclusive) res.exclusiveMinimum = true;\n\t\t\t\tsetResponseValueAndErrors(res, \"minimum\", check.value, check.message, refs);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase \"max\":\n\t\t\tif (refs.target === \"jsonSchema7\") if (check.inclusive) setResponseValueAndErrors(res, \"maximum\", check.value, check.message, refs);\n\t\t\telse setResponseValueAndErrors(res, \"exclusiveMaximum\", check.value, check.message, refs);\n\t\t\telse {\n\t\t\t\tif (!check.inclusive) res.exclusiveMaximum = true;\n\t\t\t\tsetResponseValueAndErrors(res, \"maximum\", check.value, check.message, refs);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase \"multipleOf\":\n\t\t\tsetResponseValueAndErrors(res, \"multipleOf\", check.value, check.message, refs);\n\t\t\tbreak;\n\t}\n\treturn res;\n}\n\n//#endregion\nexport { parseNumberDef };\n//# sourceMappingURL=number.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/object.ts\nfunction parseObjectDef(def, refs) {\n\tconst forceOptionalIntoNullable = refs.target === \"openAi\";\n\tconst result = {\n\t\ttype: \"object\",\n\t\tproperties: {}\n\t};\n\tconst required = [];\n\tconst shape = def.shape();\n\tfor (const propName in shape) {\n\t\tlet propDef = shape[propName];\n\t\tif (propDef === void 0 || propDef._def === void 0) continue;\n\t\tlet propOptional = safeIsOptional(propDef);\n\t\tif (propOptional && forceOptionalIntoNullable) {\n\t\t\tif (propDef._def.typeName === \"ZodOptional\") propDef = propDef._def.innerType;\n\t\t\tif (!propDef.isNullable()) propDef = propDef.nullable();\n\t\t\tpropOptional = false;\n\t\t}\n\t\tconst parsedDef = parseDef(propDef._def, {\n\t\t\t...refs,\n\t\t\tcurrentPath: [\n\t\t\t\t...refs.currentPath,\n\t\t\t\t\"properties\",\n\t\t\t\tpropName\n\t\t\t],\n\t\t\tpropertyPath: [\n\t\t\t\t...refs.currentPath,\n\t\t\t\t\"properties\",\n\t\t\t\tpropName\n\t\t\t]\n\t\t});\n\t\tif (parsedDef === void 0) continue;\n\t\tresult.properties[propName] = parsedDef;\n\t\tif (!propOptional) required.push(propName);\n\t}\n\tif (required.length) result.required = required;\n\tconst additionalProperties = decideAdditionalProperties(def, refs);\n\tif (additionalProperties !== void 0) result.additionalProperties = additionalProperties;\n\treturn result;\n}\nfunction decideAdditionalProperties(def, refs) {\n\tif (def.catchall._def.typeName !== \"ZodNever\") return parseDef(def.catchall._def, {\n\t\t...refs,\n\t\tcurrentPath: [...refs.currentPath, \"additionalProperties\"]\n\t});\n\tswitch (def.unknownKeys) {\n\t\tcase \"passthrough\": return refs.allowedAdditionalProperties;\n\t\tcase \"strict\": return refs.rejectedAdditionalProperties;\n\t\tcase \"strip\": return refs.removeAdditionalStrategy === \"strict\" ? refs.allowedAdditionalProperties : refs.rejectedAdditionalProperties;\n\t}\n}\nfunction safeIsOptional(schema) {\n\ttry {\n\t\treturn schema.isOptional();\n\t} catch {\n\t\treturn true;\n\t}\n}\n\n//#endregion\nexport { parseObjectDef };\n//# sourceMappingURL=object.js.map","import { parseAnyDef } from \"./any.js\";\nimport { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/optional.ts\nconst parseOptionalDef = (def, refs) => {\n\tif (refs.currentPath.toString() === refs.propertyPath?.toString()) return parseDef(def.innerType._def, refs);\n\tconst innerSchema = parseDef(def.innerType._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"anyOf\",\n\t\t\t\"1\"\n\t\t]\n\t});\n\treturn innerSchema ? { anyOf: [{ not: parseAnyDef(refs) }, innerSchema] } : parseAnyDef(refs);\n};\n\n//#endregion\nexport { parseOptionalDef };\n//# sourceMappingURL=optional.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/pipeline.ts\nconst parsePipelineDef = (def, refs) => {\n\tif (refs.pipeStrategy === \"input\") return parseDef(def.in._def, refs);\n\telse if (refs.pipeStrategy === \"output\") return parseDef(def.out._def, refs);\n\tconst a = parseDef(def.in._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"allOf\",\n\t\t\t\"0\"\n\t\t]\n\t});\n\tconst b = parseDef(def.out._def, {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.currentPath,\n\t\t\t\"allOf\",\n\t\t\ta ? \"1\" : \"0\"\n\t\t]\n\t});\n\treturn { allOf: [a, b].filter((x) => x !== void 0) };\n};\n\n//#endregion\nexport { parsePipelineDef };\n//# sourceMappingURL=pipeline.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/promise.ts\nfunction parsePromiseDef(def, refs) {\n\treturn parseDef(def.type._def, refs);\n}\n\n//#endregion\nexport { parsePromiseDef };\n//# sourceMappingURL=promise.js.map","import { setResponseValueAndErrors } from \"../errorMessages.js\";\nimport { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/set.ts\nfunction parseSetDef(def, refs) {\n\tconst items = parseDef(def.valueType._def, {\n\t\t...refs,\n\t\tcurrentPath: [...refs.currentPath, \"items\"]\n\t});\n\tconst schema = {\n\t\ttype: \"array\",\n\t\tuniqueItems: true,\n\t\titems\n\t};\n\tif (def.minSize) setResponseValueAndErrors(schema, \"minItems\", def.minSize.value, def.minSize.message, refs);\n\tif (def.maxSize) setResponseValueAndErrors(schema, \"maxItems\", def.maxSize.value, def.maxSize.message, refs);\n\treturn schema;\n}\n\n//#endregion\nexport { parseSetDef };\n//# sourceMappingURL=set.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/tuple.ts\nfunction parseTupleDef(def, refs) {\n\tif (def.rest) return {\n\t\ttype: \"array\",\n\t\tminItems: def.items.length,\n\t\titems: def.items.map((x, i) => parseDef(x._def, {\n\t\t\t...refs,\n\t\t\tcurrentPath: [\n\t\t\t\t...refs.currentPath,\n\t\t\t\t\"items\",\n\t\t\t\t`${i}`\n\t\t\t]\n\t\t})).reduce((acc, x) => x === void 0 ? acc : [...acc, x], []),\n\t\tadditionalItems: parseDef(def.rest._def, {\n\t\t\t...refs,\n\t\t\tcurrentPath: [...refs.currentPath, \"additionalItems\"]\n\t\t})\n\t};\n\telse return {\n\t\ttype: \"array\",\n\t\tminItems: def.items.length,\n\t\tmaxItems: def.items.length,\n\t\titems: def.items.map((x, i) => parseDef(x._def, {\n\t\t\t...refs,\n\t\t\tcurrentPath: [\n\t\t\t\t...refs.currentPath,\n\t\t\t\t\"items\",\n\t\t\t\t`${i}`\n\t\t\t]\n\t\t})).reduce((acc, x) => x === void 0 ? acc : [...acc, x], [])\n\t};\n}\n\n//#endregion\nexport { parseTupleDef };\n//# sourceMappingURL=tuple.js.map","import { parseAnyDef } from \"./any.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/undefined.ts\nfunction parseUndefinedDef(refs) {\n\treturn { not: parseAnyDef(refs) };\n}\n\n//#endregion\nexport { parseUndefinedDef };\n//# sourceMappingURL=undefined.js.map","import { parseAnyDef } from \"./any.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/unknown.ts\nfunction parseUnknownDef(refs) {\n\treturn parseAnyDef(refs);\n}\n\n//#endregion\nexport { parseUnknownDef };\n//# sourceMappingURL=unknown.js.map","import { parseDef } from \"../parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/parsers/readonly.ts\nconst parseReadonlyDef = (def, refs) => {\n\treturn parseDef(def.innerType._def, refs);\n};\n\n//#endregion\nexport { parseReadonlyDef };\n//# sourceMappingURL=readonly.js.map","import { parseAnyDef } from \"./parsers/any.js\";\nimport { parseArrayDef } from \"./parsers/array.js\";\nimport { parseBigintDef } from \"./parsers/bigint.js\";\nimport { parseBooleanDef } from \"./parsers/boolean.js\";\nimport { parseBrandedDef } from \"./parsers/branded.js\";\nimport { parseCatchDef } from \"./parsers/catch.js\";\nimport { parseDateDef } from \"./parsers/date.js\";\nimport { parseDefaultDef } from \"./parsers/default.js\";\nimport { parseEffectsDef } from \"./parsers/effects.js\";\nimport { parseEnumDef } from \"./parsers/enum.js\";\nimport { parseIntersectionDef } from \"./parsers/intersection.js\";\nimport { parseLiteralDef } from \"./parsers/literal.js\";\nimport { parseStringDef } from \"./parsers/string.js\";\nimport { parseRecordDef } from \"./parsers/record.js\";\nimport { parseMapDef } from \"./parsers/map.js\";\nimport { parseNativeEnumDef } from \"./parsers/nativeEnum.js\";\nimport { parseNeverDef } from \"./parsers/never.js\";\nimport { parseNullDef } from \"./parsers/null.js\";\nimport { parseUnionDef } from \"./parsers/union.js\";\nimport { parseNullableDef } from \"./parsers/nullable.js\";\nimport { parseNumberDef } from \"./parsers/number.js\";\nimport { parseObjectDef } from \"./parsers/object.js\";\nimport { parseOptionalDef } from \"./parsers/optional.js\";\nimport { parsePipelineDef } from \"./parsers/pipeline.js\";\nimport { parsePromiseDef } from \"./parsers/promise.js\";\nimport { parseSetDef } from \"./parsers/set.js\";\nimport { parseTupleDef } from \"./parsers/tuple.js\";\nimport { parseUndefinedDef } from \"./parsers/undefined.js\";\nimport { parseUnknownDef } from \"./parsers/unknown.js\";\nimport { parseReadonlyDef } from \"./parsers/readonly.js\";\nimport { ZodFirstPartyTypeKind } from \"zod/v3\";\n\n//#region src/utils/zod-to-json-schema/selectParser.ts\nconst selectParser = (def, typeName, refs) => {\n\tswitch (typeName) {\n\t\tcase ZodFirstPartyTypeKind.ZodString: return parseStringDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodNumber: return parseNumberDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodObject: return parseObjectDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodBigInt: return parseBigintDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodBoolean: return parseBooleanDef();\n\t\tcase ZodFirstPartyTypeKind.ZodDate: return parseDateDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodUndefined: return parseUndefinedDef(refs);\n\t\tcase ZodFirstPartyTypeKind.ZodNull: return parseNullDef(refs);\n\t\tcase ZodFirstPartyTypeKind.ZodArray: return parseArrayDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodUnion:\n\t\tcase ZodFirstPartyTypeKind.ZodDiscriminatedUnion: return parseUnionDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodIntersection: return parseIntersectionDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodTuple: return parseTupleDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodRecord: return parseRecordDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodLiteral: return parseLiteralDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodEnum: return parseEnumDef(def);\n\t\tcase ZodFirstPartyTypeKind.ZodNativeEnum: return parseNativeEnumDef(def);\n\t\tcase ZodFirstPartyTypeKind.ZodNullable: return parseNullableDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodOptional: return parseOptionalDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodMap: return parseMapDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodSet: return parseSetDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodLazy: return () => def.getter()._def;\n\t\tcase ZodFirstPartyTypeKind.ZodPromise: return parsePromiseDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodNaN:\n\t\tcase ZodFirstPartyTypeKind.ZodNever: return parseNeverDef(refs);\n\t\tcase ZodFirstPartyTypeKind.ZodEffects: return parseEffectsDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodAny: return parseAnyDef(refs);\n\t\tcase ZodFirstPartyTypeKind.ZodUnknown: return parseUnknownDef(refs);\n\t\tcase ZodFirstPartyTypeKind.ZodDefault: return parseDefaultDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodBranded: return parseBrandedDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodReadonly: return parseReadonlyDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodCatch: return parseCatchDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodPipeline: return parsePipelineDef(def, refs);\n\t\tcase ZodFirstPartyTypeKind.ZodFunction:\n\t\tcase ZodFirstPartyTypeKind.ZodVoid:\n\t\tcase ZodFirstPartyTypeKind.ZodSymbol: return void 0;\n\t\tdefault:\n /* c8 ignore next */\n\t\treturn ((_) => void 0)(typeName);\n\t}\n};\n\n//#endregion\nexport { selectParser };\n//# sourceMappingURL=selectParser.js.map","import { ignoreOverride } from \"./Options.js\";\nimport { getRelativePath } from \"./getRelativePath.js\";\nimport { parseAnyDef } from \"./parsers/any.js\";\nimport { selectParser } from \"./selectParser.js\";\n\n//#region src/utils/zod-to-json-schema/parseDef.ts\nfunction parseDef(def, refs, forceResolution = false) {\n\tconst seenItem = refs.seen.get(def);\n\tif (refs.override) {\n\t\tconst overrideResult = refs.override?.(def, refs, seenItem, forceResolution);\n\t\tif (overrideResult !== ignoreOverride) return overrideResult;\n\t}\n\tif (seenItem && !forceResolution) {\n\t\tconst seenSchema = get$ref(seenItem, refs);\n\t\tif (seenSchema !== void 0) return seenSchema;\n\t}\n\tconst newItem = {\n\t\tdef,\n\t\tpath: refs.currentPath,\n\t\tjsonSchema: void 0\n\t};\n\trefs.seen.set(def, newItem);\n\tconst jsonSchemaOrGetter = selectParser(def, def.typeName, refs);\n\tconst jsonSchema = typeof jsonSchemaOrGetter === \"function\" ? parseDef(jsonSchemaOrGetter(), refs) : jsonSchemaOrGetter;\n\tif (jsonSchema) addMeta(def, refs, jsonSchema);\n\tif (refs.postProcess) {\n\t\tconst postProcessResult = refs.postProcess(jsonSchema, def, refs);\n\t\tnewItem.jsonSchema = jsonSchema;\n\t\treturn postProcessResult;\n\t}\n\tnewItem.jsonSchema = jsonSchema;\n\treturn jsonSchema;\n}\nconst get$ref = (item, refs) => {\n\tswitch (refs.$refStrategy) {\n\t\tcase \"root\": return { $ref: item.path.join(\"/\") };\n\t\tcase \"relative\": return { $ref: getRelativePath(refs.currentPath, item.path) };\n\t\tcase \"none\":\n\t\tcase \"seen\":\n\t\t\tif (item.path.length < refs.currentPath.length && item.path.every((value, index) => refs.currentPath[index] === value)) {\n\t\t\t\tconsole.warn(`Recursive reference detected at ${refs.currentPath.join(\"/\")}! Defaulting to any`);\n\t\t\t\treturn parseAnyDef(refs);\n\t\t\t}\n\t\t\treturn refs.$refStrategy === \"seen\" ? parseAnyDef(refs) : void 0;\n\t}\n};\nconst addMeta = (def, refs, jsonSchema) => {\n\tif (def.description) {\n\t\tjsonSchema.description = def.description;\n\t\tif (refs.markdownDescription) jsonSchema.markdownDescription = def.description;\n\t}\n\treturn jsonSchema;\n};\n\n//#endregion\nexport { parseDef };\n//# sourceMappingURL=parseDef.js.map","import { getRefs } from \"./Refs.js\";\nimport { parseAnyDef } from \"./parsers/any.js\";\nimport { parseDef } from \"./parseDef.js\";\n\n//#region src/utils/zod-to-json-schema/zodToJsonSchema.ts\nconst zodToJsonSchema = (schema, options) => {\n\tconst refs = getRefs(options);\n\tlet definitions = typeof options === \"object\" && options.definitions ? Object.entries(options.definitions).reduce((acc, [name$1, schema$1]) => ({\n\t\t...acc,\n\t\t[name$1]: parseDef(schema$1._def, {\n\t\t\t...refs,\n\t\t\tcurrentPath: [\n\t\t\t\t...refs.basePath,\n\t\t\t\trefs.definitionPath,\n\t\t\t\tname$1\n\t\t\t]\n\t\t}, true) ?? parseAnyDef(refs)\n\t}), {}) : void 0;\n\tconst name = typeof options === \"string\" ? options : options?.nameStrategy === \"title\" ? void 0 : options?.name;\n\tconst main = parseDef(schema._def, name === void 0 ? refs : {\n\t\t...refs,\n\t\tcurrentPath: [\n\t\t\t...refs.basePath,\n\t\t\trefs.definitionPath,\n\t\t\tname\n\t\t]\n\t}, false) ?? parseAnyDef(refs);\n\tconst title = typeof options === \"object\" && options.name !== void 0 && options.nameStrategy === \"title\" ? options.name : void 0;\n\tif (title !== void 0) main.title = title;\n\tif (refs.flags.hasReferencedOpenAiAnyType) {\n\t\tif (!definitions) definitions = {};\n\t\tif (!definitions[refs.openAiAnyTypeName]) definitions[refs.openAiAnyTypeName] = {\n\t\t\ttype: [\n\t\t\t\t\"string\",\n\t\t\t\t\"number\",\n\t\t\t\t\"integer\",\n\t\t\t\t\"boolean\",\n\t\t\t\t\"array\",\n\t\t\t\t\"null\"\n\t\t\t],\n\t\t\titems: { $ref: refs.$refStrategy === \"relative\" ? \"1\" : [\n\t\t\t\t...refs.basePath,\n\t\t\t\trefs.definitionPath,\n\t\t\t\trefs.openAiAnyTypeName\n\t\t\t].join(\"/\") }\n\t\t};\n\t}\n\tconst combined = name === void 0 ? definitions ? {\n\t\t...main,\n\t\t[refs.definitionPath]: definitions\n\t} : main : {\n\t\t$ref: [\n\t\t\t...refs.$refStrategy === \"relative\" ? [] : refs.basePath,\n\t\t\trefs.definitionPath,\n\t\t\tname\n\t\t].join(\"/\"),\n\t\t[refs.definitionPath]: {\n\t\t\t...definitions,\n\t\t\t[name]: main\n\t\t}\n\t};\n\tif (refs.target === \"jsonSchema7\") combined.$schema = \"http://json-schema.org/draft-07/schema#\";\n\telse if (refs.target === \"jsonSchema2019-09\" || refs.target === \"openAi\") combined.$schema = \"https://json-schema.org/draft/2019-09/schema#\";\n\tif (refs.target === \"openAi\" && (\"anyOf\" in combined || \"oneOf\" in combined || \"allOf\" in combined || \"type\" in combined && Array.isArray(combined.type))) console.warn(\"Warning: OpenAI may not support schemas with unions as roots! Try wrapping it in an object property.\");\n\treturn combined;\n};\n\n//#endregion\nexport { zodToJsonSchema };\n//# sourceMappingURL=zodToJsonSchema.js.map","import { defaultOptions, getDefaultOptions, ignoreOverride } from \"./Options.js\";\nimport { getRefs } from \"./Refs.js\";\nimport { addErrorMessage, setResponseValueAndErrors } from \"./errorMessages.js\";\nimport { getRelativePath } from \"./getRelativePath.js\";\nimport { parseAnyDef } from \"./parsers/any.js\";\nimport { parseArrayDef } from \"./parsers/array.js\";\nimport { parseBigintDef } from \"./parsers/bigint.js\";\nimport { parseBooleanDef } from \"./parsers/boolean.js\";\nimport { parseBrandedDef } from \"./parsers/branded.js\";\nimport { parseCatchDef } from \"./parsers/catch.js\";\nimport { parseDateDef } from \"./parsers/date.js\";\nimport { parseDefaultDef } from \"./parsers/default.js\";\nimport { parseEffectsDef } from \"./parsers/effects.js\";\nimport { parseEnumDef } from \"./parsers/enum.js\";\nimport { parseIntersectionDef } from \"./parsers/intersection.js\";\nimport { parseLiteralDef } from \"./parsers/literal.js\";\nimport { parseStringDef, zodPatterns } from \"./parsers/string.js\";\nimport { parseRecordDef } from \"./parsers/record.js\";\nimport { parseMapDef } from \"./parsers/map.js\";\nimport { parseNativeEnumDef } from \"./parsers/nativeEnum.js\";\nimport { parseNeverDef } from \"./parsers/never.js\";\nimport { parseNullDef } from \"./parsers/null.js\";\nimport { parseUnionDef, primitiveMappings } from \"./parsers/union.js\";\nimport { parseNullableDef } from \"./parsers/nullable.js\";\nimport { parseNumberDef } from \"./parsers/number.js\";\nimport { parseObjectDef } from \"./parsers/object.js\";\nimport { parseOptionalDef } from \"./parsers/optional.js\";\nimport { parsePipelineDef } from \"./parsers/pipeline.js\";\nimport { parsePromiseDef } from \"./parsers/promise.js\";\nimport { parseSetDef } from \"./parsers/set.js\";\nimport { parseTupleDef } from \"./parsers/tuple.js\";\nimport { parseUndefinedDef } from \"./parsers/undefined.js\";\nimport { parseUnknownDef } from \"./parsers/unknown.js\";\nimport { parseReadonlyDef } from \"./parsers/readonly.js\";\nimport { selectParser } from \"./selectParser.js\";\nimport { parseDef } from \"./parseDef.js\";\nimport { zodToJsonSchema } from \"./zodToJsonSchema.js\";\n","import { $ZodRegistry, globalRegistry } from \"./registries.js\";\nimport { getEnumValues } from \"./util.js\";\nexport class JSONSchemaGenerator {\n    constructor(params) {\n        this.counter = 0;\n        this.metadataRegistry = params?.metadata ?? globalRegistry;\n        this.target = params?.target ?? \"draft-2020-12\";\n        this.unrepresentable = params?.unrepresentable ?? \"throw\";\n        this.override = params?.override ?? (() => { });\n        this.io = params?.io ?? \"output\";\n        this.seen = new Map();\n    }\n    process(schema, _params = { path: [], schemaPath: [] }) {\n        var _a;\n        const def = schema._zod.def;\n        const formatMap = {\n            guid: \"uuid\",\n            url: \"uri\",\n            datetime: \"date-time\",\n            json_string: \"json-string\",\n            regex: \"\", // do not set\n        };\n        // check for schema in seens\n        const seen = this.seen.get(schema);\n        if (seen) {\n            seen.count++;\n            // check if cycle\n            const isCycle = _params.schemaPath.includes(schema);\n            if (isCycle) {\n                seen.cycle = _params.path;\n            }\n            return seen.schema;\n        }\n        // initialize\n        const result = { schema: {}, count: 1, cycle: undefined, path: _params.path };\n        this.seen.set(schema, result);\n        // custom method overrides default behavior\n        const overrideSchema = schema._zod.toJSONSchema?.();\n        if (overrideSchema) {\n            result.schema = overrideSchema;\n        }\n        else {\n            const params = {\n                ..._params,\n                schemaPath: [..._params.schemaPath, schema],\n                path: _params.path,\n            };\n            const parent = schema._zod.parent;\n            if (parent) {\n                // schema was cloned from another schema\n                result.ref = parent;\n                this.process(parent, params);\n                this.seen.get(parent).isParent = true;\n            }\n            else {\n                const _json = result.schema;\n                switch (def.type) {\n                    case \"string\": {\n                        const json = _json;\n                        json.type = \"string\";\n                        const { minimum, maximum, format, patterns, contentEncoding } = schema._zod\n                            .bag;\n                        if (typeof minimum === \"number\")\n                            json.minLength = minimum;\n                        if (typeof maximum === \"number\")\n                            json.maxLength = maximum;\n                        // custom pattern overrides format\n                        if (format) {\n                            json.format = formatMap[format] ?? format;\n                            if (json.format === \"\")\n                                delete json.format; // empty format is not valid\n                        }\n                        if (contentEncoding)\n                            json.contentEncoding = contentEncoding;\n                        if (patterns && patterns.size > 0) {\n                            const regexes = [...patterns];\n                            if (regexes.length === 1)\n                                json.pattern = regexes[0].source;\n                            else if (regexes.length > 1) {\n                                result.schema.allOf = [\n                                    ...regexes.map((regex) => ({\n                                        ...(this.target === \"draft-7\" ? { type: \"string\" } : {}),\n                                        pattern: regex.source,\n                                    })),\n                                ];\n                            }\n                        }\n                        break;\n                    }\n                    case \"number\": {\n                        const json = _json;\n                        const { minimum, maximum, format, multipleOf, exclusiveMaximum, exclusiveMinimum } = schema._zod.bag;\n                        if (typeof format === \"string\" && format.includes(\"int\"))\n                            json.type = \"integer\";\n                        else\n                            json.type = \"number\";\n                        if (typeof exclusiveMinimum === \"number\")\n                            json.exclusiveMinimum = exclusiveMinimum;\n                        if (typeof minimum === \"number\") {\n                            json.minimum = minimum;\n                            if (typeof exclusiveMinimum === \"number\") {\n                                if (exclusiveMinimum >= minimum)\n                                    delete json.minimum;\n                                else\n                                    delete json.exclusiveMinimum;\n                            }\n                        }\n                        if (typeof exclusiveMaximum === \"number\")\n                            json.exclusiveMaximum = exclusiveMaximum;\n                        if (typeof maximum === \"number\") {\n                            json.maximum = maximum;\n                            if (typeof exclusiveMaximum === \"number\") {\n                                if (exclusiveMaximum <= maximum)\n                                    delete json.maximum;\n                                else\n                                    delete json.exclusiveMaximum;\n                            }\n                        }\n                        if (typeof multipleOf === \"number\")\n                            json.multipleOf = multipleOf;\n                        break;\n                    }\n                    case \"boolean\": {\n                        const json = _json;\n                        json.type = \"boolean\";\n                        break;\n                    }\n                    case \"bigint\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"BigInt cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"symbol\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Symbols cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"null\": {\n                        _json.type = \"null\";\n                        break;\n                    }\n                    case \"any\": {\n                        break;\n                    }\n                    case \"unknown\": {\n                        break;\n                    }\n                    case \"undefined\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Undefined cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"void\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Void cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"never\": {\n                        _json.not = {};\n                        break;\n                    }\n                    case \"date\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Date cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"array\": {\n                        const json = _json;\n                        const { minimum, maximum } = schema._zod.bag;\n                        if (typeof minimum === \"number\")\n                            json.minItems = minimum;\n                        if (typeof maximum === \"number\")\n                            json.maxItems = maximum;\n                        json.type = \"array\";\n                        json.items = this.process(def.element, { ...params, path: [...params.path, \"items\"] });\n                        break;\n                    }\n                    case \"object\": {\n                        const json = _json;\n                        json.type = \"object\";\n                        json.properties = {};\n                        const shape = def.shape; // params.shapeCache.get(schema)!;\n                        for (const key in shape) {\n                            json.properties[key] = this.process(shape[key], {\n                                ...params,\n                                path: [...params.path, \"properties\", key],\n                            });\n                        }\n                        // required keys\n                        const allKeys = new Set(Object.keys(shape));\n                        // const optionalKeys = new Set(def.optional);\n                        const requiredKeys = new Set([...allKeys].filter((key) => {\n                            const v = def.shape[key]._zod;\n                            if (this.io === \"input\") {\n                                return v.optin === undefined;\n                            }\n                            else {\n                                return v.optout === undefined;\n                            }\n                        }));\n                        if (requiredKeys.size > 0) {\n                            json.required = Array.from(requiredKeys);\n                        }\n                        // catchall\n                        if (def.catchall?._zod.def.type === \"never\") {\n                            // strict\n                            json.additionalProperties = false;\n                        }\n                        else if (!def.catchall) {\n                            // regular\n                            if (this.io === \"output\")\n                                json.additionalProperties = false;\n                        }\n                        else if (def.catchall) {\n                            json.additionalProperties = this.process(def.catchall, {\n                                ...params,\n                                path: [...params.path, \"additionalProperties\"],\n                            });\n                        }\n                        break;\n                    }\n                    case \"union\": {\n                        const json = _json;\n                        json.anyOf = def.options.map((x, i) => this.process(x, {\n                            ...params,\n                            path: [...params.path, \"anyOf\", i],\n                        }));\n                        break;\n                    }\n                    case \"intersection\": {\n                        const json = _json;\n                        const a = this.process(def.left, {\n                            ...params,\n                            path: [...params.path, \"allOf\", 0],\n                        });\n                        const b = this.process(def.right, {\n                            ...params,\n                            path: [...params.path, \"allOf\", 1],\n                        });\n                        const isSimpleIntersection = (val) => \"allOf\" in val && Object.keys(val).length === 1;\n                        const allOf = [\n                            ...(isSimpleIntersection(a) ? a.allOf : [a]),\n                            ...(isSimpleIntersection(b) ? b.allOf : [b]),\n                        ];\n                        json.allOf = allOf;\n                        break;\n                    }\n                    case \"tuple\": {\n                        const json = _json;\n                        json.type = \"array\";\n                        const prefixItems = def.items.map((x, i) => this.process(x, { ...params, path: [...params.path, \"prefixItems\", i] }));\n                        if (this.target === \"draft-2020-12\") {\n                            json.prefixItems = prefixItems;\n                        }\n                        else {\n                            json.items = prefixItems;\n                        }\n                        if (def.rest) {\n                            const rest = this.process(def.rest, {\n                                ...params,\n                                path: [...params.path, \"items\"],\n                            });\n                            if (this.target === \"draft-2020-12\") {\n                                json.items = rest;\n                            }\n                            else {\n                                json.additionalItems = rest;\n                            }\n                        }\n                        // additionalItems\n                        if (def.rest) {\n                            json.items = this.process(def.rest, {\n                                ...params,\n                                path: [...params.path, \"items\"],\n                            });\n                        }\n                        // length\n                        const { minimum, maximum } = schema._zod.bag;\n                        if (typeof minimum === \"number\")\n                            json.minItems = minimum;\n                        if (typeof maximum === \"number\")\n                            json.maxItems = maximum;\n                        break;\n                    }\n                    case \"record\": {\n                        const json = _json;\n                        json.type = \"object\";\n                        json.propertyNames = this.process(def.keyType, { ...params, path: [...params.path, \"propertyNames\"] });\n                        json.additionalProperties = this.process(def.valueType, {\n                            ...params,\n                            path: [...params.path, \"additionalProperties\"],\n                        });\n                        break;\n                    }\n                    case \"map\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Map cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"set\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Set cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"enum\": {\n                        const json = _json;\n                        const values = getEnumValues(def.entries);\n                        // Number enums can have both string and number values\n                        if (values.every((v) => typeof v === \"number\"))\n                            json.type = \"number\";\n                        if (values.every((v) => typeof v === \"string\"))\n                            json.type = \"string\";\n                        json.enum = values;\n                        break;\n                    }\n                    case \"literal\": {\n                        const json = _json;\n                        const vals = [];\n                        for (const val of def.values) {\n                            if (val === undefined) {\n                                if (this.unrepresentable === \"throw\") {\n                                    throw new Error(\"Literal `undefined` cannot be represented in JSON Schema\");\n                                }\n                                else {\n                                    // do not add to vals\n                                }\n                            }\n                            else if (typeof val === \"bigint\") {\n                                if (this.unrepresentable === \"throw\") {\n                                    throw new Error(\"BigInt literals cannot be represented in JSON Schema\");\n                                }\n                                else {\n                                    vals.push(Number(val));\n                                }\n                            }\n                            else {\n                                vals.push(val);\n                            }\n                        }\n                        if (vals.length === 0) {\n                            // do nothing (an undefined literal was stripped)\n                        }\n                        else if (vals.length === 1) {\n                            const val = vals[0];\n                            json.type = val === null ? \"null\" : typeof val;\n                            json.const = val;\n                        }\n                        else {\n                            if (vals.every((v) => typeof v === \"number\"))\n                                json.type = \"number\";\n                            if (vals.every((v) => typeof v === \"string\"))\n                                json.type = \"string\";\n                            if (vals.every((v) => typeof v === \"boolean\"))\n                                json.type = \"string\";\n                            if (vals.every((v) => v === null))\n                                json.type = \"null\";\n                            json.enum = vals;\n                        }\n                        break;\n                    }\n                    case \"file\": {\n                        const json = _json;\n                        const file = {\n                            type: \"string\",\n                            format: \"binary\",\n                            contentEncoding: \"binary\",\n                        };\n                        const { minimum, maximum, mime } = schema._zod.bag;\n                        if (minimum !== undefined)\n                            file.minLength = minimum;\n                        if (maximum !== undefined)\n                            file.maxLength = maximum;\n                        if (mime) {\n                            if (mime.length === 1) {\n                                file.contentMediaType = mime[0];\n                                Object.assign(json, file);\n                            }\n                            else {\n                                json.anyOf = mime.map((m) => {\n                                    const mFile = { ...file, contentMediaType: m };\n                                    return mFile;\n                                });\n                            }\n                        }\n                        else {\n                            Object.assign(json, file);\n                        }\n                        // if (this.unrepresentable === \"throw\") {\n                        //   throw new Error(\"File cannot be represented in JSON Schema\");\n                        // }\n                        break;\n                    }\n                    case \"transform\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Transforms cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"nullable\": {\n                        const inner = this.process(def.innerType, params);\n                        _json.anyOf = [inner, { type: \"null\" }];\n                        break;\n                    }\n                    case \"nonoptional\": {\n                        this.process(def.innerType, params);\n                        result.ref = def.innerType;\n                        break;\n                    }\n                    case \"success\": {\n                        const json = _json;\n                        json.type = \"boolean\";\n                        break;\n                    }\n                    case \"default\": {\n                        this.process(def.innerType, params);\n                        result.ref = def.innerType;\n                        _json.default = JSON.parse(JSON.stringify(def.defaultValue));\n                        break;\n                    }\n                    case \"prefault\": {\n                        this.process(def.innerType, params);\n                        result.ref = def.innerType;\n                        if (this.io === \"input\")\n                            _json._prefault = JSON.parse(JSON.stringify(def.defaultValue));\n                        break;\n                    }\n                    case \"catch\": {\n                        // use conditionals\n                        this.process(def.innerType, params);\n                        result.ref = def.innerType;\n                        let catchValue;\n                        try {\n                            catchValue = def.catchValue(undefined);\n                        }\n                        catch {\n                            throw new Error(\"Dynamic catch values are not supported in JSON Schema\");\n                        }\n                        _json.default = catchValue;\n                        break;\n                    }\n                    case \"nan\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"NaN cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    case \"template_literal\": {\n                        const json = _json;\n                        const pattern = schema._zod.pattern;\n                        if (!pattern)\n                            throw new Error(\"Pattern not found in template literal\");\n                        json.type = \"string\";\n                        json.pattern = pattern.source;\n                        break;\n                    }\n                    case \"pipe\": {\n                        const innerType = this.io === \"input\" ? (def.in._zod.def.type === \"transform\" ? def.out : def.in) : def.out;\n                        this.process(innerType, params);\n                        result.ref = innerType;\n                        break;\n                    }\n                    case \"readonly\": {\n                        this.process(def.innerType, params);\n                        result.ref = def.innerType;\n                        _json.readOnly = true;\n                        break;\n                    }\n                    // passthrough types\n                    case \"promise\": {\n                        this.process(def.innerType, params);\n                        result.ref = def.innerType;\n                        break;\n                    }\n                    case \"optional\": {\n                        this.process(def.innerType, params);\n                        result.ref = def.innerType;\n                        break;\n                    }\n                    case \"lazy\": {\n                        const innerType = schema._zod.innerType;\n                        this.process(innerType, params);\n                        result.ref = innerType;\n                        break;\n                    }\n                    case \"custom\": {\n                        if (this.unrepresentable === \"throw\") {\n                            throw new Error(\"Custom types cannot be represented in JSON Schema\");\n                        }\n                        break;\n                    }\n                    default: {\n                        def;\n                    }\n                }\n            }\n        }\n        // metadata\n        const meta = this.metadataRegistry.get(schema);\n        if (meta)\n            Object.assign(result.schema, meta);\n        if (this.io === \"input\" && isTransforming(schema)) {\n            // examples/defaults only apply to output type of pipe\n            delete result.schema.examples;\n            delete result.schema.default;\n        }\n        // set prefault as default\n        if (this.io === \"input\" && result.schema._prefault)\n            (_a = result.schema).default ?? (_a.default = result.schema._prefault);\n        delete result.schema._prefault;\n        // pulling fresh from this.seen in case it was overwritten\n        const _result = this.seen.get(schema);\n        return _result.schema;\n    }\n    emit(schema, _params) {\n        const params = {\n            cycles: _params?.cycles ?? \"ref\",\n            reused: _params?.reused ?? \"inline\",\n            // unrepresentable: _params?.unrepresentable ?? \"throw\",\n            // uri: _params?.uri ?? ((id) => `${id}`),\n            external: _params?.external ?? undefined,\n        };\n        // iterate over seen map;\n        const root = this.seen.get(schema);\n        if (!root)\n            throw new Error(\"Unprocessed schema. This is a bug in Zod.\");\n        // initialize result with root schema fields\n        // Object.assign(result, seen.cached);\n        // returns a ref to the schema\n        // defId will be empty if the ref points to an external schema (or #)\n        const makeURI = (entry) => {\n            // comparing the seen objects because sometimes\n            // multiple schemas map to the same seen object.\n            // e.g. lazy\n            // external is configured\n            const defsSegment = this.target === \"draft-2020-12\" ? \"$defs\" : \"definitions\";\n            if (params.external) {\n                const externalId = params.external.registry.get(entry[0])?.id; // ?? \"__shared\";// `__schema${this.counter++}`;\n                // check if schema is in the external registry\n                const uriGenerator = params.external.uri ?? ((id) => id);\n                if (externalId) {\n                    return { ref: uriGenerator(externalId) };\n                }\n                // otherwise, add to __shared\n                const id = entry[1].defId ?? entry[1].schema.id ?? `schema${this.counter++}`;\n                entry[1].defId = id; // set defId so it will be reused if needed\n                return { defId: id, ref: `${uriGenerator(\"__shared\")}#/${defsSegment}/${id}` };\n            }\n            if (entry[1] === root) {\n                return { ref: \"#\" };\n            }\n            // self-contained schema\n            const uriPrefix = `#`;\n            const defUriPrefix = `${uriPrefix}/${defsSegment}/`;\n            const defId = entry[1].schema.id ?? `__schema${this.counter++}`;\n            return { defId, ref: defUriPrefix + defId };\n        };\n        // stored cached version in `def` property\n        // remove all properties, set $ref\n        const extractToDef = (entry) => {\n            // if the schema is already a reference, do not extract it\n            if (entry[1].schema.$ref) {\n                return;\n            }\n            const seen = entry[1];\n            const { ref, defId } = makeURI(entry);\n            seen.def = { ...seen.schema };\n            // defId won't be set if the schema is a reference to an external schema\n            if (defId)\n                seen.defId = defId;\n            // wipe away all properties except $ref\n            const schema = seen.schema;\n            for (const key in schema) {\n                delete schema[key];\n            }\n            schema.$ref = ref;\n        };\n        // throw on cycles\n        // break cycles\n        if (params.cycles === \"throw\") {\n            for (const entry of this.seen.entries()) {\n                const seen = entry[1];\n                if (seen.cycle) {\n                    throw new Error(\"Cycle detected: \" +\n                        `#/${seen.cycle?.join(\"/\")}/<root>` +\n                        '\\n\\nSet the `cycles` parameter to `\"ref\"` to resolve cyclical schemas with defs.');\n                }\n            }\n        }\n        // extract schemas into $defs\n        for (const entry of this.seen.entries()) {\n            const seen = entry[1];\n            // convert root schema to # $ref\n            if (schema === entry[0]) {\n                extractToDef(entry); // this has special handling for the root schema\n                continue;\n            }\n            // extract schemas that are in the external registry\n            if (params.external) {\n                const ext = params.external.registry.get(entry[0])?.id;\n                if (schema !== entry[0] && ext) {\n                    extractToDef(entry);\n                    continue;\n                }\n            }\n            // extract schemas with `id` meta\n            const id = this.metadataRegistry.get(entry[0])?.id;\n            if (id) {\n                extractToDef(entry);\n                continue;\n            }\n            // break cycles\n            if (seen.cycle) {\n                // any\n                extractToDef(entry);\n                continue;\n            }\n            // extract reused schemas\n            if (seen.count > 1) {\n                if (params.reused === \"ref\") {\n                    extractToDef(entry);\n                    // biome-ignore lint:\n                    continue;\n                }\n            }\n        }\n        // flatten _refs\n        const flattenRef = (zodSchema, params) => {\n            const seen = this.seen.get(zodSchema);\n            const schema = seen.def ?? seen.schema;\n            const _cached = { ...schema };\n            // already seen\n            if (seen.ref === null) {\n                return;\n            }\n            // flatten ref if defined\n            const ref = seen.ref;\n            seen.ref = null; // prevent recursion\n            if (ref) {\n                flattenRef(ref, params);\n                // merge referenced schema into current\n                const refSchema = this.seen.get(ref).schema;\n                if (refSchema.$ref && params.target === \"draft-7\") {\n                    schema.allOf = schema.allOf ?? [];\n                    schema.allOf.push(refSchema);\n                }\n                else {\n                    Object.assign(schema, refSchema);\n                    Object.assign(schema, _cached); // prevent overwriting any fields in the original schema\n                }\n            }\n            // execute overrides\n            if (!seen.isParent)\n                this.override({\n                    zodSchema: zodSchema,\n                    jsonSchema: schema,\n                    path: seen.path ?? [],\n                });\n        };\n        for (const entry of [...this.seen.entries()].reverse()) {\n            flattenRef(entry[0], { target: this.target });\n        }\n        const result = {};\n        if (this.target === \"draft-2020-12\") {\n            result.$schema = \"https://json-schema.org/draft/2020-12/schema\";\n        }\n        else if (this.target === \"draft-7\") {\n            result.$schema = \"http://json-schema.org/draft-07/schema#\";\n        }\n        else {\n            console.warn(`Invalid target: ${this.target}`);\n        }\n        if (params.external?.uri) {\n            const id = params.external.registry.get(schema)?.id;\n            if (!id)\n                throw new Error(\"Schema is missing an `id` property\");\n            result.$id = params.external.uri(id);\n        }\n        Object.assign(result, root.def);\n        // build defs object\n        const defs = params.external?.defs ?? {};\n        for (const entry of this.seen.entries()) {\n            const seen = entry[1];\n            if (seen.def && seen.defId) {\n                defs[seen.defId] = seen.def;\n            }\n        }\n        // set definitions in result\n        if (params.external) {\n        }\n        else {\n            if (Object.keys(defs).length > 0) {\n                if (this.target === \"draft-2020-12\") {\n                    result.$defs = defs;\n                }\n                else {\n                    result.definitions = defs;\n                }\n            }\n        }\n        try {\n            // this \"finalizes\" this schema and ensures all cycles are removed\n            // each call to .emit() is functionally independent\n            // though the seen map is shared\n            return JSON.parse(JSON.stringify(result));\n        }\n        catch (_err) {\n            throw new Error(\"Error converting schema to JSON.\");\n        }\n    }\n}\nexport function toJSONSchema(input, _params) {\n    if (input instanceof $ZodRegistry) {\n        const gen = new JSONSchemaGenerator(_params);\n        const defs = {};\n        for (const entry of input._idmap.entries()) {\n            const [_, schema] = entry;\n            gen.process(schema);\n        }\n        const schemas = {};\n        const external = {\n            registry: input,\n            uri: _params?.uri,\n            defs,\n        };\n        for (const entry of input._idmap.entries()) {\n            const [key, schema] = entry;\n            schemas[key] = gen.emit(schema, {\n                ..._params,\n                external,\n            });\n        }\n        if (Object.keys(defs).length > 0) {\n            const defsSegment = gen.target === \"draft-2020-12\" ? \"$defs\" : \"definitions\";\n            schemas.__shared = {\n                [defsSegment]: defs,\n            };\n        }\n        return { schemas };\n    }\n    const gen = new JSONSchemaGenerator(_params);\n    gen.process(input);\n    return gen.emit(input, _params);\n}\nfunction isTransforming(_schema, _ctx) {\n    const ctx = _ctx ?? { seen: new Set() };\n    if (ctx.seen.has(_schema))\n        return false;\n    ctx.seen.add(_schema);\n    const schema = _schema;\n    const def = schema._zod.def;\n    switch (def.type) {\n        case \"string\":\n        case \"number\":\n        case \"bigint\":\n        case \"boolean\":\n        case \"date\":\n        case \"symbol\":\n        case \"undefined\":\n        case \"null\":\n        case \"any\":\n        case \"unknown\":\n        case \"never\":\n        case \"void\":\n        case \"literal\":\n        case \"enum\":\n        case \"nan\":\n        case \"file\":\n        case \"template_literal\":\n            return false;\n        case \"array\": {\n            return isTransforming(def.element, ctx);\n        }\n        case \"object\": {\n            for (const key in def.shape) {\n                if (isTransforming(def.shape[key], ctx))\n                    return true;\n            }\n            return false;\n        }\n        case \"union\": {\n            for (const option of def.options) {\n                if (isTransforming(option, ctx))\n                    return true;\n            }\n            return false;\n        }\n        case \"intersection\": {\n            return isTransforming(def.left, ctx) || isTransforming(def.right, ctx);\n        }\n        case \"tuple\": {\n            for (const item of def.items) {\n                if (isTransforming(item, ctx))\n                    return true;\n            }\n            if (def.rest && isTransforming(def.rest, ctx))\n                return true;\n            return false;\n        }\n        case \"record\": {\n            return isTransforming(def.keyType, ctx) || isTransforming(def.valueType, ctx);\n        }\n        case \"map\": {\n            return isTransforming(def.keyType, ctx) || isTransforming(def.valueType, ctx);\n        }\n        case \"set\": {\n            return isTransforming(def.valueType, ctx);\n        }\n        // inner types\n        case \"promise\":\n        case \"optional\":\n        case \"nonoptional\":\n        case \"nullable\":\n        case \"readonly\":\n            return isTransforming(def.innerType, ctx);\n        case \"lazy\":\n            return isTransforming(def.getter(), ctx);\n        case \"default\": {\n            return isTransforming(def.innerType, ctx);\n        }\n        case \"prefault\": {\n            return isTransforming(def.innerType, ctx);\n        }\n        case \"custom\": {\n            return false;\n        }\n        case \"transform\": {\n            return true;\n        }\n        case \"pipe\": {\n            return isTransforming(def.in, ctx) || isTransforming(def.out, ctx);\n        }\n        case \"success\": {\n            return false;\n        }\n        case \"catch\": {\n            return false;\n        }\n        default:\n            def;\n    }\n    throw new Error(`Unknown schema type: ${def.type}`);\n}\n","export function deepCompareStrict(a, b) {\n    const typeofa = typeof a;\n    if (typeofa !== typeof b) {\n        return false;\n    }\n    if (Array.isArray(a)) {\n        if (!Array.isArray(b)) {\n            return false;\n        }\n        const length = a.length;\n        if (length !== b.length) {\n            return false;\n        }\n        for (let i = 0; i < length; i++) {\n            if (!deepCompareStrict(a[i], b[i])) {\n                return false;\n            }\n        }\n        return true;\n    }\n    if (typeofa === 'object') {\n        if (!a || !b) {\n            return a === b;\n        }\n        const aKeys = Object.keys(a);\n        const bKeys = Object.keys(b);\n        const length = aKeys.length;\n        if (length !== bKeys.length) {\n            return false;\n        }\n        for (const k of aKeys) {\n            if (!deepCompareStrict(a[k], b[k])) {\n                return false;\n            }\n        }\n        return true;\n    }\n    return a === b;\n}\n","export function encodePointer(p) {\n    return encodeURI(escapePointer(p));\n}\nexport function escapePointer(p) {\n    return p.replace(/~/g, '~0').replace(/\\//g, '~1');\n}\n","import { encodePointer } from './pointer.js';\nexport const schemaKeyword = {\n    additionalItems: true,\n    unevaluatedItems: true,\n    items: true,\n    contains: true,\n    additionalProperties: true,\n    unevaluatedProperties: true,\n    propertyNames: true,\n    not: true,\n    if: true,\n    then: true,\n    else: true\n};\nexport const schemaArrayKeyword = {\n    prefixItems: true,\n    items: true,\n    allOf: true,\n    anyOf: true,\n    oneOf: true\n};\nexport const schemaMapKeyword = {\n    $defs: true,\n    definitions: true,\n    properties: true,\n    patternProperties: true,\n    dependentSchemas: true\n};\nexport const ignoredKeyword = {\n    id: true,\n    $id: true,\n    $ref: true,\n    $schema: true,\n    $anchor: true,\n    $vocabulary: true,\n    $comment: true,\n    default: true,\n    enum: true,\n    const: true,\n    required: true,\n    type: true,\n    maximum: true,\n    minimum: true,\n    exclusiveMaximum: true,\n    exclusiveMinimum: true,\n    multipleOf: true,\n    maxLength: true,\n    minLength: true,\n    pattern: true,\n    format: true,\n    maxItems: true,\n    minItems: true,\n    uniqueItems: true,\n    maxProperties: true,\n    minProperties: true\n};\nexport let initialBaseURI = typeof self !== 'undefined' &&\n    self.location &&\n    self.location.origin !== 'null'\n    ?\n        new URL(self.location.origin + self.location.pathname + location.search)\n    : new URL('https://github.com/cfworker');\nexport function dereference(schema, lookup = Object.create(null), baseURI = initialBaseURI, basePointer = '') {\n    if (schema && typeof schema === 'object' && !Array.isArray(schema)) {\n        const id = schema.$id || schema.id;\n        if (id) {\n            const url = new URL(id, baseURI.href);\n            if (url.hash.length > 1) {\n                lookup[url.href] = schema;\n            }\n            else {\n                url.hash = '';\n                if (basePointer === '') {\n                    baseURI = url;\n                }\n                else {\n                    dereference(schema, lookup, baseURI);\n                }\n            }\n        }\n    }\n    else if (schema !== true && schema !== false) {\n        return lookup;\n    }\n    const schemaURI = baseURI.href + (basePointer ? '#' + basePointer : '');\n    if (lookup[schemaURI] !== undefined) {\n        throw new Error(`Duplicate schema URI \"${schemaURI}\".`);\n    }\n    lookup[schemaURI] = schema;\n    if (schema === true || schema === false) {\n        return lookup;\n    }\n    if (schema.__absolute_uri__ === undefined) {\n        Object.defineProperty(schema, '__absolute_uri__', {\n            enumerable: false,\n            value: schemaURI\n        });\n    }\n    if (schema.$ref && schema.__absolute_ref__ === undefined) {\n        const url = new URL(schema.$ref, baseURI.href);\n        url.hash = url.hash;\n        Object.defineProperty(schema, '__absolute_ref__', {\n            enumerable: false,\n            value: url.href\n        });\n    }\n    if (schema.$recursiveRef && schema.__absolute_recursive_ref__ === undefined) {\n        const url = new URL(schema.$recursiveRef, baseURI.href);\n        url.hash = url.hash;\n        Object.defineProperty(schema, '__absolute_recursive_ref__', {\n            enumerable: false,\n            value: url.href\n        });\n    }\n    if (schema.$anchor) {\n        const url = new URL('#' + schema.$anchor, baseURI.href);\n        lookup[url.href] = schema;\n    }\n    for (let key in schema) {\n        if (ignoredKeyword[key]) {\n            continue;\n        }\n        const keyBase = `${basePointer}/${encodePointer(key)}`;\n        const subSchema = schema[key];\n        if (Array.isArray(subSchema)) {\n            if (schemaArrayKeyword[key]) {\n                const length = subSchema.length;\n                for (let i = 0; i < length; i++) {\n                    dereference(subSchema[i], lookup, baseURI, `${keyBase}/${i}`);\n                }\n            }\n        }\n        else if (schemaMapKeyword[key]) {\n            for (let subKey in subSchema) {\n                dereference(subSchema[subKey], lookup, baseURI, `${keyBase}/${encodePointer(subKey)}`);\n            }\n        }\n        else {\n            dereference(subSchema, lookup, baseURI, keyBase);\n        }\n    }\n    return lookup;\n}\n","const DATE = /^(\\d\\d\\d\\d)-(\\d\\d)-(\\d\\d)$/;\nconst DAYS = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];\nconst TIME = /^(\\d\\d):(\\d\\d):(\\d\\d)(\\.\\d+)?(z|[+-]\\d\\d(?::?\\d\\d)?)?$/i;\nconst HOSTNAME = /^(?=.{1,253}\\.?$)[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?(?:\\.[a-z0-9](?:[-0-9a-z]{0,61}[0-9a-z])?)*\\.?$/i;\nconst URIREF = /^(?:[a-z][a-z0-9+\\-.]*:)?(?:\\/?\\/(?:(?:[a-z0-9\\-._~!$&'()*+,;=:]|%[0-9a-f]{2})*@)?(?:\\[(?:(?:(?:(?:[0-9a-f]{1,4}:){6}|::(?:[0-9a-f]{1,4}:){5}|(?:[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){4}|(?:(?:[0-9a-f]{1,4}:){0,1}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){3}|(?:(?:[0-9a-f]{1,4}:){0,2}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){2}|(?:(?:[0-9a-f]{1,4}:){0,3}[0-9a-f]{1,4})?::[0-9a-f]{1,4}:|(?:(?:[0-9a-f]{1,4}:){0,4}[0-9a-f]{1,4})?::)(?:[0-9a-f]{1,4}:[0-9a-f]{1,4}|(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?))|(?:(?:[0-9a-f]{1,4}:){0,5}[0-9a-f]{1,4})?::[0-9a-f]{1,4}|(?:(?:[0-9a-f]{1,4}:){0,6}[0-9a-f]{1,4})?::)|[Vv][0-9a-f]+\\.[a-z0-9\\-._~!$&'()*+,;=:]+)\\]|(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)|(?:[a-z0-9\\-._~!$&'\"()*+,;=]|%[0-9a-f]{2})*)(?::\\d*)?(?:\\/(?:[a-z0-9\\-._~!$&'\"()*+,;=:@]|%[0-9a-f]{2})*)*|\\/(?:(?:[a-z0-9\\-._~!$&'\"()*+,;=:@]|%[0-9a-f]{2})+(?:\\/(?:[a-z0-9\\-._~!$&'\"()*+,;=:@]|%[0-9a-f]{2})*)*)?|(?:[a-z0-9\\-._~!$&'\"()*+,;=:@]|%[0-9a-f]{2})+(?:\\/(?:[a-z0-9\\-._~!$&'\"()*+,;=:@]|%[0-9a-f]{2})*)*)?(?:\\?(?:[a-z0-9\\-._~!$&'\"()*+,;=:@/?]|%[0-9a-f]{2})*)?(?:#(?:[a-z0-9\\-._~!$&'\"()*+,;=:@/?]|%[0-9a-f]{2})*)?$/i;\nconst URITEMPLATE = /^(?:(?:[^\\x00-\\x20\"'<>%\\\\^`{|}]|%[0-9a-f]{2})|\\{[+#./;?&=,!@|]?(?:[a-z0-9_]|%[0-9a-f]{2})+(?::[1-9][0-9]{0,3}|\\*)?(?:,(?:[a-z0-9_]|%[0-9a-f]{2})+(?::[1-9][0-9]{0,3}|\\*)?)*\\})*$/i;\nconst URL_ = /^(?:(?:https?|ftp):\\/\\/)(?:\\S+(?::\\S*)?@)?(?:(?!10(?:\\.\\d{1,3}){3})(?!127(?:\\.\\d{1,3}){3})(?!169\\.254(?:\\.\\d{1,3}){2})(?!192\\.168(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\u{00a1}-\\u{ffff}0-9]+-?)*[a-z\\u{00a1}-\\u{ffff}0-9]+)(?:\\.(?:[a-z\\u{00a1}-\\u{ffff}0-9]+-?)*[a-z\\u{00a1}-\\u{ffff}0-9]+)*(?:\\.(?:[a-z\\u{00a1}-\\u{ffff}]{2,})))(?::\\d{2,5})?(?:\\/[^\\s]*)?$/iu;\nconst UUID = /^(?:urn:uuid:)?[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12}$/i;\nconst JSON_POINTER = /^(?:\\/(?:[^~/]|~0|~1)*)*$/;\nconst JSON_POINTER_URI_FRAGMENT = /^#(?:\\/(?:[a-z0-9_\\-.!$&'()*+,;:=@]|%[0-9a-f]{2}|~0|~1)*)*$/i;\nconst RELATIVE_JSON_POINTER = /^(?:0|[1-9][0-9]*)(?:#|(?:\\/(?:[^~/]|~0|~1)*)*)$/;\nconst EMAIL = (input) => {\n    if (input[0] === '\"')\n        return false;\n    const [name, host, ...rest] = input.split('@');\n    if (!name ||\n        !host ||\n        rest.length !== 0 ||\n        name.length > 64 ||\n        host.length > 253)\n        return false;\n    if (name[0] === '.' || name.endsWith('.') || name.includes('..'))\n        return false;\n    if (!/^[a-z0-9.-]+$/i.test(host) ||\n        !/^[a-z0-9.!#$%&'*+/=?^_`{|}~-]+$/i.test(name))\n        return false;\n    return host\n        .split('.')\n        .every(part => /^[a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?$/i.test(part));\n};\nconst IPV4 = /^(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)$/;\nconst IPV6 = /^((([0-9a-f]{1,4}:){7}([0-9a-f]{1,4}|:))|(([0-9a-f]{1,4}:){6}(:[0-9a-f]{1,4}|((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9a-f]{1,4}:){5}(((:[0-9a-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9a-f]{1,4}:){4}(((:[0-9a-f]{1,4}){1,3})|((:[0-9a-f]{1,4})?:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9a-f]{1,4}:){3}(((:[0-9a-f]{1,4}){1,4})|((:[0-9a-f]{1,4}){0,2}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9a-f]{1,4}:){2}(((:[0-9a-f]{1,4}){1,5})|((:[0-9a-f]{1,4}){0,3}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9a-f]{1,4}:){1}(((:[0-9a-f]{1,4}){1,6})|((:[0-9a-f]{1,4}){0,4}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(:(((:[0-9a-f]{1,4}){1,7})|((:[0-9a-f]{1,4}){0,5}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))$/i;\nconst DURATION = (input) => input.length > 1 &&\n    input.length < 80 &&\n    (/^P\\d+([.,]\\d+)?W$/.test(input) ||\n        (/^P[\\dYMDTHS]*(\\d[.,]\\d+)?[YMDHS]$/.test(input) &&\n            /^P([.,\\d]+Y)?([.,\\d]+M)?([.,\\d]+D)?(T([.,\\d]+H)?([.,\\d]+M)?([.,\\d]+S)?)?$/.test(input)));\nfunction bind(r) {\n    return r.test.bind(r);\n}\nexport const format = {\n    date,\n    time: time.bind(undefined, false),\n    'date-time': date_time,\n    duration: DURATION,\n    uri,\n    'uri-reference': bind(URIREF),\n    'uri-template': bind(URITEMPLATE),\n    url: bind(URL_),\n    email: EMAIL,\n    hostname: bind(HOSTNAME),\n    ipv4: bind(IPV4),\n    ipv6: bind(IPV6),\n    regex: regex,\n    uuid: bind(UUID),\n    'json-pointer': bind(JSON_POINTER),\n    'json-pointer-uri-fragment': bind(JSON_POINTER_URI_FRAGMENT),\n    'relative-json-pointer': bind(RELATIVE_JSON_POINTER)\n};\nfunction isLeapYear(year) {\n    return year % 4 === 0 && (year % 100 !== 0 || year % 400 === 0);\n}\nfunction date(str) {\n    const matches = str.match(DATE);\n    if (!matches)\n        return false;\n    const year = +matches[1];\n    const month = +matches[2];\n    const day = +matches[3];\n    return (month >= 1 &&\n        month <= 12 &&\n        day >= 1 &&\n        day <= (month == 2 && isLeapYear(year) ? 29 : DAYS[month]));\n}\nfunction time(full, str) {\n    const matches = str.match(TIME);\n    if (!matches)\n        return false;\n    const hour = +matches[1];\n    const minute = +matches[2];\n    const second = +matches[3];\n    const timeZone = !!matches[5];\n    return (((hour <= 23 && minute <= 59 && second <= 59) ||\n        (hour == 23 && minute == 59 && second == 60)) &&\n        (!full || timeZone));\n}\nconst DATE_TIME_SEPARATOR = /t|\\s/i;\nfunction date_time(str) {\n    const dateTime = str.split(DATE_TIME_SEPARATOR);\n    return dateTime.length == 2 && date(dateTime[0]) && time(true, dateTime[1]);\n}\nconst NOT_URI_FRAGMENT = /\\/|:/;\nconst URI_PATTERN = /^(?:[a-z][a-z0-9+\\-.]*:)(?:\\/?\\/(?:(?:[a-z0-9\\-._~!$&'()*+,;=:]|%[0-9a-f]{2})*@)?(?:\\[(?:(?:(?:(?:[0-9a-f]{1,4}:){6}|::(?:[0-9a-f]{1,4}:){5}|(?:[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){4}|(?:(?:[0-9a-f]{1,4}:){0,1}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){3}|(?:(?:[0-9a-f]{1,4}:){0,2}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){2}|(?:(?:[0-9a-f]{1,4}:){0,3}[0-9a-f]{1,4})?::[0-9a-f]{1,4}:|(?:(?:[0-9a-f]{1,4}:){0,4}[0-9a-f]{1,4})?::)(?:[0-9a-f]{1,4}:[0-9a-f]{1,4}|(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?))|(?:(?:[0-9a-f]{1,4}:){0,5}[0-9a-f]{1,4})?::[0-9a-f]{1,4}|(?:(?:[0-9a-f]{1,4}:){0,6}[0-9a-f]{1,4})?::)|[Vv][0-9a-f]+\\.[a-z0-9\\-._~!$&'()*+,;=:]+)\\]|(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d?)|(?:[a-z0-9\\-._~!$&'()*+,;=]|%[0-9a-f]{2})*)(?::\\d*)?(?:\\/(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*|\\/(?:(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})+(?:\\/(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*)?|(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})+(?:\\/(?:[a-z0-9\\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*)(?:\\?(?:[a-z0-9\\-._~!$&'()*+,;=:@/?]|%[0-9a-f]{2})*)?(?:#(?:[a-z0-9\\-._~!$&'()*+,;=:@/?]|%[0-9a-f]{2})*)?$/i;\nfunction uri(str) {\n    return NOT_URI_FRAGMENT.test(str) && URI_PATTERN.test(str);\n}\nconst Z_ANCHOR = /[^\\\\]\\\\Z/;\nfunction regex(str) {\n    if (Z_ANCHOR.test(str))\n        return false;\n    try {\n        new RegExp(str, 'u');\n        return true;\n    }\n    catch (e) {\n        return false;\n    }\n}\n","export var OutputFormat;\n(function (OutputFormat) {\n    OutputFormat[OutputFormat[\"Flag\"] = 1] = \"Flag\";\n    OutputFormat[OutputFormat[\"Basic\"] = 2] = \"Basic\";\n    OutputFormat[OutputFormat[\"Detailed\"] = 4] = \"Detailed\";\n})(OutputFormat || (OutputFormat = {}));\n","export function ucs2length(s) {\n    let result = 0;\n    let length = s.length;\n    let index = 0;\n    let charCode;\n    while (index < length) {\n        result++;\n        charCode = s.charCodeAt(index++);\n        if (charCode >= 0xd800 && charCode <= 0xdbff && index < length) {\n            charCode = s.charCodeAt(index);\n            if ((charCode & 0xfc00) == 0xdc00) {\n                index++;\n            }\n        }\n    }\n    return result;\n}\n","import { deepCompareStrict } from './deep-compare-strict.js';\nimport { dereference } from './dereference.js';\nimport { format } from './format.js';\nimport { encodePointer } from './pointer.js';\nimport { ucs2length } from './ucs2-length.js';\nexport function validate(instance, schema, draft = '2019-09', lookup = dereference(schema), shortCircuit = true, recursiveAnchor = null, instanceLocation = '#', schemaLocation = '#', evaluated = Object.create(null)) {\n    if (schema === true) {\n        return { valid: true, errors: [] };\n    }\n    if (schema === false) {\n        return {\n            valid: false,\n            errors: [\n                {\n                    instanceLocation,\n                    keyword: 'false',\n                    keywordLocation: instanceLocation,\n                    error: 'False boolean schema.'\n                }\n            ]\n        };\n    }\n    const rawInstanceType = typeof instance;\n    let instanceType;\n    switch (rawInstanceType) {\n        case 'boolean':\n        case 'number':\n        case 'string':\n            instanceType = rawInstanceType;\n            break;\n        case 'object':\n            if (instance === null) {\n                instanceType = 'null';\n            }\n            else if (Array.isArray(instance)) {\n                instanceType = 'array';\n            }\n            else {\n                instanceType = 'object';\n            }\n            break;\n        default:\n            throw new Error(`Instances of \"${rawInstanceType}\" type are not supported.`);\n    }\n    const { $ref, $recursiveRef, $recursiveAnchor, type: $type, const: $const, enum: $enum, required: $required, not: $not, anyOf: $anyOf, allOf: $allOf, oneOf: $oneOf, if: $if, then: $then, else: $else, format: $format, properties: $properties, patternProperties: $patternProperties, additionalProperties: $additionalProperties, unevaluatedProperties: $unevaluatedProperties, minProperties: $minProperties, maxProperties: $maxProperties, propertyNames: $propertyNames, dependentRequired: $dependentRequired, dependentSchemas: $dependentSchemas, dependencies: $dependencies, prefixItems: $prefixItems, items: $items, additionalItems: $additionalItems, unevaluatedItems: $unevaluatedItems, contains: $contains, minContains: $minContains, maxContains: $maxContains, minItems: $minItems, maxItems: $maxItems, uniqueItems: $uniqueItems, minimum: $minimum, maximum: $maximum, exclusiveMinimum: $exclusiveMinimum, exclusiveMaximum: $exclusiveMaximum, multipleOf: $multipleOf, minLength: $minLength, maxLength: $maxLength, pattern: $pattern, __absolute_ref__, __absolute_recursive_ref__ } = schema;\n    const errors = [];\n    if ($recursiveAnchor === true && recursiveAnchor === null) {\n        recursiveAnchor = schema;\n    }\n    if ($recursiveRef === '#') {\n        const refSchema = recursiveAnchor === null\n            ? lookup[__absolute_recursive_ref__]\n            : recursiveAnchor;\n        const keywordLocation = `${schemaLocation}/$recursiveRef`;\n        const result = validate(instance, recursiveAnchor === null ? schema : recursiveAnchor, draft, lookup, shortCircuit, refSchema, instanceLocation, keywordLocation, evaluated);\n        if (!result.valid) {\n            errors.push({\n                instanceLocation,\n                keyword: '$recursiveRef',\n                keywordLocation,\n                error: 'A subschema had errors.'\n            }, ...result.errors);\n        }\n    }\n    if ($ref !== undefined) {\n        const uri = __absolute_ref__ || $ref;\n        const refSchema = lookup[uri];\n        if (refSchema === undefined) {\n            let message = `Unresolved $ref \"${$ref}\".`;\n            if (__absolute_ref__ && __absolute_ref__ !== $ref) {\n                message += `  Absolute URI \"${__absolute_ref__}\".`;\n            }\n            message += `\\nKnown schemas:\\n- ${Object.keys(lookup).join('\\n- ')}`;\n            throw new Error(message);\n        }\n        const keywordLocation = `${schemaLocation}/$ref`;\n        const result = validate(instance, refSchema, draft, lookup, shortCircuit, recursiveAnchor, instanceLocation, keywordLocation, evaluated);\n        if (!result.valid) {\n            errors.push({\n                instanceLocation,\n                keyword: '$ref',\n                keywordLocation,\n                error: 'A subschema had errors.'\n            }, ...result.errors);\n        }\n        if (draft === '4' || draft === '7') {\n            return { valid: errors.length === 0, errors };\n        }\n    }\n    if (Array.isArray($type)) {\n        let length = $type.length;\n        let valid = false;\n        for (let i = 0; i < length; i++) {\n            if (instanceType === $type[i] ||\n                ($type[i] === 'integer' &&\n                    instanceType === 'number' &&\n                    instance % 1 === 0 &&\n                    instance === instance)) {\n                valid = true;\n                break;\n            }\n        }\n        if (!valid) {\n            errors.push({\n                instanceLocation,\n                keyword: 'type',\n                keywordLocation: `${schemaLocation}/type`,\n                error: `Instance type \"${instanceType}\" is invalid. Expected \"${$type.join('\", \"')}\".`\n            });\n        }\n    }\n    else if ($type === 'integer') {\n        if (instanceType !== 'number' || instance % 1 || instance !== instance) {\n            errors.push({\n                instanceLocation,\n                keyword: 'type',\n                keywordLocation: `${schemaLocation}/type`,\n                error: `Instance type \"${instanceType}\" is invalid. Expected \"${$type}\".`\n            });\n        }\n    }\n    else if ($type !== undefined && instanceType !== $type) {\n        errors.push({\n            instanceLocation,\n            keyword: 'type',\n            keywordLocation: `${schemaLocation}/type`,\n            error: `Instance type \"${instanceType}\" is invalid. Expected \"${$type}\".`\n        });\n    }\n    if ($const !== undefined) {\n        if (instanceType === 'object' || instanceType === 'array') {\n            if (!deepCompareStrict(instance, $const)) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'const',\n                    keywordLocation: `${schemaLocation}/const`,\n                    error: `Instance does not match ${JSON.stringify($const)}.`\n                });\n            }\n        }\n        else if (instance !== $const) {\n            errors.push({\n                instanceLocation,\n                keyword: 'const',\n                keywordLocation: `${schemaLocation}/const`,\n                error: `Instance does not match ${JSON.stringify($const)}.`\n            });\n        }\n    }\n    if ($enum !== undefined) {\n        if (instanceType === 'object' || instanceType === 'array') {\n            if (!$enum.some(value => deepCompareStrict(instance, value))) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'enum',\n                    keywordLocation: `${schemaLocation}/enum`,\n                    error: `Instance does not match any of ${JSON.stringify($enum)}.`\n                });\n            }\n        }\n        else if (!$enum.some(value => instance === value)) {\n            errors.push({\n                instanceLocation,\n                keyword: 'enum',\n                keywordLocation: `${schemaLocation}/enum`,\n                error: `Instance does not match any of ${JSON.stringify($enum)}.`\n            });\n        }\n    }\n    if ($not !== undefined) {\n        const keywordLocation = `${schemaLocation}/not`;\n        const result = validate(instance, $not, draft, lookup, shortCircuit, recursiveAnchor, instanceLocation, keywordLocation);\n        if (result.valid) {\n            errors.push({\n                instanceLocation,\n                keyword: 'not',\n                keywordLocation,\n                error: 'Instance matched \"not\" schema.'\n            });\n        }\n    }\n    let subEvaluateds = [];\n    if ($anyOf !== undefined) {\n        const keywordLocation = `${schemaLocation}/anyOf`;\n        const errorsLength = errors.length;\n        let anyValid = false;\n        for (let i = 0; i < $anyOf.length; i++) {\n            const subSchema = $anyOf[i];\n            const subEvaluated = Object.create(evaluated);\n            const result = validate(instance, subSchema, draft, lookup, shortCircuit, $recursiveAnchor === true ? recursiveAnchor : null, instanceLocation, `${keywordLocation}/${i}`, subEvaluated);\n            errors.push(...result.errors);\n            anyValid = anyValid || result.valid;\n            if (result.valid) {\n                subEvaluateds.push(subEvaluated);\n            }\n        }\n        if (anyValid) {\n            errors.length = errorsLength;\n        }\n        else {\n            errors.splice(errorsLength, 0, {\n                instanceLocation,\n                keyword: 'anyOf',\n                keywordLocation,\n                error: 'Instance does not match any subschemas.'\n            });\n        }\n    }\n    if ($allOf !== undefined) {\n        const keywordLocation = `${schemaLocation}/allOf`;\n        const errorsLength = errors.length;\n        let allValid = true;\n        for (let i = 0; i < $allOf.length; i++) {\n            const subSchema = $allOf[i];\n            const subEvaluated = Object.create(evaluated);\n            const result = validate(instance, subSchema, draft, lookup, shortCircuit, $recursiveAnchor === true ? recursiveAnchor : null, instanceLocation, `${keywordLocation}/${i}`, subEvaluated);\n            errors.push(...result.errors);\n            allValid = allValid && result.valid;\n            if (result.valid) {\n                subEvaluateds.push(subEvaluated);\n            }\n        }\n        if (allValid) {\n            errors.length = errorsLength;\n        }\n        else {\n            errors.splice(errorsLength, 0, {\n                instanceLocation,\n                keyword: 'allOf',\n                keywordLocation,\n                error: `Instance does not match every subschema.`\n            });\n        }\n    }\n    if ($oneOf !== undefined) {\n        const keywordLocation = `${schemaLocation}/oneOf`;\n        const errorsLength = errors.length;\n        const matches = $oneOf.filter((subSchema, i) => {\n            const subEvaluated = Object.create(evaluated);\n            const result = validate(instance, subSchema, draft, lookup, shortCircuit, $recursiveAnchor === true ? recursiveAnchor : null, instanceLocation, `${keywordLocation}/${i}`, subEvaluated);\n            errors.push(...result.errors);\n            if (result.valid) {\n                subEvaluateds.push(subEvaluated);\n            }\n            return result.valid;\n        }).length;\n        if (matches === 1) {\n            errors.length = errorsLength;\n        }\n        else {\n            errors.splice(errorsLength, 0, {\n                instanceLocation,\n                keyword: 'oneOf',\n                keywordLocation,\n                error: `Instance does not match exactly one subschema (${matches} matches).`\n            });\n        }\n    }\n    if (instanceType === 'object' || instanceType === 'array') {\n        Object.assign(evaluated, ...subEvaluateds);\n    }\n    if ($if !== undefined) {\n        const keywordLocation = `${schemaLocation}/if`;\n        const conditionResult = validate(instance, $if, draft, lookup, shortCircuit, recursiveAnchor, instanceLocation, keywordLocation, evaluated).valid;\n        if (conditionResult) {\n            if ($then !== undefined) {\n                const thenResult = validate(instance, $then, draft, lookup, shortCircuit, recursiveAnchor, instanceLocation, `${schemaLocation}/then`, evaluated);\n                if (!thenResult.valid) {\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'if',\n                        keywordLocation,\n                        error: `Instance does not match \"then\" schema.`\n                    }, ...thenResult.errors);\n                }\n            }\n        }\n        else if ($else !== undefined) {\n            const elseResult = validate(instance, $else, draft, lookup, shortCircuit, recursiveAnchor, instanceLocation, `${schemaLocation}/else`, evaluated);\n            if (!elseResult.valid) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'if',\n                    keywordLocation,\n                    error: `Instance does not match \"else\" schema.`\n                }, ...elseResult.errors);\n            }\n        }\n    }\n    if (instanceType === 'object') {\n        if ($required !== undefined) {\n            for (const key of $required) {\n                if (!(key in instance)) {\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'required',\n                        keywordLocation: `${schemaLocation}/required`,\n                        error: `Instance does not have required property \"${key}\".`\n                    });\n                }\n            }\n        }\n        const keys = Object.keys(instance);\n        if ($minProperties !== undefined && keys.length < $minProperties) {\n            errors.push({\n                instanceLocation,\n                keyword: 'minProperties',\n                keywordLocation: `${schemaLocation}/minProperties`,\n                error: `Instance does not have at least ${$minProperties} properties.`\n            });\n        }\n        if ($maxProperties !== undefined && keys.length > $maxProperties) {\n            errors.push({\n                instanceLocation,\n                keyword: 'maxProperties',\n                keywordLocation: `${schemaLocation}/maxProperties`,\n                error: `Instance does not have at least ${$maxProperties} properties.`\n            });\n        }\n        if ($propertyNames !== undefined) {\n            const keywordLocation = `${schemaLocation}/propertyNames`;\n            for (const key in instance) {\n                const subInstancePointer = `${instanceLocation}/${encodePointer(key)}`;\n                const result = validate(key, $propertyNames, draft, lookup, shortCircuit, recursiveAnchor, subInstancePointer, keywordLocation);\n                if (!result.valid) {\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'propertyNames',\n                        keywordLocation,\n                        error: `Property name \"${key}\" does not match schema.`\n                    }, ...result.errors);\n                }\n            }\n        }\n        if ($dependentRequired !== undefined) {\n            const keywordLocation = `${schemaLocation}/dependantRequired`;\n            for (const key in $dependentRequired) {\n                if (key in instance) {\n                    const required = $dependentRequired[key];\n                    for (const dependantKey of required) {\n                        if (!(dependantKey in instance)) {\n                            errors.push({\n                                instanceLocation,\n                                keyword: 'dependentRequired',\n                                keywordLocation,\n                                error: `Instance has \"${key}\" but does not have \"${dependantKey}\".`\n                            });\n                        }\n                    }\n                }\n            }\n        }\n        if ($dependentSchemas !== undefined) {\n            for (const key in $dependentSchemas) {\n                const keywordLocation = `${schemaLocation}/dependentSchemas`;\n                if (key in instance) {\n                    const result = validate(instance, $dependentSchemas[key], draft, lookup, shortCircuit, recursiveAnchor, instanceLocation, `${keywordLocation}/${encodePointer(key)}`, evaluated);\n                    if (!result.valid) {\n                        errors.push({\n                            instanceLocation,\n                            keyword: 'dependentSchemas',\n                            keywordLocation,\n                            error: `Instance has \"${key}\" but does not match dependant schema.`\n                        }, ...result.errors);\n                    }\n                }\n            }\n        }\n        if ($dependencies !== undefined) {\n            const keywordLocation = `${schemaLocation}/dependencies`;\n            for (const key in $dependencies) {\n                if (key in instance) {\n                    const propsOrSchema = $dependencies[key];\n                    if (Array.isArray(propsOrSchema)) {\n                        for (const dependantKey of propsOrSchema) {\n                            if (!(dependantKey in instance)) {\n                                errors.push({\n                                    instanceLocation,\n                                    keyword: 'dependencies',\n                                    keywordLocation,\n                                    error: `Instance has \"${key}\" but does not have \"${dependantKey}\".`\n                                });\n                            }\n                        }\n                    }\n                    else {\n                        const result = validate(instance, propsOrSchema, draft, lookup, shortCircuit, recursiveAnchor, instanceLocation, `${keywordLocation}/${encodePointer(key)}`);\n                        if (!result.valid) {\n                            errors.push({\n                                instanceLocation,\n                                keyword: 'dependencies',\n                                keywordLocation,\n                                error: `Instance has \"${key}\" but does not match dependant schema.`\n                            }, ...result.errors);\n                        }\n                    }\n                }\n            }\n        }\n        const thisEvaluated = Object.create(null);\n        let stop = false;\n        if ($properties !== undefined) {\n            const keywordLocation = `${schemaLocation}/properties`;\n            for (const key in $properties) {\n                if (!(key in instance)) {\n                    continue;\n                }\n                const subInstancePointer = `${instanceLocation}/${encodePointer(key)}`;\n                const result = validate(instance[key], $properties[key], draft, lookup, shortCircuit, recursiveAnchor, subInstancePointer, `${keywordLocation}/${encodePointer(key)}`);\n                if (result.valid) {\n                    evaluated[key] = thisEvaluated[key] = true;\n                }\n                else {\n                    stop = shortCircuit;\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'properties',\n                        keywordLocation,\n                        error: `Property \"${key}\" does not match schema.`\n                    }, ...result.errors);\n                    if (stop)\n                        break;\n                }\n            }\n        }\n        if (!stop && $patternProperties !== undefined) {\n            const keywordLocation = `${schemaLocation}/patternProperties`;\n            for (const pattern in $patternProperties) {\n                const regex = new RegExp(pattern, 'u');\n                const subSchema = $patternProperties[pattern];\n                for (const key in instance) {\n                    if (!regex.test(key)) {\n                        continue;\n                    }\n                    const subInstancePointer = `${instanceLocation}/${encodePointer(key)}`;\n                    const result = validate(instance[key], subSchema, draft, lookup, shortCircuit, recursiveAnchor, subInstancePointer, `${keywordLocation}/${encodePointer(pattern)}`);\n                    if (result.valid) {\n                        evaluated[key] = thisEvaluated[key] = true;\n                    }\n                    else {\n                        stop = shortCircuit;\n                        errors.push({\n                            instanceLocation,\n                            keyword: 'patternProperties',\n                            keywordLocation,\n                            error: `Property \"${key}\" matches pattern \"${pattern}\" but does not match associated schema.`\n                        }, ...result.errors);\n                    }\n                }\n            }\n        }\n        if (!stop && $additionalProperties !== undefined) {\n            const keywordLocation = `${schemaLocation}/additionalProperties`;\n            for (const key in instance) {\n                if (thisEvaluated[key]) {\n                    continue;\n                }\n                const subInstancePointer = `${instanceLocation}/${encodePointer(key)}`;\n                const result = validate(instance[key], $additionalProperties, draft, lookup, shortCircuit, recursiveAnchor, subInstancePointer, keywordLocation);\n                if (result.valid) {\n                    evaluated[key] = true;\n                }\n                else {\n                    stop = shortCircuit;\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'additionalProperties',\n                        keywordLocation,\n                        error: `Property \"${key}\" does not match additional properties schema.`\n                    }, ...result.errors);\n                }\n            }\n        }\n        else if (!stop && $unevaluatedProperties !== undefined) {\n            const keywordLocation = `${schemaLocation}/unevaluatedProperties`;\n            for (const key in instance) {\n                if (!evaluated[key]) {\n                    const subInstancePointer = `${instanceLocation}/${encodePointer(key)}`;\n                    const result = validate(instance[key], $unevaluatedProperties, draft, lookup, shortCircuit, recursiveAnchor, subInstancePointer, keywordLocation);\n                    if (result.valid) {\n                        evaluated[key] = true;\n                    }\n                    else {\n                        errors.push({\n                            instanceLocation,\n                            keyword: 'unevaluatedProperties',\n                            keywordLocation,\n                            error: `Property \"${key}\" does not match unevaluated properties schema.`\n                        }, ...result.errors);\n                    }\n                }\n            }\n        }\n    }\n    else if (instanceType === 'array') {\n        if ($maxItems !== undefined && instance.length > $maxItems) {\n            errors.push({\n                instanceLocation,\n                keyword: 'maxItems',\n                keywordLocation: `${schemaLocation}/maxItems`,\n                error: `Array has too many items (${instance.length} > ${$maxItems}).`\n            });\n        }\n        if ($minItems !== undefined && instance.length < $minItems) {\n            errors.push({\n                instanceLocation,\n                keyword: 'minItems',\n                keywordLocation: `${schemaLocation}/minItems`,\n                error: `Array has too few items (${instance.length} < ${$minItems}).`\n            });\n        }\n        const length = instance.length;\n        let i = 0;\n        let stop = false;\n        if ($prefixItems !== undefined) {\n            const keywordLocation = `${schemaLocation}/prefixItems`;\n            const length2 = Math.min($prefixItems.length, length);\n            for (; i < length2; i++) {\n                const result = validate(instance[i], $prefixItems[i], draft, lookup, shortCircuit, recursiveAnchor, `${instanceLocation}/${i}`, `${keywordLocation}/${i}`);\n                evaluated[i] = true;\n                if (!result.valid) {\n                    stop = shortCircuit;\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'prefixItems',\n                        keywordLocation,\n                        error: `Items did not match schema.`\n                    }, ...result.errors);\n                    if (stop)\n                        break;\n                }\n            }\n        }\n        if ($items !== undefined) {\n            const keywordLocation = `${schemaLocation}/items`;\n            if (Array.isArray($items)) {\n                const length2 = Math.min($items.length, length);\n                for (; i < length2; i++) {\n                    const result = validate(instance[i], $items[i], draft, lookup, shortCircuit, recursiveAnchor, `${instanceLocation}/${i}`, `${keywordLocation}/${i}`);\n                    evaluated[i] = true;\n                    if (!result.valid) {\n                        stop = shortCircuit;\n                        errors.push({\n                            instanceLocation,\n                            keyword: 'items',\n                            keywordLocation,\n                            error: `Items did not match schema.`\n                        }, ...result.errors);\n                        if (stop)\n                            break;\n                    }\n                }\n            }\n            else {\n                for (; i < length; i++) {\n                    const result = validate(instance[i], $items, draft, lookup, shortCircuit, recursiveAnchor, `${instanceLocation}/${i}`, keywordLocation);\n                    evaluated[i] = true;\n                    if (!result.valid) {\n                        stop = shortCircuit;\n                        errors.push({\n                            instanceLocation,\n                            keyword: 'items',\n                            keywordLocation,\n                            error: `Items did not match schema.`\n                        }, ...result.errors);\n                        if (stop)\n                            break;\n                    }\n                }\n            }\n            if (!stop && $additionalItems !== undefined) {\n                const keywordLocation = `${schemaLocation}/additionalItems`;\n                for (; i < length; i++) {\n                    const result = validate(instance[i], $additionalItems, draft, lookup, shortCircuit, recursiveAnchor, `${instanceLocation}/${i}`, keywordLocation);\n                    evaluated[i] = true;\n                    if (!result.valid) {\n                        stop = shortCircuit;\n                        errors.push({\n                            instanceLocation,\n                            keyword: 'additionalItems',\n                            keywordLocation,\n                            error: `Items did not match additional items schema.`\n                        }, ...result.errors);\n                    }\n                }\n            }\n        }\n        if ($contains !== undefined) {\n            if (length === 0 && $minContains === undefined) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'contains',\n                    keywordLocation: `${schemaLocation}/contains`,\n                    error: `Array is empty. It must contain at least one item matching the schema.`\n                });\n            }\n            else if ($minContains !== undefined && length < $minContains) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'minContains',\n                    keywordLocation: `${schemaLocation}/minContains`,\n                    error: `Array has less items (${length}) than minContains (${$minContains}).`\n                });\n            }\n            else {\n                const keywordLocation = `${schemaLocation}/contains`;\n                const errorsLength = errors.length;\n                let contained = 0;\n                for (let j = 0; j < length; j++) {\n                    const result = validate(instance[j], $contains, draft, lookup, shortCircuit, recursiveAnchor, `${instanceLocation}/${j}`, keywordLocation);\n                    if (result.valid) {\n                        evaluated[j] = true;\n                        contained++;\n                    }\n                    else {\n                        errors.push(...result.errors);\n                    }\n                }\n                if (contained >= ($minContains || 0)) {\n                    errors.length = errorsLength;\n                }\n                if ($minContains === undefined &&\n                    $maxContains === undefined &&\n                    contained === 0) {\n                    errors.splice(errorsLength, 0, {\n                        instanceLocation,\n                        keyword: 'contains',\n                        keywordLocation,\n                        error: `Array does not contain item matching schema.`\n                    });\n                }\n                else if ($minContains !== undefined && contained < $minContains) {\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'minContains',\n                        keywordLocation: `${schemaLocation}/minContains`,\n                        error: `Array must contain at least ${$minContains} items matching schema. Only ${contained} items were found.`\n                    });\n                }\n                else if ($maxContains !== undefined && contained > $maxContains) {\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'maxContains',\n                        keywordLocation: `${schemaLocation}/maxContains`,\n                        error: `Array may contain at most ${$maxContains} items matching schema. ${contained} items were found.`\n                    });\n                }\n            }\n        }\n        if (!stop && $unevaluatedItems !== undefined) {\n            const keywordLocation = `${schemaLocation}/unevaluatedItems`;\n            for (i; i < length; i++) {\n                if (evaluated[i]) {\n                    continue;\n                }\n                const result = validate(instance[i], $unevaluatedItems, draft, lookup, shortCircuit, recursiveAnchor, `${instanceLocation}/${i}`, keywordLocation);\n                evaluated[i] = true;\n                if (!result.valid) {\n                    errors.push({\n                        instanceLocation,\n                        keyword: 'unevaluatedItems',\n                        keywordLocation,\n                        error: `Items did not match unevaluated items schema.`\n                    }, ...result.errors);\n                }\n            }\n        }\n        if ($uniqueItems) {\n            for (let j = 0; j < length; j++) {\n                const a = instance[j];\n                const ao = typeof a === 'object' && a !== null;\n                for (let k = 0; k < length; k++) {\n                    if (j === k) {\n                        continue;\n                    }\n                    const b = instance[k];\n                    const bo = typeof b === 'object' && b !== null;\n                    if (a === b || (ao && bo && deepCompareStrict(a, b))) {\n                        errors.push({\n                            instanceLocation,\n                            keyword: 'uniqueItems',\n                            keywordLocation: `${schemaLocation}/uniqueItems`,\n                            error: `Duplicate items at indexes ${j} and ${k}.`\n                        });\n                        j = Number.MAX_SAFE_INTEGER;\n                        k = Number.MAX_SAFE_INTEGER;\n                    }\n                }\n            }\n        }\n    }\n    else if (instanceType === 'number') {\n        if (draft === '4') {\n            if ($minimum !== undefined &&\n                (($exclusiveMinimum === true && instance <= $minimum) ||\n                    instance < $minimum)) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'minimum',\n                    keywordLocation: `${schemaLocation}/minimum`,\n                    error: `${instance} is less than ${$exclusiveMinimum ? 'or equal to ' : ''} ${$minimum}.`\n                });\n            }\n            if ($maximum !== undefined &&\n                (($exclusiveMaximum === true && instance >= $maximum) ||\n                    instance > $maximum)) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'maximum',\n                    keywordLocation: `${schemaLocation}/maximum`,\n                    error: `${instance} is greater than ${$exclusiveMaximum ? 'or equal to ' : ''} ${$maximum}.`\n                });\n            }\n        }\n        else {\n            if ($minimum !== undefined && instance < $minimum) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'minimum',\n                    keywordLocation: `${schemaLocation}/minimum`,\n                    error: `${instance} is less than ${$minimum}.`\n                });\n            }\n            if ($maximum !== undefined && instance > $maximum) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'maximum',\n                    keywordLocation: `${schemaLocation}/maximum`,\n                    error: `${instance} is greater than ${$maximum}.`\n                });\n            }\n            if ($exclusiveMinimum !== undefined && instance <= $exclusiveMinimum) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'exclusiveMinimum',\n                    keywordLocation: `${schemaLocation}/exclusiveMinimum`,\n                    error: `${instance} is less than ${$exclusiveMinimum}.`\n                });\n            }\n            if ($exclusiveMaximum !== undefined && instance >= $exclusiveMaximum) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'exclusiveMaximum',\n                    keywordLocation: `${schemaLocation}/exclusiveMaximum`,\n                    error: `${instance} is greater than or equal to ${$exclusiveMaximum}.`\n                });\n            }\n        }\n        if ($multipleOf !== undefined) {\n            const remainder = instance % $multipleOf;\n            if (Math.abs(0 - remainder) >= 1.1920929e-7 &&\n                Math.abs($multipleOf - remainder) >= 1.1920929e-7) {\n                errors.push({\n                    instanceLocation,\n                    keyword: 'multipleOf',\n                    keywordLocation: `${schemaLocation}/multipleOf`,\n                    error: `${instance} is not a multiple of ${$multipleOf}.`\n                });\n            }\n        }\n    }\n    else if (instanceType === 'string') {\n        const length = $minLength === undefined && $maxLength === undefined\n            ? 0\n            : ucs2length(instance);\n        if ($minLength !== undefined && length < $minLength) {\n            errors.push({\n                instanceLocation,\n                keyword: 'minLength',\n                keywordLocation: `${schemaLocation}/minLength`,\n                error: `String is too short (${length} < ${$minLength}).`\n            });\n        }\n        if ($maxLength !== undefined && length > $maxLength) {\n            errors.push({\n                instanceLocation,\n                keyword: 'maxLength',\n                keywordLocation: `${schemaLocation}/maxLength`,\n                error: `String is too long (${length} > ${$maxLength}).`\n            });\n        }\n        if ($pattern !== undefined && !new RegExp($pattern, 'u').test(instance)) {\n            errors.push({\n                instanceLocation,\n                keyword: 'pattern',\n                keywordLocation: `${schemaLocation}/pattern`,\n                error: `String does not match pattern.`\n            });\n        }\n        if ($format !== undefined &&\n            format[$format] &&\n            !format[$format](instance)) {\n            errors.push({\n                instanceLocation,\n                keyword: 'format',\n                keywordLocation: `${schemaLocation}/format`,\n                error: `String does not match format \"${$format}\".`\n            });\n        }\n    }\n    return { valid: errors.length === 0, errors };\n}\n","import { dereference } from './dereference.js';\nimport { validate } from './validate.js';\nexport class Validator {\n    schema;\n    draft;\n    shortCircuit;\n    lookup;\n    constructor(schema, draft = '2019-09', shortCircuit = true) {\n        this.schema = schema;\n        this.draft = draft;\n        this.shortCircuit = shortCircuit;\n        this.lookup = dereference(schema);\n    }\n    validate(instance) {\n        return validate(instance, this.schema, this.draft, this.lookup, this.shortCircuit);\n    }\n    addSchema(schema, id) {\n        if (id) {\n            schema = { ...schema, $id: id };\n        }\n        dereference(schema, this.lookup);\n    }\n}\n","export * from './deep-compare-strict.js';\nexport * from './dereference.js';\nexport * from './format.js';\nexport * from './pointer.js';\nexport * from './types.js';\nexport * from './ucs2-length.js';\nexport * from './validate.js';\nexport * from './validator.js';\n","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { interopZodObjectStrict, interopZodTransformInputSchema, isZodObjectV4, isZodSchemaV3, isZodSchemaV4 } from \"./types/zod.js\";\nimport { zodToJsonSchema } from \"./zod-to-json-schema/zodToJsonSchema.js\";\nimport \"./zod-to-json-schema/index.js\";\nimport { toJSONSchema } from \"zod/v4/core\";\nimport { Validator, deepCompareStrict, dereference } from \"@cfworker/json-schema\";\n\n//#region src/utils/json_schema.ts\nvar json_schema_exports = {};\n__export(json_schema_exports, {\n\tValidator: () => Validator,\n\tdeepCompareStrict: () => deepCompareStrict,\n\ttoJsonSchema: () => toJsonSchema,\n\tvalidatesOnlyStrings: () => validatesOnlyStrings\n});\n/**\n* Converts a Zod schema or JSON schema to a JSON schema.\n* @param schema - The schema to convert.\n* @returns The converted schema.\n*/\nfunction toJsonSchema(schema) {\n\tif (isZodSchemaV4(schema)) {\n\t\tconst inputSchema = interopZodTransformInputSchema(schema, true);\n\t\tif (isZodObjectV4(inputSchema)) {\n\t\t\tconst strictSchema = interopZodObjectStrict(inputSchema, true);\n\t\t\treturn toJSONSchema(strictSchema);\n\t\t} else return toJSONSchema(schema);\n\t}\n\tif (isZodSchemaV3(schema)) return zodToJsonSchema(schema);\n\treturn schema;\n}\n/**\n* Validates if a JSON schema validates only strings. May return false negatives in some edge cases\n* (like recursive or unresolvable refs).\n*\n* @param schema - The schema to validate.\n* @returns `true` if the schema validates only strings, `false` otherwise.\n*/\nfunction validatesOnlyStrings(schema) {\n\tif (!schema || typeof schema !== \"object\" || Object.keys(schema).length === 0 || Array.isArray(schema)) return false;\n\tif (\"type\" in schema) {\n\t\tif (typeof schema.type === \"string\") return schema.type === \"string\";\n\t\tif (Array.isArray(schema.type)) return schema.type.every((t) => t === \"string\");\n\t\treturn false;\n\t}\n\tif (\"enum\" in schema) return Array.isArray(schema.enum) && schema.enum.length > 0 && schema.enum.every((val) => typeof val === \"string\");\n\tif (\"const\" in schema) return typeof schema.const === \"string\";\n\tif (\"allOf\" in schema && Array.isArray(schema.allOf)) return schema.allOf.some((subschema) => validatesOnlyStrings(subschema));\n\tif (\"anyOf\" in schema && Array.isArray(schema.anyOf) || \"oneOf\" in schema && Array.isArray(schema.oneOf)) {\n\t\tconst subschemas = \"anyOf\" in schema ? schema.anyOf : schema.oneOf;\n\t\treturn subschemas.length > 0 && subschemas.every((subschema) => validatesOnlyStrings(subschema));\n\t}\n\tif (\"not\" in schema) return false;\n\tif (\"$ref\" in schema && typeof schema.$ref === \"string\") {\n\t\tconst ref = schema.$ref;\n\t\tconst resolved = dereference(schema);\n\t\tif (resolved[ref]) return validatesOnlyStrings(resolved[ref]);\n\t\treturn false;\n\t}\n\treturn false;\n}\n\n//#endregion\nexport { Validator, deepCompareStrict, json_schema_exports, toJsonSchema, validatesOnlyStrings };\n//# sourceMappingURL=json_schema.js.map","//#region src/runnables/utils.ts\nfunction isRunnableInterface(thing) {\n\treturn thing ? thing.lc_runnable : false;\n}\n/**\n* Utility to filter the root event in the streamEvents implementation.\n* This is simply binding the arguments to the namespace to make save on\n* a bit of typing in the streamEvents implementation.\n*\n* TODO: Refactor and remove.\n*/\nvar _RootEventFilter = class {\n\tincludeNames;\n\tincludeTypes;\n\tincludeTags;\n\texcludeNames;\n\texcludeTypes;\n\texcludeTags;\n\tconstructor(fields) {\n\t\tthis.includeNames = fields.includeNames;\n\t\tthis.includeTypes = fields.includeTypes;\n\t\tthis.includeTags = fields.includeTags;\n\t\tthis.excludeNames = fields.excludeNames;\n\t\tthis.excludeTypes = fields.excludeTypes;\n\t\tthis.excludeTags = fields.excludeTags;\n\t}\n\tincludeEvent(event, rootType) {\n\t\tlet include = this.includeNames === void 0 && this.includeTypes === void 0 && this.includeTags === void 0;\n\t\tconst eventTags = event.tags ?? [];\n\t\tif (this.includeNames !== void 0) include = include || this.includeNames.includes(event.name);\n\t\tif (this.includeTypes !== void 0) include = include || this.includeTypes.includes(rootType);\n\t\tif (this.includeTags !== void 0) include = include || eventTags.some((tag) => this.includeTags?.includes(tag));\n\t\tif (this.excludeNames !== void 0) include = include && !this.excludeNames.includes(event.name);\n\t\tif (this.excludeTypes !== void 0) include = include && !this.excludeTypes.includes(rootType);\n\t\tif (this.excludeTags !== void 0) include = include && eventTags.every((tag) => !this.excludeTags?.includes(tag));\n\t\treturn include;\n\t}\n};\n\n//#endregion\nexport { _RootEventFilter, isRunnableInterface };\n//# sourceMappingURL=utils.js.map","//#region src/runnables/graph_mermaid.ts\nfunction _escapeNodeLabel(nodeLabel) {\n\treturn nodeLabel.replace(/[^a-zA-Z-_0-9]/g, \"_\");\n}\nconst MARKDOWN_SPECIAL_CHARS = [\n\t\"*\",\n\t\"_\",\n\t\"`\"\n];\nfunction _generateMermaidGraphStyles(nodeColors) {\n\tlet styles = \"\";\n\tfor (const [className, color] of Object.entries(nodeColors)) styles += `\\tclassDef ${className} ${color};\\n`;\n\treturn styles;\n}\n/**\n* Draws a Mermaid graph using the provided graph data\n*/\nfunction drawMermaid(nodes, edges, config) {\n\tconst { firstNode, lastNode, nodeColors, withStyles = true, curveStyle = \"linear\", wrapLabelNWords = 9 } = config ?? {};\n\tlet mermaidGraph = withStyles ? `%%{init: {'flowchart': {'curve': '${curveStyle}'}}}%%\\ngraph TD;\\n` : \"graph TD;\\n\";\n\tif (withStyles) {\n\t\tconst defaultClassLabel = \"default\";\n\t\tconst formatDict = { [defaultClassLabel]: \"{0}({1})\" };\n\t\tif (firstNode !== void 0) formatDict[firstNode] = \"{0}([{1}]):::first\";\n\t\tif (lastNode !== void 0) formatDict[lastNode] = \"{0}([{1}]):::last\";\n\t\tfor (const [key, node] of Object.entries(nodes)) {\n\t\t\tconst nodeName = node.name.split(\":\").pop() ?? \"\";\n\t\t\tconst label = MARKDOWN_SPECIAL_CHARS.some((char) => nodeName.startsWith(char) && nodeName.endsWith(char)) ? `<p>${nodeName}</p>` : nodeName;\n\t\t\tlet finalLabel = label;\n\t\t\tif (Object.keys(node.metadata ?? {}).length) finalLabel += `<hr/><small><em>${Object.entries(node.metadata ?? {}).map(([k, v]) => `${k} = ${v}`).join(\"\\n\")}</em></small>`;\n\t\t\tconst nodeLabel = (formatDict[key] ?? formatDict[defaultClassLabel]).replace(\"{0}\", _escapeNodeLabel(key)).replace(\"{1}\", finalLabel);\n\t\t\tmermaidGraph += `\\t${nodeLabel}\\n`;\n\t\t}\n\t}\n\tconst edgeGroups = {};\n\tfor (const edge of edges) {\n\t\tconst srcParts = edge.source.split(\":\");\n\t\tconst tgtParts = edge.target.split(\":\");\n\t\tconst commonPrefix = srcParts.filter((src, i) => src === tgtParts[i]).join(\":\");\n\t\tif (!edgeGroups[commonPrefix]) edgeGroups[commonPrefix] = [];\n\t\tedgeGroups[commonPrefix].push(edge);\n\t}\n\tconst seenSubgraphs = /* @__PURE__ */ new Set();\n\tfunction addSubgraph(edges$1, prefix) {\n\t\tconst selfLoop = edges$1.length === 1 && edges$1[0].source === edges$1[0].target;\n\t\tif (prefix && !selfLoop) {\n\t\t\tconst subgraph = prefix.split(\":\").pop();\n\t\t\tif (seenSubgraphs.has(subgraph)) throw new Error(`Found duplicate subgraph '${subgraph}' -- this likely means that you're reusing a subgraph node with the same name. Please adjust your graph to have subgraph nodes with unique names.`);\n\t\t\tseenSubgraphs.add(subgraph);\n\t\t\tmermaidGraph += `\\tsubgraph ${subgraph}\\n`;\n\t\t}\n\t\tfor (const edge of edges$1) {\n\t\t\tconst { source, target, data, conditional } = edge;\n\t\t\tlet edgeLabel = \"\";\n\t\t\tif (data !== void 0) {\n\t\t\t\tlet edgeData = data;\n\t\t\t\tconst words = edgeData.split(\" \");\n\t\t\t\tif (words.length > wrapLabelNWords) edgeData = Array.from({ length: Math.ceil(words.length / wrapLabelNWords) }, (_, i) => words.slice(i * wrapLabelNWords, (i + 1) * wrapLabelNWords).join(\" \")).join(\"&nbsp;<br>&nbsp;\");\n\t\t\t\tedgeLabel = conditional ? ` -. &nbsp;${edgeData}&nbsp; .-> ` : ` -- &nbsp;${edgeData}&nbsp; --> `;\n\t\t\t} else edgeLabel = conditional ? \" -.-> \" : \" --> \";\n\t\t\tmermaidGraph += `\\t${_escapeNodeLabel(source)}${edgeLabel}${_escapeNodeLabel(target)};\\n`;\n\t\t}\n\t\tfor (const nestedPrefix in edgeGroups) if (nestedPrefix.startsWith(`${prefix}:`) && nestedPrefix !== prefix) addSubgraph(edgeGroups[nestedPrefix], nestedPrefix);\n\t\tif (prefix && !selfLoop) mermaidGraph += \"\tend\\n\";\n\t}\n\taddSubgraph(edgeGroups[\"\"] ?? [], \"\");\n\tfor (const prefix in edgeGroups) if (!prefix.includes(\":\") && prefix !== \"\") addSubgraph(edgeGroups[prefix], prefix);\n\tif (withStyles) mermaidGraph += _generateMermaidGraphStyles(nodeColors ?? {});\n\treturn mermaidGraph;\n}\n/**\n* Renders Mermaid graph using the Mermaid.INK API.\n*\n* @example\n* ```javascript\n* const image = await drawMermaidImage(mermaidSyntax, {\n*   backgroundColor: \"white\",\n*   imageType: \"png\",\n* });\n* fs.writeFileSync(\"image.png\", image);\n* ```\n*\n* @param mermaidSyntax - The Mermaid syntax to render.\n* @param config - The configuration for the image.\n* @returns The image as a Blob.\n*/\nasync function drawMermaidImage(mermaidSyntax, config) {\n\tlet backgroundColor = config?.backgroundColor ?? \"white\";\n\tconst imageType = config?.imageType ?? \"png\";\n\tconst mermaidSyntaxEncoded = btoa(mermaidSyntax);\n\tif (backgroundColor !== void 0) {\n\t\tconst hexColorPattern = /^#(?:[0-9a-fA-F]{3}){1,2}$/;\n\t\tif (!hexColorPattern.test(backgroundColor)) backgroundColor = `!${backgroundColor}`;\n\t}\n\tconst imageUrl = `https://mermaid.ink/img/${mermaidSyntaxEncoded}?bgColor=${backgroundColor}&type=${imageType}`;\n\tconst res = await fetch(imageUrl);\n\tif (!res.ok) throw new Error([\n\t\t`Failed to render the graph using the Mermaid.INK API.`,\n\t\t`Status code: ${res.status}`,\n\t\t`Status text: ${res.statusText}`\n\t].join(\"\\n\"));\n\tconst content = await res.blob();\n\treturn content;\n}\n\n//#endregion\nexport { drawMermaid, drawMermaidImage };\n//# sourceMappingURL=graph_mermaid.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { isRunnableInterface } from \"./utils.js\";\nimport { drawMermaid, drawMermaidImage } from \"./graph_mermaid.js\";\nimport { toJsonSchema } from \"../utils/json_schema.js\";\nimport { v4, validate } from \"uuid\";\n\n//#region src/runnables/graph.ts\nvar graph_exports = {};\n__export(graph_exports, { Graph: () => Graph });\nfunction nodeDataStr(id, data) {\n\tif (id !== void 0 && !validate(id)) return id;\n\telse if (isRunnableInterface(data)) try {\n\t\tlet dataStr = data.getName();\n\t\tdataStr = dataStr.startsWith(\"Runnable\") ? dataStr.slice(8) : dataStr;\n\t\treturn dataStr;\n\t} catch {\n\t\treturn data.getName();\n\t}\n\telse return data.name ?? \"UnknownSchema\";\n}\nfunction nodeDataJson(node) {\n\tif (isRunnableInterface(node.data)) return {\n\t\ttype: \"runnable\",\n\t\tdata: {\n\t\t\tid: node.data.lc_id,\n\t\t\tname: node.data.getName()\n\t\t}\n\t};\n\telse return {\n\t\ttype: \"schema\",\n\t\tdata: {\n\t\t\t...toJsonSchema(node.data.schema),\n\t\t\ttitle: node.data.name\n\t\t}\n\t};\n}\nvar Graph = class Graph {\n\tnodes = {};\n\tedges = [];\n\tconstructor(params) {\n\t\tthis.nodes = params?.nodes ?? this.nodes;\n\t\tthis.edges = params?.edges ?? this.edges;\n\t}\n\ttoJSON() {\n\t\tconst stableNodeIds = {};\n\t\tObject.values(this.nodes).forEach((node, i) => {\n\t\t\tstableNodeIds[node.id] = validate(node.id) ? i : node.id;\n\t\t});\n\t\treturn {\n\t\t\tnodes: Object.values(this.nodes).map((node) => ({\n\t\t\t\tid: stableNodeIds[node.id],\n\t\t\t\t...nodeDataJson(node)\n\t\t\t})),\n\t\t\tedges: this.edges.map((edge) => {\n\t\t\t\tconst item = {\n\t\t\t\t\tsource: stableNodeIds[edge.source],\n\t\t\t\t\ttarget: stableNodeIds[edge.target]\n\t\t\t\t};\n\t\t\t\tif (typeof edge.data !== \"undefined\") item.data = edge.data;\n\t\t\t\tif (typeof edge.conditional !== \"undefined\") item.conditional = edge.conditional;\n\t\t\t\treturn item;\n\t\t\t})\n\t\t};\n\t}\n\taddNode(data, id, metadata) {\n\t\tif (id !== void 0 && this.nodes[id] !== void 0) throw new Error(`Node with id ${id} already exists`);\n\t\tconst nodeId = id ?? v4();\n\t\tconst node = {\n\t\t\tid: nodeId,\n\t\t\tdata,\n\t\t\tname: nodeDataStr(id, data),\n\t\t\tmetadata\n\t\t};\n\t\tthis.nodes[nodeId] = node;\n\t\treturn node;\n\t}\n\tremoveNode(node) {\n\t\tdelete this.nodes[node.id];\n\t\tthis.edges = this.edges.filter((edge) => edge.source !== node.id && edge.target !== node.id);\n\t}\n\taddEdge(source, target, data, conditional) {\n\t\tif (this.nodes[source.id] === void 0) throw new Error(`Source node ${source.id} not in graph`);\n\t\tif (this.nodes[target.id] === void 0) throw new Error(`Target node ${target.id} not in graph`);\n\t\tconst edge = {\n\t\t\tsource: source.id,\n\t\t\ttarget: target.id,\n\t\t\tdata,\n\t\t\tconditional\n\t\t};\n\t\tthis.edges.push(edge);\n\t\treturn edge;\n\t}\n\tfirstNode() {\n\t\treturn _firstNode(this);\n\t}\n\tlastNode() {\n\t\treturn _lastNode(this);\n\t}\n\t/**\n\t* Add all nodes and edges from another graph.\n\t* Note this doesn't check for duplicates, nor does it connect the graphs.\n\t*/\n\textend(graph, prefix = \"\") {\n\t\tlet finalPrefix = prefix;\n\t\tconst nodeIds = Object.values(graph.nodes).map((node) => node.id);\n\t\tif (nodeIds.every(validate)) finalPrefix = \"\";\n\t\tconst prefixed = (id) => {\n\t\t\treturn finalPrefix ? `${finalPrefix}:${id}` : id;\n\t\t};\n\t\tObject.entries(graph.nodes).forEach(([key, value]) => {\n\t\t\tthis.nodes[prefixed(key)] = {\n\t\t\t\t...value,\n\t\t\t\tid: prefixed(key)\n\t\t\t};\n\t\t});\n\t\tconst newEdges = graph.edges.map((edge) => {\n\t\t\treturn {\n\t\t\t\t...edge,\n\t\t\t\tsource: prefixed(edge.source),\n\t\t\t\ttarget: prefixed(edge.target)\n\t\t\t};\n\t\t});\n\t\tthis.edges = [...this.edges, ...newEdges];\n\t\tconst first = graph.firstNode();\n\t\tconst last = graph.lastNode();\n\t\treturn [first ? {\n\t\t\tid: prefixed(first.id),\n\t\t\tdata: first.data\n\t\t} : void 0, last ? {\n\t\t\tid: prefixed(last.id),\n\t\t\tdata: last.data\n\t\t} : void 0];\n\t}\n\ttrimFirstNode() {\n\t\tconst firstNode = this.firstNode();\n\t\tif (firstNode && _firstNode(this, [firstNode.id])) this.removeNode(firstNode);\n\t}\n\ttrimLastNode() {\n\t\tconst lastNode = this.lastNode();\n\t\tif (lastNode && _lastNode(this, [lastNode.id])) this.removeNode(lastNode);\n\t}\n\t/**\n\t* Return a new graph with all nodes re-identified,\n\t* using their unique, readable names where possible.\n\t*/\n\treid() {\n\t\tconst nodeLabels = Object.fromEntries(Object.values(this.nodes).map((node) => [node.id, node.name]));\n\t\tconst nodeLabelCounts = /* @__PURE__ */ new Map();\n\t\tObject.values(nodeLabels).forEach((label) => {\n\t\t\tnodeLabelCounts.set(label, (nodeLabelCounts.get(label) || 0) + 1);\n\t\t});\n\t\tconst getNodeId = (nodeId) => {\n\t\t\tconst label = nodeLabels[nodeId];\n\t\t\tif (validate(nodeId) && nodeLabelCounts.get(label) === 1) return label;\n\t\t\telse return nodeId;\n\t\t};\n\t\treturn new Graph({\n\t\t\tnodes: Object.fromEntries(Object.entries(this.nodes).map(([id, node]) => [getNodeId(id), {\n\t\t\t\t...node,\n\t\t\t\tid: getNodeId(id)\n\t\t\t}])),\n\t\t\tedges: this.edges.map((edge) => ({\n\t\t\t\t...edge,\n\t\t\t\tsource: getNodeId(edge.source),\n\t\t\t\ttarget: getNodeId(edge.target)\n\t\t\t}))\n\t\t});\n\t}\n\tdrawMermaid(params) {\n\t\tconst { withStyles, curveStyle, nodeColors = {\n\t\t\tdefault: \"fill:#f2f0ff,line-height:1.2\",\n\t\t\tfirst: \"fill-opacity:0\",\n\t\t\tlast: \"fill:#bfb6fc\"\n\t\t}, wrapLabelNWords } = params ?? {};\n\t\tconst graph = this.reid();\n\t\tconst firstNode = graph.firstNode();\n\t\tconst lastNode = graph.lastNode();\n\t\treturn drawMermaid(graph.nodes, graph.edges, {\n\t\t\tfirstNode: firstNode?.id,\n\t\t\tlastNode: lastNode?.id,\n\t\t\twithStyles,\n\t\t\tcurveStyle,\n\t\t\tnodeColors,\n\t\t\twrapLabelNWords\n\t\t});\n\t}\n\tasync drawMermaidPng(params) {\n\t\tconst mermaidSyntax = this.drawMermaid(params);\n\t\treturn drawMermaidImage(mermaidSyntax, { backgroundColor: params?.backgroundColor });\n\t}\n};\n/**\n* Find the single node that is not a target of any edge.\n* Exclude nodes/sources with ids in the exclude list.\n* If there is no such node, or there are multiple, return undefined.\n* When drawing the graph, this node would be the origin.\n*/\nfunction _firstNode(graph, exclude = []) {\n\tconst targets = new Set(graph.edges.filter((edge) => !exclude.includes(edge.source)).map((edge) => edge.target));\n\tconst found = [];\n\tfor (const node of Object.values(graph.nodes)) if (!exclude.includes(node.id) && !targets.has(node.id)) found.push(node);\n\treturn found.length === 1 ? found[0] : void 0;\n}\n/**\n* Find the single node that is not a source of any edge.\n* Exclude nodes/targets with ids in the exclude list.\n* If there is no such node, or there are multiple, return undefined.\n* When drawing the graph, this node would be the destination.\n*/\nfunction _lastNode(graph, exclude = []) {\n\tconst sources = new Set(graph.edges.filter((edge) => !exclude.includes(edge.target)).map((edge) => edge.source));\n\tconst found = [];\n\tfor (const node of Object.values(graph.nodes)) if (!exclude.includes(node.id) && !sources.has(node.id)) found.push(node);\n\treturn found.length === 1 ? found[0] : void 0;\n}\n\n//#endregion\nexport { Graph, graph_exports };\n//# sourceMappingURL=graph.js.map","import { AIMessageChunk } from \"../messages/ai.js\";\nimport { BaseTracer } from \"./base.js\";\nimport { IterableReadableStream } from \"../utils/stream.js\";\nimport { GenerationChunk } from \"../outputs.js\";\n\n//#region src/tracers/event_stream.ts\nfunction assignName({ name, serialized }) {\n\tif (name !== void 0) return name;\n\tif (serialized?.name !== void 0) return serialized.name;\n\telse if (serialized?.id !== void 0 && Array.isArray(serialized?.id)) return serialized.id[serialized.id.length - 1];\n\treturn \"Unnamed\";\n}\nconst isStreamEventsHandler = (handler) => handler.name === \"event_stream_tracer\";\n/**\n* Class that extends the `BaseTracer` class from the\n* `langchain.callbacks.tracers.base` module. It represents a callback\n* handler that logs the execution of runs and emits `RunLog` instances to a\n* `RunLogStream`.\n*/\nvar EventStreamCallbackHandler = class extends BaseTracer {\n\tautoClose = true;\n\tincludeNames;\n\tincludeTypes;\n\tincludeTags;\n\texcludeNames;\n\texcludeTypes;\n\texcludeTags;\n\trunInfoMap = /* @__PURE__ */ new Map();\n\ttappedPromises = /* @__PURE__ */ new Map();\n\ttransformStream;\n\twriter;\n\treceiveStream;\n\tname = \"event_stream_tracer\";\n\tlc_prefer_streaming = true;\n\tconstructor(fields) {\n\t\tsuper({\n\t\t\t_awaitHandler: true,\n\t\t\t...fields\n\t\t});\n\t\tthis.autoClose = fields?.autoClose ?? true;\n\t\tthis.includeNames = fields?.includeNames;\n\t\tthis.includeTypes = fields?.includeTypes;\n\t\tthis.includeTags = fields?.includeTags;\n\t\tthis.excludeNames = fields?.excludeNames;\n\t\tthis.excludeTypes = fields?.excludeTypes;\n\t\tthis.excludeTags = fields?.excludeTags;\n\t\tthis.transformStream = new TransformStream();\n\t\tthis.writer = this.transformStream.writable.getWriter();\n\t\tthis.receiveStream = IterableReadableStream.fromReadableStream(this.transformStream.readable);\n\t}\n\t[Symbol.asyncIterator]() {\n\t\treturn this.receiveStream;\n\t}\n\tasync persistRun(_run) {}\n\t_includeRun(run) {\n\t\tconst runTags = run.tags ?? [];\n\t\tlet include = this.includeNames === void 0 && this.includeTags === void 0 && this.includeTypes === void 0;\n\t\tif (this.includeNames !== void 0) include = include || this.includeNames.includes(run.name);\n\t\tif (this.includeTypes !== void 0) include = include || this.includeTypes.includes(run.runType);\n\t\tif (this.includeTags !== void 0) include = include || runTags.find((tag) => this.includeTags?.includes(tag)) !== void 0;\n\t\tif (this.excludeNames !== void 0) include = include && !this.excludeNames.includes(run.name);\n\t\tif (this.excludeTypes !== void 0) include = include && !this.excludeTypes.includes(run.runType);\n\t\tif (this.excludeTags !== void 0) include = include && runTags.every((tag) => !this.excludeTags?.includes(tag));\n\t\treturn include;\n\t}\n\tasync *tapOutputIterable(runId, outputStream) {\n\t\tconst firstChunk = await outputStream.next();\n\t\tif (firstChunk.done) return;\n\t\tconst runInfo = this.runInfoMap.get(runId);\n\t\tif (runInfo === void 0) {\n\t\t\tyield firstChunk.value;\n\t\t\treturn;\n\t\t}\n\t\tfunction _formatOutputChunk(eventType, data) {\n\t\t\tif (eventType === \"llm\" && typeof data === \"string\") return new GenerationChunk({ text: data });\n\t\t\treturn data;\n\t\t}\n\t\tlet tappedPromise = this.tappedPromises.get(runId);\n\t\tif (tappedPromise === void 0) {\n\t\t\tlet tappedPromiseResolver;\n\t\t\ttappedPromise = new Promise((resolve) => {\n\t\t\t\ttappedPromiseResolver = resolve;\n\t\t\t});\n\t\t\tthis.tappedPromises.set(runId, tappedPromise);\n\t\t\ttry {\n\t\t\t\tconst event = {\n\t\t\t\t\tevent: `on_${runInfo.runType}_stream`,\n\t\t\t\t\trun_id: runId,\n\t\t\t\t\tname: runInfo.name,\n\t\t\t\t\ttags: runInfo.tags,\n\t\t\t\t\tmetadata: runInfo.metadata,\n\t\t\t\t\tdata: {}\n\t\t\t\t};\n\t\t\t\tawait this.send({\n\t\t\t\t\t...event,\n\t\t\t\t\tdata: { chunk: _formatOutputChunk(runInfo.runType, firstChunk.value) }\n\t\t\t\t}, runInfo);\n\t\t\t\tyield firstChunk.value;\n\t\t\t\tfor await (const chunk of outputStream) {\n\t\t\t\t\tif (runInfo.runType !== \"tool\" && runInfo.runType !== \"retriever\") await this.send({\n\t\t\t\t\t\t...event,\n\t\t\t\t\t\tdata: { chunk: _formatOutputChunk(runInfo.runType, chunk) }\n\t\t\t\t\t}, runInfo);\n\t\t\t\t\tyield chunk;\n\t\t\t\t}\n\t\t\t} finally {\n\t\t\t\ttappedPromiseResolver?.();\n\t\t\t}\n\t\t} else {\n\t\t\tyield firstChunk.value;\n\t\t\tfor await (const chunk of outputStream) yield chunk;\n\t\t}\n\t}\n\tasync send(payload, run) {\n\t\tif (this._includeRun(run)) await this.writer.write(payload);\n\t}\n\tasync sendEndEvent(payload, run) {\n\t\tconst tappedPromise = this.tappedPromises.get(payload.run_id);\n\t\tif (tappedPromise !== void 0) tappedPromise.then(() => {\n\t\t\tthis.send(payload, run);\n\t\t});\n\t\telse await this.send(payload, run);\n\t}\n\tasync onLLMStart(run) {\n\t\tconst runName = assignName(run);\n\t\tconst runType = run.inputs.messages !== void 0 ? \"chat_model\" : \"llm\";\n\t\tconst runInfo = {\n\t\t\ttags: run.tags ?? [],\n\t\t\tmetadata: run.extra?.metadata ?? {},\n\t\t\tname: runName,\n\t\t\trunType,\n\t\t\tinputs: run.inputs\n\t\t};\n\t\tthis.runInfoMap.set(run.id, runInfo);\n\t\tconst eventName = `on_${runType}_start`;\n\t\tawait this.send({\n\t\t\tevent: eventName,\n\t\t\tdata: { input: run.inputs },\n\t\t\tname: runName,\n\t\t\ttags: run.tags ?? [],\n\t\t\trun_id: run.id,\n\t\t\tmetadata: run.extra?.metadata ?? {}\n\t\t}, runInfo);\n\t}\n\tasync onLLMNewToken(run, token, kwargs) {\n\t\tconst runInfo = this.runInfoMap.get(run.id);\n\t\tlet chunk;\n\t\tlet eventName;\n\t\tif (runInfo === void 0) throw new Error(`onLLMNewToken: Run ID ${run.id} not found in run map.`);\n\t\tif (this.runInfoMap.size === 1) return;\n\t\tif (runInfo.runType === \"chat_model\") {\n\t\t\teventName = \"on_chat_model_stream\";\n\t\t\tif (kwargs?.chunk === void 0) chunk = new AIMessageChunk({\n\t\t\t\tcontent: token,\n\t\t\t\tid: `run-${run.id}`\n\t\t\t});\n\t\t\telse chunk = kwargs.chunk.message;\n\t\t} else if (runInfo.runType === \"llm\") {\n\t\t\teventName = \"on_llm_stream\";\n\t\t\tif (kwargs?.chunk === void 0) chunk = new GenerationChunk({ text: token });\n\t\t\telse chunk = kwargs.chunk;\n\t\t} else throw new Error(`Unexpected run type ${runInfo.runType}`);\n\t\tawait this.send({\n\t\t\tevent: eventName,\n\t\t\tdata: { chunk },\n\t\t\trun_id: run.id,\n\t\t\tname: runInfo.name,\n\t\t\ttags: runInfo.tags,\n\t\t\tmetadata: runInfo.metadata\n\t\t}, runInfo);\n\t}\n\tasync onLLMEnd(run) {\n\t\tconst runInfo = this.runInfoMap.get(run.id);\n\t\tthis.runInfoMap.delete(run.id);\n\t\tlet eventName;\n\t\tif (runInfo === void 0) throw new Error(`onLLMEnd: Run ID ${run.id} not found in run map.`);\n\t\tconst generations = run.outputs?.generations;\n\t\tlet output;\n\t\tif (runInfo.runType === \"chat_model\") {\n\t\t\tfor (const generation of generations ?? []) {\n\t\t\t\tif (output !== void 0) break;\n\t\t\t\toutput = generation[0]?.message;\n\t\t\t}\n\t\t\teventName = \"on_chat_model_end\";\n\t\t} else if (runInfo.runType === \"llm\") {\n\t\t\toutput = {\n\t\t\t\tgenerations: generations?.map((generation) => {\n\t\t\t\t\treturn generation.map((chunk) => {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\ttext: chunk.text,\n\t\t\t\t\t\t\tgenerationInfo: chunk.generationInfo\n\t\t\t\t\t\t};\n\t\t\t\t\t});\n\t\t\t\t}),\n\t\t\t\tllmOutput: run.outputs?.llmOutput ?? {}\n\t\t\t};\n\t\t\teventName = \"on_llm_end\";\n\t\t} else throw new Error(`onLLMEnd: Unexpected run type: ${runInfo.runType}`);\n\t\tawait this.sendEndEvent({\n\t\t\tevent: eventName,\n\t\t\tdata: {\n\t\t\t\toutput,\n\t\t\t\tinput: runInfo.inputs\n\t\t\t},\n\t\t\trun_id: run.id,\n\t\t\tname: runInfo.name,\n\t\t\ttags: runInfo.tags,\n\t\t\tmetadata: runInfo.metadata\n\t\t}, runInfo);\n\t}\n\tasync onChainStart(run) {\n\t\tconst runName = assignName(run);\n\t\tconst runType = run.run_type ?? \"chain\";\n\t\tconst runInfo = {\n\t\t\ttags: run.tags ?? [],\n\t\t\tmetadata: run.extra?.metadata ?? {},\n\t\t\tname: runName,\n\t\t\trunType: run.run_type\n\t\t};\n\t\tlet eventData = {};\n\t\tif (run.inputs.input === \"\" && Object.keys(run.inputs).length === 1) {\n\t\t\teventData = {};\n\t\t\trunInfo.inputs = {};\n\t\t} else if (run.inputs.input !== void 0) {\n\t\t\teventData.input = run.inputs.input;\n\t\t\trunInfo.inputs = run.inputs.input;\n\t\t} else {\n\t\t\teventData.input = run.inputs;\n\t\t\trunInfo.inputs = run.inputs;\n\t\t}\n\t\tthis.runInfoMap.set(run.id, runInfo);\n\t\tawait this.send({\n\t\t\tevent: `on_${runType}_start`,\n\t\t\tdata: eventData,\n\t\t\tname: runName,\n\t\t\ttags: run.tags ?? [],\n\t\t\trun_id: run.id,\n\t\t\tmetadata: run.extra?.metadata ?? {}\n\t\t}, runInfo);\n\t}\n\tasync onChainEnd(run) {\n\t\tconst runInfo = this.runInfoMap.get(run.id);\n\t\tthis.runInfoMap.delete(run.id);\n\t\tif (runInfo === void 0) throw new Error(`onChainEnd: Run ID ${run.id} not found in run map.`);\n\t\tconst eventName = `on_${run.run_type}_end`;\n\t\tconst inputs = run.inputs ?? runInfo.inputs ?? {};\n\t\tconst outputs = run.outputs?.output ?? run.outputs;\n\t\tconst data = {\n\t\t\toutput: outputs,\n\t\t\tinput: inputs\n\t\t};\n\t\tif (inputs.input && Object.keys(inputs).length === 1) {\n\t\t\tdata.input = inputs.input;\n\t\t\trunInfo.inputs = inputs.input;\n\t\t}\n\t\tawait this.sendEndEvent({\n\t\t\tevent: eventName,\n\t\t\tdata,\n\t\t\trun_id: run.id,\n\t\t\tname: runInfo.name,\n\t\t\ttags: runInfo.tags,\n\t\t\tmetadata: runInfo.metadata ?? {}\n\t\t}, runInfo);\n\t}\n\tasync onToolStart(run) {\n\t\tconst runName = assignName(run);\n\t\tconst runInfo = {\n\t\t\ttags: run.tags ?? [],\n\t\t\tmetadata: run.extra?.metadata ?? {},\n\t\t\tname: runName,\n\t\t\trunType: \"tool\",\n\t\t\tinputs: run.inputs ?? {}\n\t\t};\n\t\tthis.runInfoMap.set(run.id, runInfo);\n\t\tawait this.send({\n\t\t\tevent: \"on_tool_start\",\n\t\t\tdata: { input: run.inputs ?? {} },\n\t\t\tname: runName,\n\t\t\trun_id: run.id,\n\t\t\ttags: run.tags ?? [],\n\t\t\tmetadata: run.extra?.metadata ?? {}\n\t\t}, runInfo);\n\t}\n\tasync onToolEnd(run) {\n\t\tconst runInfo = this.runInfoMap.get(run.id);\n\t\tthis.runInfoMap.delete(run.id);\n\t\tif (runInfo === void 0) throw new Error(`onToolEnd: Run ID ${run.id} not found in run map.`);\n\t\tif (runInfo.inputs === void 0) throw new Error(`onToolEnd: Run ID ${run.id} is a tool call, and is expected to have traced inputs.`);\n\t\tconst output = run.outputs?.output === void 0 ? run.outputs : run.outputs.output;\n\t\tawait this.sendEndEvent({\n\t\t\tevent: \"on_tool_end\",\n\t\t\tdata: {\n\t\t\t\toutput,\n\t\t\t\tinput: runInfo.inputs\n\t\t\t},\n\t\t\trun_id: run.id,\n\t\t\tname: runInfo.name,\n\t\t\ttags: runInfo.tags,\n\t\t\tmetadata: runInfo.metadata\n\t\t}, runInfo);\n\t}\n\tasync onRetrieverStart(run) {\n\t\tconst runName = assignName(run);\n\t\tconst runType = \"retriever\";\n\t\tconst runInfo = {\n\t\t\ttags: run.tags ?? [],\n\t\t\tmetadata: run.extra?.metadata ?? {},\n\t\t\tname: runName,\n\t\t\trunType,\n\t\t\tinputs: { query: run.inputs.query }\n\t\t};\n\t\tthis.runInfoMap.set(run.id, runInfo);\n\t\tawait this.send({\n\t\t\tevent: \"on_retriever_start\",\n\t\t\tdata: { input: { query: run.inputs.query } },\n\t\t\tname: runName,\n\t\t\ttags: run.tags ?? [],\n\t\t\trun_id: run.id,\n\t\t\tmetadata: run.extra?.metadata ?? {}\n\t\t}, runInfo);\n\t}\n\tasync onRetrieverEnd(run) {\n\t\tconst runInfo = this.runInfoMap.get(run.id);\n\t\tthis.runInfoMap.delete(run.id);\n\t\tif (runInfo === void 0) throw new Error(`onRetrieverEnd: Run ID ${run.id} not found in run map.`);\n\t\tawait this.sendEndEvent({\n\t\t\tevent: \"on_retriever_end\",\n\t\t\tdata: {\n\t\t\t\toutput: run.outputs?.documents ?? run.outputs,\n\t\t\t\tinput: runInfo.inputs\n\t\t\t},\n\t\t\trun_id: run.id,\n\t\t\tname: runInfo.name,\n\t\t\ttags: runInfo.tags,\n\t\t\tmetadata: runInfo.metadata\n\t\t}, runInfo);\n\t}\n\tasync handleCustomEvent(eventName, data, runId) {\n\t\tconst runInfo = this.runInfoMap.get(runId);\n\t\tif (runInfo === void 0) throw new Error(`handleCustomEvent: Run ID ${runId} not found in run map.`);\n\t\tawait this.send({\n\t\t\tevent: \"on_custom_event\",\n\t\t\trun_id: runId,\n\t\t\tname: eventName,\n\t\t\ttags: runInfo.tags,\n\t\t\tmetadata: runInfo.metadata,\n\t\t\tdata\n\t\t}, runInfo);\n\t}\n\tasync finish() {\n\t\tconst pendingPromises = [...this.tappedPromises.values()];\n\t\tPromise.all(pendingPromises).finally(() => {\n\t\t\tthis.writer.close();\n\t\t});\n\t}\n};\n\n//#endregion\nexport { EventStreamCallbackHandler, isStreamEventsHandler };\n//# sourceMappingURL=event_stream.js.map","import { BaseTracer } from \"./base.js\";\n\n//#region src/tracers/root_listener.ts\nvar RootListenersTracer = class extends BaseTracer {\n\tname = \"RootListenersTracer\";\n\t/** The Run's ID. Type UUID */\n\trootId;\n\tconfig;\n\targOnStart;\n\targOnEnd;\n\targOnError;\n\tconstructor({ config, onStart, onEnd, onError }) {\n\t\tsuper({ _awaitHandler: true });\n\t\tthis.config = config;\n\t\tthis.argOnStart = onStart;\n\t\tthis.argOnEnd = onEnd;\n\t\tthis.argOnError = onError;\n\t}\n\t/**\n\t* This is a legacy method only called once for an entire run tree\n\t* therefore not useful here\n\t* @param {Run} _ Not used\n\t*/\n\tpersistRun(_) {\n\t\treturn Promise.resolve();\n\t}\n\tasync onRunCreate(run) {\n\t\tif (this.rootId) return;\n\t\tthis.rootId = run.id;\n\t\tif (this.argOnStart) await this.argOnStart(run, this.config);\n\t}\n\tasync onRunUpdate(run) {\n\t\tif (run.id !== this.rootId) return;\n\t\tif (!run.error) {\n\t\t\tif (this.argOnEnd) await this.argOnEnd(run, this.config);\n\t\t} else if (this.argOnError) await this.argOnError(run, this.config);\n\t}\n};\n\n//#endregion\nexport { RootListenersTracer };\n//# sourceMappingURL=root_listener.js.map","import { IterableReadableStream } from \"../utils/stream.js\";\n\n//#region src/runnables/wrappers.ts\nfunction convertToHttpEventStream(stream) {\n\tconst encoder = new TextEncoder();\n\tconst finalStream = new ReadableStream({ async start(controller) {\n\t\tfor await (const chunk of stream) controller.enqueue(encoder.encode(`event: data\\ndata: ${JSON.stringify(chunk)}\\n\\n`));\n\t\tcontroller.enqueue(encoder.encode(\"event: end\\n\\n\"));\n\t\tcontroller.close();\n\t} });\n\treturn IterableReadableStream.fromReadableStream(finalStream);\n}\n\n//#endregion\nexport { convertToHttpEventStream };\n//# sourceMappingURL=wrappers.js.map","import { AsyncLocalStorageProviderSingleton } from \"../singletons/async_local_storage/index.js\";\nimport \"../singletons/index.js\";\nimport { pickRunnableConfigKeys } from \"./config.js\";\n\n//#region src/runnables/iter.ts\nfunction isIterableIterator(thing) {\n\treturn typeof thing === \"object\" && thing !== null && typeof thing[Symbol.iterator] === \"function\" && typeof thing.next === \"function\";\n}\nconst isIterator = (x) => x != null && typeof x === \"object\" && \"next\" in x && typeof x.next === \"function\";\nfunction isAsyncIterable(thing) {\n\treturn typeof thing === \"object\" && thing !== null && typeof thing[Symbol.asyncIterator] === \"function\";\n}\nfunction* consumeIteratorInContext(context, iter) {\n\twhile (true) {\n\t\tconst { value, done } = AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(context), iter.next.bind(iter), true);\n\t\tif (done) break;\n\t\telse yield value;\n\t}\n}\nasync function* consumeAsyncIterableInContext(context, iter) {\n\tconst iterator = iter[Symbol.asyncIterator]();\n\twhile (true) {\n\t\tconst { value, done } = await AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(context), iterator.next.bind(iter), true);\n\t\tif (done) break;\n\t\telse yield value;\n\t}\n}\n\n//#endregion\nexport { consumeAsyncIterableInContext, consumeIteratorInContext, isAsyncIterable, isIterableIterator, isIterator };\n//# sourceMappingURL=iter.js.map","import { Serializable } from \"../load/serializable.js\";\nimport { ToolInputParsingException, _isToolCall } from \"../tools/utils.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"../singletons/async_local_storage/index.js\";\nimport \"../singletons/index.js\";\nimport { DEFAULT_RECURSION_LIMIT, ensureConfig, getCallbackManagerForConfig, mergeConfigs, patchConfig, pickRunnableConfigKeys } from \"./config.js\";\nimport { getAbortSignalError, raceWithSignal } from \"../utils/signal.js\";\nimport { AsyncGeneratorWithSetup, IterableReadableStream, atee, concat, pipeGeneratorWithSetup } from \"../utils/stream.js\";\nimport { LogStreamCallbackHandler, RunLog, RunLogPatch, isLogStreamHandler } from \"../tracers/log_stream.js\";\nimport { EventStreamCallbackHandler, isStreamEventsHandler } from \"../tracers/event_stream.js\";\nimport { AsyncCaller } from \"../utils/async_caller.js\";\nimport { RootListenersTracer } from \"../tracers/root_listener.js\";\nimport { _RootEventFilter, isRunnableInterface } from \"./utils.js\";\nimport { getSchemaDescription, interopParseAsync, isSimpleStringZodSchema } from \"../utils/types/zod.js\";\nimport { Graph } from \"./graph.js\";\nimport { convertToHttpEventStream } from \"./wrappers.js\";\nimport { consumeAsyncIterableInContext, consumeIteratorInContext, isAsyncIterable, isIterableIterator, isIterator } from \"./iter.js\";\nimport { z } from \"zod/v3\";\nimport pRetry from \"p-retry\";\nimport { v4 } from \"uuid\";\nimport { isTraceableFunction } from \"langsmith/singletons/traceable\";\n\n//#region src/runnables/base.ts\nfunction _coerceToDict(value, defaultKey) {\n\treturn value && !Array.isArray(value) && !(value instanceof Date) && typeof value === \"object\" ? value : { [defaultKey]: value };\n}\n/**\n* A Runnable is a generic unit of work that can be invoked, batched, streamed, and/or\n* transformed.\n*/\nvar Runnable = class extends Serializable {\n\tlc_runnable = true;\n\tname;\n\tgetName(suffix) {\n\t\tconst name = this.name ?? this.constructor.lc_name() ?? this.constructor.name;\n\t\treturn suffix ? `${name}${suffix}` : name;\n\t}\n\t/**\n\t* Add retry logic to an existing runnable.\n\t* @param fields.stopAfterAttempt The number of attempts to retry.\n\t* @param fields.onFailedAttempt A function that is called when a retry fails.\n\t* @returns A new RunnableRetry that, when invoked, will retry according to the parameters.\n\t*/\n\twithRetry(fields) {\n\t\treturn new RunnableRetry({\n\t\t\tbound: this,\n\t\t\tkwargs: {},\n\t\t\tconfig: {},\n\t\t\tmaxAttemptNumber: fields?.stopAfterAttempt,\n\t\t\t...fields\n\t\t});\n\t}\n\t/**\n\t* Bind config to a Runnable, returning a new Runnable.\n\t* @param config New configuration parameters to attach to the new runnable.\n\t* @returns A new RunnableBinding with a config matching what's passed.\n\t*/\n\twithConfig(config) {\n\t\treturn new RunnableBinding({\n\t\t\tbound: this,\n\t\t\tconfig,\n\t\t\tkwargs: {}\n\t\t});\n\t}\n\t/**\n\t* Create a new runnable from the current one that will try invoking\n\t* other passed fallback runnables if the initial invocation fails.\n\t* @param fields.fallbacks Other runnables to call if the runnable errors.\n\t* @returns A new RunnableWithFallbacks.\n\t*/\n\twithFallbacks(fields) {\n\t\tconst fallbacks = Array.isArray(fields) ? fields : fields.fallbacks;\n\t\treturn new RunnableWithFallbacks({\n\t\t\trunnable: this,\n\t\t\tfallbacks\n\t\t});\n\t}\n\t_getOptionsList(options, length = 0) {\n\t\tif (Array.isArray(options) && options.length !== length) throw new Error(`Passed \"options\" must be an array with the same length as the inputs, but got ${options.length} options for ${length} inputs`);\n\t\tif (Array.isArray(options)) return options.map(ensureConfig);\n\t\tif (length > 1 && !Array.isArray(options) && options.runId) {\n\t\t\tconsole.warn(\"Provided runId will be used only for the first element of the batch.\");\n\t\t\tconst subsequent = Object.fromEntries(Object.entries(options).filter(([key]) => key !== \"runId\"));\n\t\t\treturn Array.from({ length }, (_, i) => ensureConfig(i === 0 ? options : subsequent));\n\t\t}\n\t\treturn Array.from({ length }, () => ensureConfig(options));\n\t}\n\tasync batch(inputs, options, batchOptions) {\n\t\tconst configList = this._getOptionsList(options ?? {}, inputs.length);\n\t\tconst maxConcurrency = configList[0]?.maxConcurrency ?? batchOptions?.maxConcurrency;\n\t\tconst caller = new AsyncCaller({\n\t\t\tmaxConcurrency,\n\t\t\tonFailedAttempt: (e) => {\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t});\n\t\tconst batchCalls = inputs.map((input, i) => caller.call(async () => {\n\t\t\ttry {\n\t\t\t\tconst result = await this.invoke(input, configList[i]);\n\t\t\t\treturn result;\n\t\t\t} catch (e) {\n\t\t\t\tif (batchOptions?.returnExceptions) return e;\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}));\n\t\treturn Promise.all(batchCalls);\n\t}\n\t/**\n\t* Default streaming implementation.\n\t* Subclasses should override this method if they support streaming output.\n\t* @param input\n\t* @param options\n\t*/\n\tasync *_streamIterator(input, options) {\n\t\tyield this.invoke(input, options);\n\t}\n\t/**\n\t* Stream output in chunks.\n\t* @param input\n\t* @param options\n\t* @returns A readable stream that is also an iterable.\n\t*/\n\tasync stream(input, options) {\n\t\tconst config = ensureConfig(options);\n\t\tconst wrappedGenerator = new AsyncGeneratorWithSetup({\n\t\t\tgenerator: this._streamIterator(input, config),\n\t\t\tconfig\n\t\t});\n\t\tawait wrappedGenerator.setup;\n\t\treturn IterableReadableStream.fromAsyncGenerator(wrappedGenerator);\n\t}\n\t_separateRunnableConfigFromCallOptions(options) {\n\t\tlet runnableConfig;\n\t\tif (options === void 0) runnableConfig = ensureConfig(options);\n\t\telse runnableConfig = ensureConfig({\n\t\t\tcallbacks: options.callbacks,\n\t\t\ttags: options.tags,\n\t\t\tmetadata: options.metadata,\n\t\t\trunName: options.runName,\n\t\t\tconfigurable: options.configurable,\n\t\t\trecursionLimit: options.recursionLimit,\n\t\t\tmaxConcurrency: options.maxConcurrency,\n\t\t\trunId: options.runId,\n\t\t\ttimeout: options.timeout,\n\t\t\tsignal: options.signal\n\t\t});\n\t\tconst callOptions = { ...options };\n\t\tdelete callOptions.callbacks;\n\t\tdelete callOptions.tags;\n\t\tdelete callOptions.metadata;\n\t\tdelete callOptions.runName;\n\t\tdelete callOptions.configurable;\n\t\tdelete callOptions.recursionLimit;\n\t\tdelete callOptions.maxConcurrency;\n\t\tdelete callOptions.runId;\n\t\tdelete callOptions.timeout;\n\t\tdelete callOptions.signal;\n\t\treturn [runnableConfig, callOptions];\n\t}\n\tasync _callWithConfig(func, input, options) {\n\t\tconst config = ensureConfig(options);\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(config);\n\t\tconst runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, \"input\"), config.runId, config?.runType, void 0, void 0, config?.runName ?? this.getName());\n\t\tdelete config.runId;\n\t\tlet output;\n\t\ttry {\n\t\t\tconst promise = func.call(this, input, config, runManager);\n\t\t\toutput = await raceWithSignal(promise, options?.signal);\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(e);\n\t\t\tthrow e;\n\t\t}\n\t\tawait runManager?.handleChainEnd(_coerceToDict(output, \"output\"));\n\t\treturn output;\n\t}\n\t/**\n\t* Internal method that handles batching and configuration for a runnable\n\t* It takes a function, input values, and optional configuration, and\n\t* returns a promise that resolves to the output values.\n\t* @param func The function to be executed for each input value.\n\t* @param input The input values to be processed.\n\t* @param config Optional configuration for the function execution.\n\t* @returns A promise that resolves to the output values.\n\t*/\n\tasync _batchWithConfig(func, inputs, options, batchOptions) {\n\t\tconst optionsList = this._getOptionsList(options ?? {}, inputs.length);\n\t\tconst callbackManagers = await Promise.all(optionsList.map(getCallbackManagerForConfig));\n\t\tconst runManagers = await Promise.all(callbackManagers.map(async (callbackManager, i) => {\n\t\t\tconst handleStartRes = await callbackManager?.handleChainStart(this.toJSON(), _coerceToDict(inputs[i], \"input\"), optionsList[i].runId, optionsList[i].runType, void 0, void 0, optionsList[i].runName ?? this.getName());\n\t\t\tdelete optionsList[i].runId;\n\t\t\treturn handleStartRes;\n\t\t}));\n\t\tlet outputs;\n\t\ttry {\n\t\t\tconst promise = func.call(this, inputs, optionsList, runManagers, batchOptions);\n\t\t\toutputs = await raceWithSignal(promise, optionsList?.[0]?.signal);\n\t\t} catch (e) {\n\t\t\tawait Promise.all(runManagers.map((runManager) => runManager?.handleChainError(e)));\n\t\t\tthrow e;\n\t\t}\n\t\tawait Promise.all(runManagers.map((runManager) => runManager?.handleChainEnd(_coerceToDict(outputs, \"output\"))));\n\t\treturn outputs;\n\t}\n\t/** @internal */\n\t_concatOutputChunks(first, second) {\n\t\treturn concat(first, second);\n\t}\n\t/**\n\t* Helper method to transform an Iterator of Input values into an Iterator of\n\t* Output values, with callbacks.\n\t* Use this to implement `stream()` or `transform()` in Runnable subclasses.\n\t*/\n\tasync *_transformStreamWithConfig(inputGenerator, transformer, options) {\n\t\tlet finalInput;\n\t\tlet finalInputSupported = true;\n\t\tlet finalOutput;\n\t\tlet finalOutputSupported = true;\n\t\tconst config = ensureConfig(options);\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(config);\n\t\tconst outerThis = this;\n\t\tasync function* wrapInputForTracing() {\n\t\t\tfor await (const chunk of inputGenerator) {\n\t\t\t\tif (finalInputSupported) if (finalInput === void 0) finalInput = chunk;\n\t\t\t\telse try {\n\t\t\t\t\tfinalInput = outerThis._concatOutputChunks(finalInput, chunk);\n\t\t\t\t} catch {\n\t\t\t\t\tfinalInput = void 0;\n\t\t\t\t\tfinalInputSupported = false;\n\t\t\t\t}\n\t\t\t\tyield chunk;\n\t\t\t}\n\t\t}\n\t\tlet runManager;\n\t\ttry {\n\t\t\tconst pipe = await pipeGeneratorWithSetup(transformer.bind(this), wrapInputForTracing(), async () => callbackManager_?.handleChainStart(this.toJSON(), { input: \"\" }, config.runId, config.runType, void 0, void 0, config.runName ?? this.getName()), options?.signal, config);\n\t\t\tdelete config.runId;\n\t\t\trunManager = pipe.setup;\n\t\t\tconst streamEventsHandler = runManager?.handlers.find(isStreamEventsHandler);\n\t\t\tlet iterator = pipe.output;\n\t\t\tif (streamEventsHandler !== void 0 && runManager !== void 0) iterator = streamEventsHandler.tapOutputIterable(runManager.runId, iterator);\n\t\t\tconst streamLogHandler = runManager?.handlers.find(isLogStreamHandler);\n\t\t\tif (streamLogHandler !== void 0 && runManager !== void 0) iterator = streamLogHandler.tapOutputIterable(runManager.runId, iterator);\n\t\t\tfor await (const chunk of iterator) {\n\t\t\t\tyield chunk;\n\t\t\t\tif (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;\n\t\t\t\telse try {\n\t\t\t\t\tfinalOutput = this._concatOutputChunks(finalOutput, chunk);\n\t\t\t\t} catch {\n\t\t\t\t\tfinalOutput = void 0;\n\t\t\t\t\tfinalOutputSupported = false;\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(e, void 0, void 0, void 0, { inputs: _coerceToDict(finalInput, \"input\") });\n\t\t\tthrow e;\n\t\t}\n\t\tawait runManager?.handleChainEnd(finalOutput ?? {}, void 0, void 0, void 0, { inputs: _coerceToDict(finalInput, \"input\") });\n\t}\n\tgetGraph(_) {\n\t\tconst graph = new Graph();\n\t\tconst inputNode = graph.addNode({\n\t\t\tname: `${this.getName()}Input`,\n\t\t\tschema: z.any()\n\t\t});\n\t\tconst runnableNode = graph.addNode(this);\n\t\tconst outputNode = graph.addNode({\n\t\t\tname: `${this.getName()}Output`,\n\t\t\tschema: z.any()\n\t\t});\n\t\tgraph.addEdge(inputNode, runnableNode);\n\t\tgraph.addEdge(runnableNode, outputNode);\n\t\treturn graph;\n\t}\n\t/**\n\t* Create a new runnable sequence that runs each individual runnable in series,\n\t* piping the output of one runnable into another runnable or runnable-like.\n\t* @param coerceable A runnable, function, or object whose values are functions or runnables.\n\t* @returns A new runnable sequence.\n\t*/\n\tpipe(coerceable) {\n\t\treturn new RunnableSequence({\n\t\t\tfirst: this,\n\t\t\tlast: _coerceToRunnable(coerceable)\n\t\t});\n\t}\n\t/**\n\t* Pick keys from the dict output of this runnable. Returns a new runnable.\n\t*/\n\tpick(keys) {\n\t\treturn this.pipe(new RunnablePick(keys));\n\t}\n\t/**\n\t* Assigns new fields to the dict output of this runnable. Returns a new runnable.\n\t*/\n\tassign(mapping) {\n\t\treturn this.pipe(new RunnableAssign(new RunnableMap({ steps: mapping })));\n\t}\n\t/**\n\t* Default implementation of transform, which buffers input and then calls stream.\n\t* Subclasses should override this method if they can start producing output while\n\t* input is still being generated.\n\t* @param generator\n\t* @param options\n\t*/\n\tasync *transform(generator, options) {\n\t\tlet finalChunk;\n\t\tfor await (const chunk of generator) if (finalChunk === void 0) finalChunk = chunk;\n\t\telse finalChunk = this._concatOutputChunks(finalChunk, chunk);\n\t\tyield* this._streamIterator(finalChunk, ensureConfig(options));\n\t}\n\t/**\n\t* Stream all output from a runnable, as reported to the callback system.\n\t* This includes all inner runs of LLMs, Retrievers, Tools, etc.\n\t* Output is streamed as Log objects, which include a list of\n\t* jsonpatch ops that describe how the state of the run has changed in each\n\t* step, and the final state of the run.\n\t* The jsonpatch ops can be applied in order to construct state.\n\t* @param input\n\t* @param options\n\t* @param streamOptions\n\t*/\n\tasync *streamLog(input, options, streamOptions) {\n\t\tconst logStreamCallbackHandler = new LogStreamCallbackHandler({\n\t\t\t...streamOptions,\n\t\t\tautoClose: false,\n\t\t\t_schemaFormat: \"original\"\n\t\t});\n\t\tconst config = ensureConfig(options);\n\t\tyield* this._streamLog(input, logStreamCallbackHandler, config);\n\t}\n\tasync *_streamLog(input, logStreamCallbackHandler, config) {\n\t\tconst { callbacks } = config;\n\t\tif (callbacks === void 0) config.callbacks = [logStreamCallbackHandler];\n\t\telse if (Array.isArray(callbacks)) config.callbacks = callbacks.concat([logStreamCallbackHandler]);\n\t\telse {\n\t\t\tconst copiedCallbacks = callbacks.copy();\n\t\t\tcopiedCallbacks.addHandler(logStreamCallbackHandler, true);\n\t\t\tconfig.callbacks = copiedCallbacks;\n\t\t}\n\t\tconst runnableStreamPromise = this.stream(input, config);\n\t\tasync function consumeRunnableStream() {\n\t\t\ttry {\n\t\t\t\tconst runnableStream = await runnableStreamPromise;\n\t\t\t\tfor await (const chunk of runnableStream) {\n\t\t\t\t\tconst patch = new RunLogPatch({ ops: [{\n\t\t\t\t\t\top: \"add\",\n\t\t\t\t\t\tpath: \"/streamed_output/-\",\n\t\t\t\t\t\tvalue: chunk\n\t\t\t\t\t}] });\n\t\t\t\t\tawait logStreamCallbackHandler.writer.write(patch);\n\t\t\t\t}\n\t\t\t} finally {\n\t\t\t\tawait logStreamCallbackHandler.writer.close();\n\t\t\t}\n\t\t}\n\t\tconst runnableStreamConsumePromise = consumeRunnableStream();\n\t\ttry {\n\t\t\tfor await (const log of logStreamCallbackHandler) yield log;\n\t\t} finally {\n\t\t\tawait runnableStreamConsumePromise;\n\t\t}\n\t}\n\tstreamEvents(input, options, streamOptions) {\n\t\tlet stream;\n\t\tif (options.version === \"v1\") stream = this._streamEventsV1(input, options, streamOptions);\n\t\telse if (options.version === \"v2\") stream = this._streamEventsV2(input, options, streamOptions);\n\t\telse throw new Error(`Only versions \"v1\" and \"v2\" of the schema are currently supported.`);\n\t\tif (options.encoding === \"text/event-stream\") return convertToHttpEventStream(stream);\n\t\telse return IterableReadableStream.fromAsyncGenerator(stream);\n\t}\n\tasync *_streamEventsV2(input, options, streamOptions) {\n\t\tconst eventStreamer = new EventStreamCallbackHandler({\n\t\t\t...streamOptions,\n\t\t\tautoClose: false\n\t\t});\n\t\tconst config = ensureConfig(options);\n\t\tconst runId = config.runId ?? v4();\n\t\tconfig.runId = runId;\n\t\tconst callbacks = config.callbacks;\n\t\tif (callbacks === void 0) config.callbacks = [eventStreamer];\n\t\telse if (Array.isArray(callbacks)) config.callbacks = callbacks.concat(eventStreamer);\n\t\telse {\n\t\t\tconst copiedCallbacks = callbacks.copy();\n\t\t\tcopiedCallbacks.addHandler(eventStreamer, true);\n\t\t\tconfig.callbacks = copiedCallbacks;\n\t\t}\n\t\tconst abortController = new AbortController();\n\t\tconst outerThis = this;\n\t\tasync function consumeRunnableStream() {\n\t\t\tlet signal;\n\t\t\tlet listener = null;\n\t\t\ttry {\n\t\t\t\tif (options?.signal) if (\"any\" in AbortSignal) signal = AbortSignal.any([abortController.signal, options.signal]);\n\t\t\t\telse {\n\t\t\t\t\tsignal = options.signal;\n\t\t\t\t\tlistener = () => {\n\t\t\t\t\t\tabortController.abort();\n\t\t\t\t\t};\n\t\t\t\t\toptions.signal.addEventListener(\"abort\", listener, { once: true });\n\t\t\t\t}\n\t\t\t\telse signal = abortController.signal;\n\t\t\t\tconst runnableStream = await outerThis.stream(input, {\n\t\t\t\t\t...config,\n\t\t\t\t\tsignal\n\t\t\t\t});\n\t\t\t\tconst tappedStream = eventStreamer.tapOutputIterable(runId, runnableStream);\n\t\t\t\tfor await (const _ of tappedStream) if (abortController.signal.aborted) break;\n\t\t\t} finally {\n\t\t\t\tawait eventStreamer.finish();\n\t\t\t\tif (signal && listener) signal.removeEventListener(\"abort\", listener);\n\t\t\t}\n\t\t}\n\t\tconst runnableStreamConsumePromise = consumeRunnableStream();\n\t\tlet firstEventSent = false;\n\t\tlet firstEventRunId;\n\t\ttry {\n\t\t\tfor await (const event of eventStreamer) {\n\t\t\t\tif (!firstEventSent) {\n\t\t\t\t\tevent.data.input = input;\n\t\t\t\t\tfirstEventSent = true;\n\t\t\t\t\tfirstEventRunId = event.run_id;\n\t\t\t\t\tyield event;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (event.run_id === firstEventRunId && event.event.endsWith(\"_end\")) {\n\t\t\t\t\tif (event.data?.input) delete event.data.input;\n\t\t\t\t}\n\t\t\t\tyield event;\n\t\t\t}\n\t\t} finally {\n\t\t\tabortController.abort();\n\t\t\tawait runnableStreamConsumePromise;\n\t\t}\n\t}\n\tasync *_streamEventsV1(input, options, streamOptions) {\n\t\tlet runLog;\n\t\tlet hasEncounteredStartEvent = false;\n\t\tconst config = ensureConfig(options);\n\t\tconst rootTags = config.tags ?? [];\n\t\tconst rootMetadata = config.metadata ?? {};\n\t\tconst rootName = config.runName ?? this.getName();\n\t\tconst logStreamCallbackHandler = new LogStreamCallbackHandler({\n\t\t\t...streamOptions,\n\t\t\tautoClose: false,\n\t\t\t_schemaFormat: \"streaming_events\"\n\t\t});\n\t\tconst rootEventFilter = new _RootEventFilter({ ...streamOptions });\n\t\tconst logStream = this._streamLog(input, logStreamCallbackHandler, config);\n\t\tfor await (const log of logStream) {\n\t\t\tif (!runLog) runLog = RunLog.fromRunLogPatch(log);\n\t\t\telse runLog = runLog.concat(log);\n\t\t\tif (runLog.state === void 0) throw new Error(`Internal error: \"streamEvents\" state is missing. Please open a bug report.`);\n\t\t\tif (!hasEncounteredStartEvent) {\n\t\t\t\thasEncounteredStartEvent = true;\n\t\t\t\tconst state$2 = { ...runLog.state };\n\t\t\t\tconst event = {\n\t\t\t\t\trun_id: state$2.id,\n\t\t\t\t\tevent: `on_${state$2.type}_start`,\n\t\t\t\t\tname: rootName,\n\t\t\t\t\ttags: rootTags,\n\t\t\t\t\tmetadata: rootMetadata,\n\t\t\t\t\tdata: { input }\n\t\t\t\t};\n\t\t\t\tif (rootEventFilter.includeEvent(event, state$2.type)) yield event;\n\t\t\t}\n\t\t\tconst paths = log.ops.filter((op) => op.path.startsWith(\"/logs/\")).map((op) => op.path.split(\"/\")[2]);\n\t\t\tconst dedupedPaths = [...new Set(paths)];\n\t\t\tfor (const path of dedupedPaths) {\n\t\t\t\tlet eventType;\n\t\t\t\tlet data = {};\n\t\t\t\tconst logEntry = runLog.state.logs[path];\n\t\t\t\tif (logEntry.end_time === void 0) if (logEntry.streamed_output.length > 0) eventType = \"stream\";\n\t\t\t\telse eventType = \"start\";\n\t\t\t\telse eventType = \"end\";\n\t\t\t\tif (eventType === \"start\") {\n\t\t\t\t\tif (logEntry.inputs !== void 0) data.input = logEntry.inputs;\n\t\t\t\t} else if (eventType === \"end\") {\n\t\t\t\t\tif (logEntry.inputs !== void 0) data.input = logEntry.inputs;\n\t\t\t\t\tdata.output = logEntry.final_output;\n\t\t\t\t} else if (eventType === \"stream\") {\n\t\t\t\t\tconst chunkCount = logEntry.streamed_output.length;\n\t\t\t\t\tif (chunkCount !== 1) throw new Error(`Expected exactly one chunk of streamed output, got ${chunkCount} instead. Encountered in: \"${logEntry.name}\"`);\n\t\t\t\t\tdata = { chunk: logEntry.streamed_output[0] };\n\t\t\t\t\tlogEntry.streamed_output = [];\n\t\t\t\t}\n\t\t\t\tyield {\n\t\t\t\t\tevent: `on_${logEntry.type}_${eventType}`,\n\t\t\t\t\tname: logEntry.name,\n\t\t\t\t\trun_id: logEntry.id,\n\t\t\t\t\ttags: logEntry.tags,\n\t\t\t\t\tmetadata: logEntry.metadata,\n\t\t\t\t\tdata\n\t\t\t\t};\n\t\t\t}\n\t\t\tconst { state: state$1 } = runLog;\n\t\t\tif (state$1.streamed_output.length > 0) {\n\t\t\t\tconst chunkCount = state$1.streamed_output.length;\n\t\t\t\tif (chunkCount !== 1) throw new Error(`Expected exactly one chunk of streamed output, got ${chunkCount} instead. Encountered in: \"${state$1.name}\"`);\n\t\t\t\tconst data = { chunk: state$1.streamed_output[0] };\n\t\t\t\tstate$1.streamed_output = [];\n\t\t\t\tconst event = {\n\t\t\t\t\tevent: `on_${state$1.type}_stream`,\n\t\t\t\t\trun_id: state$1.id,\n\t\t\t\t\ttags: rootTags,\n\t\t\t\t\tmetadata: rootMetadata,\n\t\t\t\t\tname: rootName,\n\t\t\t\t\tdata\n\t\t\t\t};\n\t\t\t\tif (rootEventFilter.includeEvent(event, state$1.type)) yield event;\n\t\t\t}\n\t\t}\n\t\tconst state = runLog?.state;\n\t\tif (state !== void 0) {\n\t\t\tconst event = {\n\t\t\t\tevent: `on_${state.type}_end`,\n\t\t\t\tname: rootName,\n\t\t\t\trun_id: state.id,\n\t\t\t\ttags: rootTags,\n\t\t\t\tmetadata: rootMetadata,\n\t\t\t\tdata: { output: state.final_output }\n\t\t\t};\n\t\t\tif (rootEventFilter.includeEvent(event, state.type)) yield event;\n\t\t}\n\t}\n\tstatic isRunnable(thing) {\n\t\treturn isRunnableInterface(thing);\n\t}\n\t/**\n\t* Bind lifecycle listeners to a Runnable, returning a new Runnable.\n\t* The Run object contains information about the run, including its id,\n\t* type, input, output, error, startTime, endTime, and any tags or metadata\n\t* added to the run.\n\t*\n\t* @param {Object} params - The object containing the callback functions.\n\t* @param {(run: Run) => void} params.onStart - Called before the runnable starts running, with the Run object.\n\t* @param {(run: Run) => void} params.onEnd - Called after the runnable finishes running, with the Run object.\n\t* @param {(run: Run) => void} params.onError - Called if the runnable throws an error, with the Run object.\n\t*/\n\twithListeners({ onStart, onEnd, onError }) {\n\t\treturn new RunnableBinding({\n\t\t\tbound: this,\n\t\t\tconfig: {},\n\t\t\tconfigFactories: [(config) => ({ callbacks: [new RootListenersTracer({\n\t\t\t\tconfig,\n\t\t\t\tonStart,\n\t\t\t\tonEnd,\n\t\t\t\tonError\n\t\t\t})] })]\n\t\t});\n\t}\n\t/**\n\t* Convert a runnable to a tool. Return a new instance of `RunnableToolLike`\n\t* which contains the runnable, name, description and schema.\n\t*\n\t* @template {T extends RunInput = RunInput} RunInput - The input type of the runnable. Should be the same as the `RunInput` type of the runnable.\n\t*\n\t* @param fields\n\t* @param {string | undefined} [fields.name] The name of the tool. If not provided, it will default to the name of the runnable.\n\t* @param {string | undefined} [fields.description] The description of the tool. Falls back to the description on the Zod schema if not provided, or undefined if neither are provided.\n\t* @param {z.ZodType<T>} [fields.schema] The Zod schema for the input of the tool. Infers the Zod type from the input type of the runnable.\n\t* @returns {RunnableToolLike<z.ZodType<T>, RunOutput>} An instance of `RunnableToolLike` which is a runnable that can be used as a tool.\n\t*/\n\tasTool(fields) {\n\t\treturn convertRunnableToTool(this, fields);\n\t}\n};\n/**\n* Wraps a runnable and applies partial config upon invocation.\n*\n* @example\n* ```typescript\n* import {\n*   type RunnableConfig,\n*   RunnableLambda,\n* } from \"@langchain/core/runnables\";\n*\n* const enhanceProfile = (\n*   profile: Record<string, any>,\n*   config?: RunnableConfig\n* ) => {\n*   if (config?.configurable?.role) {\n*     return { ...profile, role: config.configurable.role };\n*   }\n*   return profile;\n* };\n*\n* const runnable = RunnableLambda.from(enhanceProfile);\n*\n* // Bind configuration to the runnable to set the user's role dynamically\n* const adminRunnable = runnable.withConfig({ configurable: { role: \"Admin\" } });\n* const userRunnable = runnable.withConfig({ configurable: { role: \"User\" } });\n*\n* const result1 = await adminRunnable.invoke({\n*   name: \"Alice\",\n*   email: \"alice@example.com\"\n* });\n*\n* // { name: \"Alice\", email: \"alice@example.com\", role: \"Admin\" }\n*\n* const result2 = await userRunnable.invoke({\n*   name: \"Bob\",\n*   email: \"bob@example.com\"\n* });\n*\n* // { name: \"Bob\", email: \"bob@example.com\", role: \"User\" }\n* ```\n*/\nvar RunnableBinding = class RunnableBinding extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableBinding\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\tbound;\n\tconfig;\n\tkwargs;\n\tconfigFactories;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.bound = fields.bound;\n\t\tthis.kwargs = fields.kwargs;\n\t\tthis.config = fields.config;\n\t\tthis.configFactories = fields.configFactories;\n\t}\n\tgetName(suffix) {\n\t\treturn this.bound.getName(suffix);\n\t}\n\tasync _mergeConfig(...options) {\n\t\tconst config = mergeConfigs(this.config, ...options);\n\t\treturn mergeConfigs(config, ...this.configFactories ? await Promise.all(this.configFactories.map(async (configFactory) => await configFactory(config))) : []);\n\t}\n\twithConfig(config) {\n\t\treturn new this.constructor({\n\t\t\tbound: this.bound,\n\t\t\tkwargs: this.kwargs,\n\t\t\tconfig: {\n\t\t\t\t...this.config,\n\t\t\t\t...config\n\t\t\t}\n\t\t});\n\t}\n\twithRetry(fields) {\n\t\treturn new RunnableRetry({\n\t\t\tbound: this.bound,\n\t\t\tkwargs: this.kwargs,\n\t\t\tconfig: this.config,\n\t\t\tmaxAttemptNumber: fields?.stopAfterAttempt,\n\t\t\t...fields\n\t\t});\n\t}\n\tasync invoke(input, options) {\n\t\treturn this.bound.invoke(input, await this._mergeConfig(options, this.kwargs));\n\t}\n\tasync batch(inputs, options, batchOptions) {\n\t\tconst mergedOptions = Array.isArray(options) ? await Promise.all(options.map(async (individualOption) => this._mergeConfig(ensureConfig(individualOption), this.kwargs))) : await this._mergeConfig(ensureConfig(options), this.kwargs);\n\t\treturn this.bound.batch(inputs, mergedOptions, batchOptions);\n\t}\n\t/** @internal */\n\t_concatOutputChunks(first, second) {\n\t\treturn this.bound._concatOutputChunks(first, second);\n\t}\n\tasync *_streamIterator(input, options) {\n\t\tyield* this.bound._streamIterator(input, await this._mergeConfig(ensureConfig(options), this.kwargs));\n\t}\n\tasync stream(input, options) {\n\t\treturn this.bound.stream(input, await this._mergeConfig(ensureConfig(options), this.kwargs));\n\t}\n\tasync *transform(generator, options) {\n\t\tyield* this.bound.transform(generator, await this._mergeConfig(ensureConfig(options), this.kwargs));\n\t}\n\tstreamEvents(input, options, streamOptions) {\n\t\tconst outerThis = this;\n\t\tconst generator = async function* () {\n\t\t\tyield* outerThis.bound.streamEvents(input, {\n\t\t\t\t...await outerThis._mergeConfig(ensureConfig(options), outerThis.kwargs),\n\t\t\t\tversion: options.version\n\t\t\t}, streamOptions);\n\t\t};\n\t\treturn IterableReadableStream.fromAsyncGenerator(generator());\n\t}\n\tstatic isRunnableBinding(thing) {\n\t\treturn thing.bound && Runnable.isRunnable(thing.bound);\n\t}\n\t/**\n\t* Bind lifecycle listeners to a Runnable, returning a new Runnable.\n\t* The Run object contains information about the run, including its id,\n\t* type, input, output, error, startTime, endTime, and any tags or metadata\n\t* added to the run.\n\t*\n\t* @param {Object} params - The object containing the callback functions.\n\t* @param {(run: Run) => void} params.onStart - Called before the runnable starts running, with the Run object.\n\t* @param {(run: Run) => void} params.onEnd - Called after the runnable finishes running, with the Run object.\n\t* @param {(run: Run) => void} params.onError - Called if the runnable throws an error, with the Run object.\n\t*/\n\twithListeners({ onStart, onEnd, onError }) {\n\t\treturn new RunnableBinding({\n\t\t\tbound: this.bound,\n\t\t\tkwargs: this.kwargs,\n\t\t\tconfig: this.config,\n\t\t\tconfigFactories: [(config) => ({ callbacks: [new RootListenersTracer({\n\t\t\t\tconfig,\n\t\t\t\tonStart,\n\t\t\t\tonEnd,\n\t\t\t\tonError\n\t\t\t})] })]\n\t\t});\n\t}\n};\n/**\n* A runnable that delegates calls to another runnable\n* with each element of the input sequence.\n* @example\n* ```typescript\n* import { RunnableEach, RunnableLambda } from \"@langchain/core/runnables\";\n*\n* const toUpperCase = (input: string): string => input.toUpperCase();\n* const addGreeting = (input: string): string => `Hello, ${input}!`;\n*\n* const upperCaseLambda = RunnableLambda.from(toUpperCase);\n* const greetingLambda = RunnableLambda.from(addGreeting);\n*\n* const chain = new RunnableEach({\n*   bound: upperCaseLambda.pipe(greetingLambda),\n* });\n*\n* const result = await chain.invoke([\"alice\", \"bob\", \"carol\"])\n*\n* // [\"Hello, ALICE!\", \"Hello, BOB!\", \"Hello, CAROL!\"]\n* ```\n*/\nvar RunnableEach = class RunnableEach extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableEach\";\n\t}\n\tlc_serializable = true;\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tbound;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.bound = fields.bound;\n\t}\n\t/**\n\t* Invokes the runnable with the specified input and configuration.\n\t* @param input The input to invoke the runnable with.\n\t* @param config The configuration to invoke the runnable with.\n\t* @returns A promise that resolves to the output of the runnable.\n\t*/\n\tasync invoke(inputs, config) {\n\t\treturn this._callWithConfig(this._invoke.bind(this), inputs, config);\n\t}\n\t/**\n\t* A helper method that is used to invoke the runnable with the specified input and configuration.\n\t* @param input The input to invoke the runnable with.\n\t* @param config The configuration to invoke the runnable with.\n\t* @returns A promise that resolves to the output of the runnable.\n\t*/\n\tasync _invoke(inputs, config, runManager) {\n\t\treturn this.bound.batch(inputs, patchConfig(config, { callbacks: runManager?.getChild() }));\n\t}\n\t/**\n\t* Bind lifecycle listeners to a Runnable, returning a new Runnable.\n\t* The Run object contains information about the run, including its id,\n\t* type, input, output, error, startTime, endTime, and any tags or metadata\n\t* added to the run.\n\t*\n\t* @param {Object} params - The object containing the callback functions.\n\t* @param {(run: Run) => void} params.onStart - Called before the runnable starts running, with the Run object.\n\t* @param {(run: Run) => void} params.onEnd - Called after the runnable finishes running, with the Run object.\n\t* @param {(run: Run) => void} params.onError - Called if the runnable throws an error, with the Run object.\n\t*/\n\twithListeners({ onStart, onEnd, onError }) {\n\t\treturn new RunnableEach({ bound: this.bound.withListeners({\n\t\t\tonStart,\n\t\t\tonEnd,\n\t\t\tonError\n\t\t}) });\n\t}\n};\n/**\n* Base class for runnables that can be retried a\n* specified number of times.\n* @example\n* ```typescript\n* import {\n*   RunnableLambda,\n*   RunnableRetry,\n* } from \"@langchain/core/runnables\";\n*\n* // Simulate an API call that fails\n* const simulateApiCall = (input: string): string => {\n*   console.log(`Attempting API call with input: ${input}`);\n*   throw new Error(\"API call failed due to network issue\");\n* };\n*\n* const apiCallLambda = RunnableLambda.from(simulateApiCall);\n*\n* // Apply retry logic using the .withRetry() method\n* const apiCallWithRetry = apiCallLambda.withRetry({ stopAfterAttempt: 3 });\n*\n* // Alternatively, create a RunnableRetry instance manually\n* const manualRetry = new RunnableRetry({\n*   bound: apiCallLambda,\n*   maxAttemptNumber: 3,\n*   config: {},\n* });\n*\n* // Example invocation using the .withRetry() method\n* const res = await apiCallWithRetry\n*   .invoke(\"Request 1\")\n*   .catch((error) => {\n*     console.error(\"Failed after multiple retries:\", error.message);\n*   });\n*\n* // Example invocation using the manual retry instance\n* const res2 = await manualRetry\n*   .invoke(\"Request 2\")\n*   .catch((error) => {\n*     console.error(\"Failed after multiple retries:\", error.message);\n*   });\n* ```\n*/\nvar RunnableRetry = class extends RunnableBinding {\n\tstatic lc_name() {\n\t\treturn \"RunnableRetry\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tmaxAttemptNumber = 3;\n\tonFailedAttempt = () => {};\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.maxAttemptNumber = fields.maxAttemptNumber ?? this.maxAttemptNumber;\n\t\tthis.onFailedAttempt = fields.onFailedAttempt ?? this.onFailedAttempt;\n\t}\n\t_patchConfigForRetry(attempt, config, runManager) {\n\t\tconst tag = attempt > 1 ? `retry:attempt:${attempt}` : void 0;\n\t\treturn patchConfig(config, { callbacks: runManager?.getChild(tag) });\n\t}\n\tasync _invoke(input, config, runManager) {\n\t\treturn pRetry((attemptNumber) => super.invoke(input, this._patchConfigForRetry(attemptNumber, config, runManager)), {\n\t\t\tonFailedAttempt: (error) => this.onFailedAttempt(error, input),\n\t\t\tretries: Math.max(this.maxAttemptNumber - 1, 0),\n\t\t\trandomize: true\n\t\t});\n\t}\n\t/**\n\t* Method that invokes the runnable with the specified input, run manager,\n\t* and config. It handles the retry logic by catching any errors and\n\t* recursively invoking itself with the updated config for the next retry\n\t* attempt.\n\t* @param input The input for the runnable.\n\t* @param runManager The run manager for the runnable.\n\t* @param config The config for the runnable.\n\t* @returns A promise that resolves to the output of the runnable.\n\t*/\n\tasync invoke(input, config) {\n\t\treturn this._callWithConfig(this._invoke.bind(this), input, config);\n\t}\n\tasync _batch(inputs, configs, runManagers, batchOptions) {\n\t\tconst resultsMap = {};\n\t\ttry {\n\t\t\tawait pRetry(async (attemptNumber) => {\n\t\t\t\tconst remainingIndexes = inputs.map((_, i) => i).filter((i) => resultsMap[i.toString()] === void 0 || resultsMap[i.toString()] instanceof Error);\n\t\t\t\tconst remainingInputs = remainingIndexes.map((i) => inputs[i]);\n\t\t\t\tconst patchedConfigs = remainingIndexes.map((i) => this._patchConfigForRetry(attemptNumber, configs?.[i], runManagers?.[i]));\n\t\t\t\tconst results = await super.batch(remainingInputs, patchedConfigs, {\n\t\t\t\t\t...batchOptions,\n\t\t\t\t\treturnExceptions: true\n\t\t\t\t});\n\t\t\t\tlet firstException;\n\t\t\t\tfor (let i = 0; i < results.length; i += 1) {\n\t\t\t\t\tconst result = results[i];\n\t\t\t\t\tconst resultMapIndex = remainingIndexes[i];\n\t\t\t\t\tif (result instanceof Error) {\n\t\t\t\t\t\tif (firstException === void 0) {\n\t\t\t\t\t\t\tfirstException = result;\n\t\t\t\t\t\t\tfirstException.input = remainingInputs[i];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tresultsMap[resultMapIndex.toString()] = result;\n\t\t\t\t}\n\t\t\t\tif (firstException) throw firstException;\n\t\t\t\treturn results;\n\t\t\t}, {\n\t\t\t\tonFailedAttempt: (error) => this.onFailedAttempt(error, error.input),\n\t\t\t\tretries: Math.max(this.maxAttemptNumber - 1, 0),\n\t\t\t\trandomize: true\n\t\t\t});\n\t\t} catch (e) {\n\t\t\tif (batchOptions?.returnExceptions !== true) throw e;\n\t\t}\n\t\treturn Object.keys(resultsMap).sort((a, b) => parseInt(a, 10) - parseInt(b, 10)).map((key) => resultsMap[parseInt(key, 10)]);\n\t}\n\tasync batch(inputs, options, batchOptions) {\n\t\treturn this._batchWithConfig(this._batch.bind(this), inputs, options, batchOptions);\n\t}\n};\n/**\n* A sequence of runnables, where the output of each is the input of the next.\n* @example\n* ```typescript\n* const promptTemplate = PromptTemplate.fromTemplate(\n*   \"Tell me a joke about {topic}\",\n* );\n* const chain = RunnableSequence.from([promptTemplate, new ChatOpenAI({ model: \"gpt-4o-mini\" })]);\n* const result = await chain.invoke({ topic: \"bears\" });\n* ```\n*/\nvar RunnableSequence = class RunnableSequence extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableSequence\";\n\t}\n\tfirst;\n\tmiddle = [];\n\tlast;\n\tomitSequenceTags = false;\n\tlc_serializable = true;\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.first = fields.first;\n\t\tthis.middle = fields.middle ?? this.middle;\n\t\tthis.last = fields.last;\n\t\tthis.name = fields.name;\n\t\tthis.omitSequenceTags = fields.omitSequenceTags ?? this.omitSequenceTags;\n\t}\n\tget steps() {\n\t\treturn [\n\t\t\tthis.first,\n\t\t\t...this.middle,\n\t\t\tthis.last\n\t\t];\n\t}\n\tasync invoke(input, options) {\n\t\tconst config = ensureConfig(options);\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(config);\n\t\tconst runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, \"input\"), config.runId, void 0, void 0, void 0, config?.runName);\n\t\tdelete config.runId;\n\t\tlet nextStepInput = input;\n\t\tlet finalOutput;\n\t\ttry {\n\t\t\tconst initialSteps = [this.first, ...this.middle];\n\t\t\tfor (let i = 0; i < initialSteps.length; i += 1) {\n\t\t\t\tconst step = initialSteps[i];\n\t\t\t\tconst promise = step.invoke(nextStepInput, patchConfig(config, { callbacks: runManager?.getChild(this.omitSequenceTags ? void 0 : `seq:step:${i + 1}`) }));\n\t\t\t\tnextStepInput = await raceWithSignal(promise, options?.signal);\n\t\t\t}\n\t\t\tif (options?.signal?.aborted) throw getAbortSignalError(options.signal);\n\t\t\tfinalOutput = await this.last.invoke(nextStepInput, patchConfig(config, { callbacks: runManager?.getChild(this.omitSequenceTags ? void 0 : `seq:step:${this.steps.length}`) }));\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(e);\n\t\t\tthrow e;\n\t\t}\n\t\tawait runManager?.handleChainEnd(_coerceToDict(finalOutput, \"output\"));\n\t\treturn finalOutput;\n\t}\n\tasync batch(inputs, options, batchOptions) {\n\t\tconst configList = this._getOptionsList(options ?? {}, inputs.length);\n\t\tconst callbackManagers = await Promise.all(configList.map(getCallbackManagerForConfig));\n\t\tconst runManagers = await Promise.all(callbackManagers.map(async (callbackManager, i) => {\n\t\t\tconst handleStartRes = await callbackManager?.handleChainStart(this.toJSON(), _coerceToDict(inputs[i], \"input\"), configList[i].runId, void 0, void 0, void 0, configList[i].runName);\n\t\t\tdelete configList[i].runId;\n\t\t\treturn handleStartRes;\n\t\t}));\n\t\tlet nextStepInputs = inputs;\n\t\ttry {\n\t\t\tfor (let i = 0; i < this.steps.length; i += 1) {\n\t\t\t\tconst step = this.steps[i];\n\t\t\t\tconst promise = step.batch(nextStepInputs, runManagers.map((runManager, j) => {\n\t\t\t\t\tconst childRunManager = runManager?.getChild(this.omitSequenceTags ? void 0 : `seq:step:${i + 1}`);\n\t\t\t\t\treturn patchConfig(configList[j], { callbacks: childRunManager });\n\t\t\t\t}), batchOptions);\n\t\t\t\tnextStepInputs = await raceWithSignal(promise, configList[0]?.signal);\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tawait Promise.all(runManagers.map((runManager) => runManager?.handleChainError(e)));\n\t\t\tthrow e;\n\t\t}\n\t\tawait Promise.all(runManagers.map((runManager) => runManager?.handleChainEnd(_coerceToDict(nextStepInputs, \"output\"))));\n\t\treturn nextStepInputs;\n\t}\n\t/** @internal */\n\t_concatOutputChunks(first, second) {\n\t\treturn this.last._concatOutputChunks(first, second);\n\t}\n\tasync *_streamIterator(input, options) {\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(options);\n\t\tconst { runId,...otherOptions } = options ?? {};\n\t\tconst runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, \"input\"), runId, void 0, void 0, void 0, otherOptions?.runName);\n\t\tconst steps = [\n\t\t\tthis.first,\n\t\t\t...this.middle,\n\t\t\tthis.last\n\t\t];\n\t\tlet concatSupported = true;\n\t\tlet finalOutput;\n\t\tasync function* inputGenerator() {\n\t\t\tyield input;\n\t\t}\n\t\ttry {\n\t\t\tlet finalGenerator = steps[0].transform(inputGenerator(), patchConfig(otherOptions, { callbacks: runManager?.getChild(this.omitSequenceTags ? void 0 : `seq:step:1`) }));\n\t\t\tfor (let i = 1; i < steps.length; i += 1) {\n\t\t\t\tconst step = steps[i];\n\t\t\t\tfinalGenerator = await step.transform(finalGenerator, patchConfig(otherOptions, { callbacks: runManager?.getChild(this.omitSequenceTags ? void 0 : `seq:step:${i + 1}`) }));\n\t\t\t}\n\t\t\tfor await (const chunk of finalGenerator) {\n\t\t\t\toptions?.signal?.throwIfAborted();\n\t\t\t\tyield chunk;\n\t\t\t\tif (concatSupported) if (finalOutput === void 0) finalOutput = chunk;\n\t\t\t\telse try {\n\t\t\t\t\tfinalOutput = this._concatOutputChunks(finalOutput, chunk);\n\t\t\t\t} catch {\n\t\t\t\t\tfinalOutput = void 0;\n\t\t\t\t\tconcatSupported = false;\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(e);\n\t\t\tthrow e;\n\t\t}\n\t\tawait runManager?.handleChainEnd(_coerceToDict(finalOutput, \"output\"));\n\t}\n\tgetGraph(config) {\n\t\tconst graph = new Graph();\n\t\tlet currentLastNode = null;\n\t\tthis.steps.forEach((step, index) => {\n\t\t\tconst stepGraph = step.getGraph(config);\n\t\t\tif (index !== 0) stepGraph.trimFirstNode();\n\t\t\tif (index !== this.steps.length - 1) stepGraph.trimLastNode();\n\t\t\tgraph.extend(stepGraph);\n\t\t\tconst stepFirstNode = stepGraph.firstNode();\n\t\t\tif (!stepFirstNode) throw new Error(`Runnable ${step} has no first node`);\n\t\t\tif (currentLastNode) graph.addEdge(currentLastNode, stepFirstNode);\n\t\t\tcurrentLastNode = stepGraph.lastNode();\n\t\t});\n\t\treturn graph;\n\t}\n\tpipe(coerceable) {\n\t\tif (RunnableSequence.isRunnableSequence(coerceable)) return new RunnableSequence({\n\t\t\tfirst: this.first,\n\t\t\tmiddle: this.middle.concat([\n\t\t\t\tthis.last,\n\t\t\t\tcoerceable.first,\n\t\t\t\t...coerceable.middle\n\t\t\t]),\n\t\t\tlast: coerceable.last,\n\t\t\tname: this.name ?? coerceable.name\n\t\t});\n\t\telse return new RunnableSequence({\n\t\t\tfirst: this.first,\n\t\t\tmiddle: [...this.middle, this.last],\n\t\t\tlast: _coerceToRunnable(coerceable),\n\t\t\tname: this.name\n\t\t});\n\t}\n\tstatic isRunnableSequence(thing) {\n\t\treturn Array.isArray(thing.middle) && Runnable.isRunnable(thing);\n\t}\n\tstatic from([first, ...runnables], nameOrFields) {\n\t\tlet extra = {};\n\t\tif (typeof nameOrFields === \"string\") extra.name = nameOrFields;\n\t\telse if (nameOrFields !== void 0) extra = nameOrFields;\n\t\treturn new RunnableSequence({\n\t\t\t...extra,\n\t\t\tfirst: _coerceToRunnable(first),\n\t\t\tmiddle: runnables.slice(0, -1).map(_coerceToRunnable),\n\t\t\tlast: _coerceToRunnable(runnables[runnables.length - 1])\n\t\t});\n\t}\n};\n/**\n* A runnable that runs a mapping of runnables in parallel,\n* and returns a mapping of their outputs.\n* @example\n* ```typescript\n* const mapChain = RunnableMap.from({\n*   joke: PromptTemplate.fromTemplate(\"Tell me a joke about {topic}\").pipe(\n*     new ChatAnthropic({}),\n*   ),\n*   poem: PromptTemplate.fromTemplate(\"write a 2-line poem about {topic}\").pipe(\n*     new ChatAnthropic({}),\n*   ),\n* });\n* const result = await mapChain.invoke({ topic: \"bear\" });\n* ```\n*/\nvar RunnableMap = class RunnableMap extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableMap\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\tsteps;\n\tgetStepsKeys() {\n\t\treturn Object.keys(this.steps);\n\t}\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.steps = {};\n\t\tfor (const [key, value] of Object.entries(fields.steps)) this.steps[key] = _coerceToRunnable(value);\n\t}\n\tstatic from(steps) {\n\t\treturn new RunnableMap({ steps });\n\t}\n\tasync invoke(input, options) {\n\t\tconst config = ensureConfig(options);\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(config);\n\t\tconst runManager = await callbackManager_?.handleChainStart(this.toJSON(), { input }, config.runId, void 0, void 0, void 0, config?.runName);\n\t\tdelete config.runId;\n\t\tconst output = {};\n\t\ttry {\n\t\t\tconst promises = Object.entries(this.steps).map(async ([key, runnable]) => {\n\t\t\t\toutput[key] = await runnable.invoke(input, patchConfig(config, { callbacks: runManager?.getChild(`map:key:${key}`) }));\n\t\t\t});\n\t\t\tawait raceWithSignal(Promise.all(promises), options?.signal);\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(e);\n\t\t\tthrow e;\n\t\t}\n\t\tawait runManager?.handleChainEnd(output);\n\t\treturn output;\n\t}\n\tasync *_transform(generator, runManager, options) {\n\t\tconst steps = { ...this.steps };\n\t\tconst inputCopies = atee(generator, Object.keys(steps).length);\n\t\tconst tasks = new Map(Object.entries(steps).map(([key, runnable], i) => {\n\t\t\tconst gen = runnable.transform(inputCopies[i], patchConfig(options, { callbacks: runManager?.getChild(`map:key:${key}`) }));\n\t\t\treturn [key, gen.next().then((result) => ({\n\t\t\t\tkey,\n\t\t\t\tgen,\n\t\t\t\tresult\n\t\t\t}))];\n\t\t}));\n\t\twhile (tasks.size) {\n\t\t\tconst promise = Promise.race(tasks.values());\n\t\t\tconst { key, result, gen } = await raceWithSignal(promise, options?.signal);\n\t\t\ttasks.delete(key);\n\t\t\tif (!result.done) {\n\t\t\t\tyield { [key]: result.value };\n\t\t\t\ttasks.set(key, gen.next().then((result$1) => ({\n\t\t\t\t\tkey,\n\t\t\t\t\tgen,\n\t\t\t\t\tresult: result$1\n\t\t\t\t})));\n\t\t\t}\n\t\t}\n\t}\n\ttransform(generator, options) {\n\t\treturn this._transformStreamWithConfig(generator, this._transform.bind(this), options);\n\t}\n\tasync stream(input, options) {\n\t\tasync function* generator() {\n\t\t\tyield input;\n\t\t}\n\t\tconst config = ensureConfig(options);\n\t\tconst wrappedGenerator = new AsyncGeneratorWithSetup({\n\t\t\tgenerator: this.transform(generator(), config),\n\t\t\tconfig\n\t\t});\n\t\tawait wrappedGenerator.setup;\n\t\treturn IterableReadableStream.fromAsyncGenerator(wrappedGenerator);\n\t}\n};\n/**\n* A runnable that wraps a traced LangSmith function.\n*/\nvar RunnableTraceable = class RunnableTraceable extends Runnable {\n\tlc_serializable = false;\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tfunc;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tif (!isTraceableFunction(fields.func)) throw new Error(\"RunnableTraceable requires a function that is wrapped in traceable higher-order function\");\n\t\tthis.func = fields.func;\n\t}\n\tasync invoke(input, options) {\n\t\tconst [config] = this._getOptionsList(options ?? {}, 1);\n\t\tconst callbacks = await getCallbackManagerForConfig(config);\n\t\tconst promise = this.func(patchConfig(config, { callbacks }), input);\n\t\treturn raceWithSignal(promise, config?.signal);\n\t}\n\tasync *_streamIterator(input, options) {\n\t\tconst [config] = this._getOptionsList(options ?? {}, 1);\n\t\tconst result = await this.invoke(input, options);\n\t\tif (isAsyncIterable(result)) {\n\t\t\tfor await (const item of result) {\n\t\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\t\tyield item;\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tif (isIterator(result)) {\n\t\t\twhile (true) {\n\t\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\t\tconst state = result.next();\n\t\t\t\tif (state.done) break;\n\t\t\t\tyield state.value;\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tyield result;\n\t}\n\tstatic from(func) {\n\t\treturn new RunnableTraceable({ func });\n\t}\n};\nfunction assertNonTraceableFunction(func) {\n\tif (isTraceableFunction(func)) throw new Error(\"RunnableLambda requires a function that is not wrapped in traceable higher-order function. This shouldn't happen.\");\n}\n/**\n* A runnable that wraps an arbitrary function that takes a single argument.\n* @example\n* ```typescript\n* import { RunnableLambda } from \"@langchain/core/runnables\";\n*\n* const add = (input: { x: number; y: number }) => input.x + input.y;\n*\n* const multiply = (input: { value: number; multiplier: number }) =>\n*   input.value * input.multiplier;\n*\n* // Create runnables for the functions\n* const addLambda = RunnableLambda.from(add);\n* const multiplyLambda = RunnableLambda.from(multiply);\n*\n* // Chain the lambdas for a mathematical operation\n* const chainedLambda = addLambda.pipe((result) =>\n*   multiplyLambda.invoke({ value: result, multiplier: 2 })\n* );\n*\n* // Example invocation of the chainedLambda\n* const result = await chainedLambda.invoke({ x: 2, y: 3 });\n*\n* // Will log \"10\" (since (2 + 3) * 2 = 10)\n* ```\n*/\nvar RunnableLambda = class RunnableLambda extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableLambda\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tfunc;\n\tconstructor(fields) {\n\t\tif (isTraceableFunction(fields.func)) return RunnableTraceable.from(fields.func);\n\t\tsuper(fields);\n\t\tassertNonTraceableFunction(fields.func);\n\t\tthis.func = fields.func;\n\t}\n\tstatic from(func) {\n\t\treturn new RunnableLambda({ func });\n\t}\n\tasync _invoke(input, config, runManager) {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tconst childConfig = patchConfig(config, {\n\t\t\t\tcallbacks: runManager?.getChild(),\n\t\t\t\trecursionLimit: (config?.recursionLimit ?? DEFAULT_RECURSION_LIMIT) - 1\n\t\t\t});\n\t\t\tAsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {\n\t\t\t\ttry {\n\t\t\t\t\tlet output = await this.func(input, { ...childConfig });\n\t\t\t\t\tif (output && Runnable.isRunnable(output)) {\n\t\t\t\t\t\tif (config?.recursionLimit === 0) throw new Error(\"Recursion limit reached.\");\n\t\t\t\t\t\toutput = await output.invoke(input, {\n\t\t\t\t\t\t\t...childConfig,\n\t\t\t\t\t\t\trecursionLimit: (childConfig.recursionLimit ?? DEFAULT_RECURSION_LIMIT) - 1\n\t\t\t\t\t\t});\n\t\t\t\t\t} else if (isAsyncIterable(output)) {\n\t\t\t\t\t\tlet finalOutput;\n\t\t\t\t\t\tfor await (const chunk of consumeAsyncIterableInContext(childConfig, output)) {\n\t\t\t\t\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\t\t\t\t\tif (finalOutput === void 0) finalOutput = chunk;\n\t\t\t\t\t\t\telse try {\n\t\t\t\t\t\t\t\tfinalOutput = this._concatOutputChunks(finalOutput, chunk);\n\t\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\t\tfinalOutput = chunk;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = finalOutput;\n\t\t\t\t\t} else if (isIterableIterator(output)) {\n\t\t\t\t\t\tlet finalOutput;\n\t\t\t\t\t\tfor (const chunk of consumeIteratorInContext(childConfig, output)) {\n\t\t\t\t\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\t\t\t\t\tif (finalOutput === void 0) finalOutput = chunk;\n\t\t\t\t\t\t\telse try {\n\t\t\t\t\t\t\t\tfinalOutput = this._concatOutputChunks(finalOutput, chunk);\n\t\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\t\tfinalOutput = chunk;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = finalOutput;\n\t\t\t\t\t}\n\t\t\t\t\tresolve(output);\n\t\t\t\t} catch (e) {\n\t\t\t\t\treject(e);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\tasync invoke(input, options) {\n\t\treturn this._callWithConfig(this._invoke.bind(this), input, options);\n\t}\n\tasync *_transform(generator, runManager, config) {\n\t\tlet finalChunk;\n\t\tfor await (const chunk of generator) if (finalChunk === void 0) finalChunk = chunk;\n\t\telse try {\n\t\t\tfinalChunk = this._concatOutputChunks(finalChunk, chunk);\n\t\t} catch {\n\t\t\tfinalChunk = chunk;\n\t\t}\n\t\tconst childConfig = patchConfig(config, {\n\t\t\tcallbacks: runManager?.getChild(),\n\t\t\trecursionLimit: (config?.recursionLimit ?? DEFAULT_RECURSION_LIMIT) - 1\n\t\t});\n\t\tconst output = await new Promise((resolve, reject) => {\n\t\t\tAsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {\n\t\t\t\ttry {\n\t\t\t\t\tconst res = await this.func(finalChunk, {\n\t\t\t\t\t\t...childConfig,\n\t\t\t\t\t\tconfig: childConfig\n\t\t\t\t\t});\n\t\t\t\t\tresolve(res);\n\t\t\t\t} catch (e) {\n\t\t\t\t\treject(e);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t\tif (output && Runnable.isRunnable(output)) {\n\t\t\tif (config?.recursionLimit === 0) throw new Error(\"Recursion limit reached.\");\n\t\t\tconst stream = await output.stream(finalChunk, childConfig);\n\t\t\tfor await (const chunk of stream) yield chunk;\n\t\t} else if (isAsyncIterable(output)) for await (const chunk of consumeAsyncIterableInContext(childConfig, output)) {\n\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\tyield chunk;\n\t\t}\n\t\telse if (isIterableIterator(output)) for (const chunk of consumeIteratorInContext(childConfig, output)) {\n\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\tyield chunk;\n\t\t}\n\t\telse yield output;\n\t}\n\ttransform(generator, options) {\n\t\treturn this._transformStreamWithConfig(generator, this._transform.bind(this), options);\n\t}\n\tasync stream(input, options) {\n\t\tasync function* generator() {\n\t\t\tyield input;\n\t\t}\n\t\tconst config = ensureConfig(options);\n\t\tconst wrappedGenerator = new AsyncGeneratorWithSetup({\n\t\t\tgenerator: this.transform(generator(), config),\n\t\t\tconfig\n\t\t});\n\t\tawait wrappedGenerator.setup;\n\t\treturn IterableReadableStream.fromAsyncGenerator(wrappedGenerator);\n\t}\n};\n/**\n* A runnable that runs a mapping of runnables in parallel,\n* and returns a mapping of their outputs.\n* @example\n* ```typescript\n* import {\n*   RunnableLambda,\n*   RunnableParallel,\n* } from \"@langchain/core/runnables\";\n*\n* const addYears = (age: number): number => age + 5;\n* const yearsToFifty = (age: number): number => 50 - age;\n* const yearsToHundred = (age: number): number => 100 - age;\n*\n* const addYearsLambda = RunnableLambda.from(addYears);\n* const milestoneFiftyLambda = RunnableLambda.from(yearsToFifty);\n* const milestoneHundredLambda = RunnableLambda.from(yearsToHundred);\n*\n* // Pipe will coerce objects into RunnableParallel by default, but we\n* // explicitly instantiate one here to demonstrate\n* const sequence = addYearsLambda.pipe(\n*   RunnableParallel.from({\n*     years_to_fifty: milestoneFiftyLambda,\n*     years_to_hundred: milestoneHundredLambda,\n*   })\n* );\n*\n* // Invoke the sequence with a single age input\n* const res = await sequence.invoke(25);\n*\n* // { years_to_fifty: 20, years_to_hundred: 70 }\n* ```\n*/\nvar RunnableParallel = class extends RunnableMap {};\n/**\n* A Runnable that can fallback to other Runnables if it fails.\n* External APIs (e.g., APIs for a language model) may at times experience\n* degraded performance or even downtime.\n*\n* In these cases, it can be useful to have a fallback Runnable that can be\n* used in place of the original Runnable (e.g., fallback to another LLM provider).\n*\n* Fallbacks can be defined at the level of a single Runnable, or at the level\n* of a chain of Runnables. Fallbacks are tried in order until one succeeds or\n* all fail.\n*\n* While you can instantiate a `RunnableWithFallbacks` directly, it is usually\n* more convenient to use the `withFallbacks` method on an existing Runnable.\n*\n* When streaming, fallbacks will only be called on failures during the initial\n* stream creation. Errors that occur after a stream starts will not fallback\n* to the next Runnable.\n*\n* @example\n* ```typescript\n* import {\n*   RunnableLambda,\n*   RunnableWithFallbacks,\n* } from \"@langchain/core/runnables\";\n*\n* const primaryOperation = (input: string): string => {\n*   if (input !== \"safe\") {\n*     throw new Error(\"Primary operation failed due to unsafe input\");\n*   }\n*   return `Processed: ${input}`;\n* };\n*\n* // Define a fallback operation that processes the input differently\n* const fallbackOperation = (input: string): string =>\n*   `Fallback processed: ${input}`;\n*\n* const primaryRunnable = RunnableLambda.from(primaryOperation);\n* const fallbackRunnable = RunnableLambda.from(fallbackOperation);\n*\n* // Apply the fallback logic using the .withFallbacks() method\n* const runnableWithFallback = primaryRunnable.withFallbacks([fallbackRunnable]);\n*\n* // Alternatively, create a RunnableWithFallbacks instance manually\n* const manualFallbackChain = new RunnableWithFallbacks({\n*   runnable: primaryRunnable,\n*   fallbacks: [fallbackRunnable],\n* });\n*\n* // Example invocation using .withFallbacks()\n* const res = await runnableWithFallback\n*   .invoke(\"unsafe input\")\n*   .catch((error) => {\n*     console.error(\"Failed after all attempts:\", error.message);\n*   });\n*\n* // \"Fallback processed: unsafe input\"\n*\n* // Example invocation using manual instantiation\n* const res = await manualFallbackChain\n*   .invoke(\"safe\")\n*   .catch((error) => {\n*     console.error(\"Failed after all attempts:\", error.message);\n*   });\n*\n* // \"Processed: safe\"\n* ```\n*/\nvar RunnableWithFallbacks = class extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableWithFallbacks\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\trunnable;\n\tfallbacks;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.runnable = fields.runnable;\n\t\tthis.fallbacks = fields.fallbacks;\n\t}\n\t*runnables() {\n\t\tyield this.runnable;\n\t\tfor (const fallback of this.fallbacks) yield fallback;\n\t}\n\tasync invoke(input, options) {\n\t\tconst config = ensureConfig(options);\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(config);\n\t\tconst { runId,...otherConfigFields } = config;\n\t\tconst runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, \"input\"), runId, void 0, void 0, void 0, otherConfigFields?.runName);\n\t\tconst childConfig = patchConfig(otherConfigFields, { callbacks: runManager?.getChild() });\n\t\tconst res = await AsyncLocalStorageProviderSingleton.runWithConfig(childConfig, async () => {\n\t\t\tlet firstError;\n\t\t\tfor (const runnable of this.runnables()) {\n\t\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\t\ttry {\n\t\t\t\t\tconst output = await runnable.invoke(input, childConfig);\n\t\t\t\t\tawait runManager?.handleChainEnd(_coerceToDict(output, \"output\"));\n\t\t\t\t\treturn output;\n\t\t\t\t} catch (e) {\n\t\t\t\t\tif (firstError === void 0) firstError = e;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (firstError === void 0) throw new Error(\"No error stored at end of fallback.\");\n\t\t\tawait runManager?.handleChainError(firstError);\n\t\t\tthrow firstError;\n\t\t});\n\t\treturn res;\n\t}\n\tasync *_streamIterator(input, options) {\n\t\tconst config = ensureConfig(options);\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(config);\n\t\tconst { runId,...otherConfigFields } = config;\n\t\tconst runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, \"input\"), runId, void 0, void 0, void 0, otherConfigFields?.runName);\n\t\tlet firstError;\n\t\tlet stream;\n\t\tfor (const runnable of this.runnables()) {\n\t\t\tconfig?.signal?.throwIfAborted();\n\t\t\tconst childConfig = patchConfig(otherConfigFields, { callbacks: runManager?.getChild() });\n\t\t\ttry {\n\t\t\t\tconst originalStream = await runnable.stream(input, childConfig);\n\t\t\t\tstream = consumeAsyncIterableInContext(childConfig, originalStream);\n\t\t\t\tbreak;\n\t\t\t} catch (e) {\n\t\t\t\tif (firstError === void 0) firstError = e;\n\t\t\t}\n\t\t}\n\t\tif (stream === void 0) {\n\t\t\tconst error = firstError ?? /* @__PURE__ */ new Error(\"No error stored at end of fallback.\");\n\t\t\tawait runManager?.handleChainError(error);\n\t\t\tthrow error;\n\t\t}\n\t\tlet output;\n\t\ttry {\n\t\t\tfor await (const chunk of stream) {\n\t\t\t\tyield chunk;\n\t\t\t\ttry {\n\t\t\t\t\toutput = output === void 0 ? output : this._concatOutputChunks(output, chunk);\n\t\t\t\t} catch {\n\t\t\t\t\toutput = void 0;\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(e);\n\t\t\tthrow e;\n\t\t}\n\t\tawait runManager?.handleChainEnd(_coerceToDict(output, \"output\"));\n\t}\n\tasync batch(inputs, options, batchOptions) {\n\t\tif (batchOptions?.returnExceptions) throw new Error(\"Not implemented.\");\n\t\tconst configList = this._getOptionsList(options ?? {}, inputs.length);\n\t\tconst callbackManagers = await Promise.all(configList.map((config) => getCallbackManagerForConfig(config)));\n\t\tconst runManagers = await Promise.all(callbackManagers.map(async (callbackManager, i) => {\n\t\t\tconst handleStartRes = await callbackManager?.handleChainStart(this.toJSON(), _coerceToDict(inputs[i], \"input\"), configList[i].runId, void 0, void 0, void 0, configList[i].runName);\n\t\t\tdelete configList[i].runId;\n\t\t\treturn handleStartRes;\n\t\t}));\n\t\tlet firstError;\n\t\tfor (const runnable of this.runnables()) {\n\t\t\tconfigList[0].signal?.throwIfAborted();\n\t\t\ttry {\n\t\t\t\tconst outputs = await runnable.batch(inputs, runManagers.map((runManager, j) => patchConfig(configList[j], { callbacks: runManager?.getChild() })), batchOptions);\n\t\t\t\tawait Promise.all(runManagers.map((runManager, i) => runManager?.handleChainEnd(_coerceToDict(outputs[i], \"output\"))));\n\t\t\t\treturn outputs;\n\t\t\t} catch (e) {\n\t\t\t\tif (firstError === void 0) firstError = e;\n\t\t\t}\n\t\t}\n\t\tif (!firstError) throw new Error(\"No error stored at end of fallbacks.\");\n\t\tawait Promise.all(runManagers.map((runManager) => runManager?.handleChainError(firstError)));\n\t\tthrow firstError;\n\t}\n};\nfunction _coerceToRunnable(coerceable) {\n\tif (typeof coerceable === \"function\") return new RunnableLambda({ func: coerceable });\n\telse if (Runnable.isRunnable(coerceable)) return coerceable;\n\telse if (!Array.isArray(coerceable) && typeof coerceable === \"object\") {\n\t\tconst runnables = {};\n\t\tfor (const [key, value] of Object.entries(coerceable)) runnables[key] = _coerceToRunnable(value);\n\t\treturn new RunnableMap({ steps: runnables });\n\t} else throw new Error(`Expected a Runnable, function or object.\\nInstead got an unsupported type.`);\n}\n/**\n* A runnable that assigns key-value pairs to inputs of type `Record<string, unknown>`.\n* @example\n* ```typescript\n* import {\n*   RunnableAssign,\n*   RunnableLambda,\n*   RunnableParallel,\n* } from \"@langchain/core/runnables\";\n*\n* const calculateAge = (x: { birthYear: number }): { age: number } => {\n*   const currentYear = new Date().getFullYear();\n*   return { age: currentYear - x.birthYear };\n* };\n*\n* const createGreeting = (x: { name: string }): { greeting: string } => {\n*   return { greeting: `Hello, ${x.name}!` };\n* };\n*\n* const mapper = RunnableParallel.from({\n*   age_step: RunnableLambda.from(calculateAge),\n*   greeting_step: RunnableLambda.from(createGreeting),\n* });\n*\n* const runnableAssign = new RunnableAssign({ mapper });\n*\n* const res = await runnableAssign.invoke({ name: \"Alice\", birthYear: 1990 });\n*\n* // { name: \"Alice\", birthYear: 1990, age_step: { age: 34 }, greeting_step: { greeting: \"Hello, Alice!\" } }\n* ```\n*/\nvar RunnableAssign = class extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableAssign\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\tmapper;\n\tconstructor(fields) {\n\t\tif (fields instanceof RunnableMap) fields = { mapper: fields };\n\t\tsuper(fields);\n\t\tthis.mapper = fields.mapper;\n\t}\n\tasync invoke(input, options) {\n\t\tconst mapperResult = await this.mapper.invoke(input, options);\n\t\treturn {\n\t\t\t...input,\n\t\t\t...mapperResult\n\t\t};\n\t}\n\tasync *_transform(generator, runManager, options) {\n\t\tconst mapperKeys = this.mapper.getStepsKeys();\n\t\tconst [forPassthrough, forMapper] = atee(generator);\n\t\tconst mapperOutput = this.mapper.transform(forMapper, patchConfig(options, { callbacks: runManager?.getChild() }));\n\t\tconst firstMapperChunkPromise = mapperOutput.next();\n\t\tfor await (const chunk of forPassthrough) {\n\t\t\tif (typeof chunk !== \"object\" || Array.isArray(chunk)) throw new Error(`RunnableAssign can only be used with objects as input, got ${typeof chunk}`);\n\t\t\tconst filtered = Object.fromEntries(Object.entries(chunk).filter(([key]) => !mapperKeys.includes(key)));\n\t\t\tif (Object.keys(filtered).length > 0) yield filtered;\n\t\t}\n\t\tyield (await firstMapperChunkPromise).value;\n\t\tfor await (const chunk of mapperOutput) yield chunk;\n\t}\n\ttransform(generator, options) {\n\t\treturn this._transformStreamWithConfig(generator, this._transform.bind(this), options);\n\t}\n\tasync stream(input, options) {\n\t\tasync function* generator() {\n\t\t\tyield input;\n\t\t}\n\t\tconst config = ensureConfig(options);\n\t\tconst wrappedGenerator = new AsyncGeneratorWithSetup({\n\t\t\tgenerator: this.transform(generator(), config),\n\t\t\tconfig\n\t\t});\n\t\tawait wrappedGenerator.setup;\n\t\treturn IterableReadableStream.fromAsyncGenerator(wrappedGenerator);\n\t}\n};\n/**\n* A runnable that assigns key-value pairs to inputs of type `Record<string, unknown>`.\n* Useful for streaming, can be automatically created and chained by calling `runnable.pick();`.\n* @example\n* ```typescript\n* import { RunnablePick } from \"@langchain/core/runnables\";\n*\n* const inputData = {\n*   name: \"John\",\n*   age: 30,\n*   city: \"New York\",\n*   country: \"USA\",\n*   email: \"john.doe@example.com\",\n*   phone: \"+1234567890\",\n* };\n*\n* const basicInfoRunnable = new RunnablePick([\"name\", \"city\"]);\n*\n* // Example invocation\n* const res = await basicInfoRunnable.invoke(inputData);\n*\n* // { name: 'John', city: 'New York' }\n* ```\n*/\nvar RunnablePick = class extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnablePick\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\tkeys;\n\tconstructor(fields) {\n\t\tif (typeof fields === \"string\" || Array.isArray(fields)) fields = { keys: fields };\n\t\tsuper(fields);\n\t\tthis.keys = fields.keys;\n\t}\n\tasync _pick(input) {\n\t\tif (typeof this.keys === \"string\") return input[this.keys];\n\t\telse {\n\t\t\tconst picked = this.keys.map((key) => [key, input[key]]).filter((v) => v[1] !== void 0);\n\t\t\treturn picked.length === 0 ? void 0 : Object.fromEntries(picked);\n\t\t}\n\t}\n\tasync invoke(input, options) {\n\t\treturn this._callWithConfig(this._pick.bind(this), input, options);\n\t}\n\tasync *_transform(generator) {\n\t\tfor await (const chunk of generator) {\n\t\t\tconst picked = await this._pick(chunk);\n\t\t\tif (picked !== void 0) yield picked;\n\t\t}\n\t}\n\ttransform(generator, options) {\n\t\treturn this._transformStreamWithConfig(generator, this._transform.bind(this), options);\n\t}\n\tasync stream(input, options) {\n\t\tasync function* generator() {\n\t\t\tyield input;\n\t\t}\n\t\tconst config = ensureConfig(options);\n\t\tconst wrappedGenerator = new AsyncGeneratorWithSetup({\n\t\t\tgenerator: this.transform(generator(), config),\n\t\t\tconfig\n\t\t});\n\t\tawait wrappedGenerator.setup;\n\t\treturn IterableReadableStream.fromAsyncGenerator(wrappedGenerator);\n\t}\n};\nvar RunnableToolLike = class extends RunnableBinding {\n\tname;\n\tdescription;\n\tschema;\n\tconstructor(fields) {\n\t\tconst sequence = RunnableSequence.from([RunnableLambda.from(async (input) => {\n\t\t\tlet toolInput;\n\t\t\tif (_isToolCall(input)) try {\n\t\t\t\ttoolInput = await interopParseAsync(this.schema, input.args);\n\t\t\t} catch {\n\t\t\t\tthrow new ToolInputParsingException(`Received tool input did not match expected schema`, JSON.stringify(input.args));\n\t\t\t}\n\t\t\telse toolInput = input;\n\t\t\treturn toolInput;\n\t\t}).withConfig({ runName: `${fields.name}:parse_input` }), fields.bound]).withConfig({ runName: fields.name });\n\t\tsuper({\n\t\t\tbound: sequence,\n\t\t\tconfig: fields.config ?? {}\n\t\t});\n\t\tthis.name = fields.name;\n\t\tthis.description = fields.description;\n\t\tthis.schema = fields.schema;\n\t}\n\tstatic lc_name() {\n\t\treturn \"RunnableToolLike\";\n\t}\n};\n/**\n* Given a runnable and a Zod schema, convert the runnable to a tool.\n*\n* @template RunInput The input type for the runnable.\n* @template RunOutput The output type for the runnable.\n*\n* @param {Runnable<RunInput, RunOutput>} runnable The runnable to convert to a tool.\n* @param fields\n* @param {string | undefined} [fields.name] The name of the tool. If not provided, it will default to the name of the runnable.\n* @param {string | undefined} [fields.description] The description of the tool. Falls back to the description on the Zod schema if not provided, or undefined if neither are provided.\n* @param {InteropZodType<RunInput>} [fields.schema] The Zod schema for the input of the tool. Infers the Zod type from the input type of the runnable.\n* @returns {RunnableToolLike<InteropZodType<RunInput>, RunOutput>} An instance of `RunnableToolLike` which is a runnable that can be used as a tool.\n*/\nfunction convertRunnableToTool(runnable, fields) {\n\tconst name = fields.name ?? runnable.getName();\n\tconst description = fields.description ?? getSchemaDescription(fields.schema);\n\tif (isSimpleStringZodSchema(fields.schema)) return new RunnableToolLike({\n\t\tname,\n\t\tdescription,\n\t\tschema: z.object({ input: z.string() }).transform((input) => input.input),\n\t\tbound: runnable\n\t});\n\treturn new RunnableToolLike({\n\t\tname,\n\t\tdescription,\n\t\tschema: fields.schema,\n\t\tbound: runnable\n\t});\n}\n\n//#endregion\nexport { Runnable, RunnableAssign, RunnableBinding, RunnableEach, RunnableLambda, RunnableMap, RunnableParallel, RunnablePick, RunnableRetry, RunnableSequence, RunnableToolLike, RunnableWithFallbacks, _coerceToDict, _coerceToRunnable };\n//# sourceMappingURL=base.js.map","import { isBaseMessageChunk } from \"./base.js\";\nimport { ToolMessage, ToolMessageChunk } from \"./tool.js\";\nimport { AIMessage, AIMessageChunk } from \"./ai.js\";\nimport { ChatMessage, ChatMessageChunk } from \"./chat.js\";\nimport { FunctionMessage, FunctionMessageChunk } from \"./function.js\";\nimport { HumanMessage, HumanMessageChunk } from \"./human.js\";\nimport { SystemMessage, SystemMessageChunk } from \"./system.js\";\nimport { RemoveMessage } from \"./modifier.js\";\nimport { convertToChunk } from \"./utils.js\";\nimport { RunnableLambda } from \"../runnables/base.js\";\n\n//#region src/messages/transformers.ts\nconst _isMessageType = (msg, types) => {\n\tconst typesAsStrings = [...new Set(types?.map((t) => {\n\t\tif (typeof t === \"string\") return t;\n\t\tconst instantiatedMsgClass = new t({});\n\t\tif (!(\"getType\" in instantiatedMsgClass) || typeof instantiatedMsgClass.getType !== \"function\") throw new Error(\"Invalid type provided.\");\n\t\treturn instantiatedMsgClass.getType();\n\t}))];\n\tconst msgType = msg.getType();\n\treturn typesAsStrings.some((t) => t === msgType);\n};\nfunction filterMessages(messagesOrOptions, options) {\n\tif (Array.isArray(messagesOrOptions)) return _filterMessages(messagesOrOptions, options);\n\treturn RunnableLambda.from((input) => {\n\t\treturn _filterMessages(input, messagesOrOptions);\n\t});\n}\nfunction _filterMessages(messages, options = {}) {\n\tconst { includeNames, excludeNames, includeTypes, excludeTypes, includeIds, excludeIds } = options;\n\tconst filtered = [];\n\tfor (const msg of messages) {\n\t\tif (excludeNames && msg.name && excludeNames.includes(msg.name)) continue;\n\t\telse if (excludeTypes && _isMessageType(msg, excludeTypes)) continue;\n\t\telse if (excludeIds && msg.id && excludeIds.includes(msg.id)) continue;\n\t\tif (!(includeTypes || includeIds || includeNames)) filtered.push(msg);\n\t\telse if (includeNames && msg.name && includeNames.some((iName) => iName === msg.name)) filtered.push(msg);\n\t\telse if (includeTypes && _isMessageType(msg, includeTypes)) filtered.push(msg);\n\t\telse if (includeIds && msg.id && includeIds.some((id) => id === msg.id)) filtered.push(msg);\n\t}\n\treturn filtered;\n}\nfunction mergeMessageRuns(messages) {\n\tif (Array.isArray(messages)) return _mergeMessageRuns(messages);\n\treturn RunnableLambda.from(_mergeMessageRuns);\n}\nfunction _mergeMessageRuns(messages) {\n\tif (!messages.length) return [];\n\tconst merged = [];\n\tfor (const msg of messages) {\n\t\tconst curr = msg;\n\t\tconst last = merged.pop();\n\t\tif (!last) merged.push(curr);\n\t\telse if (curr.getType() === \"tool\" || !(curr.getType() === last.getType())) merged.push(last, curr);\n\t\telse {\n\t\t\tconst lastChunk = convertToChunk(last);\n\t\t\tconst currChunk = convertToChunk(curr);\n\t\t\tconst mergedChunks = lastChunk.concat(currChunk);\n\t\t\tif (typeof lastChunk.content === \"string\" && typeof currChunk.content === \"string\") mergedChunks.content = `${lastChunk.content}\\n${currChunk.content}`;\n\t\t\tmerged.push(_chunkToMsg(mergedChunks));\n\t\t}\n\t}\n\treturn merged;\n}\nfunction trimMessages(messagesOrOptions, options) {\n\tif (Array.isArray(messagesOrOptions)) {\n\t\tconst messages = messagesOrOptions;\n\t\tif (!options) throw new Error(\"Options parameter is required when providing messages.\");\n\t\treturn _trimMessagesHelper(messages, options);\n\t} else {\n\t\tconst trimmerOptions = messagesOrOptions;\n\t\treturn RunnableLambda.from((input) => _trimMessagesHelper(input, trimmerOptions)).withConfig({ runName: \"trim_messages\" });\n\t}\n}\nasync function _trimMessagesHelper(messages, options) {\n\tconst { maxTokens, tokenCounter, strategy = \"last\", allowPartial = false, endOn, startOn, includeSystem = false, textSplitter } = options;\n\tif (startOn && strategy === \"first\") throw new Error(\"`startOn` should only be specified if `strategy` is 'last'.\");\n\tif (includeSystem && strategy === \"first\") throw new Error(\"`includeSystem` should only be specified if `strategy` is 'last'.\");\n\tlet listTokenCounter;\n\tif (\"getNumTokens\" in tokenCounter) listTokenCounter = async (msgs) => {\n\t\tconst tokenCounts = await Promise.all(msgs.map((msg) => tokenCounter.getNumTokens(msg.content)));\n\t\treturn tokenCounts.reduce((sum, count) => sum + count, 0);\n\t};\n\telse listTokenCounter = async (msgs) => tokenCounter(msgs);\n\tlet textSplitterFunc = defaultTextSplitter;\n\tif (textSplitter) if (\"splitText\" in textSplitter) textSplitterFunc = textSplitter.splitText;\n\telse textSplitterFunc = async (text) => textSplitter(text);\n\tif (strategy === \"first\") return _firstMaxTokens(messages, {\n\t\tmaxTokens,\n\t\ttokenCounter: listTokenCounter,\n\t\ttextSplitter: textSplitterFunc,\n\t\tpartialStrategy: allowPartial ? \"first\" : void 0,\n\t\tendOn\n\t});\n\telse if (strategy === \"last\") return _lastMaxTokens(messages, {\n\t\tmaxTokens,\n\t\ttokenCounter: listTokenCounter,\n\t\ttextSplitter: textSplitterFunc,\n\t\tallowPartial,\n\t\tincludeSystem,\n\t\tstartOn,\n\t\tendOn\n\t});\n\telse throw new Error(`Unrecognized strategy: '${strategy}'. Must be one of 'first' or 'last'.`);\n}\nasync function _firstMaxTokens(messages, options) {\n\tconst { maxTokens, tokenCounter, textSplitter, partialStrategy, endOn } = options;\n\tlet messagesCopy = [...messages];\n\tlet idx = 0;\n\tfor (let i = 0; i < messagesCopy.length; i += 1) {\n\t\tconst remainingMessages = i > 0 ? messagesCopy.slice(0, -i) : messagesCopy;\n\t\tif (await tokenCounter(remainingMessages) <= maxTokens) {\n\t\t\tidx = messagesCopy.length - i;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (idx < messagesCopy.length && partialStrategy) {\n\t\tlet includedPartial = false;\n\t\tif (Array.isArray(messagesCopy[idx].content)) {\n\t\t\tconst excluded = messagesCopy[idx];\n\t\t\tif (typeof excluded.content === \"string\") throw new Error(\"Expected content to be an array.\");\n\t\t\tconst numBlock = excluded.content.length;\n\t\t\tconst reversedContent = partialStrategy === \"last\" ? [...excluded.content].reverse() : excluded.content;\n\t\t\tfor (let i = 1; i <= numBlock; i += 1) {\n\t\t\t\tconst partialContent = partialStrategy === \"first\" ? reversedContent.slice(0, i) : reversedContent.slice(-i);\n\t\t\t\tconst fields = Object.fromEntries(Object.entries(excluded).filter(([k]) => k !== \"type\" && !k.startsWith(\"lc_\")));\n\t\t\t\tconst updatedMessage = _switchTypeToMessage(excluded.getType(), {\n\t\t\t\t\t...fields,\n\t\t\t\t\tcontent: partialContent\n\t\t\t\t});\n\t\t\t\tconst slicedMessages = [...messagesCopy.slice(0, idx), updatedMessage];\n\t\t\t\tif (await tokenCounter(slicedMessages) <= maxTokens) {\n\t\t\t\t\tmessagesCopy = slicedMessages;\n\t\t\t\t\tidx += 1;\n\t\t\t\t\tincludedPartial = true;\n\t\t\t\t} else break;\n\t\t\t}\n\t\t\tif (includedPartial && partialStrategy === \"last\") excluded.content = [...reversedContent].reverse();\n\t\t}\n\t\tif (!includedPartial) {\n\t\t\tconst excluded = messagesCopy[idx];\n\t\t\tlet text;\n\t\t\tif (Array.isArray(excluded.content) && excluded.content.some((block) => typeof block === \"string\" || block.type === \"text\")) {\n\t\t\t\tconst textBlock = excluded.content.find((block) => block.type === \"text\" && block.text);\n\t\t\t\ttext = textBlock?.text;\n\t\t\t} else if (typeof excluded.content === \"string\") text = excluded.content;\n\t\t\tif (text) {\n\t\t\t\tconst splitTexts = await textSplitter(text);\n\t\t\t\tconst numSplits = splitTexts.length;\n\t\t\t\tif (partialStrategy === \"last\") splitTexts.reverse();\n\t\t\t\tfor (let _ = 0; _ < numSplits - 1; _ += 1) {\n\t\t\t\t\tsplitTexts.pop();\n\t\t\t\t\texcluded.content = splitTexts.join(\"\");\n\t\t\t\t\tif (await tokenCounter([...messagesCopy.slice(0, idx), excluded]) <= maxTokens) {\n\t\t\t\t\t\tif (partialStrategy === \"last\") excluded.content = [...splitTexts].reverse().join(\"\");\n\t\t\t\t\t\tmessagesCopy = [...messagesCopy.slice(0, idx), excluded];\n\t\t\t\t\t\tidx += 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif (endOn) {\n\t\tconst endOnArr = Array.isArray(endOn) ? endOn : [endOn];\n\t\twhile (idx > 0 && !_isMessageType(messagesCopy[idx - 1], endOnArr)) idx -= 1;\n\t}\n\treturn messagesCopy.slice(0, idx);\n}\nasync function _lastMaxTokens(messages, options) {\n\tconst { allowPartial = false, includeSystem = false, endOn, startOn,...rest } = options;\n\tlet messagesCopy = messages.map((message) => {\n\t\tconst fields = Object.fromEntries(Object.entries(message).filter(([k]) => k !== \"type\" && !k.startsWith(\"lc_\")));\n\t\treturn _switchTypeToMessage(message.getType(), fields, isBaseMessageChunk(message));\n\t});\n\tif (endOn) {\n\t\tconst endOnArr = Array.isArray(endOn) ? endOn : [endOn];\n\t\twhile (messagesCopy.length > 0 && !_isMessageType(messagesCopy[messagesCopy.length - 1], endOnArr)) messagesCopy = messagesCopy.slice(0, -1);\n\t}\n\tconst swappedSystem = includeSystem && messagesCopy[0]?.getType() === \"system\";\n\tlet reversed_ = swappedSystem ? messagesCopy.slice(0, 1).concat(messagesCopy.slice(1).reverse()) : messagesCopy.reverse();\n\treversed_ = await _firstMaxTokens(reversed_, {\n\t\t...rest,\n\t\tpartialStrategy: allowPartial ? \"last\" : void 0,\n\t\tendOn: startOn\n\t});\n\tif (swappedSystem) return [reversed_[0], ...reversed_.slice(1).reverse()];\n\telse return reversed_.reverse();\n}\nconst _MSG_CHUNK_MAP = {\n\thuman: {\n\t\tmessage: HumanMessage,\n\t\tmessageChunk: HumanMessageChunk\n\t},\n\tai: {\n\t\tmessage: AIMessage,\n\t\tmessageChunk: AIMessageChunk\n\t},\n\tsystem: {\n\t\tmessage: SystemMessage,\n\t\tmessageChunk: SystemMessageChunk\n\t},\n\tdeveloper: {\n\t\tmessage: SystemMessage,\n\t\tmessageChunk: SystemMessageChunk\n\t},\n\ttool: {\n\t\tmessage: ToolMessage,\n\t\tmessageChunk: ToolMessageChunk\n\t},\n\tfunction: {\n\t\tmessage: FunctionMessage,\n\t\tmessageChunk: FunctionMessageChunk\n\t},\n\tgeneric: {\n\t\tmessage: ChatMessage,\n\t\tmessageChunk: ChatMessageChunk\n\t},\n\tremove: {\n\t\tmessage: RemoveMessage,\n\t\tmessageChunk: RemoveMessage\n\t}\n};\nfunction _switchTypeToMessage(messageType, fields, returnChunk) {\n\tlet chunk;\n\tlet msg;\n\tswitch (messageType) {\n\t\tcase \"human\":\n\t\t\tif (returnChunk) chunk = new HumanMessageChunk(fields);\n\t\t\telse msg = new HumanMessage(fields);\n\t\t\tbreak;\n\t\tcase \"ai\":\n\t\t\tif (returnChunk) {\n\t\t\t\tlet aiChunkFields = { ...fields };\n\t\t\t\tif (\"tool_calls\" in aiChunkFields) aiChunkFields = {\n\t\t\t\t\t...aiChunkFields,\n\t\t\t\t\ttool_call_chunks: aiChunkFields.tool_calls?.map((tc) => ({\n\t\t\t\t\t\t...tc,\n\t\t\t\t\t\ttype: \"tool_call_chunk\",\n\t\t\t\t\t\tindex: void 0,\n\t\t\t\t\t\targs: JSON.stringify(tc.args)\n\t\t\t\t\t}))\n\t\t\t\t};\n\t\t\t\tchunk = new AIMessageChunk(aiChunkFields);\n\t\t\t} else msg = new AIMessage(fields);\n\t\t\tbreak;\n\t\tcase \"system\":\n\t\t\tif (returnChunk) chunk = new SystemMessageChunk(fields);\n\t\t\telse msg = new SystemMessage(fields);\n\t\t\tbreak;\n\t\tcase \"developer\":\n\t\t\tif (returnChunk) chunk = new SystemMessageChunk({\n\t\t\t\t...fields,\n\t\t\t\tadditional_kwargs: {\n\t\t\t\t\t...fields.additional_kwargs,\n\t\t\t\t\t__openai_role__: \"developer\"\n\t\t\t\t}\n\t\t\t});\n\t\t\telse msg = new SystemMessage({\n\t\t\t\t...fields,\n\t\t\t\tadditional_kwargs: {\n\t\t\t\t\t...fields.additional_kwargs,\n\t\t\t\t\t__openai_role__: \"developer\"\n\t\t\t\t}\n\t\t\t});\n\t\t\tbreak;\n\t\tcase \"tool\":\n\t\t\tif (\"tool_call_id\" in fields) if (returnChunk) chunk = new ToolMessageChunk(fields);\n\t\t\telse msg = new ToolMessage(fields);\n\t\t\telse throw new Error(\"Can not convert ToolMessage to ToolMessageChunk if 'tool_call_id' field is not defined.\");\n\t\t\tbreak;\n\t\tcase \"function\":\n\t\t\tif (returnChunk) chunk = new FunctionMessageChunk(fields);\n\t\t\telse {\n\t\t\t\tif (!fields.name) throw new Error(\"FunctionMessage must have a 'name' field\");\n\t\t\t\tmsg = new FunctionMessage(fields);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase \"generic\":\n\t\t\tif (\"role\" in fields) if (returnChunk) chunk = new ChatMessageChunk(fields);\n\t\t\telse msg = new ChatMessage(fields);\n\t\t\telse throw new Error(\"Can not convert ChatMessage to ChatMessageChunk if 'role' field is not defined.\");\n\t\t\tbreak;\n\t\tdefault: throw new Error(`Unrecognized message type ${messageType}`);\n\t}\n\tif (returnChunk && chunk) return chunk;\n\tif (msg) return msg;\n\tthrow new Error(`Unrecognized message type ${messageType}`);\n}\nfunction _chunkToMsg(chunk) {\n\tconst chunkType = chunk.getType();\n\tlet msg;\n\tconst fields = Object.fromEntries(Object.entries(chunk).filter(([k]) => ![\"type\", \"tool_call_chunks\"].includes(k) && !k.startsWith(\"lc_\")));\n\tif (chunkType in _MSG_CHUNK_MAP) msg = _switchTypeToMessage(chunkType, fields);\n\tif (!msg) throw new Error(`Unrecognized message chunk class ${chunkType}. Supported classes are ${Object.keys(_MSG_CHUNK_MAP)}`);\n\treturn msg;\n}\n/**\n* The default text splitter function that splits text by newlines.\n*\n* @param {string} text\n* @returns A promise that resolves to an array of strings split by newlines.\n*/\nfunction defaultTextSplitter(text) {\n\tconst splits = text.split(\"\\n\");\n\treturn Promise.resolve([...splits.slice(0, -1).map((s) => `${s}\\n`), splits[splits.length - 1]]);\n}\n\n//#endregion\nexport { defaultTextSplitter, filterMessages, mergeMessageRuns, trimMessages };\n//# sourceMappingURL=transformers.js.map","//#region src/messages/content/tools.ts\nconst KNOWN_BLOCK_TYPES = [\n\t\"tool_call\",\n\t\"tool_call_chunk\",\n\t\"invalid_tool_call\",\n\t\"server_tool_call\",\n\t\"server_tool_call_chunk\",\n\t\"server_tool_call_result\"\n];\n\n//#endregion\nexport { KNOWN_BLOCK_TYPES };\n//# sourceMappingURL=tools.js.map","//#region src/messages/content/multimodal.ts\nconst KNOWN_BLOCK_TYPES = [\n\t\"image\",\n\t\"video\",\n\t\"audio\",\n\t\"text-plain\",\n\t\"file\"\n];\n\n//#endregion\nexport { KNOWN_BLOCK_TYPES };\n//# sourceMappingURL=multimodal.js.map","import { KNOWN_BLOCK_TYPES } from \"./tools.js\";\nimport { KNOWN_BLOCK_TYPES as KNOWN_BLOCK_TYPES$1 } from \"./multimodal.js\";\n\n//#region src/messages/content/index.ts\nconst KNOWN_BLOCK_TYPES$2 = [\n\t\"text\",\n\t\"reasoning\",\n\t...KNOWN_BLOCK_TYPES,\n\t...KNOWN_BLOCK_TYPES$1\n];\n\n//#endregion\nexport { KNOWN_BLOCK_TYPES$2 as KNOWN_BLOCK_TYPES };\n//# sourceMappingURL=index.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { convertToOpenAIImageBlock, convertToProviderContentBlock, isBase64ContentBlock, isDataContentBlock, isIDContentBlock, isPlainTextContentBlock, isURLContentBlock, parseBase64DataUrl, parseMimeType } from \"./content/data.js\";\nimport { isMessage } from \"./message.js\";\nimport { BaseMessage, BaseMessageChunk, _isMessageFieldWithRole, _mergeDicts, _mergeLists, _mergeObj, _mergeStatus, isBaseMessage, isBaseMessageChunk, isOpenAIToolCallArray, mergeContent } from \"./base.js\";\nimport { mergeResponseMetadata, mergeUsageMetadata } from \"./metadata.js\";\nimport { ToolMessage, ToolMessageChunk, defaultToolCallParser, isDirectToolOutput, isToolMessage, isToolMessageChunk } from \"./tool.js\";\nimport { AIMessage, AIMessageChunk, isAIMessage, isAIMessageChunk } from \"./ai.js\";\nimport { ChatMessage, ChatMessageChunk, isChatMessage, isChatMessageChunk } from \"./chat.js\";\nimport { FunctionMessage, FunctionMessageChunk, isFunctionMessage, isFunctionMessageChunk } from \"./function.js\";\nimport { HumanMessage, HumanMessageChunk, isHumanMessage, isHumanMessageChunk } from \"./human.js\";\nimport { SystemMessage, SystemMessageChunk, isSystemMessage, isSystemMessageChunk } from \"./system.js\";\nimport { RemoveMessage } from \"./modifier.js\";\nimport { coerceMessageLikeToMessage, convertToChunk, getBufferString, iife, mapChatMessagesToStoredMessages, mapStoredMessageToChatMessage, mapStoredMessagesToChatMessages } from \"./utils.js\";\nimport { defaultTextSplitter, filterMessages, mergeMessageRuns, trimMessages } from \"./transformers.js\";\nimport { KNOWN_BLOCK_TYPES } from \"./content/index.js\";\n\n//#region src/messages/index.ts\nvar messages_exports = {};\n__export(messages_exports, {\n\tAIMessage: () => AIMessage,\n\tAIMessageChunk: () => AIMessageChunk,\n\tBaseMessage: () => BaseMessage,\n\tBaseMessageChunk: () => BaseMessageChunk,\n\tChatMessage: () => ChatMessage,\n\tChatMessageChunk: () => ChatMessageChunk,\n\tFunctionMessage: () => FunctionMessage,\n\tFunctionMessageChunk: () => FunctionMessageChunk,\n\tHumanMessage: () => HumanMessage,\n\tHumanMessageChunk: () => HumanMessageChunk,\n\tKNOWN_BLOCK_TYPES: () => KNOWN_BLOCK_TYPES,\n\tRemoveMessage: () => RemoveMessage,\n\tSystemMessage: () => SystemMessage,\n\tSystemMessageChunk: () => SystemMessageChunk,\n\tToolMessage: () => ToolMessage,\n\tToolMessageChunk: () => ToolMessageChunk,\n\t_isMessageFieldWithRole: () => _isMessageFieldWithRole,\n\t_mergeDicts: () => _mergeDicts,\n\t_mergeLists: () => _mergeLists,\n\t_mergeObj: () => _mergeObj,\n\t_mergeStatus: () => _mergeStatus,\n\tcoerceMessageLikeToMessage: () => coerceMessageLikeToMessage,\n\tconvertToChunk: () => convertToChunk,\n\tconvertToOpenAIImageBlock: () => convertToOpenAIImageBlock,\n\tconvertToProviderContentBlock: () => convertToProviderContentBlock,\n\tdefaultTextSplitter: () => defaultTextSplitter,\n\tdefaultToolCallParser: () => defaultToolCallParser,\n\tfilterMessages: () => filterMessages,\n\tgetBufferString: () => getBufferString,\n\tiife: () => iife,\n\tisAIMessage: () => isAIMessage,\n\tisAIMessageChunk: () => isAIMessageChunk,\n\tisBase64ContentBlock: () => isBase64ContentBlock,\n\tisBaseMessage: () => isBaseMessage,\n\tisBaseMessageChunk: () => isBaseMessageChunk,\n\tisChatMessage: () => isChatMessage,\n\tisChatMessageChunk: () => isChatMessageChunk,\n\tisDataContentBlock: () => isDataContentBlock,\n\tisDirectToolOutput: () => isDirectToolOutput,\n\tisFunctionMessage: () => isFunctionMessage,\n\tisFunctionMessageChunk: () => isFunctionMessageChunk,\n\tisHumanMessage: () => isHumanMessage,\n\tisHumanMessageChunk: () => isHumanMessageChunk,\n\tisIDContentBlock: () => isIDContentBlock,\n\tisMessage: () => isMessage,\n\tisOpenAIToolCallArray: () => isOpenAIToolCallArray,\n\tisPlainTextContentBlock: () => isPlainTextContentBlock,\n\tisSystemMessage: () => isSystemMessage,\n\tisSystemMessageChunk: () => isSystemMessageChunk,\n\tisToolMessage: () => isToolMessage,\n\tisToolMessageChunk: () => isToolMessageChunk,\n\tisURLContentBlock: () => isURLContentBlock,\n\tmapChatMessagesToStoredMessages: () => mapChatMessagesToStoredMessages,\n\tmapStoredMessageToChatMessage: () => mapStoredMessageToChatMessage,\n\tmapStoredMessagesToChatMessages: () => mapStoredMessagesToChatMessages,\n\tmergeContent: () => mergeContent,\n\tmergeMessageRuns: () => mergeMessageRuns,\n\tmergeResponseMetadata: () => mergeResponseMetadata,\n\tmergeUsageMetadata: () => mergeUsageMetadata,\n\tparseBase64DataUrl: () => parseBase64DataUrl,\n\tparseMimeType: () => parseMimeType,\n\ttrimMessages: () => trimMessages\n});\n\n//#endregion\nexport { AIMessage, AIMessageChunk, BaseMessage, BaseMessageChunk, ChatMessage, ChatMessageChunk, FunctionMessage, FunctionMessageChunk, HumanMessage, HumanMessageChunk, KNOWN_BLOCK_TYPES, RemoveMessage, SystemMessage, SystemMessageChunk, ToolMessage, ToolMessageChunk, _isMessageFieldWithRole, _mergeDicts, _mergeLists, _mergeObj, _mergeStatus, coerceMessageLikeToMessage, convertToChunk, convertToOpenAIImageBlock, convertToProviderContentBlock, defaultTextSplitter, defaultToolCallParser, filterMessages, getBufferString, iife, isAIMessage, isAIMessageChunk, isBase64ContentBlock, isBaseMessage, isBaseMessageChunk, isChatMessage, isChatMessageChunk, isDataContentBlock, isDirectToolOutput, isFunctionMessage, isFunctionMessageChunk, isHumanMessage, isHumanMessageChunk, isIDContentBlock, isMessage, isOpenAIToolCallArray, isPlainTextContentBlock, isSystemMessage, isSystemMessageChunk, isToolMessage, isToolMessageChunk, isURLContentBlock, mapChatMessagesToStoredMessages, mapStoredMessageToChatMessage, mapStoredMessagesToChatMessages, mergeContent, mergeMessageRuns, mergeResponseMetadata, mergeUsageMetadata, messages_exports, parseBase64DataUrl, parseMimeType, trimMessages };\n//# sourceMappingURL=index.js.map","import { __export } from \"./_virtual/rolldown_runtime.js\";\nimport { Serializable } from \"./load/serializable.js\";\nimport { AIMessage } from \"./messages/ai.js\";\nimport { HumanMessage } from \"./messages/human.js\";\nimport \"./messages/index.js\";\n\n//#region src/chat_history.ts\nvar chat_history_exports = {};\n__export(chat_history_exports, {\n\tBaseChatMessageHistory: () => BaseChatMessageHistory,\n\tBaseListChatMessageHistory: () => BaseListChatMessageHistory,\n\tInMemoryChatMessageHistory: () => InMemoryChatMessageHistory\n});\n/**\n* Base class for all chat message histories. All chat message histories\n* should extend this class.\n*/\nvar BaseChatMessageHistory = class extends Serializable {\n\t/**\n\t* Add a list of messages.\n\t*\n\t* Implementations should override this method to handle bulk addition of messages\n\t* in an efficient manner to avoid unnecessary round-trips to the underlying store.\n\t*\n\t* @param messages - A list of BaseMessage objects to store.\n\t*/\n\tasync addMessages(messages) {\n\t\tfor (const message of messages) await this.addMessage(message);\n\t}\n};\n/**\n* Base class for all list chat message histories. All list chat message\n* histories should extend this class.\n*/\nvar BaseListChatMessageHistory = class extends Serializable {\n\t/**\n\t* This is a convenience method for adding a human message string to the store.\n\t* Please note that this is a convenience method. Code should favor the\n\t* bulk addMessages interface instead to save on round-trips to the underlying\n\t* persistence layer.\n\t* This method may be deprecated in a future release.\n\t*/\n\taddUserMessage(message) {\n\t\treturn this.addMessage(new HumanMessage(message));\n\t}\n\t/**\n\t* This is a convenience method for adding an AI message string to the store.\n\t* Please note that this is a convenience method. Code should favor the bulk\n\t* addMessages interface instead to save on round-trips to the underlying\n\t* persistence layer.\n\t* This method may be deprecated in a future release.\n\t*/\n\taddAIMessage(message) {\n\t\treturn this.addMessage(new AIMessage(message));\n\t}\n\t/**\n\t* Add a list of messages.\n\t*\n\t* Implementations should override this method to handle bulk addition of messages\n\t* in an efficient manner to avoid unnecessary round-trips to the underlying store.\n\t*\n\t* @param messages - A list of BaseMessage objects to store.\n\t*/\n\tasync addMessages(messages) {\n\t\tfor (const message of messages) await this.addMessage(message);\n\t}\n\t/**\n\t* Remove all messages from the store.\n\t*/\n\tclear() {\n\t\tthrow new Error(\"Not implemented.\");\n\t}\n};\n/**\n* Class for storing chat message history in-memory. It extends the\n* BaseListChatMessageHistory class and provides methods to get, add, and\n* clear messages.\n*/\nvar InMemoryChatMessageHistory = class extends BaseListChatMessageHistory {\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"stores\",\n\t\t\"message\",\n\t\t\"in_memory\"\n\t];\n\tmessages = [];\n\tconstructor(messages) {\n\t\tsuper(...arguments);\n\t\tthis.messages = messages ?? [];\n\t}\n\t/**\n\t* Method to get all the messages stored in the ChatMessageHistory\n\t* instance.\n\t* @returns Array of stored BaseMessage instances.\n\t*/\n\tasync getMessages() {\n\t\treturn this.messages;\n\t}\n\t/**\n\t* Method to add a new message to the ChatMessageHistory instance.\n\t* @param message The BaseMessage instance to add.\n\t* @returns A promise that resolves when the message has been added.\n\t*/\n\tasync addMessage(message) {\n\t\tthis.messages.push(message);\n\t}\n\t/**\n\t* Method to clear all the messages from the ChatMessageHistory instance.\n\t* @returns A promise that resolves when all messages have been cleared.\n\t*/\n\tasync clear() {\n\t\tthis.messages = [];\n\t}\n};\n\n//#endregion\nexport { BaseChatMessageHistory, BaseListChatMessageHistory, InMemoryChatMessageHistory, chat_history_exports };\n//# sourceMappingURL=chat_history.js.map","import { __export } from \"./_virtual/rolldown_runtime.js\";\nimport { AsyncCaller } from \"./utils/async_caller.js\";\n\n//#region src/embeddings.ts\nvar embeddings_exports = {};\n__export(embeddings_exports, { Embeddings: () => Embeddings });\n/**\n* An abstract class that provides methods for embedding documents and\n* queries using LangChain.\n*/\nvar Embeddings = class {\n\t/**\n\t* The async caller should be used by subclasses to make any async calls,\n\t* which will thus benefit from the concurrency and retry logic.\n\t*/\n\tcaller;\n\tconstructor(params) {\n\t\tthis.caller = new AsyncCaller(params ?? {});\n\t}\n};\n\n//#endregion\nexport { Embeddings, embeddings_exports };\n//# sourceMappingURL=embeddings.js.map","//#region src/index.ts\nvar src_exports = {};\n\n//#endregion\nexport { src_exports };\n//# sourceMappingURL=index.js.map","import { __export } from \"./_virtual/rolldown_runtime.js\";\n\n//#region src/memory.ts\nvar memory_exports = {};\n__export(memory_exports, {\n\tBaseMemory: () => BaseMemory,\n\tgetInputValue: () => getInputValue,\n\tgetOutputValue: () => getOutputValue,\n\tgetPromptInputKey: () => getPromptInputKey\n});\n/**\n* Abstract base class for memory in LangChain's Chains. Memory refers to\n* the state in Chains. It can be used to store information about past\n* executions of a Chain and inject that information into the inputs of\n* future executions of the Chain.\n*/\nvar BaseMemory = class {};\nconst getValue = (values, key) => {\n\tif (key !== void 0) return values[key];\n\tconst keys = Object.keys(values);\n\tif (keys.length === 1) return values[keys[0]];\n};\n/**\n* This function is used by memory classes to select the input value\n* to use for the memory. If there is only one input value, it is used.\n* If there are multiple input values, the inputKey must be specified.\n*/\nconst getInputValue = (inputValues, inputKey) => {\n\tconst value = getValue(inputValues, inputKey);\n\tif (!value) {\n\t\tconst keys = Object.keys(inputValues);\n\t\tthrow new Error(`input values have ${keys.length} keys, you must specify an input key or pass only 1 key as input`);\n\t}\n\treturn value;\n};\n/**\n* This function is used by memory classes to select the output value\n* to use for the memory. If there is only one output value, it is used.\n* If there are multiple output values, the outputKey must be specified.\n* If no outputKey is specified, an error is thrown.\n*/\nconst getOutputValue = (outputValues, outputKey) => {\n\tconst value = getValue(outputValues, outputKey);\n\tif (!value && value !== \"\") {\n\t\tconst keys = Object.keys(outputValues);\n\t\tthrow new Error(`output values have ${keys.length} keys, you must specify an output key or pass only 1 key as output`);\n\t}\n\treturn value;\n};\n/**\n* Function used by memory classes to get the key of the prompt input,\n* excluding any keys that are memory variables or the \"stop\" key. If\n* there is not exactly one prompt input key, an error is thrown.\n*/\nfunction getPromptInputKey(inputs, memoryVariables) {\n\tconst promptInputKeys = Object.keys(inputs).filter((key) => !memoryVariables.includes(key) && key !== \"stop\");\n\tif (promptInputKeys.length !== 1) throw new Error(`One input key expected, but got ${promptInputKeys.length}`);\n\treturn promptInputKeys[0];\n}\n\n//#endregion\nexport { BaseMemory, getInputValue, getOutputValue, getPromptInputKey, memory_exports };\n//# sourceMappingURL=memory.js.map","import { __export } from \"./_virtual/rolldown_runtime.js\";\nimport { Serializable } from \"./load/serializable.js\";\nimport { HumanMessage } from \"./messages/human.js\";\nimport { getBufferString } from \"./messages/utils.js\";\n\n//#region src/prompt_values.ts\nvar prompt_values_exports = {};\n__export(prompt_values_exports, {\n\tBasePromptValue: () => BasePromptValue,\n\tChatPromptValue: () => ChatPromptValue,\n\tImagePromptValue: () => ImagePromptValue,\n\tStringPromptValue: () => StringPromptValue\n});\n/**\n* Base PromptValue class. All prompt values should extend this class.\n*/\nvar BasePromptValue = class extends Serializable {};\n/**\n* Represents a prompt value as a string. It extends the BasePromptValue\n* class and overrides the toString and toChatMessages methods.\n*/\nvar StringPromptValue = class extends BasePromptValue {\n\tstatic lc_name() {\n\t\treturn \"StringPromptValue\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"prompt_values\"];\n\tlc_serializable = true;\n\tvalue;\n\tconstructor(value) {\n\t\tsuper({ value });\n\t\tthis.value = value;\n\t}\n\ttoString() {\n\t\treturn this.value;\n\t}\n\ttoChatMessages() {\n\t\treturn [new HumanMessage(this.value)];\n\t}\n};\n/**\n* Class that represents a chat prompt value. It extends the\n* BasePromptValue and includes an array of BaseMessage instances.\n*/\nvar ChatPromptValue = class extends BasePromptValue {\n\tlc_namespace = [\"langchain_core\", \"prompt_values\"];\n\tlc_serializable = true;\n\tstatic lc_name() {\n\t\treturn \"ChatPromptValue\";\n\t}\n\tmessages;\n\tconstructor(fields) {\n\t\tif (Array.isArray(fields)) fields = { messages: fields };\n\t\tsuper(fields);\n\t\tthis.messages = fields.messages;\n\t}\n\ttoString() {\n\t\treturn getBufferString(this.messages);\n\t}\n\ttoChatMessages() {\n\t\treturn this.messages;\n\t}\n};\n/**\n* Class that represents an image prompt value. It extends the\n* BasePromptValue and includes an ImageURL instance.\n*/\nvar ImagePromptValue = class extends BasePromptValue {\n\tlc_namespace = [\"langchain_core\", \"prompt_values\"];\n\tlc_serializable = true;\n\tstatic lc_name() {\n\t\treturn \"ImagePromptValue\";\n\t}\n\timageUrl;\n\t/** @ignore */\n\tvalue;\n\tconstructor(fields) {\n\t\tif (!(\"imageUrl\" in fields)) fields = { imageUrl: fields };\n\t\tsuper(fields);\n\t\tthis.imageUrl = fields.imageUrl;\n\t}\n\ttoString() {\n\t\treturn this.imageUrl.url;\n\t}\n\ttoChatMessages() {\n\t\treturn [new HumanMessage({ content: [{\n\t\t\ttype: \"image_url\",\n\t\t\timage_url: {\n\t\t\t\tdetail: this.imageUrl.detail,\n\t\t\t\turl: this.imageUrl.url\n\t\t\t}\n\t\t}] })];\n\t}\n};\n\n//#endregion\nexport { BasePromptValue, ChatPromptValue, ImagePromptValue, StringPromptValue, prompt_values_exports };\n//# sourceMappingURL=prompt_values.js.map","import { __export } from \"./_virtual/rolldown_runtime.js\";\nimport { Serializable } from \"./load/serializable.js\";\n\n//#region src/stores.ts\nvar stores_exports = {};\n__export(stores_exports, {\n\tBaseStore: () => BaseStore,\n\tInMemoryStore: () => InMemoryStore\n});\n/**\n* Abstract interface for a key-value store.\n*/\nvar BaseStore = class extends Serializable {};\n/**\n* In-memory implementation of the BaseStore using a dictionary. Used for\n* storing key-value pairs in memory.\n* @example\n* ```typescript\n* const store = new InMemoryStore<BaseMessage>();\n* await store.mset(\n*   Array.from({ length: 5 }).map((_, index) => [\n*     `message:id:${index}`,\n*     index % 2 === 0\n*       ? new AIMessage(\"ai stuff...\")\n*       : new HumanMessage(\"human stuff...\"),\n*   ]),\n* );\n*\n* const retrievedMessages = await store.mget([\"message:id:0\", \"message:id:1\"]);\n* await store.mdelete(await store.yieldKeys(\"message:id:\").toArray());\n* ```\n*/\nvar InMemoryStore = class extends BaseStore {\n\tlc_namespace = [\"langchain\", \"storage\"];\n\tstore = {};\n\t/**\n\t* Retrieves the values associated with the given keys from the store.\n\t* @param keys Keys to retrieve values for.\n\t* @returns Array of values associated with the given keys.\n\t*/\n\tasync mget(keys) {\n\t\treturn keys.map((key) => this.store[key]);\n\t}\n\t/**\n\t* Sets the values for the given keys in the store.\n\t* @param keyValuePairs Array of key-value pairs to set in the store.\n\t* @returns Promise that resolves when all key-value pairs have been set.\n\t*/\n\tasync mset(keyValuePairs) {\n\t\tfor (const [key, value] of keyValuePairs) this.store[key] = value;\n\t}\n\t/**\n\t* Deletes the given keys and their associated values from the store.\n\t* @param keys Keys to delete from the store.\n\t* @returns Promise that resolves when all keys have been deleted.\n\t*/\n\tasync mdelete(keys) {\n\t\tfor (const key of keys) delete this.store[key];\n\t}\n\t/**\n\t* Asynchronous generator that yields keys from the store. If a prefix is\n\t* provided, it only yields keys that start with the prefix.\n\t* @param prefix Optional prefix to filter keys.\n\t* @returns AsyncGenerator that yields keys from the store.\n\t*/\n\tasync *yieldKeys(prefix) {\n\t\tconst keys = Object.keys(this.store);\n\t\tfor (const key of keys) if (prefix === void 0 || key.startsWith(prefix)) yield key;\n\t}\n};\n\n//#endregion\nexport { BaseStore, InMemoryStore, stores_exports };\n//# sourceMappingURL=stores.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { CallbackManager, parseCallbackConfigArg } from \"../callbacks/manager.js\";\nimport { ensureConfig } from \"../runnables/config.js\";\nimport { Runnable } from \"../runnables/base.js\";\n\n//#region src/retrievers/index.ts\nvar retrievers_exports = {};\n__export(retrievers_exports, { BaseRetriever: () => BaseRetriever });\n/**\n* Abstract base class for a document retrieval system, designed to\n* process string queries and return the most relevant documents from a source.\n*\n* `BaseRetriever` provides common properties and methods for derived retrievers,\n* such as callbacks, tagging, and verbose logging. Custom retrieval systems\n* should extend this class and implement `_getRelevantDocuments` to define\n* the specific retrieval logic.\n*\n* @template Metadata - The type of metadata associated with each document,\n*                      defaulting to `Record<string, any>`.\n*/\nvar BaseRetriever = class extends Runnable {\n\t/**\n\t* Optional callbacks to handle various events in the retrieval process.\n\t*/\n\tcallbacks;\n\t/**\n\t* Tags to label or categorize the retrieval operation.\n\t*/\n\ttags;\n\t/**\n\t* Metadata to provide additional context or information about the retrieval\n\t* operation.\n\t*/\n\tmetadata;\n\t/**\n\t* If set to `true`, enables verbose logging for the retrieval process.\n\t*/\n\tverbose;\n\t/**\n\t* Constructs a new `BaseRetriever` instance with optional configuration fields.\n\t*\n\t* @param fields - Optional input configuration that can include `callbacks`,\n\t*                 `tags`, `metadata`, and `verbose` settings for custom retriever behavior.\n\t*/\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.callbacks = fields?.callbacks;\n\t\tthis.tags = fields?.tags ?? [];\n\t\tthis.metadata = fields?.metadata ?? {};\n\t\tthis.verbose = fields?.verbose ?? false;\n\t}\n\t/**\n\t* TODO: This should be an abstract method, but we'd like to avoid breaking\n\t* changes to people currently using subclassed custom retrievers.\n\t* Change it on next major release.\n\t*/\n\t/**\n\t* Placeholder method for retrieving relevant documents based on a query.\n\t*\n\t* This method is intended to be implemented by subclasses and will be\n\t* converted to an abstract method in the next major release. Currently, it\n\t* throws an error if not implemented, ensuring that custom retrievers define\n\t* the specific retrieval logic.\n\t*\n\t* @param _query - The query string used to search for relevant documents.\n\t* @param _callbacks - (optional) Callback manager for managing callbacks\n\t*                     during retrieval.\n\t* @returns A promise resolving to an array of `DocumentInterface` instances relevant to the query.\n\t* @throws {Error} Throws an error indicating the method is not implemented.\n\t*/\n\t_getRelevantDocuments(_query, _callbacks) {\n\t\tthrow new Error(\"Not implemented!\");\n\t}\n\t/**\n\t* Executes a retrieval operation.\n\t*\n\t* @param input - The query string used to search for relevant documents.\n\t* @param options - (optional) Configuration options for the retrieval run,\n\t*                  which may include callbacks, tags, and metadata.\n\t* @returns A promise that resolves to an array of `DocumentInterface` instances\n\t*          representing the most relevant documents to the query.\n\t*/\n\tasync invoke(input, options) {\n\t\tconst parsedConfig = ensureConfig(parseCallbackConfigArg(options));\n\t\tconst callbackManager_ = await CallbackManager.configure(parsedConfig.callbacks, this.callbacks, parsedConfig.tags, this.tags, parsedConfig.metadata, this.metadata, { verbose: this.verbose });\n\t\tconst runManager = await callbackManager_?.handleRetrieverStart(this.toJSON(), input, parsedConfig.runId, void 0, void 0, void 0, parsedConfig.runName);\n\t\ttry {\n\t\t\tconst results = await this._getRelevantDocuments(input, runManager);\n\t\t\tawait runManager?.handleRetrieverEnd(results);\n\t\t\treturn results;\n\t\t} catch (error) {\n\t\t\tawait runManager?.handleRetrieverError(error);\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\n//#endregion\nexport { BaseRetriever, retrievers_exports };\n//# sourceMappingURL=index.js.map","import { __export } from \"./_virtual/rolldown_runtime.js\";\nimport { Serializable } from \"./load/serializable.js\";\nimport { BaseRetriever } from \"./retrievers/index.js\";\n\n//#region src/vectorstores.ts\nvar vectorstores_exports = {};\n__export(vectorstores_exports, {\n\tSaveableVectorStore: () => SaveableVectorStore,\n\tVectorStore: () => VectorStore,\n\tVectorStoreRetriever: () => VectorStoreRetriever\n});\n/**\n* Class for retrieving documents from a `VectorStore` based on vector similarity\n* or maximal marginal relevance (MMR).\n*\n* `VectorStoreRetriever` extends `BaseRetriever`, implementing methods for\n* adding documents to the underlying vector store and performing document\n* retrieval with optional configurations.\n*\n* @class VectorStoreRetriever\n* @extends BaseRetriever\n* @implements VectorStoreRetrieverInterface\n* @template V - Type of vector store implementing `VectorStoreInterface`.\n*/\nvar VectorStoreRetriever = class extends BaseRetriever {\n\tstatic lc_name() {\n\t\treturn \"VectorStoreRetriever\";\n\t}\n\tget lc_namespace() {\n\t\treturn [\"langchain_core\", \"vectorstores\"];\n\t}\n\t/**\n\t* The instance of `VectorStore` used for storing and retrieving document embeddings.\n\t* This vector store must implement the `VectorStoreInterface` to be compatible\n\t* with the retrievers operations.\n\t*/\n\tvectorStore;\n\t/**\n\t* Specifies the number of documents to retrieve for each search query.\n\t* Defaults to 4 if not specified, providing a basic result count for similarity or MMR searches.\n\t*/\n\tk = 4;\n\t/**\n\t* Determines the type of search operation to perform on the vector store.\n\t*\n\t* - `\"similarity\"` (default): Conducts a similarity search based purely on vector similarity\n\t*   to the query.\n\t* - `\"mmr\"`: Executes a maximal marginal relevance (MMR) search, balancing relevance and\n\t*   diversity in the retrieved results.\n\t*/\n\tsearchType = \"similarity\";\n\t/**\n\t* Additional options specific to maximal marginal relevance (MMR) search, applicable\n\t* only if `searchType` is set to `\"mmr\"`.\n\t*\n\t* Includes:\n\t* - `fetchK`: The initial number of documents fetched before applying the MMR algorithm,\n\t*   allowing for a larger selection from which to choose the most diverse results.\n\t* - `lambda`: A parameter between 0 and 1 to adjust the relevance-diversity balance,\n\t*   where 0 prioritizes diversity and 1 prioritizes relevance.\n\t*/\n\tsearchKwargs;\n\t/**\n\t* Optional filter applied to search results, defined by the `FilterType` of the vector store.\n\t* Allows for refined, targeted results by restricting the returned documents based\n\t* on specified filter criteria.\n\t*/\n\tfilter;\n\t/**\n\t* Returns the type of vector store, as defined by the `vectorStore` instance.\n\t*\n\t* @returns {string} The vector store type.\n\t*/\n\t_vectorstoreType() {\n\t\treturn this.vectorStore._vectorstoreType();\n\t}\n\t/**\n\t* Initializes a new instance of `VectorStoreRetriever` with the specified configuration.\n\t*\n\t* This constructor configures the retriever to interact with a given `VectorStore`\n\t* and supports different retrieval strategies, including similarity search and maximal\n\t* marginal relevance (MMR) search. Various options allow customization of the number\n\t* of documents retrieved per query, filtering based on conditions, and fine-tuning\n\t* MMR-specific parameters.\n\t*\n\t* @param fields - Configuration options for setting up the retriever:\n\t*\n\t*   - `vectorStore` (required): The `VectorStore` instance implementing `VectorStoreInterface`\n\t*     that will be used to store and retrieve document embeddings. This is the core component\n\t*     of the retriever, enabling vector-based similarity and MMR searches.\n\t*\n\t*   - `k` (optional): Specifies the number of documents to retrieve per search query. If not\n\t*     provided, defaults to 4. This count determines the number of most relevant documents returned\n\t*     for each search operation, balancing performance with comprehensiveness.\n\t*\n\t*   - `searchType` (optional): Defines the search approach used by the retriever, allowing for\n\t*     flexibility between two methods:\n\t*       - `\"similarity\"` (default): A similarity-based search, retrieving documents with high vector\n\t*         similarity to the query. This type prioritizes relevance and is often used when diversity\n\t*         among results is less critical.\n\t*       - `\"mmr\"`: Maximal Marginal Relevance search, which combines relevance with diversity. MMR\n\t*         is useful for scenarios where varied content is essential, as it selects results that\n\t*         both match the query and introduce content diversity.\n\t*\n\t*   - `filter` (optional): A filter of type `FilterType`, defined by the vector store, that allows\n\t*     for refined and targeted search results. This filter applies specified conditions to limit\n\t*     which documents are eligible for retrieval, offering control over the scope of results.\n\t*\n\t*   - `searchKwargs` (optional, applicable only if `searchType` is `\"mmr\"`): Additional settings\n\t*     for configuring MMR-specific behavior. These parameters allow further tuning of the MMR\n\t*     search process:\n\t*       - `fetchK`: The initial number of documents fetched from the vector store before the MMR\n\t*         algorithm is applied. Fetching a larger set enables the algorithm to select a more\n\t*         diverse subset of documents.\n\t*       - `lambda`: A parameter controlling the relevance-diversity balance, where 0 emphasizes\n\t*         diversity and 1 prioritizes relevance. Intermediate values provide a blend of the two,\n\t*         allowing customization based on the importance of content variety relative to query relevance.\n\t*/\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.vectorStore = fields.vectorStore;\n\t\tthis.k = fields.k ?? this.k;\n\t\tthis.searchType = fields.searchType ?? this.searchType;\n\t\tthis.filter = fields.filter;\n\t\tif (fields.searchType === \"mmr\") this.searchKwargs = fields.searchKwargs;\n\t}\n\t/**\n\t* Retrieves relevant documents based on the specified query, using either\n\t* similarity or maximal marginal relevance (MMR) search.\n\t*\n\t* If `searchType` is set to `\"mmr\"`, performs an MMR search to balance\n\t* similarity and diversity among results. If `searchType` is `\"similarity\"`,\n\t* retrieves results purely based on similarity to the query.\n\t*\n\t* @param query - The query string used to find relevant documents.\n\t* @param runManager - Optional callback manager for tracking retrieval progress.\n\t* @returns A promise that resolves to an array of `DocumentInterface` instances\n\t*          representing the most relevant documents to the query.\n\t* @throws {Error} Throws an error if MMR search is requested but not supported\n\t*                 by the vector store.\n\t* @protected\n\t*/\n\tasync _getRelevantDocuments(query, runManager) {\n\t\tif (this.searchType === \"mmr\") {\n\t\t\tif (typeof this.vectorStore.maxMarginalRelevanceSearch !== \"function\") throw new Error(`The vector store backing this retriever, ${this._vectorstoreType()} does not support max marginal relevance search.`);\n\t\t\treturn this.vectorStore.maxMarginalRelevanceSearch(query, {\n\t\t\t\tk: this.k,\n\t\t\t\tfilter: this.filter,\n\t\t\t\t...this.searchKwargs\n\t\t\t}, runManager?.getChild(\"vectorstore\"));\n\t\t}\n\t\treturn this.vectorStore.similaritySearch(query, this.k, this.filter, runManager?.getChild(\"vectorstore\"));\n\t}\n\t/**\n\t* Adds an array of documents to the vector store, embedding them as part of\n\t* the storage process.\n\t*\n\t* This method delegates document embedding and storage to the `addDocuments`\n\t* method of the underlying vector store.\n\t*\n\t* @param documents - An array of documents to embed and add to the vector store.\n\t* @param options - Optional settings to customize document addition.\n\t* @returns A promise that resolves to an array of document IDs or `void`,\n\t*          depending on the vector store's implementation.\n\t*/\n\tasync addDocuments(documents, options) {\n\t\treturn this.vectorStore.addDocuments(documents, options);\n\t}\n};\n/**\n* Abstract class representing a vector storage system for performing\n* similarity searches on embedded documents.\n*\n* `VectorStore` provides methods for adding precomputed vectors or documents,\n* removing documents based on criteria, and performing similarity searches\n* with optional scoring. Subclasses are responsible for implementing specific\n* storage mechanisms and the exact behavior of certain abstract methods.\n*\n* @abstract\n* @extends Serializable\n* @implements VectorStoreInterface\n*/\nvar VectorStore = class extends Serializable {\n\t/**\n\t* Namespace within LangChain to uniquely identify this vector store's\n\t* location, based on the vector store type.\n\t*\n\t* @internal\n\t*/\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"vectorstores\",\n\t\tthis._vectorstoreType()\n\t];\n\t/**\n\t* Embeddings interface for generating vector embeddings from text queries,\n\t* enabling vector-based similarity searches.\n\t*/\n\tembeddings;\n\t/**\n\t* Initializes a new vector store with embeddings and database configuration.\n\t*\n\t* @param embeddings - Instance of `EmbeddingsInterface` used to embed queries.\n\t* @param dbConfig - Configuration settings for the database or storage system.\n\t*/\n\tconstructor(embeddings, dbConfig) {\n\t\tsuper(dbConfig);\n\t\tthis.embeddings = embeddings;\n\t}\n\t/**\n\t* Deletes documents from the vector store based on the specified parameters.\n\t*\n\t* @param _params - Flexible key-value pairs defining conditions for document deletion.\n\t* @returns A promise that resolves once the deletion is complete.\n\t*/\n\tasync delete(_params) {\n\t\tthrow new Error(\"Not implemented.\");\n\t}\n\t/**\n\t* Searches for documents similar to a text query by embedding the query and\n\t* performing a similarity search on the resulting vector.\n\t*\n\t* @param query - Text query for finding similar documents.\n\t* @param k - Number of similar results to return. Defaults to 4.\n\t* @param filter - Optional filter based on `FilterType`.\n\t* @param _callbacks - Optional callbacks for monitoring search progress\n\t* @returns A promise resolving to an array of `DocumentInterface` instances representing similar documents.\n\t*/\n\tasync similaritySearch(query, k = 4, filter = void 0, _callbacks = void 0) {\n\t\tconst results = await this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k, filter);\n\t\treturn results.map((result) => result[0]);\n\t}\n\t/**\n\t* Searches for documents similar to a text query by embedding the query,\n\t* and returns results with similarity scores.\n\t*\n\t* @param query - Text query for finding similar documents.\n\t* @param k - Number of similar results to return. Defaults to 4.\n\t* @param filter - Optional filter based on `FilterType`.\n\t* @param _callbacks - Optional callbacks for monitoring search progress\n\t* @returns A promise resolving to an array of tuples, each containing a\n\t*          document and its similarity score.\n\t*/\n\tasync similaritySearchWithScore(query, k = 4, filter = void 0, _callbacks = void 0) {\n\t\treturn this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k, filter);\n\t}\n\t/**\n\t* Creates a `VectorStore` instance from an array of text strings and optional\n\t* metadata, using the specified embeddings and database configuration.\n\t*\n\t* Subclasses must implement this method to define how text and metadata\n\t* are embedded and stored in the vector store. Throws an error if not overridden.\n\t*\n\t* @param _texts - Array of strings representing the text documents to be stored.\n\t* @param _metadatas - Metadata for the texts, either as an array (one for each text)\n\t*                     or a single object (applied to all texts).\n\t* @param _embeddings - Instance of `EmbeddingsInterface` to embed the texts.\n\t* @param _dbConfig - Database configuration settings.\n\t* @returns A promise that resolves to a new `VectorStore` instance.\n\t* @throws {Error} Throws an error if this method is not overridden by a subclass.\n\t*/\n\tstatic fromTexts(_texts, _metadatas, _embeddings, _dbConfig) {\n\t\tthrow new Error(\"the Langchain vectorstore implementation you are using forgot to override this, please report a bug\");\n\t}\n\t/**\n\t* Creates a `VectorStore` instance from an array of documents, using the specified\n\t* embeddings and database configuration.\n\t*\n\t* Subclasses must implement this method to define how documents are embedded\n\t* and stored. Throws an error if not overridden.\n\t*\n\t* @param _docs - Array of `DocumentInterface` instances representing the documents to be stored.\n\t* @param _embeddings - Instance of `EmbeddingsInterface` to embed the documents.\n\t* @param _dbConfig - Database configuration settings.\n\t* @returns A promise that resolves to a new `VectorStore` instance.\n\t* @throws {Error} Throws an error if this method is not overridden by a subclass.\n\t*/\n\tstatic fromDocuments(_docs, _embeddings, _dbConfig) {\n\t\tthrow new Error(\"the Langchain vectorstore implementation you are using forgot to override this, please report a bug\");\n\t}\n\t/**\n\t* Creates a `VectorStoreRetriever` instance with flexible configuration options.\n\t*\n\t* @param kOrFields\n\t*    - If a number is provided, it sets the `k` parameter (number of items to retrieve).\n\t*    - If an object is provided, it should contain various configuration options.\n\t* @param filter\n\t*    - Optional filter criteria to limit the items retrieved based on the specified filter type.\n\t* @param callbacks\n\t*    - Optional callbacks that may be triggered at specific stages of the retrieval process.\n\t* @param tags\n\t*    - Tags to categorize or label the `VectorStoreRetriever`. Defaults to an empty array if not provided.\n\t* @param metadata\n\t*    - Additional metadata as key-value pairs to add contextual information for the retrieval process.\n\t* @param verbose\n\t*    - If `true`, enables detailed logging for the retrieval process. Defaults to `false`.\n\t*\n\t* @returns\n\t*    - A configured `VectorStoreRetriever` instance based on the provided parameters.\n\t*\n\t* @example\n\t* Basic usage with a `k` value:\n\t* ```typescript\n\t* const retriever = myVectorStore.asRetriever(5);\n\t* ```\n\t*\n\t* Usage with a configuration object:\n\t* ```typescript\n\t* const retriever = myVectorStore.asRetriever({\n\t*   k: 10,\n\t*   filter: myFilter,\n\t*   tags: ['example', 'test'],\n\t*   verbose: true,\n\t*   searchType: 'mmr',\n\t*   searchKwargs: { alpha: 0.5 },\n\t* });\n\t* ```\n\t*/\n\tasRetriever(kOrFields, filter, callbacks, tags, metadata, verbose) {\n\t\tif (typeof kOrFields === \"number\") return new VectorStoreRetriever({\n\t\t\tvectorStore: this,\n\t\t\tk: kOrFields,\n\t\t\tfilter,\n\t\t\ttags: [...tags ?? [], this._vectorstoreType()],\n\t\t\tmetadata,\n\t\t\tverbose,\n\t\t\tcallbacks\n\t\t});\n\t\telse {\n\t\t\tconst params = {\n\t\t\t\tvectorStore: this,\n\t\t\t\tk: kOrFields?.k,\n\t\t\t\tfilter: kOrFields?.filter,\n\t\t\t\ttags: [...kOrFields?.tags ?? [], this._vectorstoreType()],\n\t\t\t\tmetadata: kOrFields?.metadata,\n\t\t\t\tverbose: kOrFields?.verbose,\n\t\t\t\tcallbacks: kOrFields?.callbacks,\n\t\t\t\tsearchType: kOrFields?.searchType\n\t\t\t};\n\t\t\tif (kOrFields?.searchType === \"mmr\") return new VectorStoreRetriever({\n\t\t\t\t...params,\n\t\t\t\tsearchKwargs: kOrFields.searchKwargs\n\t\t\t});\n\t\t\treturn new VectorStoreRetriever({ ...params });\n\t\t}\n\t}\n};\n/**\n* Abstract class extending `VectorStore` that defines a contract for saving\n* and loading vector store instances.\n*\n* The `SaveableVectorStore` class allows vector store implementations to\n* persist their data and retrieve it when needed.The format for saving and\n* loading data is left to the implementing subclass.\n*\n* Subclasses must implement the `save` method to handle their custom\n* serialization logic, while the `load` method enables reconstruction of a\n* vector store from saved data, requiring compatible embeddings through the\n* `EmbeddingsInterface`.\n*\n* @abstract\n* @extends VectorStore\n*/\nvar SaveableVectorStore = class extends VectorStore {\n\t/**\n\t* Loads a vector store instance from the specified directory, using the\n\t* provided embeddings to ensure compatibility.\n\t*\n\t* This static method reconstructs a `SaveableVectorStore` from previously\n\t* saved data. Implementations should interpret the saved data format to\n\t* recreate the vector store instance.\n\t*\n\t* @param _directory - The directory path from which the vector store\n\t* data will be loaded.\n\t* @param _embeddings - An instance of `EmbeddingsInterface` to align\n\t* the embeddings with the loaded vector data.\n\t* @returns A promise that resolves to a `SaveableVectorStore` instance\n\t* constructed from the saved data.\n\t*/\n\tstatic load(_directory, _embeddings) {\n\t\tthrow new Error(\"Not implemented\");\n\t}\n};\n\n//#endregion\nexport { SaveableVectorStore, VectorStore, VectorStoreRetriever, vectorstores_exports };\n//# sourceMappingURL=vectorstores.js.map","\n\n//#region src/utils/js-sha256/hash.ts\nvar HEX_CHARS = \"0123456789abcdef\".split(\"\");\nvar EXTRA = [\n\t-2147483648,\n\t8388608,\n\t32768,\n\t128\n];\nvar SHIFT = [\n\t24,\n\t16,\n\t8,\n\t0\n];\nvar K = [\n\t1116352408,\n\t1899447441,\n\t3049323471,\n\t3921009573,\n\t961987163,\n\t1508970993,\n\t2453635748,\n\t2870763221,\n\t3624381080,\n\t310598401,\n\t607225278,\n\t1426881987,\n\t1925078388,\n\t2162078206,\n\t2614888103,\n\t3248222580,\n\t3835390401,\n\t4022224774,\n\t264347078,\n\t604807628,\n\t770255983,\n\t1249150122,\n\t1555081692,\n\t1996064986,\n\t2554220882,\n\t2821834349,\n\t2952996808,\n\t3210313671,\n\t3336571891,\n\t3584528711,\n\t113926993,\n\t338241895,\n\t666307205,\n\t773529912,\n\t1294757372,\n\t1396182291,\n\t1695183700,\n\t1986661051,\n\t2177026350,\n\t2456956037,\n\t2730485921,\n\t2820302411,\n\t3259730800,\n\t3345764771,\n\t3516065817,\n\t3600352804,\n\t4094571909,\n\t275423344,\n\t430227734,\n\t506948616,\n\t659060556,\n\t883997877,\n\t958139571,\n\t1322822218,\n\t1537002063,\n\t1747873779,\n\t1955562222,\n\t2024104815,\n\t2227730452,\n\t2361852424,\n\t2428436474,\n\t2756734187,\n\t3204031479,\n\t3329325298\n];\nvar blocks = [];\nfunction Sha256(is224, sharedMemory) {\n\tif (sharedMemory) {\n\t\tblocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;\n\t\tthis.blocks = blocks;\n\t} else this.blocks = [\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0,\n\t\t0\n\t];\n\tif (is224) {\n\t\tthis.h0 = 3238371032;\n\t\tthis.h1 = 914150663;\n\t\tthis.h2 = 812702999;\n\t\tthis.h3 = 4144912697;\n\t\tthis.h4 = 4290775857;\n\t\tthis.h5 = 1750603025;\n\t\tthis.h6 = 1694076839;\n\t\tthis.h7 = 3204075428;\n\t} else {\n\t\tthis.h0 = 1779033703;\n\t\tthis.h1 = 3144134277;\n\t\tthis.h2 = 1013904242;\n\t\tthis.h3 = 2773480762;\n\t\tthis.h4 = 1359893119;\n\t\tthis.h5 = 2600822924;\n\t\tthis.h6 = 528734635;\n\t\tthis.h7 = 1541459225;\n\t}\n\tthis.block = this.start = this.bytes = this.hBytes = 0;\n\tthis.finalized = this.hashed = false;\n\tthis.first = true;\n\tthis.is224 = is224;\n}\nSha256.prototype.update = function(message) {\n\tif (this.finalized) return;\n\tvar notString, type = typeof message;\n\tif (type !== \"string\") {\n\t\tif (type === \"object\") {\n\t\t\tif (message === null) throw new Error(ERROR);\n\t\t\telse if (ARRAY_BUFFER && message.constructor === ArrayBuffer) message = new Uint8Array(message);\n\t\t\telse if (!Array.isArray(message)) {\n\t\t\t\tif (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) throw new Error(ERROR);\n\t\t\t}\n\t\t} else throw new Error(ERROR);\n\t\tnotString = true;\n\t}\n\tvar code, index = 0, i, length = message.length, blocks$1 = this.blocks;\n\twhile (index < length) {\n\t\tif (this.hashed) {\n\t\t\tthis.hashed = false;\n\t\t\tblocks$1[0] = this.block;\n\t\t\tthis.block = blocks$1[16] = blocks$1[1] = blocks$1[2] = blocks$1[3] = blocks$1[4] = blocks$1[5] = blocks$1[6] = blocks$1[7] = blocks$1[8] = blocks$1[9] = blocks$1[10] = blocks$1[11] = blocks$1[12] = blocks$1[13] = blocks$1[14] = blocks$1[15] = 0;\n\t\t}\n\t\tif (notString) for (i = this.start; index < length && i < 64; ++index) blocks$1[i >>> 2] |= message[index] << SHIFT[i++ & 3];\n\t\telse for (i = this.start; index < length && i < 64; ++index) {\n\t\t\tcode = message.charCodeAt(index);\n\t\t\tif (code < 128) blocks$1[i >>> 2] |= code << SHIFT[i++ & 3];\n\t\t\telse if (code < 2048) {\n\t\t\t\tblocks$1[i >>> 2] |= (192 | code >>> 6) << SHIFT[i++ & 3];\n\t\t\t\tblocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];\n\t\t\t} else if (code < 55296 || code >= 57344) {\n\t\t\t\tblocks$1[i >>> 2] |= (224 | code >>> 12) << SHIFT[i++ & 3];\n\t\t\t\tblocks$1[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];\n\t\t\t\tblocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];\n\t\t\t} else {\n\t\t\t\tcode = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index) & 1023);\n\t\t\t\tblocks$1[i >>> 2] |= (240 | code >>> 18) << SHIFT[i++ & 3];\n\t\t\t\tblocks$1[i >>> 2] |= (128 | code >>> 12 & 63) << SHIFT[i++ & 3];\n\t\t\t\tblocks$1[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];\n\t\t\t\tblocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];\n\t\t\t}\n\t\t}\n\t\tthis.lastByteIndex = i;\n\t\tthis.bytes += i - this.start;\n\t\tif (i >= 64) {\n\t\t\tthis.block = blocks$1[16];\n\t\t\tthis.start = i - 64;\n\t\t\tthis.hash();\n\t\t\tthis.hashed = true;\n\t\t} else this.start = i;\n\t}\n\tif (this.bytes > 4294967295) {\n\t\tthis.hBytes += this.bytes / 4294967296 << 0;\n\t\tthis.bytes = this.bytes % 4294967296;\n\t}\n\treturn this;\n};\nSha256.prototype.finalize = function() {\n\tif (this.finalized) return;\n\tthis.finalized = true;\n\tvar blocks$1 = this.blocks, i = this.lastByteIndex;\n\tblocks$1[16] = this.block;\n\tblocks$1[i >>> 2] |= EXTRA[i & 3];\n\tthis.block = blocks$1[16];\n\tif (i >= 56) {\n\t\tif (!this.hashed) this.hash();\n\t\tblocks$1[0] = this.block;\n\t\tblocks$1[16] = blocks$1[1] = blocks$1[2] = blocks$1[3] = blocks$1[4] = blocks$1[5] = blocks$1[6] = blocks$1[7] = blocks$1[8] = blocks$1[9] = blocks$1[10] = blocks$1[11] = blocks$1[12] = blocks$1[13] = blocks$1[14] = blocks$1[15] = 0;\n\t}\n\tblocks$1[14] = this.hBytes << 3 | this.bytes >>> 29;\n\tblocks$1[15] = this.bytes << 3;\n\tthis.hash();\n};\nSha256.prototype.hash = function() {\n\tvar a = this.h0, b = this.h1, c = this.h2, d = this.h3, e = this.h4, f = this.h5, g = this.h6, h = this.h7, blocks$1 = this.blocks, j, s0, s1, maj, t1, t2, ch, ab, da, cd, bc;\n\tfor (j = 16; j < 64; ++j) {\n\t\tt1 = blocks$1[j - 15];\n\t\ts0 = (t1 >>> 7 | t1 << 25) ^ (t1 >>> 18 | t1 << 14) ^ t1 >>> 3;\n\t\tt1 = blocks$1[j - 2];\n\t\ts1 = (t1 >>> 17 | t1 << 15) ^ (t1 >>> 19 | t1 << 13) ^ t1 >>> 10;\n\t\tblocks$1[j] = blocks$1[j - 16] + s0 + blocks$1[j - 7] + s1 << 0;\n\t}\n\tbc = b & c;\n\tfor (j = 0; j < 64; j += 4) {\n\t\tif (this.first) {\n\t\t\tif (this.is224) {\n\t\t\t\tab = 300032;\n\t\t\t\tt1 = blocks$1[0] - 1413257819;\n\t\t\t\th = t1 - 150054599 << 0;\n\t\t\t\td = t1 + 24177077 << 0;\n\t\t\t} else {\n\t\t\t\tab = 704751109;\n\t\t\t\tt1 = blocks$1[0] - 210244248;\n\t\t\t\th = t1 - 1521486534 << 0;\n\t\t\t\td = t1 + 143694565 << 0;\n\t\t\t}\n\t\t\tthis.first = false;\n\t\t} else {\n\t\t\ts0 = (a >>> 2 | a << 30) ^ (a >>> 13 | a << 19) ^ (a >>> 22 | a << 10);\n\t\t\ts1 = (e >>> 6 | e << 26) ^ (e >>> 11 | e << 21) ^ (e >>> 25 | e << 7);\n\t\t\tab = a & b;\n\t\t\tmaj = ab ^ a & c ^ bc;\n\t\t\tch = e & f ^ ~e & g;\n\t\t\tt1 = h + s1 + ch + K[j] + blocks$1[j];\n\t\t\tt2 = s0 + maj;\n\t\t\th = d + t1 << 0;\n\t\t\td = t1 + t2 << 0;\n\t\t}\n\t\ts0 = (d >>> 2 | d << 30) ^ (d >>> 13 | d << 19) ^ (d >>> 22 | d << 10);\n\t\ts1 = (h >>> 6 | h << 26) ^ (h >>> 11 | h << 21) ^ (h >>> 25 | h << 7);\n\t\tda = d & a;\n\t\tmaj = da ^ d & b ^ ab;\n\t\tch = g & h ^ ~g & e;\n\t\tt1 = f + s1 + ch + K[j + 1] + blocks$1[j + 1];\n\t\tt2 = s0 + maj;\n\t\tg = c + t1 << 0;\n\t\tc = t1 + t2 << 0;\n\t\ts0 = (c >>> 2 | c << 30) ^ (c >>> 13 | c << 19) ^ (c >>> 22 | c << 10);\n\t\ts1 = (g >>> 6 | g << 26) ^ (g >>> 11 | g << 21) ^ (g >>> 25 | g << 7);\n\t\tcd = c & d;\n\t\tmaj = cd ^ c & a ^ da;\n\t\tch = f & g ^ ~f & h;\n\t\tt1 = e + s1 + ch + K[j + 2] + blocks$1[j + 2];\n\t\tt2 = s0 + maj;\n\t\tf = b + t1 << 0;\n\t\tb = t1 + t2 << 0;\n\t\ts0 = (b >>> 2 | b << 30) ^ (b >>> 13 | b << 19) ^ (b >>> 22 | b << 10);\n\t\ts1 = (f >>> 6 | f << 26) ^ (f >>> 11 | f << 21) ^ (f >>> 25 | f << 7);\n\t\tbc = b & c;\n\t\tmaj = bc ^ b & d ^ cd;\n\t\tch = f & g ^ ~f & h;\n\t\tt1 = e + s1 + ch + K[j + 3] + blocks$1[j + 3];\n\t\tt2 = s0 + maj;\n\t\te = a + t1 << 0;\n\t\ta = t1 + t2 << 0;\n\t\tthis.chromeBugWorkAround = true;\n\t}\n\tthis.h0 = this.h0 + a << 0;\n\tthis.h1 = this.h1 + b << 0;\n\tthis.h2 = this.h2 + c << 0;\n\tthis.h3 = this.h3 + d << 0;\n\tthis.h4 = this.h4 + e << 0;\n\tthis.h5 = this.h5 + f << 0;\n\tthis.h6 = this.h6 + g << 0;\n\tthis.h7 = this.h7 + h << 0;\n};\nSha256.prototype.hex = function() {\n\tthis.finalize();\n\tvar h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;\n\tvar hex = HEX_CHARS[h0 >>> 28 & 15] + HEX_CHARS[h0 >>> 24 & 15] + HEX_CHARS[h0 >>> 20 & 15] + HEX_CHARS[h0 >>> 16 & 15] + HEX_CHARS[h0 >>> 12 & 15] + HEX_CHARS[h0 >>> 8 & 15] + HEX_CHARS[h0 >>> 4 & 15] + HEX_CHARS[h0 & 15] + HEX_CHARS[h1 >>> 28 & 15] + HEX_CHARS[h1 >>> 24 & 15] + HEX_CHARS[h1 >>> 20 & 15] + HEX_CHARS[h1 >>> 16 & 15] + HEX_CHARS[h1 >>> 12 & 15] + HEX_CHARS[h1 >>> 8 & 15] + HEX_CHARS[h1 >>> 4 & 15] + HEX_CHARS[h1 & 15] + HEX_CHARS[h2 >>> 28 & 15] + HEX_CHARS[h2 >>> 24 & 15] + HEX_CHARS[h2 >>> 20 & 15] + HEX_CHARS[h2 >>> 16 & 15] + HEX_CHARS[h2 >>> 12 & 15] + HEX_CHARS[h2 >>> 8 & 15] + HEX_CHARS[h2 >>> 4 & 15] + HEX_CHARS[h2 & 15] + HEX_CHARS[h3 >>> 28 & 15] + HEX_CHARS[h3 >>> 24 & 15] + HEX_CHARS[h3 >>> 20 & 15] + HEX_CHARS[h3 >>> 16 & 15] + HEX_CHARS[h3 >>> 12 & 15] + HEX_CHARS[h3 >>> 8 & 15] + HEX_CHARS[h3 >>> 4 & 15] + HEX_CHARS[h3 & 15] + HEX_CHARS[h4 >>> 28 & 15] + HEX_CHARS[h4 >>> 24 & 15] + HEX_CHARS[h4 >>> 20 & 15] + HEX_CHARS[h4 >>> 16 & 15] + HEX_CHARS[h4 >>> 12 & 15] + HEX_CHARS[h4 >>> 8 & 15] + HEX_CHARS[h4 >>> 4 & 15] + HEX_CHARS[h4 & 15] + HEX_CHARS[h5 >>> 28 & 15] + HEX_CHARS[h5 >>> 24 & 15] + HEX_CHARS[h5 >>> 20 & 15] + HEX_CHARS[h5 >>> 16 & 15] + HEX_CHARS[h5 >>> 12 & 15] + HEX_CHARS[h5 >>> 8 & 15] + HEX_CHARS[h5 >>> 4 & 15] + HEX_CHARS[h5 & 15] + HEX_CHARS[h6 >>> 28 & 15] + HEX_CHARS[h6 >>> 24 & 15] + HEX_CHARS[h6 >>> 20 & 15] + HEX_CHARS[h6 >>> 16 & 15] + HEX_CHARS[h6 >>> 12 & 15] + HEX_CHARS[h6 >>> 8 & 15] + HEX_CHARS[h6 >>> 4 & 15] + HEX_CHARS[h6 & 15];\n\tif (!this.is224) hex += HEX_CHARS[h7 >>> 28 & 15] + HEX_CHARS[h7 >>> 24 & 15] + HEX_CHARS[h7 >>> 20 & 15] + HEX_CHARS[h7 >>> 16 & 15] + HEX_CHARS[h7 >>> 12 & 15] + HEX_CHARS[h7 >>> 8 & 15] + HEX_CHARS[h7 >>> 4 & 15] + HEX_CHARS[h7 & 15];\n\treturn hex;\n};\nSha256.prototype.toString = Sha256.prototype.hex;\nSha256.prototype.digest = function() {\n\tthis.finalize();\n\tvar h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;\n\tvar arr = [\n\t\th0 >>> 24 & 255,\n\t\th0 >>> 16 & 255,\n\t\th0 >>> 8 & 255,\n\t\th0 & 255,\n\t\th1 >>> 24 & 255,\n\t\th1 >>> 16 & 255,\n\t\th1 >>> 8 & 255,\n\t\th1 & 255,\n\t\th2 >>> 24 & 255,\n\t\th2 >>> 16 & 255,\n\t\th2 >>> 8 & 255,\n\t\th2 & 255,\n\t\th3 >>> 24 & 255,\n\t\th3 >>> 16 & 255,\n\t\th3 >>> 8 & 255,\n\t\th3 & 255,\n\t\th4 >>> 24 & 255,\n\t\th4 >>> 16 & 255,\n\t\th4 >>> 8 & 255,\n\t\th4 & 255,\n\t\th5 >>> 24 & 255,\n\t\th5 >>> 16 & 255,\n\t\th5 >>> 8 & 255,\n\t\th5 & 255,\n\t\th6 >>> 24 & 255,\n\t\th6 >>> 16 & 255,\n\t\th6 >>> 8 & 255,\n\t\th6 & 255\n\t];\n\tif (!this.is224) arr.push(h7 >>> 24 & 255, h7 >>> 16 & 255, h7 >>> 8 & 255, h7 & 255);\n\treturn arr;\n};\nSha256.prototype.array = Sha256.prototype.digest;\nSha256.prototype.arrayBuffer = function() {\n\tthis.finalize();\n\tvar buffer = /* @__PURE__ */ new ArrayBuffer(this.is224 ? 28 : 32);\n\tvar dataView = new DataView(buffer);\n\tdataView.setUint32(0, this.h0);\n\tdataView.setUint32(4, this.h1);\n\tdataView.setUint32(8, this.h2);\n\tdataView.setUint32(12, this.h3);\n\tdataView.setUint32(16, this.h4);\n\tdataView.setUint32(20, this.h5);\n\tdataView.setUint32(24, this.h6);\n\tif (!this.is224) dataView.setUint32(28, this.h7);\n\treturn buffer;\n};\nconst sha256 = (...strings) => {\n\treturn new Sha256(false, true).update(strings.join(\"\")).hex();\n};\n\n//#endregion\nexport { sha256 };\n//# sourceMappingURL=hash.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { sha256 } from \"./js-sha256/hash.js\";\n\n//#region src/utils/hash.ts\nvar hash_exports = {};\n__export(hash_exports, { sha256: () => sha256 });\n\n//#endregion\nexport { hash_exports, sha256 };\n//# sourceMappingURL=hash.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { mapStoredMessageToChatMessage } from \"../messages/utils.js\";\nimport { sha256 } from \"../utils/js-sha256/hash.js\";\nimport \"../utils/hash.js\";\n\n//#region src/caches/base.ts\nvar base_exports = {};\n__export(base_exports, {\n\tBaseCache: () => BaseCache,\n\tInMemoryCache: () => InMemoryCache,\n\tdefaultHashKeyEncoder: () => defaultHashKeyEncoder,\n\tdeserializeStoredGeneration: () => deserializeStoredGeneration,\n\tserializeGeneration: () => serializeGeneration\n});\nconst defaultHashKeyEncoder = (...strings) => sha256(strings.join(\"_\"));\nfunction deserializeStoredGeneration(storedGeneration) {\n\tif (storedGeneration.message !== void 0) return {\n\t\ttext: storedGeneration.text,\n\t\tmessage: mapStoredMessageToChatMessage(storedGeneration.message)\n\t};\n\telse return { text: storedGeneration.text };\n}\nfunction serializeGeneration(generation) {\n\tconst serializedValue = { text: generation.text };\n\tif (generation.message !== void 0) serializedValue.message = generation.message.toDict();\n\treturn serializedValue;\n}\n/**\n* Base class for all caches. All caches should extend this class.\n*/\nvar BaseCache = class {\n\tkeyEncoder = defaultHashKeyEncoder;\n\t/**\n\t* Sets a custom key encoder function for the cache.\n\t* This function should take a prompt and an LLM key and return a string\n\t* that will be used as the cache key.\n\t* @param keyEncoderFn The custom key encoder function.\n\t*/\n\tmakeDefaultKeyEncoder(keyEncoderFn) {\n\t\tthis.keyEncoder = keyEncoderFn;\n\t}\n};\nconst GLOBAL_MAP = /* @__PURE__ */ new Map();\n/**\n* A cache for storing LLM generations that stores data in memory.\n*/\nvar InMemoryCache = class InMemoryCache extends BaseCache {\n\tcache;\n\tconstructor(map) {\n\t\tsuper();\n\t\tthis.cache = map ?? /* @__PURE__ */ new Map();\n\t}\n\t/**\n\t* Retrieves data from the cache using a prompt and an LLM key. If the\n\t* data is not found, it returns null.\n\t* @param prompt The prompt used to find the data.\n\t* @param llmKey The LLM key used to find the data.\n\t* @returns The data corresponding to the prompt and LLM key, or null if not found.\n\t*/\n\tlookup(prompt, llmKey) {\n\t\treturn Promise.resolve(this.cache.get(this.keyEncoder(prompt, llmKey)) ?? null);\n\t}\n\t/**\n\t* Updates the cache with new data using a prompt and an LLM key.\n\t* @param prompt The prompt used to store the data.\n\t* @param llmKey The LLM key used to store the data.\n\t* @param value The data to be stored.\n\t*/\n\tasync update(prompt, llmKey, value) {\n\t\tthis.cache.set(this.keyEncoder(prompt, llmKey), value);\n\t}\n\t/**\n\t* Returns a global instance of InMemoryCache using a predefined global\n\t* map as the initial cache.\n\t* @returns A global instance of InMemoryCache.\n\t*/\n\tstatic global() {\n\t\treturn new InMemoryCache(GLOBAL_MAP);\n\t}\n};\n\n//#endregion\nexport { BaseCache, InMemoryCache, base_exports, defaultHashKeyEncoder, deserializeStoredGeneration, serializeGeneration };\n//# sourceMappingURL=base.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\n\n//#region src/document_loaders/base.ts\nvar base_exports = {};\n__export(base_exports, { BaseDocumentLoader: () => BaseDocumentLoader });\n/**\n* Abstract class that provides a default implementation for the\n* loadAndSplit() method from the DocumentLoader interface. The load()\n* method is left abstract and needs to be implemented by subclasses.\n*/\nvar BaseDocumentLoader = class {};\n\n//#endregion\nexport { BaseDocumentLoader, base_exports };\n//# sourceMappingURL=base.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { BaseDocumentLoader } from \"./base.js\";\nimport { Client } from \"langsmith\";\n\n//#region src/document_loaders/langsmith.ts\nvar langsmith_exports = {};\n__export(langsmith_exports, { LangSmithLoader: () => LangSmithLoader });\n/**\n* Document loader integration with LangSmith.\n*\n* ## [Constructor args](https://api.js.langchain.com/interfaces/_langchain_core.document_loaders_langsmith.LangSmithLoaderFields.html)\n*\n* <details open>\n* <summary><strong>Load</strong></summary>\n*\n* ```typescript\n* import { LangSmithLoader } from '@langchain/core/document_loaders/langsmith';\n* import { Client } from 'langsmith';\n*\n* const langSmithClient = new Client({\n*   apiKey: process.env.LANGSMITH_API_KEY,\n* })\n*\n* const loader = new LangSmithLoader({\n*   datasetId: \"9a3b36f7-b308-40a5-9b46-6613853b6330\",\n*   limit: 1,\n* });\n*\n* const docs = await loader.load();\n* ```\n*\n* ```txt\n* [\n*   {\n*     pageContent: '{\\n  \"input_key_str\": \"string\",\\n  \"input_key_bool\": true\\n}',\n*     metadata: {\n*       id: '8523d9e9-c123-4b23-9b46-21021nds289e',\n*       created_at: '2024-08-19T17:09:14.806441+00:00',\n*       modified_at: '2024-08-19T17:09:14.806441+00:00',\n*       name: '#8517 @ brace-test-dataset',\n*       dataset_id: '9a3b36f7-b308-40a5-9b46-6613853b6330',\n*       source_run_id: null,\n*       metadata: [Object],\n*       inputs: [Object],\n*       outputs: [Object]\n*     }\n*   }\n* ]\n* ```\n* </details>\n*/\nvar LangSmithLoader = class extends BaseDocumentLoader {\n\tdatasetId;\n\tdatasetName;\n\texampleIds;\n\tasOf;\n\tsplits;\n\tinlineS3Urls;\n\toffset;\n\tlimit;\n\tmetadata;\n\tfilter;\n\tcontentKey;\n\tformatContent;\n\tclient;\n\tconstructor(fields) {\n\t\tsuper();\n\t\tif (fields.client && fields.clientConfig) throw new Error(\"client and clientConfig cannot both be provided.\");\n\t\tthis.client = fields.client ?? new Client(fields?.clientConfig);\n\t\tthis.contentKey = fields.contentKey ? fields.contentKey.split(\".\") : [];\n\t\tthis.formatContent = fields.formatContent ?? _stringify;\n\t\tthis.datasetId = fields.datasetId;\n\t\tthis.datasetName = fields.datasetName;\n\t\tthis.exampleIds = fields.exampleIds;\n\t\tthis.asOf = fields.asOf;\n\t\tthis.splits = fields.splits;\n\t\tthis.inlineS3Urls = fields.inlineS3Urls;\n\t\tthis.offset = fields.offset;\n\t\tthis.limit = fields.limit;\n\t\tthis.metadata = fields.metadata;\n\t\tthis.filter = fields.filter;\n\t}\n\tasync load() {\n\t\tconst documents = [];\n\t\tfor await (const example of this.client.listExamples({\n\t\t\tdatasetId: this.datasetId,\n\t\t\tdatasetName: this.datasetName,\n\t\t\texampleIds: this.exampleIds,\n\t\t\tasOf: this.asOf,\n\t\t\tsplits: this.splits,\n\t\t\tinlineS3Urls: this.inlineS3Urls,\n\t\t\toffset: this.offset,\n\t\t\tlimit: this.limit,\n\t\t\tmetadata: this.metadata,\n\t\t\tfilter: this.filter\n\t\t})) {\n\t\t\tlet content = example.inputs;\n\t\t\tfor (const key of this.contentKey) content = content[key];\n\t\t\tconst contentStr = this.formatContent(content);\n\t\t\tconst metadata = example;\n\t\t\t[\"created_at\", \"modified_at\"].forEach((k) => {\n\t\t\t\tif (k in metadata) {\n\t\t\t\t\tif (typeof metadata[k] === \"object\") metadata[k] = metadata[k].toString();\n\t\t\t\t}\n\t\t\t});\n\t\t\tdocuments.push({\n\t\t\t\tpageContent: contentStr,\n\t\t\t\tmetadata\n\t\t\t});\n\t\t}\n\t\treturn documents;\n\t}\n};\nfunction _stringify(x) {\n\tif (typeof x === \"string\") return x;\n\telse try {\n\t\treturn JSON.stringify(x, null, 2);\n\t} catch {\n\t\treturn String(x);\n\t}\n}\n\n//#endregion\nexport { LangSmithLoader, langsmith_exports };\n//# sourceMappingURL=langsmith.js.map","//#region src/documents/document.ts\n/**\n* Interface for interacting with a document.\n*/\nvar Document = class {\n\tpageContent;\n\tmetadata;\n\t/**\n\t* An optional identifier for the document.\n\t*\n\t* Ideally this should be unique across the document collection and formatted\n\t* as a UUID, but this will not be enforced.\n\t*/\n\tid;\n\tconstructor(fields) {\n\t\tthis.pageContent = fields.pageContent !== void 0 ? fields.pageContent.toString() : \"\";\n\t\tthis.metadata = fields.metadata ?? {};\n\t\tthis.id = fields.id;\n\t}\n};\n\n//#endregion\nexport { Document };\n//# sourceMappingURL=document.js.map","import { Runnable } from \"../runnables/base.js\";\n\n//#region src/documents/transformers.ts\n/**\n* Abstract base class for document transformation systems.\n*\n* A document transformation system takes an array of Documents and returns an\n* array of transformed Documents. These arrays do not necessarily have to have\n* the same length.\n*\n* One example of this is a text splitter that splits a large document into\n* many smaller documents.\n*/\nvar BaseDocumentTransformer = class extends Runnable {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"documents\",\n\t\t\"transformers\"\n\t];\n\t/**\n\t* Method to invoke the document transformation. This method calls the\n\t* transformDocuments method with the provided input.\n\t* @param input The input documents to be transformed.\n\t* @param _options Optional configuration object to customize the behavior of callbacks.\n\t* @returns A Promise that resolves to the transformed documents.\n\t*/\n\tinvoke(input, _options) {\n\t\treturn this.transformDocuments(input);\n\t}\n};\n/**\n* Class for document transformers that return exactly one transformed document\n* for each input document.\n*/\nvar MappingDocumentTransformer = class extends BaseDocumentTransformer {\n\tasync transformDocuments(documents) {\n\t\tconst newDocuments = [];\n\t\tfor (const document of documents) {\n\t\t\tconst transformedDocument = await this._transformDocument(document);\n\t\t\tnewDocuments.push(transformedDocument);\n\t\t}\n\t\treturn newDocuments;\n\t}\n};\n\n//#endregion\nexport { BaseDocumentTransformer, MappingDocumentTransformer };\n//# sourceMappingURL=transformers.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { Document } from \"./document.js\";\nimport { BaseDocumentTransformer, MappingDocumentTransformer } from \"./transformers.js\";\n\n//#region src/documents/index.ts\nvar documents_exports = {};\n__export(documents_exports, {\n\tBaseDocumentTransformer: () => BaseDocumentTransformer,\n\tDocument: () => Document,\n\tMappingDocumentTransformer: () => MappingDocumentTransformer\n});\n\n//#endregion\nexport { BaseDocumentTransformer, Document, MappingDocumentTransformer, documents_exports };\n//# sourceMappingURL=index.js.map","import { Serializable } from \"../load/serializable.js\";\n\n//#region src/example_selectors/base.ts\n/**\n* Base class for example selectors.\n*/\nvar BaseExampleSelector = class extends Serializable {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"example_selectors\",\n\t\t\"base\"\n\t];\n};\n\n//#endregion\nexport { BaseExampleSelector };\n//# sourceMappingURL=base.js.map","//#region src/example_selectors/conditional.ts\n/**\n* Abstract class that defines the interface for selecting a prompt for a\n* given language model.\n*/\nvar BasePromptSelector = class {\n\t/**\n\t* Asynchronous version of `getPrompt` that also accepts an options object\n\t* for partial variables.\n\t* @param llm The language model for which to get a prompt.\n\t* @param options Optional object for partial variables.\n\t* @returns A Promise that resolves to a prompt template.\n\t*/\n\tasync getPromptAsync(llm, options) {\n\t\tconst prompt = this.getPrompt(llm);\n\t\treturn prompt.partial(options?.partialVariables ?? {});\n\t}\n};\n/**\n* Concrete implementation of `BasePromptSelector` that selects a prompt\n* based on a set of conditions. It has a default prompt that it returns\n* if none of the conditions are met.\n*/\nvar ConditionalPromptSelector = class extends BasePromptSelector {\n\tdefaultPrompt;\n\tconditionals;\n\tconstructor(default_prompt, conditionals = []) {\n\t\tsuper();\n\t\tthis.defaultPrompt = default_prompt;\n\t\tthis.conditionals = conditionals;\n\t}\n\t/**\n\t* Method that selects a prompt based on a set of conditions. If none of\n\t* the conditions are met, it returns the default prompt.\n\t* @param llm The language model for which to get a prompt.\n\t* @returns A prompt template.\n\t*/\n\tgetPrompt(llm) {\n\t\tfor (const [condition, prompt] of this.conditionals) if (condition(llm)) return prompt;\n\t\treturn this.defaultPrompt;\n\t}\n};\n/**\n* Type guard function that checks if a given language model is of type\n* `BaseLLM`.\n*/\nfunction isLLM(llm) {\n\treturn llm._modelType() === \"base_llm\";\n}\n/**\n* Type guard function that checks if a given language model is of type\n* `BaseChatModel`.\n*/\nfunction isChatModel(llm) {\n\treturn llm._modelType() === \"base_chat_model\";\n}\n\n//#endregion\nexport { BasePromptSelector, ConditionalPromptSelector, isChatModel, isLLM };\n//# sourceMappingURL=conditional.js.map","import { BaseExampleSelector } from \"./base.js\";\n\n//#region src/example_selectors/length_based.ts\n/**\n* Calculates the length of a text based on the number of words and lines.\n*/\nfunction getLengthBased(text) {\n\treturn text.split(/\\n| /).length;\n}\n/**\n* A specialized example selector that selects examples based on their\n* length, ensuring that the total length of the selected examples does\n* not exceed a specified maximum length.\n* @example\n* ```typescript\n* const exampleSelector = new LengthBasedExampleSelector(\n*   [\n*     { input: \"happy\", output: \"sad\" },\n*     { input: \"tall\", output: \"short\" },\n*     { input: \"energetic\", output: \"lethargic\" },\n*     { input: \"sunny\", output: \"gloomy\" },\n*     { input: \"windy\", output: \"calm\" },\n*   ],\n*   {\n*     examplePrompt: new PromptTemplate({\n*       inputVariables: [\"input\", \"output\"],\n*       template: \"Input: {input}\\nOutput: {output}\",\n*     }),\n*     maxLength: 25,\n*   },\n* );\n* const dynamicPrompt = new FewShotPromptTemplate({\n*   exampleSelector,\n*   examplePrompt: new PromptTemplate({\n*     inputVariables: [\"input\", \"output\"],\n*     template: \"Input: {input}\\nOutput: {output}\",\n*   }),\n*   prefix: \"Give the antonym of every input\",\n*   suffix: \"Input: {adjective}\\nOutput:\",\n*   inputVariables: [\"adjective\"],\n* });\n* console.log(dynamicPrompt.format({ adjective: \"big\" }));\n* console.log(\n*   dynamicPrompt.format({\n*     adjective:\n*       \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\",\n*   }),\n* );\n* ```\n*/\nvar LengthBasedExampleSelector = class LengthBasedExampleSelector extends BaseExampleSelector {\n\texamples = [];\n\texamplePrompt;\n\tgetTextLength = getLengthBased;\n\tmaxLength = 2048;\n\texampleTextLengths = [];\n\tconstructor(data) {\n\t\tsuper(data);\n\t\tthis.examplePrompt = data.examplePrompt;\n\t\tthis.maxLength = data.maxLength ?? 2048;\n\t\tthis.getTextLength = data.getTextLength ?? getLengthBased;\n\t}\n\t/**\n\t* Adds an example to the list of examples and calculates its length.\n\t* @param example The example to be added.\n\t* @returns Promise that resolves when the example has been added and its length calculated.\n\t*/\n\tasync addExample(example) {\n\t\tthis.examples.push(example);\n\t\tconst stringExample = await this.examplePrompt.format(example);\n\t\tthis.exampleTextLengths.push(this.getTextLength(stringExample));\n\t}\n\t/**\n\t* Calculates the lengths of the examples.\n\t* @param v Array of lengths of the examples.\n\t* @param values Instance of LengthBasedExampleSelector.\n\t* @returns Promise that resolves with an array of lengths of the examples.\n\t*/\n\tasync calculateExampleTextLengths(v, values) {\n\t\tif (v.length > 0) return v;\n\t\tconst { examples, examplePrompt } = values;\n\t\tconst stringExamples = await Promise.all(examples.map((eg) => examplePrompt.format(eg)));\n\t\treturn stringExamples.map((eg) => this.getTextLength(eg));\n\t}\n\t/**\n\t* Selects examples until the total length of the selected examples\n\t* reaches the maxLength.\n\t* @param inputVariables The input variables for the examples.\n\t* @returns Promise that resolves with an array of selected examples.\n\t*/\n\tasync selectExamples(inputVariables) {\n\t\tconst inputs = Object.values(inputVariables).join(\" \");\n\t\tlet remainingLength = this.maxLength - this.getTextLength(inputs);\n\t\tlet i = 0;\n\t\tconst examples = [];\n\t\twhile (remainingLength > 0 && i < this.examples.length) {\n\t\t\tconst newLength = remainingLength - this.exampleTextLengths[i];\n\t\t\tif (newLength < 0) break;\n\t\t\telse {\n\t\t\t\texamples.push(this.examples[i]);\n\t\t\t\tremainingLength = newLength;\n\t\t\t}\n\t\t\ti += 1;\n\t\t}\n\t\treturn examples;\n\t}\n\t/**\n\t* Creates a new instance of LengthBasedExampleSelector and adds a list of\n\t* examples to it.\n\t* @param examples Array of examples to be added.\n\t* @param args Input parameters for the LengthBasedExampleSelector.\n\t* @returns Promise that resolves with a new instance of LengthBasedExampleSelector with the examples added.\n\t*/\n\tstatic async fromExamples(examples, args) {\n\t\tconst selector = new LengthBasedExampleSelector(args);\n\t\tawait Promise.all(examples.map((eg) => selector.addExample(eg)));\n\t\treturn selector;\n\t}\n};\n\n//#endregion\nexport { LengthBasedExampleSelector };\n//# sourceMappingURL=length_based.js.map","import { Document } from \"../documents/document.js\";\nimport { BaseExampleSelector } from \"./base.js\";\n\n//#region src/example_selectors/semantic_similarity.ts\nfunction sortedValues(values) {\n\treturn Object.keys(values).sort().map((key) => values[key]);\n}\n/**\n* Class that selects examples based on semantic similarity. It extends\n* the BaseExampleSelector class.\n* @example\n* ```typescript\n* const exampleSelector = await SemanticSimilarityExampleSelector.fromExamples(\n*   [\n*     { input: \"happy\", output: \"sad\" },\n*     { input: \"tall\", output: \"short\" },\n*     { input: \"energetic\", output: \"lethargic\" },\n*     { input: \"sunny\", output: \"gloomy\" },\n*     { input: \"windy\", output: \"calm\" },\n*   ],\n*   new OpenAIEmbeddings(),\n*   HNSWLib,\n*   { k: 1 },\n* );\n* const dynamicPrompt = new FewShotPromptTemplate({\n*   exampleSelector,\n*   examplePrompt: PromptTemplate.fromTemplate(\n*     \"Input: {input}\\nOutput: {output}\",\n*   ),\n*   prefix: \"Give the antonym of every input\",\n*   suffix: \"Input: {adjective}\\nOutput:\",\n*   inputVariables: [\"adjective\"],\n* });\n* console.log(await dynamicPrompt.format({ adjective: \"rainy\" }));\n* ```\n*/\nvar SemanticSimilarityExampleSelector = class SemanticSimilarityExampleSelector extends BaseExampleSelector {\n\tvectorStoreRetriever;\n\texampleKeys;\n\tinputKeys;\n\tconstructor(data) {\n\t\tsuper(data);\n\t\tthis.exampleKeys = data.exampleKeys;\n\t\tthis.inputKeys = data.inputKeys;\n\t\tif (data.vectorStore !== void 0) this.vectorStoreRetriever = data.vectorStore.asRetriever({\n\t\t\tk: data.k ?? 4,\n\t\t\tfilter: data.filter\n\t\t});\n\t\telse if (data.vectorStoreRetriever) this.vectorStoreRetriever = data.vectorStoreRetriever;\n\t\telse throw new Error(`You must specify one of \"vectorStore\" and \"vectorStoreRetriever\".`);\n\t}\n\t/**\n\t* Method that adds a new example to the vectorStore. The example is\n\t* converted to a string and added to the vectorStore as a document.\n\t* @param example The example to be added to the vectorStore.\n\t* @returns Promise that resolves when the example has been added to the vectorStore.\n\t*/\n\tasync addExample(example) {\n\t\tconst inputKeys = this.inputKeys ?? Object.keys(example);\n\t\tconst stringExample = sortedValues(inputKeys.reduce((acc, key) => ({\n\t\t\t...acc,\n\t\t\t[key]: example[key]\n\t\t}), {})).join(\" \");\n\t\tawait this.vectorStoreRetriever.addDocuments([new Document({\n\t\t\tpageContent: stringExample,\n\t\t\tmetadata: example\n\t\t})]);\n\t}\n\t/**\n\t* Method that selects which examples to use based on semantic similarity.\n\t* It performs a similarity search in the vectorStore using the input\n\t* variables and returns the examples with the highest similarity.\n\t* @param inputVariables The input variables used for the similarity search.\n\t* @returns Promise that resolves with an array of the selected examples.\n\t*/\n\tasync selectExamples(inputVariables) {\n\t\tconst inputKeys = this.inputKeys ?? Object.keys(inputVariables);\n\t\tconst query = sortedValues(inputKeys.reduce((acc, key) => ({\n\t\t\t...acc,\n\t\t\t[key]: inputVariables[key]\n\t\t}), {})).join(\" \");\n\t\tconst exampleDocs = await this.vectorStoreRetriever.invoke(query);\n\t\tconst examples = exampleDocs.map((doc) => doc.metadata);\n\t\tif (this.exampleKeys) return examples.map((example) => this.exampleKeys.reduce((acc, key) => ({\n\t\t\t...acc,\n\t\t\t[key]: example[key]\n\t\t}), {}));\n\t\treturn examples;\n\t}\n\t/**\n\t* Static method that creates a new instance of\n\t* SemanticSimilarityExampleSelector. It takes a list of examples, an\n\t* instance of Embeddings, a VectorStore class, and an options object as\n\t* parameters. It converts the examples to strings, creates a VectorStore\n\t* from the strings and the embeddings, and returns a new\n\t* SemanticSimilarityExampleSelector with the created VectorStore and the\n\t* options provided.\n\t* @param examples The list of examples to be used.\n\t* @param embeddings The instance of Embeddings to be used.\n\t* @param vectorStoreCls The VectorStore class to be used.\n\t* @param options The options object for the SemanticSimilarityExampleSelector.\n\t* @returns Promise that resolves with a new instance of SemanticSimilarityExampleSelector.\n\t*/\n\tstatic async fromExamples(examples, embeddings, vectorStoreCls, options = {}) {\n\t\tconst inputKeys = options.inputKeys ?? null;\n\t\tconst stringExamples = examples.map((example) => sortedValues(inputKeys ? inputKeys.reduce((acc, key) => ({\n\t\t\t...acc,\n\t\t\t[key]: example[key]\n\t\t}), {}) : example).join(\" \"));\n\t\tconst vectorStore = await vectorStoreCls.fromTexts(stringExamples, examples, embeddings, options);\n\t\treturn new SemanticSimilarityExampleSelector({\n\t\t\tvectorStore,\n\t\t\tk: options.k ?? 4,\n\t\t\texampleKeys: options.exampleKeys,\n\t\t\tinputKeys: options.inputKeys\n\t\t});\n\t}\n};\n\n//#endregion\nexport { SemanticSimilarityExampleSelector };\n//# sourceMappingURL=semantic_similarity.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { BaseExampleSelector } from \"./base.js\";\nimport { BasePromptSelector, ConditionalPromptSelector, isChatModel, isLLM } from \"./conditional.js\";\nimport { LengthBasedExampleSelector } from \"./length_based.js\";\nimport { SemanticSimilarityExampleSelector } from \"./semantic_similarity.js\";\n\n//#region src/example_selectors/index.ts\nvar example_selectors_exports = {};\n__export(example_selectors_exports, {\n\tBaseExampleSelector: () => BaseExampleSelector,\n\tBasePromptSelector: () => BasePromptSelector,\n\tConditionalPromptSelector: () => ConditionalPromptSelector,\n\tLengthBasedExampleSelector: () => LengthBasedExampleSelector,\n\tSemanticSimilarityExampleSelector: () => SemanticSimilarityExampleSelector,\n\tisChatModel: () => isChatModel,\n\tisLLM: () => isLLM\n});\n\n//#endregion\nexport { BaseExampleSelector, BasePromptSelector, ConditionalPromptSelector, LengthBasedExampleSelector, SemanticSimilarityExampleSelector, example_selectors_exports, isChatModel, isLLM };\n//# sourceMappingURL=index.js.map","import { Serializable } from \"../load/serializable.js\";\n\n//#region src/indexing/record_manager.ts\nconst UUIDV5_NAMESPACE = \"10f90ea3-90a4-4962-bf75-83a0f3c1c62a\";\nvar RecordManager = class extends Serializable {\n\tlc_namespace = [\"langchain\", \"recordmanagers\"];\n};\n\n//#endregion\nexport { RecordManager, UUIDV5_NAMESPACE };\n//# sourceMappingURL=record_manager.js.map","import { sha256 } from \"../utils/js-sha256/hash.js\";\nimport \"../utils/hash.js\";\nimport { Document } from \"../documents/document.js\";\nimport { UUIDV5_NAMESPACE } from \"./record_manager.js\";\nimport { v5 } from \"uuid\";\n\n//#region src/indexing/base.ts\n/**\n* HashedDocument is a Document with hashes calculated.\n* Hashes are calculated based on page content and metadata.\n* It is used for indexing.\n*/\nvar _HashedDocument = class {\n\tuid;\n\thash_;\n\tcontentHash;\n\tmetadataHash;\n\tpageContent;\n\tmetadata;\n\tkeyEncoder = sha256;\n\tconstructor(fields) {\n\t\tthis.uid = fields.uid;\n\t\tthis.pageContent = fields.pageContent;\n\t\tthis.metadata = fields.metadata;\n\t}\n\tmakeDefaultKeyEncoder(keyEncoderFn) {\n\t\tthis.keyEncoder = keyEncoderFn;\n\t}\n\tcalculateHashes() {\n\t\tconst forbiddenKeys = [\n\t\t\t\"hash_\",\n\t\t\t\"content_hash\",\n\t\t\t\"metadata_hash\"\n\t\t];\n\t\tfor (const key of forbiddenKeys) if (key in this.metadata) throw new Error(`Metadata cannot contain key ${key} as it is reserved for internal use. Restricted keys: [${forbiddenKeys.join(\", \")}]`);\n\t\tconst contentHash = this._hashStringToUUID(this.pageContent);\n\t\ttry {\n\t\t\tconst metadataHash = this._hashNestedDictToUUID(this.metadata);\n\t\t\tthis.contentHash = contentHash;\n\t\t\tthis.metadataHash = metadataHash;\n\t\t} catch (e) {\n\t\t\tthrow new Error(`Failed to hash metadata: ${e}. Please use a dict that can be serialized using json.`);\n\t\t}\n\t\tthis.hash_ = this._hashStringToUUID(this.contentHash + this.metadataHash);\n\t\tif (!this.uid) this.uid = this.hash_;\n\t}\n\ttoDocument() {\n\t\treturn new Document({\n\t\t\tpageContent: this.pageContent,\n\t\t\tmetadata: this.metadata\n\t\t});\n\t}\n\tstatic fromDocument(document, uid) {\n\t\tconst doc = new this({\n\t\t\tpageContent: document.pageContent,\n\t\t\tmetadata: document.metadata,\n\t\t\tuid: uid || document.uid\n\t\t});\n\t\tdoc.calculateHashes();\n\t\treturn doc;\n\t}\n\t_hashStringToUUID(inputString) {\n\t\tconst hash_value = this.keyEncoder(inputString);\n\t\treturn v5(hash_value, UUIDV5_NAMESPACE);\n\t}\n\t_hashNestedDictToUUID(data) {\n\t\tconst serialized_data = JSON.stringify(data, Object.keys(data).sort());\n\t\tconst hash_value = this.keyEncoder(serialized_data);\n\t\treturn v5(hash_value, UUIDV5_NAMESPACE);\n\t}\n};\nfunction _batch(size, iterable) {\n\tconst batches = [];\n\tlet currentBatch = [];\n\titerable.forEach((item) => {\n\t\tcurrentBatch.push(item);\n\t\tif (currentBatch.length >= size) {\n\t\t\tbatches.push(currentBatch);\n\t\t\tcurrentBatch = [];\n\t\t}\n\t});\n\tif (currentBatch.length > 0) batches.push(currentBatch);\n\treturn batches;\n}\nfunction _deduplicateInOrder(hashedDocuments) {\n\tconst seen = /* @__PURE__ */ new Set();\n\tconst deduplicated = [];\n\tfor (const hashedDoc of hashedDocuments) {\n\t\tif (!hashedDoc.hash_) throw new Error(\"Hashed document does not have a hash\");\n\t\tif (!seen.has(hashedDoc.hash_)) {\n\t\t\tseen.add(hashedDoc.hash_);\n\t\t\tdeduplicated.push(hashedDoc);\n\t\t}\n\t}\n\treturn deduplicated;\n}\nfunction _getSourceIdAssigner(sourceIdKey) {\n\tif (sourceIdKey === null) return (_doc) => null;\n\telse if (typeof sourceIdKey === \"string\") return (doc) => doc.metadata[sourceIdKey];\n\telse if (typeof sourceIdKey === \"function\") return sourceIdKey;\n\telse throw new Error(`sourceIdKey should be null, a string or a function, got ${typeof sourceIdKey}`);\n}\nconst _isBaseDocumentLoader = (arg) => {\n\tif (\"load\" in arg && typeof arg.load === \"function\" && \"loadAndSplit\" in arg && typeof arg.loadAndSplit === \"function\") return true;\n\treturn false;\n};\n/**\n* Index data from the doc source into the vector store.\n*\n* Indexing functionality uses a manager to keep track of which documents\n* are in the vector store.\n*\n* This allows us to keep track of which documents were updated, and which\n* documents were deleted, which documents should be skipped.\n*\n* For the time being, documents are indexed using their hashes, and users\n*  are not able to specify the uid of the document.\n*\n* @param {IndexArgs} args\n* @param {BaseDocumentLoader | DocumentInterface[]} args.docsSource The source of documents to index. Can be a DocumentLoader or a list of Documents.\n* @param {RecordManagerInterface} args.recordManager The record manager to use for keeping track of indexed documents.\n* @param {VectorStore} args.vectorStore The vector store to use for storing the documents.\n* @param {IndexOptions | undefined} args.options Options for indexing.\n* @returns {Promise<IndexingResult>}\n*/\nasync function index(args) {\n\tconst { docsSource, recordManager, vectorStore, options } = args;\n\tconst { batchSize = 100, cleanup, sourceIdKey, cleanupBatchSize = 1e3, forceUpdate = false } = options ?? {};\n\tif (cleanup === \"incremental\" && !sourceIdKey) throw new Error(\"sourceIdKey is required when cleanup mode is incremental. Please provide through 'options.sourceIdKey'.\");\n\tconst docs = _isBaseDocumentLoader(docsSource) ? await docsSource.load() : docsSource;\n\tconst sourceIdAssigner = _getSourceIdAssigner(sourceIdKey ?? null);\n\tconst indexStartDt = await recordManager.getTime();\n\tlet numAdded = 0;\n\tlet numDeleted = 0;\n\tlet numUpdated = 0;\n\tlet numSkipped = 0;\n\tconst batches = _batch(batchSize ?? 100, docs);\n\tfor (const batch of batches) {\n\t\tconst hashedDocs = _deduplicateInOrder(batch.map((doc) => _HashedDocument.fromDocument(doc)));\n\t\tconst sourceIds = hashedDocs.map((doc) => sourceIdAssigner(doc));\n\t\tif (cleanup === \"incremental\") hashedDocs.forEach((_hashedDoc, index$1) => {\n\t\t\tconst source = sourceIds[index$1];\n\t\t\tif (source === null) throw new Error(\"sourceIdKey must be provided when cleanup is incremental\");\n\t\t});\n\t\tconst batchExists = await recordManager.exists(hashedDocs.map((doc) => doc.uid));\n\t\tconst uids = [];\n\t\tconst docsToIndex = [];\n\t\tconst docsToUpdate = [];\n\t\tconst seenDocs = /* @__PURE__ */ new Set();\n\t\thashedDocs.forEach((hashedDoc, i) => {\n\t\t\tconst docExists = batchExists[i];\n\t\t\tif (docExists) if (forceUpdate) seenDocs.add(hashedDoc.uid);\n\t\t\telse {\n\t\t\t\tdocsToUpdate.push(hashedDoc.uid);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tuids.push(hashedDoc.uid);\n\t\t\tdocsToIndex.push(hashedDoc.toDocument());\n\t\t});\n\t\tif (docsToUpdate.length > 0) {\n\t\t\tawait recordManager.update(docsToUpdate, { timeAtLeast: indexStartDt });\n\t\t\tnumSkipped += docsToUpdate.length;\n\t\t}\n\t\tif (docsToIndex.length > 0) {\n\t\t\tawait vectorStore.addDocuments(docsToIndex, { ids: uids });\n\t\t\tnumAdded += docsToIndex.length - seenDocs.size;\n\t\t\tnumUpdated += seenDocs.size;\n\t\t}\n\t\tawait recordManager.update(hashedDocs.map((doc) => doc.uid), {\n\t\t\ttimeAtLeast: indexStartDt,\n\t\t\tgroupIds: sourceIds\n\t\t});\n\t\tif (cleanup === \"incremental\") {\n\t\t\tsourceIds.forEach((sourceId) => {\n\t\t\t\tif (!sourceId) throw new Error(\"Source id cannot be null\");\n\t\t\t});\n\t\t\tconst uidsToDelete = await recordManager.listKeys({\n\t\t\t\tbefore: indexStartDt,\n\t\t\t\tgroupIds: sourceIds\n\t\t\t});\n\t\t\tif (uidsToDelete.length > 0) {\n\t\t\t\tawait vectorStore.delete({ ids: uidsToDelete });\n\t\t\t\tawait recordManager.deleteKeys(uidsToDelete);\n\t\t\t\tnumDeleted += uidsToDelete.length;\n\t\t\t}\n\t\t}\n\t}\n\tif (cleanup === \"full\") {\n\t\tlet uidsToDelete = await recordManager.listKeys({\n\t\t\tbefore: indexStartDt,\n\t\t\tlimit: cleanupBatchSize\n\t\t});\n\t\twhile (uidsToDelete.length > 0) {\n\t\t\tawait vectorStore.delete({ ids: uidsToDelete });\n\t\t\tawait recordManager.deleteKeys(uidsToDelete);\n\t\t\tnumDeleted += uidsToDelete.length;\n\t\t\tuidsToDelete = await recordManager.listKeys({\n\t\t\t\tbefore: indexStartDt,\n\t\t\t\tlimit: cleanupBatchSize\n\t\t\t});\n\t\t}\n\t}\n\treturn {\n\t\tnumAdded,\n\t\tnumDeleted,\n\t\tnumUpdated,\n\t\tnumSkipped\n\t};\n}\n\n//#endregion\nexport { _HashedDocument, _batch, _deduplicateInOrder, _getSourceIdAssigner, _isBaseDocumentLoader, index };\n//# sourceMappingURL=base.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { RecordManager, UUIDV5_NAMESPACE } from \"./record_manager.js\";\nimport { _HashedDocument, _batch, _deduplicateInOrder, _getSourceIdAssigner, _isBaseDocumentLoader, index } from \"./base.js\";\n\n//#region src/indexing/index.ts\nvar indexing_exports = {};\n__export(indexing_exports, {\n\tRecordManager: () => RecordManager,\n\tUUIDV5_NAMESPACE: () => UUIDV5_NAMESPACE,\n\t_HashedDocument: () => _HashedDocument,\n\t_batch: () => _batch,\n\t_deduplicateInOrder: () => _deduplicateInOrder,\n\t_getSourceIdAssigner: () => _getSourceIdAssigner,\n\t_isBaseDocumentLoader: () => _isBaseDocumentLoader,\n\tindex: () => index\n});\n\n//#endregion\nexport { RecordManager, UUIDV5_NAMESPACE, _HashedDocument, _batch, _deduplicateInOrder, _getSourceIdAssigner, _isBaseDocumentLoader, index, indexing_exports };\n//# sourceMappingURL=index.js.map","import base64 from 'base64-js';\n\nvar __defProp = Object.defineProperty;\nvar __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;\nvar __publicField = (obj, key, value) => {\n  __defNormalProp(obj, typeof key !== \"symbol\" ? key + \"\" : key, value);\n  return value;\n};\n\n// src/utils.ts\nfunction never(_) {\n}\nfunction bytePairMerge(piece, ranks) {\n  let parts = Array.from(\n    { length: piece.length },\n    (_, i) => ({ start: i, end: i + 1 })\n  );\n  while (parts.length > 1) {\n    let minRank = null;\n    for (let i = 0; i < parts.length - 1; i++) {\n      const slice = piece.slice(parts[i].start, parts[i + 1].end);\n      const rank = ranks.get(slice.join(\",\"));\n      if (rank == null)\n        continue;\n      if (minRank == null || rank < minRank[0]) {\n        minRank = [rank, i];\n      }\n    }\n    if (minRank != null) {\n      const i = minRank[1];\n      parts[i] = { start: parts[i].start, end: parts[i + 1].end };\n      parts.splice(i + 1, 1);\n    } else {\n      break;\n    }\n  }\n  return parts;\n}\nfunction bytePairEncode(piece, ranks) {\n  if (piece.length === 1)\n    return [ranks.get(piece.join(\",\"))];\n  return bytePairMerge(piece, ranks).map((p) => ranks.get(piece.slice(p.start, p.end).join(\",\"))).filter((x) => x != null);\n}\nfunction escapeRegex(str) {\n  return str.replace(/[\\\\^$*+?.()|[\\]{}]/g, \"\\\\$&\");\n}\nvar _Tiktoken = class {\n  /** @internal */\n  specialTokens;\n  /** @internal */\n  inverseSpecialTokens;\n  /** @internal */\n  patStr;\n  /** @internal */\n  textEncoder = new TextEncoder();\n  /** @internal */\n  textDecoder = new TextDecoder(\"utf-8\");\n  /** @internal */\n  rankMap = /* @__PURE__ */ new Map();\n  /** @internal */\n  textMap = /* @__PURE__ */ new Map();\n  constructor(ranks, extendedSpecialTokens) {\n    this.patStr = ranks.pat_str;\n    const uncompressed = ranks.bpe_ranks.split(\"\\n\").filter(Boolean).reduce((memo, x) => {\n      const [_, offsetStr, ...tokens] = x.split(\" \");\n      const offset = Number.parseInt(offsetStr, 10);\n      tokens.forEach((token, i) => memo[token] = offset + i);\n      return memo;\n    }, {});\n    for (const [token, rank] of Object.entries(uncompressed)) {\n      const bytes = base64.toByteArray(token);\n      this.rankMap.set(bytes.join(\",\"), rank);\n      this.textMap.set(rank, bytes);\n    }\n    this.specialTokens = { ...ranks.special_tokens, ...extendedSpecialTokens };\n    this.inverseSpecialTokens = Object.entries(this.specialTokens).reduce((memo, [text, rank]) => {\n      memo[rank] = this.textEncoder.encode(text);\n      return memo;\n    }, {});\n  }\n  encode(text, allowedSpecial = [], disallowedSpecial = \"all\") {\n    const regexes = new RegExp(this.patStr, \"ug\");\n    const specialRegex = _Tiktoken.specialTokenRegex(\n      Object.keys(this.specialTokens)\n    );\n    const ret = [];\n    const allowedSpecialSet = new Set(\n      allowedSpecial === \"all\" ? Object.keys(this.specialTokens) : allowedSpecial\n    );\n    const disallowedSpecialSet = new Set(\n      disallowedSpecial === \"all\" ? Object.keys(this.specialTokens).filter(\n        (x) => !allowedSpecialSet.has(x)\n      ) : disallowedSpecial\n    );\n    if (disallowedSpecialSet.size > 0) {\n      const disallowedSpecialRegex = _Tiktoken.specialTokenRegex([\n        ...disallowedSpecialSet\n      ]);\n      const specialMatch = text.match(disallowedSpecialRegex);\n      if (specialMatch != null) {\n        throw new Error(\n          `The text contains a special token that is not allowed: ${specialMatch[0]}`\n        );\n      }\n    }\n    let start = 0;\n    while (true) {\n      let nextSpecial = null;\n      let startFind = start;\n      while (true) {\n        specialRegex.lastIndex = startFind;\n        nextSpecial = specialRegex.exec(text);\n        if (nextSpecial == null || allowedSpecialSet.has(nextSpecial[0]))\n          break;\n        startFind = nextSpecial.index + 1;\n      }\n      const end = nextSpecial?.index ?? text.length;\n      for (const match of text.substring(start, end).matchAll(regexes)) {\n        const piece = this.textEncoder.encode(match[0]);\n        const token2 = this.rankMap.get(piece.join(\",\"));\n        if (token2 != null) {\n          ret.push(token2);\n          continue;\n        }\n        ret.push(...bytePairEncode(piece, this.rankMap));\n      }\n      if (nextSpecial == null)\n        break;\n      let token = this.specialTokens[nextSpecial[0]];\n      ret.push(token);\n      start = nextSpecial.index + nextSpecial[0].length;\n    }\n    return ret;\n  }\n  decode(tokens) {\n    const res = [];\n    let length = 0;\n    for (let i2 = 0; i2 < tokens.length; ++i2) {\n      const token = tokens[i2];\n      const bytes = this.textMap.get(token) ?? this.inverseSpecialTokens[token];\n      if (bytes != null) {\n        res.push(bytes);\n        length += bytes.length;\n      }\n    }\n    const mergedArray = new Uint8Array(length);\n    let i = 0;\n    for (const bytes of res) {\n      mergedArray.set(bytes, i);\n      i += bytes.length;\n    }\n    return this.textDecoder.decode(mergedArray);\n  }\n};\nvar Tiktoken = _Tiktoken;\n__publicField(Tiktoken, \"specialTokenRegex\", (tokens) => {\n  return new RegExp(tokens.map((i) => escapeRegex(i)).join(\"|\"), \"g\");\n});\nfunction getEncodingNameForModel(model) {\n  switch (model) {\n    case \"gpt2\": {\n      return \"gpt2\";\n    }\n    case \"code-cushman-001\":\n    case \"code-cushman-002\":\n    case \"code-davinci-001\":\n    case \"code-davinci-002\":\n    case \"cushman-codex\":\n    case \"davinci-codex\":\n    case \"davinci-002\":\n    case \"text-davinci-002\":\n    case \"text-davinci-003\": {\n      return \"p50k_base\";\n    }\n    case \"code-davinci-edit-001\":\n    case \"text-davinci-edit-001\": {\n      return \"p50k_edit\";\n    }\n    case \"ada\":\n    case \"babbage\":\n    case \"babbage-002\":\n    case \"code-search-ada-code-001\":\n    case \"code-search-babbage-code-001\":\n    case \"curie\":\n    case \"davinci\":\n    case \"text-ada-001\":\n    case \"text-babbage-001\":\n    case \"text-curie-001\":\n    case \"text-davinci-001\":\n    case \"text-search-ada-doc-001\":\n    case \"text-search-babbage-doc-001\":\n    case \"text-search-curie-doc-001\":\n    case \"text-search-davinci-doc-001\":\n    case \"text-similarity-ada-001\":\n    case \"text-similarity-babbage-001\":\n    case \"text-similarity-curie-001\":\n    case \"text-similarity-davinci-001\": {\n      return \"r50k_base\";\n    }\n    case \"gpt-3.5-turbo-instruct-0914\":\n    case \"gpt-3.5-turbo-instruct\":\n    case \"gpt-3.5-turbo-16k-0613\":\n    case \"gpt-3.5-turbo-16k\":\n    case \"gpt-3.5-turbo-0613\":\n    case \"gpt-3.5-turbo-0301\":\n    case \"gpt-3.5-turbo\":\n    case \"gpt-4-32k-0613\":\n    case \"gpt-4-32k-0314\":\n    case \"gpt-4-32k\":\n    case \"gpt-4-0613\":\n    case \"gpt-4-0314\":\n    case \"gpt-4\":\n    case \"gpt-3.5-turbo-1106\":\n    case \"gpt-35-turbo\":\n    case \"gpt-4-1106-preview\":\n    case \"gpt-4-vision-preview\":\n    case \"gpt-3.5-turbo-0125\":\n    case \"gpt-4-turbo\":\n    case \"gpt-4-turbo-2024-04-09\":\n    case \"gpt-4-turbo-preview\":\n    case \"gpt-4-0125-preview\":\n    case \"text-embedding-ada-002\":\n    case \"text-embedding-3-small\":\n    case \"text-embedding-3-large\": {\n      return \"cl100k_base\";\n    }\n    case \"gpt-4o\":\n    case \"gpt-4o-2024-05-13\":\n    case \"gpt-4o-2024-08-06\":\n    case \"gpt-4o-2024-11-20\":\n    case \"gpt-4o-mini-2024-07-18\":\n    case \"gpt-4o-mini\":\n    case \"gpt-4o-search-preview\":\n    case \"gpt-4o-search-preview-2025-03-11\":\n    case \"gpt-4o-mini-search-preview\":\n    case \"gpt-4o-mini-search-preview-2025-03-11\":\n    case \"gpt-4o-audio-preview\":\n    case \"gpt-4o-audio-preview-2024-12-17\":\n    case \"gpt-4o-audio-preview-2024-10-01\":\n    case \"gpt-4o-mini-audio-preview\":\n    case \"gpt-4o-mini-audio-preview-2024-12-17\":\n    case \"o1\":\n    case \"o1-2024-12-17\":\n    case \"o1-mini\":\n    case \"o1-mini-2024-09-12\":\n    case \"o1-preview\":\n    case \"o1-preview-2024-09-12\":\n    case \"o1-pro\":\n    case \"o1-pro-2025-03-19\":\n    case \"o3\":\n    case \"o3-2025-04-16\":\n    case \"o3-mini\":\n    case \"o3-mini-2025-01-31\":\n    case \"o4-mini\":\n    case \"o4-mini-2025-04-16\":\n    case \"chatgpt-4o-latest\":\n    case \"gpt-4o-realtime\":\n    case \"gpt-4o-realtime-preview-2024-10-01\":\n    case \"gpt-4o-realtime-preview-2024-12-17\":\n    case \"gpt-4o-mini-realtime-preview\":\n    case \"gpt-4o-mini-realtime-preview-2024-12-17\":\n    case \"gpt-4.1\":\n    case \"gpt-4.1-2025-04-14\":\n    case \"gpt-4.1-mini\":\n    case \"gpt-4.1-mini-2025-04-14\":\n    case \"gpt-4.1-nano\":\n    case \"gpt-4.1-nano-2025-04-14\":\n    case \"gpt-4.5-preview\":\n    case \"gpt-4.5-preview-2025-02-27\":\n    case \"gpt-5\":\n    case \"gpt-5-2025-08-07\":\n    case \"gpt-5-nano\":\n    case \"gpt-5-nano-2025-08-07\":\n    case \"gpt-5-mini\":\n    case \"gpt-5-mini-2025-08-07\":\n    case \"gpt-5-chat-latest\": {\n      return \"o200k_base\";\n    }\n    default:\n      throw new Error(\"Unknown model\");\n  }\n}\n\nexport { Tiktoken, getEncodingNameForModel, never };\n","export { Tiktoken, getEncodingNameForModel } from './chunk-VL2OQCWN.js';\n","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { AsyncCaller } from \"./async_caller.js\";\nimport { Tiktoken, getEncodingNameForModel } from \"js-tiktoken/lite\";\n\n//#region src/utils/tiktoken.ts\nvar tiktoken_exports = {};\n__export(tiktoken_exports, {\n\tencodingForModel: () => encodingForModel,\n\tgetEncoding: () => getEncoding\n});\nconst cache = {};\nconst caller = /* @__PURE__ */ new AsyncCaller({});\nasync function getEncoding(encoding) {\n\tif (!(encoding in cache)) cache[encoding] = caller.fetch(`https://tiktoken.pages.dev/js/${encoding}.json`).then((res) => res.json()).then((data) => new Tiktoken(data)).catch((e) => {\n\t\tdelete cache[encoding];\n\t\tthrow e;\n\t});\n\treturn await cache[encoding];\n}\nasync function encodingForModel(model) {\n\treturn getEncoding(getEncodingNameForModel(model));\n}\n\n//#endregion\nexport { encodingForModel, getEncoding, tiktoken_exports };\n//# sourceMappingURL=tiktoken.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { coerceMessageLikeToMessage } from \"../messages/utils.js\";\nimport { AsyncCaller } from \"../utils/async_caller.js\";\nimport { Runnable } from \"../runnables/base.js\";\nimport { ChatPromptValue, StringPromptValue } from \"../prompt_values.js\";\nimport { InMemoryCache } from \"../caches/base.js\";\nimport { encodingForModel } from \"../utils/tiktoken.js\";\n\n//#region src/language_models/base.ts\nvar base_exports = {};\n__export(base_exports, {\n\tBaseLangChain: () => BaseLangChain,\n\tBaseLanguageModel: () => BaseLanguageModel,\n\tcalculateMaxTokens: () => calculateMaxTokens,\n\tgetEmbeddingContextSize: () => getEmbeddingContextSize,\n\tgetModelContextSize: () => getModelContextSize,\n\tgetModelNameForTiktoken: () => getModelNameForTiktoken,\n\tisOpenAITool: () => isOpenAITool\n});\nconst getModelNameForTiktoken = (modelName) => {\n\tif (modelName.startsWith(\"gpt-3.5-turbo-16k\")) return \"gpt-3.5-turbo-16k\";\n\tif (modelName.startsWith(\"gpt-3.5-turbo-\")) return \"gpt-3.5-turbo\";\n\tif (modelName.startsWith(\"gpt-4-32k\")) return \"gpt-4-32k\";\n\tif (modelName.startsWith(\"gpt-4-\")) return \"gpt-4\";\n\tif (modelName.startsWith(\"gpt-4o\")) return \"gpt-4o\";\n\treturn modelName;\n};\nconst getEmbeddingContextSize = (modelName) => {\n\tswitch (modelName) {\n\t\tcase \"text-embedding-ada-002\": return 8191;\n\t\tdefault: return 2046;\n\t}\n};\nconst getModelContextSize = (modelName) => {\n\tswitch (getModelNameForTiktoken(modelName)) {\n\t\tcase \"gpt-3.5-turbo-16k\": return 16384;\n\t\tcase \"gpt-3.5-turbo\": return 4096;\n\t\tcase \"gpt-4-32k\": return 32768;\n\t\tcase \"gpt-4\": return 8192;\n\t\tcase \"text-davinci-003\": return 4097;\n\t\tcase \"text-curie-001\": return 2048;\n\t\tcase \"text-babbage-001\": return 2048;\n\t\tcase \"text-ada-001\": return 2048;\n\t\tcase \"code-davinci-002\": return 8e3;\n\t\tcase \"code-cushman-001\": return 2048;\n\t\tdefault: return 4097;\n\t}\n};\n/**\n* Whether or not the input matches the OpenAI tool definition.\n* @param {unknown} tool The input to check.\n* @returns {boolean} Whether the input is an OpenAI tool definition.\n*/\nfunction isOpenAITool(tool) {\n\tif (typeof tool !== \"object\" || !tool) return false;\n\tif (\"type\" in tool && tool.type === \"function\" && \"function\" in tool && typeof tool.function === \"object\" && tool.function && \"name\" in tool.function && \"parameters\" in tool.function) return true;\n\treturn false;\n}\nconst calculateMaxTokens = async ({ prompt, modelName }) => {\n\tlet numTokens;\n\ttry {\n\t\tnumTokens = (await encodingForModel(getModelNameForTiktoken(modelName))).encode(prompt).length;\n\t} catch {\n\t\tconsole.warn(\"Failed to calculate number of tokens, falling back to approximate count\");\n\t\tnumTokens = Math.ceil(prompt.length / 4);\n\t}\n\tconst maxTokens = getModelContextSize(modelName);\n\treturn maxTokens - numTokens;\n};\nconst getVerbosity = () => false;\n/**\n* Base class for language models, chains, tools.\n*/\nvar BaseLangChain = class extends Runnable {\n\t/**\n\t* Whether to print out response text.\n\t*/\n\tverbose;\n\tcallbacks;\n\ttags;\n\tmetadata;\n\tget lc_attributes() {\n\t\treturn {\n\t\t\tcallbacks: void 0,\n\t\t\tverbose: void 0\n\t\t};\n\t}\n\tconstructor(params) {\n\t\tsuper(params);\n\t\tthis.verbose = params.verbose ?? getVerbosity();\n\t\tthis.callbacks = params.callbacks;\n\t\tthis.tags = params.tags ?? [];\n\t\tthis.metadata = params.metadata ?? {};\n\t}\n};\n/**\n* Base class for language models.\n*/\nvar BaseLanguageModel = class extends BaseLangChain {\n\t/**\n\t* Keys that the language model accepts as call options.\n\t*/\n\tget callKeys() {\n\t\treturn [\n\t\t\t\"stop\",\n\t\t\t\"timeout\",\n\t\t\t\"signal\",\n\t\t\t\"tags\",\n\t\t\t\"metadata\",\n\t\t\t\"callbacks\"\n\t\t];\n\t}\n\t/**\n\t* The async caller should be used by subclasses to make any async calls,\n\t* which will thus benefit from the concurrency and retry logic.\n\t*/\n\tcaller;\n\tcache;\n\tconstructor({ callbacks, callbackManager,...params }) {\n\t\tconst { cache,...rest } = params;\n\t\tsuper({\n\t\t\tcallbacks: callbacks ?? callbackManager,\n\t\t\t...rest\n\t\t});\n\t\tif (typeof cache === \"object\") this.cache = cache;\n\t\telse if (cache) this.cache = InMemoryCache.global();\n\t\telse this.cache = void 0;\n\t\tthis.caller = new AsyncCaller(params ?? {});\n\t}\n\t_encoding;\n\t/**\n\t* Get the number of tokens in the content.\n\t* @param content The content to get the number of tokens for.\n\t* @returns The number of tokens in the content.\n\t*/\n\tasync getNumTokens(content) {\n\t\tlet textContent;\n\t\tif (typeof content === \"string\") textContent = content;\n\t\telse\n /**\n\t\t* Content is an array of ContentBlock\n\t\t*\n\t\t* ToDo(@christian-bromann): This is a temporary fix to get the number of tokens for the content.\n\t\t* We need to find a better way to do this.\n\t\t* @see https://github.com/langchain-ai/langchainjs/pull/8341#pullrequestreview-2933713116\n\t\t*/\n\t\ttextContent = content.map((item) => {\n\t\t\tif (typeof item === \"string\") return item;\n\t\t\tif (item.type === \"text\" && \"text\" in item) return item.text;\n\t\t\treturn \"\";\n\t\t}).join(\"\");\n\t\tlet numTokens = Math.ceil(textContent.length / 4);\n\t\tif (!this._encoding) try {\n\t\t\tthis._encoding = await encodingForModel(\"modelName\" in this ? getModelNameForTiktoken(this.modelName) : \"gpt2\");\n\t\t} catch (error) {\n\t\t\tconsole.warn(\"Failed to calculate number of tokens, falling back to approximate count\", error);\n\t\t}\n\t\tif (this._encoding) try {\n\t\t\tnumTokens = this._encoding.encode(textContent).length;\n\t\t} catch (error) {\n\t\t\tconsole.warn(\"Failed to calculate number of tokens, falling back to approximate count\", error);\n\t\t}\n\t\treturn numTokens;\n\t}\n\tstatic _convertInputToPromptValue(input) {\n\t\tif (typeof input === \"string\") return new StringPromptValue(input);\n\t\telse if (Array.isArray(input)) return new ChatPromptValue(input.map(coerceMessageLikeToMessage));\n\t\telse return input;\n\t}\n\t/**\n\t* Get the identifying parameters of the LLM.\n\t*/\n\t_identifyingParams() {\n\t\treturn {};\n\t}\n\t/**\n\t* Create a unique cache key for a specific call to a specific language model.\n\t* @param callOptions Call options for the model\n\t* @returns A unique cache key.\n\t*/\n\t_getSerializedCacheKeyParametersForCall({ config,...callOptions }) {\n\t\tconst params = {\n\t\t\t...this._identifyingParams(),\n\t\t\t...callOptions,\n\t\t\t_type: this._llmType(),\n\t\t\t_model: this._modelType()\n\t\t};\n\t\tconst filteredEntries = Object.entries(params).filter(([_, value]) => value !== void 0);\n\t\tconst serializedEntries = filteredEntries.map(([key, value]) => `${key}:${JSON.stringify(value)}`).sort().join(\",\");\n\t\treturn serializedEntries;\n\t}\n\t/**\n\t* @deprecated\n\t* Return a json-like object representing this LLM.\n\t*/\n\tserialize() {\n\t\treturn {\n\t\t\t...this._identifyingParams(),\n\t\t\t_type: this._llmType(),\n\t\t\t_model: this._modelType()\n\t\t};\n\t}\n\t/**\n\t* @deprecated\n\t* Load an LLM from a json-like object describing it.\n\t*/\n\tstatic async deserialize(_data) {\n\t\tthrow new Error(\"Use .toJSON() instead\");\n\t}\n};\n\n//#endregion\nexport { BaseLangChain, BaseLanguageModel, base_exports, calculateMaxTokens, getEmbeddingContextSize, getModelContextSize, getModelNameForTiktoken, isOpenAITool };\n//# sourceMappingURL=base.js.map","import { ensureConfig } from \"./config.js\";\nimport { concat } from \"../utils/stream.js\";\nimport { Runnable, RunnableAssign, RunnableMap } from \"./base.js\";\n\n//#region src/runnables/passthrough.ts\n/**\n* A runnable to passthrough inputs unchanged or with additional keys.\n*\n* This runnable behaves almost like the identity function, except that it\n* can be configured to add additional keys to the output, if the input is\n* an object.\n*\n* The example below demonstrates how to use `RunnablePassthrough to\n* passthrough the input from the `.invoke()`\n*\n* @example\n* ```typescript\n* const chain = RunnableSequence.from([\n*   {\n*     question: new RunnablePassthrough(),\n*     context: async () => loadContextFromStore(),\n*   },\n*   prompt,\n*   llm,\n*   outputParser,\n* ]);\n* const response = await chain.invoke(\n*   \"I can pass a single string instead of an object since I'm using `RunnablePassthrough`.\"\n* );\n* ```\n*/\nvar RunnablePassthrough = class extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnablePassthrough\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\tfunc;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tif (fields) this.func = fields.func;\n\t}\n\tasync invoke(input, options) {\n\t\tconst config = ensureConfig(options);\n\t\tif (this.func) await this.func(input, config);\n\t\treturn this._callWithConfig((input$1) => Promise.resolve(input$1), input, config);\n\t}\n\tasync *transform(generator, options) {\n\t\tconst config = ensureConfig(options);\n\t\tlet finalOutput;\n\t\tlet finalOutputSupported = true;\n\t\tfor await (const chunk of this._transformStreamWithConfig(generator, (input) => input, config)) {\n\t\t\tyield chunk;\n\t\t\tif (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;\n\t\t\telse try {\n\t\t\t\tfinalOutput = concat(finalOutput, chunk);\n\t\t\t} catch {\n\t\t\t\tfinalOutput = void 0;\n\t\t\t\tfinalOutputSupported = false;\n\t\t\t}\n\t\t}\n\t\tif (this.func && finalOutput !== void 0) await this.func(finalOutput, config);\n\t}\n\t/**\n\t* A runnable that assigns key-value pairs to the input.\n\t*\n\t* The example below shows how you could use it with an inline function.\n\t*\n\t* @example\n\t* ```typescript\n\t* const prompt =\n\t*   PromptTemplate.fromTemplate(`Write a SQL query to answer the question using the following schema: {schema}\n\t* Question: {question}\n\t* SQL Query:`);\n\t*\n\t* // The `RunnablePassthrough.assign()` is used here to passthrough the input from the `.invoke()`\n\t* // call (in this example it's the question), along with any inputs passed to the `.assign()` method.\n\t* // In this case, we're passing the schema.\n\t* const sqlQueryGeneratorChain = RunnableSequence.from([\n\t*   RunnablePassthrough.assign({\n\t*     schema: async () => db.getTableInfo(),\n\t*   }),\n\t*   prompt,\n\t*   new ChatOpenAI({ model: \"gpt-4o-mini\" }).withConfig({ stop: [\"\\nSQLResult:\"] }),\n\t*   new StringOutputParser(),\n\t* ]);\n\t* const result = await sqlQueryGeneratorChain.invoke({\n\t*   question: \"How many employees are there?\",\n\t* });\n\t* ```\n\t*/\n\tstatic assign(mapping) {\n\t\treturn new RunnableAssign(new RunnableMap({ steps: mapping }));\n\t}\n};\n\n//#endregion\nexport { RunnablePassthrough };\n//# sourceMappingURL=passthrough.js.map","//#region src/language_models/utils.ts\nconst iife = (fn) => fn();\nfunction castStandardMessageContent(message) {\n\tconst Cls = message.constructor;\n\treturn new Cls({\n\t\t...message,\n\t\tcontent: message.contentBlocks,\n\t\tresponse_metadata: {\n\t\t\t...message.response_metadata,\n\t\t\toutput_version: \"v1\"\n\t\t}\n\t});\n}\n\n//#endregion\nexport { castStandardMessageContent, iife };\n//# sourceMappingURL=utils.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { convertToOpenAIImageBlock, isBase64ContentBlock, isURLContentBlock } from \"../messages/content/data.js\";\nimport { isBaseMessage } from \"../messages/base.js\";\nimport { AIMessage, AIMessageChunk, isAIMessage, isAIMessageChunk } from \"../messages/ai.js\";\nimport { coerceMessageLikeToMessage } from \"../messages/utils.js\";\nimport { getEnvironmentVariable } from \"../utils/env.js\";\nimport { callbackHandlerPrefersStreaming } from \"../callbacks/base.js\";\nimport { CallbackManager } from \"../callbacks/manager.js\";\nimport { concat } from \"../utils/stream.js\";\nimport { RUN_KEY } from \"../outputs.js\";\nimport { getSchemaDescription, isInteropZodSchema } from \"../utils/types/zod.js\";\nimport { toJsonSchema } from \"../utils/json_schema.js\";\nimport { RunnableLambda, RunnableSequence } from \"../runnables/base.js\";\nimport \"../messages/index.js\";\nimport { BaseLanguageModel } from \"./base.js\";\nimport { RunnablePassthrough } from \"../runnables/passthrough.js\";\nimport { castStandardMessageContent, iife } from \"./utils.js\";\n\n//#region src/language_models/chat_models.ts\nvar chat_models_exports = {};\n__export(chat_models_exports, {\n\tBaseChatModel: () => BaseChatModel,\n\tSimpleChatModel: () => SimpleChatModel\n});\nfunction _formatForTracing(messages) {\n\tconst messagesToTrace = [];\n\tfor (const message of messages) {\n\t\tlet messageToTrace = message;\n\t\tif (Array.isArray(message.content)) for (let idx = 0; idx < message.content.length; idx++) {\n\t\t\tconst block = message.content[idx];\n\t\t\tif (isURLContentBlock(block) || isBase64ContentBlock(block)) {\n\t\t\t\tif (messageToTrace === message) messageToTrace = new message.constructor({\n\t\t\t\t\t...messageToTrace,\n\t\t\t\t\tcontent: [\n\t\t\t\t\t\t...message.content.slice(0, idx),\n\t\t\t\t\t\tconvertToOpenAIImageBlock(block),\n\t\t\t\t\t\t...message.content.slice(idx + 1)\n\t\t\t\t\t]\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\tmessagesToTrace.push(messageToTrace);\n\t}\n\treturn messagesToTrace;\n}\n/**\n* Base class for chat models. It extends the BaseLanguageModel class and\n* provides methods for generating chat based on input messages.\n*/\nvar BaseChatModel = class BaseChatModel extends BaseLanguageModel {\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"chat_models\",\n\t\tthis._llmType()\n\t];\n\tdisableStreaming = false;\n\toutputVersion;\n\tget callKeys() {\n\t\treturn [...super.callKeys, \"outputVersion\"];\n\t}\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.outputVersion = iife(() => {\n\t\t\tconst outputVersion = fields.outputVersion ?? getEnvironmentVariable(\"LC_OUTPUT_VERSION\");\n\t\t\tif (outputVersion && [\"v0\", \"v1\"].includes(outputVersion)) return outputVersion;\n\t\t\treturn \"v0\";\n\t\t});\n\t}\n\t_separateRunnableConfigFromCallOptionsCompat(options) {\n\t\tconst [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);\n\t\tcallOptions.signal = runnableConfig.signal;\n\t\treturn [runnableConfig, callOptions];\n\t}\n\t/**\n\t* Invokes the chat model with a single input.\n\t* @param input The input for the language model.\n\t* @param options The call options.\n\t* @returns A Promise that resolves to a BaseMessageChunk.\n\t*/\n\tasync invoke(input, options) {\n\t\tconst promptValue = BaseChatModel._convertInputToPromptValue(input);\n\t\tconst result = await this.generatePrompt([promptValue], options, options?.callbacks);\n\t\tconst chatGeneration = result.generations[0][0];\n\t\treturn chatGeneration.message;\n\t}\n\tasync *_streamResponseChunks(_messages, _options, _runManager) {\n\t\tthrow new Error(\"Not implemented.\");\n\t}\n\tasync *_streamIterator(input, options) {\n\t\tif (this._streamResponseChunks === BaseChatModel.prototype._streamResponseChunks || this.disableStreaming) yield this.invoke(input, options);\n\t\telse {\n\t\t\tconst prompt = BaseChatModel._convertInputToPromptValue(input);\n\t\t\tconst messages = prompt.toChatMessages();\n\t\t\tconst [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);\n\t\t\tconst inheritableMetadata = {\n\t\t\t\t...runnableConfig.metadata,\n\t\t\t\t...this.getLsParams(callOptions)\n\t\t\t};\n\t\t\tconst callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });\n\t\t\tconst extra = {\n\t\t\t\toptions: callOptions,\n\t\t\t\tinvocation_params: this?.invocationParams(callOptions),\n\t\t\t\tbatch_size: 1\n\t\t\t};\n\t\t\tconst outputVersion = callOptions.outputVersion ?? this.outputVersion;\n\t\t\tconst runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), [_formatForTracing(messages)], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);\n\t\t\tlet generationChunk;\n\t\t\tlet llmOutput;\n\t\t\ttry {\n\t\t\t\tfor await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers?.[0])) {\n\t\t\t\t\tif (chunk.message.id == null) {\n\t\t\t\t\t\tconst runId = runManagers?.at(0)?.runId;\n\t\t\t\t\t\tif (runId != null) chunk.message._updateId(`run-${runId}`);\n\t\t\t\t\t}\n\t\t\t\t\tchunk.message.response_metadata = {\n\t\t\t\t\t\t...chunk.generationInfo,\n\t\t\t\t\t\t...chunk.message.response_metadata\n\t\t\t\t\t};\n\t\t\t\t\tif (outputVersion === \"v1\") yield castStandardMessageContent(chunk.message);\n\t\t\t\t\telse yield chunk.message;\n\t\t\t\t\tif (!generationChunk) generationChunk = chunk;\n\t\t\t\t\telse generationChunk = generationChunk.concat(chunk);\n\t\t\t\t\tif (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {\n\t\t\t\t\t\tpromptTokens: chunk.message.usage_metadata.input_tokens,\n\t\t\t\t\t\tcompletionTokens: chunk.message.usage_metadata.output_tokens,\n\t\t\t\t\t\ttotalTokens: chunk.message.usage_metadata.total_tokens\n\t\t\t\t\t} };\n\t\t\t\t}\n\t\t\t} catch (err) {\n\t\t\t\tawait Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));\n\t\t\t\tthrow err;\n\t\t\t}\n\t\t\tawait Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({\n\t\t\t\tgenerations: [[generationChunk]],\n\t\t\t\tllmOutput\n\t\t\t})));\n\t\t}\n\t}\n\tgetLsParams(options) {\n\t\tconst providerName = this.getName().startsWith(\"Chat\") ? this.getName().replace(\"Chat\", \"\") : this.getName();\n\t\treturn {\n\t\t\tls_model_type: \"chat\",\n\t\t\tls_stop: options.stop,\n\t\t\tls_provider: providerName\n\t\t};\n\t}\n\t/** @ignore */\n\tasync _generateUncached(messages, parsedOptions, handledOptions, startedRunManagers) {\n\t\tconst baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));\n\t\tlet runManagers;\n\t\tif (startedRunManagers !== void 0 && startedRunManagers.length === baseMessages.length) runManagers = startedRunManagers;\n\t\telse {\n\t\t\tconst inheritableMetadata = {\n\t\t\t\t...handledOptions.metadata,\n\t\t\t\t...this.getLsParams(parsedOptions)\n\t\t\t};\n\t\t\tconst callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });\n\t\t\tconst extra = {\n\t\t\t\toptions: parsedOptions,\n\t\t\t\tinvocation_params: this?.invocationParams(parsedOptions),\n\t\t\t\tbatch_size: 1\n\t\t\t};\n\t\t\trunManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);\n\t\t}\n\t\tconst outputVersion = parsedOptions.outputVersion ?? this.outputVersion;\n\t\tconst generations = [];\n\t\tconst llmOutputs = [];\n\t\tconst hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);\n\t\tif (hasStreamingHandler && !this.disableStreaming && baseMessages.length === 1 && this._streamResponseChunks !== BaseChatModel.prototype._streamResponseChunks) try {\n\t\t\tconst stream = await this._streamResponseChunks(baseMessages[0], parsedOptions, runManagers?.[0]);\n\t\t\tlet aggregated;\n\t\t\tlet llmOutput;\n\t\t\tfor await (const chunk of stream) {\n\t\t\t\tif (chunk.message.id == null) {\n\t\t\t\t\tconst runId = runManagers?.at(0)?.runId;\n\t\t\t\t\tif (runId != null) chunk.message._updateId(`run-${runId}`);\n\t\t\t\t}\n\t\t\t\tif (aggregated === void 0) aggregated = chunk;\n\t\t\t\telse aggregated = concat(aggregated, chunk);\n\t\t\t\tif (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {\n\t\t\t\t\tpromptTokens: chunk.message.usage_metadata.input_tokens,\n\t\t\t\t\tcompletionTokens: chunk.message.usage_metadata.output_tokens,\n\t\t\t\t\ttotalTokens: chunk.message.usage_metadata.total_tokens\n\t\t\t\t} };\n\t\t\t}\n\t\t\tif (aggregated === void 0) throw new Error(\"Received empty response from chat model call.\");\n\t\t\tgenerations.push([aggregated]);\n\t\t\tawait runManagers?.[0].handleLLMEnd({\n\t\t\t\tgenerations,\n\t\t\t\tllmOutput\n\t\t\t});\n\t\t} catch (e) {\n\t\t\tawait runManagers?.[0].handleLLMError(e);\n\t\t\tthrow e;\n\t\t}\n\t\telse {\n\t\t\tconst results = await Promise.allSettled(baseMessages.map(async (messageList, i) => {\n\t\t\t\tconst generateResults = await this._generate(messageList, {\n\t\t\t\t\t...parsedOptions,\n\t\t\t\t\tpromptIndex: i\n\t\t\t\t}, runManagers?.[i]);\n\t\t\t\tif (outputVersion === \"v1\") for (const generation of generateResults.generations) generation.message = castStandardMessageContent(generation.message);\n\t\t\t\treturn generateResults;\n\t\t\t}));\n\t\t\tawait Promise.all(results.map(async (pResult, i) => {\n\t\t\t\tif (pResult.status === \"fulfilled\") {\n\t\t\t\t\tconst result = pResult.value;\n\t\t\t\t\tfor (const generation of result.generations) {\n\t\t\t\t\t\tif (generation.message.id == null) {\n\t\t\t\t\t\t\tconst runId = runManagers?.at(0)?.runId;\n\t\t\t\t\t\t\tif (runId != null) generation.message._updateId(`run-${runId}`);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tgeneration.message.response_metadata = {\n\t\t\t\t\t\t\t...generation.generationInfo,\n\t\t\t\t\t\t\t...generation.message.response_metadata\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\t\t\t\t\tif (result.generations.length === 1) result.generations[0].message.response_metadata = {\n\t\t\t\t\t\t...result.llmOutput,\n\t\t\t\t\t\t...result.generations[0].message.response_metadata\n\t\t\t\t\t};\n\t\t\t\t\tgenerations[i] = result.generations;\n\t\t\t\t\tllmOutputs[i] = result.llmOutput;\n\t\t\t\t\treturn runManagers?.[i]?.handleLLMEnd({\n\t\t\t\t\t\tgenerations: [result.generations],\n\t\t\t\t\t\tllmOutput: result.llmOutput\n\t\t\t\t\t});\n\t\t\t\t} else {\n\t\t\t\t\tawait runManagers?.[i]?.handleLLMError(pResult.reason);\n\t\t\t\t\treturn Promise.reject(pResult.reason);\n\t\t\t\t}\n\t\t\t}));\n\t\t}\n\t\tconst output = {\n\t\t\tgenerations,\n\t\t\tllmOutput: llmOutputs.length ? this._combineLLMOutput?.(...llmOutputs) : void 0\n\t\t};\n\t\tObject.defineProperty(output, RUN_KEY, {\n\t\t\tvalue: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,\n\t\t\tconfigurable: true\n\t\t});\n\t\treturn output;\n\t}\n\tasync _generateCached({ messages, cache, llmStringKey, parsedOptions, handledOptions }) {\n\t\tconst baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));\n\t\tconst inheritableMetadata = {\n\t\t\t...handledOptions.metadata,\n\t\t\t...this.getLsParams(parsedOptions)\n\t\t};\n\t\tconst callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });\n\t\tconst extra = {\n\t\t\toptions: parsedOptions,\n\t\t\tinvocation_params: this?.invocationParams(parsedOptions),\n\t\t\tbatch_size: 1\n\t\t};\n\t\tconst runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);\n\t\tconst missingPromptIndices = [];\n\t\tconst results = await Promise.allSettled(baseMessages.map(async (baseMessage, index) => {\n\t\t\tconst prompt = BaseChatModel._convertInputToPromptValue(baseMessage).toString();\n\t\t\tconst result = await cache.lookup(prompt, llmStringKey);\n\t\t\tif (result == null) missingPromptIndices.push(index);\n\t\t\treturn result;\n\t\t}));\n\t\tconst cachedResults = results.map((result, index) => ({\n\t\t\tresult,\n\t\t\trunManager: runManagers?.[index]\n\t\t})).filter(({ result }) => result.status === \"fulfilled\" && result.value != null || result.status === \"rejected\");\n\t\tconst outputVersion = parsedOptions.outputVersion ?? this.outputVersion;\n\t\tconst generations = [];\n\t\tawait Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {\n\t\t\tif (promiseResult.status === \"fulfilled\") {\n\t\t\t\tconst result = promiseResult.value;\n\t\t\t\tgenerations[i] = result.map((result$1) => {\n\t\t\t\t\tif (\"message\" in result$1 && isBaseMessage(result$1.message) && isAIMessage(result$1.message)) {\n\t\t\t\t\t\tresult$1.message.usage_metadata = {\n\t\t\t\t\t\t\tinput_tokens: 0,\n\t\t\t\t\t\t\toutput_tokens: 0,\n\t\t\t\t\t\t\ttotal_tokens: 0\n\t\t\t\t\t\t};\n\t\t\t\t\t\tif (outputVersion === \"v1\") result$1.message = castStandardMessageContent(result$1.message);\n\t\t\t\t\t}\n\t\t\t\t\tresult$1.generationInfo = {\n\t\t\t\t\t\t...result$1.generationInfo,\n\t\t\t\t\t\ttokenUsage: {}\n\t\t\t\t\t};\n\t\t\t\t\treturn result$1;\n\t\t\t\t});\n\t\t\t\tif (result.length) await runManager?.handleLLMNewToken(result[0].text);\n\t\t\t\treturn runManager?.handleLLMEnd({ generations: [result] }, void 0, void 0, void 0, { cached: true });\n\t\t\t} else {\n\t\t\t\tawait runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, { cached: true });\n\t\t\t\treturn Promise.reject(promiseResult.reason);\n\t\t\t}\n\t\t}));\n\t\tconst output = {\n\t\t\tgenerations,\n\t\t\tmissingPromptIndices,\n\t\t\tstartedRunManagers: runManagers\n\t\t};\n\t\tObject.defineProperty(output, RUN_KEY, {\n\t\t\tvalue: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,\n\t\t\tconfigurable: true\n\t\t});\n\t\treturn output;\n\t}\n\t/**\n\t* Generates chat based on the input messages.\n\t* @param messages An array of arrays of BaseMessage instances.\n\t* @param options The call options or an array of stop sequences.\n\t* @param callbacks The callbacks for the language model.\n\t* @returns A Promise that resolves to an LLMResult.\n\t*/\n\tasync generate(messages, options, callbacks) {\n\t\tlet parsedOptions;\n\t\tif (Array.isArray(options)) parsedOptions = { stop: options };\n\t\telse parsedOptions = options;\n\t\tconst baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));\n\t\tconst [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);\n\t\trunnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;\n\t\tif (!this.cache) return this._generateUncached(baseMessages, callOptions, runnableConfig);\n\t\tconst { cache } = this;\n\t\tconst llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);\n\t\tconst { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({\n\t\t\tmessages: baseMessages,\n\t\t\tcache,\n\t\t\tllmStringKey,\n\t\t\tparsedOptions: callOptions,\n\t\t\thandledOptions: runnableConfig\n\t\t});\n\t\tlet llmOutput = {};\n\t\tif (missingPromptIndices.length > 0) {\n\t\t\tconst results = await this._generateUncached(missingPromptIndices.map((i) => baseMessages[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers?.[i]) : void 0);\n\t\t\tawait Promise.all(results.generations.map(async (generation, index) => {\n\t\t\t\tconst promptIndex = missingPromptIndices[index];\n\t\t\t\tgenerations[promptIndex] = generation;\n\t\t\t\tconst prompt = BaseChatModel._convertInputToPromptValue(baseMessages[promptIndex]).toString();\n\t\t\t\treturn cache.update(prompt, llmStringKey, generation);\n\t\t\t}));\n\t\t\tllmOutput = results.llmOutput ?? {};\n\t\t}\n\t\treturn {\n\t\t\tgenerations,\n\t\t\tllmOutput\n\t\t};\n\t}\n\t/**\n\t* Get the parameters used to invoke the model\n\t*/\n\tinvocationParams(_options) {\n\t\treturn {};\n\t}\n\t_modelType() {\n\t\treturn \"base_chat_model\";\n\t}\n\t/**\n\t* Generates a prompt based on the input prompt values.\n\t* @param promptValues An array of BasePromptValue instances.\n\t* @param options The call options or an array of stop sequences.\n\t* @param callbacks The callbacks for the language model.\n\t* @returns A Promise that resolves to an LLMResult.\n\t*/\n\tasync generatePrompt(promptValues, options, callbacks) {\n\t\tconst promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());\n\t\treturn this.generate(promptMessages, options, callbacks);\n\t}\n\twithStructuredOutput(outputSchema, config) {\n\t\tif (typeof this.bindTools !== \"function\") throw new Error(`Chat model must implement \".bindTools()\" to use withStructuredOutput.`);\n\t\tif (config?.strict) throw new Error(`\"strict\" mode is not supported for this model by default.`);\n\t\tconst schema = outputSchema;\n\t\tconst name = config?.name;\n\t\tconst description = getSchemaDescription(schema) ?? \"A function available to call.\";\n\t\tconst method = config?.method;\n\t\tconst includeRaw = config?.includeRaw;\n\t\tif (method === \"jsonMode\") throw new Error(`Base withStructuredOutput implementation only supports \"functionCalling\" as a method.`);\n\t\tlet functionName = name ?? \"extract\";\n\t\tlet tools;\n\t\tif (isInteropZodSchema(schema)) tools = [{\n\t\t\ttype: \"function\",\n\t\t\tfunction: {\n\t\t\t\tname: functionName,\n\t\t\t\tdescription,\n\t\t\t\tparameters: toJsonSchema(schema)\n\t\t\t}\n\t\t}];\n\t\telse {\n\t\t\tif (\"name\" in schema) functionName = schema.name;\n\t\t\ttools = [{\n\t\t\t\ttype: \"function\",\n\t\t\t\tfunction: {\n\t\t\t\t\tname: functionName,\n\t\t\t\t\tdescription,\n\t\t\t\t\tparameters: schema\n\t\t\t\t}\n\t\t\t}];\n\t\t}\n\t\tconst llm = this.bindTools(tools);\n\t\tconst outputParser = RunnableLambda.from((input) => {\n\t\t\tif (!AIMessageChunk.isInstance(input)) throw new Error(\"Input is not an AIMessageChunk.\");\n\t\t\tif (!input.tool_calls || input.tool_calls.length === 0) throw new Error(\"No tool calls found in the response.\");\n\t\t\tconst toolCall = input.tool_calls.find((tc) => tc.name === functionName);\n\t\t\tif (!toolCall) throw new Error(`No tool call found with name ${functionName}.`);\n\t\t\treturn toolCall.args;\n\t\t});\n\t\tif (!includeRaw) return llm.pipe(outputParser).withConfig({ runName: \"StructuredOutput\" });\n\t\tconst parserAssign = RunnablePassthrough.assign({ parsed: (input, config$1) => outputParser.invoke(input.raw, config$1) });\n\t\tconst parserNone = RunnablePassthrough.assign({ parsed: () => null });\n\t\tconst parsedWithFallback = parserAssign.withFallbacks({ fallbacks: [parserNone] });\n\t\treturn RunnableSequence.from([{ raw: llm }, parsedWithFallback]).withConfig({ runName: \"StructuredOutputRunnable\" });\n\t}\n};\n/**\n* An abstract class that extends BaseChatModel and provides a simple\n* implementation of _generate.\n*/\nvar SimpleChatModel = class extends BaseChatModel {\n\tasync _generate(messages, options, runManager) {\n\t\tconst text = await this._call(messages, options, runManager);\n\t\tconst message = new AIMessage(text);\n\t\tif (typeof message.content !== \"string\") throw new Error(\"Cannot generate with a simple chat model when output is not a string.\");\n\t\treturn { generations: [{\n\t\t\ttext: message.content,\n\t\t\tmessage\n\t\t}] };\n\t}\n};\n\n//#endregion\nexport { BaseChatModel, SimpleChatModel, chat_models_exports };\n//# sourceMappingURL=chat_models.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { callbackHandlerPrefersStreaming } from \"../callbacks/base.js\";\nimport { CallbackManager } from \"../callbacks/manager.js\";\nimport { concat } from \"../utils/stream.js\";\nimport { GenerationChunk, RUN_KEY } from \"../outputs.js\";\nimport { BaseLanguageModel } from \"./base.js\";\n\n//#region src/language_models/llms.ts\nvar llms_exports = {};\n__export(llms_exports, {\n\tBaseLLM: () => BaseLLM,\n\tLLM: () => LLM\n});\n/**\n* LLM Wrapper. Takes in a prompt (or prompts) and returns a string.\n*/\nvar BaseLLM = class BaseLLM extends BaseLanguageModel {\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"llms\",\n\t\tthis._llmType()\n\t];\n\t/**\n\t* This method takes an input and options, and returns a string. It\n\t* converts the input to a prompt value and generates a result based on\n\t* the prompt.\n\t* @param input Input for the LLM.\n\t* @param options Options for the LLM call.\n\t* @returns A string result based on the prompt.\n\t*/\n\tasync invoke(input, options) {\n\t\tconst promptValue = BaseLLM._convertInputToPromptValue(input);\n\t\tconst result = await this.generatePrompt([promptValue], options, options?.callbacks);\n\t\treturn result.generations[0][0].text;\n\t}\n\tasync *_streamResponseChunks(_input, _options, _runManager) {\n\t\tthrow new Error(\"Not implemented.\");\n\t}\n\t_separateRunnableConfigFromCallOptionsCompat(options) {\n\t\tconst [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);\n\t\tcallOptions.signal = runnableConfig.signal;\n\t\treturn [runnableConfig, callOptions];\n\t}\n\tasync *_streamIterator(input, options) {\n\t\tif (this._streamResponseChunks === BaseLLM.prototype._streamResponseChunks) yield this.invoke(input, options);\n\t\telse {\n\t\t\tconst prompt = BaseLLM._convertInputToPromptValue(input);\n\t\t\tconst [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);\n\t\t\tconst callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, { verbose: this.verbose });\n\t\t\tconst extra = {\n\t\t\t\toptions: callOptions,\n\t\t\t\tinvocation_params: this?.invocationParams(callOptions),\n\t\t\t\tbatch_size: 1\n\t\t\t};\n\t\t\tconst runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), [prompt.toString()], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);\n\t\t\tlet generation = new GenerationChunk({ text: \"\" });\n\t\t\ttry {\n\t\t\t\tfor await (const chunk of this._streamResponseChunks(prompt.toString(), callOptions, runManagers?.[0])) {\n\t\t\t\t\tif (!generation) generation = chunk;\n\t\t\t\t\telse generation = generation.concat(chunk);\n\t\t\t\t\tif (typeof chunk.text === \"string\") yield chunk.text;\n\t\t\t\t}\n\t\t\t} catch (err) {\n\t\t\t\tawait Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));\n\t\t\t\tthrow err;\n\t\t\t}\n\t\t\tawait Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({ generations: [[generation]] })));\n\t\t}\n\t}\n\t/**\n\t* This method takes prompt values, options, and callbacks, and generates\n\t* a result based on the prompts.\n\t* @param promptValues Prompt values for the LLM.\n\t* @param options Options for the LLM call.\n\t* @param callbacks Callbacks for the LLM call.\n\t* @returns An LLMResult based on the prompts.\n\t*/\n\tasync generatePrompt(promptValues, options, callbacks) {\n\t\tconst prompts = promptValues.map((promptValue) => promptValue.toString());\n\t\treturn this.generate(prompts, options, callbacks);\n\t}\n\t/**\n\t* Get the parameters used to invoke the model\n\t*/\n\tinvocationParams(_options) {\n\t\treturn {};\n\t}\n\t_flattenLLMResult(llmResult) {\n\t\tconst llmResults = [];\n\t\tfor (let i = 0; i < llmResult.generations.length; i += 1) {\n\t\t\tconst genList = llmResult.generations[i];\n\t\t\tif (i === 0) llmResults.push({\n\t\t\t\tgenerations: [genList],\n\t\t\t\tllmOutput: llmResult.llmOutput\n\t\t\t});\n\t\t\telse {\n\t\t\t\tconst llmOutput = llmResult.llmOutput ? {\n\t\t\t\t\t...llmResult.llmOutput,\n\t\t\t\t\ttokenUsage: {}\n\t\t\t\t} : void 0;\n\t\t\t\tllmResults.push({\n\t\t\t\t\tgenerations: [genList],\n\t\t\t\t\tllmOutput\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn llmResults;\n\t}\n\t/** @ignore */\n\tasync _generateUncached(prompts, parsedOptions, handledOptions, startedRunManagers) {\n\t\tlet runManagers;\n\t\tif (startedRunManagers !== void 0 && startedRunManagers.length === prompts.length) runManagers = startedRunManagers;\n\t\telse {\n\t\t\tconst callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });\n\t\t\tconst extra = {\n\t\t\t\toptions: parsedOptions,\n\t\t\t\tinvocation_params: this?.invocationParams(parsedOptions),\n\t\t\t\tbatch_size: prompts.length\n\t\t\t};\n\t\t\trunManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, handledOptions.runId, void 0, extra, void 0, void 0, handledOptions?.runName);\n\t\t}\n\t\tconst hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);\n\t\tlet output;\n\t\tif (hasStreamingHandler && prompts.length === 1 && this._streamResponseChunks !== BaseLLM.prototype._streamResponseChunks) try {\n\t\t\tconst stream = await this._streamResponseChunks(prompts[0], parsedOptions, runManagers?.[0]);\n\t\t\tlet aggregated;\n\t\t\tfor await (const chunk of stream) if (aggregated === void 0) aggregated = chunk;\n\t\t\telse aggregated = concat(aggregated, chunk);\n\t\t\tif (aggregated === void 0) throw new Error(\"Received empty response from chat model call.\");\n\t\t\toutput = {\n\t\t\t\tgenerations: [[aggregated]],\n\t\t\t\tllmOutput: {}\n\t\t\t};\n\t\t\tawait runManagers?.[0].handleLLMEnd(output);\n\t\t} catch (e) {\n\t\t\tawait runManagers?.[0].handleLLMError(e);\n\t\t\tthrow e;\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\toutput = await this._generate(prompts, parsedOptions, runManagers?.[0]);\n\t\t\t} catch (err) {\n\t\t\t\tawait Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));\n\t\t\t\tthrow err;\n\t\t\t}\n\t\t\tconst flattenedOutputs = this._flattenLLMResult(output);\n\t\t\tawait Promise.all((runManagers ?? []).map((runManager, i) => runManager?.handleLLMEnd(flattenedOutputs[i])));\n\t\t}\n\t\tconst runIds = runManagers?.map((manager) => manager.runId) || void 0;\n\t\tObject.defineProperty(output, RUN_KEY, {\n\t\t\tvalue: runIds ? { runIds } : void 0,\n\t\t\tconfigurable: true\n\t\t});\n\t\treturn output;\n\t}\n\tasync _generateCached({ prompts, cache, llmStringKey, parsedOptions, handledOptions, runId }) {\n\t\tconst callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });\n\t\tconst extra = {\n\t\t\toptions: parsedOptions,\n\t\t\tinvocation_params: this?.invocationParams(parsedOptions),\n\t\t\tbatch_size: prompts.length\n\t\t};\n\t\tconst runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, runId, void 0, extra, void 0, void 0, handledOptions?.runName);\n\t\tconst missingPromptIndices = [];\n\t\tconst results = await Promise.allSettled(prompts.map(async (prompt, index) => {\n\t\t\tconst result = await cache.lookup(prompt, llmStringKey);\n\t\t\tif (result == null) missingPromptIndices.push(index);\n\t\t\treturn result;\n\t\t}));\n\t\tconst cachedResults = results.map((result, index) => ({\n\t\t\tresult,\n\t\t\trunManager: runManagers?.[index]\n\t\t})).filter(({ result }) => result.status === \"fulfilled\" && result.value != null || result.status === \"rejected\");\n\t\tconst generations = [];\n\t\tawait Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {\n\t\t\tif (promiseResult.status === \"fulfilled\") {\n\t\t\t\tconst result = promiseResult.value;\n\t\t\t\tgenerations[i] = result.map((result$1) => {\n\t\t\t\t\tresult$1.generationInfo = {\n\t\t\t\t\t\t...result$1.generationInfo,\n\t\t\t\t\t\ttokenUsage: {}\n\t\t\t\t\t};\n\t\t\t\t\treturn result$1;\n\t\t\t\t});\n\t\t\t\tif (result.length) await runManager?.handleLLMNewToken(result[0].text);\n\t\t\t\treturn runManager?.handleLLMEnd({ generations: [result] }, void 0, void 0, void 0, { cached: true });\n\t\t\t} else {\n\t\t\t\tawait runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, { cached: true });\n\t\t\t\treturn Promise.reject(promiseResult.reason);\n\t\t\t}\n\t\t}));\n\t\tconst output = {\n\t\t\tgenerations,\n\t\t\tmissingPromptIndices,\n\t\t\tstartedRunManagers: runManagers\n\t\t};\n\t\tObject.defineProperty(output, RUN_KEY, {\n\t\t\tvalue: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,\n\t\t\tconfigurable: true\n\t\t});\n\t\treturn output;\n\t}\n\t/**\n\t* Run the LLM on the given prompts and input, handling caching.\n\t*/\n\tasync generate(prompts, options, callbacks) {\n\t\tif (!Array.isArray(prompts)) throw new Error(\"Argument 'prompts' is expected to be a string[]\");\n\t\tlet parsedOptions;\n\t\tif (Array.isArray(options)) parsedOptions = { stop: options };\n\t\telse parsedOptions = options;\n\t\tconst [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);\n\t\trunnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;\n\t\tif (!this.cache) return this._generateUncached(prompts, callOptions, runnableConfig);\n\t\tconst { cache } = this;\n\t\tconst llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);\n\t\tconst { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({\n\t\t\tprompts,\n\t\t\tcache,\n\t\t\tllmStringKey,\n\t\t\tparsedOptions: callOptions,\n\t\t\thandledOptions: runnableConfig,\n\t\t\trunId: runnableConfig.runId\n\t\t});\n\t\tlet llmOutput = {};\n\t\tif (missingPromptIndices.length > 0) {\n\t\t\tconst results = await this._generateUncached(missingPromptIndices.map((i) => prompts[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers?.[i]) : void 0);\n\t\t\tawait Promise.all(results.generations.map(async (generation, index) => {\n\t\t\t\tconst promptIndex = missingPromptIndices[index];\n\t\t\t\tgenerations[promptIndex] = generation;\n\t\t\t\treturn cache.update(prompts[promptIndex], llmStringKey, generation);\n\t\t\t}));\n\t\t\tllmOutput = results.llmOutput ?? {};\n\t\t}\n\t\treturn {\n\t\t\tgenerations,\n\t\t\tllmOutput\n\t\t};\n\t}\n\t/**\n\t* Get the identifying parameters of the LLM.\n\t*/\n\t_identifyingParams() {\n\t\treturn {};\n\t}\n\t_modelType() {\n\t\treturn \"base_llm\";\n\t}\n};\n/**\n* LLM class that provides a simpler interface to subclass than {@link BaseLLM}.\n*\n* Requires only implementing a simpler {@link _call} method instead of {@link _generate}.\n*\n* @augments BaseLLM\n*/\nvar LLM = class extends BaseLLM {\n\tasync _generate(prompts, options, runManager) {\n\t\tconst generations = await Promise.all(prompts.map((prompt, promptIndex) => this._call(prompt, {\n\t\t\t...options,\n\t\t\tpromptIndex\n\t\t}, runManager).then((text) => [{ text }])));\n\t\treturn { generations };\n\t}\n};\n\n//#endregion\nexport { BaseLLM, LLM, llms_exports };\n//# sourceMappingURL=llms.js.map","import { ensureConfig } from \"./config.js\";\nimport { Runnable } from \"./base.js\";\n\n//#region src/runnables/router.ts\n/**\n* A runnable that routes to a set of runnables based on Input['key'].\n* Returns the output of the selected runnable.\n* @example\n* ```typescript\n* import { RouterRunnable, RunnableLambda } from \"@langchain/core/runnables\";\n*\n* const router = new RouterRunnable({\n*   runnables: {\n*     toUpperCase: RunnableLambda.from((text: string) => text.toUpperCase()),\n*     reverseText: RunnableLambda.from((text: string) =>\n*       text.split(\"\").reverse().join(\"\")\n*     ),\n*   },\n* });\n*\n* // Invoke the 'reverseText' runnable\n* const result1 = router.invoke({ key: \"reverseText\", input: \"Hello World\" });\n*\n* // \"dlroW olleH\"\n*\n* // Invoke the 'toUpperCase' runnable\n* const result2 = router.invoke({ key: \"toUpperCase\", input: \"Hello World\" });\n*\n* // \"HELLO WORLD\"\n* ```\n*/\nvar RouterRunnable = class extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RouterRunnable\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\trunnables;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.runnables = fields.runnables;\n\t}\n\tasync invoke(input, options) {\n\t\tconst { key, input: actualInput } = input;\n\t\tconst runnable = this.runnables[key];\n\t\tif (runnable === void 0) throw new Error(`No runnable associated with key \"${key}\".`);\n\t\treturn runnable.invoke(actualInput, ensureConfig(options));\n\t}\n\tasync batch(inputs, options, batchOptions) {\n\t\tconst keys = inputs.map((input) => input.key);\n\t\tconst actualInputs = inputs.map((input) => input.input);\n\t\tconst missingKey = keys.find((key) => this.runnables[key] === void 0);\n\t\tif (missingKey !== void 0) throw new Error(`One or more keys do not have a corresponding runnable.`);\n\t\tconst runnables = keys.map((key) => this.runnables[key]);\n\t\tconst optionsList = this._getOptionsList(options ?? {}, inputs.length);\n\t\tconst maxConcurrency = optionsList[0]?.maxConcurrency ?? batchOptions?.maxConcurrency;\n\t\tconst batchSize = maxConcurrency && maxConcurrency > 0 ? maxConcurrency : inputs.length;\n\t\tconst batchResults = [];\n\t\tfor (let i = 0; i < actualInputs.length; i += batchSize) {\n\t\t\tconst batchPromises = actualInputs.slice(i, i + batchSize).map((actualInput, i$1) => runnables[i$1].invoke(actualInput, optionsList[i$1]));\n\t\t\tconst batchResult = await Promise.all(batchPromises);\n\t\t\tbatchResults.push(batchResult);\n\t\t}\n\t\treturn batchResults.flat();\n\t}\n\tasync stream(input, options) {\n\t\tconst { key, input: actualInput } = input;\n\t\tconst runnable = this.runnables[key];\n\t\tif (runnable === void 0) throw new Error(`No runnable associated with key \"${key}\".`);\n\t\treturn runnable.stream(actualInput, options);\n\t}\n};\n\n//#endregion\nexport { RouterRunnable };\n//# sourceMappingURL=router.js.map","import { getCallbackManagerForConfig, patchConfig } from \"./config.js\";\nimport { concat } from \"../utils/stream.js\";\nimport { Runnable, _coerceToDict, _coerceToRunnable } from \"./base.js\";\n\n//#region src/runnables/branch.ts\n/**\n* Class that represents a runnable branch. The RunnableBranch is\n* initialized with an array of branches and a default branch. When invoked,\n* it evaluates the condition of each branch in order and executes the\n* corresponding branch if the condition is true. If none of the conditions\n* are true, it executes the default branch.\n* @example\n* ```typescript\n* const branch = RunnableBranch.from([\n*   [\n*     (x: { topic: string; question: string }) =>\n*       x.topic.toLowerCase().includes(\"anthropic\"),\n*     anthropicChain,\n*   ],\n*   [\n*     (x: { topic: string; question: string }) =>\n*       x.topic.toLowerCase().includes(\"langchain\"),\n*     langChainChain,\n*   ],\n*   generalChain,\n* ]);\n*\n* const fullChain = RunnableSequence.from([\n*   {\n*     topic: classificationChain,\n*     question: (input: { question: string }) => input.question,\n*   },\n*   branch,\n* ]);\n*\n* const result = await fullChain.invoke({\n*   question: \"how do I use LangChain?\",\n* });\n* ```\n*/\nvar RunnableBranch = class extends Runnable {\n\tstatic lc_name() {\n\t\treturn \"RunnableBranch\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"runnables\"];\n\tlc_serializable = true;\n\tdefault;\n\tbranches;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.branches = fields.branches;\n\t\tthis.default = fields.default;\n\t}\n\t/**\n\t* Convenience method for instantiating a RunnableBranch from\n\t* RunnableLikes (objects, functions, or Runnables).\n\t*\n\t* Each item in the input except for the last one should be a\n\t* tuple with two items. The first is a \"condition\" RunnableLike that\n\t* returns \"true\" if the second RunnableLike in the tuple should run.\n\t*\n\t* The final item in the input should be a RunnableLike that acts as a\n\t* default branch if no other branches match.\n\t*\n\t* @example\n\t* ```ts\n\t* import { RunnableBranch } from \"@langchain/core/runnables\";\n\t*\n\t* const branch = RunnableBranch.from([\n\t*   [(x: number) => x > 0, (x: number) => x + 1],\n\t*   [(x: number) => x < 0, (x: number) => x - 1],\n\t*   (x: number) => x\n\t* ]);\n\t* ```\n\t* @param branches An array where the every item except the last is a tuple of [condition, runnable]\n\t*   pairs. The last item is a default runnable which is invoked if no other condition matches.\n\t* @returns A new RunnableBranch.\n\t*/\n\tstatic from(branches) {\n\t\tif (branches.length < 1) throw new Error(\"RunnableBranch requires at least one branch\");\n\t\tconst branchLikes = branches.slice(0, -1);\n\t\tconst coercedBranches = branchLikes.map(([condition, runnable]) => [_coerceToRunnable(condition), _coerceToRunnable(runnable)]);\n\t\tconst defaultBranch = _coerceToRunnable(branches[branches.length - 1]);\n\t\treturn new this({\n\t\t\tbranches: coercedBranches,\n\t\t\tdefault: defaultBranch\n\t\t});\n\t}\n\tasync _invoke(input, config, runManager) {\n\t\tlet result;\n\t\tfor (let i = 0; i < this.branches.length; i += 1) {\n\t\t\tconst [condition, branchRunnable] = this.branches[i];\n\t\t\tconst conditionValue = await condition.invoke(input, patchConfig(config, { callbacks: runManager?.getChild(`condition:${i + 1}`) }));\n\t\t\tif (conditionValue) {\n\t\t\t\tresult = await branchRunnable.invoke(input, patchConfig(config, { callbacks: runManager?.getChild(`branch:${i + 1}`) }));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!result) result = await this.default.invoke(input, patchConfig(config, { callbacks: runManager?.getChild(\"branch:default\") }));\n\t\treturn result;\n\t}\n\tasync invoke(input, config = {}) {\n\t\treturn this._callWithConfig(this._invoke, input, config);\n\t}\n\tasync *_streamIterator(input, config) {\n\t\tconst callbackManager_ = await getCallbackManagerForConfig(config);\n\t\tconst runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, \"input\"), config?.runId, void 0, void 0, void 0, config?.runName);\n\t\tlet finalOutput;\n\t\tlet finalOutputSupported = true;\n\t\tlet stream;\n\t\ttry {\n\t\t\tfor (let i = 0; i < this.branches.length; i += 1) {\n\t\t\t\tconst [condition, branchRunnable] = this.branches[i];\n\t\t\t\tconst conditionValue = await condition.invoke(input, patchConfig(config, { callbacks: runManager?.getChild(`condition:${i + 1}`) }));\n\t\t\t\tif (conditionValue) {\n\t\t\t\t\tstream = await branchRunnable.stream(input, patchConfig(config, { callbacks: runManager?.getChild(`branch:${i + 1}`) }));\n\t\t\t\t\tfor await (const chunk of stream) {\n\t\t\t\t\t\tyield chunk;\n\t\t\t\t\t\tif (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;\n\t\t\t\t\t\telse try {\n\t\t\t\t\t\t\tfinalOutput = concat(finalOutput, chunk);\n\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\tfinalOutput = void 0;\n\t\t\t\t\t\t\tfinalOutputSupported = false;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (stream === void 0) {\n\t\t\t\tstream = await this.default.stream(input, patchConfig(config, { callbacks: runManager?.getChild(\"branch:default\") }));\n\t\t\t\tfor await (const chunk of stream) {\n\t\t\t\t\tyield chunk;\n\t\t\t\t\tif (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;\n\t\t\t\t\telse try {\n\t\t\t\t\t\tfinalOutput = concat(finalOutput, chunk);\n\t\t\t\t\t} catch {\n\t\t\t\t\t\tfinalOutput = void 0;\n\t\t\t\t\t\tfinalOutputSupported = false;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(e);\n\t\t\tthrow e;\n\t\t}\n\t\tawait runManager?.handleChainEnd(finalOutput ?? {});\n\t}\n};\n\n//#endregion\nexport { RunnableBranch };\n//# sourceMappingURL=branch.js.map","import { isBaseMessage } from \"../messages/base.js\";\nimport { AIMessage } from \"../messages/ai.js\";\nimport { HumanMessage } from \"../messages/human.js\";\nimport { RunnableBinding, RunnableLambda } from \"./base.js\";\nimport \"../messages/index.js\";\nimport { RunnablePassthrough } from \"./passthrough.js\";\n\n//#region src/runnables/history.ts\n/**\n* Wraps a LCEL chain and manages history. It appends input messages\n* and chain outputs as history, and adds the current history messages to\n* the chain input.\n* @example\n* ```typescript\n* // pnpm install @langchain/anthropic @langchain/community @upstash/redis\n*\n* import {\n*   ChatPromptTemplate,\n*   MessagesPlaceholder,\n* } from \"@langchain/core/prompts\";\n* import { ChatAnthropic } from \"@langchain/anthropic\";\n* import { UpstashRedisChatMessageHistory } from \"@langchain/community/stores/message/upstash_redis\";\n* // For demos, you can also use an in-memory store:\n* // import { ChatMessageHistory } from \"@langchain/classic/stores/message/in_memory\";\n*\n* const prompt = ChatPromptTemplate.fromMessages([\n*   [\"system\", \"You're an assistant who's good at {ability}\"],\n*   new MessagesPlaceholder(\"history\"),\n*   [\"human\", \"{question}\"],\n* ]);\n*\n* const chain = prompt.pipe(new ChatAnthropic({}));\n*\n* const chainWithHistory = new RunnableWithMessageHistory({\n*   runnable: chain,\n*   getMessageHistory: (sessionId) =>\n*     new UpstashRedisChatMessageHistory({\n*       sessionId,\n*       config: {\n*         url: process.env.UPSTASH_REDIS_REST_URL!,\n*         token: process.env.UPSTASH_REDIS_REST_TOKEN!,\n*       },\n*     }),\n*   inputMessagesKey: \"question\",\n*   historyMessagesKey: \"history\",\n* });\n*\n* const result = await chainWithHistory.invoke(\n*   {\n*     ability: \"math\",\n*     question: \"What does cosine mean?\",\n*   },\n*   {\n*     configurable: {\n*       sessionId: \"some_string_identifying_a_user\",\n*     },\n*   }\n* );\n*\n* const result2 = await chainWithHistory.invoke(\n*   {\n*     ability: \"math\",\n*     question: \"What's its inverse?\",\n*   },\n*   {\n*     configurable: {\n*       sessionId: \"some_string_identifying_a_user\",\n*     },\n*   }\n* );\n* ```\n*/\nvar RunnableWithMessageHistory = class extends RunnableBinding {\n\trunnable;\n\tinputMessagesKey;\n\toutputMessagesKey;\n\thistoryMessagesKey;\n\tgetMessageHistory;\n\tconstructor(fields) {\n\t\tlet historyChain = RunnableLambda.from((input, options) => this._enterHistory(input, options ?? {})).withConfig({ runName: \"loadHistory\" });\n\t\tconst messagesKey = fields.historyMessagesKey ?? fields.inputMessagesKey;\n\t\tif (messagesKey) historyChain = RunnablePassthrough.assign({ [messagesKey]: historyChain }).withConfig({ runName: \"insertHistory\" });\n\t\tconst bound = historyChain.pipe(fields.runnable.withListeners({ onEnd: (run, config$1) => this._exitHistory(run, config$1 ?? {}) })).withConfig({ runName: \"RunnableWithMessageHistory\" });\n\t\tconst config = fields.config ?? {};\n\t\tsuper({\n\t\t\t...fields,\n\t\t\tconfig,\n\t\t\tbound\n\t\t});\n\t\tthis.runnable = fields.runnable;\n\t\tthis.getMessageHistory = fields.getMessageHistory;\n\t\tthis.inputMessagesKey = fields.inputMessagesKey;\n\t\tthis.outputMessagesKey = fields.outputMessagesKey;\n\t\tthis.historyMessagesKey = fields.historyMessagesKey;\n\t}\n\t_getInputMessages(inputValue) {\n\t\tlet parsedInputValue;\n\t\tif (typeof inputValue === \"object\" && !Array.isArray(inputValue) && !isBaseMessage(inputValue)) {\n\t\t\tlet key;\n\t\t\tif (this.inputMessagesKey) key = this.inputMessagesKey;\n\t\t\telse if (Object.keys(inputValue).length === 1) key = Object.keys(inputValue)[0];\n\t\t\telse key = \"input\";\n\t\t\tif (Array.isArray(inputValue[key]) && Array.isArray(inputValue[key][0])) parsedInputValue = inputValue[key][0];\n\t\t\telse parsedInputValue = inputValue[key];\n\t\t} else parsedInputValue = inputValue;\n\t\tif (typeof parsedInputValue === \"string\") return [new HumanMessage(parsedInputValue)];\n\t\telse if (Array.isArray(parsedInputValue)) return parsedInputValue;\n\t\telse if (isBaseMessage(parsedInputValue)) return [parsedInputValue];\n\t\telse throw new Error(`Expected a string, BaseMessage, or array of BaseMessages.\\nGot ${JSON.stringify(parsedInputValue, null, 2)}`);\n\t}\n\t_getOutputMessages(outputValue) {\n\t\tlet parsedOutputValue;\n\t\tif (!Array.isArray(outputValue) && !isBaseMessage(outputValue) && typeof outputValue !== \"string\") {\n\t\t\tlet key;\n\t\t\tif (this.outputMessagesKey !== void 0) key = this.outputMessagesKey;\n\t\t\telse if (Object.keys(outputValue).length === 1) key = Object.keys(outputValue)[0];\n\t\t\telse key = \"output\";\n\t\t\tif (outputValue.generations !== void 0) parsedOutputValue = outputValue.generations[0][0].message;\n\t\t\telse parsedOutputValue = outputValue[key];\n\t\t} else parsedOutputValue = outputValue;\n\t\tif (typeof parsedOutputValue === \"string\") return [new AIMessage(parsedOutputValue)];\n\t\telse if (Array.isArray(parsedOutputValue)) return parsedOutputValue;\n\t\telse if (isBaseMessage(parsedOutputValue)) return [parsedOutputValue];\n\t\telse throw new Error(`Expected a string, BaseMessage, or array of BaseMessages. Received: ${JSON.stringify(parsedOutputValue, null, 2)}`);\n\t}\n\tasync _enterHistory(input, kwargs) {\n\t\tconst history = kwargs?.configurable?.messageHistory;\n\t\tconst messages = await history.getMessages();\n\t\tif (this.historyMessagesKey === void 0) return messages.concat(this._getInputMessages(input));\n\t\treturn messages;\n\t}\n\tasync _exitHistory(run, config) {\n\t\tconst history = config.configurable?.messageHistory;\n\t\tlet inputs;\n\t\tif (Array.isArray(run.inputs) && Array.isArray(run.inputs[0])) inputs = run.inputs[0];\n\t\telse inputs = run.inputs;\n\t\tlet inputMessages = this._getInputMessages(inputs);\n\t\tif (this.historyMessagesKey === void 0) {\n\t\t\tconst existingMessages = await history.getMessages();\n\t\t\tinputMessages = inputMessages.slice(existingMessages.length);\n\t\t}\n\t\tconst outputValue = run.outputs;\n\t\tif (!outputValue) throw new Error(`Output values from 'Run' undefined. Run: ${JSON.stringify(run, null, 2)}`);\n\t\tconst outputMessages = this._getOutputMessages(outputValue);\n\t\tawait history.addMessages([...inputMessages, ...outputMessages]);\n\t}\n\tasync _mergeConfig(...configs) {\n\t\tconst config = await super._mergeConfig(...configs);\n\t\tif (!config.configurable || !config.configurable.sessionId) {\n\t\t\tconst exampleInput = { [this.inputMessagesKey ?? \"input\"]: \"foo\" };\n\t\t\tconst exampleConfig = { configurable: { sessionId: \"123\" } };\n\t\t\tthrow new Error(`sessionId is required. Pass it in as part of the config argument to .invoke() or .stream()\\neg. chain.invoke(${JSON.stringify(exampleInput)}, ${JSON.stringify(exampleConfig)})`);\n\t\t}\n\t\tconst { sessionId } = config.configurable;\n\t\tconfig.configurable.messageHistory = await this.getMessageHistory(sessionId);\n\t\treturn config;\n\t}\n};\n\n//#endregion\nexport { RunnableWithMessageHistory };\n//# sourceMappingURL=history.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { ensureConfig, getCallbackManagerForConfig, mergeConfigs, patchConfig, pickRunnableConfigKeys } from \"./config.js\";\nimport { Runnable, RunnableAssign, RunnableBinding, RunnableEach, RunnableLambda, RunnableMap, RunnableParallel, RunnablePick, RunnableRetry, RunnableSequence, RunnableToolLike, RunnableWithFallbacks, _coerceToRunnable } from \"./base.js\";\nimport { RunnablePassthrough } from \"./passthrough.js\";\nimport { RouterRunnable } from \"./router.js\";\nimport { RunnableBranch } from \"./branch.js\";\nimport { RunnableWithMessageHistory } from \"./history.js\";\n\n//#region src/runnables/index.ts\nvar runnables_exports = {};\n__export(runnables_exports, {\n\tRouterRunnable: () => RouterRunnable,\n\tRunnable: () => Runnable,\n\tRunnableAssign: () => RunnableAssign,\n\tRunnableBinding: () => RunnableBinding,\n\tRunnableBranch: () => RunnableBranch,\n\tRunnableEach: () => RunnableEach,\n\tRunnableLambda: () => RunnableLambda,\n\tRunnableMap: () => RunnableMap,\n\tRunnableParallel: () => RunnableParallel,\n\tRunnablePassthrough: () => RunnablePassthrough,\n\tRunnablePick: () => RunnablePick,\n\tRunnableRetry: () => RunnableRetry,\n\tRunnableSequence: () => RunnableSequence,\n\tRunnableToolLike: () => RunnableToolLike,\n\tRunnableWithFallbacks: () => RunnableWithFallbacks,\n\tRunnableWithMessageHistory: () => RunnableWithMessageHistory,\n\t_coerceToRunnable: () => _coerceToRunnable,\n\tensureConfig: () => ensureConfig,\n\tgetCallbackManagerForConfig: () => getCallbackManagerForConfig,\n\tmergeConfigs: () => mergeConfigs,\n\tpatchConfig: () => patchConfig,\n\tpickRunnableConfigKeys: () => pickRunnableConfigKeys\n});\n\n//#endregion\nexport { RouterRunnable, Runnable, RunnableAssign, RunnableBinding, RunnableBranch, RunnableEach, RunnableLambda, RunnableMap, RunnableParallel, RunnablePassthrough, RunnablePick, RunnableRetry, RunnableSequence, RunnableToolLike, RunnableWithFallbacks, RunnableWithMessageHistory, _coerceToRunnable, ensureConfig, getCallbackManagerForConfig, mergeConfigs, patchConfig, pickRunnableConfigKeys, runnables_exports };\n//# sourceMappingURL=index.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { applyPatch } from \"./fast-json-patch/src/core.js\";\nimport { compare } from \"./fast-json-patch/src/duplex.js\";\nimport \"./fast-json-patch/index.js\";\n\n//#region src/utils/json_patch.ts\nvar json_patch_exports = {};\n__export(json_patch_exports, {\n\tapplyPatch: () => applyPatch,\n\tcompare: () => compare\n});\n\n//#endregion\nexport { applyPatch, compare, json_patch_exports };\n//# sourceMappingURL=json_patch.js.map","import { addLangChainErrorFields } from \"../errors/index.js\";\nimport { Runnable } from \"../runnables/base.js\";\nimport \"../runnables/index.js\";\n\n//#region src/output_parsers/base.ts\n/**\n* Abstract base class for parsing the output of a Large Language Model\n* (LLM) call. It provides methods for parsing the result of an LLM call\n* and invoking the parser with a given input.\n*/\nvar BaseLLMOutputParser = class extends Runnable {\n\t/**\n\t* Parses the result of an LLM call with a given prompt. By default, it\n\t* simply calls `parseResult`.\n\t* @param generations The generations from an LLM call.\n\t* @param _prompt The prompt used in the LLM call.\n\t* @param callbacks Optional callbacks.\n\t* @returns A promise of the parsed output.\n\t*/\n\tparseResultWithPrompt(generations, _prompt, callbacks) {\n\t\treturn this.parseResult(generations, callbacks);\n\t}\n\t_baseMessageToString(message) {\n\t\treturn typeof message.content === \"string\" ? message.content : this._baseMessageContentToString(message.content);\n\t}\n\t_baseMessageContentToString(content) {\n\t\treturn JSON.stringify(content);\n\t}\n\t/**\n\t* Calls the parser with a given input and optional configuration options.\n\t* If the input is a string, it creates a generation with the input as\n\t* text and calls `parseResult`. If the input is a `BaseMessage`, it\n\t* creates a generation with the input as a message and the content of the\n\t* input as text, and then calls `parseResult`.\n\t* @param input The input to the parser, which can be a string or a `BaseMessage`.\n\t* @param options Optional configuration options.\n\t* @returns A promise of the parsed output.\n\t*/\n\tasync invoke(input, options) {\n\t\tif (typeof input === \"string\") return this._callWithConfig(async (input$1, options$1) => this.parseResult([{ text: input$1 }], options$1?.callbacks), input, {\n\t\t\t...options,\n\t\t\trunType: \"parser\"\n\t\t});\n\t\telse return this._callWithConfig(async (input$1, options$1) => this.parseResult([{\n\t\t\tmessage: input$1,\n\t\t\ttext: this._baseMessageToString(input$1)\n\t\t}], options$1?.callbacks), input, {\n\t\t\t...options,\n\t\t\trunType: \"parser\"\n\t\t});\n\t}\n};\n/**\n* Class to parse the output of an LLM call.\n*/\nvar BaseOutputParser = class extends BaseLLMOutputParser {\n\tparseResult(generations, callbacks) {\n\t\treturn this.parse(generations[0].text, callbacks);\n\t}\n\tasync parseWithPrompt(text, _prompt, callbacks) {\n\t\treturn this.parse(text, callbacks);\n\t}\n\t/**\n\t* Return the string type key uniquely identifying this class of parser\n\t*/\n\t_type() {\n\t\tthrow new Error(\"_type not implemented\");\n\t}\n};\n/**\n* Exception that output parsers should raise to signify a parsing error.\n*\n* This exists to differentiate parsing errors from other code or execution errors\n* that also may arise inside the output parser. OutputParserExceptions will be\n* available to catch and handle in ways to fix the parsing error, while other\n* errors will be raised.\n*\n* @param message - The error that's being re-raised or an error message.\n* @param llmOutput - String model output which is error-ing.\n* @param observation - String explanation of error which can be passed to a\n*     model to try and remediate the issue.\n* @param sendToLLM - Whether to send the observation and llm_output back to an Agent\n*     after an OutputParserException has been raised. This gives the underlying\n*     model driving the agent the context that the previous output was improperly\n*     structured, in the hopes that it will update the output to the correct\n*     format.\n*/\nvar OutputParserException = class extends Error {\n\tllmOutput;\n\tobservation;\n\tsendToLLM;\n\tconstructor(message, llmOutput, observation, sendToLLM = false) {\n\t\tsuper(message);\n\t\tthis.llmOutput = llmOutput;\n\t\tthis.observation = observation;\n\t\tthis.sendToLLM = sendToLLM;\n\t\tif (sendToLLM) {\n\t\t\tif (observation === void 0 || llmOutput === void 0) throw new Error(\"Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true\");\n\t\t}\n\t\taddLangChainErrorFields(this, \"OUTPUT_PARSING_FAILURE\");\n\t}\n};\n\n//#endregion\nexport { BaseLLMOutputParser, BaseOutputParser, OutputParserException };\n//# sourceMappingURL=base.js.map","import { isBaseMessage, isBaseMessageChunk } from \"../messages/base.js\";\nimport { convertToChunk } from \"../messages/utils.js\";\nimport { ChatGenerationChunk, GenerationChunk } from \"../outputs.js\";\nimport { BaseOutputParser } from \"./base.js\";\nimport { deepCompareStrict } from \"@cfworker/json-schema\";\n\n//#region src/output_parsers/transform.ts\n/**\n* Class to parse the output of an LLM call that also allows streaming inputs.\n*/\nvar BaseTransformOutputParser = class extends BaseOutputParser {\n\tasync *_transform(inputGenerator) {\n\t\tfor await (const chunk of inputGenerator) if (typeof chunk === \"string\") yield this.parseResult([{ text: chunk }]);\n\t\telse yield this.parseResult([{\n\t\t\tmessage: chunk,\n\t\t\ttext: this._baseMessageToString(chunk)\n\t\t}]);\n\t}\n\t/**\n\t* Transforms an asynchronous generator of input into an asynchronous\n\t* generator of parsed output.\n\t* @param inputGenerator An asynchronous generator of input.\n\t* @param options A configuration object.\n\t* @returns An asynchronous generator of parsed output.\n\t*/\n\tasync *transform(inputGenerator, options) {\n\t\tyield* this._transformStreamWithConfig(inputGenerator, this._transform.bind(this), {\n\t\t\t...options,\n\t\t\trunType: \"parser\"\n\t\t});\n\t}\n};\n/**\n* A base class for output parsers that can handle streaming input. It\n* extends the `BaseTransformOutputParser` class and provides a method for\n* converting parsed outputs into a diff format.\n*/\nvar BaseCumulativeTransformOutputParser = class extends BaseTransformOutputParser {\n\tdiff = false;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.diff = fields?.diff ?? this.diff;\n\t}\n\tasync *_transform(inputGenerator) {\n\t\tlet prevParsed;\n\t\tlet accGen;\n\t\tfor await (const chunk of inputGenerator) {\n\t\t\tif (typeof chunk !== \"string\" && typeof chunk.content !== \"string\") throw new Error(\"Cannot handle non-string output.\");\n\t\t\tlet chunkGen;\n\t\t\tif (isBaseMessageChunk(chunk)) {\n\t\t\t\tif (typeof chunk.content !== \"string\") throw new Error(\"Cannot handle non-string message output.\");\n\t\t\t\tchunkGen = new ChatGenerationChunk({\n\t\t\t\t\tmessage: chunk,\n\t\t\t\t\ttext: chunk.content\n\t\t\t\t});\n\t\t\t} else if (isBaseMessage(chunk)) {\n\t\t\t\tif (typeof chunk.content !== \"string\") throw new Error(\"Cannot handle non-string message output.\");\n\t\t\t\tchunkGen = new ChatGenerationChunk({\n\t\t\t\t\tmessage: convertToChunk(chunk),\n\t\t\t\t\ttext: chunk.content\n\t\t\t\t});\n\t\t\t} else chunkGen = new GenerationChunk({ text: chunk });\n\t\t\tif (accGen === void 0) accGen = chunkGen;\n\t\t\telse accGen = accGen.concat(chunkGen);\n\t\t\tconst parsed = await this.parsePartialResult([accGen]);\n\t\t\tif (parsed !== void 0 && parsed !== null && !deepCompareStrict(parsed, prevParsed)) {\n\t\t\t\tif (this.diff) yield this._diff(prevParsed, parsed);\n\t\t\t\telse yield parsed;\n\t\t\t\tprevParsed = parsed;\n\t\t\t}\n\t\t}\n\t}\n\tgetFormatInstructions() {\n\t\treturn \"\";\n\t}\n};\n\n//#endregion\nexport { BaseCumulativeTransformOutputParser, BaseTransformOutputParser };\n//# sourceMappingURL=transform.js.map","import { BaseTransformOutputParser } from \"./transform.js\";\n\n//#region src/output_parsers/bytes.ts\n/**\n* OutputParser that parses LLMResult into the top likely string and\n* encodes it into bytes.\n*/\nvar BytesOutputParser = class extends BaseTransformOutputParser {\n\tstatic lc_name() {\n\t\treturn \"BytesOutputParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"output_parsers\",\n\t\t\"bytes\"\n\t];\n\tlc_serializable = true;\n\ttextEncoder = new TextEncoder();\n\tparse(text) {\n\t\treturn Promise.resolve(this.textEncoder.encode(text));\n\t}\n\tgetFormatInstructions() {\n\t\treturn \"\";\n\t}\n};\n\n//#endregion\nexport { BytesOutputParser };\n//# sourceMappingURL=bytes.js.map","import { OutputParserException } from \"./base.js\";\nimport { BaseTransformOutputParser } from \"./transform.js\";\n\n//#region src/output_parsers/list.ts\n/**\n* Class to parse the output of an LLM call to a list.\n* @augments BaseOutputParser\n*/\nvar ListOutputParser = class extends BaseTransformOutputParser {\n\tre;\n\tasync *_transform(inputGenerator) {\n\t\tlet buffer = \"\";\n\t\tfor await (const input of inputGenerator) {\n\t\t\tif (typeof input === \"string\") buffer += input;\n\t\t\telse buffer += input.content;\n\t\t\tif (!this.re) {\n\t\t\t\tconst parts = await this.parse(buffer);\n\t\t\t\tif (parts.length > 1) {\n\t\t\t\t\tfor (const part of parts.slice(0, -1)) yield [part];\n\t\t\t\t\tbuffer = parts[parts.length - 1];\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst matches = [...buffer.matchAll(this.re)];\n\t\t\t\tif (matches.length > 1) {\n\t\t\t\t\tlet doneIdx = 0;\n\t\t\t\t\tfor (const match of matches.slice(0, -1)) {\n\t\t\t\t\t\tyield [match[1]];\n\t\t\t\t\t\tdoneIdx += (match.index ?? 0) + match[0].length;\n\t\t\t\t\t}\n\t\t\t\t\tbuffer = buffer.slice(doneIdx);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (const part of await this.parse(buffer)) yield [part];\n\t}\n};\n/**\n* Class to parse the output of an LLM call as a comma-separated list.\n* @augments ListOutputParser\n*/\nvar CommaSeparatedListOutputParser = class extends ListOutputParser {\n\tstatic lc_name() {\n\t\treturn \"CommaSeparatedListOutputParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"output_parsers\",\n\t\t\"list\"\n\t];\n\tlc_serializable = true;\n\t/**\n\t* Parses the given text into an array of strings, using a comma as the\n\t* separator. If the parsing fails, throws an OutputParserException.\n\t* @param text The text to parse.\n\t* @returns An array of strings obtained by splitting the input text at each comma.\n\t*/\n\tasync parse(text) {\n\t\ttry {\n\t\t\treturn text.trim().split(\",\").map((s) => s.trim());\n\t\t} catch {\n\t\t\tthrow new OutputParserException(`Could not parse output: ${text}`, text);\n\t\t}\n\t}\n\t/**\n\t* Provides instructions on the expected format of the response for the\n\t* CommaSeparatedListOutputParser.\n\t* @returns A string containing instructions on the expected format of the response.\n\t*/\n\tgetFormatInstructions() {\n\t\treturn `Your response should be a list of comma separated values, eg: \\`foo, bar, baz\\``;\n\t}\n};\n/**\n* Class to parse the output of an LLM call to a list with a specific length and separator.\n* @augments ListOutputParser\n*/\nvar CustomListOutputParser = class extends ListOutputParser {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"output_parsers\",\n\t\t\"list\"\n\t];\n\tlength;\n\tseparator;\n\tconstructor({ length, separator }) {\n\t\tsuper(...arguments);\n\t\tthis.length = length;\n\t\tthis.separator = separator || \",\";\n\t}\n\t/**\n\t* Parses the given text into an array of strings, using the specified\n\t* separator. If the parsing fails or the number of items in the list\n\t* doesn't match the expected length, throws an OutputParserException.\n\t* @param text The text to parse.\n\t* @returns An array of strings obtained by splitting the input text at each occurrence of the specified separator.\n\t*/\n\tasync parse(text) {\n\t\ttry {\n\t\t\tconst items = text.trim().split(this.separator).map((s) => s.trim());\n\t\t\tif (this.length !== void 0 && items.length !== this.length) throw new OutputParserException(`Incorrect number of items. Expected ${this.length}, got ${items.length}.`);\n\t\t\treturn items;\n\t\t} catch (e) {\n\t\t\tif (Object.getPrototypeOf(e) === OutputParserException.prototype) throw e;\n\t\t\tthrow new OutputParserException(`Could not parse output: ${text}`);\n\t\t}\n\t}\n\t/**\n\t* Provides instructions on the expected format of the response for the\n\t* CustomListOutputParser, including the number of items and the\n\t* separator.\n\t* @returns A string containing instructions on the expected format of the response.\n\t*/\n\tgetFormatInstructions() {\n\t\treturn `Your response should be a list of ${this.length === void 0 ? \"\" : `${this.length} `}items separated by \"${this.separator}\" (eg: \\`foo${this.separator} bar${this.separator} baz\\`)`;\n\t}\n};\nvar NumberedListOutputParser = class extends ListOutputParser {\n\tstatic lc_name() {\n\t\treturn \"NumberedListOutputParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"output_parsers\",\n\t\t\"list\"\n\t];\n\tlc_serializable = true;\n\tgetFormatInstructions() {\n\t\treturn `Your response should be a numbered list with each item on a new line. For example: \\n\\n1. foo\\n\\n2. bar\\n\\n3. baz`;\n\t}\n\tre = /\\d+\\.\\s([^\\n]+)/g;\n\tasync parse(text) {\n\t\treturn [...text.matchAll(this.re) ?? []].map((m) => m[1]);\n\t}\n};\nvar MarkdownListOutputParser = class extends ListOutputParser {\n\tstatic lc_name() {\n\t\treturn \"NumberedListOutputParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"output_parsers\",\n\t\t\"list\"\n\t];\n\tlc_serializable = true;\n\tgetFormatInstructions() {\n\t\treturn `Your response should be a numbered list with each item on a new line. For example: \\n\\n1. foo\\n\\n2. bar\\n\\n3. baz`;\n\t}\n\tre = /^\\s*[-*]\\s([^\\n]+)$/gm;\n\tasync parse(text) {\n\t\treturn [...text.matchAll(this.re) ?? []].map((m) => m[1]);\n\t}\n};\n\n//#endregion\nexport { CommaSeparatedListOutputParser, CustomListOutputParser, ListOutputParser, MarkdownListOutputParser, NumberedListOutputParser };\n//# sourceMappingURL=list.js.map","import { BaseTransformOutputParser } from \"./transform.js\";\n\n//#region src/output_parsers/string.ts\n/**\n* OutputParser that parses LLMResult into the top likely string.\n* @example\n* ```typescript\n* const promptTemplate = PromptTemplate.fromTemplate(\n*   \"Tell me a joke about {topic}\",\n* );\n*\n* const chain = RunnableSequence.from([\n*   promptTemplate,\n*   new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n*   new StringOutputParser(),\n* ]);\n*\n* const result = await chain.invoke({ topic: \"bears\" });\n* console.log(\"What do you call a bear with no teeth? A gummy bear!\");\n* ```\n*/\nvar StringOutputParser = class extends BaseTransformOutputParser {\n\tstatic lc_name() {\n\t\treturn \"StrOutputParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"output_parsers\",\n\t\t\"string\"\n\t];\n\tlc_serializable = true;\n\t/**\n\t* Parses a string output from an LLM call. This method is meant to be\n\t* implemented by subclasses to define how a string output from an LLM\n\t* should be parsed.\n\t* @param text The string output from an LLM call.\n\t* @param callbacks Optional callbacks.\n\t* @returns A promise of the parsed output.\n\t*/\n\tparse(text) {\n\t\treturn Promise.resolve(text);\n\t}\n\tgetFormatInstructions() {\n\t\treturn \"\";\n\t}\n\t_textContentToString(content) {\n\t\treturn content.text;\n\t}\n\t_imageUrlContentToString(_content) {\n\t\tthrow new Error(`Cannot coerce a multimodal \"image_url\" message part into a string.`);\n\t}\n\t_messageContentToString(content) {\n\t\tswitch (content.type) {\n\t\t\tcase \"text\":\n\t\t\tcase \"text_delta\":\n\t\t\t\tif (\"text\" in content) return this._textContentToString(content);\n\t\t\t\tbreak;\n\t\t\tcase \"image_url\":\n\t\t\t\tif (\"image_url\" in content) return this._imageUrlContentToString(content);\n\t\t\t\tbreak;\n\t\t\tdefault: throw new Error(`Cannot coerce \"${content.type}\" message part into a string.`);\n\t\t}\n\t\tthrow new Error(`Invalid content type: ${content.type}`);\n\t}\n\t_baseMessageContentToString(content) {\n\t\treturn content.reduce((acc, item) => acc + this._messageContentToString(item), \"\");\n\t}\n};\n\n//#endregion\nexport { StringOutputParser };\n//# sourceMappingURL=string.js.map","import { interopParseAsync } from \"../utils/types/zod.js\";\nimport { toJsonSchema } from \"../utils/json_schema.js\";\nimport { BaseOutputParser, OutputParserException } from \"./base.js\";\nimport { z } from \"zod/v3\";\n\n//#region src/output_parsers/structured.ts\nvar StructuredOutputParser = class extends BaseOutputParser {\n\tstatic lc_name() {\n\t\treturn \"StructuredOutputParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"output_parsers\",\n\t\t\"structured\"\n\t];\n\ttoJSON() {\n\t\treturn this.toJSONNotImplemented();\n\t}\n\tconstructor(schema) {\n\t\tsuper(schema);\n\t\tthis.schema = schema;\n\t}\n\t/**\n\t* Creates a new StructuredOutputParser from a Zod schema.\n\t* @param schema The Zod schema which the output should match\n\t* @returns A new instance of StructuredOutputParser.\n\t*/\n\tstatic fromZodSchema(schema) {\n\t\treturn new this(schema);\n\t}\n\t/**\n\t* Creates a new StructuredOutputParser from a set of names and\n\t* descriptions.\n\t* @param schemas An object where each key is a name and each value is a description\n\t* @returns A new instance of StructuredOutputParser.\n\t*/\n\tstatic fromNamesAndDescriptions(schemas) {\n\t\tconst zodSchema = z.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, z.string().describe(description)])));\n\t\treturn new this(zodSchema);\n\t}\n\t/**\n\t* Returns a markdown code snippet with a JSON object formatted according\n\t* to the schema.\n\t* @param options Optional. The options for formatting the instructions\n\t* @returns A markdown code snippet with a JSON object formatted according to the schema.\n\t*/\n\tgetFormatInstructions() {\n\t\treturn `You must format your output as a JSON value that adheres to a given \"JSON Schema\" instance.\n\n\"JSON Schema\" is a declarative language that allows you to annotate and validate JSON documents.\n\nFor example, the example \"JSON Schema\" instance {{\"properties\": {{\"foo\": {{\"description\": \"a list of test words\", \"type\": \"array\", \"items\": {{\"type\": \"string\"}}}}}}, \"required\": [\"foo\"]}}\nwould match an object with one required property, \"foo\". The \"type\" property specifies \"foo\" must be an \"array\", and the \"description\" property semantically describes it as \"a list of test words\". The items within \"foo\" must be strings.\nThus, the object {{\"foo\": [\"bar\", \"baz\"]}} is a well-formatted instance of this example \"JSON Schema\". The object {{\"properties\": {{\"foo\": [\"bar\", \"baz\"]}}}} is not well-formatted.\n\nYour output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match the schema exactly and there are no trailing commas!\n\nHere is the JSON Schema instance your output must adhere to. Include the enclosing markdown codeblock:\n\\`\\`\\`json\n${JSON.stringify(toJsonSchema(this.schema))}\n\\`\\`\\`\n`;\n\t}\n\t/**\n\t* Parses the given text according to the schema.\n\t* @param text The text to parse\n\t* @returns The parsed output.\n\t*/\n\tasync parse(text) {\n\t\ttry {\n\t\t\tconst trimmedText = text.trim();\n\t\t\tconst json = trimmedText.match(/^```(?:json)?\\s*([\\s\\S]*?)```/)?.[1] || trimmedText.match(/```json\\s*([\\s\\S]*?)```/)?.[1] || trimmedText;\n\t\t\tconst escapedJson = json.replace(/\"([^\"\\\\]*(\\\\.[^\"\\\\]*)*)\"/g, (_match, capturedGroup) => {\n\t\t\t\tconst escapedInsideQuotes = capturedGroup.replace(/\\n/g, \"\\\\n\");\n\t\t\t\treturn `\"${escapedInsideQuotes}\"`;\n\t\t\t}).replace(/\\n/g, \"\");\n\t\t\treturn await interopParseAsync(this.schema, JSON.parse(escapedJson));\n\t\t} catch (e) {\n\t\t\tthrow new OutputParserException(`Failed to parse. Text: \"${text}\". Error: ${e}`, text);\n\t\t}\n\t}\n};\n/**\n* A specific type of `StructuredOutputParser` that parses JSON data\n* formatted as a markdown code snippet.\n*/\nvar JsonMarkdownStructuredOutputParser = class extends StructuredOutputParser {\n\tstatic lc_name() {\n\t\treturn \"JsonMarkdownStructuredOutputParser\";\n\t}\n\tgetFormatInstructions(options) {\n\t\tconst interpolationDepth = options?.interpolationDepth ?? 1;\n\t\tif (interpolationDepth < 1) throw new Error(\"f string interpolation depth must be at least 1\");\n\t\treturn `Return a markdown code snippet with a JSON object formatted to look like:\\n\\`\\`\\`json\\n${this._schemaToInstruction(toJsonSchema(this.schema)).replaceAll(\"{\", \"{\".repeat(interpolationDepth)).replaceAll(\"}\", \"}\".repeat(interpolationDepth))}\\n\\`\\`\\``;\n\t}\n\t_schemaToInstruction(schemaInput, indent = 2) {\n\t\tconst schema = schemaInput;\n\t\tif (\"type\" in schema) {\n\t\t\tlet nullable = false;\n\t\t\tlet type;\n\t\t\tif (Array.isArray(schema.type)) {\n\t\t\t\tconst nullIdx = schema.type.findIndex((type$1) => type$1 === \"null\");\n\t\t\t\tif (nullIdx !== -1) {\n\t\t\t\t\tnullable = true;\n\t\t\t\t\tschema.type.splice(nullIdx, 1);\n\t\t\t\t}\n\t\t\t\ttype = schema.type.join(\" | \");\n\t\t\t} else type = schema.type;\n\t\t\tif (schema.type === \"object\" && schema.properties) {\n\t\t\t\tconst description$1 = schema.description ? ` // ${schema.description}` : \"\";\n\t\t\t\tconst properties = Object.entries(schema.properties).map(([key, value]) => {\n\t\t\t\t\tconst isOptional = schema.required?.includes(key) ? \"\" : \" (optional)\";\n\t\t\t\t\treturn `${\" \".repeat(indent)}\"${key}\": ${this._schemaToInstruction(value, indent + 2)}${isOptional}`;\n\t\t\t\t}).join(\"\\n\");\n\t\t\t\treturn `{\\n${properties}\\n${\" \".repeat(indent - 2)}}${description$1}`;\n\t\t\t}\n\t\t\tif (schema.type === \"array\" && schema.items) {\n\t\t\t\tconst description$1 = schema.description ? ` // ${schema.description}` : \"\";\n\t\t\t\treturn `array[\\n${\" \".repeat(indent)}${this._schemaToInstruction(schema.items, indent + 2)}\\n${\" \".repeat(indent - 2)}] ${description$1}`;\n\t\t\t}\n\t\t\tconst isNullable = nullable ? \" (nullable)\" : \"\";\n\t\t\tconst description = schema.description ? ` // ${schema.description}` : \"\";\n\t\t\treturn `${type}${description}${isNullable}`;\n\t\t}\n\t\tif (\"anyOf\" in schema) return schema.anyOf.map((s) => this._schemaToInstruction(s, indent)).join(`\\n${\" \".repeat(indent - 2)}`);\n\t\tthrow new Error(\"unsupported schema type\");\n\t}\n\tstatic fromZodSchema(schema) {\n\t\treturn new this(schema);\n\t}\n\tstatic fromNamesAndDescriptions(schemas) {\n\t\tconst zodSchema = z.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, z.string().describe(description)])));\n\t\treturn new this(zodSchema);\n\t}\n};\n/**\n* A type of `StructuredOutputParser` that handles asymmetric input and\n* output schemas.\n*/\nvar AsymmetricStructuredOutputParser = class extends BaseOutputParser {\n\tstructuredInputParser;\n\tconstructor({ inputSchema }) {\n\t\tsuper(...arguments);\n\t\tthis.structuredInputParser = new JsonMarkdownStructuredOutputParser(inputSchema);\n\t}\n\tasync parse(text) {\n\t\tlet parsedInput;\n\t\ttry {\n\t\t\tparsedInput = await this.structuredInputParser.parse(text);\n\t\t} catch (e) {\n\t\t\tthrow new OutputParserException(`Failed to parse. Text: \"${text}\". Error: ${e}`, text);\n\t\t}\n\t\treturn this.outputProcessor(parsedInput);\n\t}\n\tgetFormatInstructions() {\n\t\treturn this.structuredInputParser.getFormatInstructions();\n\t}\n};\n\n//#endregion\nexport { AsymmetricStructuredOutputParser, JsonMarkdownStructuredOutputParser, StructuredOutputParser };\n//# sourceMappingURL=structured.js.map","import { parseJsonMarkdown, parsePartialJson } from \"../utils/json.js\";\nimport { compare } from \"../utils/fast-json-patch/src/duplex.js\";\nimport { BaseCumulativeTransformOutputParser } from \"./transform.js\";\nimport \"../utils/json_patch.js\";\n\n//#region src/output_parsers/json.ts\n/**\n* Class for parsing the output of an LLM into a JSON object.\n*/\nvar JsonOutputParser = class extends BaseCumulativeTransformOutputParser {\n\tstatic lc_name() {\n\t\treturn \"JsonOutputParser\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"output_parsers\"];\n\tlc_serializable = true;\n\t/** @internal */\n\t_concatOutputChunks(first, second) {\n\t\tif (this.diff) return super._concatOutputChunks(first, second);\n\t\treturn second;\n\t}\n\t_diff(prev, next) {\n\t\tif (!next) return void 0;\n\t\tif (!prev) return [{\n\t\t\top: \"replace\",\n\t\t\tpath: \"\",\n\t\t\tvalue: next\n\t\t}];\n\t\treturn compare(prev, next);\n\t}\n\tasync parsePartialResult(generations) {\n\t\treturn parseJsonMarkdown(generations[0].text);\n\t}\n\tasync parse(text) {\n\t\treturn parseJsonMarkdown(text, JSON.parse);\n\t}\n\tgetFormatInstructions() {\n\t\treturn \"\";\n\t}\n};\n\n//#endregion\nexport { JsonOutputParser };\n//# sourceMappingURL=json.js.map","//#region src/utils/sax-js/sax.ts\nconst initializeSax = function() {\n\tconst sax$1 = {};\n\tsax$1.parser = function(strict, opt) {\n\t\treturn new SAXParser(strict, opt);\n\t};\n\tsax$1.SAXParser = SAXParser;\n\tsax$1.SAXStream = SAXStream;\n\tsax$1.createStream = createStream;\n\tsax$1.MAX_BUFFER_LENGTH = 64 * 1024;\n\tconst buffers = [\n\t\t\"comment\",\n\t\t\"sgmlDecl\",\n\t\t\"textNode\",\n\t\t\"tagName\",\n\t\t\"doctype\",\n\t\t\"procInstName\",\n\t\t\"procInstBody\",\n\t\t\"entity\",\n\t\t\"attribName\",\n\t\t\"attribValue\",\n\t\t\"cdata\",\n\t\t\"script\"\n\t];\n\tsax$1.EVENTS = [\n\t\t\"text\",\n\t\t\"processinginstruction\",\n\t\t\"sgmldeclaration\",\n\t\t\"doctype\",\n\t\t\"comment\",\n\t\t\"opentagstart\",\n\t\t\"attribute\",\n\t\t\"opentag\",\n\t\t\"closetag\",\n\t\t\"opencdata\",\n\t\t\"cdata\",\n\t\t\"closecdata\",\n\t\t\"error\",\n\t\t\"end\",\n\t\t\"ready\",\n\t\t\"script\",\n\t\t\"opennamespace\",\n\t\t\"closenamespace\"\n\t];\n\tfunction SAXParser(strict, opt) {\n\t\tif (!(this instanceof SAXParser)) return new SAXParser(strict, opt);\n\t\tvar parser = this;\n\t\tclearBuffers(parser);\n\t\tparser.q = parser.c = \"\";\n\t\tparser.bufferCheckPosition = sax$1.MAX_BUFFER_LENGTH;\n\t\tparser.opt = opt || {};\n\t\tparser.opt.lowercase = parser.opt.lowercase || parser.opt.lowercasetags;\n\t\tparser.looseCase = parser.opt.lowercase ? \"toLowerCase\" : \"toUpperCase\";\n\t\tparser.tags = [];\n\t\tparser.closed = parser.closedRoot = parser.sawRoot = false;\n\t\tparser.tag = parser.error = null;\n\t\tparser.strict = !!strict;\n\t\tparser.noscript = !!(strict || parser.opt.noscript);\n\t\tparser.state = S.BEGIN;\n\t\tparser.strictEntities = parser.opt.strictEntities;\n\t\tparser.ENTITIES = parser.strictEntities ? Object.create(sax$1.XML_ENTITIES) : Object.create(sax$1.ENTITIES);\n\t\tparser.attribList = [];\n\t\tif (parser.opt.xmlns) parser.ns = Object.create(rootNS);\n\t\tparser.trackPosition = parser.opt.position !== false;\n\t\tif (parser.trackPosition) parser.position = parser.line = parser.column = 0;\n\t\temit(parser, \"onready\");\n\t}\n\tif (!Object.create) Object.create = function(o) {\n\t\tfunction F() {}\n\t\tF.prototype = o;\n\t\tvar newf = new F();\n\t\treturn newf;\n\t};\n\tif (!Object.keys) Object.keys = function(o) {\n\t\tvar a = [];\n\t\tfor (var i in o) if (o.hasOwnProperty(i)) a.push(i);\n\t\treturn a;\n\t};\n\tfunction checkBufferLength(parser) {\n\t\tvar maxAllowed = Math.max(sax$1.MAX_BUFFER_LENGTH, 10);\n\t\tvar maxActual = 0;\n\t\tfor (var i = 0, l = buffers.length; i < l; i++) {\n\t\t\tvar len = parser[buffers[i]].length;\n\t\t\tif (len > maxAllowed) switch (buffers[i]) {\n\t\t\t\tcase \"textNode\":\n\t\t\t\t\tcloseText(parser);\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"cdata\":\n\t\t\t\t\temitNode(parser, \"oncdata\", parser.cdata);\n\t\t\t\t\tparser.cdata = \"\";\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"script\":\n\t\t\t\t\temitNode(parser, \"onscript\", parser.script);\n\t\t\t\t\tparser.script = \"\";\n\t\t\t\t\tbreak;\n\t\t\t\tdefault: error(parser, \"Max buffer length exceeded: \" + buffers[i]);\n\t\t\t}\n\t\t\tmaxActual = Math.max(maxActual, len);\n\t\t}\n\t\tvar m = sax$1.MAX_BUFFER_LENGTH - maxActual;\n\t\tparser.bufferCheckPosition = m + parser.position;\n\t}\n\tfunction clearBuffers(parser) {\n\t\tfor (var i = 0, l = buffers.length; i < l; i++) parser[buffers[i]] = \"\";\n\t}\n\tfunction flushBuffers(parser) {\n\t\tcloseText(parser);\n\t\tif (parser.cdata !== \"\") {\n\t\t\temitNode(parser, \"oncdata\", parser.cdata);\n\t\t\tparser.cdata = \"\";\n\t\t}\n\t\tif (parser.script !== \"\") {\n\t\t\temitNode(parser, \"onscript\", parser.script);\n\t\t\tparser.script = \"\";\n\t\t}\n\t}\n\tSAXParser.prototype = {\n\t\tend: function() {\n\t\t\tend(this);\n\t\t},\n\t\twrite,\n\t\tresume: function() {\n\t\t\tthis.error = null;\n\t\t\treturn this;\n\t\t},\n\t\tclose: function() {\n\t\t\treturn this.write(null);\n\t\t},\n\t\tflush: function() {\n\t\t\tflushBuffers(this);\n\t\t}\n\t};\n\tvar Stream = ReadableStream;\n\tif (!Stream) Stream = function() {};\n\tvar streamWraps = sax$1.EVENTS.filter(function(ev) {\n\t\treturn ev !== \"error\" && ev !== \"end\";\n\t});\n\tfunction createStream(strict, opt) {\n\t\treturn new SAXStream(strict, opt);\n\t}\n\tfunction SAXStream(strict, opt) {\n\t\tif (!(this instanceof SAXStream)) return new SAXStream(strict, opt);\n\t\tStream.apply(this);\n\t\tthis._parser = new SAXParser(strict, opt);\n\t\tthis.writable = true;\n\t\tthis.readable = true;\n\t\tvar me = this;\n\t\tthis._parser.onend = function() {\n\t\t\tme.emit(\"end\");\n\t\t};\n\t\tthis._parser.onerror = function(er) {\n\t\t\tme.emit(\"error\", er);\n\t\t\tme._parser.error = null;\n\t\t};\n\t\tthis._decoder = null;\n\t\tstreamWraps.forEach(function(ev) {\n\t\t\tObject.defineProperty(me, \"on\" + ev, {\n\t\t\t\tget: function() {\n\t\t\t\t\treturn me._parser[\"on\" + ev];\n\t\t\t\t},\n\t\t\t\tset: function(h) {\n\t\t\t\t\tif (!h) {\n\t\t\t\t\t\tme.removeAllListeners(ev);\n\t\t\t\t\t\tme._parser[\"on\" + ev] = h;\n\t\t\t\t\t\treturn h;\n\t\t\t\t\t}\n\t\t\t\t\tme.on(ev, h);\n\t\t\t\t},\n\t\t\t\tenumerable: true,\n\t\t\t\tconfigurable: false\n\t\t\t});\n\t\t});\n\t}\n\tSAXStream.prototype = Object.create(Stream.prototype, { constructor: { value: SAXStream } });\n\tSAXStream.prototype.write = function(data) {\n\t\tthis._parser.write(data.toString());\n\t\tthis.emit(\"data\", data);\n\t\treturn true;\n\t};\n\tSAXStream.prototype.end = function(chunk) {\n\t\tif (chunk && chunk.length) this.write(chunk);\n\t\tthis._parser.end();\n\t\treturn true;\n\t};\n\tSAXStream.prototype.on = function(ev, handler) {\n\t\tvar me = this;\n\t\tif (!me._parser[\"on\" + ev] && streamWraps.indexOf(ev) !== -1) me._parser[\"on\" + ev] = function() {\n\t\t\tvar args = arguments.length === 1 ? [arguments[0]] : Array.apply(null, arguments);\n\t\t\targs.splice(0, 0, ev);\n\t\t\tme.emit.apply(me, args);\n\t\t};\n\t\treturn Stream.prototype.on.call(me, ev, handler);\n\t};\n\tvar CDATA = \"[CDATA[\";\n\tvar DOCTYPE = \"DOCTYPE\";\n\tvar XML_NAMESPACE = \"http://www.w3.org/XML/1998/namespace\";\n\tvar XMLNS_NAMESPACE = \"http://www.w3.org/2000/xmlns/\";\n\tvar rootNS = {\n\t\txml: XML_NAMESPACE,\n\t\txmlns: XMLNS_NAMESPACE\n\t};\n\tvar nameStart = /[:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD]/;\n\tvar nameBody = /[:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\u00B7\\u0300-\\u036F\\u203F-\\u2040.\\d-]/;\n\tvar entityStart = /[#:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD]/;\n\tvar entityBody = /[#:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\u00B7\\u0300-\\u036F\\u203F-\\u2040.\\d-]/;\n\tfunction isWhitespace(c) {\n\t\treturn c === \" \" || c === \"\\n\" || c === \"\\r\" || c === \"\t\";\n\t}\n\tfunction isQuote(c) {\n\t\treturn c === \"\\\"\" || c === \"'\";\n\t}\n\tfunction isAttribEnd(c) {\n\t\treturn c === \">\" || isWhitespace(c);\n\t}\n\tfunction isMatch(regex, c) {\n\t\treturn regex.test(c);\n\t}\n\tfunction notMatch(regex, c) {\n\t\treturn !isMatch(regex, c);\n\t}\n\tvar S = 0;\n\tsax$1.STATE = {\n\t\tBEGIN: S++,\n\t\tBEGIN_WHITESPACE: S++,\n\t\tTEXT: S++,\n\t\tTEXT_ENTITY: S++,\n\t\tOPEN_WAKA: S++,\n\t\tSGML_DECL: S++,\n\t\tSGML_DECL_QUOTED: S++,\n\t\tDOCTYPE: S++,\n\t\tDOCTYPE_QUOTED: S++,\n\t\tDOCTYPE_DTD: S++,\n\t\tDOCTYPE_DTD_QUOTED: S++,\n\t\tCOMMENT_STARTING: S++,\n\t\tCOMMENT: S++,\n\t\tCOMMENT_ENDING: S++,\n\t\tCOMMENT_ENDED: S++,\n\t\tCDATA: S++,\n\t\tCDATA_ENDING: S++,\n\t\tCDATA_ENDING_2: S++,\n\t\tPROC_INST: S++,\n\t\tPROC_INST_BODY: S++,\n\t\tPROC_INST_ENDING: S++,\n\t\tOPEN_TAG: S++,\n\t\tOPEN_TAG_SLASH: S++,\n\t\tATTRIB: S++,\n\t\tATTRIB_NAME: S++,\n\t\tATTRIB_NAME_SAW_WHITE: S++,\n\t\tATTRIB_VALUE: S++,\n\t\tATTRIB_VALUE_QUOTED: S++,\n\t\tATTRIB_VALUE_CLOSED: S++,\n\t\tATTRIB_VALUE_UNQUOTED: S++,\n\t\tATTRIB_VALUE_ENTITY_Q: S++,\n\t\tATTRIB_VALUE_ENTITY_U: S++,\n\t\tCLOSE_TAG: S++,\n\t\tCLOSE_TAG_SAW_WHITE: S++,\n\t\tSCRIPT: S++,\n\t\tSCRIPT_ENDING: S++\n\t};\n\tsax$1.XML_ENTITIES = {\n\t\tamp: \"&\",\n\t\tgt: \">\",\n\t\tlt: \"<\",\n\t\tquot: \"\\\"\",\n\t\tapos: \"'\"\n\t};\n\tsax$1.ENTITIES = {\n\t\tamp: \"&\",\n\t\tgt: \">\",\n\t\tlt: \"<\",\n\t\tquot: \"\\\"\",\n\t\tapos: \"'\",\n\t\tAElig: 198,\n\t\tAacute: 193,\n\t\tAcirc: 194,\n\t\tAgrave: 192,\n\t\tAring: 197,\n\t\tAtilde: 195,\n\t\tAuml: 196,\n\t\tCcedil: 199,\n\t\tETH: 208,\n\t\tEacute: 201,\n\t\tEcirc: 202,\n\t\tEgrave: 200,\n\t\tEuml: 203,\n\t\tIacute: 205,\n\t\tIcirc: 206,\n\t\tIgrave: 204,\n\t\tIuml: 207,\n\t\tNtilde: 209,\n\t\tOacute: 211,\n\t\tOcirc: 212,\n\t\tOgrave: 210,\n\t\tOslash: 216,\n\t\tOtilde: 213,\n\t\tOuml: 214,\n\t\tTHORN: 222,\n\t\tUacute: 218,\n\t\tUcirc: 219,\n\t\tUgrave: 217,\n\t\tUuml: 220,\n\t\tYacute: 221,\n\t\taacute: 225,\n\t\tacirc: 226,\n\t\taelig: 230,\n\t\tagrave: 224,\n\t\taring: 229,\n\t\tatilde: 227,\n\t\tauml: 228,\n\t\tccedil: 231,\n\t\teacute: 233,\n\t\tecirc: 234,\n\t\tegrave: 232,\n\t\teth: 240,\n\t\teuml: 235,\n\t\tiacute: 237,\n\t\ticirc: 238,\n\t\tigrave: 236,\n\t\tiuml: 239,\n\t\tntilde: 241,\n\t\toacute: 243,\n\t\tocirc: 244,\n\t\tograve: 242,\n\t\toslash: 248,\n\t\totilde: 245,\n\t\touml: 246,\n\t\tszlig: 223,\n\t\tthorn: 254,\n\t\tuacute: 250,\n\t\tucirc: 251,\n\t\tugrave: 249,\n\t\tuuml: 252,\n\t\tyacute: 253,\n\t\tyuml: 255,\n\t\tcopy: 169,\n\t\treg: 174,\n\t\tnbsp: 160,\n\t\tiexcl: 161,\n\t\tcent: 162,\n\t\tpound: 163,\n\t\tcurren: 164,\n\t\tyen: 165,\n\t\tbrvbar: 166,\n\t\tsect: 167,\n\t\tuml: 168,\n\t\tordf: 170,\n\t\tlaquo: 171,\n\t\tnot: 172,\n\t\tshy: 173,\n\t\tmacr: 175,\n\t\tdeg: 176,\n\t\tplusmn: 177,\n\t\tsup1: 185,\n\t\tsup2: 178,\n\t\tsup3: 179,\n\t\tacute: 180,\n\t\tmicro: 181,\n\t\tpara: 182,\n\t\tmiddot: 183,\n\t\tcedil: 184,\n\t\tordm: 186,\n\t\traquo: 187,\n\t\tfrac14: 188,\n\t\tfrac12: 189,\n\t\tfrac34: 190,\n\t\tiquest: 191,\n\t\ttimes: 215,\n\t\tdivide: 247,\n\t\tOElig: 338,\n\t\toelig: 339,\n\t\tScaron: 352,\n\t\tscaron: 353,\n\t\tYuml: 376,\n\t\tfnof: 402,\n\t\tcirc: 710,\n\t\ttilde: 732,\n\t\tAlpha: 913,\n\t\tBeta: 914,\n\t\tGamma: 915,\n\t\tDelta: 916,\n\t\tEpsilon: 917,\n\t\tZeta: 918,\n\t\tEta: 919,\n\t\tTheta: 920,\n\t\tIota: 921,\n\t\tKappa: 922,\n\t\tLambda: 923,\n\t\tMu: 924,\n\t\tNu: 925,\n\t\tXi: 926,\n\t\tOmicron: 927,\n\t\tPi: 928,\n\t\tRho: 929,\n\t\tSigma: 931,\n\t\tTau: 932,\n\t\tUpsilon: 933,\n\t\tPhi: 934,\n\t\tChi: 935,\n\t\tPsi: 936,\n\t\tOmega: 937,\n\t\talpha: 945,\n\t\tbeta: 946,\n\t\tgamma: 947,\n\t\tdelta: 948,\n\t\tepsilon: 949,\n\t\tzeta: 950,\n\t\teta: 951,\n\t\ttheta: 952,\n\t\tiota: 953,\n\t\tkappa: 954,\n\t\tlambda: 955,\n\t\tmu: 956,\n\t\tnu: 957,\n\t\txi: 958,\n\t\tomicron: 959,\n\t\tpi: 960,\n\t\trho: 961,\n\t\tsigmaf: 962,\n\t\tsigma: 963,\n\t\ttau: 964,\n\t\tupsilon: 965,\n\t\tphi: 966,\n\t\tchi: 967,\n\t\tpsi: 968,\n\t\tomega: 969,\n\t\tthetasym: 977,\n\t\tupsih: 978,\n\t\tpiv: 982,\n\t\tensp: 8194,\n\t\temsp: 8195,\n\t\tthinsp: 8201,\n\t\tzwnj: 8204,\n\t\tzwj: 8205,\n\t\tlrm: 8206,\n\t\trlm: 8207,\n\t\tndash: 8211,\n\t\tmdash: 8212,\n\t\tlsquo: 8216,\n\t\trsquo: 8217,\n\t\tsbquo: 8218,\n\t\tldquo: 8220,\n\t\trdquo: 8221,\n\t\tbdquo: 8222,\n\t\tdagger: 8224,\n\t\tDagger: 8225,\n\t\tbull: 8226,\n\t\thellip: 8230,\n\t\tpermil: 8240,\n\t\tprime: 8242,\n\t\tPrime: 8243,\n\t\tlsaquo: 8249,\n\t\trsaquo: 8250,\n\t\toline: 8254,\n\t\tfrasl: 8260,\n\t\teuro: 8364,\n\t\timage: 8465,\n\t\tweierp: 8472,\n\t\treal: 8476,\n\t\ttrade: 8482,\n\t\talefsym: 8501,\n\t\tlarr: 8592,\n\t\tuarr: 8593,\n\t\trarr: 8594,\n\t\tdarr: 8595,\n\t\tharr: 8596,\n\t\tcrarr: 8629,\n\t\tlArr: 8656,\n\t\tuArr: 8657,\n\t\trArr: 8658,\n\t\tdArr: 8659,\n\t\thArr: 8660,\n\t\tforall: 8704,\n\t\tpart: 8706,\n\t\texist: 8707,\n\t\tempty: 8709,\n\t\tnabla: 8711,\n\t\tisin: 8712,\n\t\tnotin: 8713,\n\t\tni: 8715,\n\t\tprod: 8719,\n\t\tsum: 8721,\n\t\tminus: 8722,\n\t\tlowast: 8727,\n\t\tradic: 8730,\n\t\tprop: 8733,\n\t\tinfin: 8734,\n\t\tang: 8736,\n\t\tand: 8743,\n\t\tor: 8744,\n\t\tcap: 8745,\n\t\tcup: 8746,\n\t\tint: 8747,\n\t\tthere4: 8756,\n\t\tsim: 8764,\n\t\tcong: 8773,\n\t\tasymp: 8776,\n\t\tne: 8800,\n\t\tequiv: 8801,\n\t\tle: 8804,\n\t\tge: 8805,\n\t\tsub: 8834,\n\t\tsup: 8835,\n\t\tnsub: 8836,\n\t\tsube: 8838,\n\t\tsupe: 8839,\n\t\toplus: 8853,\n\t\totimes: 8855,\n\t\tperp: 8869,\n\t\tsdot: 8901,\n\t\tlceil: 8968,\n\t\trceil: 8969,\n\t\tlfloor: 8970,\n\t\trfloor: 8971,\n\t\tlang: 9001,\n\t\trang: 9002,\n\t\tloz: 9674,\n\t\tspades: 9824,\n\t\tclubs: 9827,\n\t\thearts: 9829,\n\t\tdiams: 9830\n\t};\n\tObject.keys(sax$1.ENTITIES).forEach(function(key) {\n\t\tvar e = sax$1.ENTITIES[key];\n\t\tvar s$1 = typeof e === \"number\" ? String.fromCharCode(e) : e;\n\t\tsax$1.ENTITIES[key] = s$1;\n\t});\n\tfor (var s in sax$1.STATE) sax$1.STATE[sax$1.STATE[s]] = s;\n\tS = sax$1.STATE;\n\tfunction emit(parser, event, data) {\n\t\tparser[event] && parser[event](data);\n\t}\n\tfunction emitNode(parser, nodeType, data) {\n\t\tif (parser.textNode) closeText(parser);\n\t\temit(parser, nodeType, data);\n\t}\n\tfunction closeText(parser) {\n\t\tparser.textNode = textopts(parser.opt, parser.textNode);\n\t\tif (parser.textNode) emit(parser, \"ontext\", parser.textNode);\n\t\tparser.textNode = \"\";\n\t}\n\tfunction textopts(opt, text) {\n\t\tif (opt.trim) text = text.trim();\n\t\tif (opt.normalize) text = text.replace(/\\s+/g, \" \");\n\t\treturn text;\n\t}\n\tfunction error(parser, er) {\n\t\tcloseText(parser);\n\t\tif (parser.trackPosition) er += \"\\nLine: \" + parser.line + \"\\nColumn: \" + parser.column + \"\\nChar: \" + parser.c;\n\t\ter = new Error(er);\n\t\tparser.error = er;\n\t\temit(parser, \"onerror\", er);\n\t\treturn parser;\n\t}\n\tfunction end(parser) {\n\t\tif (parser.sawRoot && !parser.closedRoot) strictFail(parser, \"Unclosed root tag\");\n\t\tif (parser.state !== S.BEGIN && parser.state !== S.BEGIN_WHITESPACE && parser.state !== S.TEXT) error(parser, \"Unexpected end\");\n\t\tcloseText(parser);\n\t\tparser.c = \"\";\n\t\tparser.closed = true;\n\t\temit(parser, \"onend\");\n\t\tSAXParser.call(parser, parser.strict, parser.opt);\n\t\treturn parser;\n\t}\n\tfunction strictFail(parser, message) {\n\t\tif (typeof parser !== \"object\" || !(parser instanceof SAXParser)) throw new Error(\"bad call to strictFail\");\n\t\tif (parser.strict) error(parser, message);\n\t}\n\tfunction newTag(parser) {\n\t\tif (!parser.strict) parser.tagName = parser.tagName[parser.looseCase]();\n\t\tvar parent = parser.tags[parser.tags.length - 1] || parser;\n\t\tvar tag = parser.tag = {\n\t\t\tname: parser.tagName,\n\t\t\tattributes: {}\n\t\t};\n\t\tif (parser.opt.xmlns) tag.ns = parent.ns;\n\t\tparser.attribList.length = 0;\n\t\temitNode(parser, \"onopentagstart\", tag);\n\t}\n\tfunction qname(name, attribute) {\n\t\tvar i = name.indexOf(\":\");\n\t\tvar qualName = i < 0 ? [\"\", name] : name.split(\":\");\n\t\tvar prefix = qualName[0];\n\t\tvar local = qualName[1];\n\t\tif (attribute && name === \"xmlns\") {\n\t\t\tprefix = \"xmlns\";\n\t\t\tlocal = \"\";\n\t\t}\n\t\treturn {\n\t\t\tprefix,\n\t\t\tlocal\n\t\t};\n\t}\n\tfunction attrib(parser) {\n\t\tif (!parser.strict) parser.attribName = parser.attribName[parser.looseCase]();\n\t\tif (parser.attribList.indexOf(parser.attribName) !== -1 || parser.tag.attributes.hasOwnProperty(parser.attribName)) {\n\t\t\tparser.attribName = parser.attribValue = \"\";\n\t\t\treturn;\n\t\t}\n\t\tif (parser.opt.xmlns) {\n\t\t\tvar qn = qname(parser.attribName, true);\n\t\t\tvar prefix = qn.prefix;\n\t\t\tvar local = qn.local;\n\t\t\tif (prefix === \"xmlns\") if (local === \"xml\" && parser.attribValue !== XML_NAMESPACE) strictFail(parser, \"xml: prefix must be bound to \" + XML_NAMESPACE + \"\\nActual: \" + parser.attribValue);\n\t\t\telse if (local === \"xmlns\" && parser.attribValue !== XMLNS_NAMESPACE) strictFail(parser, \"xmlns: prefix must be bound to \" + XMLNS_NAMESPACE + \"\\nActual: \" + parser.attribValue);\n\t\t\telse {\n\t\t\t\tvar tag = parser.tag;\n\t\t\t\tvar parent = parser.tags[parser.tags.length - 1] || parser;\n\t\t\t\tif (tag.ns === parent.ns) tag.ns = Object.create(parent.ns);\n\t\t\t\ttag.ns[local] = parser.attribValue;\n\t\t\t}\n\t\t\tparser.attribList.push([parser.attribName, parser.attribValue]);\n\t\t} else {\n\t\t\tparser.tag.attributes[parser.attribName] = parser.attribValue;\n\t\t\temitNode(parser, \"onattribute\", {\n\t\t\t\tname: parser.attribName,\n\t\t\t\tvalue: parser.attribValue\n\t\t\t});\n\t\t}\n\t\tparser.attribName = parser.attribValue = \"\";\n\t}\n\tfunction openTag(parser, selfClosing) {\n\t\tif (parser.opt.xmlns) {\n\t\t\tvar tag = parser.tag;\n\t\t\tvar qn = qname(parser.tagName);\n\t\t\ttag.prefix = qn.prefix;\n\t\t\ttag.local = qn.local;\n\t\t\ttag.uri = tag.ns[qn.prefix] || \"\";\n\t\t\tif (tag.prefix && !tag.uri) {\n\t\t\t\tstrictFail(parser, \"Unbound namespace prefix: \" + JSON.stringify(parser.tagName));\n\t\t\t\ttag.uri = qn.prefix;\n\t\t\t}\n\t\t\tvar parent = parser.tags[parser.tags.length - 1] || parser;\n\t\t\tif (tag.ns && parent.ns !== tag.ns) Object.keys(tag.ns).forEach(function(p) {\n\t\t\t\temitNode(parser, \"onopennamespace\", {\n\t\t\t\t\tprefix: p,\n\t\t\t\t\turi: tag.ns[p]\n\t\t\t\t});\n\t\t\t});\n\t\t\tfor (var i = 0, l = parser.attribList.length; i < l; i++) {\n\t\t\t\tvar nv = parser.attribList[i];\n\t\t\t\tvar name = nv[0];\n\t\t\t\tvar value = nv[1];\n\t\t\t\tvar qualName = qname(name, true);\n\t\t\t\tvar prefix = qualName.prefix;\n\t\t\t\tvar local = qualName.local;\n\t\t\t\tvar uri = prefix === \"\" ? \"\" : tag.ns[prefix] || \"\";\n\t\t\t\tvar a = {\n\t\t\t\t\tname,\n\t\t\t\t\tvalue,\n\t\t\t\t\tprefix,\n\t\t\t\t\tlocal,\n\t\t\t\t\turi\n\t\t\t\t};\n\t\t\t\tif (prefix && prefix !== \"xmlns\" && !uri) {\n\t\t\t\t\tstrictFail(parser, \"Unbound namespace prefix: \" + JSON.stringify(prefix));\n\t\t\t\t\ta.uri = prefix;\n\t\t\t\t}\n\t\t\t\tparser.tag.attributes[name] = a;\n\t\t\t\temitNode(parser, \"onattribute\", a);\n\t\t\t}\n\t\t\tparser.attribList.length = 0;\n\t\t}\n\t\tparser.tag.isSelfClosing = !!selfClosing;\n\t\tparser.sawRoot = true;\n\t\tparser.tags.push(parser.tag);\n\t\temitNode(parser, \"onopentag\", parser.tag);\n\t\tif (!selfClosing) {\n\t\t\tif (!parser.noscript && parser.tagName.toLowerCase() === \"script\") parser.state = S.SCRIPT;\n\t\t\telse parser.state = S.TEXT;\n\t\t\tparser.tag = null;\n\t\t\tparser.tagName = \"\";\n\t\t}\n\t\tparser.attribName = parser.attribValue = \"\";\n\t\tparser.attribList.length = 0;\n\t}\n\tfunction closeTag(parser) {\n\t\tif (!parser.tagName) {\n\t\t\tstrictFail(parser, \"Weird empty close tag.\");\n\t\t\tparser.textNode += \"</>\";\n\t\t\tparser.state = S.TEXT;\n\t\t\treturn;\n\t\t}\n\t\tif (parser.script) {\n\t\t\tif (parser.tagName !== \"script\") {\n\t\t\t\tparser.script += \"</\" + parser.tagName + \">\";\n\t\t\t\tparser.tagName = \"\";\n\t\t\t\tparser.state = S.SCRIPT;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\temitNode(parser, \"onscript\", parser.script);\n\t\t\tparser.script = \"\";\n\t\t}\n\t\tvar t = parser.tags.length;\n\t\tvar tagName = parser.tagName;\n\t\tif (!parser.strict) tagName = tagName[parser.looseCase]();\n\t\tvar closeTo = tagName;\n\t\twhile (t--) {\n\t\t\tvar close = parser.tags[t];\n\t\t\tif (close.name !== closeTo) strictFail(parser, \"Unexpected close tag\");\n\t\t\telse break;\n\t\t}\n\t\tif (t < 0) {\n\t\t\tstrictFail(parser, \"Unmatched closing tag: \" + parser.tagName);\n\t\t\tparser.textNode += \"</\" + parser.tagName + \">\";\n\t\t\tparser.state = S.TEXT;\n\t\t\treturn;\n\t\t}\n\t\tparser.tagName = tagName;\n\t\tvar s$1 = parser.tags.length;\n\t\twhile (s$1-- > t) {\n\t\t\tvar tag = parser.tag = parser.tags.pop();\n\t\t\tparser.tagName = parser.tag.name;\n\t\t\temitNode(parser, \"onclosetag\", parser.tagName);\n\t\t\tvar x = {};\n\t\t\tfor (var i in tag.ns) x[i] = tag.ns[i];\n\t\t\tvar parent = parser.tags[parser.tags.length - 1] || parser;\n\t\t\tif (parser.opt.xmlns && tag.ns !== parent.ns) Object.keys(tag.ns).forEach(function(p) {\n\t\t\t\tvar n = tag.ns[p];\n\t\t\t\temitNode(parser, \"onclosenamespace\", {\n\t\t\t\t\tprefix: p,\n\t\t\t\t\turi: n\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\t\tif (t === 0) parser.closedRoot = true;\n\t\tparser.tagName = parser.attribValue = parser.attribName = \"\";\n\t\tparser.attribList.length = 0;\n\t\tparser.state = S.TEXT;\n\t}\n\tfunction parseEntity(parser) {\n\t\tvar entity = parser.entity;\n\t\tvar entityLC = entity.toLowerCase();\n\t\tvar num;\n\t\tvar numStr = \"\";\n\t\tif (parser.ENTITIES[entity]) return parser.ENTITIES[entity];\n\t\tif (parser.ENTITIES[entityLC]) return parser.ENTITIES[entityLC];\n\t\tentity = entityLC;\n\t\tif (entity.charAt(0) === \"#\") if (entity.charAt(1) === \"x\") {\n\t\t\tentity = entity.slice(2);\n\t\t\tnum = parseInt(entity, 16);\n\t\t\tnumStr = num.toString(16);\n\t\t} else {\n\t\t\tentity = entity.slice(1);\n\t\t\tnum = parseInt(entity, 10);\n\t\t\tnumStr = num.toString(10);\n\t\t}\n\t\tentity = entity.replace(/^0+/, \"\");\n\t\tif (isNaN(num) || numStr.toLowerCase() !== entity) {\n\t\t\tstrictFail(parser, \"Invalid character entity\");\n\t\t\treturn \"&\" + parser.entity + \";\";\n\t\t}\n\t\treturn String.fromCodePoint(num);\n\t}\n\tfunction beginWhiteSpace(parser, c) {\n\t\tif (c === \"<\") {\n\t\t\tparser.state = S.OPEN_WAKA;\n\t\t\tparser.startTagPosition = parser.position;\n\t\t} else if (!isWhitespace(c)) {\n\t\t\tstrictFail(parser, \"Non-whitespace before first tag.\");\n\t\t\tparser.textNode = c;\n\t\t\tparser.state = S.TEXT;\n\t\t}\n\t}\n\tfunction charAt(chunk, i) {\n\t\tvar result = \"\";\n\t\tif (i < chunk.length) result = chunk.charAt(i);\n\t\treturn result;\n\t}\n\tfunction write(chunk) {\n\t\tvar parser = this;\n\t\tif (this.error) throw this.error;\n\t\tif (parser.closed) return error(parser, \"Cannot write after close. Assign an onready handler.\");\n\t\tif (chunk === null) return end(parser);\n\t\tif (typeof chunk === \"object\") chunk = chunk.toString();\n\t\tvar i = 0;\n\t\tvar c = \"\";\n\t\twhile (true) {\n\t\t\tc = charAt(chunk, i++);\n\t\t\tparser.c = c;\n\t\t\tif (!c) break;\n\t\t\tif (parser.trackPosition) {\n\t\t\t\tparser.position++;\n\t\t\t\tif (c === \"\\n\") {\n\t\t\t\t\tparser.line++;\n\t\t\t\t\tparser.column = 0;\n\t\t\t\t} else parser.column++;\n\t\t\t}\n\t\t\tswitch (parser.state) {\n\t\t\t\tcase S.BEGIN:\n\t\t\t\t\tparser.state = S.BEGIN_WHITESPACE;\n\t\t\t\t\tif (c === \"\") continue;\n\t\t\t\t\tbeginWhiteSpace(parser, c);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.BEGIN_WHITESPACE:\n\t\t\t\t\tbeginWhiteSpace(parser, c);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.TEXT:\n\t\t\t\t\tif (parser.sawRoot && !parser.closedRoot) {\n\t\t\t\t\t\tvar starti = i - 1;\n\t\t\t\t\t\twhile (c && c !== \"<\" && c !== \"&\") {\n\t\t\t\t\t\t\tc = charAt(chunk, i++);\n\t\t\t\t\t\t\tif (c && parser.trackPosition) {\n\t\t\t\t\t\t\t\tparser.position++;\n\t\t\t\t\t\t\t\tif (c === \"\\n\") {\n\t\t\t\t\t\t\t\t\tparser.line++;\n\t\t\t\t\t\t\t\t\tparser.column = 0;\n\t\t\t\t\t\t\t\t} else parser.column++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tparser.textNode += chunk.substring(starti, i - 1);\n\t\t\t\t\t}\n\t\t\t\t\tif (c === \"<\" && !(parser.sawRoot && parser.closedRoot && !parser.strict)) {\n\t\t\t\t\t\tparser.state = S.OPEN_WAKA;\n\t\t\t\t\t\tparser.startTagPosition = parser.position;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (!isWhitespace(c) && (!parser.sawRoot || parser.closedRoot)) strictFail(parser, \"Text data outside of root node.\");\n\t\t\t\t\t\tif (c === \"&\") parser.state = S.TEXT_ENTITY;\n\t\t\t\t\t\telse parser.textNode += c;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.SCRIPT:\n\t\t\t\t\tif (c === \"<\") parser.state = S.SCRIPT_ENDING;\n\t\t\t\t\telse parser.script += c;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.SCRIPT_ENDING:\n\t\t\t\t\tif (c === \"/\") parser.state = S.CLOSE_TAG;\n\t\t\t\t\telse {\n\t\t\t\t\t\tparser.script += \"<\" + c;\n\t\t\t\t\t\tparser.state = S.SCRIPT;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.OPEN_WAKA:\n\t\t\t\t\tif (c === \"!\") {\n\t\t\t\t\t\tparser.state = S.SGML_DECL;\n\t\t\t\t\t\tparser.sgmlDecl = \"\";\n\t\t\t\t\t} else if (isWhitespace(c)) {} else if (isMatch(nameStart, c)) {\n\t\t\t\t\t\tparser.state = S.OPEN_TAG;\n\t\t\t\t\t\tparser.tagName = c;\n\t\t\t\t\t} else if (c === \"/\") {\n\t\t\t\t\t\tparser.state = S.CLOSE_TAG;\n\t\t\t\t\t\tparser.tagName = \"\";\n\t\t\t\t\t} else if (c === \"?\") {\n\t\t\t\t\t\tparser.state = S.PROC_INST;\n\t\t\t\t\t\tparser.procInstName = parser.procInstBody = \"\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstrictFail(parser, \"Unencoded <\");\n\t\t\t\t\t\tif (parser.startTagPosition + 1 < parser.position) {\n\t\t\t\t\t\t\tvar pad = parser.position - parser.startTagPosition;\n\t\t\t\t\t\t\tc = new Array(pad).join(\" \") + c;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tparser.textNode += \"<\" + c;\n\t\t\t\t\t\tparser.state = S.TEXT;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.SGML_DECL:\n\t\t\t\t\tif ((parser.sgmlDecl + c).toUpperCase() === CDATA) {\n\t\t\t\t\t\temitNode(parser, \"onopencdata\");\n\t\t\t\t\t\tparser.state = S.CDATA;\n\t\t\t\t\t\tparser.sgmlDecl = \"\";\n\t\t\t\t\t\tparser.cdata = \"\";\n\t\t\t\t\t} else if (parser.sgmlDecl + c === \"--\") {\n\t\t\t\t\t\tparser.state = S.COMMENT;\n\t\t\t\t\t\tparser.comment = \"\";\n\t\t\t\t\t\tparser.sgmlDecl = \"\";\n\t\t\t\t\t} else if ((parser.sgmlDecl + c).toUpperCase() === DOCTYPE) {\n\t\t\t\t\t\tparser.state = S.DOCTYPE;\n\t\t\t\t\t\tif (parser.doctype || parser.sawRoot) strictFail(parser, \"Inappropriately located doctype declaration\");\n\t\t\t\t\t\tparser.doctype = \"\";\n\t\t\t\t\t\tparser.sgmlDecl = \"\";\n\t\t\t\t\t} else if (c === \">\") {\n\t\t\t\t\t\temitNode(parser, \"onsgmldeclaration\", parser.sgmlDecl);\n\t\t\t\t\t\tparser.sgmlDecl = \"\";\n\t\t\t\t\t\tparser.state = S.TEXT;\n\t\t\t\t\t} else if (isQuote(c)) {\n\t\t\t\t\t\tparser.state = S.SGML_DECL_QUOTED;\n\t\t\t\t\t\tparser.sgmlDecl += c;\n\t\t\t\t\t} else parser.sgmlDecl += c;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.SGML_DECL_QUOTED:\n\t\t\t\t\tif (c === parser.q) {\n\t\t\t\t\t\tparser.state = S.SGML_DECL;\n\t\t\t\t\t\tparser.q = \"\";\n\t\t\t\t\t}\n\t\t\t\t\tparser.sgmlDecl += c;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.DOCTYPE:\n\t\t\t\t\tif (c === \">\") {\n\t\t\t\t\t\tparser.state = S.TEXT;\n\t\t\t\t\t\temitNode(parser, \"ondoctype\", parser.doctype);\n\t\t\t\t\t\tparser.doctype = true;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tparser.doctype += c;\n\t\t\t\t\t\tif (c === \"[\") parser.state = S.DOCTYPE_DTD;\n\t\t\t\t\t\telse if (isQuote(c)) {\n\t\t\t\t\t\t\tparser.state = S.DOCTYPE_QUOTED;\n\t\t\t\t\t\t\tparser.q = c;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.DOCTYPE_QUOTED:\n\t\t\t\t\tparser.doctype += c;\n\t\t\t\t\tif (c === parser.q) {\n\t\t\t\t\t\tparser.q = \"\";\n\t\t\t\t\t\tparser.state = S.DOCTYPE;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.DOCTYPE_DTD:\n\t\t\t\t\tparser.doctype += c;\n\t\t\t\t\tif (c === \"]\") parser.state = S.DOCTYPE;\n\t\t\t\t\telse if (isQuote(c)) {\n\t\t\t\t\t\tparser.state = S.DOCTYPE_DTD_QUOTED;\n\t\t\t\t\t\tparser.q = c;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.DOCTYPE_DTD_QUOTED:\n\t\t\t\t\tparser.doctype += c;\n\t\t\t\t\tif (c === parser.q) {\n\t\t\t\t\t\tparser.state = S.DOCTYPE_DTD;\n\t\t\t\t\t\tparser.q = \"\";\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.COMMENT:\n\t\t\t\t\tif (c === \"-\") parser.state = S.COMMENT_ENDING;\n\t\t\t\t\telse parser.comment += c;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.COMMENT_ENDING:\n\t\t\t\t\tif (c === \"-\") {\n\t\t\t\t\t\tparser.state = S.COMMENT_ENDED;\n\t\t\t\t\t\tparser.comment = textopts(parser.opt, parser.comment);\n\t\t\t\t\t\tif (parser.comment) emitNode(parser, \"oncomment\", parser.comment);\n\t\t\t\t\t\tparser.comment = \"\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\tparser.comment += \"-\" + c;\n\t\t\t\t\t\tparser.state = S.COMMENT;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.COMMENT_ENDED:\n\t\t\t\t\tif (c !== \">\") {\n\t\t\t\t\t\tstrictFail(parser, \"Malformed comment\");\n\t\t\t\t\t\tparser.comment += \"--\" + c;\n\t\t\t\t\t\tparser.state = S.COMMENT;\n\t\t\t\t\t} else parser.state = S.TEXT;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.CDATA:\n\t\t\t\t\tif (c === \"]\") parser.state = S.CDATA_ENDING;\n\t\t\t\t\telse parser.cdata += c;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.CDATA_ENDING:\n\t\t\t\t\tif (c === \"]\") parser.state = S.CDATA_ENDING_2;\n\t\t\t\t\telse {\n\t\t\t\t\t\tparser.cdata += \"]\" + c;\n\t\t\t\t\t\tparser.state = S.CDATA;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.CDATA_ENDING_2:\n\t\t\t\t\tif (c === \">\") {\n\t\t\t\t\t\tif (parser.cdata) emitNode(parser, \"oncdata\", parser.cdata);\n\t\t\t\t\t\temitNode(parser, \"onclosecdata\");\n\t\t\t\t\t\tparser.cdata = \"\";\n\t\t\t\t\t\tparser.state = S.TEXT;\n\t\t\t\t\t} else if (c === \"]\") parser.cdata += \"]\";\n\t\t\t\t\telse {\n\t\t\t\t\t\tparser.cdata += \"]]\" + c;\n\t\t\t\t\t\tparser.state = S.CDATA;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.PROC_INST:\n\t\t\t\t\tif (c === \"?\") parser.state = S.PROC_INST_ENDING;\n\t\t\t\t\telse if (isWhitespace(c)) parser.state = S.PROC_INST_BODY;\n\t\t\t\t\telse parser.procInstName += c;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.PROC_INST_BODY:\n\t\t\t\t\tif (!parser.procInstBody && isWhitespace(c)) continue;\n\t\t\t\t\telse if (c === \"?\") parser.state = S.PROC_INST_ENDING;\n\t\t\t\t\telse parser.procInstBody += c;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.PROC_INST_ENDING:\n\t\t\t\t\tif (c === \">\") {\n\t\t\t\t\t\temitNode(parser, \"onprocessinginstruction\", {\n\t\t\t\t\t\t\tname: parser.procInstName,\n\t\t\t\t\t\t\tbody: parser.procInstBody\n\t\t\t\t\t\t});\n\t\t\t\t\t\tparser.procInstName = parser.procInstBody = \"\";\n\t\t\t\t\t\tparser.state = S.TEXT;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tparser.procInstBody += \"?\" + c;\n\t\t\t\t\t\tparser.state = S.PROC_INST_BODY;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.OPEN_TAG:\n\t\t\t\t\tif (isMatch(nameBody, c)) parser.tagName += c;\n\t\t\t\t\telse {\n\t\t\t\t\t\tnewTag(parser);\n\t\t\t\t\t\tif (c === \">\") openTag(parser);\n\t\t\t\t\t\telse if (c === \"/\") parser.state = S.OPEN_TAG_SLASH;\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tif (!isWhitespace(c)) strictFail(parser, \"Invalid character in tag name\");\n\t\t\t\t\t\t\tparser.state = S.ATTRIB;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.OPEN_TAG_SLASH:\n\t\t\t\t\tif (c === \">\") {\n\t\t\t\t\t\topenTag(parser, true);\n\t\t\t\t\t\tcloseTag(parser);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstrictFail(parser, \"Forward-slash in opening tag not followed by >\");\n\t\t\t\t\t\tparser.state = S.ATTRIB;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.ATTRIB:\n\t\t\t\t\tif (isWhitespace(c)) continue;\n\t\t\t\t\telse if (c === \">\") openTag(parser);\n\t\t\t\t\telse if (c === \"/\") parser.state = S.OPEN_TAG_SLASH;\n\t\t\t\t\telse if (isMatch(nameStart, c)) {\n\t\t\t\t\t\tparser.attribName = c;\n\t\t\t\t\t\tparser.attribValue = \"\";\n\t\t\t\t\t\tparser.state = S.ATTRIB_NAME;\n\t\t\t\t\t} else strictFail(parser, \"Invalid attribute name\");\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.ATTRIB_NAME:\n\t\t\t\t\tif (c === \"=\") parser.state = S.ATTRIB_VALUE;\n\t\t\t\t\telse if (c === \">\") {\n\t\t\t\t\t\tstrictFail(parser, \"Attribute without value\");\n\t\t\t\t\t\tparser.attribValue = parser.attribName;\n\t\t\t\t\t\tattrib(parser);\n\t\t\t\t\t\topenTag(parser);\n\t\t\t\t\t} else if (isWhitespace(c)) parser.state = S.ATTRIB_NAME_SAW_WHITE;\n\t\t\t\t\telse if (isMatch(nameBody, c)) parser.attribName += c;\n\t\t\t\t\telse strictFail(parser, \"Invalid attribute name\");\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.ATTRIB_NAME_SAW_WHITE:\n\t\t\t\t\tif (c === \"=\") parser.state = S.ATTRIB_VALUE;\n\t\t\t\t\telse if (isWhitespace(c)) continue;\n\t\t\t\t\telse {\n\t\t\t\t\t\tstrictFail(parser, \"Attribute without value\");\n\t\t\t\t\t\tparser.tag.attributes[parser.attribName] = \"\";\n\t\t\t\t\t\tparser.attribValue = \"\";\n\t\t\t\t\t\temitNode(parser, \"onattribute\", {\n\t\t\t\t\t\t\tname: parser.attribName,\n\t\t\t\t\t\t\tvalue: \"\"\n\t\t\t\t\t\t});\n\t\t\t\t\t\tparser.attribName = \"\";\n\t\t\t\t\t\tif (c === \">\") openTag(parser);\n\t\t\t\t\t\telse if (isMatch(nameStart, c)) {\n\t\t\t\t\t\t\tparser.attribName = c;\n\t\t\t\t\t\t\tparser.state = S.ATTRIB_NAME;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrictFail(parser, \"Invalid attribute name\");\n\t\t\t\t\t\t\tparser.state = S.ATTRIB;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.ATTRIB_VALUE:\n\t\t\t\t\tif (isWhitespace(c)) continue;\n\t\t\t\t\telse if (isQuote(c)) {\n\t\t\t\t\t\tparser.q = c;\n\t\t\t\t\t\tparser.state = S.ATTRIB_VALUE_QUOTED;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstrictFail(parser, \"Unquoted attribute value\");\n\t\t\t\t\t\tparser.state = S.ATTRIB_VALUE_UNQUOTED;\n\t\t\t\t\t\tparser.attribValue = c;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.ATTRIB_VALUE_QUOTED:\n\t\t\t\t\tif (c !== parser.q) {\n\t\t\t\t\t\tif (c === \"&\") parser.state = S.ATTRIB_VALUE_ENTITY_Q;\n\t\t\t\t\t\telse parser.attribValue += c;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tattrib(parser);\n\t\t\t\t\tparser.q = \"\";\n\t\t\t\t\tparser.state = S.ATTRIB_VALUE_CLOSED;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.ATTRIB_VALUE_CLOSED:\n\t\t\t\t\tif (isWhitespace(c)) parser.state = S.ATTRIB;\n\t\t\t\t\telse if (c === \">\") openTag(parser);\n\t\t\t\t\telse if (c === \"/\") parser.state = S.OPEN_TAG_SLASH;\n\t\t\t\t\telse if (isMatch(nameStart, c)) {\n\t\t\t\t\t\tstrictFail(parser, \"No whitespace between attributes\");\n\t\t\t\t\t\tparser.attribName = c;\n\t\t\t\t\t\tparser.attribValue = \"\";\n\t\t\t\t\t\tparser.state = S.ATTRIB_NAME;\n\t\t\t\t\t} else strictFail(parser, \"Invalid attribute name\");\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.ATTRIB_VALUE_UNQUOTED:\n\t\t\t\t\tif (!isAttribEnd(c)) {\n\t\t\t\t\t\tif (c === \"&\") parser.state = S.ATTRIB_VALUE_ENTITY_U;\n\t\t\t\t\t\telse parser.attribValue += c;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tattrib(parser);\n\t\t\t\t\tif (c === \">\") openTag(parser);\n\t\t\t\t\telse parser.state = S.ATTRIB;\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.CLOSE_TAG:\n\t\t\t\t\tif (!parser.tagName) if (isWhitespace(c)) continue;\n\t\t\t\t\telse if (notMatch(nameStart, c)) if (parser.script) {\n\t\t\t\t\t\tparser.script += \"</\" + c;\n\t\t\t\t\t\tparser.state = S.SCRIPT;\n\t\t\t\t\t} else strictFail(parser, \"Invalid tagname in closing tag.\");\n\t\t\t\t\telse parser.tagName = c;\n\t\t\t\t\telse if (c === \">\") closeTag(parser);\n\t\t\t\t\telse if (isMatch(nameBody, c)) parser.tagName += c;\n\t\t\t\t\telse if (parser.script) {\n\t\t\t\t\t\tparser.script += \"</\" + parser.tagName;\n\t\t\t\t\t\tparser.tagName = \"\";\n\t\t\t\t\t\tparser.state = S.SCRIPT;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (!isWhitespace(c)) strictFail(parser, \"Invalid tagname in closing tag\");\n\t\t\t\t\t\tparser.state = S.CLOSE_TAG_SAW_WHITE;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.CLOSE_TAG_SAW_WHITE:\n\t\t\t\t\tif (isWhitespace(c)) continue;\n\t\t\t\t\tif (c === \">\") closeTag(parser);\n\t\t\t\t\telse strictFail(parser, \"Invalid characters in closing tag\");\n\t\t\t\t\tcontinue;\n\t\t\t\tcase S.TEXT_ENTITY:\n\t\t\t\tcase S.ATTRIB_VALUE_ENTITY_Q:\n\t\t\t\tcase S.ATTRIB_VALUE_ENTITY_U:\n\t\t\t\t\tvar returnState;\n\t\t\t\t\tvar buffer;\n\t\t\t\t\tswitch (parser.state) {\n\t\t\t\t\t\tcase S.TEXT_ENTITY:\n\t\t\t\t\t\t\treturnState = S.TEXT;\n\t\t\t\t\t\t\tbuffer = \"textNode\";\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase S.ATTRIB_VALUE_ENTITY_Q:\n\t\t\t\t\t\t\treturnState = S.ATTRIB_VALUE_QUOTED;\n\t\t\t\t\t\t\tbuffer = \"attribValue\";\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase S.ATTRIB_VALUE_ENTITY_U:\n\t\t\t\t\t\t\treturnState = S.ATTRIB_VALUE_UNQUOTED;\n\t\t\t\t\t\t\tbuffer = \"attribValue\";\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif (c === \";\") if (parser.opt.unparsedEntities) {\n\t\t\t\t\t\tvar parsedEntity = parseEntity(parser);\n\t\t\t\t\t\tparser.entity = \"\";\n\t\t\t\t\t\tparser.state = returnState;\n\t\t\t\t\t\tparser.write(parsedEntity);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tparser[buffer] += parseEntity(parser);\n\t\t\t\t\t\tparser.entity = \"\";\n\t\t\t\t\t\tparser.state = returnState;\n\t\t\t\t\t}\n\t\t\t\t\telse if (isMatch(parser.entity.length ? entityBody : entityStart, c)) parser.entity += c;\n\t\t\t\t\telse {\n\t\t\t\t\t\tstrictFail(parser, \"Invalid character in entity name\");\n\t\t\t\t\t\tparser[buffer] += \"&\" + parser.entity + c;\n\t\t\t\t\t\tparser.entity = \"\";\n\t\t\t\t\t\tparser.state = returnState;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\tdefault: throw new Error(parser, \"Unknown state: \" + parser.state);\n\t\t\t}\n\t\t}\n\t\tif (parser.position >= parser.bufferCheckPosition) checkBufferLength(parser);\n\t\treturn parser;\n\t}\n\t/*! http://mths.be/fromcodepoint v0.1.0 by @mathias */\n\t/* istanbul ignore next */\n\tif (!String.fromCodePoint) (function() {\n\t\tvar stringFromCharCode = String.fromCharCode;\n\t\tvar floor = Math.floor;\n\t\tvar fromCodePoint = function() {\n\t\t\tvar MAX_SIZE = 16384;\n\t\t\tvar codeUnits = [];\n\t\t\tvar highSurrogate;\n\t\t\tvar lowSurrogate;\n\t\t\tvar index = -1;\n\t\t\tvar length = arguments.length;\n\t\t\tif (!length) return \"\";\n\t\t\tvar result = \"\";\n\t\t\twhile (++index < length) {\n\t\t\t\tvar codePoint = Number(arguments[index]);\n\t\t\t\tif (!isFinite(codePoint) || codePoint < 0 || codePoint > 1114111 || floor(codePoint) !== codePoint) throw RangeError(\"Invalid code point: \" + codePoint);\n\t\t\t\tif (codePoint <= 65535) codeUnits.push(codePoint);\n\t\t\t\telse {\n\t\t\t\t\tcodePoint -= 65536;\n\t\t\t\t\thighSurrogate = (codePoint >> 10) + 55296;\n\t\t\t\t\tlowSurrogate = codePoint % 1024 + 56320;\n\t\t\t\t\tcodeUnits.push(highSurrogate, lowSurrogate);\n\t\t\t\t}\n\t\t\t\tif (index + 1 === length || codeUnits.length > MAX_SIZE) {\n\t\t\t\t\tresult += stringFromCharCode.apply(null, codeUnits);\n\t\t\t\t\tcodeUnits.length = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t};\n\t\t/* istanbul ignore next */\n\t\tif (Object.defineProperty) Object.defineProperty(String, \"fromCodePoint\", {\n\t\t\tvalue: fromCodePoint,\n\t\t\tconfigurable: true,\n\t\t\twritable: true\n\t\t});\n\t\telse String.fromCodePoint = fromCodePoint;\n\t})();\n\treturn sax$1;\n};\nconst sax = initializeSax();\n\n//#endregion\nexport { sax };\n//# sourceMappingURL=sax.js.map","import { compare } from \"../utils/fast-json-patch/src/duplex.js\";\nimport { BaseCumulativeTransformOutputParser } from \"./transform.js\";\nimport \"../utils/json_patch.js\";\nimport { sax } from \"../utils/sax-js/sax.js\";\n\n//#region src/output_parsers/xml.ts\nconst XML_FORMAT_INSTRUCTIONS = `The output should be formatted as a XML file.\n1. Output should conform to the tags below. \n2. If tags are not given, make them on your own.\n3. Remember to always open and close all the tags.\n\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema. \n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\n\nHere are the output tags:\n\\`\\`\\`\n{tags}\n\\`\\`\\``;\nvar XMLOutputParser = class extends BaseCumulativeTransformOutputParser {\n\ttags;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.tags = fields?.tags;\n\t}\n\tstatic lc_name() {\n\t\treturn \"XMLOutputParser\";\n\t}\n\tlc_namespace = [\"langchain_core\", \"output_parsers\"];\n\tlc_serializable = true;\n\t_diff(prev, next) {\n\t\tif (!next) return void 0;\n\t\tif (!prev) return [{\n\t\t\top: \"replace\",\n\t\t\tpath: \"\",\n\t\t\tvalue: next\n\t\t}];\n\t\treturn compare(prev, next);\n\t}\n\tasync parsePartialResult(generations) {\n\t\treturn parseXMLMarkdown(generations[0].text);\n\t}\n\tasync parse(text) {\n\t\treturn parseXMLMarkdown(text);\n\t}\n\tgetFormatInstructions() {\n\t\tconst withTags = !!(this.tags && this.tags.length > 0);\n\t\treturn withTags ? XML_FORMAT_INSTRUCTIONS.replace(\"{tags}\", this.tags?.join(\", \") ?? \"\") : XML_FORMAT_INSTRUCTIONS;\n\t}\n};\nconst strip = (text) => text.split(\"\\n\").map((line) => line.replace(/^\\s+/, \"\")).join(\"\\n\").trim();\nconst parseParsedResult = (input) => {\n\tif (Object.keys(input).length === 0) return {};\n\tconst result = {};\n\tif (input.children.length > 0) {\n\t\tresult[input.name] = input.children.map(parseParsedResult);\n\t\treturn result;\n\t} else {\n\t\tresult[input.name] = input.text ?? void 0;\n\t\treturn result;\n\t}\n};\nfunction parseXMLMarkdown(s) {\n\tconst cleanedString = strip(s);\n\tconst parser = sax.parser(true);\n\tlet parsedResult = {};\n\tconst elementStack = [];\n\tparser.onopentag = (node) => {\n\t\tconst element = {\n\t\t\tname: node.name,\n\t\t\tattributes: node.attributes,\n\t\t\tchildren: [],\n\t\t\ttext: \"\",\n\t\t\tisSelfClosing: node.isSelfClosing\n\t\t};\n\t\tif (elementStack.length > 0) {\n\t\t\tconst parentElement = elementStack[elementStack.length - 1];\n\t\t\tparentElement.children.push(element);\n\t\t} else parsedResult = element;\n\t\tif (!node.isSelfClosing) elementStack.push(element);\n\t};\n\tparser.onclosetag = () => {\n\t\tif (elementStack.length > 0) {\n\t\t\tconst lastElement = elementStack.pop();\n\t\t\tif (elementStack.length === 0 && lastElement) parsedResult = lastElement;\n\t\t}\n\t};\n\tparser.ontext = (text) => {\n\t\tif (elementStack.length > 0) {\n\t\t\tconst currentElement = elementStack[elementStack.length - 1];\n\t\t\tcurrentElement.text += text;\n\t\t}\n\t};\n\tparser.onattribute = (attr) => {\n\t\tif (elementStack.length > 0) {\n\t\t\tconst currentElement = elementStack[elementStack.length - 1];\n\t\t\tcurrentElement.attributes[attr.name] = attr.value;\n\t\t}\n\t};\n\tconst match = /```(xml)?(.*)```/s.exec(cleanedString);\n\tconst xmlString = match ? match[2] : cleanedString;\n\tparser.write(xmlString).close();\n\tif (parsedResult && parsedResult.name === \"?xml\") parsedResult = parsedResult.children[0];\n\treturn parseParsedResult(parsedResult);\n}\n\n//#endregion\nexport { XMLOutputParser, XML_FORMAT_INSTRUCTIONS, parseXMLMarkdown };\n//# sourceMappingURL=xml.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { parseJsonMarkdown, parsePartialJson } from \"../utils/json.js\";\nimport { BaseLLMOutputParser, BaseOutputParser, OutputParserException } from \"./base.js\";\nimport { BaseCumulativeTransformOutputParser, BaseTransformOutputParser } from \"./transform.js\";\nimport { BytesOutputParser } from \"./bytes.js\";\nimport { CommaSeparatedListOutputParser, CustomListOutputParser, ListOutputParser, MarkdownListOutputParser, NumberedListOutputParser } from \"./list.js\";\nimport { StringOutputParser } from \"./string.js\";\nimport { AsymmetricStructuredOutputParser, JsonMarkdownStructuredOutputParser, StructuredOutputParser } from \"./structured.js\";\nimport { JsonOutputParser } from \"./json.js\";\nimport { XMLOutputParser, XML_FORMAT_INSTRUCTIONS, parseXMLMarkdown } from \"./xml.js\";\n\n//#region src/output_parsers/index.ts\nvar output_parsers_exports = {};\n__export(output_parsers_exports, {\n\tAsymmetricStructuredOutputParser: () => AsymmetricStructuredOutputParser,\n\tBaseCumulativeTransformOutputParser: () => BaseCumulativeTransformOutputParser,\n\tBaseLLMOutputParser: () => BaseLLMOutputParser,\n\tBaseOutputParser: () => BaseOutputParser,\n\tBaseTransformOutputParser: () => BaseTransformOutputParser,\n\tBytesOutputParser: () => BytesOutputParser,\n\tCommaSeparatedListOutputParser: () => CommaSeparatedListOutputParser,\n\tCustomListOutputParser: () => CustomListOutputParser,\n\tJsonMarkdownStructuredOutputParser: () => JsonMarkdownStructuredOutputParser,\n\tJsonOutputParser: () => JsonOutputParser,\n\tListOutputParser: () => ListOutputParser,\n\tMarkdownListOutputParser: () => MarkdownListOutputParser,\n\tNumberedListOutputParser: () => NumberedListOutputParser,\n\tOutputParserException: () => OutputParserException,\n\tStringOutputParser: () => StringOutputParser,\n\tStructuredOutputParser: () => StructuredOutputParser,\n\tXMLOutputParser: () => XMLOutputParser,\n\tXML_FORMAT_INSTRUCTIONS: () => XML_FORMAT_INSTRUCTIONS,\n\tparseJsonMarkdown: () => parseJsonMarkdown,\n\tparsePartialJson: () => parsePartialJson,\n\tparseXMLMarkdown: () => parseXMLMarkdown\n});\n\n//#endregion\nexport { AsymmetricStructuredOutputParser, BaseCumulativeTransformOutputParser, BaseLLMOutputParser, BaseOutputParser, BaseTransformOutputParser, BytesOutputParser, CommaSeparatedListOutputParser, CustomListOutputParser, JsonMarkdownStructuredOutputParser, JsonOutputParser, ListOutputParser, MarkdownListOutputParser, NumberedListOutputParser, OutputParserException, StringOutputParser, StructuredOutputParser, XMLOutputParser, XML_FORMAT_INSTRUCTIONS, output_parsers_exports, parseJsonMarkdown, parsePartialJson, parseXMLMarkdown };\n//# sourceMappingURL=index.js.map","import { parsePartialJson } from \"../../utils/json.js\";\nimport { isAIMessage } from \"../../messages/ai.js\";\nimport { interopSafeParseAsync } from \"../../utils/types/zod.js\";\nimport { OutputParserException } from \"../base.js\";\nimport { BaseCumulativeTransformOutputParser } from \"../transform.js\";\nimport \"../json.js\";\n\n//#region src/output_parsers/openai_tools/json_output_tools_parsers.ts\nfunction parseToolCall(rawToolCall, options) {\n\tif (rawToolCall.function === void 0) return void 0;\n\tlet functionArgs;\n\tif (options?.partial) try {\n\t\tfunctionArgs = parsePartialJson(rawToolCall.function.arguments ?? \"{}\");\n\t} catch {\n\t\treturn void 0;\n\t}\n\telse try {\n\t\tfunctionArgs = JSON.parse(rawToolCall.function.arguments);\n\t} catch (e) {\n\t\tthrow new OutputParserException([\n\t\t\t`Function \"${rawToolCall.function.name}\" arguments:`,\n\t\t\t``,\n\t\t\trawToolCall.function.arguments,\n\t\t\t``,\n\t\t\t`are not valid JSON.`,\n\t\t\t`Error: ${e.message}`\n\t\t].join(\"\\n\"));\n\t}\n\tconst parsedToolCall = {\n\t\tname: rawToolCall.function.name,\n\t\targs: functionArgs,\n\t\ttype: \"tool_call\"\n\t};\n\tif (options?.returnId) parsedToolCall.id = rawToolCall.id;\n\treturn parsedToolCall;\n}\nfunction convertLangChainToolCallToOpenAI(toolCall) {\n\tif (toolCall.id === void 0) throw new Error(`All OpenAI tool calls must have an \"id\" field.`);\n\treturn {\n\t\tid: toolCall.id,\n\t\ttype: \"function\",\n\t\tfunction: {\n\t\t\tname: toolCall.name,\n\t\t\targuments: JSON.stringify(toolCall.args)\n\t\t}\n\t};\n}\nfunction makeInvalidToolCall(rawToolCall, errorMsg) {\n\treturn {\n\t\tname: rawToolCall.function?.name,\n\t\targs: rawToolCall.function?.arguments,\n\t\tid: rawToolCall.id,\n\t\terror: errorMsg,\n\t\ttype: \"invalid_tool_call\"\n\t};\n}\n/**\n* Class for parsing the output of a tool-calling LLM into a JSON object.\n*/\nvar JsonOutputToolsParser = class extends BaseCumulativeTransformOutputParser {\n\tstatic lc_name() {\n\t\treturn \"JsonOutputToolsParser\";\n\t}\n\treturnId = false;\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"output_parsers\",\n\t\t\"openai_tools\"\n\t];\n\tlc_serializable = true;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.returnId = fields?.returnId ?? this.returnId;\n\t}\n\t_diff() {\n\t\tthrow new Error(\"Not supported.\");\n\t}\n\tasync parse() {\n\t\tthrow new Error(\"Not implemented.\");\n\t}\n\tasync parseResult(generations) {\n\t\tconst result = await this.parsePartialResult(generations, false);\n\t\treturn result;\n\t}\n\t/**\n\t* Parses the output and returns a JSON object. If `argsOnly` is true,\n\t* only the arguments of the function call are returned.\n\t* @param generations The output of the LLM to parse.\n\t* @returns A JSON object representation of the function call or its arguments.\n\t*/\n\tasync parsePartialResult(generations, partial = true) {\n\t\tconst message = generations[0].message;\n\t\tlet toolCalls;\n\t\tif (isAIMessage(message) && message.tool_calls?.length) toolCalls = message.tool_calls.map((toolCall) => {\n\t\t\tconst { id,...rest } = toolCall;\n\t\t\tif (!this.returnId) return rest;\n\t\t\treturn {\n\t\t\t\tid,\n\t\t\t\t...rest\n\t\t\t};\n\t\t});\n\t\telse if (message.additional_kwargs.tool_calls !== void 0) {\n\t\t\tconst rawToolCalls = JSON.parse(JSON.stringify(message.additional_kwargs.tool_calls));\n\t\t\ttoolCalls = rawToolCalls.map((rawToolCall) => {\n\t\t\t\treturn parseToolCall(rawToolCall, {\n\t\t\t\t\treturnId: this.returnId,\n\t\t\t\t\tpartial\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\t\tif (!toolCalls) return [];\n\t\tconst parsedToolCalls = [];\n\t\tfor (const toolCall of toolCalls) if (toolCall !== void 0) {\n\t\t\tconst backwardsCompatibleToolCall = {\n\t\t\t\ttype: toolCall.name,\n\t\t\t\targs: toolCall.args,\n\t\t\t\tid: toolCall.id\n\t\t\t};\n\t\t\tparsedToolCalls.push(backwardsCompatibleToolCall);\n\t\t}\n\t\treturn parsedToolCalls;\n\t}\n};\n/**\n* Class for parsing the output of a tool-calling LLM into a JSON object if you are\n* expecting only a single tool to be called.\n*/\nvar JsonOutputKeyToolsParser = class extends JsonOutputToolsParser {\n\tstatic lc_name() {\n\t\treturn \"JsonOutputKeyToolsParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"output_parsers\",\n\t\t\"openai_tools\"\n\t];\n\tlc_serializable = true;\n\treturnId = false;\n\t/** The type of tool calls to return. */\n\tkeyName;\n\t/** Whether to return only the first tool call. */\n\treturnSingle = false;\n\tzodSchema;\n\tconstructor(params) {\n\t\tsuper(params);\n\t\tthis.keyName = params.keyName;\n\t\tthis.returnSingle = params.returnSingle ?? this.returnSingle;\n\t\tthis.zodSchema = params.zodSchema;\n\t}\n\tasync _validateResult(result) {\n\t\tif (this.zodSchema === void 0) return result;\n\t\tconst zodParsedResult = await interopSafeParseAsync(this.zodSchema, result);\n\t\tif (zodParsedResult.success) return zodParsedResult.data;\n\t\telse throw new OutputParserException(`Failed to parse. Text: \"${JSON.stringify(result, null, 2)}\". Error: ${JSON.stringify(zodParsedResult.error?.issues)}`, JSON.stringify(result, null, 2));\n\t}\n\tasync parsePartialResult(generations) {\n\t\tconst results = await super.parsePartialResult(generations);\n\t\tconst matchingResults = results.filter((result) => result.type === this.keyName);\n\t\tlet returnedValues = matchingResults;\n\t\tif (!matchingResults.length) return void 0;\n\t\tif (!this.returnId) returnedValues = matchingResults.map((result) => result.args);\n\t\tif (this.returnSingle) return returnedValues[0];\n\t\treturn returnedValues;\n\t}\n\tasync parseResult(generations) {\n\t\tconst results = await super.parsePartialResult(generations, false);\n\t\tconst matchingResults = results.filter((result) => result.type === this.keyName);\n\t\tlet returnedValues = matchingResults;\n\t\tif (!matchingResults.length) return void 0;\n\t\tif (!this.returnId) returnedValues = matchingResults.map((result) => result.args);\n\t\tif (this.returnSingle) return this._validateResult(returnedValues[0]);\n\t\tconst toolCallResults = await Promise.all(returnedValues.map((value) => this._validateResult(value)));\n\t\treturn toolCallResults;\n\t}\n};\n\n//#endregion\nexport { JsonOutputKeyToolsParser, JsonOutputToolsParser, convertLangChainToolCallToOpenAI, makeInvalidToolCall, parseToolCall };\n//# sourceMappingURL=json_output_tools_parsers.js.map","import { __export } from \"../../_virtual/rolldown_runtime.js\";\nimport { JsonOutputKeyToolsParser, JsonOutputToolsParser, convertLangChainToolCallToOpenAI, makeInvalidToolCall, parseToolCall } from \"./json_output_tools_parsers.js\";\n\n//#region src/output_parsers/openai_tools/index.ts\nvar openai_tools_exports = {};\n__export(openai_tools_exports, {\n\tJsonOutputKeyToolsParser: () => JsonOutputKeyToolsParser,\n\tJsonOutputToolsParser: () => JsonOutputToolsParser,\n\tconvertLangChainToolCallToOpenAI: () => convertLangChainToolCallToOpenAI,\n\tmakeInvalidToolCall: () => makeInvalidToolCall,\n\tparseToolCall: () => parseToolCall\n});\n\n//#endregion\nexport { JsonOutputKeyToolsParser, JsonOutputToolsParser, convertLangChainToolCallToOpenAI, makeInvalidToolCall, openai_tools_exports, parseToolCall };\n//# sourceMappingURL=index.js.map","import { parsePartialJson } from \"../../utils/json.js\";\nimport { compare } from \"../../utils/fast-json-patch/src/duplex.js\";\nimport { BaseLLMOutputParser } from \"../base.js\";\nimport { BaseCumulativeTransformOutputParser } from \"../transform.js\";\nimport \"../../utils/json_patch.js\";\nimport \"../json.js\";\n\n//#region src/output_parsers/openai_functions/json_output_functions_parsers.ts\n/**\n* Class for parsing the output of an LLM. Can be configured to return\n* only the arguments of the function call in the output.\n*/\nvar OutputFunctionsParser = class extends BaseLLMOutputParser {\n\tstatic lc_name() {\n\t\treturn \"OutputFunctionsParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"output_parsers\",\n\t\t\"openai_functions\"\n\t];\n\tlc_serializable = true;\n\targsOnly = true;\n\tconstructor(config) {\n\t\tsuper();\n\t\tthis.argsOnly = config?.argsOnly ?? this.argsOnly;\n\t}\n\t/**\n\t* Parses the output and returns a string representation of the function\n\t* call or its arguments.\n\t* @param generations The output of the LLM to parse.\n\t* @returns A string representation of the function call or its arguments.\n\t*/\n\tasync parseResult(generations) {\n\t\tif (\"message\" in generations[0]) {\n\t\t\tconst gen = generations[0];\n\t\t\tconst functionCall = gen.message.additional_kwargs.function_call;\n\t\t\tif (!functionCall) throw new Error(`No function_call in message ${JSON.stringify(generations)}`);\n\t\t\tif (!functionCall.arguments) throw new Error(`No arguments in function_call ${JSON.stringify(generations)}`);\n\t\t\tif (this.argsOnly) return functionCall.arguments;\n\t\t\treturn JSON.stringify(functionCall);\n\t\t} else throw new Error(`No message in generations ${JSON.stringify(generations)}`);\n\t}\n};\n/**\n* Class for parsing the output of an LLM into a JSON object. Uses an\n* instance of `OutputFunctionsParser` to parse the output.\n*/\nvar JsonOutputFunctionsParser = class extends BaseCumulativeTransformOutputParser {\n\tstatic lc_name() {\n\t\treturn \"JsonOutputFunctionsParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"output_parsers\",\n\t\t\"openai_functions\"\n\t];\n\tlc_serializable = true;\n\toutputParser;\n\targsOnly = true;\n\tconstructor(config) {\n\t\tsuper(config);\n\t\tthis.argsOnly = config?.argsOnly ?? this.argsOnly;\n\t\tthis.outputParser = new OutputFunctionsParser(config);\n\t}\n\t_diff(prev, next) {\n\t\tif (!next) return void 0;\n\t\tconst ops = compare(prev ?? {}, next);\n\t\treturn ops;\n\t}\n\tasync parsePartialResult(generations) {\n\t\tconst generation = generations[0];\n\t\tif (!generation.message) return void 0;\n\t\tconst { message } = generation;\n\t\tconst functionCall = message.additional_kwargs.function_call;\n\t\tif (!functionCall) return void 0;\n\t\tif (this.argsOnly) return parsePartialJson(functionCall.arguments);\n\t\treturn {\n\t\t\t...functionCall,\n\t\t\targuments: parsePartialJson(functionCall.arguments)\n\t\t};\n\t}\n\t/**\n\t* Parses the output and returns a JSON object. If `argsOnly` is true,\n\t* only the arguments of the function call are returned.\n\t* @param generations The output of the LLM to parse.\n\t* @returns A JSON object representation of the function call or its arguments.\n\t*/\n\tasync parseResult(generations) {\n\t\tconst result = await this.outputParser.parseResult(generations);\n\t\tif (!result) throw new Error(`No result from \"OutputFunctionsParser\" ${JSON.stringify(generations)}`);\n\t\treturn this.parse(result);\n\t}\n\tasync parse(text) {\n\t\tconst parsedResult = JSON.parse(text);\n\t\tif (this.argsOnly) return parsedResult;\n\t\tparsedResult.arguments = JSON.parse(parsedResult.arguments);\n\t\treturn parsedResult;\n\t}\n\tgetFormatInstructions() {\n\t\treturn \"\";\n\t}\n};\n/**\n* Class for parsing the output of an LLM into a JSON object and returning\n* a specific attribute. Uses an instance of `JsonOutputFunctionsParser`\n* to parse the output.\n*/\nvar JsonKeyOutputFunctionsParser = class extends BaseLLMOutputParser {\n\tstatic lc_name() {\n\t\treturn \"JsonKeyOutputFunctionsParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"output_parsers\",\n\t\t\"openai_functions\"\n\t];\n\tlc_serializable = true;\n\toutputParser = new JsonOutputFunctionsParser();\n\tattrName;\n\tget lc_aliases() {\n\t\treturn { attrName: \"key_name\" };\n\t}\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.attrName = fields.attrName;\n\t}\n\t/**\n\t* Parses the output and returns a specific attribute of the parsed JSON\n\t* object.\n\t* @param generations The output of the LLM to parse.\n\t* @returns The value of a specific attribute of the parsed JSON object.\n\t*/\n\tasync parseResult(generations) {\n\t\tconst result = await this.outputParser.parseResult(generations);\n\t\treturn result[this.attrName];\n\t}\n};\n\n//#endregion\nexport { JsonKeyOutputFunctionsParser, JsonOutputFunctionsParser, OutputFunctionsParser };\n//# sourceMappingURL=json_output_functions_parsers.js.map","import { __export } from \"../../_virtual/rolldown_runtime.js\";\nimport { JsonKeyOutputFunctionsParser, JsonOutputFunctionsParser, OutputFunctionsParser } from \"./json_output_functions_parsers.js\";\n\n//#region src/output_parsers/openai_functions/index.ts\nvar openai_functions_exports = {};\n__export(openai_functions_exports, {\n\tJsonKeyOutputFunctionsParser: () => JsonKeyOutputFunctionsParser,\n\tJsonOutputFunctionsParser: () => JsonOutputFunctionsParser,\n\tOutputFunctionsParser: () => OutputFunctionsParser\n});\n\n//#endregion\nexport { JsonKeyOutputFunctionsParser, JsonOutputFunctionsParser, OutputFunctionsParser, openai_functions_exports };\n//# sourceMappingURL=index.js.map","import { Runnable } from \"../runnables/base.js\";\n\n//#region src/prompts/base.ts\n/**\n* Base class for prompt templates. Exposes a format method that returns a\n* string prompt given a set of input values.\n*/\nvar BasePromptTemplate = class extends Runnable {\n\tlc_serializable = true;\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"prompts\",\n\t\tthis._getPromptType()\n\t];\n\tget lc_attributes() {\n\t\treturn { partialVariables: void 0 };\n\t}\n\tinputVariables;\n\toutputParser;\n\tpartialVariables;\n\t/**\n\t* Metadata to be used for tracing.\n\t*/\n\tmetadata;\n\t/** Tags to be used for tracing. */\n\ttags;\n\tconstructor(input) {\n\t\tsuper(input);\n\t\tconst { inputVariables } = input;\n\t\tif (inputVariables.includes(\"stop\")) throw new Error(\"Cannot have an input variable named 'stop', as it is used internally, please rename.\");\n\t\tObject.assign(this, input);\n\t}\n\t/**\n\t* Merges partial variables and user variables.\n\t* @param userVariables The user variables to merge with the partial variables.\n\t* @returns A Promise that resolves to an object containing the merged variables.\n\t*/\n\tasync mergePartialAndUserVariables(userVariables) {\n\t\tconst partialVariables = this.partialVariables ?? {};\n\t\tconst partialValues = {};\n\t\tfor (const [key, value] of Object.entries(partialVariables)) if (typeof value === \"string\") partialValues[key] = value;\n\t\telse partialValues[key] = await value();\n\t\tconst allKwargs = {\n\t\t\t...partialValues,\n\t\t\t...userVariables\n\t\t};\n\t\treturn allKwargs;\n\t}\n\t/**\n\t* Invokes the prompt template with the given input and options.\n\t* @param input The input to invoke the prompt template with.\n\t* @param options Optional configuration for the callback.\n\t* @returns A Promise that resolves to the output of the prompt template.\n\t*/\n\tasync invoke(input, options) {\n\t\tconst metadata = {\n\t\t\t...this.metadata,\n\t\t\t...options?.metadata\n\t\t};\n\t\tconst tags = [...this.tags ?? [], ...options?.tags ?? []];\n\t\treturn this._callWithConfig((input$1) => this.formatPromptValue(input$1), input, {\n\t\t\t...options,\n\t\t\ttags,\n\t\t\tmetadata,\n\t\t\trunType: \"prompt\"\n\t\t});\n\t}\n};\n\n//#endregion\nexport { BasePromptTemplate };\n//# sourceMappingURL=base.js.map","import { StringPromptValue } from \"../prompt_values.js\";\nimport { BasePromptTemplate } from \"./base.js\";\n\n//#region src/prompts/string.ts\n/**\n* Base class for string prompt templates. It extends the\n* BasePromptTemplate class and overrides the formatPromptValue method to\n* return a StringPromptValue.\n*/\nvar BaseStringPromptTemplate = class extends BasePromptTemplate {\n\t/**\n\t* Formats the prompt given the input values and returns a formatted\n\t* prompt value.\n\t* @param values The input values to format the prompt.\n\t* @returns A Promise that resolves to a formatted prompt value.\n\t*/\n\tasync formatPromptValue(values) {\n\t\tconst formattedPrompt = await this.format(values);\n\t\treturn new StringPromptValue(formattedPrompt);\n\t}\n};\n\n//#endregion\nexport { BaseStringPromptTemplate };\n//# sourceMappingURL=string.js.map","/*!\n * mustache.js - Logic-less {{mustache}} templates with JavaScript\n * http://github.com/janl/mustache.js\n */\n\nvar objectToString = Object.prototype.toString;\nvar isArray = Array.isArray || function isArrayPolyfill (object) {\n  return objectToString.call(object) === '[object Array]';\n};\n\nfunction isFunction (object) {\n  return typeof object === 'function';\n}\n\n/**\n * More correct typeof string handling array\n * which normally returns typeof 'object'\n */\nfunction typeStr (obj) {\n  return isArray(obj) ? 'array' : typeof obj;\n}\n\nfunction escapeRegExp (string) {\n  return string.replace(/[\\-\\[\\]{}()*+?.,\\\\\\^$|#\\s]/g, '\\\\$&');\n}\n\n/**\n * Null safe way of checking whether or not an object,\n * including its prototype, has a given property\n */\nfunction hasProperty (obj, propName) {\n  return obj != null && typeof obj === 'object' && (propName in obj);\n}\n\n/**\n * Safe way of detecting whether or not the given thing is a primitive and\n * whether it has the given property\n */\nfunction primitiveHasOwnProperty (primitive, propName) {\n  return (\n    primitive != null\n    && typeof primitive !== 'object'\n    && primitive.hasOwnProperty\n    && primitive.hasOwnProperty(propName)\n  );\n}\n\n// Workaround for https://issues.apache.org/jira/browse/COUCHDB-577\n// See https://github.com/janl/mustache.js/issues/189\nvar regExpTest = RegExp.prototype.test;\nfunction testRegExp (re, string) {\n  return regExpTest.call(re, string);\n}\n\nvar nonSpaceRe = /\\S/;\nfunction isWhitespace (string) {\n  return !testRegExp(nonSpaceRe, string);\n}\n\nvar entityMap = {\n  '&': '&amp;',\n  '<': '&lt;',\n  '>': '&gt;',\n  '\"': '&quot;',\n  \"'\": '&#39;',\n  '/': '&#x2F;',\n  '`': '&#x60;',\n  '=': '&#x3D;'\n};\n\nfunction escapeHtml (string) {\n  return String(string).replace(/[&<>\"'`=\\/]/g, function fromEntityMap (s) {\n    return entityMap[s];\n  });\n}\n\nvar whiteRe = /\\s*/;\nvar spaceRe = /\\s+/;\nvar equalsRe = /\\s*=/;\nvar curlyRe = /\\s*\\}/;\nvar tagRe = /#|\\^|\\/|>|\\{|&|=|!/;\n\n/**\n * Breaks up the given `template` string into a tree of tokens. If the `tags`\n * argument is given here it must be an array with two string values: the\n * opening and closing tags used in the template (e.g. [ \"<%\", \"%>\" ]). Of\n * course, the default is to use mustaches (i.e. mustache.tags).\n *\n * A token is an array with at least 4 elements. The first element is the\n * mustache symbol that was used inside the tag, e.g. \"#\" or \"&\". If the tag\n * did not contain a symbol (i.e. {{myValue}}) this element is \"name\". For\n * all text that appears outside a symbol this element is \"text\".\n *\n * The second element of a token is its \"value\". For mustache tags this is\n * whatever else was inside the tag besides the opening symbol. For text tokens\n * this is the text itself.\n *\n * The third and fourth elements of the token are the start and end indices,\n * respectively, of the token in the original template.\n *\n * Tokens that are the root node of a subtree contain two more elements: 1) an\n * array of tokens in the subtree and 2) the index in the original template at\n * which the closing tag for that section begins.\n *\n * Tokens for partials also contain two more elements: 1) a string value of\n * indendation prior to that tag and 2) the index of that tag on that line -\n * eg a value of 2 indicates the partial is the third tag on this line.\n */\nfunction parseTemplate (template, tags) {\n  if (!template)\n    return [];\n  var lineHasNonSpace = false;\n  var sections = [];     // Stack to hold section tokens\n  var tokens = [];       // Buffer to hold the tokens\n  var spaces = [];       // Indices of whitespace tokens on the current line\n  var hasTag = false;    // Is there a {{tag}} on the current line?\n  var nonSpace = false;  // Is there a non-space char on the current line?\n  var indentation = '';  // Tracks indentation for tags that use it\n  var tagIndex = 0;      // Stores a count of number of tags encountered on a line\n\n  // Strips all whitespace tokens array for the current line\n  // if there was a {{#tag}} on it and otherwise only space.\n  function stripSpace () {\n    if (hasTag && !nonSpace) {\n      while (spaces.length)\n        delete tokens[spaces.pop()];\n    } else {\n      spaces = [];\n    }\n\n    hasTag = false;\n    nonSpace = false;\n  }\n\n  var openingTagRe, closingTagRe, closingCurlyRe;\n  function compileTags (tagsToCompile) {\n    if (typeof tagsToCompile === 'string')\n      tagsToCompile = tagsToCompile.split(spaceRe, 2);\n\n    if (!isArray(tagsToCompile) || tagsToCompile.length !== 2)\n      throw new Error('Invalid tags: ' + tagsToCompile);\n\n    openingTagRe = new RegExp(escapeRegExp(tagsToCompile[0]) + '\\\\s*');\n    closingTagRe = new RegExp('\\\\s*' + escapeRegExp(tagsToCompile[1]));\n    closingCurlyRe = new RegExp('\\\\s*' + escapeRegExp('}' + tagsToCompile[1]));\n  }\n\n  compileTags(tags || mustache.tags);\n\n  var scanner = new Scanner(template);\n\n  var start, type, value, chr, token, openSection;\n  while (!scanner.eos()) {\n    start = scanner.pos;\n\n    // Match any text between tags.\n    value = scanner.scanUntil(openingTagRe);\n\n    if (value) {\n      for (var i = 0, valueLength = value.length; i < valueLength; ++i) {\n        chr = value.charAt(i);\n\n        if (isWhitespace(chr)) {\n          spaces.push(tokens.length);\n          indentation += chr;\n        } else {\n          nonSpace = true;\n          lineHasNonSpace = true;\n          indentation += ' ';\n        }\n\n        tokens.push([ 'text', chr, start, start + 1 ]);\n        start += 1;\n\n        // Check for whitespace on the current line.\n        if (chr === '\\n') {\n          stripSpace();\n          indentation = '';\n          tagIndex = 0;\n          lineHasNonSpace = false;\n        }\n      }\n    }\n\n    // Match the opening tag.\n    if (!scanner.scan(openingTagRe))\n      break;\n\n    hasTag = true;\n\n    // Get the tag type.\n    type = scanner.scan(tagRe) || 'name';\n    scanner.scan(whiteRe);\n\n    // Get the tag value.\n    if (type === '=') {\n      value = scanner.scanUntil(equalsRe);\n      scanner.scan(equalsRe);\n      scanner.scanUntil(closingTagRe);\n    } else if (type === '{') {\n      value = scanner.scanUntil(closingCurlyRe);\n      scanner.scan(curlyRe);\n      scanner.scanUntil(closingTagRe);\n      type = '&';\n    } else {\n      value = scanner.scanUntil(closingTagRe);\n    }\n\n    // Match the closing tag.\n    if (!scanner.scan(closingTagRe))\n      throw new Error('Unclosed tag at ' + scanner.pos);\n\n    if (type == '>') {\n      token = [ type, value, start, scanner.pos, indentation, tagIndex, lineHasNonSpace ];\n    } else {\n      token = [ type, value, start, scanner.pos ];\n    }\n    tagIndex++;\n    tokens.push(token);\n\n    if (type === '#' || type === '^') {\n      sections.push(token);\n    } else if (type === '/') {\n      // Check section nesting.\n      openSection = sections.pop();\n\n      if (!openSection)\n        throw new Error('Unopened section \"' + value + '\" at ' + start);\n\n      if (openSection[1] !== value)\n        throw new Error('Unclosed section \"' + openSection[1] + '\" at ' + start);\n    } else if (type === 'name' || type === '{' || type === '&') {\n      nonSpace = true;\n    } else if (type === '=') {\n      // Set the tags for the next time around.\n      compileTags(value);\n    }\n  }\n\n  stripSpace();\n\n  // Make sure there are no open sections when we're done.\n  openSection = sections.pop();\n\n  if (openSection)\n    throw new Error('Unclosed section \"' + openSection[1] + '\" at ' + scanner.pos);\n\n  return nestTokens(squashTokens(tokens));\n}\n\n/**\n * Combines the values of consecutive text tokens in the given `tokens` array\n * to a single token.\n */\nfunction squashTokens (tokens) {\n  var squashedTokens = [];\n\n  var token, lastToken;\n  for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n    token = tokens[i];\n\n    if (token) {\n      if (token[0] === 'text' && lastToken && lastToken[0] === 'text') {\n        lastToken[1] += token[1];\n        lastToken[3] = token[3];\n      } else {\n        squashedTokens.push(token);\n        lastToken = token;\n      }\n    }\n  }\n\n  return squashedTokens;\n}\n\n/**\n * Forms the given array of `tokens` into a nested tree structure where\n * tokens that represent a section have two additional items: 1) an array of\n * all tokens that appear in that section and 2) the index in the original\n * template that represents the end of that section.\n */\nfunction nestTokens (tokens) {\n  var nestedTokens = [];\n  var collector = nestedTokens;\n  var sections = [];\n\n  var token, section;\n  for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n    token = tokens[i];\n\n    switch (token[0]) {\n      case '#':\n      case '^':\n        collector.push(token);\n        sections.push(token);\n        collector = token[4] = [];\n        break;\n      case '/':\n        section = sections.pop();\n        section[5] = token[2];\n        collector = sections.length > 0 ? sections[sections.length - 1][4] : nestedTokens;\n        break;\n      default:\n        collector.push(token);\n    }\n  }\n\n  return nestedTokens;\n}\n\n/**\n * A simple string scanner that is used by the template parser to find\n * tokens in template strings.\n */\nfunction Scanner (string) {\n  this.string = string;\n  this.tail = string;\n  this.pos = 0;\n}\n\n/**\n * Returns `true` if the tail is empty (end of string).\n */\nScanner.prototype.eos = function eos () {\n  return this.tail === '';\n};\n\n/**\n * Tries to match the given regular expression at the current position.\n * Returns the matched text if it can match, the empty string otherwise.\n */\nScanner.prototype.scan = function scan (re) {\n  var match = this.tail.match(re);\n\n  if (!match || match.index !== 0)\n    return '';\n\n  var string = match[0];\n\n  this.tail = this.tail.substring(string.length);\n  this.pos += string.length;\n\n  return string;\n};\n\n/**\n * Skips all text until the given regular expression can be matched. Returns\n * the skipped string, which is the entire tail if no match can be made.\n */\nScanner.prototype.scanUntil = function scanUntil (re) {\n  var index = this.tail.search(re), match;\n\n  switch (index) {\n    case -1:\n      match = this.tail;\n      this.tail = '';\n      break;\n    case 0:\n      match = '';\n      break;\n    default:\n      match = this.tail.substring(0, index);\n      this.tail = this.tail.substring(index);\n  }\n\n  this.pos += match.length;\n\n  return match;\n};\n\n/**\n * Represents a rendering context by wrapping a view object and\n * maintaining a reference to the parent context.\n */\nfunction Context (view, parentContext) {\n  this.view = view;\n  this.cache = { '.': this.view };\n  this.parent = parentContext;\n}\n\n/**\n * Creates a new context using the given view with this context\n * as the parent.\n */\nContext.prototype.push = function push (view) {\n  return new Context(view, this);\n};\n\n/**\n * Returns the value of the given name in this context, traversing\n * up the context hierarchy if the value is absent in this context's view.\n */\nContext.prototype.lookup = function lookup (name) {\n  var cache = this.cache;\n\n  var value;\n  if (cache.hasOwnProperty(name)) {\n    value = cache[name];\n  } else {\n    var context = this, intermediateValue, names, index, lookupHit = false;\n\n    while (context) {\n      if (name.indexOf('.') > 0) {\n        intermediateValue = context.view;\n        names = name.split('.');\n        index = 0;\n\n        /**\n         * Using the dot notion path in `name`, we descend through the\n         * nested objects.\n         *\n         * To be certain that the lookup has been successful, we have to\n         * check if the last object in the path actually has the property\n         * we are looking for. We store the result in `lookupHit`.\n         *\n         * This is specially necessary for when the value has been set to\n         * `undefined` and we want to avoid looking up parent contexts.\n         *\n         * In the case where dot notation is used, we consider the lookup\n         * to be successful even if the last \"object\" in the path is\n         * not actually an object but a primitive (e.g., a string, or an\n         * integer), because it is sometimes useful to access a property\n         * of an autoboxed primitive, such as the length of a string.\n         **/\n        while (intermediateValue != null && index < names.length) {\n          if (index === names.length - 1)\n            lookupHit = (\n              hasProperty(intermediateValue, names[index])\n              || primitiveHasOwnProperty(intermediateValue, names[index])\n            );\n\n          intermediateValue = intermediateValue[names[index++]];\n        }\n      } else {\n        intermediateValue = context.view[name];\n\n        /**\n         * Only checking against `hasProperty`, which always returns `false` if\n         * `context.view` is not an object. Deliberately omitting the check\n         * against `primitiveHasOwnProperty` if dot notation is not used.\n         *\n         * Consider this example:\n         * ```\n         * Mustache.render(\"The length of a football field is {{#length}}{{length}}{{/length}}.\", {length: \"100 yards\"})\n         * ```\n         *\n         * If we were to check also against `primitiveHasOwnProperty`, as we do\n         * in the dot notation case, then render call would return:\n         *\n         * \"The length of a football field is 9.\"\n         *\n         * rather than the expected:\n         *\n         * \"The length of a football field is 100 yards.\"\n         **/\n        lookupHit = hasProperty(context.view, name);\n      }\n\n      if (lookupHit) {\n        value = intermediateValue;\n        break;\n      }\n\n      context = context.parent;\n    }\n\n    cache[name] = value;\n  }\n\n  if (isFunction(value))\n    value = value.call(this.view);\n\n  return value;\n};\n\n/**\n * A Writer knows how to take a stream of tokens and render them to a\n * string, given a context. It also maintains a cache of templates to\n * avoid the need to parse the same template twice.\n */\nfunction Writer () {\n  this.templateCache = {\n    _cache: {},\n    set: function set (key, value) {\n      this._cache[key] = value;\n    },\n    get: function get (key) {\n      return this._cache[key];\n    },\n    clear: function clear () {\n      this._cache = {};\n    }\n  };\n}\n\n/**\n * Clears all cached templates in this writer.\n */\nWriter.prototype.clearCache = function clearCache () {\n  if (typeof this.templateCache !== 'undefined') {\n    this.templateCache.clear();\n  }\n};\n\n/**\n * Parses and caches the given `template` according to the given `tags` or\n * `mustache.tags` if `tags` is omitted,  and returns the array of tokens\n * that is generated from the parse.\n */\nWriter.prototype.parse = function parse (template, tags) {\n  var cache = this.templateCache;\n  var cacheKey = template + ':' + (tags || mustache.tags).join(':');\n  var isCacheEnabled = typeof cache !== 'undefined';\n  var tokens = isCacheEnabled ? cache.get(cacheKey) : undefined;\n\n  if (tokens == undefined) {\n    tokens = parseTemplate(template, tags);\n    isCacheEnabled && cache.set(cacheKey, tokens);\n  }\n  return tokens;\n};\n\n/**\n * High-level method that is used to render the given `template` with\n * the given `view`.\n *\n * The optional `partials` argument may be an object that contains the\n * names and templates of partials that are used in the template. It may\n * also be a function that is used to load partial templates on the fly\n * that takes a single argument: the name of the partial.\n *\n * If the optional `config` argument is given here, then it should be an\n * object with a `tags` attribute or an `escape` attribute or both.\n * If an array is passed, then it will be interpreted the same way as\n * a `tags` attribute on a `config` object.\n *\n * The `tags` attribute of a `config` object must be an array with two\n * string values: the opening and closing tags used in the template (e.g.\n * [ \"<%\", \"%>\" ]). The default is to mustache.tags.\n *\n * The `escape` attribute of a `config` object must be a function which\n * accepts a string as input and outputs a safely escaped string.\n * If an `escape` function is not provided, then an HTML-safe string\n * escaping function is used as the default.\n */\nWriter.prototype.render = function render (template, view, partials, config) {\n  var tags = this.getConfigTags(config);\n  var tokens = this.parse(template, tags);\n  var context = (view instanceof Context) ? view : new Context(view, undefined);\n  return this.renderTokens(tokens, context, partials, template, config);\n};\n\n/**\n * Low-level method that renders the given array of `tokens` using\n * the given `context` and `partials`.\n *\n * Note: The `originalTemplate` is only ever used to extract the portion\n * of the original template that was contained in a higher-order section.\n * If the template doesn't use higher-order sections, this argument may\n * be omitted.\n */\nWriter.prototype.renderTokens = function renderTokens (tokens, context, partials, originalTemplate, config) {\n  var buffer = '';\n\n  var token, symbol, value;\n  for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n    value = undefined;\n    token = tokens[i];\n    symbol = token[0];\n\n    if (symbol === '#') value = this.renderSection(token, context, partials, originalTemplate, config);\n    else if (symbol === '^') value = this.renderInverted(token, context, partials, originalTemplate, config);\n    else if (symbol === '>') value = this.renderPartial(token, context, partials, config);\n    else if (symbol === '&') value = this.unescapedValue(token, context);\n    else if (symbol === 'name') value = this.escapedValue(token, context, config);\n    else if (symbol === 'text') value = this.rawValue(token);\n\n    if (value !== undefined)\n      buffer += value;\n  }\n\n  return buffer;\n};\n\nWriter.prototype.renderSection = function renderSection (token, context, partials, originalTemplate, config) {\n  var self = this;\n  var buffer = '';\n  var value = context.lookup(token[1]);\n\n  // This function is used to render an arbitrary template\n  // in the current context by higher-order sections.\n  function subRender (template) {\n    return self.render(template, context, partials, config);\n  }\n\n  if (!value) return;\n\n  if (isArray(value)) {\n    for (var j = 0, valueLength = value.length; j < valueLength; ++j) {\n      buffer += this.renderTokens(token[4], context.push(value[j]), partials, originalTemplate, config);\n    }\n  } else if (typeof value === 'object' || typeof value === 'string' || typeof value === 'number') {\n    buffer += this.renderTokens(token[4], context.push(value), partials, originalTemplate, config);\n  } else if (isFunction(value)) {\n    if (typeof originalTemplate !== 'string')\n      throw new Error('Cannot use higher-order sections without the original template');\n\n    // Extract the portion of the original template that the section contains.\n    value = value.call(context.view, originalTemplate.slice(token[3], token[5]), subRender);\n\n    if (value != null)\n      buffer += value;\n  } else {\n    buffer += this.renderTokens(token[4], context, partials, originalTemplate, config);\n  }\n  return buffer;\n};\n\nWriter.prototype.renderInverted = function renderInverted (token, context, partials, originalTemplate, config) {\n  var value = context.lookup(token[1]);\n\n  // Use JavaScript's definition of falsy. Include empty arrays.\n  // See https://github.com/janl/mustache.js/issues/186\n  if (!value || (isArray(value) && value.length === 0))\n    return this.renderTokens(token[4], context, partials, originalTemplate, config);\n};\n\nWriter.prototype.indentPartial = function indentPartial (partial, indentation, lineHasNonSpace) {\n  var filteredIndentation = indentation.replace(/[^ \\t]/g, '');\n  var partialByNl = partial.split('\\n');\n  for (var i = 0; i < partialByNl.length; i++) {\n    if (partialByNl[i].length && (i > 0 || !lineHasNonSpace)) {\n      partialByNl[i] = filteredIndentation + partialByNl[i];\n    }\n  }\n  return partialByNl.join('\\n');\n};\n\nWriter.prototype.renderPartial = function renderPartial (token, context, partials, config) {\n  if (!partials) return;\n  var tags = this.getConfigTags(config);\n\n  var value = isFunction(partials) ? partials(token[1]) : partials[token[1]];\n  if (value != null) {\n    var lineHasNonSpace = token[6];\n    var tagIndex = token[5];\n    var indentation = token[4];\n    var indentedValue = value;\n    if (tagIndex == 0 && indentation) {\n      indentedValue = this.indentPartial(value, indentation, lineHasNonSpace);\n    }\n    var tokens = this.parse(indentedValue, tags);\n    return this.renderTokens(tokens, context, partials, indentedValue, config);\n  }\n};\n\nWriter.prototype.unescapedValue = function unescapedValue (token, context) {\n  var value = context.lookup(token[1]);\n  if (value != null)\n    return value;\n};\n\nWriter.prototype.escapedValue = function escapedValue (token, context, config) {\n  var escape = this.getConfigEscape(config) || mustache.escape;\n  var value = context.lookup(token[1]);\n  if (value != null)\n    return (typeof value === 'number' && escape === mustache.escape) ? String(value) : escape(value);\n};\n\nWriter.prototype.rawValue = function rawValue (token) {\n  return token[1];\n};\n\nWriter.prototype.getConfigTags = function getConfigTags (config) {\n  if (isArray(config)) {\n    return config;\n  }\n  else if (config && typeof config === 'object') {\n    return config.tags;\n  }\n  else {\n    return undefined;\n  }\n};\n\nWriter.prototype.getConfigEscape = function getConfigEscape (config) {\n  if (config && typeof config === 'object' && !isArray(config)) {\n    return config.escape;\n  }\n  else {\n    return undefined;\n  }\n};\n\nvar mustache = {\n  name: 'mustache.js',\n  version: '4.2.0',\n  tags: [ '{{', '}}' ],\n  clearCache: undefined,\n  escape: undefined,\n  parse: undefined,\n  render: undefined,\n  Scanner: undefined,\n  Context: undefined,\n  Writer: undefined,\n  /**\n   * Allows a user to override the default caching strategy, by providing an\n   * object with set, get and clear methods. This can also be used to disable\n   * the cache by setting it to the literal `undefined`.\n   */\n  set templateCache (cache) {\n    defaultWriter.templateCache = cache;\n  },\n  /**\n   * Gets the default or overridden caching object from the default writer.\n   */\n  get templateCache () {\n    return defaultWriter.templateCache;\n  }\n};\n\n// All high-level mustache.* functions use this writer.\nvar defaultWriter = new Writer();\n\n/**\n * Clears all cached templates in the default writer.\n */\nmustache.clearCache = function clearCache () {\n  return defaultWriter.clearCache();\n};\n\n/**\n * Parses and caches the given template in the default writer and returns the\n * array of tokens it contains. Doing this ahead of time avoids the need to\n * parse templates on the fly as they are rendered.\n */\nmustache.parse = function parse (template, tags) {\n  return defaultWriter.parse(template, tags);\n};\n\n/**\n * Renders the `template` with the given `view`, `partials`, and `config`\n * using the default writer.\n */\nmustache.render = function render (template, view, partials, config) {\n  if (typeof template !== 'string') {\n    throw new TypeError('Invalid template! Template should be a \"string\" ' +\n                        'but \"' + typeStr(template) + '\" was given as the first ' +\n                        'argument for mustache#render(template, view, partials)');\n  }\n\n  return defaultWriter.render(template, view, partials, config);\n};\n\n// Export the escaping function so that the user may override it.\n// See https://github.com/janl/mustache.js/issues/244\nmustache.escape = escapeHtml;\n\n// Export these mainly for testing, but also for advanced usage.\nmustache.Scanner = Scanner;\nmustache.Context = Context;\nmustache.Writer = Writer;\n\nexport default mustache;\n","import { addLangChainErrorFields } from \"../errors/index.js\";\nimport mustache from \"mustache\";\n\n//#region src/prompts/template.ts\nfunction configureMustache() {\n\tmustache.escape = (text) => text;\n}\nconst parseFString = (template) => {\n\tconst chars = template.split(\"\");\n\tconst nodes = [];\n\tconst nextBracket = (bracket, start) => {\n\t\tfor (let i$1 = start; i$1 < chars.length; i$1 += 1) if (bracket.includes(chars[i$1])) return i$1;\n\t\treturn -1;\n\t};\n\tlet i = 0;\n\twhile (i < chars.length) if (chars[i] === \"{\" && i + 1 < chars.length && chars[i + 1] === \"{\") {\n\t\tnodes.push({\n\t\t\ttype: \"literal\",\n\t\t\ttext: \"{\"\n\t\t});\n\t\ti += 2;\n\t} else if (chars[i] === \"}\" && i + 1 < chars.length && chars[i + 1] === \"}\") {\n\t\tnodes.push({\n\t\t\ttype: \"literal\",\n\t\t\ttext: \"}\"\n\t\t});\n\t\ti += 2;\n\t} else if (chars[i] === \"{\") {\n\t\tconst j = nextBracket(\"}\", i);\n\t\tif (j < 0) throw new Error(\"Unclosed '{' in template.\");\n\t\tnodes.push({\n\t\t\ttype: \"variable\",\n\t\t\tname: chars.slice(i + 1, j).join(\"\")\n\t\t});\n\t\ti = j + 1;\n\t} else if (chars[i] === \"}\") throw new Error(\"Single '}' in template.\");\n\telse {\n\t\tconst next = nextBracket(\"{}\", i);\n\t\tconst text = (next < 0 ? chars.slice(i) : chars.slice(i, next)).join(\"\");\n\t\tnodes.push({\n\t\t\ttype: \"literal\",\n\t\t\ttext\n\t\t});\n\t\ti = next < 0 ? chars.length : next;\n\t}\n\treturn nodes;\n};\n/**\n* Convert the result of mustache.parse into an array of ParsedTemplateNode,\n* to make it compatible with other LangChain string parsing template formats.\n*\n* @param {mustache.TemplateSpans} template The result of parsing a mustache template with the mustache.js library.\n* @param {string[]} context Array of section variable names for nested context\n* @returns {ParsedTemplateNode[]}\n*/\nconst mustacheTemplateToNodes = (template, context = []) => {\n\tconst nodes = [];\n\tfor (const temp of template) if (temp[0] === \"name\") {\n\t\tconst name = temp[1].includes(\".\") ? temp[1].split(\".\")[0] : temp[1];\n\t\tnodes.push({\n\t\t\ttype: \"variable\",\n\t\t\tname\n\t\t});\n\t} else if ([\n\t\t\"#\",\n\t\t\"&\",\n\t\t\"^\",\n\t\t\">\"\n\t].includes(temp[0])) {\n\t\tnodes.push({\n\t\t\ttype: \"variable\",\n\t\t\tname: temp[1]\n\t\t});\n\t\tif (temp[0] === \"#\" && temp.length > 4 && Array.isArray(temp[4])) {\n\t\t\tconst newContext = [...context, temp[1]];\n\t\t\tconst nestedNodes = mustacheTemplateToNodes(temp[4], newContext);\n\t\t\tnodes.push(...nestedNodes);\n\t\t}\n\t} else nodes.push({\n\t\ttype: \"literal\",\n\t\ttext: temp[1]\n\t});\n\treturn nodes;\n};\nconst parseMustache = (template) => {\n\tconfigureMustache();\n\tconst parsed = mustache.parse(template);\n\treturn mustacheTemplateToNodes(parsed);\n};\nconst interpolateFString = (template, values) => {\n\treturn parseFString(template).reduce((res, node) => {\n\t\tif (node.type === \"variable\") {\n\t\t\tif (node.name in values) {\n\t\t\t\tconst stringValue = typeof values[node.name] === \"string\" ? values[node.name] : JSON.stringify(values[node.name]);\n\t\t\t\treturn res + stringValue;\n\t\t\t}\n\t\t\tthrow new Error(`(f-string) Missing value for input ${node.name}`);\n\t\t}\n\t\treturn res + node.text;\n\t}, \"\");\n};\nconst interpolateMustache = (template, values) => {\n\tconfigureMustache();\n\treturn mustache.render(template, values);\n};\nconst DEFAULT_FORMATTER_MAPPING = {\n\t\"f-string\": interpolateFString,\n\tmustache: interpolateMustache\n};\nconst DEFAULT_PARSER_MAPPING = {\n\t\"f-string\": parseFString,\n\tmustache: parseMustache\n};\nconst renderTemplate = (template, templateFormat, inputValues) => {\n\ttry {\n\t\treturn DEFAULT_FORMATTER_MAPPING[templateFormat](template, inputValues);\n\t} catch (e) {\n\t\tconst error = addLangChainErrorFields(e, \"INVALID_PROMPT_INPUT\");\n\t\tthrow error;\n\t}\n};\nconst parseTemplate = (template, templateFormat) => DEFAULT_PARSER_MAPPING[templateFormat](template);\nconst checkValidTemplate = (template, templateFormat, inputVariables) => {\n\tif (!(templateFormat in DEFAULT_FORMATTER_MAPPING)) {\n\t\tconst validFormats = Object.keys(DEFAULT_FORMATTER_MAPPING);\n\t\tthrow new Error(`Invalid template format. Got \\`${templateFormat}\\`;\n                         should be one of ${validFormats}`);\n\t}\n\ttry {\n\t\tconst dummyInputs = inputVariables.reduce((acc, v) => {\n\t\t\tacc[v] = \"foo\";\n\t\t\treturn acc;\n\t\t}, {});\n\t\tif (Array.isArray(template)) template.forEach((message) => {\n\t\t\tif (message.type === \"text\" && \"text\" in message && typeof message.text === \"string\") renderTemplate(message.text, templateFormat, dummyInputs);\n\t\t\telse if (message.type === \"image_url\") {\n\t\t\t\tif (typeof message.image_url === \"string\") renderTemplate(message.image_url, templateFormat, dummyInputs);\n\t\t\t\telse if (typeof message.image_url === \"object\" && message.image_url !== null && \"url\" in message.image_url && typeof message.image_url.url === \"string\") {\n\t\t\t\t\tconst imageUrl = message.image_url.url;\n\t\t\t\t\trenderTemplate(imageUrl, templateFormat, dummyInputs);\n\t\t\t\t}\n\t\t\t} else throw new Error(`Invalid message template received. ${JSON.stringify(message, null, 2)}`);\n\t\t});\n\t\telse renderTemplate(template, templateFormat, dummyInputs);\n\t} catch (e) {\n\t\tthrow new Error(`Invalid prompt schema: ${e.message}`);\n\t}\n};\n\n//#endregion\nexport { DEFAULT_FORMATTER_MAPPING, DEFAULT_PARSER_MAPPING, checkValidTemplate, interpolateFString, interpolateMustache, parseFString, parseMustache, parseTemplate, renderTemplate };\n//# sourceMappingURL=template.js.map","import { BaseStringPromptTemplate } from \"./string.js\";\nimport { checkValidTemplate, parseTemplate, renderTemplate } from \"./template.js\";\n\n//#region src/prompts/prompt.ts\n/**\n* Schema to represent a basic prompt for an LLM.\n* @augments BasePromptTemplate\n* @augments PromptTemplateInput\n*\n* @example\n* ```ts\n* import { PromptTemplate } from \"langchain/prompts\";\n*\n* const prompt = new PromptTemplate({\n*   inputVariables: [\"foo\"],\n*   template: \"Say {foo}\",\n* });\n* ```\n*/\nvar PromptTemplate = class PromptTemplate extends BaseStringPromptTemplate {\n\tstatic lc_name() {\n\t\treturn \"PromptTemplate\";\n\t}\n\ttemplate;\n\ttemplateFormat = \"f-string\";\n\tvalidateTemplate = true;\n\t/**\n\t* Additional fields which should be included inside\n\t* the message content array if using a complex message\n\t* content.\n\t*/\n\tadditionalContentFields;\n\tconstructor(input) {\n\t\tsuper(input);\n\t\tif (input.templateFormat === \"mustache\" && input.validateTemplate === void 0) this.validateTemplate = false;\n\t\tObject.assign(this, input);\n\t\tif (this.validateTemplate) {\n\t\t\tif (this.templateFormat === \"mustache\") throw new Error(\"Mustache templates cannot be validated.\");\n\t\t\tlet totalInputVariables = this.inputVariables;\n\t\t\tif (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));\n\t\t\tcheckValidTemplate(this.template, this.templateFormat, totalInputVariables);\n\t\t}\n\t}\n\t_getPromptType() {\n\t\treturn \"prompt\";\n\t}\n\t/**\n\t* Formats the prompt template with the provided values.\n\t* @param values The values to be used to format the prompt template.\n\t* @returns A promise that resolves to a string which is the formatted prompt.\n\t*/\n\tasync format(values) {\n\t\tconst allValues = await this.mergePartialAndUserVariables(values);\n\t\treturn renderTemplate(this.template, this.templateFormat, allValues);\n\t}\n\t/**\n\t* Take examples in list format with prefix and suffix to create a prompt.\n\t*\n\t* Intended to be used a a way to dynamically create a prompt from examples.\n\t*\n\t* @param examples - List of examples to use in the prompt.\n\t* @param suffix - String to go after the list of examples. Should generally set up the user's input.\n\t* @param inputVariables - A list of variable names the final prompt template will expect\n\t* @param exampleSeparator - The separator to use in between examples\n\t* @param prefix - String that should go before any examples. Generally includes examples.\n\t*\n\t* @returns The final prompt template generated.\n\t*/\n\tstatic fromExamples(examples, suffix, inputVariables, exampleSeparator = \"\\n\\n\", prefix = \"\") {\n\t\tconst template = [\n\t\t\tprefix,\n\t\t\t...examples,\n\t\t\tsuffix\n\t\t].join(exampleSeparator);\n\t\treturn new PromptTemplate({\n\t\t\tinputVariables,\n\t\t\ttemplate\n\t\t});\n\t}\n\tstatic fromTemplate(template, options) {\n\t\tconst { templateFormat = \"f-string\",...rest } = options ?? {};\n\t\tconst names = /* @__PURE__ */ new Set();\n\t\tparseTemplate(template, templateFormat).forEach((node) => {\n\t\t\tif (node.type === \"variable\") names.add(node.name);\n\t\t});\n\t\treturn new PromptTemplate({\n\t\t\tinputVariables: [...names],\n\t\t\ttemplateFormat,\n\t\t\ttemplate,\n\t\t\t...rest\n\t\t});\n\t}\n\t/**\n\t* Partially applies values to the prompt template.\n\t* @param values The values to be partially applied to the prompt template.\n\t* @returns A new instance of PromptTemplate with the partially applied values.\n\t*/\n\tasync partial(values) {\n\t\tconst newInputVariables = this.inputVariables.filter((iv) => !(iv in values));\n\t\tconst newPartialVariables = {\n\t\t\t...this.partialVariables ?? {},\n\t\t\t...values\n\t\t};\n\t\tconst promptDict = {\n\t\t\t...this,\n\t\t\tinputVariables: newInputVariables,\n\t\t\tpartialVariables: newPartialVariables\n\t\t};\n\t\treturn new PromptTemplate(promptDict);\n\t}\n\tserialize() {\n\t\tif (this.outputParser !== void 0) throw new Error(\"Cannot serialize a prompt template with an output parser\");\n\t\treturn {\n\t\t\t_type: this._getPromptType(),\n\t\t\tinput_variables: this.inputVariables,\n\t\t\ttemplate: this.template,\n\t\t\ttemplate_format: this.templateFormat\n\t\t};\n\t}\n\tstatic async deserialize(data) {\n\t\tif (!data.template) throw new Error(\"Prompt template must have a template\");\n\t\tconst res = new PromptTemplate({\n\t\t\tinputVariables: data.input_variables,\n\t\t\ttemplate: data.template,\n\t\t\ttemplateFormat: data.template_format\n\t\t});\n\t\treturn res;\n\t}\n};\n\n//#endregion\nexport { PromptTemplate };\n//# sourceMappingURL=prompt.js.map","import { ImagePromptValue } from \"../prompt_values.js\";\nimport { BasePromptTemplate } from \"./base.js\";\nimport { checkValidTemplate, renderTemplate } from \"./template.js\";\n\n//#region src/prompts/image.ts\n/**\n* An image prompt template for a multimodal model.\n*/\nvar ImagePromptTemplate = class ImagePromptTemplate extends BasePromptTemplate {\n\tstatic lc_name() {\n\t\treturn \"ImagePromptTemplate\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"prompts\",\n\t\t\"image\"\n\t];\n\ttemplate;\n\ttemplateFormat = \"f-string\";\n\tvalidateTemplate = true;\n\t/**\n\t* Additional fields which should be included inside\n\t* the message content array if using a complex message\n\t* content.\n\t*/\n\tadditionalContentFields;\n\tconstructor(input) {\n\t\tsuper(input);\n\t\tthis.template = input.template;\n\t\tthis.templateFormat = input.templateFormat ?? this.templateFormat;\n\t\tthis.validateTemplate = input.validateTemplate ?? this.validateTemplate;\n\t\tthis.additionalContentFields = input.additionalContentFields;\n\t\tif (this.validateTemplate) {\n\t\t\tlet totalInputVariables = this.inputVariables;\n\t\t\tif (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));\n\t\t\tcheckValidTemplate([{\n\t\t\t\ttype: \"image_url\",\n\t\t\t\timage_url: this.template\n\t\t\t}], this.templateFormat, totalInputVariables);\n\t\t}\n\t}\n\t_getPromptType() {\n\t\treturn \"prompt\";\n\t}\n\t/**\n\t* Partially applies values to the prompt template.\n\t* @param values The values to be partially applied to the prompt template.\n\t* @returns A new instance of ImagePromptTemplate with the partially applied values.\n\t*/\n\tasync partial(values) {\n\t\tconst newInputVariables = this.inputVariables.filter((iv) => !(iv in values));\n\t\tconst newPartialVariables = {\n\t\t\t...this.partialVariables ?? {},\n\t\t\t...values\n\t\t};\n\t\tconst promptDict = {\n\t\t\t...this,\n\t\t\tinputVariables: newInputVariables,\n\t\t\tpartialVariables: newPartialVariables\n\t\t};\n\t\treturn new ImagePromptTemplate(promptDict);\n\t}\n\t/**\n\t* Formats the prompt template with the provided values.\n\t* @param values The values to be used to format the prompt template.\n\t* @returns A promise that resolves to a string which is the formatted prompt.\n\t*/\n\tasync format(values) {\n\t\tconst formatted = {};\n\t\tfor (const [key, value] of Object.entries(this.template)) if (typeof value === \"string\") formatted[key] = renderTemplate(value, this.templateFormat, values);\n\t\telse formatted[key] = value;\n\t\tconst url = values.url || formatted.url;\n\t\tconst detail = values.detail || formatted.detail;\n\t\tif (!url) throw new Error(\"Must provide either an image URL.\");\n\t\tif (typeof url !== \"string\") throw new Error(\"url must be a string.\");\n\t\tconst output = { url };\n\t\tif (detail) output.detail = detail;\n\t\treturn output;\n\t}\n\t/**\n\t* Formats the prompt given the input values and returns a formatted\n\t* prompt value.\n\t* @param values The input values to format the prompt.\n\t* @returns A Promise that resolves to a formatted prompt value.\n\t*/\n\tasync formatPromptValue(values) {\n\t\tconst formattedPrompt = await this.format(values);\n\t\treturn new ImagePromptValue(formattedPrompt);\n\t}\n};\n\n//#endregion\nexport { ImagePromptTemplate };\n//# sourceMappingURL=image.js.map","import { Runnable } from \"../runnables/base.js\";\nimport { parseTemplate, renderTemplate } from \"./template.js\";\n\n//#region src/prompts/dict.ts\nvar DictPromptTemplate = class extends Runnable {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"prompts\",\n\t\t\"dict\"\n\t];\n\tlc_serializable = true;\n\ttemplate;\n\ttemplateFormat;\n\tinputVariables;\n\tstatic lc_name() {\n\t\treturn \"DictPromptTemplate\";\n\t}\n\tconstructor(fields) {\n\t\tconst templateFormat = fields.templateFormat ?? \"f-string\";\n\t\tconst inputVariables = _getInputVariables(fields.template, templateFormat);\n\t\tsuper({\n\t\t\tinputVariables,\n\t\t\t...fields\n\t\t});\n\t\tthis.template = fields.template;\n\t\tthis.templateFormat = templateFormat;\n\t\tthis.inputVariables = inputVariables;\n\t}\n\tasync format(values) {\n\t\treturn _insertInputVariables(this.template, values, this.templateFormat);\n\t}\n\tasync invoke(values) {\n\t\treturn await this._callWithConfig(this.format.bind(this), values, { runType: \"prompt\" });\n\t}\n};\nfunction _getInputVariables(template, templateFormat) {\n\tconst inputVariables = [];\n\tfor (const v of Object.values(template)) if (typeof v === \"string\") parseTemplate(v, templateFormat).forEach((t) => {\n\t\tif (t.type === \"variable\") inputVariables.push(t.name);\n\t});\n\telse if (Array.isArray(v)) {\n\t\tfor (const x of v) if (typeof x === \"string\") parseTemplate(x, templateFormat).forEach((t) => {\n\t\t\tif (t.type === \"variable\") inputVariables.push(t.name);\n\t\t});\n\t\telse if (typeof x === \"object\") inputVariables.push(..._getInputVariables(x, templateFormat));\n\t} else if (typeof v === \"object\" && v !== null) inputVariables.push(..._getInputVariables(v, templateFormat));\n\treturn Array.from(new Set(inputVariables));\n}\nfunction _insertInputVariables(template, inputs, templateFormat) {\n\tconst formatted = {};\n\tfor (const [k, v] of Object.entries(template)) if (typeof v === \"string\") formatted[k] = renderTemplate(v, templateFormat, inputs);\n\telse if (Array.isArray(v)) {\n\t\tconst formattedV = [];\n\t\tfor (const x of v) if (typeof x === \"string\") formattedV.push(renderTemplate(x, templateFormat, inputs));\n\t\telse if (typeof x === \"object\") formattedV.push(_insertInputVariables(x, inputs, templateFormat));\n\t\tformatted[k] = formattedV;\n\t} else if (typeof v === \"object\" && v !== null) formatted[k] = _insertInputVariables(v, inputs, templateFormat);\n\telse formatted[k] = v;\n\treturn formatted;\n}\n\n//#endregion\nexport { DictPromptTemplate };\n//# sourceMappingURL=dict.js.map","import { BaseMessage, isBaseMessage } from \"../messages/base.js\";\nimport { AIMessage } from \"../messages/ai.js\";\nimport { ChatMessage } from \"../messages/chat.js\";\nimport { HumanMessage } from \"../messages/human.js\";\nimport { SystemMessage } from \"../messages/system.js\";\nimport { addLangChainErrorFields } from \"../errors/index.js\";\nimport { coerceMessageLikeToMessage } from \"../messages/utils.js\";\nimport { Runnable } from \"../runnables/base.js\";\nimport \"../messages/index.js\";\nimport { ChatPromptValue } from \"../prompt_values.js\";\nimport { BasePromptTemplate } from \"./base.js\";\nimport { BaseStringPromptTemplate } from \"./string.js\";\nimport { parseFString, parseMustache } from \"./template.js\";\nimport { PromptTemplate } from \"./prompt.js\";\nimport { ImagePromptTemplate } from \"./image.js\";\nimport { DictPromptTemplate } from \"./dict.js\";\n\n//#region src/prompts/chat.ts\n/**\n* Abstract class that serves as a base for creating message prompt\n* templates. It defines how to format messages for different roles in a\n* conversation.\n*/\nvar BaseMessagePromptTemplate = class extends Runnable {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"prompts\",\n\t\t\"chat\"\n\t];\n\tlc_serializable = true;\n\t/**\n\t* Calls the formatMessages method with the provided input and options.\n\t* @param input Input for the formatMessages method\n\t* @param options Optional BaseCallbackConfig\n\t* @returns Formatted output messages\n\t*/\n\tasync invoke(input, options) {\n\t\treturn this._callWithConfig((input$1) => this.formatMessages(input$1), input, {\n\t\t\t...options,\n\t\t\trunType: \"prompt\"\n\t\t});\n\t}\n};\n/**\n* Class that represents a placeholder for messages in a chat prompt. It\n* extends the BaseMessagePromptTemplate.\n*/\nvar MessagesPlaceholder = class extends BaseMessagePromptTemplate {\n\tstatic lc_name() {\n\t\treturn \"MessagesPlaceholder\";\n\t}\n\tvariableName;\n\toptional;\n\tconstructor(fields) {\n\t\tif (typeof fields === \"string\") fields = { variableName: fields };\n\t\tsuper(fields);\n\t\tthis.variableName = fields.variableName;\n\t\tthis.optional = fields.optional ?? false;\n\t}\n\tget inputVariables() {\n\t\treturn [this.variableName];\n\t}\n\tasync formatMessages(values) {\n\t\tconst input = values[this.variableName];\n\t\tif (this.optional && !input) return [];\n\t\telse if (!input) {\n\t\t\tconst error = /* @__PURE__ */ new Error(`Field \"${this.variableName}\" in prompt uses a MessagesPlaceholder, which expects an array of BaseMessages as an input value. Received: undefined`);\n\t\t\terror.name = \"InputFormatError\";\n\t\t\tthrow error;\n\t\t}\n\t\tlet formattedMessages;\n\t\ttry {\n\t\t\tif (Array.isArray(input)) formattedMessages = input.map(coerceMessageLikeToMessage);\n\t\t\telse formattedMessages = [coerceMessageLikeToMessage(input)];\n\t\t} catch (e) {\n\t\t\tconst readableInput = typeof input === \"string\" ? input : JSON.stringify(input, null, 2);\n\t\t\tconst error = new Error([\n\t\t\t\t`Field \"${this.variableName}\" in prompt uses a MessagesPlaceholder, which expects an array of BaseMessages or coerceable values as input.`,\n\t\t\t\t`Received value: ${readableInput}`,\n\t\t\t\t`Additional message: ${e.message}`\n\t\t\t].join(\"\\n\\n\"));\n\t\t\terror.name = \"InputFormatError\";\n\t\t\terror.lc_error_code = e.lc_error_code;\n\t\t\tthrow error;\n\t\t}\n\t\treturn formattedMessages;\n\t}\n};\n/**\n* Abstract class that serves as a base for creating message string prompt\n* templates. It extends the BaseMessagePromptTemplate.\n*/\nvar BaseMessageStringPromptTemplate = class extends BaseMessagePromptTemplate {\n\tprompt;\n\tconstructor(fields) {\n\t\tif (!(\"prompt\" in fields)) fields = { prompt: fields };\n\t\tsuper(fields);\n\t\tthis.prompt = fields.prompt;\n\t}\n\tget inputVariables() {\n\t\treturn this.prompt.inputVariables;\n\t}\n\tasync formatMessages(values) {\n\t\treturn [await this.format(values)];\n\t}\n};\n/**\n* Abstract class that serves as a base for creating chat prompt\n* templates. It extends the BasePromptTemplate.\n*/\nvar BaseChatPromptTemplate = class extends BasePromptTemplate {\n\tconstructor(input) {\n\t\tsuper(input);\n\t}\n\tasync format(values) {\n\t\treturn (await this.formatPromptValue(values)).toString();\n\t}\n\tasync formatPromptValue(values) {\n\t\tconst resultMessages = await this.formatMessages(values);\n\t\treturn new ChatPromptValue(resultMessages);\n\t}\n};\n/**\n* Class that represents a chat message prompt template. It extends the\n* BaseMessageStringPromptTemplate.\n*/\nvar ChatMessagePromptTemplate = class extends BaseMessageStringPromptTemplate {\n\tstatic lc_name() {\n\t\treturn \"ChatMessagePromptTemplate\";\n\t}\n\trole;\n\tconstructor(fields, role) {\n\t\tif (!(\"prompt\" in fields)) fields = {\n\t\t\tprompt: fields,\n\t\t\trole\n\t\t};\n\t\tsuper(fields);\n\t\tthis.role = fields.role;\n\t}\n\tasync format(values) {\n\t\treturn new ChatMessage(await this.prompt.format(values), this.role);\n\t}\n\tstatic fromTemplate(template, role, options) {\n\t\treturn new this(PromptTemplate.fromTemplate(template, { templateFormat: options?.templateFormat }), role);\n\t}\n};\nfunction isTextTemplateParam(param) {\n\tif (param === null || typeof param !== \"object\" || Array.isArray(param)) return false;\n\treturn Object.keys(param).length === 1 && \"text\" in param && typeof param.text === \"string\";\n}\nfunction isImageTemplateParam(param) {\n\tif (param === null || typeof param !== \"object\" || Array.isArray(param)) return false;\n\treturn \"image_url\" in param && (typeof param.image_url === \"string\" || typeof param.image_url === \"object\" && param.image_url !== null && \"url\" in param.image_url && typeof param.image_url.url === \"string\");\n}\nvar _StringImageMessagePromptTemplate = class extends BaseMessagePromptTemplate {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"prompts\",\n\t\t\"chat\"\n\t];\n\tlc_serializable = true;\n\tinputVariables = [];\n\tadditionalOptions = {};\n\tprompt;\n\tmessageClass;\n\tstatic _messageClass() {\n\t\tthrow new Error(\"Can not invoke _messageClass from inside _StringImageMessagePromptTemplate\");\n\t}\n\tchatMessageClass;\n\tconstructor(fields, additionalOptions) {\n\t\tif (!(\"prompt\" in fields)) fields = { prompt: fields };\n\t\tsuper(fields);\n\t\tthis.prompt = fields.prompt;\n\t\tif (Array.isArray(this.prompt)) {\n\t\t\tlet inputVariables = [];\n\t\t\tthis.prompt.forEach((prompt) => {\n\t\t\t\tif (\"inputVariables\" in prompt) inputVariables = inputVariables.concat(prompt.inputVariables);\n\t\t\t});\n\t\t\tthis.inputVariables = inputVariables;\n\t\t} else this.inputVariables = this.prompt.inputVariables;\n\t\tthis.additionalOptions = additionalOptions ?? this.additionalOptions;\n\t}\n\tcreateMessage(content) {\n\t\tconst constructor = this.constructor;\n\t\tif (constructor._messageClass()) {\n\t\t\tconst MsgClass = constructor._messageClass();\n\t\t\treturn new MsgClass({ content });\n\t\t} else if (constructor.chatMessageClass) {\n\t\t\tconst MsgClass = constructor.chatMessageClass();\n\t\t\treturn new MsgClass({\n\t\t\t\tcontent,\n\t\t\t\trole: this.getRoleFromMessageClass(MsgClass.lc_name())\n\t\t\t});\n\t\t} else throw new Error(\"No message class defined\");\n\t}\n\tgetRoleFromMessageClass(name) {\n\t\tswitch (name) {\n\t\t\tcase \"HumanMessage\": return \"human\";\n\t\t\tcase \"AIMessage\": return \"ai\";\n\t\t\tcase \"SystemMessage\": return \"system\";\n\t\t\tcase \"ChatMessage\": return \"chat\";\n\t\t\tdefault: throw new Error(\"Invalid message class name\");\n\t\t}\n\t}\n\tstatic fromTemplate(template, additionalOptions) {\n\t\tif (typeof template === \"string\") return new this(PromptTemplate.fromTemplate(template, additionalOptions));\n\t\tconst prompt = [];\n\t\tfor (const item of template) if (typeof item === \"string\") prompt.push(PromptTemplate.fromTemplate(item, additionalOptions));\n\t\telse if (item === null) {} else if (isTextTemplateParam(item)) {\n\t\t\tlet text = \"\";\n\t\t\tif (typeof item.text === \"string\") text = item.text ?? \"\";\n\t\t\tconst options = {\n\t\t\t\t...additionalOptions,\n\t\t\t\tadditionalContentFields: item\n\t\t\t};\n\t\t\tprompt.push(PromptTemplate.fromTemplate(text, options));\n\t\t} else if (isImageTemplateParam(item)) {\n\t\t\tlet imgTemplate = item.image_url ?? \"\";\n\t\t\tlet imgTemplateObject;\n\t\t\tlet inputVariables = [];\n\t\t\tif (typeof imgTemplate === \"string\") {\n\t\t\t\tlet parsedTemplate;\n\t\t\t\tif (additionalOptions?.templateFormat === \"mustache\") parsedTemplate = parseMustache(imgTemplate);\n\t\t\t\telse parsedTemplate = parseFString(imgTemplate);\n\t\t\t\tconst variables = parsedTemplate.flatMap((item$1) => item$1.type === \"variable\" ? [item$1.name] : []);\n\t\t\t\tif ((variables?.length ?? 0) > 0) {\n\t\t\t\t\tif (variables.length > 1) throw new Error(`Only one format variable allowed per image template.\\nGot: ${variables}\\nFrom: ${imgTemplate}`);\n\t\t\t\t\tinputVariables = [variables[0]];\n\t\t\t\t} else inputVariables = [];\n\t\t\t\timgTemplate = { url: imgTemplate };\n\t\t\t\timgTemplateObject = new ImagePromptTemplate({\n\t\t\t\t\ttemplate: imgTemplate,\n\t\t\t\t\tinputVariables,\n\t\t\t\t\ttemplateFormat: additionalOptions?.templateFormat,\n\t\t\t\t\tadditionalContentFields: item\n\t\t\t\t});\n\t\t\t} else if (typeof imgTemplate === \"object\") {\n\t\t\t\tif (\"url\" in imgTemplate) {\n\t\t\t\t\tlet parsedTemplate;\n\t\t\t\t\tif (additionalOptions?.templateFormat === \"mustache\") parsedTemplate = parseMustache(imgTemplate.url);\n\t\t\t\t\telse parsedTemplate = parseFString(imgTemplate.url);\n\t\t\t\t\tinputVariables = parsedTemplate.flatMap((item$1) => item$1.type === \"variable\" ? [item$1.name] : []);\n\t\t\t\t} else inputVariables = [];\n\t\t\t\timgTemplateObject = new ImagePromptTemplate({\n\t\t\t\t\ttemplate: imgTemplate,\n\t\t\t\t\tinputVariables,\n\t\t\t\t\ttemplateFormat: additionalOptions?.templateFormat,\n\t\t\t\t\tadditionalContentFields: item\n\t\t\t\t});\n\t\t\t} else throw new Error(\"Invalid image template\");\n\t\t\tprompt.push(imgTemplateObject);\n\t\t} else if (typeof item === \"object\") prompt.push(new DictPromptTemplate({\n\t\t\ttemplate: item,\n\t\t\ttemplateFormat: additionalOptions?.templateFormat\n\t\t}));\n\t\treturn new this({\n\t\t\tprompt,\n\t\t\tadditionalOptions\n\t\t});\n\t}\n\tasync format(input) {\n\t\tif (this.prompt instanceof BaseStringPromptTemplate) {\n\t\t\tconst text = await this.prompt.format(input);\n\t\t\treturn this.createMessage(text);\n\t\t} else {\n\t\t\tconst content = [];\n\t\t\tfor (const prompt of this.prompt) {\n\t\t\t\tlet inputs = {};\n\t\t\t\tif (!(\"inputVariables\" in prompt)) throw new Error(`Prompt ${prompt} does not have inputVariables defined.`);\n\t\t\t\tfor (const item of prompt.inputVariables) {\n\t\t\t\t\tif (!inputs) inputs = { [item]: input[item] };\n\t\t\t\t\tinputs = {\n\t\t\t\t\t\t...inputs,\n\t\t\t\t\t\t[item]: input[item]\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t\tif (prompt instanceof BaseStringPromptTemplate) {\n\t\t\t\t\tconst formatted = await prompt.format(inputs);\n\t\t\t\t\tlet additionalContentFields;\n\t\t\t\t\tif (\"additionalContentFields\" in prompt) additionalContentFields = prompt.additionalContentFields;\n\t\t\t\t\tif (formatted !== \"\") content.push({\n\t\t\t\t\t\t...additionalContentFields,\n\t\t\t\t\t\ttype: \"text\",\n\t\t\t\t\t\ttext: formatted\n\t\t\t\t\t});\n\t\t\t\t} else if (prompt instanceof ImagePromptTemplate) {\n\t\t\t\t\tconst formatted = await prompt.format(inputs);\n\t\t\t\t\tlet additionalContentFields;\n\t\t\t\t\tif (\"additionalContentFields\" in prompt) additionalContentFields = prompt.additionalContentFields;\n\t\t\t\t\tcontent.push({\n\t\t\t\t\t\t...additionalContentFields,\n\t\t\t\t\t\ttype: \"image_url\",\n\t\t\t\t\t\timage_url: formatted\n\t\t\t\t\t});\n\t\t\t\t} else if (prompt instanceof DictPromptTemplate) {\n\t\t\t\t\tconst formatted = await prompt.format(inputs);\n\t\t\t\t\tlet additionalContentFields;\n\t\t\t\t\tif (\"additionalContentFields\" in prompt) additionalContentFields = prompt.additionalContentFields;\n\t\t\t\t\tcontent.push({\n\t\t\t\t\t\t...additionalContentFields,\n\t\t\t\t\t\t...formatted\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this.createMessage(content);\n\t\t}\n\t}\n\tasync formatMessages(values) {\n\t\treturn [await this.format(values)];\n\t}\n};\n/**\n* Class that represents a human message prompt template. It extends the\n* BaseMessageStringPromptTemplate.\n* @example\n* ```typescript\n* const message = HumanMessagePromptTemplate.fromTemplate(\"{text}\");\n* const formatted = await message.format({ text: \"Hello world!\" });\n*\n* const chatPrompt = ChatPromptTemplate.fromMessages([message]);\n* const formattedChatPrompt = await chatPrompt.invoke({\n*   text: \"Hello world!\",\n* });\n* ```\n*/\nvar HumanMessagePromptTemplate = class extends _StringImageMessagePromptTemplate {\n\tstatic _messageClass() {\n\t\treturn HumanMessage;\n\t}\n\tstatic lc_name() {\n\t\treturn \"HumanMessagePromptTemplate\";\n\t}\n};\n/**\n* Class that represents an AI message prompt template. It extends the\n* BaseMessageStringPromptTemplate.\n*/\nvar AIMessagePromptTemplate = class extends _StringImageMessagePromptTemplate {\n\tstatic _messageClass() {\n\t\treturn AIMessage;\n\t}\n\tstatic lc_name() {\n\t\treturn \"AIMessagePromptTemplate\";\n\t}\n};\n/**\n* Class that represents a system message prompt template. It extends the\n* BaseMessageStringPromptTemplate.\n* @example\n* ```typescript\n* const message = SystemMessagePromptTemplate.fromTemplate(\"{text}\");\n* const formatted = await message.format({ text: \"Hello world!\" });\n*\n* const chatPrompt = ChatPromptTemplate.fromMessages([message]);\n* const formattedChatPrompt = await chatPrompt.invoke({\n*   text: \"Hello world!\",\n* });\n* ```\n*/\nvar SystemMessagePromptTemplate = class extends _StringImageMessagePromptTemplate {\n\tstatic _messageClass() {\n\t\treturn SystemMessage;\n\t}\n\tstatic lc_name() {\n\t\treturn \"SystemMessagePromptTemplate\";\n\t}\n};\nfunction _isBaseMessagePromptTemplate(baseMessagePromptTemplateLike) {\n\treturn typeof baseMessagePromptTemplateLike.formatMessages === \"function\";\n}\nfunction _coerceMessagePromptTemplateLike(messagePromptTemplateLike, extra) {\n\tif (_isBaseMessagePromptTemplate(messagePromptTemplateLike) || isBaseMessage(messagePromptTemplateLike)) return messagePromptTemplateLike;\n\tif (Array.isArray(messagePromptTemplateLike) && messagePromptTemplateLike[0] === \"placeholder\") {\n\t\tconst messageContent = messagePromptTemplateLike[1];\n\t\tif (extra?.templateFormat === \"mustache\" && typeof messageContent === \"string\" && messageContent.slice(0, 2) === \"{{\" && messageContent.slice(-2) === \"}}\") {\n\t\t\tconst variableName = messageContent.slice(2, -2);\n\t\t\treturn new MessagesPlaceholder({\n\t\t\t\tvariableName,\n\t\t\t\toptional: true\n\t\t\t});\n\t\t} else if (typeof messageContent === \"string\" && messageContent[0] === \"{\" && messageContent[messageContent.length - 1] === \"}\") {\n\t\t\tconst variableName = messageContent.slice(1, -1);\n\t\t\treturn new MessagesPlaceholder({\n\t\t\t\tvariableName,\n\t\t\t\toptional: true\n\t\t\t});\n\t\t}\n\t\tthrow new Error(`Invalid placeholder template for format ${extra?.templateFormat ?? `\"f-string\"`}: \"${messagePromptTemplateLike[1]}\". Expected a variable name surrounded by ${extra?.templateFormat === \"mustache\" ? \"double\" : \"single\"} curly braces.`);\n\t}\n\tconst message = coerceMessageLikeToMessage(messagePromptTemplateLike);\n\tlet templateData;\n\tif (typeof message.content === \"string\") templateData = message.content;\n\telse templateData = message.content.map((item) => {\n\t\tif (\"text\" in item) return {\n\t\t\t...item,\n\t\t\ttext: item.text\n\t\t};\n\t\telse if (\"image_url\" in item) return {\n\t\t\t...item,\n\t\t\timage_url: item.image_url\n\t\t};\n\t\telse return item;\n\t});\n\tif (message._getType() === \"human\") return HumanMessagePromptTemplate.fromTemplate(templateData, extra);\n\telse if (message._getType() === \"ai\") return AIMessagePromptTemplate.fromTemplate(templateData, extra);\n\telse if (message._getType() === \"system\") return SystemMessagePromptTemplate.fromTemplate(templateData, extra);\n\telse if (ChatMessage.isInstance(message)) return ChatMessagePromptTemplate.fromTemplate(message.content, message.role, extra);\n\telse throw new Error(`Could not coerce message prompt template from input. Received message type: \"${message._getType()}\".`);\n}\nfunction isMessagesPlaceholder(x) {\n\treturn x.constructor.lc_name() === \"MessagesPlaceholder\";\n}\n/**\n* Class that represents a chat prompt. It extends the\n* BaseChatPromptTemplate and uses an array of BaseMessagePromptTemplate\n* instances to format a series of messages for a conversation.\n* @example\n* ```typescript\n* const message = SystemMessagePromptTemplate.fromTemplate(\"{text}\");\n* const chatPrompt = ChatPromptTemplate.fromMessages([\n*   [\"ai\", \"You are a helpful assistant.\"],\n*   message,\n* ]);\n* const formattedChatPrompt = await chatPrompt.invoke({\n*   text: \"Hello world!\",\n* });\n* ```\n*/\nvar ChatPromptTemplate = class ChatPromptTemplate extends BaseChatPromptTemplate {\n\tstatic lc_name() {\n\t\treturn \"ChatPromptTemplate\";\n\t}\n\tget lc_aliases() {\n\t\treturn { promptMessages: \"messages\" };\n\t}\n\tpromptMessages;\n\tvalidateTemplate = true;\n\ttemplateFormat = \"f-string\";\n\tconstructor(input) {\n\t\tsuper(input);\n\t\tif (input.templateFormat === \"mustache\" && input.validateTemplate === void 0) this.validateTemplate = false;\n\t\tObject.assign(this, input);\n\t\tif (this.validateTemplate) {\n\t\t\tconst inputVariablesMessages = /* @__PURE__ */ new Set();\n\t\t\tfor (const promptMessage of this.promptMessages) {\n\t\t\t\tif (promptMessage instanceof BaseMessage) continue;\n\t\t\t\tfor (const inputVariable of promptMessage.inputVariables) inputVariablesMessages.add(inputVariable);\n\t\t\t}\n\t\t\tconst totalInputVariables = this.inputVariables;\n\t\t\tconst inputVariablesInstance = new Set(this.partialVariables ? totalInputVariables.concat(Object.keys(this.partialVariables)) : totalInputVariables);\n\t\t\tconst difference = new Set([...inputVariablesInstance].filter((x) => !inputVariablesMessages.has(x)));\n\t\t\tif (difference.size > 0) throw new Error(`Input variables \\`${[...difference]}\\` are not used in any of the prompt messages.`);\n\t\t\tconst otherDifference = new Set([...inputVariablesMessages].filter((x) => !inputVariablesInstance.has(x)));\n\t\t\tif (otherDifference.size > 0) throw new Error(`Input variables \\`${[...otherDifference]}\\` are used in prompt messages but not in the prompt template.`);\n\t\t}\n\t}\n\t_getPromptType() {\n\t\treturn \"chat\";\n\t}\n\tasync _parseImagePrompts(message, inputValues) {\n\t\tif (typeof message.content === \"string\") return message;\n\t\tconst formattedMessageContent = await Promise.all(message.content.map(async (item) => {\n\t\t\tif (item.type !== \"image_url\") return item;\n\t\t\tlet imageUrl = \"\";\n\t\t\tif (typeof item.image_url === \"string\") imageUrl = item.image_url;\n\t\t\telse if (typeof item.image_url === \"object\" && item.image_url !== null && \"url\" in item.image_url && typeof item.image_url.url === \"string\") imageUrl = item.image_url.url;\n\t\t\tconst promptTemplatePlaceholder = PromptTemplate.fromTemplate(imageUrl, { templateFormat: this.templateFormat });\n\t\t\tconst formattedUrl = await promptTemplatePlaceholder.format(inputValues);\n\t\t\tif (typeof item.image_url === \"object\" && item.image_url !== null && \"url\" in item.image_url) item.image_url.url = formattedUrl;\n\t\t\telse item.image_url = formattedUrl;\n\t\t\treturn item;\n\t\t}));\n\t\tmessage.content = formattedMessageContent;\n\t\treturn message;\n\t}\n\tasync formatMessages(values) {\n\t\tconst allValues = await this.mergePartialAndUserVariables(values);\n\t\tlet resultMessages = [];\n\t\tfor (const promptMessage of this.promptMessages) if (promptMessage instanceof BaseMessage) resultMessages.push(await this._parseImagePrompts(promptMessage, allValues));\n\t\telse {\n\t\t\tlet inputValues;\n\t\t\tif (this.templateFormat === \"mustache\") inputValues = { ...allValues };\n\t\t\telse inputValues = promptMessage.inputVariables.reduce((acc, inputVariable) => {\n\t\t\t\tif (!(inputVariable in allValues) && !(isMessagesPlaceholder(promptMessage) && promptMessage.optional)) {\n\t\t\t\t\tconst error = addLangChainErrorFields(/* @__PURE__ */ new Error(`Missing value for input variable \\`${inputVariable.toString()}\\``), \"INVALID_PROMPT_INPUT\");\n\t\t\t\t\tthrow error;\n\t\t\t\t}\n\t\t\t\tacc[inputVariable] = allValues[inputVariable];\n\t\t\t\treturn acc;\n\t\t\t}, {});\n\t\t\tconst message = await promptMessage.formatMessages(inputValues);\n\t\t\tresultMessages = resultMessages.concat(message);\n\t\t}\n\t\treturn resultMessages;\n\t}\n\tasync partial(values) {\n\t\tconst newInputVariables = this.inputVariables.filter((iv) => !(iv in values));\n\t\tconst newPartialVariables = {\n\t\t\t...this.partialVariables ?? {},\n\t\t\t...values\n\t\t};\n\t\tconst promptDict = {\n\t\t\t...this,\n\t\t\tinputVariables: newInputVariables,\n\t\t\tpartialVariables: newPartialVariables\n\t\t};\n\t\treturn new ChatPromptTemplate(promptDict);\n\t}\n\tstatic fromTemplate(template, options) {\n\t\tconst prompt = PromptTemplate.fromTemplate(template, options);\n\t\tconst humanTemplate = new HumanMessagePromptTemplate({ prompt });\n\t\treturn this.fromMessages([humanTemplate]);\n\t}\n\t/**\n\t* Create a chat model-specific prompt from individual chat messages\n\t* or message-like tuples.\n\t* @param promptMessages Messages to be passed to the chat model\n\t* @returns A new ChatPromptTemplate\n\t*/\n\tstatic fromMessages(promptMessages, extra) {\n\t\tconst flattenedMessages = promptMessages.reduce((acc, promptMessage) => acc.concat(promptMessage instanceof ChatPromptTemplate ? promptMessage.promptMessages : [_coerceMessagePromptTemplateLike(promptMessage, extra)]), []);\n\t\tconst flattenedPartialVariables = promptMessages.reduce((acc, promptMessage) => promptMessage instanceof ChatPromptTemplate ? Object.assign(acc, promptMessage.partialVariables) : acc, Object.create(null));\n\t\tconst inputVariables = /* @__PURE__ */ new Set();\n\t\tfor (const promptMessage of flattenedMessages) {\n\t\t\tif (promptMessage instanceof BaseMessage) continue;\n\t\t\tfor (const inputVariable of promptMessage.inputVariables) {\n\t\t\t\tif (inputVariable in flattenedPartialVariables) continue;\n\t\t\t\tinputVariables.add(inputVariable);\n\t\t\t}\n\t\t}\n\t\treturn new this({\n\t\t\t...extra,\n\t\t\tinputVariables: [...inputVariables],\n\t\t\tpromptMessages: flattenedMessages,\n\t\t\tpartialVariables: flattenedPartialVariables,\n\t\t\ttemplateFormat: extra?.templateFormat\n\t\t});\n\t}\n};\n\n//#endregion\nexport { AIMessagePromptTemplate, BaseChatPromptTemplate, BaseMessagePromptTemplate, BaseMessageStringPromptTemplate, ChatMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate };\n//# sourceMappingURL=chat.js.map","import { BaseStringPromptTemplate } from \"./string.js\";\nimport { checkValidTemplate, renderTemplate } from \"./template.js\";\nimport { PromptTemplate } from \"./prompt.js\";\nimport { BaseChatPromptTemplate } from \"./chat.js\";\n\n//#region src/prompts/few_shot.ts\n/**\n* Prompt template that contains few-shot examples.\n* @augments BasePromptTemplate\n* @augments FewShotPromptTemplateInput\n* @example\n* ```typescript\n* const examplePrompt = PromptTemplate.fromTemplate(\n*   \"Input: {input}\\nOutput: {output}\",\n* );\n*\n* const exampleSelector = await SemanticSimilarityExampleSelector.fromExamples(\n*   [\n*     { input: \"happy\", output: \"sad\" },\n*     { input: \"tall\", output: \"short\" },\n*     { input: \"energetic\", output: \"lethargic\" },\n*     { input: \"sunny\", output: \"gloomy\" },\n*     { input: \"windy\", output: \"calm\" },\n*   ],\n*   new OpenAIEmbeddings(),\n*   HNSWLib,\n*   { k: 1 },\n* );\n*\n* const dynamicPrompt = new FewShotPromptTemplate({\n*   exampleSelector,\n*   examplePrompt,\n*   prefix: \"Give the antonym of every input\",\n*   suffix: \"Input: {adjective}\\nOutput:\",\n*   inputVariables: [\"adjective\"],\n* });\n*\n* // Format the dynamic prompt with the input 'rainy'\n* console.log(await dynamicPrompt.format({ adjective: \"rainy\" }));\n*\n* ```\n*/\nvar FewShotPromptTemplate = class FewShotPromptTemplate extends BaseStringPromptTemplate {\n\tlc_serializable = false;\n\texamples;\n\texampleSelector;\n\texamplePrompt;\n\tsuffix = \"\";\n\texampleSeparator = \"\\n\\n\";\n\tprefix = \"\";\n\ttemplateFormat = \"f-string\";\n\tvalidateTemplate = true;\n\tconstructor(input) {\n\t\tsuper(input);\n\t\tObject.assign(this, input);\n\t\tif (this.examples !== void 0 && this.exampleSelector !== void 0) throw new Error(\"Only one of 'examples' and 'example_selector' should be provided\");\n\t\tif (this.examples === void 0 && this.exampleSelector === void 0) throw new Error(\"One of 'examples' and 'example_selector' should be provided\");\n\t\tif (this.validateTemplate) {\n\t\t\tlet totalInputVariables = this.inputVariables;\n\t\t\tif (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));\n\t\t\tcheckValidTemplate(this.prefix + this.suffix, this.templateFormat, totalInputVariables);\n\t\t}\n\t}\n\t_getPromptType() {\n\t\treturn \"few_shot\";\n\t}\n\tstatic lc_name() {\n\t\treturn \"FewShotPromptTemplate\";\n\t}\n\tasync getExamples(inputVariables) {\n\t\tif (this.examples !== void 0) return this.examples;\n\t\tif (this.exampleSelector !== void 0) return this.exampleSelector.selectExamples(inputVariables);\n\t\tthrow new Error(\"One of 'examples' and 'example_selector' should be provided\");\n\t}\n\tasync partial(values) {\n\t\tconst newInputVariables = this.inputVariables.filter((iv) => !(iv in values));\n\t\tconst newPartialVariables = {\n\t\t\t...this.partialVariables ?? {},\n\t\t\t...values\n\t\t};\n\t\tconst promptDict = {\n\t\t\t...this,\n\t\t\tinputVariables: newInputVariables,\n\t\t\tpartialVariables: newPartialVariables\n\t\t};\n\t\treturn new FewShotPromptTemplate(promptDict);\n\t}\n\t/**\n\t* Formats the prompt with the given values.\n\t* @param values The values to format the prompt with.\n\t* @returns A promise that resolves to a string representing the formatted prompt.\n\t*/\n\tasync format(values) {\n\t\tconst allValues = await this.mergePartialAndUserVariables(values);\n\t\tconst examples = await this.getExamples(allValues);\n\t\tconst exampleStrings = await Promise.all(examples.map((example) => this.examplePrompt.format(example)));\n\t\tconst template = [\n\t\t\tthis.prefix,\n\t\t\t...exampleStrings,\n\t\t\tthis.suffix\n\t\t].join(this.exampleSeparator);\n\t\treturn renderTemplate(template, this.templateFormat, allValues);\n\t}\n\tserialize() {\n\t\tif (this.exampleSelector || !this.examples) throw new Error(\"Serializing an example selector is not currently supported\");\n\t\tif (this.outputParser !== void 0) throw new Error(\"Serializing an output parser is not currently supported\");\n\t\treturn {\n\t\t\t_type: this._getPromptType(),\n\t\t\tinput_variables: this.inputVariables,\n\t\t\texample_prompt: this.examplePrompt.serialize(),\n\t\t\texample_separator: this.exampleSeparator,\n\t\t\tsuffix: this.suffix,\n\t\t\tprefix: this.prefix,\n\t\t\ttemplate_format: this.templateFormat,\n\t\t\texamples: this.examples\n\t\t};\n\t}\n\tstatic async deserialize(data) {\n\t\tconst { example_prompt } = data;\n\t\tif (!example_prompt) throw new Error(\"Missing example prompt\");\n\t\tconst examplePrompt = await PromptTemplate.deserialize(example_prompt);\n\t\tlet examples;\n\t\tif (Array.isArray(data.examples)) examples = data.examples;\n\t\telse throw new Error(\"Invalid examples format. Only list or string are supported.\");\n\t\treturn new FewShotPromptTemplate({\n\t\t\tinputVariables: data.input_variables,\n\t\t\texamplePrompt,\n\t\t\texamples,\n\t\t\texampleSeparator: data.example_separator,\n\t\t\tprefix: data.prefix,\n\t\t\tsuffix: data.suffix,\n\t\t\ttemplateFormat: data.template_format\n\t\t});\n\t}\n};\n/**\n* Chat prompt template that contains few-shot examples.\n* @augments BasePromptTemplateInput\n* @augments FewShotChatMessagePromptTemplateInput\n*/\nvar FewShotChatMessagePromptTemplate = class FewShotChatMessagePromptTemplate extends BaseChatPromptTemplate {\n\tlc_serializable = true;\n\texamples;\n\texampleSelector;\n\texamplePrompt;\n\tsuffix = \"\";\n\texampleSeparator = \"\\n\\n\";\n\tprefix = \"\";\n\ttemplateFormat = \"f-string\";\n\tvalidateTemplate = true;\n\t_getPromptType() {\n\t\treturn \"few_shot_chat\";\n\t}\n\tstatic lc_name() {\n\t\treturn \"FewShotChatMessagePromptTemplate\";\n\t}\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.examples = fields.examples;\n\t\tthis.examplePrompt = fields.examplePrompt;\n\t\tthis.exampleSeparator = fields.exampleSeparator ?? \"\\n\\n\";\n\t\tthis.exampleSelector = fields.exampleSelector;\n\t\tthis.prefix = fields.prefix ?? \"\";\n\t\tthis.suffix = fields.suffix ?? \"\";\n\t\tthis.templateFormat = fields.templateFormat ?? \"f-string\";\n\t\tthis.validateTemplate = fields.validateTemplate ?? true;\n\t\tif (this.examples !== void 0 && this.exampleSelector !== void 0) throw new Error(\"Only one of 'examples' and 'example_selector' should be provided\");\n\t\tif (this.examples === void 0 && this.exampleSelector === void 0) throw new Error(\"One of 'examples' and 'example_selector' should be provided\");\n\t\tif (this.validateTemplate) {\n\t\t\tlet totalInputVariables = this.inputVariables;\n\t\t\tif (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));\n\t\t\tcheckValidTemplate(this.prefix + this.suffix, this.templateFormat, totalInputVariables);\n\t\t}\n\t}\n\tasync getExamples(inputVariables) {\n\t\tif (this.examples !== void 0) return this.examples;\n\t\tif (this.exampleSelector !== void 0) return this.exampleSelector.selectExamples(inputVariables);\n\t\tthrow new Error(\"One of 'examples' and 'example_selector' should be provided\");\n\t}\n\t/**\n\t* Formats the list of values and returns a list of formatted messages.\n\t* @param values The values to format the prompt with.\n\t* @returns A promise that resolves to a string representing the formatted prompt.\n\t*/\n\tasync formatMessages(values) {\n\t\tconst allValues = await this.mergePartialAndUserVariables(values);\n\t\tlet examples = await this.getExamples(allValues);\n\t\texamples = examples.map((example) => {\n\t\t\tconst result = {};\n\t\t\tthis.examplePrompt.inputVariables.forEach((inputVariable) => {\n\t\t\t\tresult[inputVariable] = example[inputVariable];\n\t\t\t});\n\t\t\treturn result;\n\t\t});\n\t\tconst messages = [];\n\t\tfor (const example of examples) {\n\t\t\tconst exampleMessages = await this.examplePrompt.formatMessages(example);\n\t\t\tmessages.push(...exampleMessages);\n\t\t}\n\t\treturn messages;\n\t}\n\t/**\n\t* Formats the prompt with the given values.\n\t* @param values The values to format the prompt with.\n\t* @returns A promise that resolves to a string representing the formatted prompt.\n\t*/\n\tasync format(values) {\n\t\tconst allValues = await this.mergePartialAndUserVariables(values);\n\t\tconst examples = await this.getExamples(allValues);\n\t\tconst exampleMessages = await Promise.all(examples.map((example) => this.examplePrompt.formatMessages(example)));\n\t\tconst exampleStrings = exampleMessages.flat().map((message) => message.content);\n\t\tconst template = [\n\t\t\tthis.prefix,\n\t\t\t...exampleStrings,\n\t\t\tthis.suffix\n\t\t].join(this.exampleSeparator);\n\t\treturn renderTemplate(template, this.templateFormat, allValues);\n\t}\n\t/**\n\t* Partially formats the prompt with the given values.\n\t* @param values The values to partially format the prompt with.\n\t* @returns A promise that resolves to an instance of `FewShotChatMessagePromptTemplate` with the given values partially formatted.\n\t*/\n\tasync partial(values) {\n\t\tconst newInputVariables = this.inputVariables.filter((variable) => !(variable in values));\n\t\tconst newPartialVariables = {\n\t\t\t...this.partialVariables ?? {},\n\t\t\t...values\n\t\t};\n\t\tconst promptDict = {\n\t\t\t...this,\n\t\t\tinputVariables: newInputVariables,\n\t\t\tpartialVariables: newPartialVariables\n\t\t};\n\t\treturn new FewShotChatMessagePromptTemplate(promptDict);\n\t}\n};\n\n//#endregion\nexport { FewShotChatMessagePromptTemplate, FewShotPromptTemplate };\n//# sourceMappingURL=few_shot.js.map","import { BasePromptTemplate } from \"./base.js\";\nimport { ChatPromptTemplate } from \"./chat.js\";\n\n//#region src/prompts/pipeline.ts\n/**\n* Class that handles a sequence of prompts, each of which may require\n* different input variables. Includes methods for formatting these\n* prompts, extracting required input values, and handling partial\n* prompts.\n* @example\n* ```typescript\n* const composedPrompt = new PipelinePromptTemplate({\n*   pipelinePrompts: [\n*     {\n*       name: \"introduction\",\n*       prompt: PromptTemplate.fromTemplate(`You are impersonating {person}.`),\n*     },\n*     {\n*       name: \"example\",\n*       prompt: PromptTemplate.fromTemplate(\n*         `Here's an example of an interaction:\n* Q: {example_q}\n* A: {example_a}`,\n*       ),\n*     },\n*     {\n*       name: \"start\",\n*       prompt: PromptTemplate.fromTemplate(\n*         `Now, do this for real!\n* Q: {input}\n* A:`,\n*       ),\n*     },\n*   ],\n*   finalPrompt: PromptTemplate.fromTemplate(\n*     `{introduction}\n* {example}\n* {start}`,\n*   ),\n* });\n*\n* const formattedPrompt = await composedPrompt.format({\n*   person: \"Elon Musk\",\n*   example_q: `What's your favorite car?`,\n*   example_a: \"Tesla\",\n*   input: `What's your favorite social media site?`,\n* });\n* ```\n*/\nvar PipelinePromptTemplate = class PipelinePromptTemplate extends BasePromptTemplate {\n\tstatic lc_name() {\n\t\treturn \"PipelinePromptTemplate\";\n\t}\n\tpipelinePrompts;\n\tfinalPrompt;\n\tconstructor(input) {\n\t\tsuper({\n\t\t\t...input,\n\t\t\tinputVariables: []\n\t\t});\n\t\tthis.pipelinePrompts = input.pipelinePrompts;\n\t\tthis.finalPrompt = input.finalPrompt;\n\t\tthis.inputVariables = this.computeInputValues();\n\t}\n\t/**\n\t* Computes the input values required by the pipeline prompts.\n\t* @returns Array of input values required by the pipeline prompts.\n\t*/\n\tcomputeInputValues() {\n\t\tconst intermediateValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.name);\n\t\tconst inputValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.prompt.inputVariables.filter((inputValue) => !intermediateValues.includes(inputValue))).flat();\n\t\treturn [...new Set(inputValues)];\n\t}\n\tstatic extractRequiredInputValues(allValues, requiredValueNames) {\n\t\treturn requiredValueNames.reduce((requiredValues, valueName) => {\n\t\t\trequiredValues[valueName] = allValues[valueName];\n\t\t\treturn requiredValues;\n\t\t}, {});\n\t}\n\t/**\n\t* Formats the pipeline prompts based on the provided input values.\n\t* @param values Input values to format the pipeline prompts.\n\t* @returns Promise that resolves with the formatted input values.\n\t*/\n\tasync formatPipelinePrompts(values) {\n\t\tconst allValues = await this.mergePartialAndUserVariables(values);\n\t\tfor (const { name: pipelinePromptName, prompt: pipelinePrompt } of this.pipelinePrompts) {\n\t\t\tconst pipelinePromptInputValues = PipelinePromptTemplate.extractRequiredInputValues(allValues, pipelinePrompt.inputVariables);\n\t\t\tif (pipelinePrompt instanceof ChatPromptTemplate) allValues[pipelinePromptName] = await pipelinePrompt.formatMessages(pipelinePromptInputValues);\n\t\t\telse allValues[pipelinePromptName] = await pipelinePrompt.format(pipelinePromptInputValues);\n\t\t}\n\t\treturn PipelinePromptTemplate.extractRequiredInputValues(allValues, this.finalPrompt.inputVariables);\n\t}\n\t/**\n\t* Formats the final prompt value based on the provided input values.\n\t* @param values Input values to format the final prompt value.\n\t* @returns Promise that resolves with the formatted final prompt value.\n\t*/\n\tasync formatPromptValue(values) {\n\t\treturn this.finalPrompt.formatPromptValue(await this.formatPipelinePrompts(values));\n\t}\n\tasync format(values) {\n\t\treturn this.finalPrompt.format(await this.formatPipelinePrompts(values));\n\t}\n\t/**\n\t* Handles partial prompts, which are prompts that have been partially\n\t* filled with input values.\n\t* @param values Partial input values.\n\t* @returns Promise that resolves with a new PipelinePromptTemplate instance with updated input variables.\n\t*/\n\tasync partial(values) {\n\t\tconst promptDict = { ...this };\n\t\tpromptDict.inputVariables = this.inputVariables.filter((iv) => !(iv in values));\n\t\tpromptDict.partialVariables = {\n\t\t\t...this.partialVariables ?? {},\n\t\t\t...values\n\t\t};\n\t\treturn new PipelinePromptTemplate(promptDict);\n\t}\n\tserialize() {\n\t\tthrow new Error(\"Not implemented.\");\n\t}\n\t_getPromptType() {\n\t\treturn \"pipeline\";\n\t}\n};\n\n//#endregion\nexport { PipelinePromptTemplate };\n//# sourceMappingURL=pipeline.js.map","import { RunnableBinding } from \"../runnables/base.js\";\nimport { ChatPromptTemplate } from \"./chat.js\";\n\n//#region src/prompts/structured.ts\nfunction isWithStructuredOutput(x) {\n\treturn typeof x === \"object\" && x != null && \"withStructuredOutput\" in x && typeof x.withStructuredOutput === \"function\";\n}\nfunction isRunnableBinding(x) {\n\treturn typeof x === \"object\" && x != null && \"lc_id\" in x && Array.isArray(x.lc_id) && x.lc_id.join(\"/\") === \"langchain_core/runnables/RunnableBinding\";\n}\nvar StructuredPrompt = class StructuredPrompt extends ChatPromptTemplate {\n\tschema;\n\tmethod;\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"prompts\",\n\t\t\"structured\"\n\t];\n\tget lc_aliases() {\n\t\treturn {\n\t\t\t...super.lc_aliases,\n\t\t\tschema: \"schema_\"\n\t\t};\n\t}\n\tconstructor(input) {\n\t\tsuper(input);\n\t\tthis.schema = input.schema;\n\t\tthis.method = input.method;\n\t}\n\tpipe(coerceable) {\n\t\tif (isWithStructuredOutput(coerceable)) return super.pipe(coerceable.withStructuredOutput(this.schema));\n\t\tif (isRunnableBinding(coerceable) && isWithStructuredOutput(coerceable.bound)) return super.pipe(new RunnableBinding({\n\t\t\tbound: coerceable.bound.withStructuredOutput(this.schema, ...this.method ? [{ method: this.method }] : []),\n\t\t\tkwargs: coerceable.kwargs ?? {},\n\t\t\tconfig: coerceable.config,\n\t\t\tconfigFactories: coerceable.configFactories\n\t\t}));\n\t\tthrow new Error(`Structured prompts need to be piped to a language model that supports the \"withStructuredOutput()\" method.`);\n\t}\n\tstatic fromMessagesAndSchema(promptMessages, schema, method) {\n\t\treturn StructuredPrompt.fromMessages(promptMessages, {\n\t\t\tschema,\n\t\t\tmethod\n\t\t});\n\t}\n};\n\n//#endregion\nexport { StructuredPrompt };\n//# sourceMappingURL=structured.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { BasePromptTemplate } from \"./base.js\";\nimport { BaseStringPromptTemplate } from \"./string.js\";\nimport { DEFAULT_FORMATTER_MAPPING, DEFAULT_PARSER_MAPPING, checkValidTemplate, interpolateFString, interpolateMustache, parseFString, parseMustache, parseTemplate, renderTemplate } from \"./template.js\";\nimport { PromptTemplate } from \"./prompt.js\";\nimport { ImagePromptTemplate } from \"./image.js\";\nimport { DictPromptTemplate } from \"./dict.js\";\nimport { AIMessagePromptTemplate, BaseChatPromptTemplate, BaseMessagePromptTemplate, BaseMessageStringPromptTemplate, ChatMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate } from \"./chat.js\";\nimport { FewShotChatMessagePromptTemplate, FewShotPromptTemplate } from \"./few_shot.js\";\nimport { PipelinePromptTemplate } from \"./pipeline.js\";\nimport { StructuredPrompt } from \"./structured.js\";\n\n//#region src/prompts/index.ts\nvar prompts_exports = {};\n__export(prompts_exports, {\n\tAIMessagePromptTemplate: () => AIMessagePromptTemplate,\n\tBaseChatPromptTemplate: () => BaseChatPromptTemplate,\n\tBaseMessagePromptTemplate: () => BaseMessagePromptTemplate,\n\tBaseMessageStringPromptTemplate: () => BaseMessageStringPromptTemplate,\n\tBasePromptTemplate: () => BasePromptTemplate,\n\tBaseStringPromptTemplate: () => BaseStringPromptTemplate,\n\tChatMessagePromptTemplate: () => ChatMessagePromptTemplate,\n\tChatPromptTemplate: () => ChatPromptTemplate,\n\tDEFAULT_FORMATTER_MAPPING: () => DEFAULT_FORMATTER_MAPPING,\n\tDEFAULT_PARSER_MAPPING: () => DEFAULT_PARSER_MAPPING,\n\tDictPromptTemplate: () => DictPromptTemplate,\n\tFewShotChatMessagePromptTemplate: () => FewShotChatMessagePromptTemplate,\n\tFewShotPromptTemplate: () => FewShotPromptTemplate,\n\tHumanMessagePromptTemplate: () => HumanMessagePromptTemplate,\n\tImagePromptTemplate: () => ImagePromptTemplate,\n\tMessagesPlaceholder: () => MessagesPlaceholder,\n\tPipelinePromptTemplate: () => PipelinePromptTemplate,\n\tPromptTemplate: () => PromptTemplate,\n\tStructuredPrompt: () => StructuredPrompt,\n\tSystemMessagePromptTemplate: () => SystemMessagePromptTemplate,\n\tcheckValidTemplate: () => checkValidTemplate,\n\tinterpolateFString: () => interpolateFString,\n\tinterpolateMustache: () => interpolateMustache,\n\tparseFString: () => parseFString,\n\tparseMustache: () => parseMustache,\n\tparseTemplate: () => parseTemplate,\n\trenderTemplate: () => renderTemplate\n});\n\n//#endregion\nexport { AIMessagePromptTemplate, BaseChatPromptTemplate, BaseMessagePromptTemplate, BaseMessageStringPromptTemplate, BasePromptTemplate, BaseStringPromptTemplate, ChatMessagePromptTemplate, ChatPromptTemplate, DEFAULT_FORMATTER_MAPPING, DEFAULT_PARSER_MAPPING, DictPromptTemplate, FewShotChatMessagePromptTemplate, FewShotPromptTemplate, HumanMessagePromptTemplate, ImagePromptTemplate, MessagesPlaceholder, PipelinePromptTemplate, PromptTemplate, StructuredPrompt, SystemMessagePromptTemplate, checkValidTemplate, interpolateFString, interpolateMustache, parseFString, parseMustache, parseTemplate, prompts_exports, renderTemplate };\n//# sourceMappingURL=index.js.map","import { __export } from \"../../_virtual/rolldown_runtime.js\";\n\n//#region src/retrievers/document_compressors/base.ts\nvar base_exports = {};\n__export(base_exports, { BaseDocumentCompressor: () => BaseDocumentCompressor });\n/**\n* Base Document Compression class. All compressors should extend this class.\n*/\nvar BaseDocumentCompressor = class {\n\tstatic isBaseDocumentCompressor(x) {\n\t\treturn x?.compressDocuments !== void 0;\n\t}\n};\n\n//#endregion\nexport { BaseDocumentCompressor, base_exports };\n//# sourceMappingURL=base.js.map","//#region src/structured_query/ir.ts\nconst Operators = {\n\tand: \"and\",\n\tor: \"or\",\n\tnot: \"not\"\n};\nconst Comparators = {\n\teq: \"eq\",\n\tne: \"ne\",\n\tlt: \"lt\",\n\tgt: \"gt\",\n\tlte: \"lte\",\n\tgte: \"gte\"\n};\n/**\n* Abstract class for visiting expressions. Subclasses must implement\n* visitOperation, visitComparison, and visitStructuredQuery methods.\n*/\nvar Visitor = class {};\n/**\n* Abstract class representing an expression. Subclasses must implement\n* the exprName property and the accept method.\n*/\nvar Expression = class {\n\taccept(visitor) {\n\t\tif (this.exprName === \"Operation\") return visitor.visitOperation(this);\n\t\telse if (this.exprName === \"Comparison\") return visitor.visitComparison(this);\n\t\telse if (this.exprName === \"StructuredQuery\") return visitor.visitStructuredQuery(this);\n\t\telse throw new Error(\"Unknown Expression type\");\n\t}\n};\n/**\n* Abstract class representing a filter directive. It extends the\n* Expression class.\n*/\nvar FilterDirective = class extends Expression {};\n/**\n* Class representing a comparison filter directive. It extends the\n* FilterDirective class.\n*/\nvar Comparison = class extends FilterDirective {\n\texprName = \"Comparison\";\n\tconstructor(comparator, attribute, value) {\n\t\tsuper();\n\t\tthis.comparator = comparator;\n\t\tthis.attribute = attribute;\n\t\tthis.value = value;\n\t}\n};\n/**\n* Class representing an operation filter directive. It extends the\n* FilterDirective class.\n*/\nvar Operation = class extends FilterDirective {\n\texprName = \"Operation\";\n\tconstructor(operator, args) {\n\t\tsuper();\n\t\tthis.operator = operator;\n\t\tthis.args = args;\n\t}\n};\n/**\n* Class representing a structured query expression. It extends the\n* Expression class.\n*/\nvar StructuredQuery = class extends Expression {\n\texprName = \"StructuredQuery\";\n\tconstructor(query, filter) {\n\t\tsuper();\n\t\tthis.query = query;\n\t\tthis.filter = filter;\n\t}\n};\n\n//#endregion\nexport { Comparators, Comparison, Expression, FilterDirective, Operation, Operators, StructuredQuery, Visitor };\n//# sourceMappingURL=ir.js.map","//#region src/structured_query/utils.ts\n/**\n* Checks if the provided argument is an object and not an array.\n*/\nfunction isObject(obj) {\n\treturn obj && typeof obj === \"object\" && !Array.isArray(obj);\n}\n/**\n* Checks if a provided filter is empty. The filter can be a function, an\n* object, a string, or undefined.\n*/\nfunction isFilterEmpty(filter) {\n\tif (!filter) return true;\n\tif (typeof filter === \"string\" && filter.length > 0) return false;\n\tif (typeof filter === \"function\") return false;\n\treturn isObject(filter) && Object.keys(filter).length === 0;\n}\n/**\n* Checks if the provided value is an integer.\n*/\nfunction isInt(value) {\n\tif (typeof value === \"number\") return value % 1 === 0;\n\telse if (typeof value === \"string\") {\n\t\tconst numberValue = parseInt(value, 10);\n\t\treturn !Number.isNaN(numberValue) && numberValue % 1 === 0 && numberValue.toString() === value;\n\t}\n\treturn false;\n}\n/**\n* Checks if the provided value is a floating-point number.\n*/\nfunction isFloat(value) {\n\tif (typeof value === \"number\") return value % 1 !== 0;\n\telse if (typeof value === \"string\") {\n\t\tconst numberValue = parseFloat(value);\n\t\treturn !Number.isNaN(numberValue) && numberValue % 1 !== 0 && numberValue.toString() === value;\n\t}\n\treturn false;\n}\n/**\n* Checks if the provided value is a string that cannot be parsed into a\n* number.\n*/\nfunction isString(value) {\n\treturn typeof value === \"string\" && (Number.isNaN(parseFloat(value)) || parseFloat(value).toString() !== value);\n}\n/**\n* Checks if the provided value is a boolean.\n*/\nfunction isBoolean(value) {\n\treturn typeof value === \"boolean\";\n}\n/**\n* Casts a value that might be string or number to actual string or number.\n* Since LLM might return back an integer/float as a string, we need to cast\n* it back to a number, as many vector databases can't handle number as string\n* values as a comparator.\n*/\nfunction castValue(input) {\n\tlet value;\n\tif (isString(input)) value = input;\n\telse if (isInt(input)) value = parseInt(input, 10);\n\telse if (isFloat(input)) value = parseFloat(input);\n\telse if (isBoolean(input)) value = Boolean(input);\n\telse throw new Error(\"Unsupported value type\");\n\treturn value;\n}\n\n//#endregion\nexport { castValue, isBoolean, isFilterEmpty, isFloat, isInt, isObject, isString };\n//# sourceMappingURL=utils.js.map","import { Comparators, Operators, Visitor } from \"./ir.js\";\nimport { castValue, isFilterEmpty } from \"./utils.js\";\n\n//#region src/structured_query/base.ts\n/**\n* Abstract class that provides a blueprint for creating specific\n* translator classes. Defines two abstract methods: formatFunction and\n* mergeFilters.\n*/\nvar BaseTranslator = class extends Visitor {};\n/**\n* Class that extends the BaseTranslator class and provides concrete\n* implementations for the abstract methods. Also declares three types:\n* VisitOperationOutput, VisitComparisonOutput, and\n* VisitStructuredQueryOutput, which are used as the return types for the\n* visitOperation, visitComparison, and visitStructuredQuery methods\n* respectively.\n*/\nvar BasicTranslator = class extends BaseTranslator {\n\tallowedOperators;\n\tallowedComparators;\n\tconstructor(opts) {\n\t\tsuper();\n\t\tthis.allowedOperators = opts?.allowedOperators ?? [Operators.and, Operators.or];\n\t\tthis.allowedComparators = opts?.allowedComparators ?? [\n\t\t\tComparators.eq,\n\t\t\tComparators.ne,\n\t\t\tComparators.gt,\n\t\t\tComparators.gte,\n\t\t\tComparators.lt,\n\t\t\tComparators.lte\n\t\t];\n\t}\n\tformatFunction(func) {\n\t\tif (func in Comparators) {\n\t\t\tif (this.allowedComparators.length > 0 && this.allowedComparators.indexOf(func) === -1) throw new Error(`Comparator ${func} not allowed. Allowed comparators: ${this.allowedComparators.join(\", \")}`);\n\t\t} else if (func in Operators) {\n\t\t\tif (this.allowedOperators.length > 0 && this.allowedOperators.indexOf(func) === -1) throw new Error(`Operator ${func} not allowed. Allowed operators: ${this.allowedOperators.join(\", \")}`);\n\t\t} else throw new Error(\"Unknown comparator or operator\");\n\t\treturn `$${func}`;\n\t}\n\t/**\n\t* Visits an operation and returns a result.\n\t* @param operation The operation to visit.\n\t* @returns The result of visiting the operation.\n\t*/\n\tvisitOperation(operation) {\n\t\tconst args = operation.args?.map((arg) => arg.accept(this));\n\t\treturn { [this.formatFunction(operation.operator)]: args };\n\t}\n\t/**\n\t* Visits a comparison and returns a result.\n\t* @param comparison The comparison to visit.\n\t* @returns The result of visiting the comparison.\n\t*/\n\tvisitComparison(comparison) {\n\t\treturn { [comparison.attribute]: { [this.formatFunction(comparison.comparator)]: castValue(comparison.value) } };\n\t}\n\t/**\n\t* Visits a structured query and returns a result.\n\t* @param query The structured query to visit.\n\t* @returns The result of visiting the structured query.\n\t*/\n\tvisitStructuredQuery(query) {\n\t\tlet nextArg = {};\n\t\tif (query.filter) nextArg = { filter: query.filter.accept(this) };\n\t\treturn nextArg;\n\t}\n\tmergeFilters(defaultFilter, generatedFilter, mergeType = \"and\", forceDefaultFilter = false) {\n\t\tif (isFilterEmpty(defaultFilter) && isFilterEmpty(generatedFilter)) return void 0;\n\t\tif (isFilterEmpty(defaultFilter) || mergeType === \"replace\") {\n\t\t\tif (isFilterEmpty(generatedFilter)) return void 0;\n\t\t\treturn generatedFilter;\n\t\t}\n\t\tif (isFilterEmpty(generatedFilter)) {\n\t\t\tif (forceDefaultFilter) return defaultFilter;\n\t\t\tif (mergeType === \"and\") return void 0;\n\t\t\treturn defaultFilter;\n\t\t}\n\t\tif (mergeType === \"and\") return { $and: [defaultFilter, generatedFilter] };\n\t\telse if (mergeType === \"or\") return { $or: [defaultFilter, generatedFilter] };\n\t\telse throw new Error(\"Unknown merge type\");\n\t}\n};\n\n//#endregion\nexport { BaseTranslator, BasicTranslator };\n//# sourceMappingURL=base.js.map","import { Comparators, Operators } from \"./ir.js\";\nimport { castValue, isFilterEmpty } from \"./utils.js\";\nimport { BaseTranslator } from \"./base.js\";\n\n//#region src/structured_query/functional.ts\n/**\n* A class that extends `BaseTranslator` to translate structured queries\n* into functional filters.\n* @example\n* ```typescript\n* const functionalTranslator = new FunctionalTranslator();\n* const relevantDocuments = await functionalTranslator.getRelevantDocuments(\n*   \"Which movies are rated higher than 8.5?\",\n* );\n* ```\n*/\nvar FunctionalTranslator = class extends BaseTranslator {\n\tallowedOperators = [Operators.and, Operators.or];\n\tallowedComparators = [\n\t\tComparators.eq,\n\t\tComparators.ne,\n\t\tComparators.gt,\n\t\tComparators.gte,\n\t\tComparators.lt,\n\t\tComparators.lte\n\t];\n\tformatFunction() {\n\t\tthrow new Error(\"Not implemented\");\n\t}\n\t/**\n\t* Returns the allowed comparators for a given data type.\n\t* @param input The input value to get the allowed comparators for.\n\t* @returns An array of allowed comparators for the input data type.\n\t*/\n\tgetAllowedComparatorsForType(inputType) {\n\t\tswitch (inputType) {\n\t\t\tcase \"string\": return [\n\t\t\t\tComparators.eq,\n\t\t\t\tComparators.ne,\n\t\t\t\tComparators.gt,\n\t\t\t\tComparators.gte,\n\t\t\t\tComparators.lt,\n\t\t\t\tComparators.lte\n\t\t\t];\n\t\t\tcase \"number\": return [\n\t\t\t\tComparators.eq,\n\t\t\t\tComparators.ne,\n\t\t\t\tComparators.gt,\n\t\t\t\tComparators.gte,\n\t\t\t\tComparators.lt,\n\t\t\t\tComparators.lte\n\t\t\t];\n\t\t\tcase \"boolean\": return [Comparators.eq, Comparators.ne];\n\t\t\tdefault: throw new Error(`Unsupported data type: ${inputType}`);\n\t\t}\n\t}\n\t/**\n\t* Returns a function that performs a comparison based on the provided\n\t* comparator.\n\t* @param comparator The comparator to base the comparison function on.\n\t* @returns A function that takes two arguments and returns a boolean based on the comparison.\n\t*/\n\tgetComparatorFunction(comparator) {\n\t\tswitch (comparator) {\n\t\t\tcase Comparators.eq: return (a, b) => a === b;\n\t\t\tcase Comparators.ne: return (a, b) => a !== b;\n\t\t\tcase Comparators.gt: return (a, b) => a > b;\n\t\t\tcase Comparators.gte: return (a, b) => a >= b;\n\t\t\tcase Comparators.lt: return (a, b) => a < b;\n\t\t\tcase Comparators.lte: return (a, b) => a <= b;\n\t\t\tdefault: throw new Error(\"Unknown comparator\");\n\t\t}\n\t}\n\t/**\n\t* Returns a function that performs an operation based on the provided\n\t* operator.\n\t* @param operator The operator to base the operation function on.\n\t* @returns A function that takes two boolean arguments and returns a boolean based on the operation.\n\t*/\n\tgetOperatorFunction(operator) {\n\t\tswitch (operator) {\n\t\t\tcase Operators.and: return (a, b) => a && b;\n\t\t\tcase Operators.or: return (a, b) => a || b;\n\t\t\tdefault: throw new Error(\"Unknown operator\");\n\t\t}\n\t}\n\t/**\n\t* Visits the operation part of a structured query and translates it into\n\t* a functional filter.\n\t* @param operation The operation part of a structured query.\n\t* @returns A function that takes a `Document` as an argument and returns a boolean based on the operation.\n\t*/\n\tvisitOperation(operation) {\n\t\tconst { operator, args } = operation;\n\t\tif (this.allowedOperators.includes(operator)) {\n\t\t\tconst operatorFunction = this.getOperatorFunction(operator);\n\t\t\treturn (document) => {\n\t\t\t\tif (!args) return true;\n\t\t\t\treturn args.reduce((acc, arg) => {\n\t\t\t\t\tconst result = arg.accept(this);\n\t\t\t\t\tif (typeof result === \"function\") return operatorFunction(acc, result(document));\n\t\t\t\t\telse throw new Error(\"Filter is not a function\");\n\t\t\t\t}, true);\n\t\t\t};\n\t\t} else throw new Error(\"Operator not allowed\");\n\t}\n\t/**\n\t* Visits the comparison part of a structured query and translates it into\n\t* a functional filter.\n\t* @param comparison The comparison part of a structured query.\n\t* @returns A function that takes a `Document` as an argument and returns a boolean based on the comparison.\n\t*/\n\tvisitComparison(comparison) {\n\t\tconst { comparator, attribute, value } = comparison;\n\t\tconst undefinedTrue = [Comparators.ne];\n\t\tif (this.allowedComparators.includes(comparator)) {\n\t\t\tif (!this.getAllowedComparatorsForType(typeof value).includes(comparator)) throw new Error(`'${comparator}' comparator not allowed to be used with ${typeof value}`);\n\t\t\tconst comparatorFunction = this.getComparatorFunction(comparator);\n\t\t\treturn (document) => {\n\t\t\t\tconst documentValue = document.metadata[attribute];\n\t\t\t\tif (documentValue === void 0) {\n\t\t\t\t\tif (undefinedTrue.includes(comparator)) return true;\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\treturn comparatorFunction(documentValue, castValue(value));\n\t\t\t};\n\t\t} else throw new Error(\"Comparator not allowed\");\n\t}\n\t/**\n\t* Visits a structured query and translates it into a functional filter.\n\t* @param query The structured query to translate.\n\t* @returns An object containing a `filter` property, which is a function that takes a `Document` as an argument and returns a boolean based on the structured query.\n\t*/\n\tvisitStructuredQuery(query) {\n\t\tif (!query.filter) return {};\n\t\tconst filterFunction = query.filter?.accept(this);\n\t\tif (typeof filterFunction !== \"function\") throw new Error(\"Structured query filter is not a function\");\n\t\treturn { filter: filterFunction };\n\t}\n\t/**\n\t* Merges two filters into one, based on the specified merge type.\n\t* @param defaultFilter The default filter function.\n\t* @param generatedFilter The generated filter function.\n\t* @param mergeType The type of merge to perform. Can be 'and', 'or', or 'replace'. Default is 'and'.\n\t* @returns A function that takes a `Document` as an argument and returns a boolean based on the merged filters, or `undefined` if both filters are empty.\n\t*/\n\tmergeFilters(defaultFilter, generatedFilter, mergeType = \"and\") {\n\t\tif (isFilterEmpty(defaultFilter) && isFilterEmpty(generatedFilter)) return void 0;\n\t\tif (isFilterEmpty(defaultFilter) || mergeType === \"replace\") {\n\t\t\tif (isFilterEmpty(generatedFilter)) return void 0;\n\t\t\treturn generatedFilter;\n\t\t}\n\t\tif (isFilterEmpty(generatedFilter)) {\n\t\t\tif (mergeType === \"and\") return void 0;\n\t\t\treturn defaultFilter;\n\t\t}\n\t\tif (mergeType === \"and\") return (document) => defaultFilter(document) && generatedFilter(document);\n\t\telse if (mergeType === \"or\") return (document) => defaultFilter(document) || generatedFilter(document);\n\t\telse throw new Error(\"Unknown merge type\");\n\t}\n};\n\n//#endregion\nexport { FunctionalTranslator };\n//# sourceMappingURL=functional.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { Comparators, Comparison, Expression, FilterDirective, Operation, Operators, StructuredQuery, Visitor } from \"./ir.js\";\nimport { castValue, isBoolean, isFilterEmpty, isFloat, isInt, isObject, isString } from \"./utils.js\";\nimport { BaseTranslator, BasicTranslator } from \"./base.js\";\nimport { FunctionalTranslator } from \"./functional.js\";\n\n//#region src/structured_query/index.ts\nvar structured_query_exports = {};\n__export(structured_query_exports, {\n\tBaseTranslator: () => BaseTranslator,\n\tBasicTranslator: () => BasicTranslator,\n\tComparators: () => Comparators,\n\tComparison: () => Comparison,\n\tExpression: () => Expression,\n\tFilterDirective: () => FilterDirective,\n\tFunctionalTranslator: () => FunctionalTranslator,\n\tOperation: () => Operation,\n\tOperators: () => Operators,\n\tStructuredQuery: () => StructuredQuery,\n\tVisitor: () => Visitor,\n\tcastValue: () => castValue,\n\tisBoolean: () => isBoolean,\n\tisFilterEmpty: () => isFilterEmpty,\n\tisFloat: () => isFloat,\n\tisInt: () => isInt,\n\tisObject: () => isObject,\n\tisString: () => isString\n});\n\n//#endregion\nexport { BaseTranslator, BasicTranslator, Comparators, Comparison, Expression, FilterDirective, FunctionalTranslator, Operation, Operators, StructuredQuery, Visitor, castValue, isBoolean, isFilterEmpty, isFloat, isInt, isObject, isString, structured_query_exports };\n//# sourceMappingURL=index.js.map","import { isInteropZodSchema } from \"../utils/types/zod.js\";\nimport { Runnable } from \"../runnables/base.js\";\n\n//#region src/tools/types.ts\n/**\n* Confirm whether the inputted tool is an instance of `StructuredToolInterface`.\n*\n* @param {StructuredToolInterface | JSONSchema | undefined} tool The tool to check if it is an instance of `StructuredToolInterface`.\n* @returns {tool is StructuredToolInterface} Whether the inputted tool is an instance of `StructuredToolInterface`.\n*/\nfunction isStructuredTool(tool) {\n\treturn tool !== void 0 && Array.isArray(tool.lc_namespace);\n}\n/**\n* Confirm whether the inputted tool is an instance of `RunnableToolLike`.\n*\n* @param {unknown | undefined} tool The tool to check if it is an instance of `RunnableToolLike`.\n* @returns {tool is RunnableToolLike} Whether the inputted tool is an instance of `RunnableToolLike`.\n*/\nfunction isRunnableToolLike(tool) {\n\treturn tool !== void 0 && Runnable.isRunnable(tool) && \"lc_name\" in tool.constructor && typeof tool.constructor.lc_name === \"function\" && tool.constructor.lc_name() === \"RunnableToolLike\";\n}\n/**\n* Confirm whether or not the tool contains the necessary properties to be considered a `StructuredToolParams`.\n*\n* @param {unknown | undefined} tool The object to check if it is a `StructuredToolParams`.\n* @returns {tool is StructuredToolParams} Whether the inputted object is a `StructuredToolParams`.\n*/\nfunction isStructuredToolParams(tool) {\n\treturn !!tool && typeof tool === \"object\" && \"name\" in tool && \"schema\" in tool && (isInteropZodSchema(tool.schema) || tool.schema != null && typeof tool.schema === \"object\" && \"type\" in tool.schema && typeof tool.schema.type === \"string\" && [\n\t\t\"null\",\n\t\t\"boolean\",\n\t\t\"object\",\n\t\t\"array\",\n\t\t\"number\",\n\t\t\"string\"\n\t].includes(tool.schema.type));\n}\n/**\n* Whether or not the tool is one of StructuredTool, RunnableTool or StructuredToolParams.\n* It returns `is StructuredToolParams` since that is the most minimal interface of the three,\n* while still containing the necessary properties to be passed to a LLM for tool calling.\n*\n* @param {unknown | undefined} tool The tool to check if it is a LangChain tool.\n* @returns {tool is StructuredToolParams} Whether the inputted tool is a LangChain tool.\n*/\nfunction isLangChainTool(tool) {\n\treturn isStructuredToolParams(tool) || isRunnableToolLike(tool) || isStructuredTool(tool);\n}\n\n//#endregion\nexport { isLangChainTool, isRunnableToolLike, isStructuredTool, isStructuredToolParams };\n//# sourceMappingURL=types.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { ToolMessage, isDirectToolOutput } from \"../messages/tool.js\";\nimport { ToolInputParsingException, _configHasToolCallId, _isToolCall } from \"./utils.js\";\nimport { CallbackManager, parseCallbackConfigArg } from \"../callbacks/manager.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"../singletons/async_local_storage/index.js\";\nimport \"../singletons/index.js\";\nimport { ensureConfig, mergeConfigs, patchConfig, pickRunnableConfigKeys } from \"../runnables/config.js\";\nimport { getAbortSignalError } from \"../utils/signal.js\";\nimport { interopParseAsync, isInteropZodSchema, isSimpleStringZodSchema } from \"../utils/types/zod.js\";\nimport { validatesOnlyStrings } from \"../utils/json_schema.js\";\nimport { BaseLangChain } from \"../language_models/base.js\";\nimport { isLangChainTool, isRunnableToolLike, isStructuredTool, isStructuredToolParams } from \"./types.js\";\nimport { z } from \"zod/v3\";\nimport { validate } from \"@cfworker/json-schema\";\nimport { z as z$1 } from \"zod/v4\";\n\n//#region src/tools/index.ts\nvar tools_exports = {};\n__export(tools_exports, {\n\tBaseToolkit: () => BaseToolkit,\n\tDynamicStructuredTool: () => DynamicStructuredTool,\n\tDynamicTool: () => DynamicTool,\n\tStructuredTool: () => StructuredTool,\n\tTool: () => Tool,\n\tToolInputParsingException: () => ToolInputParsingException,\n\tisLangChainTool: () => isLangChainTool,\n\tisRunnableToolLike: () => isRunnableToolLike,\n\tisStructuredTool: () => isStructuredTool,\n\tisStructuredToolParams: () => isStructuredToolParams,\n\ttool: () => tool\n});\n/**\n* Base class for Tools that accept input of any shape defined by a Zod schema.\n*/\nvar StructuredTool = class extends BaseLangChain {\n\t/**\n\t* Whether to return the tool's output directly.\n\t*\n\t* Setting this to true means that after the tool is called,\n\t* an agent should stop looping.\n\t*/\n\treturnDirect = false;\n\tverboseParsingErrors = false;\n\tget lc_namespace() {\n\t\treturn [\"langchain\", \"tools\"];\n\t}\n\t/**\n\t* The tool response format.\n\t*\n\t* If \"content\" then the output of the tool is interpreted as the contents of a\n\t* ToolMessage. If \"content_and_artifact\" then the output is expected to be a\n\t* two-tuple corresponding to the (content, artifact) of a ToolMessage.\n\t*\n\t* @default \"content\"\n\t*/\n\tresponseFormat = \"content\";\n\t/**\n\t* Default config object for the tool runnable.\n\t*/\n\tdefaultConfig;\n\tconstructor(fields) {\n\t\tsuper(fields ?? {});\n\t\tthis.verboseParsingErrors = fields?.verboseParsingErrors ?? this.verboseParsingErrors;\n\t\tthis.responseFormat = fields?.responseFormat ?? this.responseFormat;\n\t\tthis.defaultConfig = fields?.defaultConfig ?? this.defaultConfig;\n\t\tthis.metadata = fields?.metadata ?? this.metadata;\n\t}\n\t/**\n\t* Invokes the tool with the provided input and configuration.\n\t* @param input The input for the tool.\n\t* @param config Optional configuration for the tool.\n\t* @returns A Promise that resolves with the tool's output.\n\t*/\n\tasync invoke(input, config) {\n\t\tlet toolInput;\n\t\tlet enrichedConfig = ensureConfig(mergeConfigs(this.defaultConfig, config));\n\t\tif (_isToolCall(input)) {\n\t\t\ttoolInput = input.args;\n\t\t\tenrichedConfig = {\n\t\t\t\t...enrichedConfig,\n\t\t\t\ttoolCall: input\n\t\t\t};\n\t\t} else toolInput = input;\n\t\treturn this.call(toolInput, enrichedConfig);\n\t}\n\t/**\n\t* @deprecated Use .invoke() instead. Will be removed in 0.3.0.\n\t*\n\t* Calls the tool with the provided argument, configuration, and tags. It\n\t* parses the input according to the schema, handles any errors, and\n\t* manages callbacks.\n\t* @param arg The input argument for the tool.\n\t* @param configArg Optional configuration or callbacks for the tool.\n\t* @param tags Optional tags for the tool.\n\t* @returns A Promise that resolves with a string.\n\t*/\n\tasync call(arg, configArg, tags) {\n\t\tconst inputForValidation = _isToolCall(arg) ? arg.args : arg;\n\t\tlet parsed;\n\t\tif (isInteropZodSchema(this.schema)) try {\n\t\t\tparsed = await interopParseAsync(this.schema, inputForValidation);\n\t\t} catch (e) {\n\t\t\tlet message = `Received tool input did not match expected schema`;\n\t\t\tif (this.verboseParsingErrors) message = `${message}\\nDetails: ${e.message}`;\n\t\t\tif (e instanceof Error && e.constructor.name === \"ZodError\") message = `${message}\\n\\n${z$1.prettifyError(e)}`;\n\t\t\tthrow new ToolInputParsingException(message, JSON.stringify(arg));\n\t\t}\n\t\telse {\n\t\t\tconst result$1 = validate(inputForValidation, this.schema);\n\t\t\tif (!result$1.valid) {\n\t\t\t\tlet message = `Received tool input did not match expected schema`;\n\t\t\t\tif (this.verboseParsingErrors) message = `${message}\\nDetails: ${result$1.errors.map((e) => `${e.keywordLocation}: ${e.error}`).join(\"\\n\")}`;\n\t\t\t\tthrow new ToolInputParsingException(message, JSON.stringify(arg));\n\t\t\t}\n\t\t\tparsed = inputForValidation;\n\t\t}\n\t\tconst config = parseCallbackConfigArg(configArg);\n\t\tconst callbackManager_ = CallbackManager.configure(config.callbacks, this.callbacks, config.tags || tags, this.tags, config.metadata, this.metadata, { verbose: this.verbose });\n\t\tconst runManager = await callbackManager_?.handleToolStart(this.toJSON(), typeof arg === \"string\" ? arg : JSON.stringify(arg), config.runId, void 0, void 0, void 0, config.runName);\n\t\tdelete config.runId;\n\t\tlet result;\n\t\ttry {\n\t\t\tresult = await this._call(parsed, runManager, config);\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleToolError(e);\n\t\t\tthrow e;\n\t\t}\n\t\tlet content;\n\t\tlet artifact;\n\t\tif (this.responseFormat === \"content_and_artifact\") if (Array.isArray(result) && result.length === 2) [content, artifact] = result;\n\t\telse throw new Error(`Tool response format is \"content_and_artifact\" but the output was not a two-tuple.\\nResult: ${JSON.stringify(result)}`);\n\t\telse content = result;\n\t\tlet toolCallId;\n\t\tif (_isToolCall(arg)) toolCallId = arg.id;\n\t\tif (!toolCallId && _configHasToolCallId(config)) toolCallId = config.toolCall.id;\n\t\tconst formattedOutput = _formatToolOutput({\n\t\t\tcontent,\n\t\t\tartifact,\n\t\t\ttoolCallId,\n\t\t\tname: this.name,\n\t\t\tmetadata: this.metadata\n\t\t});\n\t\tawait runManager?.handleToolEnd(formattedOutput);\n\t\treturn formattedOutput;\n\t}\n};\n/**\n* Base class for Tools that accept input as a string.\n*/\nvar Tool = class extends StructuredTool {\n\tschema = z.object({ input: z.string().optional() }).transform((obj) => obj.input);\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t}\n\t/**\n\t* @deprecated Use .invoke() instead. Will be removed in 0.3.0.\n\t*\n\t* Calls the tool with the provided argument and callbacks. It handles\n\t* string inputs specifically.\n\t* @param arg The input argument for the tool, which can be a string, undefined, or an input of the tool's schema.\n\t* @param callbacks Optional callbacks for the tool.\n\t* @returns A Promise that resolves with a string.\n\t*/\n\tcall(arg, callbacks) {\n\t\tconst structuredArg = typeof arg === \"string\" || arg == null ? { input: arg } : arg;\n\t\treturn super.call(structuredArg, callbacks);\n\t}\n};\n/**\n* A tool that can be created dynamically from a function, name, and description.\n*/\nvar DynamicTool = class extends Tool {\n\tstatic lc_name() {\n\t\treturn \"DynamicTool\";\n\t}\n\tname;\n\tdescription;\n\tfunc;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.name = fields.name;\n\t\tthis.description = fields.description;\n\t\tthis.func = fields.func;\n\t\tthis.returnDirect = fields.returnDirect ?? this.returnDirect;\n\t}\n\t/**\n\t* @deprecated Use .invoke() instead. Will be removed in 0.3.0.\n\t*/\n\tasync call(arg, configArg) {\n\t\tconst config = parseCallbackConfigArg(configArg);\n\t\tif (config.runName === void 0) config.runName = this.name;\n\t\treturn super.call(arg, config);\n\t}\n\t/** @ignore */\n\tasync _call(input, runManager, parentConfig) {\n\t\treturn this.func(input, runManager, parentConfig);\n\t}\n};\n/**\n* A tool that can be created dynamically from a function, name, and\n* description, designed to work with structured data. It extends the\n* StructuredTool class and overrides the _call method to execute the\n* provided function when the tool is called.\n*\n* Schema can be passed as Zod or JSON schema. The tool will not validate\n* input if JSON schema is passed.\n*/\nvar DynamicStructuredTool = class extends StructuredTool {\n\tstatic lc_name() {\n\t\treturn \"DynamicStructuredTool\";\n\t}\n\tname;\n\tdescription;\n\tfunc;\n\tschema;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.name = fields.name;\n\t\tthis.description = fields.description;\n\t\tthis.func = fields.func;\n\t\tthis.returnDirect = fields.returnDirect ?? this.returnDirect;\n\t\tthis.schema = fields.schema;\n\t}\n\t/**\n\t* @deprecated Use .invoke() instead. Will be removed in 0.3.0.\n\t*/\n\tasync call(arg, configArg, tags) {\n\t\tconst config = parseCallbackConfigArg(configArg);\n\t\tif (config.runName === void 0) config.runName = this.name;\n\t\treturn super.call(arg, config, tags);\n\t}\n\t_call(arg, runManager, parentConfig) {\n\t\treturn this.func(arg, runManager, parentConfig);\n\t}\n};\n/**\n* Abstract base class for toolkits in LangChain. Toolkits are collections\n* of tools that agents can use. Subclasses must implement the `tools`\n* property to provide the specific tools for the toolkit.\n*/\nvar BaseToolkit = class {\n\tgetTools() {\n\t\treturn this.tools;\n\t}\n};\nfunction tool(func, fields) {\n\tconst isSimpleStringSchema = isSimpleStringZodSchema(fields.schema);\n\tconst isStringJSONSchema = validatesOnlyStrings(fields.schema);\n\tif (!fields.schema || isSimpleStringSchema || isStringJSONSchema) return new DynamicTool({\n\t\t...fields,\n\t\tdescription: fields.description ?? fields.schema?.description ?? `${fields.name} tool`,\n\t\tfunc: async (input, runManager, config) => {\n\t\t\treturn new Promise((resolve, reject) => {\n\t\t\t\tconst childConfig = patchConfig(config, { callbacks: runManager?.getChild() });\n\t\t\t\tAsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(func(input, childConfig));\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\treject(e);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\t});\n\tconst schema = fields.schema;\n\tconst description = fields.description ?? fields.schema.description ?? `${fields.name} tool`;\n\treturn new DynamicStructuredTool({\n\t\t...fields,\n\t\tdescription,\n\t\tschema,\n\t\tfunc: async (input, runManager, config) => {\n\t\t\treturn new Promise((resolve, reject) => {\n\t\t\t\tif (config?.signal) config.signal.addEventListener(\"abort\", () => {\n\t\t\t\t\treturn reject(getAbortSignalError(config.signal));\n\t\t\t\t});\n\t\t\t\tconst childConfig = patchConfig(config, { callbacks: runManager?.getChild() });\n\t\t\t\tAsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tconst result = await func(input, childConfig);\n\t\t\t\t\t\t/**\n\t\t\t\t\t\t* If the signal is aborted, we don't want to resolve the promise\n\t\t\t\t\t\t* as the promise is already rejected.\n\t\t\t\t\t\t*/\n\t\t\t\t\t\tif (config?.signal?.aborted) return;\n\t\t\t\t\t\tresolve(result);\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\treject(e);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\t});\n}\nfunction _formatToolOutput(params) {\n\tconst { content, artifact, toolCallId, metadata } = params;\n\tif (toolCallId && !isDirectToolOutput(content)) if (typeof content === \"string\" || Array.isArray(content) && content.every((item) => typeof item === \"object\")) return new ToolMessage({\n\t\tstatus: \"success\",\n\t\tcontent,\n\t\tartifact,\n\t\ttool_call_id: toolCallId,\n\t\tname: params.name,\n\t\tmetadata\n\t});\n\telse return new ToolMessage({\n\t\tstatus: \"success\",\n\t\tcontent: _stringify(content),\n\t\tartifact,\n\t\ttool_call_id: toolCallId,\n\t\tname: params.name,\n\t\tmetadata\n\t});\n\telse return content;\n}\nfunction _stringify(content) {\n\ttry {\n\t\treturn JSON.stringify(content, null, 2) ?? \"\";\n\t} catch (_noOp) {\n\t\treturn `${content}`;\n\t}\n}\n\n//#endregion\nexport { BaseToolkit, DynamicStructuredTool, DynamicTool, StructuredTool, Tool, ToolInputParsingException, isLangChainTool, isRunnableToolLike, isStructuredTool, isStructuredToolParams, tool, tools_exports };\n//# sourceMappingURL=index.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { BaseTracer } from \"./base.js\";\n\n//#region src/tracers/run_collector.ts\nvar run_collector_exports = {};\n__export(run_collector_exports, { RunCollectorCallbackHandler: () => RunCollectorCallbackHandler });\n/**\n* A callback handler that collects traced runs and makes it easy to fetch the traced run object from calls through any langchain object.\n* For instance, it makes it easy to fetch the run ID and then do things with that, such as log feedback.\n*/\nvar RunCollectorCallbackHandler = class extends BaseTracer {\n\t/** The name of the callback handler. */\n\tname = \"run_collector\";\n\t/** The ID of the example. */\n\texampleId;\n\t/** An array of traced runs. */\n\ttracedRuns;\n\t/**\n\t* Creates a new instance of the RunCollectorCallbackHandler class.\n\t* @param exampleId The ID of the example.\n\t*/\n\tconstructor({ exampleId } = {}) {\n\t\tsuper({ _awaitHandler: true });\n\t\tthis.exampleId = exampleId;\n\t\tthis.tracedRuns = [];\n\t}\n\t/**\n\t* Persists the given run object.\n\t* @param run The run object to persist.\n\t*/\n\tasync persistRun(run) {\n\t\tconst run_ = { ...run };\n\t\trun_.reference_example_id = this.exampleId;\n\t\tthis.tracedRuns.push(run_);\n\t}\n};\n\n//#endregion\nexport { RunCollectorCallbackHandler, run_collector_exports };\n//# sourceMappingURL=run_collector.js.map","//#region src/types/stream.ts\nvar stream_exports = {};\n\n//#endregion\nexport { stream_exports };\n//# sourceMappingURL=stream.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\n\n//#region src/utils/chunk_array.ts\nvar chunk_array_exports = {};\n__export(chunk_array_exports, { chunkArray: () => chunkArray });\nconst chunkArray = (arr, chunkSize) => arr.reduce((chunks, elem, index) => {\n\tconst chunkIndex = Math.floor(index / chunkSize);\n\tconst chunk = chunks[chunkIndex] || [];\n\tchunks[chunkIndex] = chunk.concat([elem]);\n\treturn chunks;\n}, []);\n\n//#endregion\nexport { chunkArray, chunk_array_exports };\n//# sourceMappingURL=chunk_array.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { IterableReadableStream } from \"./stream.js\";\n\n//#region src/utils/event_source_parse.ts\nvar event_source_parse_exports = {};\n__export(event_source_parse_exports, {\n\tEventStreamContentType: () => EventStreamContentType,\n\tconvertEventStreamToIterableReadableDataStream: () => convertEventStreamToIterableReadableDataStream,\n\tgetBytes: () => getBytes,\n\tgetLines: () => getLines,\n\tgetMessages: () => getMessages\n});\nconst EventStreamContentType = \"text/event-stream\";\n/**\n* Converts a ReadableStream into a callback pattern.\n* @param stream The input ReadableStream.\n* @param onChunk A function that will be called on each new byte chunk in the stream.\n* @returns {Promise<void>} A promise that will be resolved when the stream closes.\n*/\nasync function getBytes(stream, onChunk) {\n\tif (stream instanceof ReadableStream) {\n\t\tconst reader = stream.getReader();\n\t\twhile (true) {\n\t\t\tconst result = await reader.read();\n\t\t\tif (result.done) {\n\t\t\t\tonChunk(new Uint8Array(), true);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tonChunk(result.value);\n\t\t}\n\t} else try {\n\t\tfor await (const chunk of stream) onChunk(new Uint8Array(chunk));\n\t\tonChunk(new Uint8Array(), true);\n\t} catch (e) {\n\t\tthrow new Error([\n\t\t\t\"Parsing event source stream failed.\",\n\t\t\t\"Ensure your implementation of fetch returns a web or Node readable stream.\",\n\t\t\t`Error: ${e.message}`\n\t\t].join(\"\\n\"));\n\t}\n}\nvar ControlChars = /* @__PURE__ */ function(ControlChars$1) {\n\tControlChars$1[ControlChars$1[\"NewLine\"] = 10] = \"NewLine\";\n\tControlChars$1[ControlChars$1[\"CarriageReturn\"] = 13] = \"CarriageReturn\";\n\tControlChars$1[ControlChars$1[\"Space\"] = 32] = \"Space\";\n\tControlChars$1[ControlChars$1[\"Colon\"] = 58] = \"Colon\";\n\treturn ControlChars$1;\n}(ControlChars || {});\n/**\n* Parses arbitary byte chunks into EventSource line buffers.\n* Each line should be of the format \"field: value\" and ends with \\r, \\n, or \\r\\n.\n* @param onLine A function that will be called on each new EventSource line.\n* @returns A function that should be called for each incoming byte chunk.\n*/\nfunction getLines(onLine) {\n\tlet buffer;\n\tlet position;\n\tlet fieldLength;\n\tlet discardTrailingNewline = false;\n\treturn function onChunk(arr, flush) {\n\t\tif (flush) {\n\t\t\tonLine(arr, 0, true);\n\t\t\treturn;\n\t\t}\n\t\tif (buffer === void 0) {\n\t\t\tbuffer = arr;\n\t\t\tposition = 0;\n\t\t\tfieldLength = -1;\n\t\t} else buffer = concat(buffer, arr);\n\t\tconst bufLength = buffer.length;\n\t\tlet lineStart = 0;\n\t\twhile (position < bufLength) {\n\t\t\tif (discardTrailingNewline) {\n\t\t\t\tif (buffer[position] === ControlChars.NewLine) lineStart = ++position;\n\t\t\t\tdiscardTrailingNewline = false;\n\t\t\t}\n\t\t\tlet lineEnd = -1;\n\t\t\tfor (; position < bufLength && lineEnd === -1; ++position) switch (buffer[position]) {\n\t\t\t\tcase ControlChars.Colon:\n\t\t\t\t\tif (fieldLength === -1) fieldLength = position - lineStart;\n\t\t\t\t\tbreak;\n\t\t\t\tcase ControlChars.CarriageReturn: discardTrailingNewline = true;\n\t\t\t\tcase ControlChars.NewLine:\n\t\t\t\t\tlineEnd = position;\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (lineEnd === -1) break;\n\t\t\tonLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n\t\t\tlineStart = position;\n\t\t\tfieldLength = -1;\n\t\t}\n\t\tif (lineStart === bufLength) buffer = void 0;\n\t\telse if (lineStart !== 0) {\n\t\t\tbuffer = buffer.subarray(lineStart);\n\t\t\tposition -= lineStart;\n\t\t}\n\t};\n}\n/**\n* Parses line buffers into EventSourceMessages.\n* @param onId A function that will be called on each `id` field.\n* @param onRetry A function that will be called on each `retry` field.\n* @param onMessage A function that will be called on each message.\n* @returns A function that should be called for each incoming line buffer.\n*/\nfunction getMessages(onMessage, onId, onRetry) {\n\tlet message = newMessage();\n\tconst decoder = new TextDecoder();\n\treturn function onLine(line, fieldLength, flush) {\n\t\tif (flush) {\n\t\t\tif (!isEmpty(message)) {\n\t\t\t\tonMessage?.(message);\n\t\t\t\tmessage = newMessage();\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tif (line.length === 0) {\n\t\t\tonMessage?.(message);\n\t\t\tmessage = newMessage();\n\t\t} else if (fieldLength > 0) {\n\t\t\tconst field = decoder.decode(line.subarray(0, fieldLength));\n\t\t\tconst valueOffset = fieldLength + (line[fieldLength + 1] === ControlChars.Space ? 2 : 1);\n\t\t\tconst value = decoder.decode(line.subarray(valueOffset));\n\t\t\tswitch (field) {\n\t\t\t\tcase \"data\":\n\t\t\t\t\tmessage.data = message.data ? message.data + \"\\n\" + value : value;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"event\":\n\t\t\t\t\tmessage.event = value;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"id\":\n\t\t\t\t\tonId?.(message.id = value);\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"retry\": {\n\t\t\t\t\tconst retry = parseInt(value, 10);\n\t\t\t\t\tif (!Number.isNaN(retry)) onRetry?.(message.retry = retry);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n}\nfunction concat(a, b) {\n\tconst res = new Uint8Array(a.length + b.length);\n\tres.set(a);\n\tres.set(b, a.length);\n\treturn res;\n}\nfunction newMessage() {\n\treturn {\n\t\tdata: \"\",\n\t\tevent: \"\",\n\t\tid: \"\",\n\t\tretry: void 0\n\t};\n}\nfunction convertEventStreamToIterableReadableDataStream(stream, onMetadataEvent) {\n\tconst dataStream = new ReadableStream({ async start(controller) {\n\t\tconst enqueueLine = getMessages((msg) => {\n\t\t\tif (msg.event === \"error\") throw new Error(msg.data ?? \"Unspecified event streaming error.\");\n\t\t\telse if (msg.event === \"metadata\") onMetadataEvent?.(msg);\n\t\t\telse if (msg.data) controller.enqueue(msg.data);\n\t\t});\n\t\tconst onLine = (line, fieldLength, flush) => {\n\t\t\tenqueueLine(line, fieldLength, flush);\n\t\t\tif (flush) controller.close();\n\t\t};\n\t\tawait getBytes(stream, getLines(onLine));\n\t} });\n\treturn IterableReadableStream.fromReadableStream(dataStream);\n}\nfunction isEmpty(message) {\n\treturn message.data === \"\" && message.event === \"\" && message.id === \"\" && message.retry === void 0;\n}\n\n//#endregion\nexport { EventStreamContentType, convertEventStreamToIterableReadableDataStream, event_source_parse_exports, getBytes, getLines, getMessages };\n//# sourceMappingURL=event_source_parse.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { toJsonSchema } from \"./json_schema.js\";\nimport { isLangChainTool, isRunnableToolLike, isStructuredTool, isStructuredToolParams } from \"../tools/types.js\";\n\n//#region src/utils/function_calling.ts\nvar function_calling_exports = {};\n__export(function_calling_exports, {\n\tconvertToOpenAIFunction: () => convertToOpenAIFunction,\n\tconvertToOpenAITool: () => convertToOpenAITool,\n\tisLangChainTool: () => isLangChainTool,\n\tisRunnableToolLike: () => isRunnableToolLike,\n\tisStructuredTool: () => isStructuredTool,\n\tisStructuredToolParams: () => isStructuredToolParams\n});\n/**\n* Formats a `StructuredTool` or `RunnableToolLike` instance into a format\n* that is compatible with OpenAI function calling. If `StructuredTool` or\n* `RunnableToolLike` has a zod schema, the output will be converted into a\n* JSON schema, which is then used as the parameters for the OpenAI tool.\n*\n* @param {StructuredToolInterface | RunnableToolLike} tool The tool to convert to an OpenAI function.\n* @returns {FunctionDefinition} The inputted tool in OpenAI function format.\n*/\nfunction convertToOpenAIFunction(tool, fields) {\n\tconst fieldsCopy = typeof fields === \"number\" ? void 0 : fields;\n\treturn {\n\t\tname: tool.name,\n\t\tdescription: tool.description,\n\t\tparameters: toJsonSchema(tool.schema),\n\t\t...fieldsCopy?.strict !== void 0 ? { strict: fieldsCopy.strict } : {}\n\t};\n}\n/**\n* Formats a `StructuredTool` or `RunnableToolLike` instance into a\n* format that is compatible with OpenAI tool calling. If `StructuredTool` or\n* `RunnableToolLike` has a zod schema, the output will be converted into a\n* JSON schema, which is then used as the parameters for the OpenAI tool.\n*\n* @param {StructuredToolInterface | Record<string, any> | RunnableToolLike} tool The tool to convert to an OpenAI tool.\n* @returns {ToolDefinition} The inputted tool in OpenAI tool format.\n*/\nfunction convertToOpenAITool(tool, fields) {\n\tconst fieldsCopy = typeof fields === \"number\" ? void 0 : fields;\n\tlet toolDef;\n\tif (isLangChainTool(tool)) toolDef = {\n\t\ttype: \"function\",\n\t\tfunction: convertToOpenAIFunction(tool)\n\t};\n\telse toolDef = tool;\n\tif (fieldsCopy?.strict !== void 0) toolDef.function.strict = fieldsCopy.strict;\n\treturn toolDef;\n}\n\n//#endregion\nexport { convertToOpenAIFunction, convertToOpenAITool, function_calling_exports, isLangChainTool, isRunnableToolLike, isStructuredTool, isStructuredToolParams };\n//# sourceMappingURL=function_calling.js.map","//#region src/utils/ml-distance/similarities.ts\n/**\n* Returns the average of cosine distances between vectors a and b\n* @param a - first vector\n* @param b - second vector\n*\n*/\nfunction cosine(a, b) {\n\tlet p = 0;\n\tlet p2 = 0;\n\tlet q2 = 0;\n\tfor (let i = 0; i < a.length; i++) {\n\t\tp += a[i] * b[i];\n\t\tp2 += a[i] * a[i];\n\t\tq2 += b[i] * b[i];\n\t}\n\treturn p / (Math.sqrt(p2) * Math.sqrt(q2));\n}\n\n//#endregion\nexport { cosine };\n//# sourceMappingURL=similarities.js.map","//#region src/utils/ml-distance/distances.ts\n/**\n*Returns the Inner Product similarity between vectors a and b\n* @link [Inner Product Similarity algorithm](https://www.naun.org/main/NAUN/ijmmas/mmmas-49.pdf)\n* @param a - first vector\n* @param b - second vector\n*\n*/\nfunction innerProduct(a, b) {\n\tlet ans = 0;\n\tfor (let i = 0; i < a.length; i++) ans += a[i] * b[i];\n\treturn ans;\n}\n\n//#endregion\nexport { innerProduct };\n//# sourceMappingURL=distances.js.map","//#region src/utils/ml-distance-euclidean/euclidean.ts\nfunction squaredEuclidean(p, q) {\n\tlet d = 0;\n\tfor (let i = 0; i < p.length; i++) d += (p[i] - q[i]) * (p[i] - q[i]);\n\treturn d;\n}\nfunction euclidean(p, q) {\n\treturn Math.sqrt(squaredEuclidean(p, q));\n}\n\n//#endregion\nexport { euclidean };\n//# sourceMappingURL=euclidean.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { cosine } from \"./ml-distance/similarities.js\";\nimport { innerProduct } from \"./ml-distance/distances.js\";\nimport { euclidean } from \"./ml-distance-euclidean/euclidean.js\";\n\n//#region src/utils/math.ts\nvar math_exports = {};\n__export(math_exports, {\n\tcosineSimilarity: () => cosineSimilarity,\n\teuclideanDistance: () => euclideanDistance,\n\tinnerProduct: () => innerProduct$1,\n\tmatrixFunc: () => matrixFunc,\n\tmaximalMarginalRelevance: () => maximalMarginalRelevance,\n\tnormalize: () => normalize\n});\n/**\n* Apply a row-wise function between two matrices with the same number of columns.\n*\n* @param {number[][]} X - The first matrix.\n* @param {number[][]} Y - The second matrix.\n* @param {VectorFunction} func - The function to apply.\n*\n* @throws {Error} If the number of columns in X and Y are not the same.\n*\n* @returns {number[][] | [[]]} A matrix where each row represents the result of applying the function between the corresponding rows of X and Y.\n*/\nfunction matrixFunc(X, Y, func) {\n\tif (X.length === 0 || X[0].length === 0 || Y.length === 0 || Y[0].length === 0) return [[]];\n\tif (X[0].length !== Y[0].length) throw new Error(`Number of columns in X and Y must be the same. X has shape ${[X.length, X[0].length]} and Y has shape ${[Y.length, Y[0].length]}.`);\n\treturn X.map((xVector) => Y.map((yVector) => func(xVector, yVector)).map((similarity) => Number.isNaN(similarity) ? 0 : similarity));\n}\nfunction normalize(M, similarity = false) {\n\tconst max = matrixMaxVal(M);\n\treturn M.map((row) => row.map((val) => similarity ? 1 - val / max : val / max));\n}\n/**\n* This function calculates the row-wise cosine similarity between two matrices with the same number of columns.\n*\n* @param {number[][]} X - The first matrix.\n* @param {number[][]} Y - The second matrix.\n*\n* @throws {Error} If the number of columns in X and Y are not the same.\n*\n* @returns {number[][] | [[]]} A matrix where each row represents the cosine similarity values between the corresponding rows of X and Y.\n*/\nfunction cosineSimilarity(X, Y) {\n\treturn matrixFunc(X, Y, cosine);\n}\nfunction innerProduct$1(X, Y) {\n\treturn matrixFunc(X, Y, innerProduct);\n}\nfunction euclideanDistance(X, Y) {\n\treturn matrixFunc(X, Y, euclidean);\n}\n/**\n* This function implements the Maximal Marginal Relevance algorithm\n* to select a set of embeddings that maximizes the diversity and relevance to a query embedding.\n*\n* @param {number[]|number[][]} queryEmbedding - The query embedding.\n* @param {number[][]} embeddingList - The list of embeddings to select from.\n* @param {number} [lambda=0.5] - The trade-off parameter between relevance and diversity.\n* @param {number} [k=4] - The maximum number of embeddings to select.\n*\n* @returns {number[]} The indexes of the selected embeddings in the embeddingList.\n*/\nfunction maximalMarginalRelevance(queryEmbedding, embeddingList, lambda = .5, k = 4) {\n\tif (Math.min(k, embeddingList.length) <= 0) return [];\n\tconst queryEmbeddingExpanded = Array.isArray(queryEmbedding[0]) ? queryEmbedding : [queryEmbedding];\n\tconst similarityToQuery = cosineSimilarity(queryEmbeddingExpanded, embeddingList)[0];\n\tconst mostSimilarEmbeddingIndex = argMax(similarityToQuery).maxIndex;\n\tconst selectedEmbeddings = [embeddingList[mostSimilarEmbeddingIndex]];\n\tconst selectedEmbeddingsIndexes = [mostSimilarEmbeddingIndex];\n\twhile (selectedEmbeddingsIndexes.length < Math.min(k, embeddingList.length)) {\n\t\tlet bestScore = -Infinity;\n\t\tlet bestIndex = -1;\n\t\tconst similarityToSelected = cosineSimilarity(embeddingList, selectedEmbeddings);\n\t\tsimilarityToQuery.forEach((queryScore, queryScoreIndex) => {\n\t\t\tif (selectedEmbeddingsIndexes.includes(queryScoreIndex)) return;\n\t\t\tconst maxSimilarityToSelected = Math.max(...similarityToSelected[queryScoreIndex]);\n\t\t\tconst score = lambda * queryScore - (1 - lambda) * maxSimilarityToSelected;\n\t\t\tif (score > bestScore) {\n\t\t\t\tbestScore = score;\n\t\t\t\tbestIndex = queryScoreIndex;\n\t\t\t}\n\t\t});\n\t\tselectedEmbeddings.push(embeddingList[bestIndex]);\n\t\tselectedEmbeddingsIndexes.push(bestIndex);\n\t}\n\treturn selectedEmbeddingsIndexes;\n}\n/**\n* Finds the index of the maximum value in the given array.\n* @param {number[]} array - The input array.\n*\n* @returns {number} The index of the maximum value in the array. If the array is empty, returns -1.\n*/\nfunction argMax(array) {\n\tif (array.length === 0) return {\n\t\tmaxIndex: -1,\n\t\tmaxValue: NaN\n\t};\n\tlet maxValue = array[0];\n\tlet maxIndex = 0;\n\tfor (let i = 1; i < array.length; i += 1) if (array[i] > maxValue) {\n\t\tmaxIndex = i;\n\t\tmaxValue = array[i];\n\t}\n\treturn {\n\t\tmaxIndex,\n\t\tmaxValue\n\t};\n}\nfunction matrixMaxVal(arrays) {\n\treturn arrays.reduce((acc, array) => Math.max(acc, argMax(array).maxValue), 0);\n}\n\n//#endregion\nexport { cosineSimilarity, euclideanDistance, innerProduct$1 as innerProduct, math_exports, matrixFunc, maximalMarginalRelevance, normalize };\n//# sourceMappingURL=math.js.map","import { AIMessage, AIMessageChunk } from \"../../messages/ai.js\";\nimport { ChatGenerationChunk } from \"../../outputs.js\";\nimport { toJsonSchema } from \"../json_schema.js\";\nimport { RunnableLambda } from \"../../runnables/base.js\";\nimport \"../../messages/index.js\";\nimport { BaseChatModel } from \"../../language_models/chat_models.js\";\n\n//#region src/utils/testing/chat_models.ts\nvar FakeChatModel = class extends BaseChatModel {\n\t_combineLLMOutput() {\n\t\treturn [];\n\t}\n\t_llmType() {\n\t\treturn \"fake\";\n\t}\n\tasync _generate(messages, options, runManager) {\n\t\tif (options?.stop?.length) return { generations: [{\n\t\t\tmessage: new AIMessage(options.stop[0]),\n\t\t\ttext: options.stop[0]\n\t\t}] };\n\t\tconst text = messages.map((m) => {\n\t\t\tif (typeof m.content === \"string\") return m.content;\n\t\t\treturn JSON.stringify(m.content, null, 2);\n\t\t}).join(\"\\n\");\n\t\tawait runManager?.handleLLMNewToken(text);\n\t\treturn {\n\t\t\tgenerations: [{\n\t\t\t\tmessage: new AIMessage(text),\n\t\t\t\ttext\n\t\t\t}],\n\t\t\tllmOutput: {}\n\t\t};\n\t}\n};\nvar FakeStreamingChatModel = class FakeStreamingChatModel extends BaseChatModel {\n\tsleep = 50;\n\tresponses = [];\n\tchunks = [];\n\ttoolStyle = \"openai\";\n\tthrownErrorString;\n\ttools = [];\n\tconstructor({ sleep = 50, responses = [], chunks = [], toolStyle = \"openai\", thrownErrorString,...rest }) {\n\t\tsuper(rest);\n\t\tthis.sleep = sleep;\n\t\tthis.responses = responses;\n\t\tthis.chunks = chunks;\n\t\tthis.toolStyle = toolStyle;\n\t\tthis.thrownErrorString = thrownErrorString;\n\t}\n\t_llmType() {\n\t\treturn \"fake\";\n\t}\n\tbindTools(tools) {\n\t\tconst merged = [...this.tools, ...tools];\n\t\tconst toolDicts = merged.map((t) => {\n\t\t\tswitch (this.toolStyle) {\n\t\t\t\tcase \"openai\": return {\n\t\t\t\t\ttype: \"function\",\n\t\t\t\t\tfunction: {\n\t\t\t\t\t\tname: t.name,\n\t\t\t\t\t\tdescription: t.description,\n\t\t\t\t\t\tparameters: toJsonSchema(t.schema)\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t\tcase \"anthropic\": return {\n\t\t\t\t\tname: t.name,\n\t\t\t\t\tdescription: t.description,\n\t\t\t\t\tinput_schema: toJsonSchema(t.schema)\n\t\t\t\t};\n\t\t\t\tcase \"bedrock\": return { toolSpec: {\n\t\t\t\t\tname: t.name,\n\t\t\t\t\tdescription: t.description,\n\t\t\t\t\tinputSchema: toJsonSchema(t.schema)\n\t\t\t\t} };\n\t\t\t\tcase \"google\": return {\n\t\t\t\t\tname: t.name,\n\t\t\t\t\tdescription: t.description,\n\t\t\t\t\tparameters: toJsonSchema(t.schema)\n\t\t\t\t};\n\t\t\t\tdefault: throw new Error(`Unsupported tool style: ${this.toolStyle}`);\n\t\t\t}\n\t\t});\n\t\tconst wrapped = this.toolStyle === \"google\" ? [{ functionDeclarations: toolDicts }] : toolDicts;\n\t\tconst next = new FakeStreamingChatModel({\n\t\t\tsleep: this.sleep,\n\t\t\tresponses: this.responses,\n\t\t\tchunks: this.chunks,\n\t\t\ttoolStyle: this.toolStyle,\n\t\t\tthrownErrorString: this.thrownErrorString\n\t\t});\n\t\tnext.tools = merged;\n\t\treturn next.withConfig({ tools: wrapped });\n\t}\n\tasync _generate(messages, _options, _runManager) {\n\t\tif (this.thrownErrorString) throw new Error(this.thrownErrorString);\n\t\tconst content = this.responses?.[0]?.content ?? messages[0].content ?? \"\";\n\t\tconst generation = { generations: [{\n\t\t\ttext: \"\",\n\t\t\tmessage: new AIMessage({\n\t\t\t\tcontent,\n\t\t\t\ttool_calls: this.chunks?.[0]?.tool_calls\n\t\t\t})\n\t\t}] };\n\t\treturn generation;\n\t}\n\tasync *_streamResponseChunks(_messages, _options, runManager) {\n\t\tif (this.thrownErrorString) throw new Error(this.thrownErrorString);\n\t\tif (this.chunks?.length) {\n\t\t\tfor (const msgChunk of this.chunks) {\n\t\t\t\tconst cg = new ChatGenerationChunk({\n\t\t\t\t\tmessage: new AIMessageChunk({\n\t\t\t\t\t\tcontent: msgChunk.content,\n\t\t\t\t\t\ttool_calls: msgChunk.tool_calls,\n\t\t\t\t\t\tadditional_kwargs: msgChunk.additional_kwargs ?? {}\n\t\t\t\t\t}),\n\t\t\t\t\ttext: msgChunk.content?.toString() ?? \"\"\n\t\t\t\t});\n\t\t\t\tyield cg;\n\t\t\t\tawait runManager?.handleLLMNewToken(msgChunk.content, void 0, void 0, void 0, void 0, { chunk: cg });\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tconst fallback = this.responses?.[0] ?? new AIMessage(typeof _messages[0].content === \"string\" ? _messages[0].content : \"\");\n\t\tconst text = typeof fallback.content === \"string\" ? fallback.content : \"\";\n\t\tfor (const ch of text) {\n\t\t\tawait new Promise((r) => setTimeout(r, this.sleep));\n\t\t\tconst cg = new ChatGenerationChunk({\n\t\t\t\tmessage: new AIMessageChunk({ content: ch }),\n\t\t\t\ttext: ch\n\t\t\t});\n\t\t\tyield cg;\n\t\t\tawait runManager?.handleLLMNewToken(ch, void 0, void 0, void 0, void 0, { chunk: cg });\n\t\t}\n\t}\n};\n/**\n* A fake Chat Model that returns a predefined list of responses. It can be used\n* for testing purposes.\n* @example\n* ```typescript\n* const chat = new FakeListChatModel({\n*   responses: [\"I'll callback later.\", \"You 'console' them!\"]\n* });\n*\n* const firstMessage = new HumanMessage(\"You want to hear a JavaScript joke?\");\n* const secondMessage = new HumanMessage(\"How do you cheer up a JavaScript developer?\");\n*\n* // Call the chat model with a message and log the response\n* const firstResponse = await chat.call([firstMessage]);\n* console.log({ firstResponse });\n*\n* const secondResponse = await chat.call([secondMessage]);\n* console.log({ secondResponse });\n* ```\n*/\nvar FakeListChatModel = class extends BaseChatModel {\n\tstatic lc_name() {\n\t\treturn \"FakeListChatModel\";\n\t}\n\tlc_serializable = true;\n\tresponses;\n\ti = 0;\n\tsleep;\n\temitCustomEvent = false;\n\tconstructor(params) {\n\t\tsuper(params);\n\t\tconst { responses, sleep, emitCustomEvent } = params;\n\t\tthis.responses = responses;\n\t\tthis.sleep = sleep;\n\t\tthis.emitCustomEvent = emitCustomEvent ?? this.emitCustomEvent;\n\t}\n\t_combineLLMOutput() {\n\t\treturn [];\n\t}\n\t_llmType() {\n\t\treturn \"fake-list\";\n\t}\n\tasync _generate(_messages, options, runManager) {\n\t\tawait this._sleepIfRequested();\n\t\tif (options?.thrownErrorString) throw new Error(options.thrownErrorString);\n\t\tif (this.emitCustomEvent) await runManager?.handleCustomEvent(\"some_test_event\", { someval: true });\n\t\tif (options?.stop?.length) return { generations: [this._formatGeneration(options.stop[0])] };\n\t\telse {\n\t\t\tconst response = this._currentResponse();\n\t\t\tthis._incrementResponse();\n\t\t\treturn {\n\t\t\t\tgenerations: [this._formatGeneration(response)],\n\t\t\t\tllmOutput: {}\n\t\t\t};\n\t\t}\n\t}\n\t_formatGeneration(text) {\n\t\treturn {\n\t\t\tmessage: new AIMessage(text),\n\t\t\ttext\n\t\t};\n\t}\n\tasync *_streamResponseChunks(_messages, options, runManager) {\n\t\tconst response = this._currentResponse();\n\t\tthis._incrementResponse();\n\t\tif (this.emitCustomEvent) await runManager?.handleCustomEvent(\"some_test_event\", { someval: true });\n\t\tfor await (const text of response) {\n\t\t\tawait this._sleepIfRequested();\n\t\t\tif (options?.thrownErrorString) throw new Error(options.thrownErrorString);\n\t\t\tconst chunk = this._createResponseChunk(text);\n\t\t\tyield chunk;\n\t\t\trunManager?.handleLLMNewToken(text);\n\t\t}\n\t}\n\tasync _sleepIfRequested() {\n\t\tif (this.sleep !== void 0) await this._sleep();\n\t}\n\tasync _sleep() {\n\t\treturn new Promise((resolve) => {\n\t\t\tsetTimeout(() => resolve(), this.sleep);\n\t\t});\n\t}\n\t_createResponseChunk(text) {\n\t\treturn new ChatGenerationChunk({\n\t\t\tmessage: new AIMessageChunk({ content: text }),\n\t\t\ttext\n\t\t});\n\t}\n\t_currentResponse() {\n\t\treturn this.responses[this.i];\n\t}\n\t_incrementResponse() {\n\t\tif (this.i < this.responses.length - 1) this.i += 1;\n\t\telse this.i = 0;\n\t}\n\twithStructuredOutput(_params, _config) {\n\t\treturn RunnableLambda.from(async (input) => {\n\t\t\tconst message = await this.invoke(input);\n\t\t\tif (message.tool_calls?.[0]?.args) return message.tool_calls[0].args;\n\t\t\tif (typeof message.content === \"string\") return JSON.parse(message.content);\n\t\t\tthrow new Error(\"No structured output found\");\n\t\t});\n\t}\n};\n\n//#endregion\nexport { FakeChatModel, FakeListChatModel, FakeStreamingChatModel };\n//# sourceMappingURL=chat_models.js.map","import { Embeddings } from \"../../embeddings.js\";\n\n//#region src/utils/testing/embeddings.ts\n/**\n* A class that provides synthetic embeddings by overriding the\n* embedDocuments and embedQuery methods to generate embeddings based on\n* the input documents. The embeddings are generated by converting each\n* document into chunks, calculating a numerical value for each chunk, and\n* returning an array of these values as the embedding.\n*/\nvar SyntheticEmbeddings = class extends Embeddings {\n\tvectorSize;\n\tconstructor(params) {\n\t\tsuper(params ?? {});\n\t\tthis.vectorSize = params?.vectorSize ?? 4;\n\t}\n\t/**\n\t* Generates synthetic embeddings for a list of documents.\n\t* @param documents List of documents to generate embeddings for.\n\t* @returns A promise that resolves with a list of synthetic embeddings for each document.\n\t*/\n\tasync embedDocuments(documents) {\n\t\treturn Promise.all(documents.map((doc) => this.embedQuery(doc)));\n\t}\n\t/**\n\t* Generates a synthetic embedding for a document. The document is\n\t* converted into chunks, a numerical value is calculated for each chunk,\n\t* and an array of these values is returned as the embedding.\n\t* @param document The document to generate an embedding for.\n\t* @returns A promise that resolves with a synthetic embedding for the document.\n\t*/\n\tasync embedQuery(document) {\n\t\tlet doc = document;\n\t\tdoc = doc.toLowerCase().replaceAll(/[^a-z ]/g, \"\");\n\t\tconst padMod = doc.length % this.vectorSize;\n\t\tconst padGapSize = padMod === 0 ? 0 : this.vectorSize - padMod;\n\t\tconst padSize = doc.length + padGapSize;\n\t\tdoc = doc.padEnd(padSize, \" \");\n\t\tconst chunkSize = doc.length / this.vectorSize;\n\t\tconst docChunk = [];\n\t\tfor (let co = 0; co < doc.length; co += chunkSize) docChunk.push(doc.slice(co, co + chunkSize));\n\t\tconst ret = docChunk.map((s) => {\n\t\t\tlet sum = 0;\n\t\t\tfor (let co = 0; co < s.length; co += 1) sum += s === \" \" ? 0 : s.charCodeAt(co);\n\t\t\tconst ret$1 = sum % 26 / 26;\n\t\t\treturn ret$1;\n\t\t});\n\t\treturn ret;\n\t}\n};\n/**\n* A class that provides fake embeddings by overriding the embedDocuments\n* and embedQuery methods to return fixed values.\n*/\nvar FakeEmbeddings = class extends Embeddings {\n\tconstructor(params) {\n\t\tsuper(params ?? {});\n\t}\n\t/**\n\t* Generates fixed embeddings for a list of documents.\n\t* @param documents List of documents to generate embeddings for.\n\t* @returns A promise that resolves with a list of fixed embeddings for each document.\n\t*/\n\tembedDocuments(documents) {\n\t\treturn Promise.resolve(documents.map(() => [\n\t\t\t.1,\n\t\t\t.2,\n\t\t\t.3,\n\t\t\t.4\n\t\t]));\n\t}\n\t/**\n\t* Generates a fixed embedding for a query.\n\t* @param _ The query to generate an embedding for.\n\t* @returns A promise that resolves with a fixed embedding for the query.\n\t*/\n\tembedQuery(_) {\n\t\treturn Promise.resolve([\n\t\t\t.1,\n\t\t\t.2,\n\t\t\t.3,\n\t\t\t.4\n\t\t]);\n\t}\n};\n\n//#endregion\nexport { FakeEmbeddings, SyntheticEmbeddings };\n//# sourceMappingURL=embeddings.js.map","import { LLM } from \"../../language_models/llms.js\";\n\n//#region src/utils/testing/llms.ts\nvar FakeLLM = class extends LLM {\n\tresponse;\n\tthrownErrorString;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.response = fields.response;\n\t\tthis.thrownErrorString = fields.thrownErrorString;\n\t}\n\t_llmType() {\n\t\treturn \"fake\";\n\t}\n\tasync _call(prompt, _options, runManager) {\n\t\tif (this.thrownErrorString) throw new Error(this.thrownErrorString);\n\t\tconst response = this.response ?? prompt;\n\t\tawait runManager?.handleLLMNewToken(response);\n\t\treturn response;\n\t}\n};\nvar FakeStreamingLLM = class extends LLM {\n\tsleep = 50;\n\tresponses;\n\tthrownErrorString;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.sleep = fields.sleep ?? this.sleep;\n\t\tthis.responses = fields.responses;\n\t\tthis.thrownErrorString = fields.thrownErrorString;\n\t}\n\t_llmType() {\n\t\treturn \"fake\";\n\t}\n\tasync _call(prompt) {\n\t\tif (this.thrownErrorString) throw new Error(this.thrownErrorString);\n\t\tconst response = this.responses?.[0];\n\t\tthis.responses = this.responses?.slice(1);\n\t\treturn response ?? prompt;\n\t}\n\tasync *_streamResponseChunks(input, _options, runManager) {\n\t\tif (this.thrownErrorString) throw new Error(this.thrownErrorString);\n\t\tconst response = this.responses?.[0];\n\t\tthis.responses = this.responses?.slice(1);\n\t\tfor (const c of response ?? input) {\n\t\t\tawait new Promise((resolve) => setTimeout(resolve, this.sleep));\n\t\t\tyield {\n\t\t\t\ttext: c,\n\t\t\t\tgenerationInfo: {}\n\t\t\t};\n\t\t\tawait runManager?.handleLLMNewToken(c);\n\t\t}\n\t}\n};\n\n//#endregion\nexport { FakeLLM, FakeStreamingLLM };\n//# sourceMappingURL=llms.js.map","import { AIMessage } from \"../../messages/ai.js\";\nimport { HumanMessage } from \"../../messages/human.js\";\nimport { BaseTracer } from \"../../tracers/base.js\";\nimport \"../../messages/index.js\";\nimport { BaseChatMessageHistory, BaseListChatMessageHistory } from \"../../chat_history.js\";\n\n//#region src/utils/testing/message_history.ts\nvar FakeChatMessageHistory = class extends BaseChatMessageHistory {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"message\",\n\t\t\"fake\"\n\t];\n\tmessages = [];\n\tconstructor() {\n\t\tsuper();\n\t}\n\tasync getMessages() {\n\t\treturn this.messages;\n\t}\n\tasync addMessage(message) {\n\t\tthis.messages.push(message);\n\t}\n\tasync addUserMessage(message) {\n\t\tthis.messages.push(new HumanMessage(message));\n\t}\n\tasync addAIMessage(message) {\n\t\tthis.messages.push(new AIMessage(message));\n\t}\n\tasync clear() {\n\t\tthis.messages = [];\n\t}\n};\nvar FakeListChatMessageHistory = class extends BaseListChatMessageHistory {\n\tlc_namespace = [\n\t\t\"langchain_core\",\n\t\t\"message\",\n\t\t\"fake\"\n\t];\n\tmessages = [];\n\tconstructor() {\n\t\tsuper();\n\t}\n\tasync addMessage(message) {\n\t\tthis.messages.push(message);\n\t}\n\tasync getMessages() {\n\t\treturn this.messages;\n\t}\n};\nvar FakeTracer = class extends BaseTracer {\n\tname = \"fake_tracer\";\n\truns = [];\n\tconstructor() {\n\t\tsuper();\n\t}\n\tpersistRun(run) {\n\t\tthis.runs.push(run);\n\t\treturn Promise.resolve();\n\t}\n};\n\n//#endregion\nexport { FakeChatMessageHistory, FakeListChatMessageHistory, FakeTracer };\n//# sourceMappingURL=message_history.js.map","import { BaseOutputParser } from \"../../output_parsers/base.js\";\n\n//#region src/utils/testing/output_parsers.ts\n/**\n* Parser for comma-separated values. It splits the input text by commas\n* and trims the resulting values.\n*/\nvar FakeSplitIntoListParser = class extends BaseOutputParser {\n\tlc_namespace = [\"tests\", \"fake\"];\n\tgetFormatInstructions() {\n\t\treturn \"\";\n\t}\n\tasync parse(text) {\n\t\treturn text.split(\",\").map((value) => value.trim());\n\t}\n};\n\n//#endregion\nexport { FakeSplitIntoListParser };\n//# sourceMappingURL=output_parsers.js.map","import { BaseRetriever } from \"../../retrievers/index.js\";\nimport { Document } from \"../../documents/document.js\";\n\n//#region src/utils/testing/retrievers.ts\nvar FakeRetriever = class extends BaseRetriever {\n\tlc_namespace = [\"test\", \"fake\"];\n\toutput = [new Document({ pageContent: \"foo\" }), new Document({ pageContent: \"bar\" })];\n\tconstructor(fields) {\n\t\tsuper();\n\t\tthis.output = fields?.output ?? this.output;\n\t}\n\tasync _getRelevantDocuments(_query) {\n\t\treturn this.output;\n\t}\n};\n\n//#endregion\nexport { FakeRetriever };\n//# sourceMappingURL=retrievers.js.map","import { Runnable } from \"../../runnables/base.js\";\n\n//#region src/utils/testing/runnables.ts\nvar FakeRunnable = class extends Runnable {\n\tlc_namespace = [\"tests\", \"fake\"];\n\treturnOptions;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.returnOptions = fields.returnOptions;\n\t}\n\tasync invoke(input, options) {\n\t\tif (this.returnOptions) return options ?? {};\n\t\treturn { input };\n\t}\n};\n\n//#endregion\nexport { FakeRunnable };\n//# sourceMappingURL=runnables.js.map","import { StructuredTool } from \"../../tools/index.js\";\n\n//#region src/utils/testing/tools.ts\nvar FakeTool = class extends StructuredTool {\n\tname;\n\tdescription;\n\tschema;\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tthis.name = fields.name;\n\t\tthis.description = fields.description;\n\t\tthis.schema = fields.schema;\n\t}\n\tasync _call(arg, _runManager) {\n\t\treturn JSON.stringify(arg);\n\t}\n};\n\n//#endregion\nexport { FakeTool };\n//# sourceMappingURL=tools.js.map","import { BaseTracer } from \"../../tracers/base.js\";\n\n//#region src/utils/testing/tracers.ts\nvar SingleRunExtractor = class extends BaseTracer {\n\trunPromiseResolver;\n\trunPromise;\n\t/** The name of the callback handler. */\n\tname = \"single_run_extractor\";\n\tconstructor() {\n\t\tsuper();\n\t\tthis.runPromise = new Promise((extract) => {\n\t\t\tthis.runPromiseResolver = extract;\n\t\t});\n\t}\n\tasync persistRun(run) {\n\t\tthis.runPromiseResolver(run);\n\t}\n\tasync extract() {\n\t\treturn this.runPromise;\n\t}\n};\n\n//#endregion\nexport { SingleRunExtractor };\n//# sourceMappingURL=tracers.js.map","import { VectorStore } from \"../../vectorstores.js\";\nimport { Document } from \"../../documents/document.js\";\nimport { cosine } from \"../ml-distance/similarities.js\";\n\n//#region src/utils/testing/vectorstores.ts\n/**\n* Class that extends `VectorStore` to store vectors in memory. Provides\n* methods for adding documents, performing similarity searches, and\n* creating instances from texts, documents, or an existing index.\n*/\nvar FakeVectorStore = class FakeVectorStore extends VectorStore {\n\tmemoryVectors = [];\n\tsimilarity;\n\t_vectorstoreType() {\n\t\treturn \"memory\";\n\t}\n\tconstructor(embeddings, { similarity,...rest } = {}) {\n\t\tsuper(embeddings, rest);\n\t\tthis.similarity = similarity ?? cosine;\n\t}\n\t/**\n\t* Method to add documents to the memory vector store. It extracts the\n\t* text from each document, generates embeddings for them, and adds the\n\t* resulting vectors to the store.\n\t* @param documents Array of `Document` instances to be added to the store.\n\t* @returns Promise that resolves when all documents have been added.\n\t*/\n\tasync addDocuments(documents) {\n\t\tconst texts = documents.map(({ pageContent }) => pageContent);\n\t\treturn this.addVectors(await this.embeddings.embedDocuments(texts), documents);\n\t}\n\t/**\n\t* Method to add vectors to the memory vector store. It creates\n\t* `MemoryVector` instances for each vector and document pair and adds\n\t* them to the store.\n\t* @param vectors Array of vectors to be added to the store.\n\t* @param documents Array of `Document` instances corresponding to the vectors.\n\t* @returns Promise that resolves when all vectors have been added.\n\t*/\n\tasync addVectors(vectors, documents) {\n\t\tconst memoryVectors = vectors.map((embedding, idx) => ({\n\t\t\tcontent: documents[idx].pageContent,\n\t\t\tembedding,\n\t\t\tmetadata: documents[idx].metadata\n\t\t}));\n\t\tthis.memoryVectors = this.memoryVectors.concat(memoryVectors);\n\t}\n\t/**\n\t* Method to perform a similarity search in the memory vector store. It\n\t* calculates the similarity between the query vector and each vector in\n\t* the store, sorts the results by similarity, and returns the top `k`\n\t* results along with their scores.\n\t* @param query Query vector to compare against the vectors in the store.\n\t* @param k Number of top results to return.\n\t* @param filter Optional filter function to apply to the vectors before performing the search.\n\t* @returns Promise that resolves with an array of tuples, each containing a `Document` and its similarity score.\n\t*/\n\tasync similaritySearchVectorWithScore(query, k, filter) {\n\t\tconst filterFunction = (memoryVector) => {\n\t\t\tif (!filter) return true;\n\t\t\tconst doc = new Document({\n\t\t\t\tmetadata: memoryVector.metadata,\n\t\t\t\tpageContent: memoryVector.content\n\t\t\t});\n\t\t\treturn filter(doc);\n\t\t};\n\t\tconst filteredMemoryVectors = this.memoryVectors.filter(filterFunction);\n\t\tconst searches = filteredMemoryVectors.map((vector, index) => ({\n\t\t\tsimilarity: this.similarity(query, vector.embedding),\n\t\t\tindex\n\t\t})).sort((a, b) => a.similarity > b.similarity ? -1 : 0).slice(0, k);\n\t\tconst result = searches.map((search) => [new Document({\n\t\t\tmetadata: filteredMemoryVectors[search.index].metadata,\n\t\t\tpageContent: filteredMemoryVectors[search.index].content\n\t\t}), search.similarity]);\n\t\treturn result;\n\t}\n\t/**\n\t* Static method to create a `FakeVectorStore` instance from an array of\n\t* texts. It creates a `Document` for each text and metadata pair, and\n\t* adds them to the store.\n\t* @param texts Array of texts to be added to the store.\n\t* @param metadatas Array or single object of metadata corresponding to the texts.\n\t* @param embeddings `Embeddings` instance used to generate embeddings for the texts.\n\t* @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.\n\t* @returns Promise that resolves with a new `FakeVectorStore` instance.\n\t*/\n\tstatic async fromTexts(texts, metadatas, embeddings, dbConfig) {\n\t\tconst docs = [];\n\t\tfor (let i = 0; i < texts.length; i += 1) {\n\t\t\tconst metadata = Array.isArray(metadatas) ? metadatas[i] : metadatas;\n\t\t\tconst newDoc = new Document({\n\t\t\t\tpageContent: texts[i],\n\t\t\t\tmetadata\n\t\t\t});\n\t\t\tdocs.push(newDoc);\n\t\t}\n\t\treturn FakeVectorStore.fromDocuments(docs, embeddings, dbConfig);\n\t}\n\t/**\n\t* Static method to create a `FakeVectorStore` instance from an array of\n\t* `Document` instances. It adds the documents to the store.\n\t* @param docs Array of `Document` instances to be added to the store.\n\t* @param embeddings `Embeddings` instance used to generate embeddings for the documents.\n\t* @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.\n\t* @returns Promise that resolves with a new `FakeVectorStore` instance.\n\t*/\n\tstatic async fromDocuments(docs, embeddings, dbConfig) {\n\t\tconst instance = new this(embeddings, dbConfig);\n\t\tawait instance.addDocuments(docs);\n\t\treturn instance;\n\t}\n\t/**\n\t* Static method to create a `FakeVectorStore` instance from an existing\n\t* index. It creates a new `FakeVectorStore` instance without adding any\n\t* documents or vectors.\n\t* @param embeddings `Embeddings` instance used to generate embeddings for the documents.\n\t* @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.\n\t* @returns Promise that resolves with a new `FakeVectorStore` instance.\n\t*/\n\tstatic async fromExistingIndex(embeddings, dbConfig) {\n\t\tconst instance = new this(embeddings, dbConfig);\n\t\treturn instance;\n\t}\n};\n\n//#endregion\nexport { FakeVectorStore };\n//# sourceMappingURL=vectorstores.js.map","import { __export } from \"../../_virtual/rolldown_runtime.js\";\nimport { FakeChatModel, FakeListChatModel, FakeStreamingChatModel } from \"./chat_models.js\";\nimport { FakeEmbeddings, SyntheticEmbeddings } from \"./embeddings.js\";\nimport { FakeLLM, FakeStreamingLLM } from \"./llms.js\";\nimport { FakeChatMessageHistory, FakeListChatMessageHistory, FakeTracer } from \"./message_history.js\";\nimport { FakeSplitIntoListParser } from \"./output_parsers.js\";\nimport { FakeRetriever } from \"./retrievers.js\";\nimport { FakeRunnable } from \"./runnables.js\";\nimport { FakeTool } from \"./tools.js\";\nimport { SingleRunExtractor } from \"./tracers.js\";\nimport { FakeVectorStore } from \"./vectorstores.js\";\n\n//#region src/utils/testing/index.ts\nvar testing_exports = {};\n__export(testing_exports, {\n\tFakeChatMessageHistory: () => FakeChatMessageHistory,\n\tFakeChatModel: () => FakeChatModel,\n\tFakeEmbeddings: () => FakeEmbeddings,\n\tFakeLLM: () => FakeLLM,\n\tFakeListChatMessageHistory: () => FakeListChatMessageHistory,\n\tFakeListChatModel: () => FakeListChatModel,\n\tFakeRetriever: () => FakeRetriever,\n\tFakeRunnable: () => FakeRunnable,\n\tFakeSplitIntoListParser: () => FakeSplitIntoListParser,\n\tFakeStreamingChatModel: () => FakeStreamingChatModel,\n\tFakeStreamingLLM: () => FakeStreamingLLM,\n\tFakeTool: () => FakeTool,\n\tFakeTracer: () => FakeTracer,\n\tFakeVectorStore: () => FakeVectorStore,\n\tSingleRunExtractor: () => SingleRunExtractor,\n\tSyntheticEmbeddings: () => SyntheticEmbeddings\n});\n\n//#endregion\nexport { FakeChatMessageHistory, FakeChatModel, FakeEmbeddings, FakeLLM, FakeListChatMessageHistory, FakeListChatModel, FakeRetriever, FakeRunnable, FakeSplitIntoListParser, FakeStreamingChatModel, FakeStreamingLLM, FakeTool, FakeTracer, FakeVectorStore, SingleRunExtractor, SyntheticEmbeddings, testing_exports };\n//# sourceMappingURL=index.js.map","import { __export } from \"../../_virtual/rolldown_runtime.js\";\nimport { extendInteropZodObject, getInteropZodDefaultGetter, getInteropZodObjectShape, getSchemaDescription, interopParse, interopParseAsync, interopSafeParse, interopSafeParseAsync, interopZodObjectMakeFieldsOptional, interopZodObjectPartial, interopZodObjectPassthrough, interopZodObjectStrict, interopZodTransformInputSchema, isInteropZodLiteral, isInteropZodObject, isInteropZodSchema, isShapelessZodSchema, isSimpleStringZodSchema, isZodArrayV4, isZodLiteralV3, isZodLiteralV4, isZodObjectV3, isZodObjectV4, isZodSchema, isZodSchemaV3, isZodSchemaV4 } from \"./zod.js\";\n\n//#region src/utils/types/index.ts\nvar types_exports = {};\n__export(types_exports, {\n\textendInteropZodObject: () => extendInteropZodObject,\n\tgetInteropZodDefaultGetter: () => getInteropZodDefaultGetter,\n\tgetInteropZodObjectShape: () => getInteropZodObjectShape,\n\tgetSchemaDescription: () => getSchemaDescription,\n\tinteropParse: () => interopParse,\n\tinteropParseAsync: () => interopParseAsync,\n\tinteropSafeParse: () => interopSafeParse,\n\tinteropSafeParseAsync: () => interopSafeParseAsync,\n\tinteropZodObjectMakeFieldsOptional: () => interopZodObjectMakeFieldsOptional,\n\tinteropZodObjectPartial: () => interopZodObjectPartial,\n\tinteropZodObjectPassthrough: () => interopZodObjectPassthrough,\n\tinteropZodObjectStrict: () => interopZodObjectStrict,\n\tinteropZodTransformInputSchema: () => interopZodTransformInputSchema,\n\tisInteropZodLiteral: () => isInteropZodLiteral,\n\tisInteropZodObject: () => isInteropZodObject,\n\tisInteropZodSchema: () => isInteropZodSchema,\n\tisShapelessZodSchema: () => isShapelessZodSchema,\n\tisSimpleStringZodSchema: () => isSimpleStringZodSchema,\n\tisZodArrayV4: () => isZodArrayV4,\n\tisZodLiteralV3: () => isZodLiteralV3,\n\tisZodLiteralV4: () => isZodLiteralV4,\n\tisZodObjectV3: () => isZodObjectV3,\n\tisZodObjectV4: () => isZodObjectV4,\n\tisZodSchema: () => isZodSchema,\n\tisZodSchemaV3: () => isZodSchemaV3,\n\tisZodSchemaV4: () => isZodSchemaV4\n});\n\n//#endregion\nexport { extendInteropZodObject, getInteropZodDefaultGetter, getInteropZodObjectShape, getSchemaDescription, interopParse, interopParseAsync, interopSafeParse, interopSafeParseAsync, interopZodObjectMakeFieldsOptional, interopZodObjectPartial, interopZodObjectPassthrough, interopZodObjectStrict, interopZodTransformInputSchema, isInteropZodLiteral, isInteropZodObject, isInteropZodSchema, isShapelessZodSchema, isSimpleStringZodSchema, isZodArrayV4, isZodLiteralV3, isZodLiteralV4, isZodObjectV3, isZodObjectV4, isZodSchema, isZodSchemaV3, isZodSchemaV4, types_exports };\n//# sourceMappingURL=index.js.map","import { __export } from \"../_virtual/rolldown_runtime.js\";\nimport { agents_exports } from \"../agents.js\";\nimport { serializable_exports } from \"./serializable.js\";\nimport { tool_exports } from \"../messages/tool.js\";\nimport { env_exports } from \"../utils/env.js\";\nimport { base_exports } from \"../callbacks/base.js\";\nimport { base_exports as base_exports$1 } from \"../tracers/base.js\";\nimport { console_exports } from \"../tracers/console.js\";\nimport { tracer_langchain_exports } from \"../tracers/tracer_langchain.js\";\nimport { promises_exports } from \"../callbacks/promises.js\";\nimport { manager_exports } from \"../callbacks/manager.js\";\nimport { singletons_exports } from \"../singletons/index.js\";\nimport { stream_exports } from \"../utils/stream.js\";\nimport { log_stream_exports } from \"../tracers/log_stream.js\";\nimport { outputs_exports } from \"../outputs.js\";\nimport { async_caller_exports } from \"../utils/async_caller.js\";\nimport { json_schema_exports } from \"../utils/json_schema.js\";\nimport { graph_exports } from \"../runnables/graph.js\";\nimport { messages_exports } from \"../messages/index.js\";\nimport { chat_history_exports } from \"../chat_history.js\";\nimport { embeddings_exports } from \"../embeddings.js\";\nimport { src_exports } from \"../index.js\";\nimport { memory_exports } from \"../memory.js\";\nimport { prompt_values_exports } from \"../prompt_values.js\";\nimport { stores_exports } from \"../stores.js\";\nimport { retrievers_exports } from \"../retrievers/index.js\";\nimport { vectorstores_exports } from \"../vectorstores.js\";\nimport { hash_exports } from \"../utils/hash.js\";\nimport { base_exports as base_exports$2 } from \"../caches/base.js\";\nimport { base_exports as base_exports$3 } from \"../document_loaders/base.js\";\nimport { langsmith_exports } from \"../document_loaders/langsmith.js\";\nimport { documents_exports } from \"../documents/index.js\";\nimport { example_selectors_exports } from \"../example_selectors/index.js\";\nimport { indexing_exports } from \"../indexing/index.js\";\nimport { tiktoken_exports } from \"../utils/tiktoken.js\";\nimport { base_exports as base_exports$4 } from \"../language_models/base.js\";\nimport { chat_models_exports } from \"../language_models/chat_models.js\";\nimport { llms_exports } from \"../language_models/llms.js\";\nimport { runnables_exports } from \"../runnables/index.js\";\nimport { json_patch_exports } from \"../utils/json_patch.js\";\nimport { output_parsers_exports } from \"../output_parsers/index.js\";\nimport { openai_tools_exports } from \"../output_parsers/openai_tools/index.js\";\nimport { openai_functions_exports } from \"../output_parsers/openai_functions/index.js\";\nimport { prompts_exports } from \"../prompts/index.js\";\nimport { base_exports as base_exports$5 } from \"../retrievers/document_compressors/base.js\";\nimport { structured_query_exports } from \"../structured_query/index.js\";\nimport { tools_exports } from \"../tools/index.js\";\nimport { run_collector_exports } from \"../tracers/run_collector.js\";\nimport { stream_exports as stream_exports$1 } from \"../types/stream.js\";\nimport { chunk_array_exports } from \"../utils/chunk_array.js\";\nimport { event_source_parse_exports } from \"../utils/event_source_parse.js\";\nimport { function_calling_exports } from \"../utils/function_calling.js\";\nimport { math_exports } from \"../utils/math.js\";\nimport { testing_exports } from \"../utils/testing/index.js\";\nimport { types_exports } from \"../utils/types/index.js\";\n\n//#region src/load/import_map.ts\nvar import_map_exports = {};\n__export(import_map_exports, {\n\tagents: () => agents_exports,\n\tcaches: () => base_exports$2,\n\tcallbacks__base: () => base_exports,\n\tcallbacks__manager: () => manager_exports,\n\tcallbacks__promises: () => promises_exports,\n\tchat_history: () => chat_history_exports,\n\tdocument_loaders__base: () => base_exports$3,\n\tdocument_loaders__langsmith: () => langsmith_exports,\n\tdocuments: () => documents_exports,\n\tembeddings: () => embeddings_exports,\n\texample_selectors: () => example_selectors_exports,\n\tindex: () => src_exports,\n\tindexing: () => indexing_exports,\n\tlanguage_models__base: () => base_exports$4,\n\tlanguage_models__chat_models: () => chat_models_exports,\n\tlanguage_models__llms: () => llms_exports,\n\tload__serializable: () => serializable_exports,\n\tmemory: () => memory_exports,\n\tmessages: () => messages_exports,\n\tmessages__tool: () => tool_exports,\n\toutput_parsers: () => output_parsers_exports,\n\toutput_parsers__openai_functions: () => openai_functions_exports,\n\toutput_parsers__openai_tools: () => openai_tools_exports,\n\toutputs: () => outputs_exports,\n\tprompt_values: () => prompt_values_exports,\n\tprompts: () => prompts_exports,\n\tretrievers: () => retrievers_exports,\n\tretrievers__document_compressors: () => base_exports$5,\n\trunnables: () => runnables_exports,\n\trunnables__graph: () => graph_exports,\n\tsingletons: () => singletons_exports,\n\tstores: () => stores_exports,\n\tstructured_query: () => structured_query_exports,\n\ttools: () => tools_exports,\n\ttracers__base: () => base_exports$1,\n\ttracers__console: () => console_exports,\n\ttracers__log_stream: () => log_stream_exports,\n\ttracers__run_collector: () => run_collector_exports,\n\ttracers__tracer_langchain: () => tracer_langchain_exports,\n\ttypes__stream: () => stream_exports$1,\n\tutils__async_caller: () => async_caller_exports,\n\tutils__chunk_array: () => chunk_array_exports,\n\tutils__env: () => env_exports,\n\tutils__event_source_parse: () => event_source_parse_exports,\n\tutils__function_calling: () => function_calling_exports,\n\tutils__hash: () => hash_exports,\n\tutils__json_patch: () => json_patch_exports,\n\tutils__json_schema: () => json_schema_exports,\n\tutils__math: () => math_exports,\n\tutils__stream: () => stream_exports,\n\tutils__testing: () => testing_exports,\n\tutils__tiktoken: () => tiktoken_exports,\n\tutils__types: () => types_exports,\n\tvectorstores: () => vectorstores_exports\n});\n\n//#endregion\nexport { import_map_exports };\n//# sourceMappingURL=import_map.js.map","import { keyFromJson, mapKeys } from \"./map_keys.js\";\nimport { get_lc_unique_name } from \"./serializable.js\";\nimport { getEnvironmentVariable } from \"../utils/env.js\";\nimport { optionalImportEntrypoints } from \"./import_constants.js\";\nimport { import_map_exports } from \"./import_map.js\";\n\n//#region src/load/index.ts\nfunction combineAliasesAndInvert(constructor) {\n\tconst aliases = {};\n\tfor (let current = constructor; current && current.prototype; current = Object.getPrototypeOf(current)) Object.assign(aliases, Reflect.get(current.prototype, \"lc_aliases\"));\n\treturn Object.entries(aliases).reduce((acc, [key, value]) => {\n\t\tacc[value] = key;\n\t\treturn acc;\n\t}, {});\n}\nasync function reviver(value) {\n\tconst { optionalImportsMap = {}, optionalImportEntrypoints: optionalImportEntrypoints$1 = [], importMap = {}, secretsMap = {}, path = [\"$\"] } = this;\n\tconst pathStr = path.join(\".\");\n\tif (typeof value === \"object\" && value !== null && !Array.isArray(value) && \"lc\" in value && \"type\" in value && \"id\" in value && value.lc === 1 && value.type === \"secret\") {\n\t\tconst serialized = value;\n\t\tconst [key] = serialized.id;\n\t\tif (key in secretsMap) return secretsMap[key];\n\t\telse {\n\t\t\tconst secretValueInEnv = getEnvironmentVariable(key);\n\t\t\tif (secretValueInEnv) return secretValueInEnv;\n\t\t\telse throw new Error(`Missing key \"${key}\" for ${pathStr} in load(secretsMap={})`);\n\t\t}\n\t} else if (typeof value === \"object\" && value !== null && !Array.isArray(value) && \"lc\" in value && \"type\" in value && \"id\" in value && value.lc === 1 && value.type === \"not_implemented\") {\n\t\tconst serialized = value;\n\t\tconst str = JSON.stringify(serialized);\n\t\tthrow new Error(`Trying to load an object that doesn't implement serialization: ${pathStr} -> ${str}`);\n\t} else if (typeof value === \"object\" && value !== null && !Array.isArray(value) && \"lc\" in value && \"type\" in value && \"id\" in value && \"kwargs\" in value && value.lc === 1) {\n\t\tconst serialized = value;\n\t\tconst str = JSON.stringify(serialized);\n\t\tconst [name, ...namespaceReverse] = serialized.id.slice().reverse();\n\t\tconst namespace = namespaceReverse.reverse();\n\t\tconst importMaps = {\n\t\t\tlangchain_core: import_map_exports,\n\t\t\tlangchain: importMap\n\t\t};\n\t\tlet module = null;\n\t\tconst optionalImportNamespaceAliases = [namespace.join(\"/\")];\n\t\tif (namespace[0] === \"langchain_community\") optionalImportNamespaceAliases.push([\"langchain\", ...namespace.slice(1)].join(\"/\"));\n\t\tconst matchingNamespaceAlias = optionalImportNamespaceAliases.find((alias) => alias in optionalImportsMap);\n\t\tif (optionalImportEntrypoints.concat(optionalImportEntrypoints$1).includes(namespace.join(\"/\")) || matchingNamespaceAlias) if (matchingNamespaceAlias !== void 0) module = await optionalImportsMap[matchingNamespaceAlias];\n\t\telse throw new Error(`Missing key \"${namespace.join(\"/\")}\" for ${pathStr} in load(optionalImportsMap={})`);\n\t\telse {\n\t\t\tlet finalImportMap;\n\t\t\tif (namespace[0] === \"langchain\" || namespace[0] === \"langchain_core\") {\n\t\t\t\tfinalImportMap = importMaps[namespace[0]];\n\t\t\t\tnamespace.shift();\n\t\t\t} else throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);\n\t\t\tif (namespace.length === 0) throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);\n\t\t\tlet importMapKey;\n\t\t\tdo {\n\t\t\t\timportMapKey = namespace.join(\"__\");\n\t\t\t\tif (importMapKey in finalImportMap) break;\n\t\t\t\telse namespace.pop();\n\t\t\t} while (namespace.length > 0);\n\t\t\tif (importMapKey in finalImportMap) module = finalImportMap[importMapKey];\n\t\t}\n\t\tif (typeof module !== \"object\" || module === null) throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);\n\t\tconst builder = module[name] ?? Object.values(module).find((v) => typeof v === \"function\" && get_lc_unique_name(v) === name);\n\t\tif (typeof builder !== \"function\") throw new Error(`Invalid identifer: ${pathStr} -> ${str}`);\n\t\tconst kwargs = await reviver.call({\n\t\t\t...this,\n\t\t\tpath: [...path, \"kwargs\"]\n\t\t}, serialized.kwargs);\n\t\tif (serialized.type === \"constructor\") {\n\t\t\tconst instance = new builder(mapKeys(kwargs, keyFromJson, combineAliasesAndInvert(builder)));\n\t\t\tObject.defineProperty(instance.constructor, \"name\", { value: name });\n\t\t\treturn instance;\n\t\t} else throw new Error(`Invalid type: ${pathStr} -> ${str}`);\n\t} else if (typeof value === \"object\" && value !== null) if (Array.isArray(value)) return Promise.all(value.map((v, i) => reviver.call({\n\t\t...this,\n\t\tpath: [...path, `${i}`]\n\t}, v)));\n\telse return Object.fromEntries(await Promise.all(Object.entries(value).map(async ([key, value$1]) => [key, await reviver.call({\n\t\t...this,\n\t\tpath: [...path, key]\n\t}, value$1)])));\n\treturn value;\n}\nasync function load(text, mappings) {\n\tconst json = JSON.parse(text);\n\treturn reviver.call({ ...mappings }, json);\n}\n\n//#endregion\nexport { load };\n//# sourceMappingURL=index.js.map","import { stringify } from \"./utils/fast-safe-stringify/index.js\";\nimport { load } from \"@langchain/core/load\";\n\n//#region src/serde/jsonplus.ts\nfunction isLangChainSerializedObject(value) {\n\treturn value !== null && value.lc === 1 && value.type === \"constructor\" && Array.isArray(value.id);\n}\n/**\n* The replacer in stringify does not allow delegation to built-in LangChain\n* serialization methods, and instead immediately calls `.toJSON()` and\n* continues to stringify subfields.\n*\n* We therefore must start from the most nested elements in the input and\n* deserialize upwards rather than top-down.\n*/\nasync function _reviver(value) {\n\tif (value && typeof value === \"object\") if (Array.isArray(value)) {\n\t\tconst revivedArray = await Promise.all(value.map((item) => _reviver(item)));\n\t\treturn revivedArray;\n\t} else {\n\t\tconst revivedObj = {};\n\t\tfor (const [k, v] of Object.entries(value)) revivedObj[k] = await _reviver(v);\n\t\tif (revivedObj.lc === 2 && revivedObj.type === \"undefined\") return void 0;\n\t\telse if (revivedObj.lc === 2 && revivedObj.type === \"constructor\" && Array.isArray(revivedObj.id)) try {\n\t\t\tconst constructorName = revivedObj.id[revivedObj.id.length - 1];\n\t\t\tlet constructor;\n\t\t\tswitch (constructorName) {\n\t\t\t\tcase \"Set\":\n\t\t\t\t\tconstructor = Set;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"Map\":\n\t\t\t\t\tconstructor = Map;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"RegExp\":\n\t\t\t\t\tconstructor = RegExp;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"Error\":\n\t\t\t\t\tconstructor = Error;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault: return revivedObj;\n\t\t\t}\n\t\t\tif (revivedObj.method) return constructor[revivedObj.method](...revivedObj.args || []);\n\t\t\telse return new constructor(...revivedObj.args || []);\n\t\t} catch (error) {\n\t\t\treturn revivedObj;\n\t\t}\n\t\telse if (isLangChainSerializedObject(revivedObj)) return load(JSON.stringify(revivedObj));\n\t\treturn revivedObj;\n\t}\n\treturn value;\n}\nfunction _encodeConstructorArgs(constructor, method, args, kwargs) {\n\treturn {\n\t\tlc: 2,\n\t\ttype: \"constructor\",\n\t\tid: [constructor.name],\n\t\tmethod: method ?? null,\n\t\targs: args ?? [],\n\t\tkwargs: kwargs ?? {}\n\t};\n}\nfunction _default(obj) {\n\tif (obj === void 0) return {\n\t\tlc: 2,\n\t\ttype: \"undefined\"\n\t};\n\telse if (obj instanceof Set || obj instanceof Map) return _encodeConstructorArgs(obj.constructor, void 0, [Array.from(obj)]);\n\telse if (obj instanceof RegExp) return _encodeConstructorArgs(RegExp, void 0, [obj.source, obj.flags]);\n\telse if (obj instanceof Error) return _encodeConstructorArgs(obj.constructor, void 0, [obj.message]);\n\telse if (obj?.lg_name === \"Send\") return {\n\t\tnode: obj.node,\n\t\targs: obj.args\n\t};\n\telse return obj;\n}\nvar JsonPlusSerializer = class {\n\t_dumps(obj) {\n\t\tconst encoder = new TextEncoder();\n\t\treturn encoder.encode(stringify(obj, (_, value) => {\n\t\t\treturn _default(value);\n\t\t}));\n\t}\n\tasync dumpsTyped(obj) {\n\t\tif (obj instanceof Uint8Array) return [\"bytes\", obj];\n\t\telse return [\"json\", this._dumps(obj)];\n\t}\n\tasync _loads(data) {\n\t\tconst parsed = JSON.parse(data);\n\t\treturn _reviver(parsed);\n\t}\n\tasync loadsTyped(type, data) {\n\t\tif (type === \"bytes\") return typeof data === \"string\" ? new TextEncoder().encode(data) : data;\n\t\telse if (type === \"json\") return this._loads(typeof data === \"string\" ? data : new TextDecoder().decode(data));\n\t\telse throw new Error(`Unknown serialization type: ${type}`);\n\t}\n};\n\n//#endregion\nexport { JsonPlusSerializer };\n//# sourceMappingURL=jsonplus.js.map","import { uuid6 } from \"./id.js\";\nimport { ERROR, INTERRUPT, RESUME, SCHEDULED } from \"./serde/types.js\";\nimport { JsonPlusSerializer } from \"./serde/jsonplus.js\";\n\n//#region src/base.ts\nfunction deepCopy(obj) {\n\tif (typeof obj !== \"object\" || obj === null) return obj;\n\tconst newObj = Array.isArray(obj) ? [] : {};\n\tfor (const key in obj) if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = deepCopy(obj[key]);\n\treturn newObj;\n}\n/** @hidden */\nfunction emptyCheckpoint() {\n\treturn {\n\t\tv: 4,\n\t\tid: uuid6(-2),\n\t\tts: (/* @__PURE__ */ new Date()).toISOString(),\n\t\tchannel_values: {},\n\t\tchannel_versions: {},\n\t\tversions_seen: {}\n\t};\n}\n/** @hidden */\nfunction copyCheckpoint(checkpoint) {\n\treturn {\n\t\tv: checkpoint.v,\n\t\tid: checkpoint.id,\n\t\tts: checkpoint.ts,\n\t\tchannel_values: { ...checkpoint.channel_values },\n\t\tchannel_versions: { ...checkpoint.channel_versions },\n\t\tversions_seen: deepCopy(checkpoint.versions_seen)\n\t};\n}\nvar BaseCheckpointSaver = class {\n\tserde = new JsonPlusSerializer();\n\tconstructor(serde) {\n\t\tthis.serde = serde || this.serde;\n\t}\n\tasync get(config) {\n\t\tconst value = await this.getTuple(config);\n\t\treturn value ? value.checkpoint : void 0;\n\t}\n\t/**\n\t* Generate the next version ID for a channel.\n\t*\n\t* Default is to use integer versions, incrementing by 1. If you override, you can use str/int/float versions,\n\t* as long as they are monotonically increasing.\n\t*/\n\tgetNextVersion(current) {\n\t\tif (typeof current === \"string\") throw new Error(\"Please override this method to use string versions.\");\n\t\treturn current !== void 0 && typeof current === \"number\" ? current + 1 : 1;\n\t}\n};\nfunction compareChannelVersions(a, b) {\n\tif (typeof a === \"number\" && typeof b === \"number\") return Math.sign(a - b);\n\treturn String(a).localeCompare(String(b));\n}\nfunction maxChannelVersion(...versions) {\n\treturn versions.reduce((max, version, idx) => {\n\t\tif (idx === 0) return version;\n\t\treturn compareChannelVersions(max, version) >= 0 ? max : version;\n\t});\n}\n/**\n* Mapping from error type to error index.\n* Regular writes just map to their index in the list of writes being saved.\n* Special writes (e.g. errors) map to negative indices, to avoid those writes from\n* conflicting with regular writes.\n* Each Checkpointer implementation should use this mapping in put_writes.\n*/\nconst WRITES_IDX_MAP = {\n\t[ERROR]: -1,\n\t[SCHEDULED]: -2,\n\t[INTERRUPT]: -3,\n\t[RESUME]: -4\n};\nfunction getCheckpointId(config) {\n\treturn config.configurable?.checkpoint_id || config.configurable?.thread_ts || \"\";\n}\n\n//#endregion\nexport { BaseCheckpointSaver, WRITES_IDX_MAP, compareChannelVersions, copyCheckpoint, deepCopy, emptyCheckpoint, getCheckpointId, maxChannelVersion };\n//# sourceMappingURL=base.js.map","import { TASKS } from \"./serde/types.js\";\nimport { BaseCheckpointSaver, WRITES_IDX_MAP, copyCheckpoint, getCheckpointId, maxChannelVersion } from \"./base.js\";\n\n//#region src/memory.ts\nfunction _generateKey(threadId, checkpointNamespace, checkpointId) {\n\treturn JSON.stringify([\n\t\tthreadId,\n\t\tcheckpointNamespace,\n\t\tcheckpointId\n\t]);\n}\nfunction _parseKey(key) {\n\tconst [threadId, checkpointNamespace, checkpointId] = JSON.parse(key);\n\treturn {\n\t\tthreadId,\n\t\tcheckpointNamespace,\n\t\tcheckpointId\n\t};\n}\nvar MemorySaver = class extends BaseCheckpointSaver {\n\tstorage = {};\n\twrites = {};\n\tconstructor(serde) {\n\t\tsuper(serde);\n\t}\n\t/** @internal */\n\tasync _migratePendingSends(mutableCheckpoint, threadId, checkpointNs, parentCheckpointId) {\n\t\tconst deseriablizableCheckpoint = mutableCheckpoint;\n\t\tconst parentKey = _generateKey(threadId, checkpointNs, parentCheckpointId);\n\t\tconst pendingSends = await Promise.all(Object.values(this.writes[parentKey] ?? {}).filter(([_taskId, channel]) => channel === TASKS).map(async ([_taskId, _channel, writes]) => await this.serde.loadsTyped(\"json\", writes)));\n\t\tdeseriablizableCheckpoint.channel_values ??= {};\n\t\tdeseriablizableCheckpoint.channel_values[TASKS] = pendingSends;\n\t\tdeseriablizableCheckpoint.channel_versions ??= {};\n\t\tdeseriablizableCheckpoint.channel_versions[TASKS] = Object.keys(deseriablizableCheckpoint.channel_versions).length > 0 ? maxChannelVersion(...Object.values(deseriablizableCheckpoint.channel_versions)) : this.getNextVersion(void 0);\n\t}\n\tasync getTuple(config) {\n\t\tconst thread_id = config.configurable?.thread_id;\n\t\tconst checkpoint_ns = config.configurable?.checkpoint_ns ?? \"\";\n\t\tlet checkpoint_id = getCheckpointId(config);\n\t\tif (checkpoint_id) {\n\t\t\tconst saved = this.storage[thread_id]?.[checkpoint_ns]?.[checkpoint_id];\n\t\t\tif (saved !== void 0) {\n\t\t\t\tconst [checkpoint, metadata, parentCheckpointId] = saved;\n\t\t\t\tconst key = _generateKey(thread_id, checkpoint_ns, checkpoint_id);\n\t\t\t\tconst deserializedCheckpoint = await this.serde.loadsTyped(\"json\", checkpoint);\n\t\t\t\tif (deserializedCheckpoint.v < 4 && parentCheckpointId !== void 0) await this._migratePendingSends(deserializedCheckpoint, thread_id, checkpoint_ns, parentCheckpointId);\n\t\t\t\tconst pendingWrites = await Promise.all(Object.values(this.writes[key] || {}).map(async ([taskId, channel, value]) => {\n\t\t\t\t\treturn [\n\t\t\t\t\t\ttaskId,\n\t\t\t\t\t\tchannel,\n\t\t\t\t\t\tawait this.serde.loadsTyped(\"json\", value)\n\t\t\t\t\t];\n\t\t\t\t}));\n\t\t\t\tconst checkpointTuple = {\n\t\t\t\t\tconfig,\n\t\t\t\t\tcheckpoint: deserializedCheckpoint,\n\t\t\t\t\tmetadata: await this.serde.loadsTyped(\"json\", metadata),\n\t\t\t\t\tpendingWrites\n\t\t\t\t};\n\t\t\t\tif (parentCheckpointId !== void 0) checkpointTuple.parentConfig = { configurable: {\n\t\t\t\t\tthread_id,\n\t\t\t\t\tcheckpoint_ns,\n\t\t\t\t\tcheckpoint_id: parentCheckpointId\n\t\t\t\t} };\n\t\t\t\treturn checkpointTuple;\n\t\t\t}\n\t\t} else {\n\t\t\tconst checkpoints = this.storage[thread_id]?.[checkpoint_ns];\n\t\t\tif (checkpoints !== void 0) {\n\t\t\t\tcheckpoint_id = Object.keys(checkpoints).sort((a, b) => b.localeCompare(a))[0];\n\t\t\t\tconst saved = checkpoints[checkpoint_id];\n\t\t\t\tconst [checkpoint, metadata, parentCheckpointId] = saved;\n\t\t\t\tconst key = _generateKey(thread_id, checkpoint_ns, checkpoint_id);\n\t\t\t\tconst deserializedCheckpoint = await this.serde.loadsTyped(\"json\", checkpoint);\n\t\t\t\tif (deserializedCheckpoint.v < 4 && parentCheckpointId !== void 0) await this._migratePendingSends(deserializedCheckpoint, thread_id, checkpoint_ns, parentCheckpointId);\n\t\t\t\tconst pendingWrites = await Promise.all(Object.values(this.writes[key] || {}).map(async ([taskId, channel, value]) => {\n\t\t\t\t\treturn [\n\t\t\t\t\t\ttaskId,\n\t\t\t\t\t\tchannel,\n\t\t\t\t\t\tawait this.serde.loadsTyped(\"json\", value)\n\t\t\t\t\t];\n\t\t\t\t}));\n\t\t\t\tconst checkpointTuple = {\n\t\t\t\t\tconfig: { configurable: {\n\t\t\t\t\t\tthread_id,\n\t\t\t\t\t\tcheckpoint_id,\n\t\t\t\t\t\tcheckpoint_ns\n\t\t\t\t\t} },\n\t\t\t\t\tcheckpoint: deserializedCheckpoint,\n\t\t\t\t\tmetadata: await this.serde.loadsTyped(\"json\", metadata),\n\t\t\t\t\tpendingWrites\n\t\t\t\t};\n\t\t\t\tif (parentCheckpointId !== void 0) checkpointTuple.parentConfig = { configurable: {\n\t\t\t\t\tthread_id,\n\t\t\t\t\tcheckpoint_ns,\n\t\t\t\t\tcheckpoint_id: parentCheckpointId\n\t\t\t\t} };\n\t\t\t\treturn checkpointTuple;\n\t\t\t}\n\t\t}\n\t\treturn void 0;\n\t}\n\tasync *list(config, options) {\n\t\tlet { before, limit, filter } = options ?? {};\n\t\tconst threadIds = config.configurable?.thread_id ? [config.configurable?.thread_id] : Object.keys(this.storage);\n\t\tconst configCheckpointNamespace = config.configurable?.checkpoint_ns;\n\t\tconst configCheckpointId = config.configurable?.checkpoint_id;\n\t\tfor (const threadId of threadIds) for (const checkpointNamespace of Object.keys(this.storage[threadId] ?? {})) {\n\t\t\tif (configCheckpointNamespace !== void 0 && checkpointNamespace !== configCheckpointNamespace) continue;\n\t\t\tconst checkpoints = this.storage[threadId]?.[checkpointNamespace] ?? {};\n\t\t\tconst sortedCheckpoints = Object.entries(checkpoints).sort((a, b) => b[0].localeCompare(a[0]));\n\t\t\tfor (const [checkpointId, [checkpoint, metadataStr, parentCheckpointId]] of sortedCheckpoints) {\n\t\t\t\tif (configCheckpointId && checkpointId !== configCheckpointId) continue;\n\t\t\t\tif (before && before.configurable?.checkpoint_id && checkpointId >= before.configurable.checkpoint_id) continue;\n\t\t\t\tconst metadata = await this.serde.loadsTyped(\"json\", metadataStr);\n\t\t\t\tif (filter && !Object.entries(filter).every(([key$1, value]) => metadata[key$1] === value)) continue;\n\t\t\t\tif (limit !== void 0) {\n\t\t\t\t\tif (limit <= 0) break;\n\t\t\t\t\tlimit -= 1;\n\t\t\t\t}\n\t\t\t\tconst key = _generateKey(threadId, checkpointNamespace, checkpointId);\n\t\t\t\tconst writes = Object.values(this.writes[key] || {});\n\t\t\t\tconst pendingWrites = await Promise.all(writes.map(async ([taskId, channel, value]) => {\n\t\t\t\t\treturn [\n\t\t\t\t\t\ttaskId,\n\t\t\t\t\t\tchannel,\n\t\t\t\t\t\tawait this.serde.loadsTyped(\"json\", value)\n\t\t\t\t\t];\n\t\t\t\t}));\n\t\t\t\tconst deserializedCheckpoint = await this.serde.loadsTyped(\"json\", checkpoint);\n\t\t\t\tif (deserializedCheckpoint.v < 4 && parentCheckpointId !== void 0) await this._migratePendingSends(deserializedCheckpoint, threadId, checkpointNamespace, parentCheckpointId);\n\t\t\t\tconst checkpointTuple = {\n\t\t\t\t\tconfig: { configurable: {\n\t\t\t\t\t\tthread_id: threadId,\n\t\t\t\t\t\tcheckpoint_ns: checkpointNamespace,\n\t\t\t\t\t\tcheckpoint_id: checkpointId\n\t\t\t\t\t} },\n\t\t\t\t\tcheckpoint: deserializedCheckpoint,\n\t\t\t\t\tmetadata,\n\t\t\t\t\tpendingWrites\n\t\t\t\t};\n\t\t\t\tif (parentCheckpointId !== void 0) checkpointTuple.parentConfig = { configurable: {\n\t\t\t\t\tthread_id: threadId,\n\t\t\t\t\tcheckpoint_ns: checkpointNamespace,\n\t\t\t\t\tcheckpoint_id: parentCheckpointId\n\t\t\t\t} };\n\t\t\t\tyield checkpointTuple;\n\t\t\t}\n\t\t}\n\t}\n\tasync put(config, checkpoint, metadata) {\n\t\tconst preparedCheckpoint = copyCheckpoint(checkpoint);\n\t\tconst threadId = config.configurable?.thread_id;\n\t\tconst checkpointNamespace = config.configurable?.checkpoint_ns ?? \"\";\n\t\tif (threadId === void 0) throw new Error(`Failed to put checkpoint. The passed RunnableConfig is missing a required \"thread_id\" field in its \"configurable\" property.`);\n\t\tif (!this.storage[threadId]) this.storage[threadId] = {};\n\t\tif (!this.storage[threadId][checkpointNamespace]) this.storage[threadId][checkpointNamespace] = {};\n\t\tconst [[, serializedCheckpoint], [, serializedMetadata]] = await Promise.all([this.serde.dumpsTyped(preparedCheckpoint), this.serde.dumpsTyped(metadata)]);\n\t\tthis.storage[threadId][checkpointNamespace][checkpoint.id] = [\n\t\t\tserializedCheckpoint,\n\t\t\tserializedMetadata,\n\t\t\tconfig.configurable?.checkpoint_id\n\t\t];\n\t\treturn { configurable: {\n\t\t\tthread_id: threadId,\n\t\t\tcheckpoint_ns: checkpointNamespace,\n\t\t\tcheckpoint_id: checkpoint.id\n\t\t} };\n\t}\n\tasync putWrites(config, writes, taskId) {\n\t\tconst threadId = config.configurable?.thread_id;\n\t\tconst checkpointNamespace = config.configurable?.checkpoint_ns;\n\t\tconst checkpointId = config.configurable?.checkpoint_id;\n\t\tif (threadId === void 0) throw new Error(`Failed to put writes. The passed RunnableConfig is missing a required \"thread_id\" field in its \"configurable\" property`);\n\t\tif (checkpointId === void 0) throw new Error(`Failed to put writes. The passed RunnableConfig is missing a required \"checkpoint_id\" field in its \"configurable\" property.`);\n\t\tconst outerKey = _generateKey(threadId, checkpointNamespace, checkpointId);\n\t\tconst outerWrites_ = this.writes[outerKey];\n\t\tif (this.writes[outerKey] === void 0) this.writes[outerKey] = {};\n\t\tawait Promise.all(writes.map(async ([channel, value], idx) => {\n\t\t\tconst [, serializedValue] = await this.serde.dumpsTyped(value);\n\t\t\tconst innerKey = [taskId, WRITES_IDX_MAP[channel] || idx];\n\t\t\tconst innerKeyStr = `${innerKey[0]},${innerKey[1]}`;\n\t\t\tif (innerKey[1] >= 0 && outerWrites_ && innerKeyStr in outerWrites_) return;\n\t\t\tthis.writes[outerKey][innerKeyStr] = [\n\t\t\t\ttaskId,\n\t\t\t\tchannel,\n\t\t\t\tserializedValue\n\t\t\t];\n\t\t}));\n\t}\n\tasync deleteThread(threadId) {\n\t\tdelete this.storage[threadId];\n\t\tfor (const key of Object.keys(this.writes)) if (_parseKey(key).threadId === threadId) delete this.writes[key];\n\t}\n};\n\n//#endregion\nexport { MemorySaver };\n//# sourceMappingURL=memory.js.map","//#region src/store/base.ts\n/**\n* Error thrown when an invalid namespace is provided.\n*/\nvar InvalidNamespaceError = class extends Error {\n\tconstructor(message) {\n\t\tsuper(message);\n\t\tthis.name = \"InvalidNamespaceError\";\n\t}\n};\n/**\n* Validates the provided namespace.\n* @param namespace The namespace to validate.\n* @throws {InvalidNamespaceError} If the namespace is invalid.\n*/\nfunction validateNamespace(namespace) {\n\tif (namespace.length === 0) throw new InvalidNamespaceError(\"Namespace cannot be empty.\");\n\tfor (const label of namespace) {\n\t\tif (typeof label !== \"string\") throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels must be strings, but got ${typeof label}.`);\n\t\tif (label.includes(\".\")) throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels cannot contain periods ('.').`);\n\t\tif (label === \"\") throw new InvalidNamespaceError(`Namespace labels cannot be empty strings. Got ${label} in ${namespace}`);\n\t}\n\tif (namespace[0] === \"langgraph\") throw new InvalidNamespaceError(`Root label for namespace cannot be \"langgraph\". Got: ${namespace}`);\n}\n/**\n* Utility function to get text at a specific JSON path\n*/\nfunction getTextAtPath(obj, path) {\n\tconst parts = path.split(\".\");\n\tlet current = obj;\n\tfor (const part of parts) {\n\t\tif (part.includes(\"[\")) {\n\t\t\tconst [arrayName, indexStr] = part.split(\"[\");\n\t\t\tconst index = indexStr.replace(\"]\", \"\");\n\t\t\tif (!current[arrayName]) return [];\n\t\t\tif (index === \"*\") {\n\t\t\t\tconst results = [];\n\t\t\t\tfor (const item of current[arrayName]) if (typeof item === \"string\") results.push(item);\n\t\t\t\treturn results;\n\t\t\t}\n\t\t\tconst idx = parseInt(index, 10);\n\t\t\tif (Number.isNaN(idx)) return [];\n\t\t\tcurrent = current[arrayName][idx];\n\t\t} else current = current[part];\n\t\tif (current === void 0) return [];\n\t}\n\treturn typeof current === \"string\" ? [current] : [];\n}\n/**\n* Tokenizes a JSON path into parts\n*/\nfunction tokenizePath(path) {\n\treturn path.split(\".\");\n}\n/**\n* Abstract base class for persistent key-value stores.\n*\n* Stores enable persistence and memory that can be shared across threads,\n* scoped to user IDs, assistant IDs, or other arbitrary namespaces.\n*\n* Features:\n* - Hierarchical namespaces for organization\n* - Key-value storage with metadata\n* - Vector similarity search (if configured)\n* - Filtering and pagination\n*/\nvar BaseStore = class {\n\t/**\n\t* Retrieve a single item by its namespace and key.\n\t*\n\t* @param namespace Hierarchical path for the item\n\t* @param key Unique identifier within the namespace\n\t* @returns Promise resolving to the item or null if not found\n\t*/\n\tasync get(namespace, key) {\n\t\treturn (await this.batch([{\n\t\t\tnamespace,\n\t\t\tkey\n\t\t}]))[0];\n\t}\n\t/**\n\t* Search for items within a namespace prefix.\n\t* Supports both metadata filtering and vector similarity search.\n\t*\n\t* @param namespacePrefix Hierarchical path prefix to search within\n\t* @param options Search options for filtering and pagination\n\t* @returns Promise resolving to list of matching items with relevance scores\n\t*\n\t* @example\n\t* // Search with filters\n\t* await store.search([\"documents\"], {\n\t*   filter: { type: \"report\", status: \"active\" },\n\t*   limit: 5,\n\t*   offset: 10\n\t* });\n\t*\n\t* // Vector similarity search\n\t* await store.search([\"users\", \"content\"], {\n\t*   query: \"technical documentation about APIs\",\n\t*   limit: 20\n\t* });\n\t*/\n\tasync search(namespacePrefix, options = {}) {\n\t\tconst { filter, limit = 10, offset = 0, query } = options;\n\t\treturn (await this.batch([{\n\t\t\tnamespacePrefix,\n\t\t\tfilter,\n\t\t\tlimit,\n\t\t\toffset,\n\t\t\tquery\n\t\t}]))[0];\n\t}\n\t/**\n\t* Store or update an item.\n\t*\n\t* @param namespace Hierarchical path for the item\n\t* @param key Unique identifier within the namespace\n\t* @param value Object containing the item's data\n\t* @param index Optional indexing configuration\n\t*\n\t* @example\n\t* // Simple storage\n\t* await store.put([\"docs\"], \"report\", { title: \"Annual Report\" });\n\t*\n\t* // With specific field indexing\n\t* await store.put(\n\t*   [\"docs\"],\n\t*   \"report\",\n\t*   {\n\t*     title: \"Q4 Report\",\n\t*     chapters: [{ content: \"...\" }, { content: \"...\" }]\n\t*   },\n\t*   [\"title\", \"chapters[*].content\"]\n\t* );\n\t*/\n\tasync put(namespace, key, value, index) {\n\t\tvalidateNamespace(namespace);\n\t\tawait this.batch([{\n\t\t\tnamespace,\n\t\t\tkey,\n\t\t\tvalue,\n\t\t\tindex\n\t\t}]);\n\t}\n\t/**\n\t* Delete an item from the store.\n\t*\n\t* @param namespace Hierarchical path for the item\n\t* @param key Unique identifier within the namespace\n\t*/\n\tasync delete(namespace, key) {\n\t\tawait this.batch([{\n\t\t\tnamespace,\n\t\t\tkey,\n\t\t\tvalue: null\n\t\t}]);\n\t}\n\t/**\n\t* List and filter namespaces in the store.\n\t* Used to explore data organization and navigate the namespace hierarchy.\n\t*\n\t* @param options Options for listing namespaces\n\t* @returns Promise resolving to list of namespace paths\n\t*\n\t* @example\n\t* // List all namespaces under \"documents\"\n\t* await store.listNamespaces({\n\t*   prefix: [\"documents\"],\n\t*   maxDepth: 2\n\t* });\n\t*\n\t* // List namespaces ending with \"v1\"\n\t* await store.listNamespaces({\n\t*   suffix: [\"v1\"],\n\t*   limit: 50\n\t* });\n\t*/\n\tasync listNamespaces(options = {}) {\n\t\tconst { prefix, suffix, maxDepth, limit = 100, offset = 0 } = options;\n\t\tconst matchConditions = [];\n\t\tif (prefix) matchConditions.push({\n\t\t\tmatchType: \"prefix\",\n\t\t\tpath: prefix\n\t\t});\n\t\tif (suffix) matchConditions.push({\n\t\t\tmatchType: \"suffix\",\n\t\t\tpath: suffix\n\t\t});\n\t\treturn (await this.batch([{\n\t\t\tmatchConditions: matchConditions.length ? matchConditions : void 0,\n\t\t\tmaxDepth,\n\t\t\tlimit,\n\t\t\toffset\n\t\t}]))[0];\n\t}\n\t/**\n\t* Start the store. Override if initialization is needed.\n\t*/\n\tstart() {}\n\t/**\n\t* Stop the store. Override if cleanup is needed.\n\t*/\n\tstop() {}\n};\n\n//#endregion\nexport { BaseStore, InvalidNamespaceError, getTextAtPath, tokenizePath };\n//# sourceMappingURL=base.js.map","import { BaseStore } from \"./base.js\";\n\n//#region src/store/batch.ts\n/**\n* Extracts and returns the underlying store from an `AsyncBatchedStore`,\n* or returns the input if it is not an `AsyncBatchedStore`.\n*/\nconst extractStore = (input) => {\n\tif (\"lg_name\" in input && input.lg_name === \"AsyncBatchedStore\") return input.store;\n\treturn input;\n};\nvar AsyncBatchedStore = class extends BaseStore {\n\tlg_name = \"AsyncBatchedStore\";\n\tstore;\n\tqueue = /* @__PURE__ */ new Map();\n\tnextKey = 0;\n\trunning = false;\n\tprocessingTask = null;\n\tconstructor(store) {\n\t\tsuper();\n\t\tthis.store = extractStore(store);\n\t}\n\tget isRunning() {\n\t\treturn this.running;\n\t}\n\t/**\n\t* @ignore\n\t* Batch is not implemented here as we're only extending `BaseStore`\n\t* to allow it to be passed where `BaseStore` is expected, and implement\n\t* the convenience methods (get, search, put, delete).\n\t*/\n\tasync batch(_operations) {\n\t\tthrow new Error(\"The `batch` method is not implemented on `AsyncBatchedStore`.\\n Instead, it calls the `batch` method on the wrapped store.\\n If you are seeing this error, something is wrong.\");\n\t}\n\tasync get(namespace, key) {\n\t\treturn this.enqueueOperation({\n\t\t\tnamespace,\n\t\t\tkey\n\t\t});\n\t}\n\tasync search(namespacePrefix, options) {\n\t\tconst { filter, limit = 10, offset = 0, query } = options || {};\n\t\treturn this.enqueueOperation({\n\t\t\tnamespacePrefix,\n\t\t\tfilter,\n\t\t\tlimit,\n\t\t\toffset,\n\t\t\tquery\n\t\t});\n\t}\n\tasync put(namespace, key, value) {\n\t\treturn this.enqueueOperation({\n\t\t\tnamespace,\n\t\t\tkey,\n\t\t\tvalue\n\t\t});\n\t}\n\tasync delete(namespace, key) {\n\t\treturn this.enqueueOperation({\n\t\t\tnamespace,\n\t\t\tkey,\n\t\t\tvalue: null\n\t\t});\n\t}\n\tstart() {\n\t\tif (!this.running) {\n\t\t\tthis.running = true;\n\t\t\tthis.processingTask = this.processBatchQueue();\n\t\t}\n\t}\n\tasync stop() {\n\t\tthis.running = false;\n\t\tif (this.processingTask) await this.processingTask;\n\t}\n\tenqueueOperation(operation) {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tconst key = this.nextKey;\n\t\t\tthis.nextKey += 1;\n\t\t\tthis.queue.set(key, {\n\t\t\t\toperation,\n\t\t\t\tresolve,\n\t\t\t\treject\n\t\t\t});\n\t\t});\n\t}\n\tasync processBatchQueue() {\n\t\twhile (this.running) {\n\t\t\tawait new Promise((resolve) => {\n\t\t\t\tsetTimeout(resolve, 0);\n\t\t\t});\n\t\t\tif (this.queue.size === 0) continue;\n\t\t\tconst batch = new Map(this.queue);\n\t\t\tthis.queue.clear();\n\t\t\ttry {\n\t\t\t\tconst operations = Array.from(batch.values()).map(({ operation }) => operation);\n\t\t\t\tconst results = await this.store.batch(operations);\n\t\t\t\tbatch.forEach(({ resolve }, key) => {\n\t\t\t\t\tconst index = Array.from(batch.keys()).indexOf(key);\n\t\t\t\t\tresolve(results[index]);\n\t\t\t\t});\n\t\t\t} catch (e) {\n\t\t\t\tbatch.forEach(({ reject }) => {\n\t\t\t\t\treject(e);\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t}\n\ttoJSON() {\n\t\treturn {\n\t\t\tqueue: this.queue,\n\t\t\tnextKey: this.nextKey,\n\t\t\trunning: this.running,\n\t\t\tstore: \"[LangGraphStore]\"\n\t\t};\n\t}\n};\n\n//#endregion\nexport { AsyncBatchedStore };\n//# sourceMappingURL=batch.js.map","//#region src/store/utils.ts\n/**\n* Tokenize a JSON path into parts.\n* @example\n* tokenizePath(\"metadata.title\") // -> [\"metadata\", \"title\"]\n* tokenizePath(\"chapters[*].content\") // -> [\"chapters[*]\", \"content\"]\n*/\nfunction tokenizePath(path) {\n\tif (!path) return [];\n\tconst tokens = [];\n\tlet current = [];\n\tlet i = 0;\n\twhile (i < path.length) {\n\t\tconst char = path[i];\n\t\tif (char === \"[\") {\n\t\t\tif (current.length) {\n\t\t\t\ttokens.push(current.join(\"\"));\n\t\t\t\tcurrent = [];\n\t\t\t}\n\t\t\tlet bracketCount = 1;\n\t\t\tconst indexChars = [\"[\"];\n\t\t\ti += 1;\n\t\t\twhile (i < path.length && bracketCount > 0) {\n\t\t\t\tif (path[i] === \"[\") bracketCount += 1;\n\t\t\t\telse if (path[i] === \"]\") bracketCount -= 1;\n\t\t\t\tindexChars.push(path[i]);\n\t\t\t\ti += 1;\n\t\t\t}\n\t\t\ttokens.push(indexChars.join(\"\"));\n\t\t\tcontinue;\n\t\t} else if (char === \"{\") {\n\t\t\tif (current.length) {\n\t\t\t\ttokens.push(current.join(\"\"));\n\t\t\t\tcurrent = [];\n\t\t\t}\n\t\t\tlet braceCount = 1;\n\t\t\tconst fieldChars = [\"{\"];\n\t\t\ti += 1;\n\t\t\twhile (i < path.length && braceCount > 0) {\n\t\t\t\tif (path[i] === \"{\") braceCount += 1;\n\t\t\t\telse if (path[i] === \"}\") braceCount -= 1;\n\t\t\t\tfieldChars.push(path[i]);\n\t\t\t\ti += 1;\n\t\t\t}\n\t\t\ttokens.push(fieldChars.join(\"\"));\n\t\t\tcontinue;\n\t\t} else if (char === \".\") {\n\t\t\tif (current.length) {\n\t\t\t\ttokens.push(current.join(\"\"));\n\t\t\t\tcurrent = [];\n\t\t\t}\n\t\t} else current.push(char);\n\t\ti += 1;\n\t}\n\tif (current.length) tokens.push(current.join(\"\"));\n\treturn tokens;\n}\n/**\n* Type guard to check if an object is a FilterOperators\n*/\nfunction isFilterOperators(obj) {\n\treturn typeof obj === \"object\" && obj !== null && Object.keys(obj).every((key) => key === \"$eq\" || key === \"$ne\" || key === \"$gt\" || key === \"$gte\" || key === \"$lt\" || key === \"$lte\" || key === \"$in\" || key === \"$nin\");\n}\n/**\n* Compare values for filtering, supporting operator-based comparisons.\n*/\nfunction compareValues(itemValue, filterValue) {\n\tif (isFilterOperators(filterValue)) {\n\t\tconst operators = Object.keys(filterValue).filter((k) => k.startsWith(\"$\"));\n\t\treturn operators.every((op) => {\n\t\t\tconst value = filterValue[op];\n\t\t\tswitch (op) {\n\t\t\t\tcase \"$eq\": return itemValue === value;\n\t\t\t\tcase \"$ne\": return itemValue !== value;\n\t\t\t\tcase \"$gt\": return Number(itemValue) > Number(value);\n\t\t\t\tcase \"$gte\": return Number(itemValue) >= Number(value);\n\t\t\t\tcase \"$lt\": return Number(itemValue) < Number(value);\n\t\t\t\tcase \"$lte\": return Number(itemValue) <= Number(value);\n\t\t\t\tcase \"$in\": return Array.isArray(value) ? value.includes(itemValue) : false;\n\t\t\t\tcase \"$nin\": return Array.isArray(value) ? !value.includes(itemValue) : true;\n\t\t\t\tdefault: return false;\n\t\t\t}\n\t\t});\n\t}\n\treturn itemValue === filterValue;\n}\n/**\n* Extract text from a value at a specific JSON path.\n*\n* Supports:\n* - Simple paths: \"field1.field2\"\n* - Array indexing: \"[0]\", \"[*]\", \"[-1]\"\n* - Wildcards: \"*\"\n* - Multi-field selection: \"{field1,field2}\"\n* - Nested paths in multi-field: \"{field1,nested.field2}\"\n*/\nfunction getTextAtPath(obj, path) {\n\tif (!path || path === \"$\") return [JSON.stringify(obj, null, 2)];\n\tconst tokens = Array.isArray(path) ? path : tokenizePath(path);\n\tfunction extractFromObj(obj$1, tokens$1, pos) {\n\t\tif (pos >= tokens$1.length) {\n\t\t\tif (typeof obj$1 === \"string\" || typeof obj$1 === \"number\" || typeof obj$1 === \"boolean\") return [String(obj$1)];\n\t\t\tif (obj$1 === null || obj$1 === void 0) return [];\n\t\t\tif (Array.isArray(obj$1) || typeof obj$1 === \"object\") return [JSON.stringify(obj$1, null, 2)];\n\t\t\treturn [];\n\t\t}\n\t\tconst token = tokens$1[pos];\n\t\tconst results = [];\n\t\tif (pos === 0 && token === \"$\") results.push(JSON.stringify(obj$1, null, 2));\n\t\tif (token.startsWith(\"[\") && token.endsWith(\"]\")) {\n\t\t\tif (!Array.isArray(obj$1)) return [];\n\t\t\tconst index = token.slice(1, -1);\n\t\t\tif (index === \"*\") for (const item of obj$1) results.push(...extractFromObj(item, tokens$1, pos + 1));\n\t\t\telse try {\n\t\t\t\tlet idx = parseInt(index, 10);\n\t\t\t\tif (idx < 0) idx = obj$1.length + idx;\n\t\t\t\tif (idx >= 0 && idx < obj$1.length) results.push(...extractFromObj(obj$1[idx], tokens$1, pos + 1));\n\t\t\t} catch {\n\t\t\t\treturn [];\n\t\t\t}\n\t\t} else if (token.startsWith(\"{\") && token.endsWith(\"}\")) {\n\t\t\tif (typeof obj$1 !== \"object\" || obj$1 === null) return [];\n\t\t\tconst fields = token.slice(1, -1).split(\",\").map((f) => f.trim());\n\t\t\tfor (const field of fields) {\n\t\t\t\tconst nestedTokens = tokenizePath(field);\n\t\t\t\tif (nestedTokens.length) {\n\t\t\t\t\tlet currentObj = obj$1;\n\t\t\t\t\tfor (const nestedToken of nestedTokens) if (currentObj && typeof currentObj === \"object\" && nestedToken in currentObj) currentObj = currentObj[nestedToken];\n\t\t\t\t\telse {\n\t\t\t\t\t\tcurrentObj = void 0;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif (currentObj !== void 0) {\n\t\t\t\t\t\tif (typeof currentObj === \"string\" || typeof currentObj === \"number\" || typeof currentObj === \"boolean\") results.push(String(currentObj));\n\t\t\t\t\t\telse if (Array.isArray(currentObj) || typeof currentObj === \"object\") results.push(JSON.stringify(currentObj, null, 2));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (token === \"*\") {\n\t\t\tif (Array.isArray(obj$1)) for (const item of obj$1) results.push(...extractFromObj(item, tokens$1, pos + 1));\n\t\t\telse if (typeof obj$1 === \"object\" && obj$1 !== null) for (const value of Object.values(obj$1)) results.push(...extractFromObj(value, tokens$1, pos + 1));\n\t\t} else if (typeof obj$1 === \"object\" && obj$1 !== null && token in obj$1) results.push(...extractFromObj(obj$1[token], tokens$1, pos + 1));\n\t\treturn results;\n\t}\n\treturn extractFromObj(obj, tokens, 0);\n}\n\n//#endregion\nexport { compareValues, getTextAtPath, tokenizePath };\n//# sourceMappingURL=utils.js.map","import { BaseStore } from \"./base.js\";\nimport { compareValues, getTextAtPath, tokenizePath } from \"./utils.js\";\n\n//#region src/store/memory.ts\n/**\n* In-memory key-value store with optional vector search.\n*\n* A lightweight store implementation using JavaScript Maps. Supports basic\n* key-value operations and vector search when configured with embeddings.\n*\n* @example\n* ```typescript\n* // Basic key-value storage\n* const store = new InMemoryStore();\n* await store.put([\"users\", \"123\"], \"prefs\", { theme: \"dark\" });\n* const item = await store.get([\"users\", \"123\"], \"prefs\");\n*\n* // Vector search with embeddings\n* import { OpenAIEmbeddings } from \"@langchain/openai\";\n* const store = new InMemoryStore({\n*   index: {\n*     dims: 1536,\n*     embeddings: new OpenAIEmbeddings({ modelName: \"text-embedding-3-small\" }),\n*   }\n* });\n*\n* // Store documents\n* await store.put([\"docs\"], \"doc1\", { text: \"Python tutorial\" });\n* await store.put([\"docs\"], \"doc2\", { text: \"TypeScript guide\" });\n*\n* // Search by similarity\n* const results = await store.search([\"docs\"], { query: \"python programming\" });\n* ```\n*\n* **Warning**: This store keeps all data in memory. Data is lost when the process exits.\n* For persistence, use a database-backed store.\n*/\nvar InMemoryStore = class extends BaseStore {\n\tdata = /* @__PURE__ */ new Map();\n\tvectors = /* @__PURE__ */ new Map();\n\t_indexConfig;\n\tconstructor(options) {\n\t\tsuper();\n\t\tif (options?.index) this._indexConfig = {\n\t\t\t...options.index,\n\t\t\t__tokenizedFields: (options.index.fields ?? [\"$\"]).map((p) => [p, p === \"$\" ? [p] : tokenizePath(p)])\n\t\t};\n\t}\n\tasync batch(operations) {\n\t\tconst results = [];\n\t\tconst putOps = /* @__PURE__ */ new Map();\n\t\tconst searchOps = /* @__PURE__ */ new Map();\n\t\tfor (let i = 0; i < operations.length; i += 1) {\n\t\t\tconst op = operations[i];\n\t\t\tif (\"key\" in op && \"namespace\" in op && !(\"value\" in op)) results.push(this.getOperation(op));\n\t\t\telse if (\"namespacePrefix\" in op) {\n\t\t\t\tconst candidates = this.filterItems(op);\n\t\t\t\tsearchOps.set(i, [op, candidates]);\n\t\t\t\tresults.push(null);\n\t\t\t} else if (\"value\" in op) {\n\t\t\t\tconst key = `${op.namespace.join(\":\")}:${op.key}`;\n\t\t\t\tputOps.set(key, op);\n\t\t\t\tresults.push(null);\n\t\t\t} else if (\"matchConditions\" in op) results.push(this.listNamespacesOperation(op));\n\t\t}\n\t\tif (searchOps.size > 0) if (this._indexConfig?.embeddings) {\n\t\t\tconst queries = /* @__PURE__ */ new Set();\n\t\t\tfor (const [op] of searchOps.values()) if (op.query) queries.add(op.query);\n\t\t\tconst queryEmbeddings = queries.size > 0 ? await Promise.all(Array.from(queries).map((q) => this._indexConfig.embeddings.embedQuery(q))) : [];\n\t\t\tconst queryVectors = Object.fromEntries(Array.from(queries).map((q, i) => [q, queryEmbeddings[i]]));\n\t\t\tfor (const [i, [op, candidates]] of searchOps.entries()) if (op.query && queryVectors[op.query]) {\n\t\t\t\tconst queryVector = queryVectors[op.query];\n\t\t\t\tconst scoredResults = this.scoreResults(candidates, queryVector, op.offset ?? 0, op.limit ?? 10);\n\t\t\t\tresults[i] = scoredResults;\n\t\t\t} else results[i] = this.paginateResults(candidates.map((item) => ({\n\t\t\t\t...item,\n\t\t\t\tscore: void 0\n\t\t\t})), op.offset ?? 0, op.limit ?? 10);\n\t\t} else for (const [i, [op, candidates]] of searchOps.entries()) results[i] = this.paginateResults(candidates.map((item) => ({\n\t\t\t...item,\n\t\t\tscore: void 0\n\t\t})), op.offset ?? 0, op.limit ?? 10);\n\t\tif (putOps.size > 0 && this._indexConfig?.embeddings) {\n\t\t\tconst toEmbed = this.extractTexts(Array.from(putOps.values()));\n\t\t\tif (Object.keys(toEmbed).length > 0) {\n\t\t\t\tconst embeddings = await this._indexConfig.embeddings.embedDocuments(Object.keys(toEmbed));\n\t\t\t\tthis.insertVectors(toEmbed, embeddings);\n\t\t\t}\n\t\t}\n\t\tfor (const op of putOps.values()) this.putOperation(op);\n\t\treturn results;\n\t}\n\tgetOperation(op) {\n\t\tconst namespaceKey = op.namespace.join(\":\");\n\t\tconst item = this.data.get(namespaceKey)?.get(op.key);\n\t\treturn item ?? null;\n\t}\n\tputOperation(op) {\n\t\tconst namespaceKey = op.namespace.join(\":\");\n\t\tif (!this.data.has(namespaceKey)) this.data.set(namespaceKey, /* @__PURE__ */ new Map());\n\t\tconst namespaceMap = this.data.get(namespaceKey);\n\t\tif (op.value === null) namespaceMap.delete(op.key);\n\t\telse {\n\t\t\tconst now = /* @__PURE__ */ new Date();\n\t\t\tif (namespaceMap.has(op.key)) {\n\t\t\t\tconst item = namespaceMap.get(op.key);\n\t\t\t\titem.value = op.value;\n\t\t\t\titem.updatedAt = now;\n\t\t\t} else namespaceMap.set(op.key, {\n\t\t\t\tvalue: op.value,\n\t\t\t\tkey: op.key,\n\t\t\t\tnamespace: op.namespace,\n\t\t\t\tcreatedAt: now,\n\t\t\t\tupdatedAt: now\n\t\t\t});\n\t\t}\n\t}\n\tlistNamespacesOperation(op) {\n\t\tconst allNamespaces = Array.from(this.data.keys()).map((ns) => ns.split(\":\"));\n\t\tlet namespaces = allNamespaces;\n\t\tif (op.matchConditions && op.matchConditions.length > 0) namespaces = namespaces.filter((ns) => op.matchConditions.every((condition) => this.doesMatch(condition, ns)));\n\t\tif (op.maxDepth !== void 0) namespaces = Array.from(new Set(namespaces.map((ns) => ns.slice(0, op.maxDepth).join(\":\")))).map((ns) => ns.split(\":\"));\n\t\tnamespaces.sort((a, b) => a.join(\":\").localeCompare(b.join(\":\")));\n\t\treturn namespaces.slice(op.offset ?? 0, (op.offset ?? 0) + (op.limit ?? namespaces.length));\n\t}\n\tdoesMatch(matchCondition, key) {\n\t\tconst { matchType, path } = matchCondition;\n\t\tif (matchType === \"prefix\") {\n\t\t\tif (path.length > key.length) return false;\n\t\t\treturn path.every((pElem, index) => {\n\t\t\t\tconst kElem = key[index];\n\t\t\t\treturn pElem === \"*\" || kElem === pElem;\n\t\t\t});\n\t\t} else if (matchType === \"suffix\") {\n\t\t\tif (path.length > key.length) return false;\n\t\t\treturn path.every((pElem, index) => {\n\t\t\t\tconst kElem = key[key.length - path.length + index];\n\t\t\t\treturn pElem === \"*\" || kElem === pElem;\n\t\t\t});\n\t\t}\n\t\tthrow new Error(`Unsupported match type: ${matchType}`);\n\t}\n\tfilterItems(op) {\n\t\tconst candidates = [];\n\t\tfor (const [namespace, items] of this.data.entries()) if (namespace.startsWith(op.namespacePrefix.join(\":\"))) candidates.push(...items.values());\n\t\tlet filteredCandidates = candidates;\n\t\tif (op.filter) filteredCandidates = candidates.filter((item) => Object.entries(op.filter).every(([key, value]) => compareValues(item.value[key], value)));\n\t\treturn filteredCandidates;\n\t}\n\tscoreResults(candidates, queryVector, offset = 0, limit = 10) {\n\t\tconst flatItems = [];\n\t\tconst flatVectors = [];\n\t\tconst scoreless = [];\n\t\tfor (const item of candidates) {\n\t\t\tconst vectors = this.getVectors(item);\n\t\t\tif (vectors.length) for (const vector of vectors) {\n\t\t\t\tflatItems.push(item);\n\t\t\t\tflatVectors.push(vector);\n\t\t\t}\n\t\t\telse scoreless.push(item);\n\t\t}\n\t\tconst scores = this.cosineSimilarity(queryVector, flatVectors);\n\t\tconst sortedResults = scores.map((score, i) => [score, flatItems[i]]).sort((a, b) => b[0] - a[0]);\n\t\tconst seen = /* @__PURE__ */ new Set();\n\t\tconst kept = [];\n\t\tfor (const [score, item] of sortedResults) {\n\t\t\tconst key = `${item.namespace.join(\":\")}:${item.key}`;\n\t\t\tif (seen.has(key)) continue;\n\t\t\tconst ix = seen.size;\n\t\t\tif (ix >= offset + limit) break;\n\t\t\tif (ix < offset) {\n\t\t\t\tseen.add(key);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tseen.add(key);\n\t\t\tkept.push([score, item]);\n\t\t}\n\t\tif (scoreless.length && kept.length < limit) for (const item of scoreless.slice(0, limit - kept.length)) {\n\t\t\tconst key = `${item.namespace.join(\":\")}:${item.key}`;\n\t\t\tif (!seen.has(key)) {\n\t\t\t\tseen.add(key);\n\t\t\t\tkept.push([void 0, item]);\n\t\t\t}\n\t\t}\n\t\treturn kept.map(([score, item]) => ({\n\t\t\t...item,\n\t\t\tscore\n\t\t}));\n\t}\n\tpaginateResults(results, offset, limit) {\n\t\treturn results.slice(offset, offset + limit);\n\t}\n\textractTexts(ops) {\n\t\tif (!ops.length || !this._indexConfig) return {};\n\t\tconst toEmbed = {};\n\t\tfor (const op of ops) if (op.value !== null && op.index !== false) {\n\t\t\tconst paths = op.index === null || op.index === void 0 ? this._indexConfig.__tokenizedFields ?? [] : op.index.map((ix) => [ix, tokenizePath(ix)]);\n\t\t\tfor (const [path, field] of paths) {\n\t\t\t\tconst texts = getTextAtPath(op.value, field);\n\t\t\t\tif (texts.length) if (texts.length > 1) texts.forEach((text, i) => {\n\t\t\t\t\tif (!toEmbed[text]) toEmbed[text] = [];\n\t\t\t\t\ttoEmbed[text].push([\n\t\t\t\t\t\top.namespace,\n\t\t\t\t\t\top.key,\n\t\t\t\t\t\t`${path}.${i}`\n\t\t\t\t\t]);\n\t\t\t\t});\n\t\t\t\telse {\n\t\t\t\t\tif (!toEmbed[texts[0]]) toEmbed[texts[0]] = [];\n\t\t\t\t\ttoEmbed[texts[0]].push([\n\t\t\t\t\t\top.namespace,\n\t\t\t\t\t\top.key,\n\t\t\t\t\t\tpath\n\t\t\t\t\t]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn toEmbed;\n\t}\n\tinsertVectors(texts, embeddings) {\n\t\tfor (const [text, metadata] of Object.entries(texts)) {\n\t\t\tconst embedding = embeddings.shift();\n\t\t\tif (!embedding) throw new Error(`No embedding found for text: ${text}`);\n\t\t\tfor (const [namespace, key, field] of metadata) {\n\t\t\t\tconst namespaceKey = namespace.join(\":\");\n\t\t\t\tif (!this.vectors.has(namespaceKey)) this.vectors.set(namespaceKey, /* @__PURE__ */ new Map());\n\t\t\t\tconst namespaceMap = this.vectors.get(namespaceKey);\n\t\t\t\tif (!namespaceMap.has(key)) namespaceMap.set(key, /* @__PURE__ */ new Map());\n\t\t\t\tconst itemMap = namespaceMap.get(key);\n\t\t\t\titemMap.set(field, embedding);\n\t\t\t}\n\t\t}\n\t}\n\tgetVectors(item) {\n\t\tconst namespaceKey = item.namespace.join(\":\");\n\t\tconst itemKey = item.key;\n\t\tif (!this.vectors.has(namespaceKey)) return [];\n\t\tconst namespaceMap = this.vectors.get(namespaceKey);\n\t\tif (!namespaceMap.has(itemKey)) return [];\n\t\tconst itemMap = namespaceMap.get(itemKey);\n\t\tconst vectors = Array.from(itemMap.values());\n\t\tif (!vectors.length) return [];\n\t\treturn vectors;\n\t}\n\tcosineSimilarity(X, Y) {\n\t\tif (!Y.length) return [];\n\t\tconst dotProducts = Y.map((vector) => vector.reduce((acc, val, i) => acc + val * X[i], 0));\n\t\tconst magnitude1 = Math.sqrt(X.reduce((acc, val) => acc + val * val, 0));\n\t\tconst magnitudes2 = Y.map((vector) => Math.sqrt(vector.reduce((acc, val) => acc + val * val, 0)));\n\t\treturn dotProducts.map((dot, i) => {\n\t\t\tconst magnitude2 = magnitudes2[i];\n\t\t\treturn magnitude1 && magnitude2 ? dot / (magnitude1 * magnitude2) : 0;\n\t\t});\n\t}\n\tget indexConfig() {\n\t\treturn this._indexConfig;\n\t}\n};\n/** @deprecated Alias for InMemoryStore */\nvar MemoryStore = class extends InMemoryStore {};\n\n//#endregion\nexport { InMemoryStore, MemoryStore };\n//# sourceMappingURL=memory.js.map","import { JsonPlusSerializer } from \"../serde/jsonplus.js\";\n\n//#region src/cache/base.ts\nvar BaseCache = class {\n\tserde = new JsonPlusSerializer();\n\t/**\n\t* Initialize the cache with a serializer.\n\t*\n\t* @param serde - The serializer to use.\n\t*/\n\tconstructor(serde) {\n\t\tthis.serde = serde || this.serde;\n\t}\n};\n\n//#endregion\nexport { BaseCache };\n//# sourceMappingURL=base.js.map","import { BaseCache } from \"./base.js\";\n\n//#region src/cache/memory.ts\nvar InMemoryCache = class extends BaseCache {\n\tcache = {};\n\tasync get(keys) {\n\t\tif (!keys.length) return [];\n\t\tconst now = Date.now();\n\t\treturn (await Promise.all(keys.map(async (fullKey) => {\n\t\t\tconst [namespace, key] = fullKey;\n\t\t\tconst strNamespace = namespace.join(\",\");\n\t\t\tif (strNamespace in this.cache && key in this.cache[strNamespace]) {\n\t\t\t\tconst cached = this.cache[strNamespace][key];\n\t\t\t\tif (cached.exp == null || now < cached.exp) {\n\t\t\t\t\tconst value = await this.serde.loadsTyped(cached.enc, cached.val);\n\t\t\t\t\treturn [{\n\t\t\t\t\t\tkey: fullKey,\n\t\t\t\t\t\tvalue\n\t\t\t\t\t}];\n\t\t\t\t} else delete this.cache[strNamespace][key];\n\t\t\t}\n\t\t\treturn [];\n\t\t}))).flat();\n\t}\n\tasync set(pairs) {\n\t\tconst now = Date.now();\n\t\tfor (const { key: fullKey, value, ttl } of pairs) {\n\t\t\tconst [namespace, key] = fullKey;\n\t\t\tconst strNamespace = namespace.join(\",\");\n\t\t\tconst [enc, val] = await this.serde.dumpsTyped(value);\n\t\t\tconst exp = ttl != null ? ttl * 1e3 + now : null;\n\t\t\tthis.cache[strNamespace] ??= {};\n\t\t\tthis.cache[strNamespace][key] = {\n\t\t\t\tenc,\n\t\t\t\tval,\n\t\t\t\texp\n\t\t\t};\n\t\t}\n\t}\n\tasync clear(namespaces) {\n\t\tif (!namespaces.length) {\n\t\t\tthis.cache = {};\n\t\t\treturn;\n\t\t}\n\t\tfor (const namespace of namespaces) {\n\t\t\tconst strNamespace = namespace.join(\",\");\n\t\t\tif (strNamespace in this.cache) delete this.cache[strNamespace];\n\t\t}\n\t}\n};\n\n//#endregion\nexport { InMemoryCache };\n//# sourceMappingURL=memory.js.map","import { BaseCache } from \"./base.js\";\nimport { InMemoryCache } from \"./memory.js\";\n\nexport {  };","import { uuid5, uuid6 } from \"./id.js\";\nimport { ERROR, INTERRUPT, RESUME, SCHEDULED, TASKS } from \"./serde/types.js\";\nimport { BaseCheckpointSaver, WRITES_IDX_MAP, compareChannelVersions, copyCheckpoint, deepCopy, emptyCheckpoint, getCheckpointId, maxChannelVersion } from \"./base.js\";\nimport { MemorySaver } from \"./memory.js\";\nimport { BaseStore, InvalidNamespaceError, getTextAtPath, tokenizePath } from \"./store/base.js\";\nimport { AsyncBatchedStore } from \"./store/batch.js\";\nimport { InMemoryStore, MemoryStore } from \"./store/memory.js\";\nimport { BaseCache } from \"./cache/base.js\";\nimport { InMemoryCache } from \"./cache/memory.js\";\nimport \"./cache/index.js\";\n\nexport { AsyncBatchedStore, BaseCache, BaseCheckpointSaver, BaseStore, ERROR, INTERRUPT, InMemoryCache, InMemoryStore, InvalidNamespaceError, MemorySaver, MemoryStore, RESUME, SCHEDULED, TASKS, WRITES_IDX_MAP, compareChannelVersions, copyCheckpoint, deepCopy, emptyCheckpoint, getCheckpointId, getTextAtPath, maxChannelVersion, tokenizePath, uuid5, uuid6 };","import { EmptyChannelError } from \"../errors.js\";\nimport { uuid6 } from \"@langchain/langgraph-checkpoint\";\n\n//#region src/channels/base.ts\nfunction isBaseChannel(obj) {\n\treturn obj != null && obj.lg_is_channel === true;\n}\n/** @internal */\nvar BaseChannel = class {\n\tValueType;\n\tUpdateType;\n\t/** @ignore */\n\tlg_is_channel = true;\n\t/**\n\t* Mark the current value of the channel as consumed. By default, no-op.\n\t* A channel can use this method to modify its state, preventing the value\n\t* from being consumed again.\n\t*\n\t* Returns True if the channel was updated, False otherwise.\n\t*/\n\tconsume() {\n\t\treturn false;\n\t}\n\t/**\n\t* Notify the channel that the Pregel run is finishing. By default, no-op.\n\t* A channel can use this method to modify its state, preventing finish.\n\t*\n\t* Returns True if the channel was updated, False otherwise.\n\t*/\n\tfinish() {\n\t\treturn false;\n\t}\n\t/**\n\t* Return True if the channel is available (not empty), False otherwise.\n\t* Subclasses should override this method to provide a more efficient\n\t* implementation than calling get() and catching EmptyChannelError.\n\t*/\n\tisAvailable() {\n\t\ttry {\n\t\t\tthis.get();\n\t\t\treturn true;\n\t\t} catch (error) {\n\t\t\tif (error.name === EmptyChannelError.unminifiable_name) return false;\n\t\t\tthrow error;\n\t\t}\n\t}\n};\nconst IS_ONLY_BASE_CHANNEL = Symbol.for(\"LG_IS_ONLY_BASE_CHANNEL\");\nfunction getOnlyChannels(channels) {\n\tif (channels[IS_ONLY_BASE_CHANNEL] === true) return channels;\n\tconst newChannels = {};\n\tfor (const k in channels) {\n\t\tif (!Object.prototype.hasOwnProperty.call(channels, k)) continue;\n\t\tconst value = channels[k];\n\t\tif (isBaseChannel(value)) newChannels[k] = value;\n\t}\n\tObject.assign(newChannels, { [IS_ONLY_BASE_CHANNEL]: true });\n\treturn newChannels;\n}\nfunction emptyChannels(channels, checkpoint) {\n\tconst filteredChannels = getOnlyChannels(channels);\n\tconst newChannels = {};\n\tfor (const k in filteredChannels) {\n\t\tif (!Object.prototype.hasOwnProperty.call(filteredChannels, k)) continue;\n\t\tconst channelValue = checkpoint.channel_values[k];\n\t\tnewChannels[k] = filteredChannels[k].fromCheckpoint(channelValue);\n\t}\n\tObject.assign(newChannels, { [IS_ONLY_BASE_CHANNEL]: true });\n\treturn newChannels;\n}\nfunction createCheckpoint(checkpoint, channels, step, options) {\n\tlet values;\n\tif (channels === void 0) values = checkpoint.channel_values;\n\telse {\n\t\tvalues = {};\n\t\tfor (const k in channels) {\n\t\t\tif (!Object.prototype.hasOwnProperty.call(channels, k)) continue;\n\t\t\ttry {\n\t\t\t\tvalues[k] = channels[k].checkpoint();\n\t\t\t} catch (error) {\n\t\t\t\tif (error.name === EmptyChannelError.unminifiable_name) {} else throw error;\n\t\t\t}\n\t\t}\n\t}\n\treturn {\n\t\tv: 4,\n\t\tid: options?.id ?? uuid6(step),\n\t\tts: (/* @__PURE__ */ new Date()).toISOString(),\n\t\tchannel_values: values,\n\t\tchannel_versions: checkpoint.channel_versions,\n\t\tversions_seen: checkpoint.versions_seen\n\t};\n}\n\n//#endregion\nexport { BaseChannel, createCheckpoint, emptyChannels, getOnlyChannels, isBaseChannel };\n//# sourceMappingURL=base.js.map","import { EmptyChannelError } from \"../errors.js\";\nimport { BaseChannel } from \"./base.js\";\n\n//#region src/channels/binop.ts\n/**\n* Stores the result of applying a binary operator to the current value and each new value.\n*/\nvar BinaryOperatorAggregate = class BinaryOperatorAggregate extends BaseChannel {\n\tlc_graph_name = \"BinaryOperatorAggregate\";\n\tvalue;\n\toperator;\n\tinitialValueFactory;\n\tconstructor(operator, initialValueFactory) {\n\t\tsuper();\n\t\tthis.operator = operator;\n\t\tthis.initialValueFactory = initialValueFactory;\n\t\tthis.value = initialValueFactory?.();\n\t}\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new BinaryOperatorAggregate(this.operator, this.initialValueFactory);\n\t\tif (typeof checkpoint !== \"undefined\") empty.value = checkpoint;\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tlet newValues = values;\n\t\tif (!newValues.length) return false;\n\t\tif (this.value === void 0) {\n\t\t\t[this.value] = newValues;\n\t\t\tnewValues = newValues.slice(1);\n\t\t}\n\t\tfor (const value of newValues) if (this.value !== void 0) this.value = this.operator(this.value, value);\n\t\treturn true;\n\t}\n\tget() {\n\t\tif (this.value === void 0) throw new EmptyChannelError();\n\t\treturn this.value;\n\t}\n\tcheckpoint() {\n\t\tif (this.value === void 0) throw new EmptyChannelError();\n\t\treturn this.value;\n\t}\n\tisAvailable() {\n\t\treturn this.value !== void 0;\n\t}\n};\n\n//#endregion\nexport { BinaryOperatorAggregate };\n//# sourceMappingURL=binop.js.map","import { EmptyChannelError, InvalidUpdateError } from \"../errors.js\";\nimport { BaseChannel } from \"./base.js\";\n\n//#region src/channels/last_value.ts\n/**\n* Stores the last value received, can receive at most one value per step.\n*\n* Since `update` is only called once per step and value can only be of length 1,\n* LastValue always stores the last value of a single node. If multiple nodes attempt to\n* write to this channel in a single step, an error will be thrown.\n* @internal\n*/\nvar LastValue = class LastValue extends BaseChannel {\n\tlc_graph_name = \"LastValue\";\n\tvalue = [];\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new LastValue();\n\t\tif (typeof checkpoint !== \"undefined\") empty.value = [checkpoint];\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tif (values.length === 0) return false;\n\t\tif (values.length !== 1) throw new InvalidUpdateError(\"LastValue can only receive one value per step.\", { lc_error_code: \"INVALID_CONCURRENT_GRAPH_UPDATE\" });\n\t\tthis.value = [values[values.length - 1]];\n\t\treturn true;\n\t}\n\tget() {\n\t\tif (this.value.length === 0) throw new EmptyChannelError();\n\t\treturn this.value[0];\n\t}\n\tcheckpoint() {\n\t\tif (this.value.length === 0) throw new EmptyChannelError();\n\t\treturn this.value[0];\n\t}\n\tisAvailable() {\n\t\treturn this.value.length !== 0;\n\t}\n};\n/**\n* Stores the last value received, but only made available after finish().\n* Once made available, clears the value.\n*/\nvar LastValueAfterFinish = class LastValueAfterFinish extends BaseChannel {\n\tlc_graph_name = \"LastValueAfterFinish\";\n\tvalue = [];\n\tfinished = false;\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new LastValueAfterFinish();\n\t\tif (typeof checkpoint !== \"undefined\") {\n\t\t\tconst [value, finished] = checkpoint;\n\t\t\tempty.value = [value];\n\t\t\tempty.finished = finished;\n\t\t}\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tif (values.length === 0) return false;\n\t\tthis.finished = false;\n\t\tthis.value = [values[values.length - 1]];\n\t\treturn true;\n\t}\n\tget() {\n\t\tif (this.value.length === 0 || !this.finished) throw new EmptyChannelError();\n\t\treturn this.value[0];\n\t}\n\tcheckpoint() {\n\t\tif (this.value.length === 0) return void 0;\n\t\treturn [this.value[0], this.finished];\n\t}\n\tconsume() {\n\t\tif (this.finished) {\n\t\t\tthis.finished = false;\n\t\t\tthis.value = [];\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tfinish() {\n\t\tif (!this.finished && this.value.length > 0) {\n\t\t\tthis.finished = true;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tisAvailable() {\n\t\treturn this.value.length !== 0 && this.finished;\n\t}\n};\n\n//#endregion\nexport { LastValue, LastValueAfterFinish };\n//# sourceMappingURL=last_value.js.map","import { BinaryOperatorAggregate } from \"../channels/binop.js\";\nimport { LastValue } from \"../channels/last_value.js\";\n\n//#region src/graph/annotation.ts\n/**\n* Should not be instantiated directly. See {@link Annotation}.\n*/\nvar AnnotationRoot = class {\n\tlc_graph_name = \"AnnotationRoot\";\n\tspec;\n\tconstructor(s) {\n\t\tthis.spec = s;\n\t}\n};\n/**\n* Helper that instantiates channels within a StateGraph state.\n*\n* Can be used as a field in an {@link Annotation.Root} wrapper in one of two ways:\n* 1. **Directly**: Creates a channel that stores the most recent value returned from a node.\n* 2. **With a reducer**: Creates a channel that applies the reducer on a node's return value.\n*\n* @example\n* ```ts\n* import { StateGraph, Annotation } from \"@langchain/langgraph\";\n*\n* // Define a state with a single string key named \"currentOutput\"\n* const SimpleAnnotation = Annotation.Root({\n*   currentOutput: Annotation<string>,\n* });\n*\n* const graphBuilder = new StateGraph(SimpleAnnotation);\n*\n* // A node in the graph that returns an object with a \"currentOutput\" key\n* // replaces the value in the state. You can get the state type as shown below:\n* const myNode = (state: typeof SimpleAnnotation.State) => {\n*   return {\n*     currentOutput: \"some_new_value\",\n*   };\n* }\n*\n* const graph = graphBuilder\n*   .addNode(\"myNode\", myNode)\n*   ...\n*   .compile();\n* ```\n*\n* @example\n* ```ts\n* import { type BaseMessage, AIMessage } from \"@langchain/core/messages\";\n* import { StateGraph, Annotation } from \"@langchain/langgraph\";\n*\n* // Define a state with a single key named \"messages\" that will\n* // combine a returned BaseMessage or arrays of BaseMessages\n* const AnnotationWithReducer = Annotation.Root({\n*   messages: Annotation<BaseMessage[]>({\n*     // Different types are allowed for updates\n*     reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {\n*       if (Array.isArray(right)) {\n*         return left.concat(right);\n*       }\n*       return left.concat([right]);\n*     },\n*     default: () => [],\n*   }),\n* });\n*\n* const graphBuilder = new StateGraph(AnnotationWithReducer);\n*\n* // A node in the graph that returns an object with a \"messages\" key\n* // will update the state by combining the existing value with the returned one.\n* const myNode = (state: typeof AnnotationWithReducer.State) => {\n*   return {\n*     messages: [new AIMessage(\"Some new response\")],\n*   };\n* };\n*\n* const graph = graphBuilder\n*   .addNode(\"myNode\", myNode)\n*   ...\n*   .compile();\n* ```\n* @namespace\n* @property Root\n* Helper function that instantiates a StateGraph state. See {@link Annotation} for usage.\n*/\nconst Annotation = function(annotation) {\n\tif (annotation) return getChannel(annotation);\n\telse return new LastValue();\n};\nAnnotation.Root = (sd) => new AnnotationRoot(sd);\nfunction getChannel(reducer) {\n\tif (typeof reducer === \"object\" && reducer && \"reducer\" in reducer && reducer.reducer) return new BinaryOperatorAggregate(reducer.reducer, reducer.default);\n\tif (typeof reducer === \"object\" && reducer && \"value\" in reducer && reducer.value) return new BinaryOperatorAggregate(reducer.value, reducer.default);\n\treturn new LastValue();\n}\n\n//#endregion\nexport { Annotation, AnnotationRoot, getChannel };\n//# sourceMappingURL=annotation.js.map","//#region src/constants.ts\n/** Special reserved node name denoting the start of a graph. */\nconst START = \"__start__\";\n/** Special reserved node name denoting the end of a graph. */\nconst END = \"__end__\";\nconst INPUT = \"__input__\";\nconst COPY = \"__copy__\";\nconst ERROR = \"__error__\";\n/** Special reserved cache namespaces */\nconst CACHE_NS_WRITES = \"__pregel_ns_writes\";\nconst CONFIG_KEY_SEND = \"__pregel_send\";\n/** config key containing function used to call a node (push task) */\nconst CONFIG_KEY_CALL = \"__pregel_call\";\nconst CONFIG_KEY_READ = \"__pregel_read\";\nconst CONFIG_KEY_CHECKPOINTER = \"__pregel_checkpointer\";\nconst CONFIG_KEY_RESUMING = \"__pregel_resuming\";\nconst CONFIG_KEY_TASK_ID = \"__pregel_task_id\";\nconst CONFIG_KEY_STREAM = \"__pregel_stream\";\nconst CONFIG_KEY_RESUME_VALUE = \"__pregel_resume_value\";\nconst CONFIG_KEY_RESUME_MAP = \"__pregel_resume_map\";\nconst CONFIG_KEY_SCRATCHPAD = \"__pregel_scratchpad\";\n/** config key containing state from previous invocation of graph for the given thread */\nconst CONFIG_KEY_PREVIOUS_STATE = \"__pregel_previous\";\nconst CONFIG_KEY_DURABILITY = \"__pregel_durability\";\nconst CONFIG_KEY_CHECKPOINT_ID = \"checkpoint_id\";\nconst CONFIG_KEY_CHECKPOINT_NS = \"checkpoint_ns\";\nconst CONFIG_KEY_NODE_FINISHED = \"__pregel_node_finished\";\nconst CONFIG_KEY_CHECKPOINT_MAP = \"checkpoint_map\";\nconst CONFIG_KEY_ABORT_SIGNALS = \"__pregel_abort_signals\";\n/** Special channel reserved for graph interrupts */\nconst INTERRUPT = \"__interrupt__\";\n/** Special channel reserved for graph resume */\nconst RESUME = \"__resume__\";\n/** Special channel reserved for cases when a task exits without any writes */\nconst NO_WRITES = \"__no_writes__\";\n/** Special channel reserved for graph return */\nconst RETURN = \"__return__\";\n/** Special channel reserved for graph previous state */\nconst PREVIOUS = \"__previous__\";\nconst TAG_HIDDEN = \"langsmith:hidden\";\nconst TAG_NOSTREAM = \"langsmith:nostream\";\nconst SELF = \"__self__\";\nconst TASKS = \"__pregel_tasks\";\nconst PUSH = \"__pregel_push\";\nconst PULL = \"__pregel_pull\";\nconst NULL_TASK_ID = \"00000000-0000-0000-0000-000000000000\";\nconst RESERVED = [\n\tTAG_HIDDEN,\n\tINPUT,\n\tINTERRUPT,\n\tRESUME,\n\tERROR,\n\tNO_WRITES,\n\tCONFIG_KEY_SEND,\n\tCONFIG_KEY_READ,\n\tCONFIG_KEY_CHECKPOINTER,\n\tCONFIG_KEY_DURABILITY,\n\tCONFIG_KEY_STREAM,\n\tCONFIG_KEY_RESUMING,\n\tCONFIG_KEY_TASK_ID,\n\tCONFIG_KEY_CALL,\n\tCONFIG_KEY_RESUME_VALUE,\n\tCONFIG_KEY_SCRATCHPAD,\n\tCONFIG_KEY_PREVIOUS_STATE,\n\tCONFIG_KEY_CHECKPOINT_MAP,\n\tCONFIG_KEY_CHECKPOINT_NS,\n\tCONFIG_KEY_CHECKPOINT_ID\n];\nconst CHECKPOINT_NAMESPACE_SEPARATOR = \"|\";\nconst CHECKPOINT_NAMESPACE_END = \":\";\n/** @internal */\nconst COMMAND_SYMBOL = Symbol.for(\"langgraph.command\");\n/**\n* Instance of a {@link Command} class.\n*\n* This is used to avoid IntelliSense suggesting public fields\n* of {@link Command} class when a plain object is expected.\n*\n* @see {@link Command}\n* @internal\n*/\nvar CommandInstance = class {\n\t[COMMAND_SYMBOL];\n\tconstructor(args) {\n\t\tthis[COMMAND_SYMBOL] = args;\n\t}\n};\nfunction _isSendInterface(x) {\n\tconst operation = x;\n\treturn operation !== null && operation !== void 0 && typeof operation.node === \"string\" && operation.args !== void 0;\n}\n/**\n*\n* A message or packet to send to a specific node in the graph.\n*\n* The `Send` class is used within a `StateGraph`'s conditional edges to\n* dynamically invoke a node with a custom state at the next step.\n*\n* Importantly, the sent state can differ from the core graph's state,\n* allowing for flexible and dynamic workflow management.\n*\n* One such example is a \"map-reduce\" workflow where your graph invokes\n* the same node multiple times in parallel with different states,\n* before aggregating the results back into the main graph's state.\n*\n* @example\n* ```typescript\n* import { Annotation, Send, StateGraph } from \"@langchain/langgraph\";\n*\n* const ChainState = Annotation.Root({\n*   subjects: Annotation<string[]>,\n*   jokes: Annotation<string[]>({\n*     reducer: (a, b) => a.concat(b),\n*   }),\n* });\n*\n* const continueToJokes = async (state: typeof ChainState.State) => {\n*   return state.subjects.map((subject) => {\n*     return new Send(\"generate_joke\", { subjects: [subject] });\n*   });\n* };\n*\n* const graph = new StateGraph(ChainState)\n*   .addNode(\"generate_joke\", (state) => ({\n*     jokes: [`Joke about ${state.subjects}`],\n*   }))\n*   .addConditionalEdges(\"__start__\", continueToJokes)\n*   .addEdge(\"generate_joke\", \"__end__\")\n*   .compile();\n*\n* const res = await graph.invoke({ subjects: [\"cats\", \"dogs\"] });\n* console.log(res);\n*\n* // Invoking with two subjects results in a generated joke for each\n* // { subjects: [\"cats\", \"dogs\"], jokes: [`Joke about cats`, `Joke about dogs`] }\n* ```\n*/\nvar Send = class {\n\tlg_name = \"Send\";\n\tnode;\n\targs;\n\tconstructor(node, args) {\n\t\tthis.node = node;\n\t\tthis.args = _deserializeCommandSendObjectGraph(args);\n\t}\n\ttoJSON() {\n\t\treturn {\n\t\t\tlg_name: this.lg_name,\n\t\t\tnode: this.node,\n\t\t\targs: this.args\n\t\t};\n\t}\n};\nfunction _isSend(x) {\n\treturn x instanceof Send;\n}\n/**\n* Checks if the given graph invoke / stream chunk contains interrupt.\n*\n* @example\n* ```ts\n* import { INTERRUPT, isInterrupted } from \"@langchain/langgraph\";\n*\n* const values = await graph.invoke({ foo: \"bar\" });\n* if (isInterrupted<string>(values)) {\n*   const interrupt = values[INTERRUPT][0].value;\n* }\n* ```\n*\n* @param values - The values to check.\n* @returns `true` if the values contain an interrupt, `false` otherwise.\n*/\nfunction isInterrupted(values) {\n\tif (!values || typeof values !== \"object\") return false;\n\tif (!(INTERRUPT in values)) return false;\n\treturn Array.isArray(values[INTERRUPT]);\n}\n/**\n* One or more commands to update the graph's state and send messages to nodes.\n* Can be used to combine routing logic with state updates in lieu of conditional edges\n*\n* @example\n* ```ts\n* import { Annotation, Command } from \"@langchain/langgraph\";\n*\n* // Define graph state\n* const StateAnnotation = Annotation.Root({\n*   foo: Annotation<string>,\n* });\n*\n* // Define the nodes\n* const nodeA = async (_state: typeof StateAnnotation.State) => {\n*   console.log(\"Called A\");\n*   // this is a replacement for a real conditional edge function\n*   const goto = Math.random() > .5 ? \"nodeB\" : \"nodeC\";\n*   // note how Command allows you to BOTH update the graph state AND route to the next node\n*   return new Command({\n*     // this is the state update\n*     update: {\n*       foo: \"a\",\n*     },\n*     // this is a replacement for an edge\n*     goto,\n*   });\n* };\n*\n* // Nodes B and C are unchanged\n* const nodeB = async (state: typeof StateAnnotation.State) => {\n*   console.log(\"Called B\");\n*   return {\n*     foo: state.foo + \"|b\",\n*   };\n* }\n*\n* const nodeC = async (state: typeof StateAnnotation.State) => {\n*   console.log(\"Called C\");\n*   return {\n*     foo: state.foo + \"|c\",\n*   };\n* }\n* \n* import { StateGraph } from \"@langchain/langgraph\";\n\n* // NOTE: there are no edges between nodes A, B and C!\n* const graph = new StateGraph(StateAnnotation)\n*   .addNode(\"nodeA\", nodeA, {\n*     ends: [\"nodeB\", \"nodeC\"],\n*   })\n*   .addNode(\"nodeB\", nodeB)\n*   .addNode(\"nodeC\", nodeC)\n*   .addEdge(\"__start__\", \"nodeA\")\n*   .compile();\n* \n* await graph.invoke({ foo: \"\" });\n*\n* // Randomly oscillates between\n* // { foo: 'a|c' } and { foo: 'a|b' }\n* ```\n*/\nvar Command = class extends CommandInstance {\n\tlg_name = \"Command\";\n\tlc_direct_tool_output = true;\n\t/**\n\t* Graph to send the command to. Supported values are:\n\t*   - None: the current graph (default)\n\t*   - The specific name of the graph to send the command to\n\t*   - {@link Command.PARENT}: closest parent graph (only supported when returned from a node in a subgraph)\n\t*/\n\tgraph;\n\t/**\n\t* Update to apply to the graph's state as a result of executing the node that is returning the command.\n\t* Written to the state as if the node had simply returned this value instead of the Command object.\n\t*/\n\tupdate;\n\t/**\n\t* Value to resume execution with. To be used together with {@link interrupt}.\n\t*/\n\tresume;\n\t/**\n\t* Can be one of the following:\n\t*   - name of the node to navigate to next (any node that belongs to the specified `graph`)\n\t*   - sequence of node names to navigate to next\n\t*   - {@link Send} object (to execute a node with the exact input provided in the {@link Send} object)\n\t*   - sequence of {@link Send} objects\n\t*/\n\tgoto = [];\n\tstatic PARENT = \"__parent__\";\n\tconstructor(args) {\n\t\tsuper(args);\n\t\tthis.resume = args.resume;\n\t\tthis.graph = args.graph;\n\t\tthis.update = args.update;\n\t\tif (args.goto) this.goto = Array.isArray(args.goto) ? _deserializeCommandSendObjectGraph(args.goto) : [_deserializeCommandSendObjectGraph(args.goto)];\n\t}\n\t/**\n\t* Convert the update field to a list of {@link PendingWrite} tuples\n\t* @returns List of {@link PendingWrite} tuples of the form `[channelKey, value]`.\n\t* @internal\n\t*/\n\t_updateAsTuples() {\n\t\tif (this.update && typeof this.update === \"object\" && !Array.isArray(this.update)) return Object.entries(this.update);\n\t\telse if (Array.isArray(this.update) && this.update.every((t) => Array.isArray(t) && t.length === 2 && typeof t[0] === \"string\")) return this.update;\n\t\telse return [[\"__root__\", this.update]];\n\t}\n\ttoJSON() {\n\t\tlet serializedGoto;\n\t\tif (typeof this.goto === \"string\") serializedGoto = this.goto;\n\t\telse if (_isSend(this.goto)) serializedGoto = this.goto.toJSON();\n\t\telse serializedGoto = this.goto?.map((innerGoto) => {\n\t\t\tif (typeof innerGoto === \"string\") return innerGoto;\n\t\t\telse return innerGoto.toJSON();\n\t\t});\n\t\treturn {\n\t\t\tlg_name: this.lg_name,\n\t\t\tupdate: this.update,\n\t\t\tresume: this.resume,\n\t\t\tgoto: serializedGoto\n\t\t};\n\t}\n};\n/**\n* A type guard to check if the given value is a {@link Command}.\n*\n* Useful for type narrowing when working with the {@link Command} object.\n*\n* @param x - The value to check.\n* @returns `true` if the value is a {@link Command}, `false` otherwise.\n*/\nfunction isCommand(x) {\n\tif (typeof x !== \"object\") return false;\n\tif (x === null || x === void 0) return false;\n\tif (\"lg_name\" in x && x.lg_name === \"Command\") return true;\n\treturn false;\n}\n/**\n* Reconstructs Command and Send objects from a deeply nested tree of anonymous objects\n* matching their interfaces.\n*\n* This is only exported for testing purposes. It is NOT intended to be used outside of\n* the Command and Send classes.\n*\n* @internal\n*\n* @param x - The command send tree to convert.\n* @param seen - A map of seen objects to avoid infinite loops.\n* @returns The converted command send tree.\n*/\nfunction _deserializeCommandSendObjectGraph(x, seen = /* @__PURE__ */ new Map()) {\n\tif (x !== void 0 && x !== null && typeof x === \"object\") {\n\t\tif (seen.has(x)) return seen.get(x);\n\t\tlet result;\n\t\tif (Array.isArray(x)) {\n\t\t\tresult = [];\n\t\t\tseen.set(x, result);\n\t\t\tx.forEach((item, index) => {\n\t\t\t\tresult[index] = _deserializeCommandSendObjectGraph(item, seen);\n\t\t\t});\n\t\t} else if (isCommand(x) && !(x instanceof Command)) {\n\t\t\tresult = new Command(x);\n\t\t\tseen.set(x, result);\n\t\t} else if (_isSendInterface(x) && !(x instanceof Send)) {\n\t\t\tresult = new Send(x.node, x.args);\n\t\t\tseen.set(x, result);\n\t\t} else if (isCommand(x) || _isSend(x)) {\n\t\t\tresult = x;\n\t\t\tseen.set(x, result);\n\t\t} else if (\"lc_serializable\" in x && x.lc_serializable) {\n\t\t\tresult = x;\n\t\t\tseen.set(x, result);\n\t\t} else {\n\t\t\tresult = {};\n\t\t\tseen.set(x, result);\n\t\t\tfor (const [key, value] of Object.entries(x)) result[key] = _deserializeCommandSendObjectGraph(value, seen);\n\t\t}\n\t\treturn result;\n\t}\n\treturn x;\n}\n\n//#endregion\nexport { CACHE_NS_WRITES, CHECKPOINT_NAMESPACE_END, CHECKPOINT_NAMESPACE_SEPARATOR, CONFIG_KEY_ABORT_SIGNALS, CONFIG_KEY_CALL, CONFIG_KEY_CHECKPOINTER, CONFIG_KEY_CHECKPOINT_ID, CONFIG_KEY_CHECKPOINT_MAP, CONFIG_KEY_CHECKPOINT_NS, CONFIG_KEY_DURABILITY, CONFIG_KEY_NODE_FINISHED, CONFIG_KEY_PREVIOUS_STATE, CONFIG_KEY_READ, CONFIG_KEY_RESUME_MAP, CONFIG_KEY_RESUMING, CONFIG_KEY_SCRATCHPAD, CONFIG_KEY_SEND, CONFIG_KEY_STREAM, CONFIG_KEY_TASK_ID, COPY, Command, CommandInstance, END, ERROR, INPUT, INTERRUPT, NO_WRITES, NULL_TASK_ID, PREVIOUS, PULL, PUSH, RESERVED, RESUME, RETURN, SELF, START, Send, TAG_HIDDEN, TAG_NOSTREAM, TASKS, _isSend, _isSendInterface, isCommand, isInterrupted };\n//# sourceMappingURL=constants.js.map","import { CHECKPOINT_NAMESPACE_END, CHECKPOINT_NAMESPACE_SEPARATOR, CONFIG_KEY_SCRATCHPAD } from \"../../constants.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\n\n//#region src/pregel/utils/config.ts\nconst COPIABLE_KEYS = [\n\t\"tags\",\n\t\"metadata\",\n\t\"callbacks\",\n\t\"configurable\"\n];\nconst CONFIG_KEYS = [\n\t\"tags\",\n\t\"metadata\",\n\t\"callbacks\",\n\t\"runName\",\n\t\"maxConcurrency\",\n\t\"recursionLimit\",\n\t\"configurable\",\n\t\"runId\",\n\t\"outputKeys\",\n\t\"streamMode\",\n\t\"store\",\n\t\"writer\",\n\t\"interrupt\",\n\t\"context\",\n\t\"interruptBefore\",\n\t\"interruptAfter\",\n\t\"checkpointDuring\",\n\t\"durability\",\n\t\"signal\"\n];\nconst DEFAULT_RECURSION_LIMIT = 25;\nfunction ensureLangGraphConfig(...configs) {\n\tconst empty = {\n\t\ttags: [],\n\t\tmetadata: {},\n\t\tcallbacks: void 0,\n\t\trecursionLimit: DEFAULT_RECURSION_LIMIT,\n\t\tconfigurable: {}\n\t};\n\tconst implicitConfig = AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tif (implicitConfig !== void 0) {\n\t\tfor (const [k, v] of Object.entries(implicitConfig)) if (v !== void 0) if (COPIABLE_KEYS.includes(k)) {\n\t\t\tlet copiedValue;\n\t\t\tif (Array.isArray(v)) copiedValue = [...v];\n\t\t\telse if (typeof v === \"object\") if (k === \"callbacks\" && \"copy\" in v && typeof v.copy === \"function\") copiedValue = v.copy();\n\t\t\telse copiedValue = { ...v };\n\t\t\telse copiedValue = v;\n\t\t\tempty[k] = copiedValue;\n\t\t} else empty[k] = v;\n\t}\n\tfor (const config of configs) {\n\t\tif (config === void 0) continue;\n\t\tfor (const [k, v] of Object.entries(config)) if (v !== void 0 && CONFIG_KEYS.includes(k)) empty[k] = v;\n\t}\n\tfor (const [key, value] of Object.entries(empty.configurable)) {\n\t\tempty.metadata = empty.metadata ?? {};\n\t\tif (!key.startsWith(\"__\") && (typeof value === \"string\" || typeof value === \"number\" || typeof value === \"boolean\") && !(key in empty.metadata)) empty.metadata[key] = value;\n\t}\n\treturn empty;\n}\n/**\n* A helper utility function that returns the {@link BaseStore} that was set when the graph was initialized\n*\n* @returns a reference to the {@link BaseStore} that was set when the graph was initialized\n*/\nfunction getStore(config) {\n\tconst runConfig = config ?? AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tif (runConfig === void 0) throw new Error([\"Config not retrievable. This is likely because you are running in an environment without support for AsyncLocalStorage.\", \"If you're running `getStore` in such environment, pass the `config` from the node function directly.\"].join(\"\\n\"));\n\treturn runConfig?.store;\n}\n/**\n* A helper utility function that returns the {@link LangGraphRunnableConfig#writer} if \"custom\" stream mode is enabled, otherwise undefined.\n*\n* @returns a reference to the {@link LangGraphRunnableConfig#writer} if \"custom\" stream mode is enabled, otherwise undefined\n*/\nfunction getWriter(config) {\n\tconst runConfig = config ?? AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tif (runConfig === void 0) throw new Error([\"Config not retrievable. This is likely because you are running in an environment without support for AsyncLocalStorage.\", \"If you're running `getWriter` in such environment, pass the `config` from the node function directly.\"].join(\"\\n\"));\n\treturn runConfig?.writer || runConfig?.configurable?.writer;\n}\n/**\n* A helper utility function that returns the {@link LangGraphRunnableConfig} that was set when the graph was initialized.\n*\n* Note: This only works when running in an environment that supports node:async_hooks and AsyncLocalStorage. If you're running this in a\n* web environment, access the LangGraphRunnableConfig from the node function directly.\n*\n* @returns the {@link LangGraphRunnableConfig} that was set when the graph was initialized\n*/\nfunction getConfig() {\n\treturn AsyncLocalStorageProviderSingleton.getRunnableConfig();\n}\n/**\n* A helper utility function that returns the input for the currently executing task\n*\n* @returns the input for the currently executing task\n*/\nfunction getCurrentTaskInput(config) {\n\tconst runConfig = config ?? AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tif (runConfig === void 0) throw new Error([\"Config not retrievable. This is likely because you are running in an environment without support for AsyncLocalStorage.\", \"If you're running `getCurrentTaskInput` in such environment, pass the `config` from the node function directly.\"].join(\"\\n\"));\n\tif (runConfig.configurable?.[CONFIG_KEY_SCRATCHPAD]?.currentTaskInput === void 0) throw new Error(\"BUG: internal scratchpad not initialized.\");\n\treturn runConfig.configurable[CONFIG_KEY_SCRATCHPAD].currentTaskInput;\n}\nfunction recastCheckpointNamespace(namespace) {\n\treturn namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR).filter((part) => !part.match(/^\\d+$/)).map((part) => part.split(CHECKPOINT_NAMESPACE_END)[0]).join(CHECKPOINT_NAMESPACE_SEPARATOR);\n}\nfunction getParentCheckpointNamespace(namespace) {\n\tconst parts = namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR);\n\twhile (parts.length > 1 && parts[parts.length - 1].match(/^\\d+$/)) parts.pop();\n\treturn parts.slice(0, -1).join(CHECKPOINT_NAMESPACE_SEPARATOR);\n}\n\n//#endregion\nexport { ensureLangGraphConfig, getConfig, getCurrentTaskInput, getParentCheckpointNamespace, getStore, getWriter, recastCheckpointNamespace };\n//# sourceMappingURL=config.js.map","//#region src/hash.ts\nconst n = (n$1) => BigInt(n$1);\nconst view = (data, offset = 0) => new DataView(data.buffer, data.byteOffset + offset, data.byteLength - offset);\nconst PRIME32_1 = n(\"0x9E3779B1\");\nconst PRIME32_2 = n(\"0x85EBCA77\");\nconst PRIME32_3 = n(\"0xC2B2AE3D\");\nconst PRIME64_1 = n(\"0x9E3779B185EBCA87\");\nconst PRIME64_2 = n(\"0xC2B2AE3D27D4EB4F\");\nconst PRIME64_3 = n(\"0x165667B19E3779F9\");\nconst PRIME64_4 = n(\"0x85EBCA77C2B2AE63\");\nconst PRIME64_5 = n(\"0x27D4EB2F165667C5\");\nconst PRIME_MX1 = n(\"0x165667919E3779F9\");\nconst PRIME_MX2 = n(\"0x9FB21C651E98DF25\");\nconst hexToUint8Array = (hex) => {\n\tconst strLen = hex.length;\n\tif (strLen % 2 !== 0) throw new Error(\"String should have an even number of characters\");\n\tconst maxLength = strLen / 2;\n\tconst bytes = new Uint8Array(maxLength);\n\tlet read = 0;\n\tlet write = 0;\n\twhile (write < maxLength) {\n\t\tconst slice = hex.slice(read, read += 2);\n\t\tbytes[write] = Number.parseInt(slice, 16);\n\t\twrite += 1;\n\t}\n\treturn view(bytes);\n};\nconst kkey = hexToUint8Array(\"b8fe6c3923a44bbe7c01812cf721ad1cded46de9839097db7240a4a4b7b3671fcb79e64eccc0e578825ad07dccff7221b8084674f743248ee03590e6813a264c3c2852bb91c300cb88d0658b1b532ea371644897a20df94e3819ef46a9deacd8a8fa763fe39c343ff9dcbbc7c70b4f1d8a51e04bcdb45931c89f7ec9d9787364eac5ac8334d3ebc3c581a0fffa1363eb170ddd51b7f0da49d316552629d4689e2b16be587d47a1fc8ff8b8d17ad031ce45cb3a8f95160428afd7fbcabb4b407e\");\nconst mask128 = (n(1) << n(128)) - n(1);\nconst mask64 = (n(1) << n(64)) - n(1);\nconst mask32 = (n(1) << n(32)) - n(1);\nconst STRIPE_LEN = 64;\nconst ACC_NB = STRIPE_LEN / 8;\nconst _U64 = 8;\nconst _U32 = 4;\nfunction assert(a) {\n\tif (!a) throw new Error(\"Assert failed\");\n}\nfunction bswap64(a) {\n\tconst scratchbuf = /* @__PURE__ */ new DataView(/* @__PURE__ */ new ArrayBuffer(8));\n\tscratchbuf.setBigUint64(0, a, true);\n\treturn scratchbuf.getBigUint64(0, false);\n}\nfunction bswap32(input) {\n\tlet a = input;\n\ta = (a & n(65535)) << n(16) | (a & n(4294901760)) >> n(16);\n\ta = (a & n(16711935)) << n(8) | (a & n(4278255360)) >> n(8);\n\treturn a;\n}\nfunction XXH_mult32to64(a, b) {\n\treturn (a & mask32) * (b & mask32) & mask64;\n}\nfunction rotl32(a, b) {\n\treturn (a << b | a >> n(32) - b) & mask32;\n}\nfunction XXH3_accumulate_512(acc, dataView, keyView) {\n\tfor (let i = 0; i < ACC_NB; i += 1) {\n\t\tconst data_val = dataView.getBigUint64(i * 8, true);\n\t\tconst data_key = data_val ^ keyView.getBigUint64(i * 8, true);\n\t\tacc[i ^ 1] += data_val;\n\t\tacc[i] += XXH_mult32to64(data_key, data_key >> n(32));\n\t}\n\treturn acc;\n}\nfunction XXH3_accumulate(acc, dataView, keyView, nbStripes) {\n\tfor (let n$1 = 0; n$1 < nbStripes; n$1 += 1) XXH3_accumulate_512(acc, view(dataView, n$1 * STRIPE_LEN), view(keyView, n$1 * 8));\n\treturn acc;\n}\nfunction XXH3_scrambleAcc(acc, key) {\n\tfor (let i = 0; i < ACC_NB; i += 1) {\n\t\tconst key64 = key.getBigUint64(i * 8, true);\n\t\tlet acc64 = acc[i];\n\t\tacc64 = xorshift64(acc64, n(47));\n\t\tacc64 ^= key64;\n\t\tacc64 *= PRIME32_1;\n\t\tacc[i] = acc64 & mask64;\n\t}\n\treturn acc;\n}\nfunction XXH3_mix2Accs(acc, key) {\n\treturn XXH3_mul128_fold64(acc[0] ^ key.getBigUint64(0, true), acc[1] ^ key.getBigUint64(_U64, true));\n}\nfunction XXH3_mergeAccs(acc, key, start) {\n\tlet result64 = start;\n\tresult64 += XXH3_mix2Accs(acc.slice(0), view(key, 0 * _U32));\n\tresult64 += XXH3_mix2Accs(acc.slice(2), view(key, 4 * _U32));\n\tresult64 += XXH3_mix2Accs(acc.slice(4), view(key, 8 * _U32));\n\tresult64 += XXH3_mix2Accs(acc.slice(6), view(key, 12 * _U32));\n\treturn XXH3_avalanche(result64 & mask64);\n}\nfunction XXH3_hashLong(input, data, secret, f_acc, f_scramble) {\n\tlet acc = input;\n\tconst nbStripesPerBlock = Math.floor((secret.byteLength - STRIPE_LEN) / 8);\n\tconst block_len = STRIPE_LEN * nbStripesPerBlock;\n\tconst nb_blocks = Math.floor((data.byteLength - 1) / block_len);\n\tfor (let n$1 = 0; n$1 < nb_blocks; n$1 += 1) {\n\t\tacc = XXH3_accumulate(acc, view(data, n$1 * block_len), secret, nbStripesPerBlock);\n\t\tacc = f_scramble(acc, view(secret, secret.byteLength - STRIPE_LEN));\n\t}\n\t{\n\t\tconst nbStripes = Math.floor((data.byteLength - 1 - block_len * nb_blocks) / STRIPE_LEN);\n\t\tacc = XXH3_accumulate(acc, view(data, nb_blocks * block_len), secret, nbStripes);\n\t\tacc = f_acc(acc, view(data, data.byteLength - STRIPE_LEN), view(secret, secret.byteLength - STRIPE_LEN - 7));\n\t}\n\treturn acc;\n}\nfunction XXH3_hashLong_128b(data, secret) {\n\tlet acc = new BigUint64Array([\n\t\tPRIME32_3,\n\t\tPRIME64_1,\n\t\tPRIME64_2,\n\t\tPRIME64_3,\n\t\tPRIME64_4,\n\t\tPRIME32_2,\n\t\tPRIME64_5,\n\t\tPRIME32_1\n\t]);\n\tassert(data.byteLength > 128);\n\tacc = XXH3_hashLong(acc, data, secret, XXH3_accumulate_512, XXH3_scrambleAcc);\n\tassert(acc.length * 8 === 64);\n\t{\n\t\tconst low64 = XXH3_mergeAccs(acc, view(secret, 11), n(data.byteLength) * PRIME64_1 & mask64);\n\t\tconst high64 = XXH3_mergeAccs(acc, view(secret, secret.byteLength - STRIPE_LEN - 11), ~(n(data.byteLength) * PRIME64_2) & mask64);\n\t\treturn high64 << n(64) | low64;\n\t}\n}\nfunction XXH3_mul128_fold64(a, b) {\n\tconst lll = a * b & mask128;\n\treturn lll & mask64 ^ lll >> n(64);\n}\nfunction XXH3_mix16B(dataView, keyView, seed) {\n\treturn XXH3_mul128_fold64((dataView.getBigUint64(0, true) ^ keyView.getBigUint64(0, true) + seed) & mask64, (dataView.getBigUint64(8, true) ^ keyView.getBigUint64(8, true) - seed) & mask64);\n}\nfunction XXH3_mix32B(acc, data1, data2, key, seed) {\n\tlet accl = acc & mask64;\n\tlet acch = acc >> n(64) & mask64;\n\taccl += XXH3_mix16B(data1, key, seed);\n\taccl ^= data2.getBigUint64(0, true) + data2.getBigUint64(8, true);\n\taccl &= mask64;\n\tacch += XXH3_mix16B(data2, view(key, 16), seed);\n\tacch ^= data1.getBigUint64(0, true) + data1.getBigUint64(8, true);\n\tacch &= mask64;\n\treturn acch << n(64) | accl;\n}\nfunction XXH3_avalanche(input) {\n\tlet h64 = input;\n\th64 ^= h64 >> n(37);\n\th64 *= PRIME_MX1;\n\th64 &= mask64;\n\th64 ^= h64 >> n(32);\n\treturn h64;\n}\nfunction XXH3_avalanche64(input) {\n\tlet h64 = input;\n\th64 ^= h64 >> n(33);\n\th64 *= PRIME64_2;\n\th64 &= mask64;\n\th64 ^= h64 >> n(29);\n\th64 *= PRIME64_3;\n\th64 &= mask64;\n\th64 ^= h64 >> n(32);\n\treturn h64;\n}\nfunction XXH3_len_1to3_128b(data, key32, seed) {\n\tconst len = data.byteLength;\n\tassert(len > 0 && len <= 3);\n\tconst combined = n(data.getUint8(len - 1)) | n(len << 8) | n(data.getUint8(0) << 16) | n(data.getUint8(len >> 1) << 24);\n\tconst blow = (n(key32.getUint32(0, true)) ^ n(key32.getUint32(4, true))) + seed;\n\tconst low = (combined ^ blow) & mask64;\n\tconst bhigh = (n(key32.getUint32(8, true)) ^ n(key32.getUint32(12, true))) - seed;\n\tconst high = (rotl32(bswap32(combined), n(13)) ^ bhigh) & mask64;\n\treturn (XXH3_avalanche64(high) & mask64) << n(64) | XXH3_avalanche64(low);\n}\nfunction xorshift64(b, shift) {\n\treturn b ^ b >> shift;\n}\nfunction XXH3_len_4to8_128b(data, key32, seed) {\n\tconst len = data.byteLength;\n\tassert(len >= 4 && len <= 8);\n\t{\n\t\tconst l1 = data.getUint32(0, true);\n\t\tconst l2 = data.getUint32(len - 4, true);\n\t\tconst l64 = n(l1) | n(l2) << n(32);\n\t\tconst bitflip = (key32.getBigUint64(16, true) ^ key32.getBigUint64(24, true)) + seed & mask64;\n\t\tconst keyed = l64 ^ bitflip;\n\t\tlet m128 = keyed * (PRIME64_1 + (n(len) << n(2))) & mask128;\n\t\tm128 += (m128 & mask64) << n(65);\n\t\tm128 &= mask128;\n\t\tm128 ^= m128 >> n(67);\n\t\treturn xorshift64(xorshift64(m128 & mask64, n(35)) * PRIME_MX2 & mask64, n(28)) | XXH3_avalanche(m128 >> n(64)) << n(64);\n\t}\n}\nfunction XXH3_len_9to16_128b(data, key64, seed) {\n\tconst len = data.byteLength;\n\tassert(len >= 9 && len <= 16);\n\t{\n\t\tconst bitflipl = (key64.getBigUint64(32, true) ^ key64.getBigUint64(40, true)) + seed & mask64;\n\t\tconst bitfliph = (key64.getBigUint64(48, true) ^ key64.getBigUint64(56, true)) - seed & mask64;\n\t\tconst ll1 = data.getBigUint64(0, true);\n\t\tlet ll2 = data.getBigUint64(len - 8, true);\n\t\tlet m128 = (ll1 ^ ll2 ^ bitflipl) * PRIME64_1;\n\t\tconst m128_l = (m128 & mask64) + (n(len - 1) << n(54));\n\t\tm128 = m128 & (mask128 ^ mask64) | m128_l;\n\t\tll2 ^= bitfliph;\n\t\tm128 += ll2 + (ll2 & mask32) * (PRIME32_2 - n(1)) << n(64);\n\t\tm128 &= mask128;\n\t\tm128 ^= bswap64(m128 >> n(64));\n\t\tlet h128 = (m128 & mask64) * PRIME64_2;\n\t\th128 += (m128 >> n(64)) * PRIME64_2 << n(64);\n\t\th128 &= mask128;\n\t\treturn XXH3_avalanche(h128 & mask64) | XXH3_avalanche(h128 >> n(64)) << n(64);\n\t}\n}\nfunction XXH3_len_0to16_128b(data, seed) {\n\tconst len = data.byteLength;\n\tassert(len <= 16);\n\tif (len > 8) return XXH3_len_9to16_128b(data, kkey, seed);\n\tif (len >= 4) return XXH3_len_4to8_128b(data, kkey, seed);\n\tif (len > 0) return XXH3_len_1to3_128b(data, kkey, seed);\n\treturn XXH3_avalanche64(seed ^ kkey.getBigUint64(64, true) ^ kkey.getBigUint64(72, true)) | XXH3_avalanche64(seed ^ kkey.getBigUint64(80, true) ^ kkey.getBigUint64(88, true)) << n(64);\n}\nfunction inv64(x) {\n\treturn ~x + n(1) & mask64;\n}\nfunction XXH3_len_17to128_128b(data, secret, seed) {\n\tlet acc = n(data.byteLength) * PRIME64_1 & mask64;\n\tlet i = n(data.byteLength - 1) / n(32);\n\twhile (i >= 0) {\n\t\tconst ni = Number(i);\n\t\tacc = XXH3_mix32B(acc, view(data, 16 * ni), view(data, data.byteLength - 16 * (ni + 1)), view(secret, 32 * ni), seed);\n\t\ti -= n(1);\n\t}\n\tlet h128l = acc + (acc >> n(64)) & mask64;\n\th128l = XXH3_avalanche(h128l);\n\tlet h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;\n\th128h &= mask64;\n\th128h = inv64(XXH3_avalanche(h128h));\n\treturn h128l | h128h << n(64);\n}\nfunction XXH3_len_129to240_128b(data, secret, seed) {\n\tlet acc = n(data.byteLength) * PRIME64_1 & mask64;\n\tfor (let i = 32; i < 160; i += 32) acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, i - 32), seed);\n\tacc = XXH3_avalanche(acc & mask64) | XXH3_avalanche(acc >> n(64)) << n(64);\n\tfor (let i = 160; i <= data.byteLength; i += 32) acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, 3 + i - 160), seed);\n\tacc = XXH3_mix32B(acc, view(data, data.byteLength - 16), view(data, data.byteLength - 32), view(secret, 103), inv64(seed));\n\tlet h128l = acc + (acc >> n(64)) & mask64;\n\th128l = XXH3_avalanche(h128l);\n\tlet h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;\n\th128h &= mask64;\n\th128h = inv64(XXH3_avalanche(h128h));\n\treturn h128l | h128h << n(64);\n}\nfunction XXH3(input, seed = n(0)) {\n\tconst encoder = new TextEncoder();\n\tconst data = view(typeof input === \"string\" ? encoder.encode(input) : input);\n\tconst len = data.byteLength;\n\tconst hexDigest = (data$1) => data$1.toString(16).padStart(32, \"0\");\n\tif (len <= 16) return hexDigest(XXH3_len_0to16_128b(data, seed));\n\tif (len <= 128) return hexDigest(XXH3_len_17to128_128b(data, kkey, seed));\n\tif (len <= 240) return hexDigest(XXH3_len_129to240_128b(data, kkey, seed));\n\treturn hexDigest(XXH3_hashLong_128b(data, kkey));\n}\nfunction isXXH3(value) {\n\treturn /^[0-9a-f]{32}$/.test(value);\n}\n\n//#endregion\nexport { XXH3, isXXH3 };\n//# sourceMappingURL=hash.js.map","import { GraphInterrupt, GraphValueError } from \"./errors.js\";\nimport { CHECKPOINT_NAMESPACE_SEPARATOR, CONFIG_KEY_CHECKPOINTER, CONFIG_KEY_CHECKPOINT_NS, CONFIG_KEY_SCRATCHPAD, CONFIG_KEY_SEND, RESUME } from \"./constants.js\";\nimport { XXH3 } from \"./hash.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\n\n//#region src/interrupt.ts\n/**\n* Interrupts the execution of a graph node.\n* This function can be used to pause execution of a node, and return the value of the `resume`\n* input when the graph is re-invoked using `Command`.\n* Multiple interrupts can be called within a single node, and each will be handled sequentially.\n*\n* When an interrupt is called:\n* 1. If there's a `resume` value available (from a previous `Command`), it returns that value.\n* 2. Otherwise, it throws a `GraphInterrupt` with the provided value\n* 3. The graph can be resumed by passing a `Command` with a `resume` value\n*\n* Because the `interrupt` function propagates by throwing a special `GraphInterrupt` error,\n* you should avoid using `try/catch` blocks around the `interrupt` function,\n* or if you do, ensure that the `GraphInterrupt` error is thrown again within your `catch` block.\n*\n* @param value - The value to include in the interrupt. This will be available in task.interrupts[].value\n* @returns The `resume` value provided when the graph is re-invoked with a Command\n*\n* @example\n* ```typescript\n* // Define a node that uses multiple interrupts\n* const nodeWithInterrupts = () => {\n*   // First interrupt - will pause execution and include {value: 1} in task values\n*   const answer1 = interrupt({ value: 1 });\n*\n*   // Second interrupt - only called after first interrupt is resumed\n*   const answer2 = interrupt({ value: 2 });\n*\n*   // Use the resume values\n*   return { myKey: answer1 + \" \" + answer2 };\n* };\n*\n* // Resume the graph after first interrupt\n* await graph.stream(new Command({ resume: \"answer 1\" }));\n*\n* // Resume the graph after second interrupt\n* await graph.stream(new Command({ resume: \"answer 2\" }));\n* // Final result: { myKey: \"answer 1 answer 2\" }\n* ```\n*\n* @throws {Error} If called outside the context of a graph\n* @throws {GraphInterrupt} When no resume value is available\n*/\nfunction interrupt(value) {\n\tconst config = AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tif (!config) throw new Error(\"Called interrupt() outside the context of a graph.\");\n\tconst conf = config.configurable;\n\tif (!conf) throw new Error(\"No configurable found in config\");\n\tconst checkpointer = conf[CONFIG_KEY_CHECKPOINTER];\n\tif (!checkpointer) throw new GraphValueError(\"No checkpointer set\", { lc_error_code: \"MISSING_CHECKPOINTER\" });\n\tconst scratchpad = conf[CONFIG_KEY_SCRATCHPAD];\n\tscratchpad.interruptCounter += 1;\n\tconst idx = scratchpad.interruptCounter;\n\tif (scratchpad.resume.length > 0 && idx < scratchpad.resume.length) {\n\t\tconf[CONFIG_KEY_SEND]?.([[RESUME, scratchpad.resume]]);\n\t\treturn scratchpad.resume[idx];\n\t}\n\tif (scratchpad.nullResume !== void 0) {\n\t\tif (scratchpad.resume.length !== idx) throw new Error(`Resume length mismatch: ${scratchpad.resume.length} !== ${idx}`);\n\t\tconst v = scratchpad.consumeNullResume();\n\t\tscratchpad.resume.push(v);\n\t\tconf[CONFIG_KEY_SEND]?.([[RESUME, scratchpad.resume]]);\n\t\treturn v;\n\t}\n\tconst ns = conf[CONFIG_KEY_CHECKPOINT_NS]?.split(CHECKPOINT_NAMESPACE_SEPARATOR);\n\tconst id = ns ? XXH3(ns.join(CHECKPOINT_NAMESPACE_SEPARATOR)) : void 0;\n\tthrow new GraphInterrupt([{\n\t\tid,\n\t\tvalue\n\t}]);\n}\n\n//#endregion\nexport { interrupt };\n//# sourceMappingURL=interrupt.js.map","import { ensureLangGraphConfig } from \"./pregel/utils/config.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\nimport { Runnable, mergeConfigs, patchConfig } from \"@langchain/core/runnables\";\n\n//#region src/utils.ts\nvar RunnableCallable = class extends Runnable {\n\tlc_namespace = [\"langgraph\"];\n\tfunc;\n\ttags;\n\tconfig;\n\ttrace = true;\n\trecurse = true;\n\tconstructor(fields) {\n\t\tsuper();\n\t\tthis.name = fields.name ?? fields.func.name;\n\t\tthis.func = fields.func;\n\t\tthis.config = fields.tags ? { tags: fields.tags } : void 0;\n\t\tthis.trace = fields.trace ?? this.trace;\n\t\tthis.recurse = fields.recurse ?? this.recurse;\n\t}\n\tasync _tracedInvoke(input, config, runManager) {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tconst childConfig = patchConfig(config, { callbacks: runManager?.getChild() });\n\t\t\tAsyncLocalStorageProviderSingleton.runWithConfig(childConfig, async () => {\n\t\t\t\ttry {\n\t\t\t\t\tconst output = await this.func(input, childConfig);\n\t\t\t\t\tresolve(output);\n\t\t\t\t} catch (e) {\n\t\t\t\t\treject(e);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\tasync invoke(input, options) {\n\t\tlet returnValue;\n\t\tconst config = ensureLangGraphConfig(options);\n\t\tconst mergedConfig = mergeConfigs(this.config, config);\n\t\tif (this.trace) returnValue = await this._callWithConfig(this._tracedInvoke, input, mergedConfig);\n\t\telse returnValue = await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => this.func(input, mergedConfig));\n\t\tif (Runnable.isRunnable(returnValue) && this.recurse) return await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => returnValue.invoke(input, mergedConfig));\n\t\treturn returnValue;\n\t}\n};\nfunction* prefixGenerator(generator, prefix) {\n\tif (prefix === void 0) yield* generator;\n\telse for (const value of generator) yield [prefix, value];\n}\nasync function gatherIterator(i) {\n\tconst out = [];\n\tfor await (const item of await i) out.push(item);\n\treturn out;\n}\nfunction gatherIteratorSync(i) {\n\tconst out = [];\n\tfor (const item of i) out.push(item);\n\treturn out;\n}\nfunction patchConfigurable(config, patch) {\n\tif (!config) return { configurable: patch };\n\telse if (!(\"configurable\" in config)) return {\n\t\t...config,\n\t\tconfigurable: patch\n\t};\n\telse return {\n\t\t...config,\n\t\tconfigurable: {\n\t\t\t...config.configurable,\n\t\t\t...patch\n\t\t}\n\t};\n}\nfunction isAsyncGeneratorFunction(val) {\n\treturn val != null && typeof val === \"function\" && val instanceof Object.getPrototypeOf(async function* () {}).constructor;\n}\nfunction isGeneratorFunction(val) {\n\treturn val != null && typeof val === \"function\" && val instanceof Object.getPrototypeOf(function* () {}).constructor;\n}\n\n//#endregion\nexport { RunnableCallable, gatherIterator, gatherIteratorSync, isAsyncGeneratorFunction, isGeneratorFunction, patchConfigurable, prefixGenerator };\n//# sourceMappingURL=utils.js.map","import { InvalidUpdateError } from \"../errors.js\";\nimport { CONFIG_KEY_SEND, TASKS, _isSend } from \"../constants.js\";\nimport { RunnableCallable } from \"../utils.js\";\nimport { Runnable } from \"@langchain/core/runnables\";\n\n//#region src/pregel/write.ts\nconst SKIP_WRITE = { [Symbol.for(\"LG_SKIP_WRITE\")]: true };\nfunction _isSkipWrite(x) {\n\treturn typeof x === \"object\" && x?.[Symbol.for(\"LG_SKIP_WRITE\")] !== void 0;\n}\nconst PASSTHROUGH = { [Symbol.for(\"LG_PASSTHROUGH\")]: true };\nfunction _isPassthrough(x) {\n\treturn typeof x === \"object\" && x?.[Symbol.for(\"LG_PASSTHROUGH\")] !== void 0;\n}\nconst IS_WRITER = Symbol(\"IS_WRITER\");\n/**\n* Mapping of write channels to Runnables that return the value to be written,\n* or None to skip writing.\n*/\nvar ChannelWrite = class ChannelWrite extends RunnableCallable {\n\twrites;\n\tconstructor(writes, tags) {\n\t\tconst name = `ChannelWrite<${writes.map((packet) => {\n\t\t\tif (_isSend(packet)) return packet.node;\n\t\t\telse if (\"channel\" in packet) return packet.channel;\n\t\t\treturn \"...\";\n\t\t}).join(\",\")}>`;\n\t\tsuper({\n\t\t\twrites,\n\t\t\tname,\n\t\t\ttags,\n\t\t\tfunc: async (input, config) => {\n\t\t\t\treturn this._write(input, config ?? {});\n\t\t\t}\n\t\t});\n\t\tthis.writes = writes;\n\t}\n\tasync _write(input, config) {\n\t\tconst writes = this.writes.map((write) => {\n\t\t\tif (_isChannelWriteTupleEntry(write) && _isPassthrough(write.value)) return {\n\t\t\t\tmapper: write.mapper,\n\t\t\t\tvalue: input\n\t\t\t};\n\t\t\telse if (_isChannelWriteEntry(write) && _isPassthrough(write.value)) return {\n\t\t\t\tchannel: write.channel,\n\t\t\t\tvalue: input,\n\t\t\t\tskipNone: write.skipNone,\n\t\t\t\tmapper: write.mapper\n\t\t\t};\n\t\t\telse return write;\n\t\t});\n\t\tawait ChannelWrite.doWrite(config, writes);\n\t\treturn input;\n\t}\n\tstatic async doWrite(config, writes) {\n\t\tfor (const w of writes) {\n\t\t\tif (_isChannelWriteEntry(w)) {\n\t\t\t\tif (w.channel === TASKS) throw new InvalidUpdateError(\"Cannot write to the reserved channel TASKS\");\n\t\t\t\tif (_isPassthrough(w.value)) throw new InvalidUpdateError(\"PASSTHROUGH value must be replaced\");\n\t\t\t}\n\t\t\tif (_isChannelWriteTupleEntry(w)) {\n\t\t\t\tif (_isPassthrough(w.value)) throw new InvalidUpdateError(\"PASSTHROUGH value must be replaced\");\n\t\t\t}\n\t\t}\n\t\tconst writeEntries = [];\n\t\tfor (const w of writes) if (_isSend(w)) writeEntries.push([TASKS, w]);\n\t\telse if (_isChannelWriteTupleEntry(w)) {\n\t\t\tconst mappedResult = await w.mapper.invoke(w.value, config);\n\t\t\tif (mappedResult != null && mappedResult.length > 0) writeEntries.push(...mappedResult);\n\t\t} else if (_isChannelWriteEntry(w)) {\n\t\t\tconst mappedValue = w.mapper !== void 0 ? await w.mapper.invoke(w.value, config) : w.value;\n\t\t\tif (_isSkipWrite(mappedValue)) continue;\n\t\t\tif (w.skipNone && mappedValue === void 0) continue;\n\t\t\twriteEntries.push([w.channel, mappedValue]);\n\t\t} else throw new Error(`Invalid write entry: ${JSON.stringify(w)}`);\n\t\tconst write = config.configurable?.[CONFIG_KEY_SEND];\n\t\twrite(writeEntries);\n\t}\n\tstatic isWriter(runnable) {\n\t\treturn runnable instanceof ChannelWrite || IS_WRITER in runnable && !!runnable[IS_WRITER];\n\t}\n\tstatic registerWriter(runnable) {\n\t\treturn Object.defineProperty(runnable, IS_WRITER, { value: true });\n\t}\n};\nfunction _isChannelWriteEntry(x) {\n\treturn x !== void 0 && typeof x.channel === \"string\";\n}\nfunction _isChannelWriteTupleEntry(x) {\n\treturn x !== void 0 && !_isChannelWriteEntry(x) && Runnable.isRunnable(x.mapper);\n}\n\n//#endregion\nexport { ChannelWrite, PASSTHROUGH };\n//# sourceMappingURL=write.js.map","import { CONFIG_KEY_READ } from \"../constants.js\";\nimport { RunnableCallable } from \"../utils.js\";\nimport { ChannelWrite } from \"./write.js\";\nimport { RunnableBinding, RunnablePassthrough, RunnableSequence, _coerceToRunnable } from \"@langchain/core/runnables\";\n\n//#region src/pregel/read.ts\nvar ChannelRead = class ChannelRead extends RunnableCallable {\n\tlc_graph_name = \"ChannelRead\";\n\tchannel;\n\tfresh = false;\n\tmapper;\n\tconstructor(channel, mapper, fresh = false) {\n\t\tsuper({ func: (_, config) => ChannelRead.doRead(config, this.channel, this.fresh, this.mapper) });\n\t\tthis.fresh = fresh;\n\t\tthis.mapper = mapper;\n\t\tthis.channel = channel;\n\t\tthis.name = Array.isArray(channel) ? `ChannelRead<${channel.join(\",\")}>` : `ChannelRead<${channel}>`;\n\t}\n\tstatic doRead(config, channel, fresh, mapper) {\n\t\tconst read = config.configurable?.[CONFIG_KEY_READ];\n\t\tif (!read) throw new Error(\"Runnable is not configured with a read function. Make sure to call in the context of a Pregel process\");\n\t\tif (mapper) return mapper(read(channel, fresh));\n\t\telse return read(channel, fresh);\n\t}\n};\nconst defaultRunnableBound = /* @__PURE__ */ new RunnablePassthrough();\nvar PregelNode = class PregelNode extends RunnableBinding {\n\tlc_graph_name = \"PregelNode\";\n\tchannels;\n\ttriggers = [];\n\tmapper;\n\twriters = [];\n\tbound = defaultRunnableBound;\n\tkwargs = {};\n\tmetadata = {};\n\ttags = [];\n\tretryPolicy;\n\tcachePolicy;\n\tsubgraphs;\n\tends;\n\tconstructor(fields) {\n\t\tconst { channels, triggers, mapper, writers, bound, kwargs, metadata, retryPolicy, cachePolicy, tags, subgraphs, ends } = fields;\n\t\tconst mergedTags = [...fields.config?.tags ? fields.config.tags : [], ...tags ?? []];\n\t\tsuper({\n\t\t\t...fields,\n\t\t\tbound: fields.bound ?? defaultRunnableBound,\n\t\t\tconfig: {\n\t\t\t\t...fields.config ? fields.config : {},\n\t\t\t\ttags: mergedTags\n\t\t\t}\n\t\t});\n\t\tthis.channels = channels;\n\t\tthis.triggers = triggers;\n\t\tthis.mapper = mapper;\n\t\tthis.writers = writers ?? this.writers;\n\t\tthis.bound = bound ?? this.bound;\n\t\tthis.kwargs = kwargs ?? this.kwargs;\n\t\tthis.metadata = metadata ?? this.metadata;\n\t\tthis.tags = mergedTags;\n\t\tthis.retryPolicy = retryPolicy;\n\t\tthis.cachePolicy = cachePolicy;\n\t\tthis.subgraphs = subgraphs;\n\t\tthis.ends = ends;\n\t}\n\tgetWriters() {\n\t\tconst newWriters = [...this.writers];\n\t\twhile (newWriters.length > 1 && newWriters[newWriters.length - 1] instanceof ChannelWrite && newWriters[newWriters.length - 2] instanceof ChannelWrite) {\n\t\t\tconst endWriters = newWriters.slice(-2);\n\t\t\tconst combinedWrites = endWriters[0].writes.concat(endWriters[1].writes);\n\t\t\tnewWriters[newWriters.length - 2] = new ChannelWrite(combinedWrites, endWriters[0].config?.tags);\n\t\t\tnewWriters.pop();\n\t\t}\n\t\treturn newWriters;\n\t}\n\tgetNode() {\n\t\tconst writers = this.getWriters();\n\t\tif (this.bound === defaultRunnableBound && writers.length === 0) return void 0;\n\t\telse if (this.bound === defaultRunnableBound && writers.length === 1) return writers[0];\n\t\telse if (this.bound === defaultRunnableBound) return new RunnableSequence({\n\t\t\tfirst: writers[0],\n\t\t\tmiddle: writers.slice(1, writers.length - 1),\n\t\t\tlast: writers[writers.length - 1],\n\t\t\tomitSequenceTags: true\n\t\t});\n\t\telse if (writers.length > 0) return new RunnableSequence({\n\t\t\tfirst: this.bound,\n\t\t\tmiddle: writers.slice(0, writers.length - 1),\n\t\t\tlast: writers[writers.length - 1],\n\t\t\tomitSequenceTags: true\n\t\t});\n\t\telse return this.bound;\n\t}\n\tjoin(channels) {\n\t\tif (!Array.isArray(channels)) throw new Error(\"channels must be a list\");\n\t\tif (typeof this.channels !== \"object\") throw new Error(\"all channels must be named when using .join()\");\n\t\treturn new PregelNode({\n\t\t\tchannels: {\n\t\t\t\t...this.channels,\n\t\t\t\t...Object.fromEntries(channels.map((chan) => [chan, chan]))\n\t\t\t},\n\t\t\ttriggers: this.triggers,\n\t\t\tmapper: this.mapper,\n\t\t\twriters: this.writers,\n\t\t\tbound: this.bound,\n\t\t\tkwargs: this.kwargs,\n\t\t\tconfig: this.config,\n\t\t\tretryPolicy: this.retryPolicy,\n\t\t\tcachePolicy: this.cachePolicy\n\t\t});\n\t}\n\tpipe(coerceable) {\n\t\tif (ChannelWrite.isWriter(coerceable)) return new PregelNode({\n\t\t\tchannels: this.channels,\n\t\t\ttriggers: this.triggers,\n\t\t\tmapper: this.mapper,\n\t\t\twriters: [...this.writers, coerceable],\n\t\t\tbound: this.bound,\n\t\t\tconfig: this.config,\n\t\t\tkwargs: this.kwargs,\n\t\t\tretryPolicy: this.retryPolicy,\n\t\t\tcachePolicy: this.cachePolicy\n\t\t});\n\t\telse if (this.bound === defaultRunnableBound) return new PregelNode({\n\t\t\tchannels: this.channels,\n\t\t\ttriggers: this.triggers,\n\t\t\tmapper: this.mapper,\n\t\t\twriters: this.writers,\n\t\t\tbound: _coerceToRunnable(coerceable),\n\t\t\tconfig: this.config,\n\t\t\tkwargs: this.kwargs,\n\t\t\tretryPolicy: this.retryPolicy,\n\t\t\tcachePolicy: this.cachePolicy\n\t\t});\n\t\telse return new PregelNode({\n\t\t\tchannels: this.channels,\n\t\t\ttriggers: this.triggers,\n\t\t\tmapper: this.mapper,\n\t\t\twriters: this.writers,\n\t\t\tbound: this.bound.pipe(coerceable),\n\t\t\tconfig: this.config,\n\t\t\tkwargs: this.kwargs,\n\t\t\tretryPolicy: this.retryPolicy,\n\t\t\tcachePolicy: this.cachePolicy\n\t\t});\n\t}\n};\n\n//#endregion\nexport { ChannelRead, PregelNode };\n//# sourceMappingURL=read.js.map","//#region src/pregel/utils/subgraph.ts\nfunction isRunnableSequence(x) {\n\treturn \"steps\" in x && Array.isArray(x.steps);\n}\nfunction isPregelLike(x) {\n\treturn \"lg_is_pregel\" in x && x.lg_is_pregel === true;\n}\nfunction findSubgraphPregel(candidate) {\n\tconst candidates = [candidate];\n\tfor (const candidate$1 of candidates) if (isPregelLike(candidate$1)) return candidate$1;\n\telse if (isRunnableSequence(candidate$1)) candidates.push(...candidate$1.steps);\n\treturn void 0;\n}\n\n//#endregion\nexport { findSubgraphPregel, isPregelLike };\n//# sourceMappingURL=subgraph.js.map","import { EmptyChannelError, InvalidUpdateError } from \"../errors.js\";\nimport { Command, ERROR, INTERRUPT, NULL_TASK_ID, RESUME, RETURN, TAG_HIDDEN, TASKS, _isSend } from \"../constants.js\";\nimport { isXXH3 } from \"../hash.js\";\n\n//#region src/pregel/io.ts\nfunction readChannel(channels, chan, catchErrors = true, returnException = false) {\n\ttry {\n\t\treturn channels[chan].get();\n\t} catch (e) {\n\t\tif (e.name === EmptyChannelError.unminifiable_name) {\n\t\t\tif (returnException) return e;\n\t\t\telse if (catchErrors) return null;\n\t\t}\n\t\tthrow e;\n\t}\n}\nfunction readChannels(channels, select, skipEmpty = true) {\n\tif (Array.isArray(select)) {\n\t\tconst values = {};\n\t\tfor (const k of select) try {\n\t\t\tvalues[k] = readChannel(channels, k, !skipEmpty);\n\t\t} catch (e) {\n\t\t\tif (e.name === EmptyChannelError.unminifiable_name) continue;\n\t\t}\n\t\treturn values;\n\t} else return readChannel(channels, select);\n}\n/**\n* Map input chunk to a sequence of pending writes in the form (channel, value).\n*/\nfunction* mapCommand(cmd, pendingWrites) {\n\tif (cmd.graph === Command.PARENT) throw new InvalidUpdateError(\"There is no parent graph.\");\n\tif (cmd.goto) {\n\t\tlet sends;\n\t\tif (Array.isArray(cmd.goto)) sends = cmd.goto;\n\t\telse sends = [cmd.goto];\n\t\tfor (const send of sends) if (_isSend(send)) yield [\n\t\t\tNULL_TASK_ID,\n\t\t\tTASKS,\n\t\t\tsend\n\t\t];\n\t\telse if (typeof send === \"string\") yield [\n\t\t\tNULL_TASK_ID,\n\t\t\t`branch:to:${send}`,\n\t\t\t\"__start__\"\n\t\t];\n\t\telse throw new Error(`In Command.send, expected Send or string, got ${typeof send}`);\n\t}\n\tif (cmd.resume) if (typeof cmd.resume === \"object\" && Object.keys(cmd.resume).length && Object.keys(cmd.resume).every(isXXH3)) for (const [tid, resume] of Object.entries(cmd.resume)) {\n\t\tconst existing = pendingWrites.filter((w) => w[0] === tid && w[1] === RESUME).map((w) => w[2]).slice(0, 1) ?? [];\n\t\texisting.push(resume);\n\t\tyield [\n\t\t\ttid,\n\t\t\tRESUME,\n\t\t\texisting\n\t\t];\n\t}\n\telse yield [\n\t\tNULL_TASK_ID,\n\t\tRESUME,\n\t\tcmd.resume\n\t];\n\tif (cmd.update) {\n\t\tif (typeof cmd.update !== \"object\" || !cmd.update) throw new Error(\"Expected cmd.update to be a dict mapping channel names to update values\");\n\t\tif (Array.isArray(cmd.update)) for (const [k, v] of cmd.update) yield [\n\t\t\tNULL_TASK_ID,\n\t\t\tk,\n\t\t\tv\n\t\t];\n\t\telse for (const [k, v] of Object.entries(cmd.update)) yield [\n\t\t\tNULL_TASK_ID,\n\t\t\tk,\n\t\t\tv\n\t\t];\n\t}\n}\n/**\n* Map input chunk to a sequence of pending writes in the form [channel, value].\n*/\nfunction* mapInput(inputChannels, chunk) {\n\tif (chunk !== void 0 && chunk !== null) if (Array.isArray(inputChannels) && typeof chunk === \"object\" && !Array.isArray(chunk)) {\n\t\tfor (const k in chunk) if (inputChannels.includes(k)) yield [k, chunk[k]];\n\t} else if (Array.isArray(inputChannels)) throw new Error(`Input chunk must be an object when \"inputChannels\" is an array`);\n\telse yield [inputChannels, chunk];\n}\n/**\n* Map pending writes (a sequence of tuples (channel, value)) to output chunk.\n*/\nfunction* mapOutputValues(outputChannels, pendingWrites, channels) {\n\tif (Array.isArray(outputChannels)) {\n\t\tif (pendingWrites === true || pendingWrites.find(([chan, _]) => outputChannels.includes(chan))) yield readChannels(channels, outputChannels);\n\t} else if (pendingWrites === true || pendingWrites.some(([chan, _]) => chan === outputChannels)) yield readChannel(channels, outputChannels);\n}\n/**\n* Map pending writes (a sequence of tuples (channel, value)) to output chunk.\n* @internal\n*\n* @param outputChannels - The channels to output.\n* @param tasks - The tasks to output.\n* @param cached - Whether the output is cached.\n*\n* @returns A generator that yields the output chunk (if any).\n*/\nfunction* mapOutputUpdates(outputChannels, tasks, cached) {\n\tconst outputTasks = tasks.filter(([task, ww]) => {\n\t\treturn (task.config === void 0 || !task.config.tags?.includes(TAG_HIDDEN)) && ww[0][0] !== ERROR && ww[0][0] !== INTERRUPT;\n\t});\n\tif (!outputTasks.length) return;\n\tlet updated;\n\tif (outputTasks.some(([task]) => task.writes.some(([chan, _]) => chan === RETURN))) updated = outputTasks.flatMap(([task]) => task.writes.filter(([chan, _]) => chan === RETURN).map(([_, value]) => [task.name, value]));\n\telse if (!Array.isArray(outputChannels)) updated = outputTasks.flatMap(([task]) => task.writes.filter(([chan, _]) => chan === outputChannels).map(([_, value]) => [task.name, value]));\n\telse updated = outputTasks.flatMap(([task]) => {\n\t\tconst { writes } = task;\n\t\tconst counts = {};\n\t\tfor (const [chan] of writes) if (outputChannels.includes(chan)) counts[chan] = (counts[chan] || 0) + 1;\n\t\tif (Object.values(counts).some((count) => count > 1)) return writes.filter(([chan]) => outputChannels.includes(chan)).map(([chan, value]) => [task.name, { [chan]: value }]);\n\t\telse return [[task.name, Object.fromEntries(writes.filter(([chan]) => outputChannels.includes(chan)))]];\n\t});\n\tconst grouped = {};\n\tfor (const [node, value] of updated) {\n\t\tif (!(node in grouped)) grouped[node] = [];\n\t\tgrouped[node].push(value);\n\t}\n\tconst flattened = {};\n\tfor (const node in grouped) if (grouped[node].length === 1) {\n\t\tconst [write] = grouped[node];\n\t\tflattened[node] = write;\n\t} else flattened[node] = grouped[node];\n\tif (cached) flattened[\"__metadata__\"] = { cached };\n\tyield flattened;\n}\n\n//#endregion\nexport { mapCommand, mapInput, mapOutputUpdates, mapOutputValues, readChannel, readChannels };\n//# sourceMappingURL=io.js.map","import { CONFIG_KEY_CHECKPOINT_MAP, START } from \"../../constants.js\";\n\n//#region src/pregel/utils/index.ts\nfunction getNullChannelVersion(currentVersions) {\n\tconst startVersion = typeof currentVersions[START];\n\tif (startVersion === \"number\") return 0;\n\tif (startVersion === \"string\") return \"\";\n\tfor (const key in currentVersions) {\n\t\tif (!Object.prototype.hasOwnProperty.call(currentVersions, key)) continue;\n\t\tconst versionType = typeof currentVersions[key];\n\t\tif (versionType === \"number\") return 0;\n\t\tif (versionType === \"string\") return \"\";\n\t\tbreak;\n\t}\n\treturn void 0;\n}\nfunction getNewChannelVersions(previousVersions, currentVersions) {\n\tif (Object.keys(previousVersions).length > 0) {\n\t\tconst nullVersion = getNullChannelVersion(currentVersions);\n\t\treturn Object.fromEntries(Object.entries(currentVersions).filter(([k, v]) => v > (previousVersions[k] ?? nullVersion)));\n\t} else return currentVersions;\n}\nfunction _coerceToDict(value, defaultKey) {\n\treturn value && !Array.isArray(value) && !(value instanceof Date) && typeof value === \"object\" ? value : { [defaultKey]: value };\n}\nfunction patchConfigurable(config, patch) {\n\tif (config === null) return { configurable: patch };\n\telse if (config?.configurable === void 0) return {\n\t\t...config,\n\t\tconfigurable: patch\n\t};\n\telse return {\n\t\t...config,\n\t\tconfigurable: {\n\t\t\t...config.configurable,\n\t\t\t...patch\n\t\t}\n\t};\n}\nfunction patchCheckpointMap(config, metadata) {\n\tconst parents = metadata?.parents ?? {};\n\tif (Object.keys(parents).length > 0) return patchConfigurable(config, { [CONFIG_KEY_CHECKPOINT_MAP]: {\n\t\t...parents,\n\t\t[config.configurable?.checkpoint_ns ?? \"\"]: config.configurable?.checkpoint_id\n\t} });\n\telse return config;\n}\n/**\n* Combine multiple abort signals into a single abort signal.\n* @param signals - The abort signals to combine.\n* @returns A combined abort signal and a dispose function to remove the abort listener if unused.\n*/\nfunction combineAbortSignals(...x) {\n\tconst signals = [...new Set(x.filter(Boolean))];\n\tif (signals.length === 0) return {\n\t\tsignal: void 0,\n\t\tdispose: void 0\n\t};\n\tif (signals.length === 1) return {\n\t\tsignal: signals[0],\n\t\tdispose: void 0\n\t};\n\tconst combinedController = new AbortController();\n\tconst listener = () => {\n\t\tconst reason = signals.find((s) => s.aborted)?.reason;\n\t\tcombinedController.abort(reason);\n\t\tsignals.forEach((s) => s.removeEventListener(\"abort\", listener));\n\t};\n\tsignals.forEach((s) => s.addEventListener(\"abort\", listener, { once: true }));\n\tconst hasAlreadyAbortedSignal = signals.find((s) => s.aborted);\n\tif (hasAlreadyAbortedSignal) combinedController.abort(hasAlreadyAbortedSignal.reason);\n\treturn {\n\t\tsignal: combinedController.signal,\n\t\tdispose: () => {\n\t\t\tsignals.forEach((s) => s.removeEventListener(\"abort\", listener));\n\t\t}\n\t};\n}\n/**\n* Combine multiple callbacks into a single callback.\n* @param callback1 - The first callback to combine.\n* @param callback2 - The second callback to combine.\n* @returns A single callback that is a combination of the input callbacks.\n*/\nconst combineCallbacks = (callback1, callback2) => {\n\tif (!callback1 && !callback2) return void 0;\n\tif (!callback1) return callback2;\n\tif (!callback2) return callback1;\n\tif (Array.isArray(callback1) && Array.isArray(callback2)) return [...callback1, ...callback2];\n\tif (Array.isArray(callback1)) return [...callback1, callback2];\n\tif (Array.isArray(callback2)) return [callback1, ...callback2];\n\treturn [callback1, callback2];\n};\n\n//#endregion\nexport { _coerceToDict, combineAbortSignals, combineCallbacks, getNewChannelVersions, getNullChannelVersion, patchCheckpointMap, patchConfigurable };\n//# sourceMappingURL=index.js.map","//#region src/pregel/types.ts\nvar Call = class {\n\tfunc;\n\tname;\n\tinput;\n\tretry;\n\tcache;\n\tcallbacks;\n\t__lg_type = \"call\";\n\tconstructor({ func, name, input, retry, cache, callbacks }) {\n\t\tthis.func = func;\n\t\tthis.name = name;\n\t\tthis.input = input;\n\t\tthis.retry = retry;\n\t\tthis.cache = cache;\n\t\tthis.callbacks = callbacks;\n\t}\n};\nfunction isCall(value) {\n\treturn typeof value === \"object\" && value !== null && \"__lg_type\" in value && value.__lg_type === \"call\";\n}\n\n//#endregion\nexport { Call, isCall };\n//# sourceMappingURL=types.js.map","import { CONFIG_KEY_CALL, RETURN, TAG_HIDDEN } from \"../constants.js\";\nimport { RunnableCallable } from \"../utils.js\";\nimport { ChannelWrite, PASSTHROUGH } from \"./write.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\nimport { RunnableSequence } from \"@langchain/core/runnables\";\n\n//#region src/pregel/call.ts\n/**\n* Wraps a user function in a Runnable that writes the returned value to the RETURN channel.\n*/\nfunction getRunnableForFunc(name, func) {\n\tconst run = new RunnableCallable({\n\t\tfunc: (input) => func(...input),\n\t\tname,\n\t\ttrace: false,\n\t\trecurse: false\n\t});\n\treturn new RunnableSequence({\n\t\tname,\n\t\tfirst: run,\n\t\tlast: new ChannelWrite([{\n\t\t\tchannel: RETURN,\n\t\t\tvalue: PASSTHROUGH\n\t\t}], [TAG_HIDDEN])\n\t});\n}\nfunction getRunnableForEntrypoint(name, func) {\n\tconst run = new RunnableCallable({\n\t\tfunc: (input, config) => {\n\t\t\treturn func(input, config);\n\t\t},\n\t\tname,\n\t\ttrace: false,\n\t\trecurse: false\n\t});\n\treturn run;\n}\nfunction call({ func, name, cache, retry }, ...args) {\n\tconst config = AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tif (typeof config.configurable?.[CONFIG_KEY_CALL] === \"function\") return config.configurable[CONFIG_KEY_CALL](func, name, args, {\n\t\tretry,\n\t\tcache,\n\t\tcallbacks: config.callbacks\n\t});\n\tthrow new Error(\"Async local storage not initialized. Please call initializeAsyncLocalStorageSingleton() before using this function.\");\n}\n\n//#endregion\nexport { call, getRunnableForEntrypoint, getRunnableForFunc };\n//# sourceMappingURL=call.js.map","import { EmptyChannelError, InvalidUpdateError } from \"../errors.js\";\nimport { createCheckpoint, emptyChannels, getOnlyChannels } from \"../channels/base.js\";\nimport { CACHE_NS_WRITES, CHECKPOINT_NAMESPACE_END, CHECKPOINT_NAMESPACE_SEPARATOR, CONFIG_KEY_CHECKPOINTER, CONFIG_KEY_CHECKPOINT_MAP, CONFIG_KEY_PREVIOUS_STATE, CONFIG_KEY_READ, CONFIG_KEY_RESUME_MAP, CONFIG_KEY_SCRATCHPAD, CONFIG_KEY_SEND, CONFIG_KEY_TASK_ID, ERROR, INTERRUPT, NO_WRITES, NULL_TASK_ID, PREVIOUS, PULL, PUSH, RESERVED, RESUME, RETURN, START, Send, TAG_HIDDEN, TASKS, _isSend, _isSendInterface } from \"../constants.js\";\nimport { XXH3 } from \"../hash.js\";\nimport { readChannel, readChannels } from \"./io.js\";\nimport { isCall } from \"./types.js\";\nimport { getNullChannelVersion } from \"./utils/index.js\";\nimport { getRunnableForFunc } from \"./call.js\";\nimport { copyCheckpoint, maxChannelVersion, uuid5 } from \"@langchain/langgraph-checkpoint\";\nimport { mergeConfigs, patchConfig } from \"@langchain/core/runnables\";\n\n//#region src/pregel/algo.ts\nconst increment = (current) => {\n\treturn current !== void 0 ? current + 1 : 1;\n};\nfunction triggersNextStep(updatedChannels, triggerToNodes) {\n\tif (triggerToNodes == null) return false;\n\tfor (const chan of updatedChannels) if (triggerToNodes[chan]) return true;\n\treturn false;\n}\nfunction maxChannelMapVersion(channelVersions) {\n\tlet maxVersion;\n\tfor (const chan in channelVersions) {\n\t\tif (!Object.prototype.hasOwnProperty.call(channelVersions, chan)) continue;\n\t\tif (maxVersion == null) maxVersion = channelVersions[chan];\n\t\telse maxVersion = maxChannelVersion(maxVersion, channelVersions[chan]);\n\t}\n\treturn maxVersion;\n}\nfunction shouldInterrupt(checkpoint, interruptNodes, tasks) {\n\tconst nullVersion = getNullChannelVersion(checkpoint.channel_versions);\n\tconst seen = checkpoint.versions_seen[INTERRUPT] ?? {};\n\tlet anyChannelUpdated = false;\n\tif ((checkpoint.channel_versions[START] ?? nullVersion) > (seen[START] ?? nullVersion)) anyChannelUpdated = true;\n\telse for (const chan in checkpoint.channel_versions) {\n\t\tif (!Object.prototype.hasOwnProperty.call(checkpoint.channel_versions, chan)) continue;\n\t\tif (checkpoint.channel_versions[chan] > (seen[chan] ?? nullVersion)) {\n\t\t\tanyChannelUpdated = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tconst anyTriggeredNodeInInterruptNodes = tasks.some((task) => interruptNodes === \"*\" ? !task.config?.tags?.includes(TAG_HIDDEN) : interruptNodes.includes(task.name));\n\treturn anyChannelUpdated && anyTriggeredNodeInInterruptNodes;\n}\nfunction _localRead(checkpoint, channels, task, select, fresh = false) {\n\tlet updated = /* @__PURE__ */ new Set();\n\tif (!Array.isArray(select)) {\n\t\tfor (const [c] of task.writes) if (c === select) {\n\t\t\tupdated = new Set([c]);\n\t\t\tbreak;\n\t\t}\n\t\tupdated = updated || /* @__PURE__ */ new Set();\n\t} else updated = new Set(select.filter((c) => task.writes.some(([key, _]) => key === c)));\n\tlet values;\n\tif (fresh && updated.size > 0) {\n\t\tconst localChannels = Object.fromEntries(Object.entries(channels).filter(([k, _]) => updated.has(k)));\n\t\tconst newCheckpoint = createCheckpoint(checkpoint, localChannels, -1);\n\t\tconst newChannels = emptyChannels(localChannels, newCheckpoint);\n\t\t_applyWrites(copyCheckpoint(newCheckpoint), newChannels, [task], void 0, void 0);\n\t\tvalues = readChannels({\n\t\t\t...channels,\n\t\t\t...newChannels\n\t\t}, select);\n\t} else values = readChannels(channels, select);\n\treturn values;\n}\nfunction _localWrite(commit, processes, writes) {\n\tfor (const [chan, value] of writes) if ([PUSH, TASKS].includes(chan) && value != null) {\n\t\tif (!_isSend(value)) throw new InvalidUpdateError(`Invalid packet type, expected SendProtocol, got ${JSON.stringify(value)}`);\n\t\tif (!(value.node in processes)) throw new InvalidUpdateError(`Invalid node name \"${value.node}\" in Send packet`);\n\t}\n\tcommit(writes);\n}\nconst IGNORE = new Set([\n\tNO_WRITES,\n\tPUSH,\n\tRESUME,\n\tINTERRUPT,\n\tRETURN,\n\tERROR\n]);\nfunction _applyWrites(checkpoint, channels, tasks, getNextVersion, triggerToNodes) {\n\ttasks.sort((a, b) => {\n\t\tconst aPath = a.path?.slice(0, 3) || [];\n\t\tconst bPath = b.path?.slice(0, 3) || [];\n\t\tfor (let i = 0; i < Math.min(aPath.length, bPath.length); i += 1) {\n\t\t\tif (aPath[i] < bPath[i]) return -1;\n\t\t\tif (aPath[i] > bPath[i]) return 1;\n\t\t}\n\t\treturn aPath.length - bPath.length;\n\t});\n\tconst bumpStep = tasks.some((task) => task.triggers.length > 0);\n\tconst onlyChannels = getOnlyChannels(channels);\n\tfor (const task of tasks) {\n\t\tcheckpoint.versions_seen[task.name] ??= {};\n\t\tfor (const chan of task.triggers) if (chan in checkpoint.channel_versions) checkpoint.versions_seen[task.name][chan] = checkpoint.channel_versions[chan];\n\t}\n\tlet maxVersion = maxChannelMapVersion(checkpoint.channel_versions);\n\tconst channelsToConsume = new Set(tasks.flatMap((task) => task.triggers).filter((chan) => !RESERVED.includes(chan)));\n\tlet usedNewVersion = false;\n\tfor (const chan of channelsToConsume) if (chan in onlyChannels && onlyChannels[chan].consume()) {\n\t\tif (getNextVersion !== void 0) {\n\t\t\tcheckpoint.channel_versions[chan] = getNextVersion(maxVersion);\n\t\t\tusedNewVersion = true;\n\t\t}\n\t}\n\tconst pendingWritesByChannel = {};\n\tfor (const task of tasks) for (const [chan, val] of task.writes) if (IGNORE.has(chan)) {} else if (chan in onlyChannels) {\n\t\tpendingWritesByChannel[chan] ??= [];\n\t\tpendingWritesByChannel[chan].push(val);\n\t}\n\tif (maxVersion != null && getNextVersion != null) maxVersion = usedNewVersion ? getNextVersion(maxVersion) : maxVersion;\n\tconst updatedChannels = /* @__PURE__ */ new Set();\n\tfor (const [chan, vals] of Object.entries(pendingWritesByChannel)) if (chan in onlyChannels) {\n\t\tconst channel = onlyChannels[chan];\n\t\tlet updated;\n\t\ttry {\n\t\t\tupdated = channel.update(vals);\n\t\t} catch (e) {\n\t\t\tif (e.name === InvalidUpdateError.unminifiable_name) {\n\t\t\t\tconst wrappedError = new InvalidUpdateError(`Invalid update for channel \"${chan}\" with values ${JSON.stringify(vals)}: ${e.message}`);\n\t\t\t\twrappedError.lc_error_code = e.lc_error_code;\n\t\t\t\tthrow wrappedError;\n\t\t\t} else throw e;\n\t\t}\n\t\tif (updated && getNextVersion !== void 0) {\n\t\t\tcheckpoint.channel_versions[chan] = getNextVersion(maxVersion);\n\t\t\tif (channel.isAvailable()) updatedChannels.add(chan);\n\t\t}\n\t}\n\tif (bumpStep) for (const chan in onlyChannels) {\n\t\tif (!Object.prototype.hasOwnProperty.call(onlyChannels, chan)) continue;\n\t\tconst channel = onlyChannels[chan];\n\t\tif (channel.isAvailable() && !updatedChannels.has(chan)) {\n\t\t\tconst updated = channel.update([]);\n\t\t\tif (updated && getNextVersion !== void 0) {\n\t\t\t\tcheckpoint.channel_versions[chan] = getNextVersion(maxVersion);\n\t\t\t\tif (channel.isAvailable()) updatedChannels.add(chan);\n\t\t\t}\n\t\t}\n\t}\n\tif (bumpStep && !triggersNextStep(updatedChannels, triggerToNodes)) for (const chan in onlyChannels) {\n\t\tif (!Object.prototype.hasOwnProperty.call(onlyChannels, chan)) continue;\n\t\tconst channel = onlyChannels[chan];\n\t\tif (channel.finish() && getNextVersion !== void 0) {\n\t\t\tcheckpoint.channel_versions[chan] = getNextVersion(maxVersion);\n\t\t\tif (channel.isAvailable()) updatedChannels.add(chan);\n\t\t}\n\t}\n\treturn updatedChannels;\n}\nfunction* candidateNodes(checkpoint, processes, extra) {\n\tif (extra.updatedChannels != null && extra.triggerToNodes != null) {\n\t\tconst triggeredNodes = /* @__PURE__ */ new Set();\n\t\tfor (const channel of extra.updatedChannels) {\n\t\t\tconst nodeIds = extra.triggerToNodes[channel];\n\t\t\tfor (const id of nodeIds ?? []) triggeredNodes.add(id);\n\t\t}\n\t\tyield* [...triggeredNodes].sort();\n\t\treturn;\n\t}\n\tconst isEmptyChannelVersions = (() => {\n\t\tfor (const chan in checkpoint.channel_versions) if (checkpoint.channel_versions[chan] !== null) return false;\n\t\treturn true;\n\t})();\n\tif (isEmptyChannelVersions) return;\n\tfor (const name in processes) {\n\t\tif (!Object.prototype.hasOwnProperty.call(processes, name)) continue;\n\t\tyield name;\n\t}\n}\n/**\n* Prepare the set of tasks that will make up the next Pregel step.\n* This is the union of all PUSH tasks (Sends) and PULL tasks (nodes triggered\n* by edges).\n*/\nfunction _prepareNextTasks(checkpoint, pendingWrites, processes, channels, config, forExecution, extra) {\n\tconst tasks = {};\n\tconst tasksChannel = channels[TASKS];\n\tif (tasksChannel?.isAvailable()) {\n\t\tconst len = tasksChannel.get().length;\n\t\tfor (let i = 0; i < len; i += 1) {\n\t\t\tconst task = _prepareSingleTask([PUSH, i], checkpoint, pendingWrites, processes, channels, config, forExecution, extra);\n\t\t\tif (task !== void 0) tasks[task.id] = task;\n\t\t}\n\t}\n\tfor (const name of candidateNodes(checkpoint, processes, extra)) {\n\t\tconst task = _prepareSingleTask([PULL, name], checkpoint, pendingWrites, processes, channels, config, forExecution, extra);\n\t\tif (task !== void 0) tasks[task.id] = task;\n\t}\n\treturn tasks;\n}\n/**\n* Prepares a single task for the next Pregel step, given a task path, which\n* uniquely identifies a PUSH or PULL task within the graph.\n*/\nfunction _prepareSingleTask(taskPath, checkpoint, pendingWrites, processes, channels, config, forExecution, extra) {\n\tconst { step, checkpointer, manager } = extra;\n\tconst configurable = config.configurable ?? {};\n\tconst parentNamespace = configurable.checkpoint_ns ?? \"\";\n\tif (taskPath[0] === PUSH && isCall(taskPath[taskPath.length - 1])) {\n\t\tconst call = taskPath[taskPath.length - 1];\n\t\tconst proc = getRunnableForFunc(call.name, call.func);\n\t\tconst triggers = [PUSH];\n\t\tconst checkpointNamespace = parentNamespace === \"\" ? call.name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${call.name}`;\n\t\tconst id = uuid5(JSON.stringify([\n\t\t\tcheckpointNamespace,\n\t\t\tstep.toString(),\n\t\t\tcall.name,\n\t\t\tPUSH,\n\t\t\ttaskPath[1],\n\t\t\ttaskPath[2]\n\t\t]), checkpoint.id);\n\t\tconst taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${id}`;\n\t\tconst outputTaskPath = [...taskPath.slice(0, 3), true];\n\t\tconst metadata = {\n\t\t\tlanggraph_step: step,\n\t\t\tlanggraph_node: call.name,\n\t\t\tlanggraph_triggers: triggers,\n\t\t\tlanggraph_path: outputTaskPath,\n\t\t\tlanggraph_checkpoint_ns: taskCheckpointNamespace\n\t\t};\n\t\tif (forExecution) {\n\t\t\tconst writes = [];\n\t\t\tconst task = {\n\t\t\t\tname: call.name,\n\t\t\t\tinput: call.input,\n\t\t\t\tproc,\n\t\t\t\twrites,\n\t\t\t\tconfig: patchConfig(mergeConfigs(config, {\n\t\t\t\t\tmetadata,\n\t\t\t\t\tstore: extra.store ?? config.store\n\t\t\t\t}), {\n\t\t\t\t\trunName: call.name,\n\t\t\t\t\tcallbacks: manager?.getChild(`graph:step:${step}`),\n\t\t\t\t\tconfigurable: {\n\t\t\t\t\t\t[CONFIG_KEY_TASK_ID]: id,\n\t\t\t\t\t\t[CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => writes.push(...items), processes, writes_),\n\t\t\t\t\t\t[CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {\n\t\t\t\t\t\t\tname: call.name,\n\t\t\t\t\t\t\twrites,\n\t\t\t\t\t\t\ttriggers,\n\t\t\t\t\t\t\tpath: outputTaskPath\n\t\t\t\t\t\t}, select_, fresh_),\n\t\t\t\t\t\t[CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],\n\t\t\t\t\t\t[CONFIG_KEY_CHECKPOINT_MAP]: {\n\t\t\t\t\t\t\t...configurable[CONFIG_KEY_CHECKPOINT_MAP],\n\t\t\t\t\t\t\t[parentNamespace]: checkpoint.id\n\t\t\t\t\t\t},\n\t\t\t\t\t\t[CONFIG_KEY_SCRATCHPAD]: _scratchpad({\n\t\t\t\t\t\t\tpendingWrites: pendingWrites ?? [],\n\t\t\t\t\t\t\ttaskId: id,\n\t\t\t\t\t\t\tcurrentTaskInput: call.input,\n\t\t\t\t\t\t\tresumeMap: config.configurable?.[CONFIG_KEY_RESUME_MAP],\n\t\t\t\t\t\t\tnamespaceHash: XXH3(taskCheckpointNamespace)\n\t\t\t\t\t\t}),\n\t\t\t\t\t\t[CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],\n\t\t\t\t\t\tcheckpoint_id: void 0,\n\t\t\t\t\t\tcheckpoint_ns: taskCheckpointNamespace\n\t\t\t\t\t}\n\t\t\t\t}),\n\t\t\t\ttriggers,\n\t\t\t\tretry_policy: call.retry,\n\t\t\t\tcache_key: call.cache ? {\n\t\t\t\t\tkey: XXH3((call.cache.keyFunc ?? JSON.stringify)([call.input])),\n\t\t\t\t\tns: [CACHE_NS_WRITES, call.name ?? \"__dynamic__\"],\n\t\t\t\t\tttl: call.cache.ttl\n\t\t\t\t} : void 0,\n\t\t\t\tid,\n\t\t\t\tpath: outputTaskPath,\n\t\t\t\twriters: []\n\t\t\t};\n\t\t\treturn task;\n\t\t} else return {\n\t\t\tid,\n\t\t\tname: call.name,\n\t\t\tinterrupts: [],\n\t\t\tpath: outputTaskPath\n\t\t};\n\t} else if (taskPath[0] === PUSH) {\n\t\tconst index = typeof taskPath[1] === \"number\" ? taskPath[1] : parseInt(taskPath[1], 10);\n\t\tif (!channels[TASKS]?.isAvailable()) return void 0;\n\t\tconst sends = channels[TASKS].get();\n\t\tif (index < 0 || index >= sends.length) return void 0;\n\t\tconst packet = _isSendInterface(sends[index]) && !_isSend(sends[index]) ? new Send(sends[index].node, sends[index].args) : sends[index];\n\t\tif (!_isSendInterface(packet)) {\n\t\t\tconsole.warn(`Ignoring invalid packet ${JSON.stringify(packet)} in pending sends.`);\n\t\t\treturn void 0;\n\t\t}\n\t\tif (!(packet.node in processes)) {\n\t\t\tconsole.warn(`Ignoring unknown node name ${packet.node} in pending sends.`);\n\t\t\treturn void 0;\n\t\t}\n\t\tconst triggers = [PUSH];\n\t\tconst checkpointNamespace = parentNamespace === \"\" ? packet.node : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${packet.node}`;\n\t\tconst taskId = uuid5(JSON.stringify([\n\t\t\tcheckpointNamespace,\n\t\t\tstep.toString(),\n\t\t\tpacket.node,\n\t\t\tPUSH,\n\t\t\tindex.toString()\n\t\t]), checkpoint.id);\n\t\tconst taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;\n\t\tlet metadata = {\n\t\t\tlanggraph_step: step,\n\t\t\tlanggraph_node: packet.node,\n\t\t\tlanggraph_triggers: triggers,\n\t\t\tlanggraph_path: taskPath.slice(0, 3),\n\t\t\tlanggraph_checkpoint_ns: taskCheckpointNamespace\n\t\t};\n\t\tif (forExecution) {\n\t\t\tconst proc = processes[packet.node];\n\t\t\tconst node = proc.getNode();\n\t\t\tif (node !== void 0) {\n\t\t\t\tif (proc.metadata !== void 0) metadata = {\n\t\t\t\t\t...metadata,\n\t\t\t\t\t...proc.metadata\n\t\t\t\t};\n\t\t\t\tconst writes = [];\n\t\t\t\treturn {\n\t\t\t\t\tname: packet.node,\n\t\t\t\t\tinput: packet.args,\n\t\t\t\t\tproc: node,\n\t\t\t\t\tsubgraphs: proc.subgraphs,\n\t\t\t\t\twrites,\n\t\t\t\t\tconfig: patchConfig(mergeConfigs(config, {\n\t\t\t\t\t\tmetadata,\n\t\t\t\t\t\ttags: proc.tags,\n\t\t\t\t\t\tstore: extra.store ?? config.store\n\t\t\t\t\t}), {\n\t\t\t\t\t\trunName: packet.node,\n\t\t\t\t\t\tcallbacks: manager?.getChild(`graph:step:${step}`),\n\t\t\t\t\t\tconfigurable: {\n\t\t\t\t\t\t\t[CONFIG_KEY_TASK_ID]: taskId,\n\t\t\t\t\t\t\t[CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => writes.push(...items), processes, writes_),\n\t\t\t\t\t\t\t[CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {\n\t\t\t\t\t\t\t\tname: packet.node,\n\t\t\t\t\t\t\t\twrites,\n\t\t\t\t\t\t\t\ttriggers,\n\t\t\t\t\t\t\t\tpath: taskPath\n\t\t\t\t\t\t\t}, select_, fresh_),\n\t\t\t\t\t\t\t[CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],\n\t\t\t\t\t\t\t[CONFIG_KEY_CHECKPOINT_MAP]: {\n\t\t\t\t\t\t\t\t...configurable[CONFIG_KEY_CHECKPOINT_MAP],\n\t\t\t\t\t\t\t\t[parentNamespace]: checkpoint.id\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t[CONFIG_KEY_SCRATCHPAD]: _scratchpad({\n\t\t\t\t\t\t\t\tpendingWrites: pendingWrites ?? [],\n\t\t\t\t\t\t\t\ttaskId,\n\t\t\t\t\t\t\t\tcurrentTaskInput: packet.args,\n\t\t\t\t\t\t\t\tresumeMap: config.configurable?.[CONFIG_KEY_RESUME_MAP],\n\t\t\t\t\t\t\t\tnamespaceHash: XXH3(taskCheckpointNamespace)\n\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t[CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],\n\t\t\t\t\t\t\tcheckpoint_id: void 0,\n\t\t\t\t\t\t\tcheckpoint_ns: taskCheckpointNamespace\n\t\t\t\t\t\t}\n\t\t\t\t\t}),\n\t\t\t\t\ttriggers,\n\t\t\t\t\tretry_policy: proc.retryPolicy,\n\t\t\t\t\tcache_key: proc.cachePolicy ? {\n\t\t\t\t\t\tkey: XXH3((proc.cachePolicy.keyFunc ?? JSON.stringify)([packet.args])),\n\t\t\t\t\t\tns: [\n\t\t\t\t\t\t\tCACHE_NS_WRITES,\n\t\t\t\t\t\t\tproc.name ?? \"__dynamic__\",\n\t\t\t\t\t\t\tpacket.node\n\t\t\t\t\t\t],\n\t\t\t\t\t\tttl: proc.cachePolicy.ttl\n\t\t\t\t\t} : void 0,\n\t\t\t\t\tid: taskId,\n\t\t\t\t\tpath: taskPath,\n\t\t\t\t\twriters: proc.getWriters()\n\t\t\t\t};\n\t\t\t}\n\t\t} else return {\n\t\t\tid: taskId,\n\t\t\tname: packet.node,\n\t\t\tinterrupts: [],\n\t\t\tpath: taskPath\n\t\t};\n\t} else if (taskPath[0] === PULL) {\n\t\tconst name = taskPath[1].toString();\n\t\tconst proc = processes[name];\n\t\tif (proc === void 0) return void 0;\n\t\tif (pendingWrites?.length) {\n\t\t\tconst checkpointNamespace = parentNamespace === \"\" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;\n\t\t\tconst taskId = uuid5(JSON.stringify([\n\t\t\t\tcheckpointNamespace,\n\t\t\t\tstep.toString(),\n\t\t\t\tname,\n\t\t\t\tPULL,\n\t\t\t\tname\n\t\t\t]), checkpoint.id);\n\t\t\tconst hasSuccessfulWrites = pendingWrites.some((w) => w[0] === taskId && w[1] !== ERROR);\n\t\t\tif (hasSuccessfulWrites) return void 0;\n\t\t}\n\t\tconst nullVersion = getNullChannelVersion(checkpoint.channel_versions);\n\t\tif (nullVersion === void 0) return void 0;\n\t\tconst seen = checkpoint.versions_seen[name] ?? {};\n\t\tconst trigger = proc.triggers.find((chan) => {\n\t\t\tif (!channels[chan].isAvailable()) return false;\n\t\t\treturn (checkpoint.channel_versions[chan] ?? nullVersion) > (seen[chan] ?? nullVersion);\n\t\t});\n\t\tif (trigger !== void 0) {\n\t\t\tconst val = _procInput(proc, channels, forExecution);\n\t\t\tif (val === void 0) return void 0;\n\t\t\tconst checkpointNamespace = parentNamespace === \"\" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;\n\t\t\tconst taskId = uuid5(JSON.stringify([\n\t\t\t\tcheckpointNamespace,\n\t\t\t\tstep.toString(),\n\t\t\t\tname,\n\t\t\t\tPULL,\n\t\t\t\t[trigger]\n\t\t\t]), checkpoint.id);\n\t\t\tconst taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;\n\t\t\tlet metadata = {\n\t\t\t\tlanggraph_step: step,\n\t\t\t\tlanggraph_node: name,\n\t\t\t\tlanggraph_triggers: [trigger],\n\t\t\t\tlanggraph_path: taskPath,\n\t\t\t\tlanggraph_checkpoint_ns: taskCheckpointNamespace\n\t\t\t};\n\t\t\tif (forExecution) {\n\t\t\t\tconst node = proc.getNode();\n\t\t\t\tif (node !== void 0) {\n\t\t\t\t\tif (proc.metadata !== void 0) metadata = {\n\t\t\t\t\t\t...metadata,\n\t\t\t\t\t\t...proc.metadata\n\t\t\t\t\t};\n\t\t\t\t\tconst writes = [];\n\t\t\t\t\treturn {\n\t\t\t\t\t\tname,\n\t\t\t\t\t\tinput: val,\n\t\t\t\t\t\tproc: node,\n\t\t\t\t\t\tsubgraphs: proc.subgraphs,\n\t\t\t\t\t\twrites,\n\t\t\t\t\t\tconfig: patchConfig(mergeConfigs(config, {\n\t\t\t\t\t\t\tmetadata,\n\t\t\t\t\t\t\ttags: proc.tags,\n\t\t\t\t\t\t\tstore: extra.store ?? config.store\n\t\t\t\t\t\t}), {\n\t\t\t\t\t\t\trunName: name,\n\t\t\t\t\t\t\tcallbacks: manager?.getChild(`graph:step:${step}`),\n\t\t\t\t\t\t\tconfigurable: {\n\t\t\t\t\t\t\t\t[CONFIG_KEY_TASK_ID]: taskId,\n\t\t\t\t\t\t\t\t[CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => {\n\t\t\t\t\t\t\t\t\twrites.push(...items);\n\t\t\t\t\t\t\t\t}, processes, writes_),\n\t\t\t\t\t\t\t\t[CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {\n\t\t\t\t\t\t\t\t\tname,\n\t\t\t\t\t\t\t\t\twrites,\n\t\t\t\t\t\t\t\t\ttriggers: [trigger],\n\t\t\t\t\t\t\t\t\tpath: taskPath\n\t\t\t\t\t\t\t\t}, select_, fresh_),\n\t\t\t\t\t\t\t\t[CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],\n\t\t\t\t\t\t\t\t[CONFIG_KEY_CHECKPOINT_MAP]: {\n\t\t\t\t\t\t\t\t\t...configurable[CONFIG_KEY_CHECKPOINT_MAP],\n\t\t\t\t\t\t\t\t\t[parentNamespace]: checkpoint.id\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t[CONFIG_KEY_SCRATCHPAD]: _scratchpad({\n\t\t\t\t\t\t\t\t\tpendingWrites: pendingWrites ?? [],\n\t\t\t\t\t\t\t\t\ttaskId,\n\t\t\t\t\t\t\t\t\tcurrentTaskInput: val,\n\t\t\t\t\t\t\t\t\tresumeMap: config.configurable?.[CONFIG_KEY_RESUME_MAP],\n\t\t\t\t\t\t\t\t\tnamespaceHash: XXH3(taskCheckpointNamespace)\n\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t\t[CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],\n\t\t\t\t\t\t\t\tcheckpoint_id: void 0,\n\t\t\t\t\t\t\t\tcheckpoint_ns: taskCheckpointNamespace\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}),\n\t\t\t\t\t\ttriggers: [trigger],\n\t\t\t\t\t\tretry_policy: proc.retryPolicy,\n\t\t\t\t\t\tcache_key: proc.cachePolicy ? {\n\t\t\t\t\t\t\tkey: XXH3((proc.cachePolicy.keyFunc ?? JSON.stringify)([val])),\n\t\t\t\t\t\t\tns: [\n\t\t\t\t\t\t\t\tCACHE_NS_WRITES,\n\t\t\t\t\t\t\t\tproc.name ?? \"__dynamic__\",\n\t\t\t\t\t\t\t\tname\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\tttl: proc.cachePolicy.ttl\n\t\t\t\t\t\t} : void 0,\n\t\t\t\t\t\tid: taskId,\n\t\t\t\t\t\tpath: taskPath,\n\t\t\t\t\t\twriters: proc.getWriters()\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t} else return {\n\t\t\t\tid: taskId,\n\t\t\t\tname,\n\t\t\t\tinterrupts: [],\n\t\t\t\tpath: taskPath\n\t\t\t};\n\t\t}\n\t}\n\treturn void 0;\n}\n/**\n*  Function injected under CONFIG_KEY_READ in task config, to read current state.\n*  Used by conditional edges to read a copy of the state with reflecting the writes\n*  from that node only.\n*\n* @internal\n*/\nfunction _procInput(proc, channels, forExecution) {\n\tlet val;\n\tif (typeof proc.channels === \"object\" && !Array.isArray(proc.channels)) {\n\t\tval = {};\n\t\tfor (const [k, chan] of Object.entries(proc.channels)) if (proc.triggers.includes(chan)) try {\n\t\t\tval[k] = readChannel(channels, chan, false);\n\t\t} catch (e) {\n\t\t\tif (e.name === EmptyChannelError.unminifiable_name) return void 0;\n\t\t\telse throw e;\n\t\t}\n\t\telse if (chan in channels) try {\n\t\t\tval[k] = readChannel(channels, chan, false);\n\t\t} catch (e) {\n\t\t\tif (e.name === EmptyChannelError.unminifiable_name) continue;\n\t\t\telse throw e;\n\t\t}\n\t} else if (Array.isArray(proc.channels)) {\n\t\tlet successfulRead = false;\n\t\tfor (const chan of proc.channels) try {\n\t\t\tval = readChannel(channels, chan, false);\n\t\t\tsuccessfulRead = true;\n\t\t\tbreak;\n\t\t} catch (e) {\n\t\t\tif (e.name === EmptyChannelError.unminifiable_name) continue;\n\t\t\telse throw e;\n\t\t}\n\t\tif (!successfulRead) return void 0;\n\t} else throw new Error(`Invalid channels type, expected list or dict, got ${proc.channels}`);\n\tif (forExecution && proc.mapper !== void 0) val = proc.mapper(val);\n\treturn val;\n}\nfunction _scratchpad({ pendingWrites, taskId, currentTaskInput, resumeMap, namespaceHash }) {\n\tconst nullResume = pendingWrites.find(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME)?.[2];\n\tconst resume = (() => {\n\t\tconst result = pendingWrites.filter(([writeTaskId, chan]) => writeTaskId === taskId && chan === RESUME).flatMap(([_writeTaskId, _chan, resume$1]) => resume$1);\n\t\tif (resumeMap != null && namespaceHash in resumeMap) {\n\t\t\tconst mappedResume = resumeMap[namespaceHash];\n\t\t\tresult.push(mappedResume);\n\t\t}\n\t\treturn result;\n\t})();\n\tconst scratchpad = {\n\t\tcallCounter: 0,\n\t\tinterruptCounter: -1,\n\t\tresume,\n\t\tnullResume,\n\t\tsubgraphCounter: 0,\n\t\tcurrentTaskInput,\n\t\tconsumeNullResume: () => {\n\t\t\tif (scratchpad.nullResume) {\n\t\t\t\tdelete scratchpad.nullResume;\n\t\t\t\tpendingWrites.splice(pendingWrites.findIndex(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME), 1);\n\t\t\t\treturn nullResume;\n\t\t\t}\n\t\t\treturn void 0;\n\t\t}\n\t};\n\treturn scratchpad;\n}\n\n//#endregion\nexport { _applyWrites, _localRead, _prepareNextTasks, _prepareSingleTask, increment, shouldInterrupt };\n//# sourceMappingURL=algo.js.map","import { ERROR, INTERRUPT, RETURN, TAG_HIDDEN } from \"../constants.js\";\nimport { readChannels } from \"./io.js\";\nimport { findSubgraphPregel } from \"./utils/subgraph.js\";\n\n//#region src/pregel/debug.ts\nconst COLORS_MAP = {\n\tblue: {\n\t\tstart: \"\\x1B[34m\",\n\t\tend: \"\\x1B[0m\"\n\t},\n\tgreen: {\n\t\tstart: \"\\x1B[32m\",\n\t\tend: \"\\x1B[0m\"\n\t},\n\tyellow: {\n\t\tstart: \"\\x1B[33;1m\",\n\t\tend: \"\\x1B[0m\"\n\t}\n};\n/**\n* Wrap some text in a color for printing to the console.\n*/\nconst wrap = (color, text) => `${color.start}${text}${color.end}`;\nfunction* mapDebugTasks(tasks) {\n\tfor (const { id, name, input, config, triggers, writes } of tasks) {\n\t\tif (config?.tags?.includes(TAG_HIDDEN)) continue;\n\t\tconst interrupts = writes.filter(([writeId, n]) => {\n\t\t\treturn writeId === id && n === INTERRUPT;\n\t\t}).map(([, v]) => {\n\t\t\treturn v;\n\t\t});\n\t\tyield {\n\t\t\tid,\n\t\t\tname,\n\t\t\tinput,\n\t\t\ttriggers,\n\t\t\tinterrupts\n\t\t};\n\t}\n}\nfunction isMultipleChannelWrite(value) {\n\tif (typeof value !== \"object\" || value === null) return false;\n\treturn \"$writes\" in value && Array.isArray(value.$writes);\n}\nfunction mapTaskResultWrites(writes) {\n\tconst result = {};\n\tfor (const [channel, value] of writes) {\n\t\tconst strChannel = String(channel);\n\t\tif (strChannel in result) {\n\t\t\tconst channelWrites = isMultipleChannelWrite(result[strChannel]) ? result[strChannel].$writes : [result[strChannel]];\n\t\t\tchannelWrites.push(value);\n\t\t\tresult[strChannel] = { $writes: channelWrites };\n\t\t} else result[strChannel] = value;\n\t}\n\treturn result;\n}\nfunction* mapDebugTaskResults(tasks, streamChannels) {\n\tfor (const [{ id, name, config }, writes] of tasks) {\n\t\tif (config?.tags?.includes(TAG_HIDDEN)) continue;\n\t\tyield {\n\t\t\tid,\n\t\t\tname,\n\t\t\tresult: mapTaskResultWrites(writes.filter(([channel]) => {\n\t\t\t\treturn Array.isArray(streamChannels) ? streamChannels.includes(channel) : channel === streamChannels;\n\t\t\t})),\n\t\t\tinterrupts: writes.filter((w) => w[0] === INTERRUPT).map((w) => w[1])\n\t\t};\n\t}\n}\nfunction* mapDebugCheckpoint(config, channels, streamChannels, metadata, tasks, pendingWrites, parentConfig, outputKeys) {\n\tfunction formatConfig(config$1) {\n\t\tconst pyConfig = {};\n\t\tif (config$1.callbacks != null) pyConfig.callbacks = config$1.callbacks;\n\t\tif (config$1.configurable != null) pyConfig.configurable = config$1.configurable;\n\t\tif (config$1.maxConcurrency != null) pyConfig.max_concurrency = config$1.maxConcurrency;\n\t\tif (config$1.metadata != null) pyConfig.metadata = config$1.metadata;\n\t\tif (config$1.recursionLimit != null) pyConfig.recursion_limit = config$1.recursionLimit;\n\t\tif (config$1.runId != null) pyConfig.run_id = config$1.runId;\n\t\tif (config$1.runName != null) pyConfig.run_name = config$1.runName;\n\t\tif (config$1.tags != null) pyConfig.tags = config$1.tags;\n\t\treturn pyConfig;\n\t}\n\tconst parentNs = config.configurable?.checkpoint_ns;\n\tconst taskStates = {};\n\tfor (const task of tasks) {\n\t\tconst candidates = task.subgraphs?.length ? task.subgraphs : [task.proc];\n\t\tif (!candidates.find(findSubgraphPregel)) continue;\n\t\tlet taskNs = `${task.name}:${task.id}`;\n\t\tif (parentNs) taskNs = `${parentNs}|${taskNs}`;\n\t\ttaskStates[task.id] = { configurable: {\n\t\t\tthread_id: config.configurable?.thread_id,\n\t\t\tcheckpoint_ns: taskNs\n\t\t} };\n\t}\n\tyield {\n\t\tconfig: formatConfig(config),\n\t\tvalues: readChannels(channels, streamChannels),\n\t\tmetadata,\n\t\tnext: tasks.map((task) => task.name),\n\t\ttasks: tasksWithWrites(tasks, pendingWrites, taskStates, outputKeys),\n\t\tparentConfig: parentConfig ? formatConfig(parentConfig) : void 0\n\t};\n}\nfunction tasksWithWrites(tasks, pendingWrites, states, outputKeys) {\n\treturn tasks.map((task) => {\n\t\tconst error = pendingWrites.find(([id, n]) => id === task.id && n === ERROR)?.[2];\n\t\tconst interrupts = pendingWrites.filter(([id, n]) => id === task.id && n === INTERRUPT).map(([, , v]) => v);\n\t\tconst result = (() => {\n\t\t\tif (error || interrupts.length || !pendingWrites.length) return void 0;\n\t\t\tconst idx = pendingWrites.findIndex(([tid, n]) => tid === task.id && n === RETURN);\n\t\t\tif (idx >= 0) return pendingWrites[idx][2];\n\t\t\tif (typeof outputKeys === \"string\") return pendingWrites.find(([tid, n]) => tid === task.id && n === outputKeys)?.[2];\n\t\t\tif (Array.isArray(outputKeys)) {\n\t\t\t\tconst results = pendingWrites.filter(([tid, n]) => tid === task.id && outputKeys.includes(n)).map(([, n, v]) => [n, v]);\n\t\t\t\tif (!results.length) return void 0;\n\t\t\t\treturn mapTaskResultWrites(results);\n\t\t\t}\n\t\t\treturn void 0;\n\t\t})();\n\t\tif (error) return {\n\t\t\tid: task.id,\n\t\t\tname: task.name,\n\t\t\tpath: task.path,\n\t\t\terror,\n\t\t\tinterrupts,\n\t\t\tresult\n\t\t};\n\t\tconst taskState = states?.[task.id];\n\t\treturn {\n\t\t\tid: task.id,\n\t\t\tname: task.name,\n\t\t\tpath: task.path,\n\t\t\tinterrupts,\n\t\t\t...taskState !== void 0 ? { state: taskState } : {},\n\t\t\tresult\n\t\t};\n\t});\n}\nfunction printStepCheckpoint(step, channels, whitelist) {\n\tconsole.log([\n\t\t`${wrap(COLORS_MAP.blue, `[${step}:checkpoint]`)}`,\n\t\t`\\x1b[1m State at the end of step ${step}:\\x1b[0m\\n`,\n\t\tJSON.stringify(readChannels(channels, whitelist), null, 2)\n\t].join(\"\"));\n}\nfunction printStepTasks(step, nextTasks) {\n\tconst nTasks = nextTasks.length;\n\tconsole.log([\n\t\t`${wrap(COLORS_MAP.blue, `[${step}:tasks]`)}`,\n\t\t`\\x1b[1m Starting step ${step} with ${nTasks} task${nTasks === 1 ? \"\" : \"s\"}:\\x1b[0m\\n`,\n\t\tnextTasks.map((task) => `- ${wrap(COLORS_MAP.green, String(task.name))} -> ${JSON.stringify(task.input, null, 2)}`).join(\"\\n\")\n\t].join(\"\"));\n}\nfunction printStepWrites(step, writes, whitelist) {\n\tconst byChannel = {};\n\tfor (const [channel, value] of writes) if (whitelist.includes(channel)) {\n\t\tif (!byChannel[channel]) byChannel[channel] = [];\n\t\tbyChannel[channel].push(value);\n\t}\n\tconsole.log([\n\t\t`${wrap(COLORS_MAP.blue, `[${step}:writes]`)}`,\n\t\t`\\x1b[1m Finished step ${step} with writes to ${Object.keys(byChannel).length} channel${Object.keys(byChannel).length !== 1 ? \"s\" : \"\"}:\\x1b[0m\\n`,\n\t\tObject.entries(byChannel).map(([name, vals]) => `- ${wrap(COLORS_MAP.yellow, name)} -> ${vals.map((v) => JSON.stringify(v)).join(\", \")}`).join(\"\\n\")\n\t].join(\"\"));\n}\n\n//#endregion\nexport { mapDebugCheckpoint, mapDebugTaskResults, mapDebugTasks, printStepCheckpoint, printStepTasks, printStepWrites, tasksWithWrites };\n//# sourceMappingURL=debug.js.map","import { IterableReadableStream } from \"@langchain/core/utils/stream\";\n\n//#region src/pregel/stream.ts\n/**\n* A wrapper around an IterableReadableStream that allows for aborting the stream when\n* {@link cancel} is called.\n*/\nvar IterableReadableStreamWithAbortSignal = class extends IterableReadableStream {\n\t_abortController;\n\t_innerReader;\n\t/**\n\t* @param readableStream - The stream to wrap.\n\t* @param abortController - The abort controller to use. Optional. One will be created if not provided.\n\t*/\n\tconstructor(readableStream, abortController) {\n\t\tconst reader = readableStream.getReader();\n\t\tconst ac = abortController ?? new AbortController();\n\t\tsuper({ start(controller) {\n\t\t\treturn pump();\n\t\t\tfunction pump() {\n\t\t\t\treturn reader.read().then(({ done, value }) => {\n\t\t\t\t\tif (done) {\n\t\t\t\t\t\tcontroller.close();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tcontroller.enqueue(value);\n\t\t\t\t\treturn pump();\n\t\t\t\t});\n\t\t\t}\n\t\t} });\n\t\tthis._abortController = ac;\n\t\tthis._innerReader = reader;\n\t}\n\t/**\n\t* Aborts the stream, abandoning any pending operations in progress. Calling this triggers an\n\t* {@link AbortSignal} that is propagated to the tasks that are producing the data for this stream.\n\t* @param reason - The reason for aborting the stream. Optional.\n\t*/\n\tasync cancel(reason) {\n\t\tthis._abortController.abort(reason);\n\t\tthis._innerReader.releaseLock();\n\t}\n\t/**\n\t* The {@link AbortSignal} for the stream. Aborted when {@link cancel} is called.\n\t*/\n\tget signal() {\n\t\treturn this._abortController.signal;\n\t}\n};\nvar IterableReadableWritableStream = class extends IterableReadableStream {\n\tmodes;\n\tcontroller;\n\tpassthroughFn;\n\t_closed = false;\n\tget closed() {\n\t\treturn this._closed;\n\t}\n\tconstructor(params) {\n\t\tlet streamControllerPromiseResolver;\n\t\tconst streamControllerPromise = new Promise((resolve) => {\n\t\t\tstreamControllerPromiseResolver = resolve;\n\t\t});\n\t\tsuper({ start: (controller) => {\n\t\t\tstreamControllerPromiseResolver(controller);\n\t\t} });\n\t\tstreamControllerPromise.then((controller) => {\n\t\t\tthis.controller = controller;\n\t\t});\n\t\tthis.passthroughFn = params.passthroughFn;\n\t\tthis.modes = params.modes;\n\t}\n\tpush(chunk) {\n\t\tthis.passthroughFn?.(chunk);\n\t\tthis.controller.enqueue(chunk);\n\t}\n\tclose() {\n\t\ttry {\n\t\t\tthis.controller.close();\n\t\t} catch (e) {} finally {\n\t\t\tthis._closed = true;\n\t\t}\n\t}\n\terror(e) {\n\t\tthis.controller.error(e);\n\t}\n};\nfunction _stringifyAsDict(obj) {\n\treturn JSON.stringify(obj, function(key, value) {\n\t\tconst rawValue = this[key];\n\t\tif (rawValue != null && typeof rawValue === \"object\" && \"toDict\" in rawValue && typeof rawValue.toDict === \"function\") {\n\t\t\tconst { type, data } = rawValue.toDict();\n\t\t\treturn {\n\t\t\t\t...data,\n\t\t\t\ttype\n\t\t\t};\n\t\t}\n\t\treturn value;\n\t});\n}\nfunction _serializeError(error) {\n\tif (error instanceof Error) return {\n\t\terror: error.name,\n\t\tmessage: error.message\n\t};\n\treturn {\n\t\terror: \"Error\",\n\t\tmessage: JSON.stringify(error)\n\t};\n}\nfunction _isRunnableConfig(config) {\n\tif (typeof config !== \"object\" || config == null) return false;\n\treturn \"configurable\" in config && typeof config.configurable === \"object\" && config.configurable != null;\n}\nfunction _extractCheckpointFromConfig(config) {\n\tif (!_isRunnableConfig(config) || !config.configurable.thread_id) return null;\n\treturn {\n\t\tthread_id: config.configurable.thread_id,\n\t\tcheckpoint_ns: config.configurable.checkpoint_ns || \"\",\n\t\tcheckpoint_id: config.configurable.checkpoint_id || null,\n\t\tcheckpoint_map: config.configurable.checkpoint_map || null\n\t};\n}\nfunction _serializeConfig(config) {\n\tif (_isRunnableConfig(config)) {\n\t\tconst configurable = Object.fromEntries(Object.entries(config.configurable).filter(([key]) => !key.startsWith(\"__\")));\n\t\tconst newConfig = {\n\t\t\t...config,\n\t\t\tconfigurable\n\t\t};\n\t\tdelete newConfig.callbacks;\n\t\treturn newConfig;\n\t}\n\treturn config;\n}\nfunction _serializeCheckpoint(payload) {\n\tconst result = {\n\t\t...payload,\n\t\tcheckpoint: _extractCheckpointFromConfig(payload.config),\n\t\tparent_checkpoint: _extractCheckpointFromConfig(payload.parentConfig),\n\t\tconfig: _serializeConfig(payload.config),\n\t\tparent_config: _serializeConfig(payload.parentConfig),\n\t\ttasks: payload.tasks.map((task) => {\n\t\t\tif (_isRunnableConfig(task.state)) {\n\t\t\t\tconst checkpoint = _extractCheckpointFromConfig(task.state);\n\t\t\t\tif (checkpoint != null) {\n\t\t\t\t\tconst cloneTask = {\n\t\t\t\t\t\t...task,\n\t\t\t\t\t\tcheckpoint\n\t\t\t\t\t};\n\t\t\t\t\tdelete cloneTask.state;\n\t\t\t\t\treturn cloneTask;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn task;\n\t\t})\n\t};\n\tdelete result.parentConfig;\n\treturn result;\n}\nfunction toEventStream(stream) {\n\tconst encoder = new TextEncoder();\n\treturn new ReadableStream({ async start(controller) {\n\t\tconst enqueueChunk = (sse) => {\n\t\t\tcontroller.enqueue(encoder.encode(`event: ${sse.event}\\ndata: ${_stringifyAsDict(sse.data)}\\n\\n`));\n\t\t};\n\t\ttry {\n\t\t\tfor await (const payload of stream) {\n\t\t\t\tconst [ns, mode, chunk] = payload;\n\t\t\t\tlet data = chunk;\n\t\t\t\tif (mode === \"debug\") {\n\t\t\t\t\tconst debugChunk = chunk;\n\t\t\t\t\tif (debugChunk.type === \"checkpoint\") data = {\n\t\t\t\t\t\t...debugChunk,\n\t\t\t\t\t\tpayload: _serializeCheckpoint(debugChunk.payload)\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t\tif (mode === \"checkpoints\") data = _serializeCheckpoint(chunk);\n\t\t\t\tconst event = ns?.length ? `${mode}|${ns.join(\"|\")}` : mode;\n\t\t\t\tenqueueChunk({\n\t\t\t\t\tevent,\n\t\t\t\t\tdata\n\t\t\t\t});\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tenqueueChunk({\n\t\t\t\tevent: \"error\",\n\t\t\t\tdata: _serializeError(error)\n\t\t\t});\n\t\t}\n\t\tcontroller.close();\n\t} });\n}\n\n//#endregion\nexport { IterableReadableStreamWithAbortSignal, IterableReadableWritableStream, toEventStream };\n//# sourceMappingURL=stream.js.map","import { EmptyInputError, GraphInterrupt, isGraphInterrupt } from \"../errors.js\";\nimport { createCheckpoint, emptyChannels } from \"../channels/base.js\";\nimport { CHECKPOINT_NAMESPACE_END, CHECKPOINT_NAMESPACE_SEPARATOR, CONFIG_KEY_CHECKPOINT_ID, CONFIG_KEY_CHECKPOINT_MAP, CONFIG_KEY_CHECKPOINT_NS, CONFIG_KEY_READ, CONFIG_KEY_RESUME_MAP, CONFIG_KEY_RESUMING, CONFIG_KEY_SCRATCHPAD, CONFIG_KEY_STREAM, ERROR, INPUT, INTERRUPT, NULL_TASK_ID, PUSH, RESUME, START, TAG_HIDDEN, isCommand } from \"../constants.js\";\nimport { gatherIterator, gatherIteratorSync, prefixGenerator } from \"../utils.js\";\nimport { isXXH3 } from \"../hash.js\";\nimport { mapCommand, mapInput, mapOutputUpdates, mapOutputValues, readChannels } from \"./io.js\";\nimport { getNewChannelVersions, patchConfigurable } from \"./utils/index.js\";\nimport { _applyWrites, _prepareNextTasks, _prepareSingleTask, increment, shouldInterrupt } from \"./algo.js\";\nimport { mapDebugCheckpoint, mapDebugTaskResults, mapDebugTasks, printStepTasks } from \"./debug.js\";\nimport { IterableReadableWritableStream } from \"./stream.js\";\nimport { AsyncBatchedStore, BaseCache, WRITES_IDX_MAP, copyCheckpoint, emptyCheckpoint } from \"@langchain/langgraph-checkpoint\";\n\n//#region src/pregel/loop.ts\nconst INPUT_DONE = Symbol.for(\"INPUT_DONE\");\nconst INPUT_RESUMING = Symbol.for(\"INPUT_RESUMING\");\nconst DEFAULT_LOOP_LIMIT = 25;\nfunction createDuplexStream(...streams) {\n\treturn new IterableReadableWritableStream({\n\t\tpassthroughFn: (value) => {\n\t\t\tfor (const stream of streams) if (stream.modes.has(value[1])) stream.push(value);\n\t\t},\n\t\tmodes: new Set(streams.flatMap((s) => Array.from(s.modes)))\n\t});\n}\nvar AsyncBatchedCache = class extends BaseCache {\n\tcache;\n\tqueue = Promise.resolve();\n\tconstructor(cache) {\n\t\tsuper();\n\t\tthis.cache = cache;\n\t}\n\tasync get(keys) {\n\t\treturn this.enqueueOperation(\"get\", keys);\n\t}\n\tasync set(pairs) {\n\t\treturn this.enqueueOperation(\"set\", pairs);\n\t}\n\tasync clear(namespaces) {\n\t\treturn this.enqueueOperation(\"clear\", namespaces);\n\t}\n\tasync stop() {\n\t\tawait this.queue;\n\t}\n\tenqueueOperation(type, ...args) {\n\t\tconst newPromise = this.queue.then(() => {\n\t\t\treturn this.cache[type](...args);\n\t\t});\n\t\tthis.queue = newPromise.then(() => void 0, () => void 0);\n\t\treturn newPromise;\n\t}\n};\nvar PregelLoop = class PregelLoop {\n\tinput;\n\toutput;\n\tconfig;\n\tcheckpointer;\n\tcheckpointerGetNextVersion;\n\tchannels;\n\tcheckpoint;\n\tcheckpointIdSaved;\n\tcheckpointConfig;\n\tcheckpointMetadata;\n\tcheckpointNamespace;\n\tcheckpointPendingWrites = [];\n\tcheckpointPreviousVersions;\n\tstep;\n\tstop;\n\tdurability;\n\toutputKeys;\n\tstreamKeys;\n\tnodes;\n\tskipDoneTasks;\n\tprevCheckpointConfig;\n\tupdatedChannels;\n\tstatus = \"pending\";\n\ttasks = {};\n\tstream;\n\tcheckpointerPromises = [];\n\tisNested;\n\t_checkpointerChainedPromise = Promise.resolve();\n\tstore;\n\tcache;\n\tmanager;\n\tinterruptAfter;\n\tinterruptBefore;\n\ttoInterrupt = [];\n\tdebug = false;\n\ttriggerToNodes;\n\tget isResuming() {\n\t\tlet hasChannelVersions = false;\n\t\tif (START in this.checkpoint.channel_versions) hasChannelVersions = true;\n\t\telse for (const chan in this.checkpoint.channel_versions) if (Object.prototype.hasOwnProperty.call(this.checkpoint.channel_versions, chan)) {\n\t\t\thasChannelVersions = true;\n\t\t\tbreak;\n\t\t}\n\t\tconst configHasResumingFlag = this.config.configurable?.[CONFIG_KEY_RESUMING] !== void 0;\n\t\tconst configIsResuming = configHasResumingFlag && this.config.configurable?.[CONFIG_KEY_RESUMING];\n\t\tconst inputIsNullOrUndefined = this.input === null || this.input === void 0;\n\t\tconst inputIsCommandResuming = isCommand(this.input) && this.input.resume != null;\n\t\tconst inputIsResuming = this.input === INPUT_RESUMING;\n\t\tconst runIdMatchesPrevious = !this.isNested && this.config.metadata?.run_id !== void 0 && this.checkpointMetadata?.run_id !== void 0 && this.config.metadata.run_id === this.checkpointMetadata?.run_id;\n\t\treturn hasChannelVersions && (configIsResuming || inputIsNullOrUndefined || inputIsCommandResuming || inputIsResuming || runIdMatchesPrevious);\n\t}\n\tconstructor(params) {\n\t\tthis.input = params.input;\n\t\tthis.checkpointer = params.checkpointer;\n\t\tif (this.checkpointer !== void 0) this.checkpointerGetNextVersion = this.checkpointer.getNextVersion.bind(this.checkpointer);\n\t\telse this.checkpointerGetNextVersion = increment;\n\t\tthis.checkpoint = params.checkpoint;\n\t\tthis.checkpointMetadata = params.checkpointMetadata;\n\t\tthis.checkpointPreviousVersions = params.checkpointPreviousVersions;\n\t\tthis.channels = params.channels;\n\t\tthis.checkpointPendingWrites = params.checkpointPendingWrites;\n\t\tthis.step = params.step;\n\t\tthis.stop = params.stop;\n\t\tthis.config = params.config;\n\t\tthis.checkpointConfig = params.checkpointConfig;\n\t\tthis.isNested = params.isNested;\n\t\tthis.manager = params.manager;\n\t\tthis.outputKeys = params.outputKeys;\n\t\tthis.streamKeys = params.streamKeys;\n\t\tthis.nodes = params.nodes;\n\t\tthis.skipDoneTasks = params.skipDoneTasks;\n\t\tthis.store = params.store;\n\t\tthis.cache = params.cache ? new AsyncBatchedCache(params.cache) : void 0;\n\t\tthis.stream = params.stream;\n\t\tthis.checkpointNamespace = params.checkpointNamespace;\n\t\tthis.prevCheckpointConfig = params.prevCheckpointConfig;\n\t\tthis.interruptAfter = params.interruptAfter;\n\t\tthis.interruptBefore = params.interruptBefore;\n\t\tthis.durability = params.durability;\n\t\tthis.debug = params.debug;\n\t\tthis.triggerToNodes = params.triggerToNodes;\n\t}\n\tstatic async initialize(params) {\n\t\tlet { config, stream } = params;\n\t\tif (stream !== void 0 && config.configurable?.[CONFIG_KEY_STREAM] !== void 0) stream = createDuplexStream(stream, config.configurable[CONFIG_KEY_STREAM]);\n\t\tconst skipDoneTasks = config.configurable ? !(\"checkpoint_id\" in config.configurable) : true;\n\t\tconst scratchpad = config.configurable?.[CONFIG_KEY_SCRATCHPAD];\n\t\tif (config.configurable && scratchpad) {\n\t\t\tif (scratchpad.subgraphCounter > 0) config = patchConfigurable(config, { [CONFIG_KEY_CHECKPOINT_NS]: [config.configurable[CONFIG_KEY_CHECKPOINT_NS], scratchpad.subgraphCounter.toString()].join(CHECKPOINT_NAMESPACE_SEPARATOR) });\n\t\t\tscratchpad.subgraphCounter += 1;\n\t\t}\n\t\tconst isNested = CONFIG_KEY_READ in (config.configurable ?? {});\n\t\tif (!isNested && config.configurable?.checkpoint_ns !== void 0 && config.configurable?.checkpoint_ns !== \"\") config = patchConfigurable(config, {\n\t\t\tcheckpoint_ns: \"\",\n\t\t\tcheckpoint_id: void 0\n\t\t});\n\t\tlet checkpointConfig = config;\n\t\tif (config.configurable?.[CONFIG_KEY_CHECKPOINT_MAP] !== void 0 && config.configurable?.[CONFIG_KEY_CHECKPOINT_MAP]?.[config.configurable?.checkpoint_ns]) checkpointConfig = patchConfigurable(config, { checkpoint_id: config.configurable[CONFIG_KEY_CHECKPOINT_MAP][config.configurable?.checkpoint_ns] });\n\t\tconst checkpointNamespace = config.configurable?.checkpoint_ns?.split(CHECKPOINT_NAMESPACE_SEPARATOR) ?? [];\n\t\tconst saved = await params.checkpointer?.getTuple(checkpointConfig) ?? {\n\t\t\tconfig,\n\t\t\tcheckpoint: emptyCheckpoint(),\n\t\t\tmetadata: {\n\t\t\t\tsource: \"input\",\n\t\t\t\tstep: -2,\n\t\t\t\tparents: {}\n\t\t\t},\n\t\t\tpendingWrites: []\n\t\t};\n\t\tcheckpointConfig = {\n\t\t\t...config,\n\t\t\t...saved.config,\n\t\t\tconfigurable: {\n\t\t\t\tcheckpoint_ns: \"\",\n\t\t\t\t...config.configurable,\n\t\t\t\t...saved.config.configurable\n\t\t\t}\n\t\t};\n\t\tconst prevCheckpointConfig = saved.parentConfig;\n\t\tconst checkpoint = copyCheckpoint(saved.checkpoint);\n\t\tconst checkpointMetadata = { ...saved.metadata };\n\t\tconst checkpointPendingWrites = saved.pendingWrites ?? [];\n\t\tconst channels = emptyChannels(params.channelSpecs, checkpoint);\n\t\tconst step = (checkpointMetadata.step ?? 0) + 1;\n\t\tconst stop = step + (config.recursionLimit ?? DEFAULT_LOOP_LIMIT) + 1;\n\t\tconst checkpointPreviousVersions = { ...checkpoint.channel_versions };\n\t\tconst store = params.store ? new AsyncBatchedStore(params.store) : void 0;\n\t\tif (store) await store.start();\n\t\treturn new PregelLoop({\n\t\t\tinput: params.input,\n\t\t\tconfig,\n\t\t\tcheckpointer: params.checkpointer,\n\t\t\tcheckpoint,\n\t\t\tcheckpointMetadata,\n\t\t\tcheckpointConfig,\n\t\t\tprevCheckpointConfig,\n\t\t\tcheckpointNamespace,\n\t\t\tchannels,\n\t\t\tisNested,\n\t\t\tmanager: params.manager,\n\t\t\tskipDoneTasks,\n\t\t\tstep,\n\t\t\tstop,\n\t\t\tcheckpointPreviousVersions,\n\t\t\tcheckpointPendingWrites,\n\t\t\toutputKeys: params.outputKeys ?? [],\n\t\t\tstreamKeys: params.streamKeys ?? [],\n\t\t\tnodes: params.nodes,\n\t\t\tstream,\n\t\t\tstore,\n\t\t\tcache: params.cache,\n\t\t\tinterruptAfter: params.interruptAfter,\n\t\t\tinterruptBefore: params.interruptBefore,\n\t\t\tdurability: params.durability,\n\t\t\tdebug: params.debug,\n\t\t\ttriggerToNodes: params.triggerToNodes\n\t\t});\n\t}\n\t_checkpointerPutAfterPrevious(input) {\n\t\tthis._checkpointerChainedPromise = this._checkpointerChainedPromise.then(() => {\n\t\t\treturn this.checkpointer?.put(input.config, input.checkpoint, input.metadata, input.newVersions);\n\t\t});\n\t\tthis.checkpointerPromises.push(this._checkpointerChainedPromise);\n\t}\n\t/**\n\t* Put writes for a task, to be read by the next tick.\n\t* @param taskId\n\t* @param writes\n\t*/\n\tputWrites(taskId, writes) {\n\t\tlet writesCopy = writes;\n\t\tif (writesCopy.length === 0) return;\n\t\tif (writesCopy.every(([key]) => key in WRITES_IDX_MAP)) writesCopy = Array.from(new Map(writesCopy.map((w) => [w[0], w])).values());\n\t\tthis.checkpointPendingWrites = this.checkpointPendingWrites.filter((w) => w[0] !== taskId);\n\t\tfor (const [c, v] of writesCopy) this.checkpointPendingWrites.push([\n\t\t\ttaskId,\n\t\t\tc,\n\t\t\tv\n\t\t]);\n\t\tconst config = patchConfigurable(this.checkpointConfig, {\n\t\t\t[CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? \"\",\n\t\t\t[CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id\n\t\t});\n\t\tif (this.durability !== \"exit\" && this.checkpointer != null) this.checkpointerPromises.push(this.checkpointer.putWrites(config, writesCopy, taskId));\n\t\tif (this.tasks) this._outputWrites(taskId, writesCopy);\n\t\tif (!writes.length || !this.cache || !this.tasks) return;\n\t\tconst task = this.tasks[taskId];\n\t\tif (task == null || task.cache_key == null) return;\n\t\tif (writes[0][0] === ERROR || writes[0][0] === INTERRUPT) return;\n\t\tthis.cache.set([{\n\t\t\tkey: [task.cache_key.ns, task.cache_key.key],\n\t\t\tvalue: task.writes,\n\t\t\tttl: task.cache_key.ttl\n\t\t}]);\n\t}\n\t_outputWrites(taskId, writes, cached = false) {\n\t\tconst task = this.tasks[taskId];\n\t\tif (task !== void 0) {\n\t\t\tif (task.config !== void 0 && (task.config.tags ?? []).includes(TAG_HIDDEN)) return;\n\t\t\tif (writes.length > 0) {\n\t\t\t\tif (writes[0][0] === INTERRUPT) {\n\t\t\t\t\tif (task.path?.[0] === PUSH && task.path?.at(-1) === true) return;\n\t\t\t\t\tconst interruptWrites = writes.filter((w) => w[0] === INTERRUPT).flatMap((w) => w[1]);\n\t\t\t\t\tthis._emit([[\"updates\", { [INTERRUPT]: interruptWrites }], [\"values\", { [INTERRUPT]: interruptWrites }]]);\n\t\t\t\t} else if (writes[0][0] !== ERROR) this._emit(gatherIteratorSync(prefixGenerator(mapOutputUpdates(this.outputKeys, [[task, writes]], cached), \"updates\")));\n\t\t\t}\n\t\t\tif (!cached) this._emit(gatherIteratorSync(prefixGenerator(mapDebugTaskResults([[task, writes]], this.streamKeys), \"tasks\")));\n\t\t}\n\t}\n\tasync _matchCachedWrites() {\n\t\tif (!this.cache) return [];\n\t\tconst matched = [];\n\t\tconst serializeKey = ([ns, key]) => {\n\t\t\treturn `ns:${ns.join(\",\")}|key:${key}`;\n\t\t};\n\t\tconst keys = [];\n\t\tconst keyMap = {};\n\t\tfor (const task of Object.values(this.tasks)) if (task.cache_key != null && !task.writes.length) {\n\t\t\tkeys.push([task.cache_key.ns, task.cache_key.key]);\n\t\t\tkeyMap[serializeKey([task.cache_key.ns, task.cache_key.key])] = task;\n\t\t}\n\t\tif (keys.length === 0) return [];\n\t\tconst cache = await this.cache.get(keys);\n\t\tfor (const { key, value } of cache) {\n\t\t\tconst task = keyMap[serializeKey(key)];\n\t\t\tif (task != null) {\n\t\t\t\ttask.writes.push(...value);\n\t\t\t\tmatched.push({\n\t\t\t\t\ttask,\n\t\t\t\t\tresult: value\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn matched;\n\t}\n\t/**\n\t* Execute a single iteration of the Pregel loop.\n\t* Returns true if more iterations are needed.\n\t* @param params\n\t*/\n\tasync tick(params) {\n\t\tif (this.store && !this.store.isRunning) await this.store?.start();\n\t\tconst { inputKeys = [] } = params;\n\t\tif (this.status !== \"pending\") throw new Error(`Cannot tick when status is no longer \"pending\". Current status: \"${this.status}\"`);\n\t\tif (![INPUT_DONE, INPUT_RESUMING].includes(this.input)) await this._first(inputKeys);\n\t\telse if (this.toInterrupt.length > 0) {\n\t\t\tthis.status = \"interrupt_before\";\n\t\t\tthrow new GraphInterrupt();\n\t\t} else if (Object.values(this.tasks).every((task) => task.writes.length > 0)) {\n\t\t\tconst writes = Object.values(this.tasks).flatMap((t) => t.writes);\n\t\t\tthis.updatedChannels = _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);\n\t\t\tconst valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, writes, this.channels), \"values\"));\n\t\t\tthis._emit(valuesOutput);\n\t\t\tthis.checkpointPendingWrites = [];\n\t\t\tawait this._putCheckpoint({ source: \"loop\" });\n\t\t\tif (shouldInterrupt(this.checkpoint, this.interruptAfter, Object.values(this.tasks))) {\n\t\t\t\tthis.status = \"interrupt_after\";\n\t\t\t\tthrow new GraphInterrupt();\n\t\t\t}\n\t\t\tif (this.config.configurable?.[CONFIG_KEY_RESUMING] !== void 0) delete this.config.configurable?.[CONFIG_KEY_RESUMING];\n\t\t} else return false;\n\t\tif (this.step > this.stop) {\n\t\t\tthis.status = \"out_of_steps\";\n\t\t\treturn false;\n\t\t}\n\t\tconst nextTasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, {\n\t\t\tstep: this.step,\n\t\t\tcheckpointer: this.checkpointer,\n\t\t\tisResuming: this.isResuming,\n\t\t\tmanager: this.manager,\n\t\t\tstore: this.store,\n\t\t\tstream: this.stream,\n\t\t\ttriggerToNodes: this.triggerToNodes,\n\t\t\tupdatedChannels: this.updatedChannels\n\t\t});\n\t\tthis.tasks = nextTasks;\n\t\tif (this.checkpointer) this._emit(await gatherIterator(prefixGenerator(mapDebugCheckpoint(this.checkpointConfig, this.channels, this.streamKeys, this.checkpointMetadata, Object.values(this.tasks), this.checkpointPendingWrites, this.prevCheckpointConfig, this.outputKeys), \"checkpoints\")));\n\t\tif (Object.values(this.tasks).length === 0) {\n\t\t\tthis.status = \"done\";\n\t\t\treturn false;\n\t\t}\n\t\tif (this.skipDoneTasks && this.checkpointPendingWrites.length > 0) {\n\t\t\tfor (const [tid, k, v] of this.checkpointPendingWrites) {\n\t\t\t\tif (k === ERROR || k === INTERRUPT || k === RESUME) continue;\n\t\t\t\tconst task = Object.values(this.tasks).find((t) => t.id === tid);\n\t\t\t\tif (task) task.writes.push([k, v]);\n\t\t\t}\n\t\t\tfor (const task of Object.values(this.tasks)) if (task.writes.length > 0) this._outputWrites(task.id, task.writes, true);\n\t\t}\n\t\tif (Object.values(this.tasks).every((task) => task.writes.length > 0)) return this.tick({ inputKeys });\n\t\tif (shouldInterrupt(this.checkpoint, this.interruptBefore, Object.values(this.tasks))) {\n\t\t\tthis.status = \"interrupt_before\";\n\t\t\tthrow new GraphInterrupt();\n\t\t}\n\t\tconst debugOutput = await gatherIterator(prefixGenerator(mapDebugTasks(Object.values(this.tasks)), \"tasks\"));\n\t\tthis._emit(debugOutput);\n\t\treturn true;\n\t}\n\tasync finishAndHandleError(error) {\n\t\tif (this.durability === \"exit\" && (!this.isNested || typeof error !== \"undefined\" || this.checkpointNamespace.every((part) => !part.includes(CHECKPOINT_NAMESPACE_END)))) {\n\t\t\tthis._putCheckpoint(this.checkpointMetadata);\n\t\t\tthis._flushPendingWrites();\n\t\t}\n\t\tconst suppress = this._suppressInterrupt(error);\n\t\tif (suppress || error === void 0) this.output = readChannels(this.channels, this.outputKeys);\n\t\tif (suppress) {\n\t\t\tif (this.tasks !== void 0 && this.checkpointPendingWrites.length > 0 && Object.values(this.tasks).some((task) => task.writes.length > 0)) {\n\t\t\t\tthis.updatedChannels = _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);\n\t\t\t\tthis._emit(gatherIteratorSync(prefixGenerator(mapOutputValues(this.outputKeys, Object.values(this.tasks).flatMap((t) => t.writes), this.channels), \"values\")));\n\t\t\t}\n\t\t\tif (isGraphInterrupt(error) && !error.interrupts.length) this._emit([[\"updates\", { [INTERRUPT]: [] }], [\"values\", { [INTERRUPT]: [] }]]);\n\t\t}\n\t\treturn suppress;\n\t}\n\tasync acceptPush(task, writeIdx, call) {\n\t\tif (this.interruptAfter?.length > 0 && shouldInterrupt(this.checkpoint, this.interruptAfter, [task])) {\n\t\t\tthis.toInterrupt.push(task);\n\t\t\treturn;\n\t\t}\n\t\tconst pushed = _prepareSingleTask([\n\t\t\tPUSH,\n\t\t\ttask.path ?? [],\n\t\t\twriteIdx,\n\t\t\ttask.id,\n\t\t\tcall\n\t\t], this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, task.config ?? {}, true, {\n\t\t\tstep: this.step,\n\t\t\tcheckpointer: this.checkpointer,\n\t\t\tmanager: this.manager,\n\t\t\tstore: this.store,\n\t\t\tstream: this.stream\n\t\t});\n\t\tif (!pushed) return;\n\t\tif (this.interruptBefore?.length > 0 && shouldInterrupt(this.checkpoint, this.interruptBefore, [pushed])) {\n\t\t\tthis.toInterrupt.push(pushed);\n\t\t\treturn;\n\t\t}\n\t\tthis._emit(gatherIteratorSync(prefixGenerator(mapDebugTasks([pushed]), \"tasks\")));\n\t\tif (this.debug) printStepTasks(this.step, [pushed]);\n\t\tthis.tasks[pushed.id] = pushed;\n\t\tif (this.skipDoneTasks) this._matchWrites({ [pushed.id]: pushed });\n\t\tconst tasks = await this._matchCachedWrites();\n\t\tfor (const { task: task$1 } of tasks) this._outputWrites(task$1.id, task$1.writes, true);\n\t\treturn pushed;\n\t}\n\t_suppressInterrupt(e) {\n\t\treturn isGraphInterrupt(e) && !this.isNested;\n\t}\n\tasync _first(inputKeys) {\n\t\tconst { configurable } = this.config;\n\t\tconst scratchpad = configurable?.[CONFIG_KEY_SCRATCHPAD];\n\t\tif (scratchpad && scratchpad.nullResume !== void 0) this.putWrites(NULL_TASK_ID, [[RESUME, scratchpad.nullResume]]);\n\t\tif (isCommand(this.input)) {\n\t\t\tconst hasResume = this.input.resume != null;\n\t\t\tif (this.input.resume != null && typeof this.input.resume === \"object\" && Object.keys(this.input.resume).every(isXXH3)) {\n\t\t\t\tthis.config.configurable ??= {};\n\t\t\t\tthis.config.configurable[CONFIG_KEY_RESUME_MAP] = this.input.resume;\n\t\t\t}\n\t\t\tif (hasResume && this.checkpointer == null) throw new Error(\"Cannot use Command(resume=...) without checkpointer\");\n\t\t\tconst writes = {};\n\t\t\tfor (const [tid, key, value] of mapCommand(this.input, this.checkpointPendingWrites)) {\n\t\t\t\twrites[tid] ??= [];\n\t\t\t\twrites[tid].push([key, value]);\n\t\t\t}\n\t\t\tif (Object.keys(writes).length === 0) throw new EmptyInputError(\"Received empty Command input\");\n\t\t\tfor (const [tid, ws] of Object.entries(writes)) this.putWrites(tid, ws);\n\t\t}\n\t\tconst nullWrites = (this.checkpointPendingWrites ?? []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));\n\t\tif (nullWrites.length > 0) _applyWrites(this.checkpoint, this.channels, [{\n\t\t\tname: INPUT,\n\t\t\twrites: nullWrites,\n\t\t\ttriggers: []\n\t\t}], this.checkpointerGetNextVersion, this.triggerToNodes);\n\t\tconst isCommandUpdateOrGoto = isCommand(this.input) && nullWrites.length > 0;\n\t\tif (this.isResuming || isCommandUpdateOrGoto) {\n\t\t\tfor (const channelName in this.channels) {\n\t\t\t\tif (!Object.prototype.hasOwnProperty.call(this.channels, channelName)) continue;\n\t\t\t\tif (this.checkpoint.channel_versions[channelName] !== void 0) {\n\t\t\t\t\tconst version = this.checkpoint.channel_versions[channelName];\n\t\t\t\t\tthis.checkpoint.versions_seen[INTERRUPT] = {\n\t\t\t\t\t\t...this.checkpoint.versions_seen[INTERRUPT],\n\t\t\t\t\t\t[channelName]: version\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, true, this.channels), \"values\"));\n\t\t\tthis._emit(valuesOutput);\n\t\t}\n\t\tif (this.isResuming) this.input = INPUT_RESUMING;\n\t\telse if (isCommandUpdateOrGoto) {\n\t\t\tawait this._putCheckpoint({ source: \"input\" });\n\t\t\tthis.input = INPUT_DONE;\n\t\t} else {\n\t\t\tconst inputWrites = await gatherIterator(mapInput(inputKeys, this.input));\n\t\t\tif (inputWrites.length > 0) {\n\t\t\t\tconst discardTasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, { step: this.step });\n\t\t\t\tthis.updatedChannels = _applyWrites(this.checkpoint, this.channels, Object.values(discardTasks).concat([{\n\t\t\t\t\tname: INPUT,\n\t\t\t\t\twrites: inputWrites,\n\t\t\t\t\ttriggers: []\n\t\t\t\t}]), this.checkpointerGetNextVersion, this.triggerToNodes);\n\t\t\t\tawait this._putCheckpoint({ source: \"input\" });\n\t\t\t\tthis.input = INPUT_DONE;\n\t\t\t} else if (!(CONFIG_KEY_RESUMING in (this.config.configurable ?? {}))) throw new EmptyInputError(`Received no input writes for ${JSON.stringify(inputKeys, null, 2)}`);\n\t\t\telse this.input = INPUT_DONE;\n\t\t}\n\t\tif (!this.isNested) this.config = patchConfigurable(this.config, { [CONFIG_KEY_RESUMING]: this.isResuming });\n\t}\n\t_emit(values) {\n\t\tfor (const [mode, payload] of values) {\n\t\t\tif (this.stream.modes.has(mode)) this.stream.push([\n\t\t\t\tthis.checkpointNamespace,\n\t\t\t\tmode,\n\t\t\t\tpayload\n\t\t\t]);\n\t\t\tif ((mode === \"checkpoints\" || mode === \"tasks\") && this.stream.modes.has(\"debug\")) {\n\t\t\t\tconst step = mode === \"checkpoints\" ? this.step - 1 : this.step;\n\t\t\t\tconst timestamp = (/* @__PURE__ */ new Date()).toISOString();\n\t\t\t\tconst type = (() => {\n\t\t\t\t\tif (mode === \"checkpoints\") return \"checkpoint\";\n\t\t\t\t\telse if (typeof payload === \"object\" && payload != null && \"result\" in payload) return \"task_result\";\n\t\t\t\t\telse return \"task\";\n\t\t\t\t})();\n\t\t\t\tthis.stream.push([\n\t\t\t\t\tthis.checkpointNamespace,\n\t\t\t\t\t\"debug\",\n\t\t\t\t\t{\n\t\t\t\t\t\tstep,\n\t\t\t\t\t\ttype,\n\t\t\t\t\t\ttimestamp,\n\t\t\t\t\t\tpayload\n\t\t\t\t\t}\n\t\t\t\t]);\n\t\t\t}\n\t\t}\n\t}\n\t_putCheckpoint(inputMetadata) {\n\t\tconst exiting = this.checkpointMetadata === inputMetadata;\n\t\tconst doCheckpoint = this.checkpointer != null && (this.durability !== \"exit\" || exiting);\n\t\tconst storeCheckpoint = (checkpoint) => {\n\t\t\tthis.prevCheckpointConfig = this.checkpointConfig?.configurable?.checkpoint_id ? this.checkpointConfig : void 0;\n\t\t\tthis.checkpointConfig = patchConfigurable(this.checkpointConfig, { [CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? \"\" });\n\t\t\tconst channelVersions = { ...this.checkpoint.channel_versions };\n\t\t\tconst newVersions = getNewChannelVersions(this.checkpointPreviousVersions, channelVersions);\n\t\t\tthis.checkpointPreviousVersions = channelVersions;\n\t\t\tthis._checkpointerPutAfterPrevious({\n\t\t\t\tconfig: { ...this.checkpointConfig },\n\t\t\t\tcheckpoint: copyCheckpoint(checkpoint),\n\t\t\t\tmetadata: { ...this.checkpointMetadata },\n\t\t\t\tnewVersions\n\t\t\t});\n\t\t\tthis.checkpointConfig = {\n\t\t\t\t...this.checkpointConfig,\n\t\t\t\tconfigurable: {\n\t\t\t\t\t...this.checkpointConfig.configurable,\n\t\t\t\t\tcheckpoint_id: this.checkpoint.id\n\t\t\t\t}\n\t\t\t};\n\t\t};\n\t\tif (!exiting) this.checkpointMetadata = {\n\t\t\t...inputMetadata,\n\t\t\tstep: this.step,\n\t\t\tparents: this.config.configurable?.[CONFIG_KEY_CHECKPOINT_MAP] ?? {}\n\t\t};\n\t\tthis.checkpoint = createCheckpoint(this.checkpoint, doCheckpoint ? this.channels : void 0, this.step, exiting ? { id: this.checkpoint.id } : void 0);\n\t\tif (doCheckpoint) storeCheckpoint(this.checkpoint);\n\t\tif (!exiting) this.step += 1;\n\t}\n\t_flushPendingWrites() {\n\t\tif (this.checkpointer == null) return;\n\t\tif (this.checkpointPendingWrites.length === 0) return;\n\t\tconst config = patchConfigurable(this.checkpointConfig, {\n\t\t\t[CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? \"\",\n\t\t\t[CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id\n\t\t});\n\t\tconst byTask = {};\n\t\tfor (const [tid, key, value] of this.checkpointPendingWrites) {\n\t\t\tbyTask[tid] ??= [];\n\t\t\tbyTask[tid].push([key, value]);\n\t\t}\n\t\tfor (const [tid, ws] of Object.entries(byTask)) this.checkpointerPromises.push(this.checkpointer.putWrites(config, ws, tid));\n\t}\n\t_matchWrites(tasks) {\n\t\tfor (const [tid, k, v] of this.checkpointPendingWrites) {\n\t\t\tif (k === ERROR || k === INTERRUPT || k === RESUME) continue;\n\t\t\tconst task = Object.values(tasks).find((t) => t.id === tid);\n\t\t\tif (task) task.writes.push([k, v]);\n\t\t}\n\t\tfor (const task of Object.values(tasks)) if (task.writes.length > 0) this._outputWrites(task.id, task.writes, true);\n\t}\n};\n\n//#endregion\nexport { PregelLoop };\n//# sourceMappingURL=loop.js.map","import { TAG_HIDDEN, TAG_NOSTREAM } from \"../constants.js\";\nimport { BaseCallbackHandler } from \"@langchain/core/callbacks/base\";\nimport { AIMessageChunk, isBaseMessage, isBaseMessageChunk, isToolMessage } from \"@langchain/core/messages\";\n\n//#region src/pregel/messages.ts\nfunction isChatGenerationChunk(x) {\n\treturn isBaseMessage(x?.message);\n}\n/**\n* A callback handler that implements stream_mode=messages.\n* Collects messages from (1) chat model stream events and (2) node outputs.\n*/\nvar StreamMessagesHandler = class extends BaseCallbackHandler {\n\tname = \"StreamMessagesHandler\";\n\tstreamFn;\n\tmetadatas = {};\n\tseen = {};\n\temittedChatModelRunIds = {};\n\tstableMessageIdMap = {};\n\tlc_prefer_streaming = true;\n\tconstructor(streamFn) {\n\t\tsuper();\n\t\tthis.streamFn = streamFn;\n\t}\n\t_emit(meta, message, runId, dedupe = false) {\n\t\tif (dedupe && message.id !== void 0 && this.seen[message.id] !== void 0) return;\n\t\tlet messageId = message.id;\n\t\tif (runId != null) if (isToolMessage(message)) messageId ??= `run-${runId}-tool-${message.tool_call_id}`;\n\t\telse {\n\t\t\tif (messageId == null || messageId === `run-${runId}`) messageId = this.stableMessageIdMap[runId] ?? messageId ?? `run-${runId}`;\n\t\t\tthis.stableMessageIdMap[runId] ??= messageId;\n\t\t}\n\t\tif (messageId !== message.id) {\n\t\t\tmessage.id = messageId;\n\t\t\tmessage.lc_kwargs.id = messageId;\n\t\t}\n\t\tif (message.id != null) this.seen[message.id] = message;\n\t\tthis.streamFn([\n\t\t\tmeta[0],\n\t\t\t\"messages\",\n\t\t\t[message, meta[1]]\n\t\t]);\n\t}\n\thandleChatModelStart(_llm, _messages, runId, _parentRunId, _extraParams, tags, metadata, name) {\n\t\tif (metadata && (!tags || !tags.includes(TAG_NOSTREAM) && !tags.includes(\"nostream\"))) this.metadatas[runId] = [metadata.langgraph_checkpoint_ns.split(\"|\"), {\n\t\t\ttags,\n\t\t\tname,\n\t\t\t...metadata\n\t\t}];\n\t}\n\thandleLLMNewToken(token, _idx, runId, _parentRunId, _tags, fields) {\n\t\tconst chunk = fields?.chunk;\n\t\tthis.emittedChatModelRunIds[runId] = true;\n\t\tif (this.metadatas[runId] !== void 0) if (isChatGenerationChunk(chunk)) this._emit(this.metadatas[runId], chunk.message, runId);\n\t\telse this._emit(this.metadatas[runId], new AIMessageChunk({ content: token }), runId);\n\t}\n\thandleLLMEnd(output, runId) {\n\t\tif (this.metadatas[runId] === void 0) return;\n\t\tif (!this.emittedChatModelRunIds[runId]) {\n\t\t\tconst chatGeneration = output.generations?.[0]?.[0];\n\t\t\tif (isBaseMessage(chatGeneration?.message)) this._emit(this.metadatas[runId], chatGeneration?.message, runId, true);\n\t\t\tdelete this.emittedChatModelRunIds[runId];\n\t\t}\n\t\tdelete this.metadatas[runId];\n\t\tdelete this.stableMessageIdMap[runId];\n\t}\n\thandleLLMError(_err, runId) {\n\t\tdelete this.metadatas[runId];\n\t}\n\thandleChainStart(_chain, inputs, runId, _parentRunId, tags, metadata, _runType, name) {\n\t\tif (metadata !== void 0 && name === metadata.langgraph_node && (tags === void 0 || !tags.includes(TAG_HIDDEN))) {\n\t\t\tthis.metadatas[runId] = [metadata.langgraph_checkpoint_ns.split(\"|\"), {\n\t\t\t\ttags,\n\t\t\t\tname,\n\t\t\t\t...metadata\n\t\t\t}];\n\t\t\tif (typeof inputs === \"object\") {\n\t\t\t\tfor (const value of Object.values(inputs)) if ((isBaseMessage(value) || isBaseMessageChunk(value)) && value.id !== void 0) this.seen[value.id] = value;\n\t\t\t\telse if (Array.isArray(value)) {\n\t\t\t\t\tfor (const item of value) if ((isBaseMessage(item) || isBaseMessageChunk(item)) && item.id !== void 0) this.seen[item.id] = item;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\thandleChainEnd(outputs, runId) {\n\t\tconst metadata = this.metadatas[runId];\n\t\tdelete this.metadatas[runId];\n\t\tif (metadata !== void 0) {\n\t\t\tif (isBaseMessage(outputs)) this._emit(metadata, outputs, runId, true);\n\t\t\telse if (Array.isArray(outputs)) {\n\t\t\t\tfor (const value of outputs) if (isBaseMessage(value)) this._emit(metadata, value, runId, true);\n\t\t\t} else if (outputs != null && typeof outputs === \"object\") {\n\t\t\t\tfor (const value of Object.values(outputs)) if (isBaseMessage(value)) this._emit(metadata, value, runId, true);\n\t\t\t\telse if (Array.isArray(value)) {\n\t\t\t\t\tfor (const item of value) if (isBaseMessage(item)) this._emit(metadata, item, runId, true);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\thandleChainError(_err, runId) {\n\t\tdelete this.metadatas[runId];\n\t}\n};\n\n//#endregion\nexport { StreamMessagesHandler };\n//# sourceMappingURL=messages.js.map","import { isGraphBubbleUp, isParentCommand } from \"../errors.js\";\nimport { CONFIG_KEY_RESUMING, Command } from \"../constants.js\";\nimport { getParentCheckpointNamespace } from \"./utils/config.js\";\nimport { patchConfigurable } from \"./utils/index.js\";\n\n//#region src/pregel/retry.ts\nconst DEFAULT_INITIAL_INTERVAL = 500;\nconst DEFAULT_BACKOFF_FACTOR = 2;\nconst DEFAULT_MAX_INTERVAL = 128e3;\nconst DEFAULT_MAX_RETRIES = 3;\nconst DEFAULT_STATUS_NO_RETRY = [\n\t400,\n\t401,\n\t402,\n\t403,\n\t404,\n\t405,\n\t406,\n\t407,\n\t409\n];\nconst DEFAULT_RETRY_ON_HANDLER = (error) => {\n\tif (error.message.startsWith(\"Cancel\") || error.message.startsWith(\"AbortError\") || error.name === \"AbortError\") return false;\n\tif (error.name === \"GraphValueError\") return false;\n\tif (error?.code === \"ECONNABORTED\") return false;\n\tconst status = error?.response?.status ?? error?.status;\n\tif (status && DEFAULT_STATUS_NO_RETRY.includes(+status)) return false;\n\tif (error?.error?.code === \"insufficient_quota\") return false;\n\treturn true;\n};\nasync function _runWithRetry(pregelTask, retryPolicy, configurable, signal) {\n\tconst resolvedRetryPolicy = pregelTask.retry_policy ?? retryPolicy;\n\tlet interval = resolvedRetryPolicy !== void 0 ? resolvedRetryPolicy.initialInterval ?? DEFAULT_INITIAL_INTERVAL : 0;\n\tlet attempts = 0;\n\tlet error;\n\tlet result;\n\tlet { config } = pregelTask;\n\tif (configurable) config = patchConfigurable(config, configurable);\n\tconfig = {\n\t\t...config,\n\t\tsignal\n\t};\n\twhile (true) {\n\t\tif (signal?.aborted) break;\n\t\tpregelTask.writes.splice(0, pregelTask.writes.length);\n\t\terror = void 0;\n\t\ttry {\n\t\t\tresult = await pregelTask.proc.invoke(pregelTask.input, config);\n\t\t\tbreak;\n\t\t} catch (e) {\n\t\t\terror = e;\n\t\t\terror.pregelTaskId = pregelTask.id;\n\t\t\tif (isParentCommand(error)) {\n\t\t\t\tconst ns = config?.configurable?.checkpoint_ns;\n\t\t\t\tconst cmd = error.command;\n\t\t\t\tif (cmd.graph === ns) {\n\t\t\t\t\tfor (const writer of pregelTask.writers) await writer.invoke(cmd, config);\n\t\t\t\t\terror = void 0;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (cmd.graph === Command.PARENT) {\n\t\t\t\t\tconst parentNs = getParentCheckpointNamespace(ns);\n\t\t\t\t\terror.command = new Command({\n\t\t\t\t\t\t...error.command,\n\t\t\t\t\t\tgraph: parentNs\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (isGraphBubbleUp(error)) break;\n\t\t\tif (resolvedRetryPolicy === void 0) break;\n\t\t\tattempts += 1;\n\t\t\tif (attempts >= (resolvedRetryPolicy.maxAttempts ?? DEFAULT_MAX_RETRIES)) break;\n\t\t\tconst retryOn = resolvedRetryPolicy.retryOn ?? DEFAULT_RETRY_ON_HANDLER;\n\t\t\tif (!retryOn(error)) break;\n\t\t\tinterval = Math.min(resolvedRetryPolicy.maxInterval ?? DEFAULT_MAX_INTERVAL, interval * (resolvedRetryPolicy.backoffFactor ?? DEFAULT_BACKOFF_FACTOR));\n\t\t\tconst intervalWithJitter = resolvedRetryPolicy.jitter ? Math.floor(interval + Math.random() * 1e3) : interval;\n\t\t\tawait new Promise((resolve) => setTimeout(resolve, intervalWithJitter));\n\t\t\tconst errorName = error.name ?? error.constructor.unminifiable_name ?? error.constructor.name;\n\t\t\tif (resolvedRetryPolicy?.logWarning ?? true) console.log(`Retrying task \"${String(pregelTask.name)}\" after ${interval.toFixed(2)}ms (attempt ${attempts}) after ${errorName}: ${error}`);\n\t\t\tconfig = patchConfigurable(config, { [CONFIG_KEY_RESUMING]: true });\n\t\t}\n\t}\n\treturn {\n\t\ttask: pregelTask,\n\t\tresult,\n\t\terror,\n\t\tsignalAborted: signal?.aborted\n\t};\n}\n\n//#endregion\nexport { _runWithRetry };\n//# sourceMappingURL=retry.js.map","import { isGraphBubbleUp, isGraphInterrupt } from \"../errors.js\";\nimport { CONFIG_KEY_ABORT_SIGNALS, CONFIG_KEY_CALL, CONFIG_KEY_SCRATCHPAD, ERROR, INTERRUPT, NO_WRITES, RESUME, RETURN, TAG_HIDDEN } from \"../constants.js\";\nimport { Call } from \"./types.js\";\nimport { combineAbortSignals, patchConfigurable } from \"./utils/index.js\";\nimport { _runWithRetry } from \"./retry.js\";\n\n//#region src/pregel/runner.ts\nconst PROMISE_ADDED_SYMBOL = Symbol.for(\"promiseAdded\");\nfunction createPromiseBarrier() {\n\tconst barrier = {\n\t\tnext: () => void 0,\n\t\twait: Promise.resolve(PROMISE_ADDED_SYMBOL)\n\t};\n\tfunction waitHandler(resolve) {\n\t\tbarrier.next = () => {\n\t\t\tbarrier.wait = new Promise(waitHandler);\n\t\t\tresolve(PROMISE_ADDED_SYMBOL);\n\t\t};\n\t}\n\tbarrier.wait = new Promise(waitHandler);\n\treturn barrier;\n}\n/**\n* Responsible for handling task execution on each tick of the {@link PregelLoop}.\n*/\nvar PregelRunner = class {\n\tnodeFinished;\n\tloop;\n\t/**\n\t* Construct a new PregelRunner, which executes tasks from the provided PregelLoop.\n\t* @param loop - The PregelLoop that produces tasks for this runner to execute.\n\t*/\n\tconstructor({ loop, nodeFinished }) {\n\t\tthis.loop = loop;\n\t\tthis.nodeFinished = nodeFinished;\n\t}\n\t/**\n\t* Execute tasks from the current step of the PregelLoop.\n\t*\n\t* Note: this method does NOT call {@link PregelLoop}#tick. That must be handled externally.\n\t* @param options - Options for the execution.\n\t*/\n\tasync tick(options = {}) {\n\t\tconst { timeout, retryPolicy, onStepWrite, maxConcurrency } = options;\n\t\tconst nodeErrors = /* @__PURE__ */ new Set();\n\t\tlet graphBubbleUp;\n\t\tconst exceptionSignalController = new AbortController();\n\t\tconst exceptionSignal = exceptionSignalController.signal;\n\t\tconst stepTimeoutSignal = timeout ? AbortSignal.timeout(timeout) : void 0;\n\t\tconst pendingTasks = Object.values(this.loop.tasks).filter((t) => t.writes.length === 0);\n\t\tconst { signals, disposeCombinedSignal } = this._initializeAbortSignals({\n\t\t\texceptionSignal,\n\t\t\tstepTimeoutSignal,\n\t\t\tsignal: options.signal\n\t\t});\n\t\tconst taskStream = this._executeTasksWithRetry(pendingTasks, {\n\t\t\tsignals,\n\t\t\tretryPolicy,\n\t\t\tmaxConcurrency\n\t\t});\n\t\tfor await (const { task, error, signalAborted } of taskStream) {\n\t\t\tthis._commit(task, error);\n\t\t\tif (isGraphInterrupt(error)) graphBubbleUp = error;\n\t\t\telse if (isGraphBubbleUp(error) && !isGraphInterrupt(graphBubbleUp)) graphBubbleUp = error;\n\t\t\telse if (error && (nodeErrors.size === 0 || !signalAborted)) {\n\t\t\t\texceptionSignalController.abort();\n\t\t\t\tnodeErrors.add(error);\n\t\t\t}\n\t\t}\n\t\tdisposeCombinedSignal?.();\n\t\tonStepWrite?.(this.loop.step, Object.values(this.loop.tasks).map((task) => task.writes).flat());\n\t\tif (nodeErrors.size === 1) throw Array.from(nodeErrors)[0];\n\t\telse if (nodeErrors.size > 1) throw new AggregateError(Array.from(nodeErrors), `Multiple errors occurred during superstep ${this.loop.step}. See the \"errors\" field of this exception for more details.`);\n\t\tif (isGraphInterrupt(graphBubbleUp)) throw graphBubbleUp;\n\t\tif (isGraphBubbleUp(graphBubbleUp) && this.loop.isNested) throw graphBubbleUp;\n\t}\n\t/**\n\t* Initializes the current AbortSignals for the PregelRunner, handling the various ways that\n\t* AbortSignals must be chained together so that the PregelLoop can be interrupted if necessary\n\t* while still allowing nodes to gracefully exit.\n\t*\n\t* This method must only be called once per PregelRunner#tick. It has the side effect of updating\n\t* the PregelLoop#config with the new AbortSignals so they may be propagated correctly to future\n\t* ticks and subgraph calls.\n\t*\n\t* @param options - Options for the initialization.\n\t* @returns The current abort signals.\n\t* @internal\n\t*/\n\t_initializeAbortSignals({ exceptionSignal, stepTimeoutSignal, signal }) {\n\t\tconst previousSignals = this.loop.config.configurable?.[CONFIG_KEY_ABORT_SIGNALS] ?? {};\n\t\tconst externalAbortSignal = previousSignals.externalAbortSignal ?? signal;\n\t\tconst timeoutAbortSignal = stepTimeoutSignal ?? previousSignals.timeoutAbortSignal;\n\t\tconst { signal: composedAbortSignal, dispose: disposeCombinedSignal } = combineAbortSignals(externalAbortSignal, timeoutAbortSignal, exceptionSignal);\n\t\tconst signals = {\n\t\t\texternalAbortSignal,\n\t\t\ttimeoutAbortSignal,\n\t\t\tcomposedAbortSignal\n\t\t};\n\t\tthis.loop.config = patchConfigurable(this.loop.config, { [CONFIG_KEY_ABORT_SIGNALS]: signals });\n\t\treturn {\n\t\t\tsignals,\n\t\t\tdisposeCombinedSignal\n\t\t};\n\t}\n\t/**\n\t* Concurrently executes tasks with the requested retry policy, yielding a {@link SettledPregelTask} for each task as it completes.\n\t* @param tasks - The tasks to execute.\n\t* @param options - Options for the execution.\n\t*/\n\tasync *_executeTasksWithRetry(tasks, options) {\n\t\tconst { retryPolicy, maxConcurrency, signals } = options ?? {};\n\t\tconst barrier = createPromiseBarrier();\n\t\tconst executingTasksMap = {};\n\t\tconst thisCall = {\n\t\t\texecutingTasksMap,\n\t\t\tbarrier,\n\t\t\tretryPolicy,\n\t\t\tscheduleTask: async (task, writeIdx, call$1) => this.loop.acceptPush(task, writeIdx, call$1)\n\t\t};\n\t\tif (signals?.composedAbortSignal?.aborted) throw new Error(\"Abort\");\n\t\tlet startedTasksCount = 0;\n\t\tlet listener;\n\t\tconst timeoutOrCancelSignal = combineAbortSignals(signals?.externalAbortSignal, signals?.timeoutAbortSignal);\n\t\tconst abortPromise = timeoutOrCancelSignal.signal ? new Promise((_resolve, reject) => {\n\t\t\tlistener = () => reject(/* @__PURE__ */ new Error(\"Abort\"));\n\t\t\ttimeoutOrCancelSignal.signal?.addEventListener(\"abort\", listener, { once: true });\n\t\t}) : void 0;\n\t\twhile ((startedTasksCount === 0 || Object.keys(executingTasksMap).length > 0) && tasks.length) {\n\t\t\tfor (; Object.values(executingTasksMap).length < (maxConcurrency ?? tasks.length) && startedTasksCount < tasks.length; startedTasksCount += 1) {\n\t\t\t\tconst task = tasks[startedTasksCount];\n\t\t\t\texecutingTasksMap[task.id] = _runWithRetry(task, retryPolicy, { [CONFIG_KEY_CALL]: call?.bind(thisCall, this, task) }, signals?.composedAbortSignal).catch((error) => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\ttask,\n\t\t\t\t\t\terror,\n\t\t\t\t\t\tsignalAborted: signals?.composedAbortSignal?.aborted\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t}\n\t\t\tconst settledTask = await Promise.race([\n\t\t\t\t...Object.values(executingTasksMap),\n\t\t\t\t...abortPromise ? [abortPromise] : [],\n\t\t\t\tbarrier.wait\n\t\t\t]);\n\t\t\tif (settledTask === PROMISE_ADDED_SYMBOL) continue;\n\t\t\tyield settledTask;\n\t\t\tif (listener != null) {\n\t\t\t\ttimeoutOrCancelSignal.signal?.removeEventListener(\"abort\", listener);\n\t\t\t\ttimeoutOrCancelSignal.dispose?.();\n\t\t\t}\n\t\t\tdelete executingTasksMap[settledTask.task.id];\n\t\t}\n\t}\n\t/**\n\t* Determines what writes to apply based on whether the task completed successfully, and what type of error occurred.\n\t*\n\t* Throws an error if the error is a {@link GraphBubbleUp} error and {@link PregelLoop}#isNested is true.\n\t*\n\t* @param task - The task to commit.\n\t* @param error - The error that occurred, if any.\n\t*/\n\t_commit(task, error) {\n\t\tif (error !== void 0) if (isGraphInterrupt(error)) {\n\t\t\tif (error.interrupts.length) {\n\t\t\t\tconst interrupts = error.interrupts.map((interrupt) => [INTERRUPT, interrupt]);\n\t\t\t\tconst resumes = task.writes.filter((w) => w[0] === RESUME);\n\t\t\t\tif (resumes.length) interrupts.push(...resumes);\n\t\t\t\tthis.loop.putWrites(task.id, interrupts);\n\t\t\t}\n\t\t} else if (isGraphBubbleUp(error) && task.writes.length) this.loop.putWrites(task.id, task.writes);\n\t\telse this.loop.putWrites(task.id, [[ERROR, {\n\t\t\tmessage: error.message,\n\t\t\tname: error.name\n\t\t}]]);\n\t\telse {\n\t\t\tif (this.nodeFinished && (task.config?.tags == null || !task.config.tags.includes(TAG_HIDDEN))) this.nodeFinished(String(task.name));\n\t\t\tif (task.writes.length === 0) task.writes.push([NO_WRITES, null]);\n\t\t\tthis.loop.putWrites(task.id, task.writes);\n\t\t}\n\t}\n};\nasync function call(runner, task, func, name, input, options = {}) {\n\tconst scratchpad = task.config?.configurable?.[CONFIG_KEY_SCRATCHPAD];\n\tif (!scratchpad) throw new Error(`BUG: No scratchpad found on task ${task.name}__${task.id}`);\n\tconst cnt = scratchpad.callCounter;\n\tscratchpad.callCounter += 1;\n\tconst wcall = new Call({\n\t\tfunc,\n\t\tname,\n\t\tinput,\n\t\tcache: options.cache,\n\t\tretry: options.retry,\n\t\tcallbacks: options.callbacks\n\t});\n\tconst nextTask = await this.scheduleTask(task, cnt, wcall);\n\tif (!nextTask) return void 0;\n\tconst existingPromise = this.executingTasksMap[nextTask.id];\n\tif (existingPromise !== void 0) return existingPromise;\n\tif (nextTask.writes.length > 0) {\n\t\tconst returns = nextTask.writes.filter(([c]) => c === RETURN);\n\t\tconst errors = nextTask.writes.filter(([c]) => c === ERROR);\n\t\tif (returns.length > 0) {\n\t\t\tif (returns.length === 1) return Promise.resolve(returns[0][1]);\n\t\t\tthrow new Error(`BUG: multiple returns found for task ${nextTask.name}__${nextTask.id}`);\n\t\t}\n\t\tif (errors.length > 0) {\n\t\t\tif (errors.length === 1) {\n\t\t\t\tconst errorValue = errors[0][1];\n\t\t\t\tconst error = errorValue instanceof Error ? errorValue : new Error(String(errorValue));\n\t\t\t\treturn Promise.reject(error);\n\t\t\t}\n\t\t\tthrow new Error(`BUG: multiple errors found for task ${nextTask.name}__${nextTask.id}`);\n\t\t}\n\t\treturn void 0;\n\t} else {\n\t\tconst prom = _runWithRetry(nextTask, options.retry, { [CONFIG_KEY_CALL]: call.bind(this, runner, nextTask) });\n\t\tthis.executingTasksMap[nextTask.id] = prom;\n\t\tthis.barrier.next();\n\t\treturn prom.then(({ result, error }) => {\n\t\t\tif (error) return Promise.reject(error);\n\t\t\treturn result;\n\t\t});\n\t}\n}\n\n//#endregion\nexport { PregelRunner };\n//# sourceMappingURL=runner.js.map","import { INTERRUPT } from \"../constants.js\";\nimport { PregelNode } from \"./read.js\";\n\n//#region src/pregel/validate.ts\nvar GraphValidationError = class extends Error {\n\tconstructor(message) {\n\t\tsuper(message);\n\t\tthis.name = \"GraphValidationError\";\n\t}\n};\nfunction validateGraph({ nodes, channels, inputChannels, outputChannels, streamChannels, interruptAfterNodes, interruptBeforeNodes }) {\n\tif (!channels) throw new GraphValidationError(\"Channels not provided\");\n\tconst subscribedChannels = /* @__PURE__ */ new Set();\n\tconst allOutputChannels = /* @__PURE__ */ new Set();\n\tfor (const [name, node] of Object.entries(nodes)) {\n\t\tif (name === INTERRUPT) throw new GraphValidationError(`\"Node name ${INTERRUPT} is reserved\"`);\n\t\tif (node.constructor === PregelNode) node.triggers.forEach((trigger) => subscribedChannels.add(trigger));\n\t\telse throw new GraphValidationError(`Invalid node type ${typeof node}, expected PregelNode`);\n\t}\n\tfor (const chan of subscribedChannels) if (!(chan in channels)) throw new GraphValidationError(`Subscribed channel '${String(chan)}' not in channels`);\n\tif (!Array.isArray(inputChannels)) {\n\t\tif (!subscribedChannels.has(inputChannels)) throw new GraphValidationError(`Input channel ${String(inputChannels)} is not subscribed to by any node`);\n\t} else if (inputChannels.every((channel) => !subscribedChannels.has(channel))) throw new GraphValidationError(`None of the input channels ${inputChannels} are subscribed to by any node`);\n\tif (!Array.isArray(outputChannels)) allOutputChannels.add(outputChannels);\n\telse outputChannels.forEach((chan) => allOutputChannels.add(chan));\n\tif (streamChannels && !Array.isArray(streamChannels)) allOutputChannels.add(streamChannels);\n\telse if (Array.isArray(streamChannels)) streamChannels.forEach((chan) => allOutputChannels.add(chan));\n\tfor (const chan of allOutputChannels) if (!(chan in channels)) throw new GraphValidationError(`Output channel '${String(chan)}' not in channels`);\n\tif (interruptAfterNodes && interruptAfterNodes !== \"*\") {\n\t\tfor (const node of interruptAfterNodes) if (!(node in nodes)) throw new GraphValidationError(`Node ${String(node)} not in nodes`);\n\t}\n\tif (interruptBeforeNodes && interruptBeforeNodes !== \"*\") {\n\t\tfor (const node of interruptBeforeNodes) if (!(node in nodes)) throw new GraphValidationError(`Node ${String(node)} not in nodes`);\n\t}\n}\nfunction validateKeys(keys, channels) {\n\tif (Array.isArray(keys)) {\n\t\tfor (const key of keys) if (!(key in channels)) throw new Error(`Key ${String(key)} not found in channels`);\n\t} else if (!(keys in channels)) throw new Error(`Key ${String(keys)} not found in channels`);\n}\n\n//#endregion\nexport { validateGraph, validateKeys };\n//# sourceMappingURL=validate.js.map","import { EmptyChannelError } from \"../errors.js\";\nimport { BaseChannel } from \"./base.js\";\n\n//#region src/channels/topic.ts\n/**\n* A configurable PubSub Topic.\n*/\nvar Topic = class Topic extends BaseChannel {\n\tlc_graph_name = \"Topic\";\n\tunique = false;\n\taccumulate = false;\n\tseen;\n\tvalues;\n\tconstructor(fields) {\n\t\tsuper();\n\t\tthis.unique = fields?.unique ?? this.unique;\n\t\tthis.accumulate = fields?.accumulate ?? this.accumulate;\n\t\tthis.seen = /* @__PURE__ */ new Set();\n\t\tthis.values = [];\n\t}\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new Topic({\n\t\t\tunique: this.unique,\n\t\t\taccumulate: this.accumulate\n\t\t});\n\t\tif (typeof checkpoint !== \"undefined\") {\n\t\t\tempty.seen = new Set(checkpoint[0]);\n\t\t\tempty.values = checkpoint[1];\n\t\t}\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tlet updated = false;\n\t\tif (!this.accumulate) {\n\t\t\tupdated = this.values.length > 0;\n\t\t\tthis.values = [];\n\t\t}\n\t\tconst flatValues = values.flat();\n\t\tif (flatValues.length > 0) if (this.unique) {\n\t\t\tfor (const value of flatValues) if (!this.seen.has(value)) {\n\t\t\t\tupdated = true;\n\t\t\t\tthis.seen.add(value);\n\t\t\t\tthis.values.push(value);\n\t\t\t}\n\t\t} else {\n\t\t\tupdated = true;\n\t\t\tthis.values.push(...flatValues);\n\t\t}\n\t\treturn updated;\n\t}\n\tget() {\n\t\tif (this.values.length === 0) throw new EmptyChannelError();\n\t\treturn this.values;\n\t}\n\tcheckpoint() {\n\t\treturn [[...this.seen], this.values];\n\t}\n\tisAvailable() {\n\t\treturn this.values.length !== 0;\n\t}\n};\n\n//#endregion\nexport { Topic };\n//# sourceMappingURL=topic.js.map","import { GraphRecursionError, GraphValueError, InvalidUpdateError } from \"../errors.js\";\nimport { createCheckpoint, emptyChannels, getOnlyChannels } from \"../channels/base.js\";\nimport { CHECKPOINT_NAMESPACE_END, CHECKPOINT_NAMESPACE_SEPARATOR, CONFIG_KEY_CHECKPOINTER, CONFIG_KEY_CHECKPOINT_NS, CONFIG_KEY_DURABILITY, CONFIG_KEY_NODE_FINISHED, CONFIG_KEY_READ, CONFIG_KEY_SEND, CONFIG_KEY_STREAM, CONFIG_KEY_TASK_ID, COPY, END, ERROR, INPUT, INTERRUPT, NULL_TASK_ID, PUSH, TASKS, isInterrupted } from \"../constants.js\";\nimport { ensureLangGraphConfig, getConfig, recastCheckpointNamespace } from \"./utils/config.js\";\nimport { gatherIterator, patchConfigurable } from \"../utils.js\";\nimport { ChannelWrite, PASSTHROUGH } from \"./write.js\";\nimport { PregelNode } from \"./read.js\";\nimport { mapInput, readChannels } from \"./io.js\";\nimport { _coerceToDict, combineAbortSignals, combineCallbacks, getNewChannelVersions, patchCheckpointMap } from \"./utils/index.js\";\nimport { _applyWrites, _localRead, _prepareNextTasks } from \"./algo.js\";\nimport { findSubgraphPregel } from \"./utils/subgraph.js\";\nimport { printStepCheckpoint, printStepTasks, printStepWrites, tasksWithWrites } from \"./debug.js\";\nimport { IterableReadableStreamWithAbortSignal, IterableReadableWritableStream, toEventStream } from \"./stream.js\";\nimport { PregelLoop } from \"./loop.js\";\nimport { StreamMessagesHandler } from \"./messages.js\";\nimport { PregelRunner } from \"./runner.js\";\nimport { validateGraph, validateKeys } from \"./validate.js\";\nimport { Topic } from \"../channels/topic.js\";\nimport { interrupt } from \"../interrupt.js\";\nimport { SCHEDULED, compareChannelVersions, copyCheckpoint, emptyCheckpoint, uuid5 } from \"@langchain/langgraph-checkpoint\";\nimport { Runnable, RunnableSequence, _coerceToRunnable, getCallbackManagerForConfig, mergeConfigs, patchConfig } from \"@langchain/core/runnables\";\n\n//#region src/pregel/index.ts\n/**\n* Utility class for working with channels in the Pregel system.\n* Provides static methods for subscribing to channels and writing to them.\n*\n* Channels are the communication pathways between nodes in a Pregel graph.\n* They enable message passing and state updates between different parts of the graph.\n*/\nvar Channel = class {\n\tstatic subscribeTo(channels, options) {\n\t\tconst { key, tags } = {\n\t\t\tkey: void 0,\n\t\t\ttags: void 0,\n\t\t\t...options ?? {}\n\t\t};\n\t\tif (Array.isArray(channels) && key !== void 0) throw new Error(\"Can't specify a key when subscribing to multiple channels\");\n\t\tlet channelMappingOrArray;\n\t\tif (typeof channels === \"string\") if (key) channelMappingOrArray = { [key]: channels };\n\t\telse channelMappingOrArray = [channels];\n\t\telse channelMappingOrArray = Object.fromEntries(channels.map((chan) => [chan, chan]));\n\t\tconst triggers = Array.isArray(channels) ? channels : [channels];\n\t\treturn new PregelNode({\n\t\t\tchannels: channelMappingOrArray,\n\t\t\ttriggers,\n\t\t\ttags\n\t\t});\n\t}\n\t/**\n\t* Creates a ChannelWrite that specifies how to write values to channels.\n\t* This is used to define how nodes send output to channels.\n\t*\n\t* @example\n\t* ```typescript\n\t* // Write to multiple channels\n\t* const write = Channel.writeTo([\"output\", \"state\"]);\n\t*\n\t* // Write with specific values\n\t* const write = Channel.writeTo([\"output\"], {\n\t*   state: \"completed\",\n\t*   result: calculateResult()\n\t* });\n\t*\n\t* // Write with a transformation function\n\t* const write = Channel.writeTo([\"output\"], {\n\t*   result: (x) => processResult(x)\n\t* });\n\t* ```\n\t*\n\t* @param channels - Array of channel names to write to\n\t* @param writes - Optional map of channel names to values or transformations\n\t* @returns A ChannelWrite object that can be used to write to the specified channels\n\t*/\n\tstatic writeTo(channels, writes) {\n\t\tconst channelWriteEntries = [];\n\t\tfor (const channel of channels) channelWriteEntries.push({\n\t\t\tchannel,\n\t\t\tvalue: PASSTHROUGH,\n\t\t\tskipNone: false\n\t\t});\n\t\tfor (const [key, value] of Object.entries(writes ?? {})) if (Runnable.isRunnable(value) || typeof value === \"function\") channelWriteEntries.push({\n\t\t\tchannel: key,\n\t\t\tvalue: PASSTHROUGH,\n\t\t\tskipNone: true,\n\t\t\tmapper: _coerceToRunnable(value)\n\t\t});\n\t\telse channelWriteEntries.push({\n\t\t\tchannel: key,\n\t\t\tvalue,\n\t\t\tskipNone: false\n\t\t});\n\t\treturn new ChannelWrite(channelWriteEntries);\n\t}\n};\nvar PartialRunnable = class extends Runnable {\n\tlc_namespace = [\"langgraph\", \"pregel\"];\n\tinvoke(_input, _options) {\n\t\tthrow new Error(\"Not implemented\");\n\t}\n\twithConfig(_config) {\n\t\treturn super.withConfig(_config);\n\t}\n\tstream(input, options) {\n\t\treturn super.stream(input, options);\n\t}\n};\n/**\n* The Pregel class is the core runtime engine of LangGraph, implementing a message-passing graph computation model\n* inspired by [Google's Pregel system](https://research.google/pubs/pregel-a-system-for-large-scale-graph-processing/).\n* It provides the foundation for building reliable, controllable agent workflows that can evolve state over time.\n*\n* Key features:\n* - Message passing between nodes in discrete \"supersteps\"\n* - Built-in persistence layer through checkpointers\n* - First-class streaming support for values, updates, and events\n* - Human-in-the-loop capabilities via interrupts\n* - Support for parallel node execution within supersteps\n*\n* The Pregel class is not intended to be instantiated directly by consumers. Instead, use the following higher-level APIs:\n* - {@link StateGraph}: The main graph class for building agent workflows\n*   - Compiling a {@link StateGraph} will return a {@link CompiledGraph} instance, which extends `Pregel`\n* - Functional API: A declarative approach using tasks and entrypoints\n*   - A `Pregel` instance is returned by the {@link entrypoint} function\n*\n* @example\n* ```typescript\n* // Using StateGraph API\n* const graph = new StateGraph(annotation)\n*   .addNode(\"nodeA\", myNodeFunction)\n*   .addEdge(\"nodeA\", \"nodeB\")\n*   .compile();\n*\n* // The compiled graph is a Pregel instance\n* const result = await graph.invoke(input);\n* ```\n*\n* @example\n* ```typescript\n* // Using Functional API\n* import { task, entrypoint } from \"@langchain/langgraph\";\n* import { MemorySaver } from \"@langchain/langgraph-checkpoint\";\n*\n* // Define tasks that can be composed\n* const addOne = task(\"add\", async (x: number) => x + 1);\n*\n* // Create a workflow using the entrypoint function\n* const workflow = entrypoint({\n*   name: \"workflow\",\n*   checkpointer: new MemorySaver()\n* }, async (numbers: number[]) => {\n*   // Tasks can be run in parallel\n*   const results = await Promise.all(numbers.map(n => addOne(n)));\n*   return results;\n* });\n*\n* // The workflow is a Pregel instance\n* const result = await workflow.invoke([1, 2, 3]); // Returns [2, 3, 4]\n* ```\n*\n* @typeParam Nodes - Mapping of node names to their {@link PregelNode} implementations\n* @typeParam Channels - Mapping of channel names to their {@link BaseChannel} or {@link ManagedValueSpec} implementations\n* @typeParam ContextType - Type of context that can be passed to the graph\n* @typeParam InputType - Type of input values accepted by the graph\n* @typeParam OutputType - Type of output values produced by the graph\n*/\nvar Pregel = class extends PartialRunnable {\n\t/**\n\t* Name of the class when serialized\n\t* @internal\n\t*/\n\tstatic lc_name() {\n\t\treturn \"LangGraph\";\n\t}\n\t/** @internal LangChain namespace for serialization necessary because Pregel extends Runnable */\n\tlc_namespace = [\"langgraph\", \"pregel\"];\n\t/** @internal Flag indicating this is a Pregel instance - necessary for serialization */\n\tlg_is_pregel = true;\n\t/** The nodes in the graph, mapping node names to their PregelNode instances */\n\tnodes;\n\t/** The channels in the graph, mapping channel names to their BaseChannel or ManagedValueSpec instances */\n\tchannels;\n\t/**\n\t* The input channels for the graph. These channels receive the initial input when the graph is invoked.\n\t* Can be a single channel key or an array of channel keys.\n\t*/\n\tinputChannels;\n\t/**\n\t* The output channels for the graph. These channels contain the final output when the graph completes.\n\t* Can be a single channel key or an array of channel keys.\n\t*/\n\toutputChannels;\n\t/** Whether to automatically validate the graph structure when it is compiled. Defaults to true. */\n\tautoValidate = true;\n\t/**\n\t* The streaming modes enabled for this graph. Defaults to [\"values\"].\n\t* Supported modes:\n\t* - \"values\": Streams the full state after each step\n\t* - \"updates\": Streams state updates after each step\n\t* - \"messages\": Streams messages from within nodes\n\t* - \"custom\": Streams custom events from within nodes\n\t* - \"debug\": Streams events related to the execution of the graph - useful for tracing & debugging graph execution\n\t*/\n\tstreamMode = [\"values\"];\n\t/**\n\t* Optional channels to stream. If not specified, all channels will be streamed.\n\t* Can be a single channel key or an array of channel keys.\n\t*/\n\tstreamChannels;\n\t/**\n\t* Optional array of node names or \"all\" to interrupt after executing these nodes.\n\t* Used for implementing human-in-the-loop workflows.\n\t*/\n\tinterruptAfter;\n\t/**\n\t* Optional array of node names or \"all\" to interrupt before executing these nodes.\n\t* Used for implementing human-in-the-loop workflows.\n\t*/\n\tinterruptBefore;\n\t/** Optional timeout in milliseconds for the execution of each superstep */\n\tstepTimeout;\n\t/** Whether to enable debug logging. Defaults to false. */\n\tdebug = false;\n\t/**\n\t* Optional checkpointer for persisting graph state.\n\t* When provided, saves a checkpoint of the graph state at every superstep.\n\t* When false or undefined, checkpointing is disabled, and the graph will not be able to save or restore state.\n\t*/\n\tcheckpointer;\n\t/** Optional retry policy for handling failures in node execution */\n\tretryPolicy;\n\t/** The default configuration for graph execution, can be overridden on a per-invocation basis */\n\tconfig;\n\t/**\n\t* Optional long-term memory store for the graph, allows for persistence & retrieval of data across threads\n\t*/\n\tstore;\n\t/**\n\t* Optional cache for the graph, useful for caching tasks.\n\t*/\n\tcache;\n\t/**\n\t* Optional interrupt helper function.\n\t* @internal\n\t*/\n\tuserInterrupt;\n\t/**\n\t* The trigger to node mapping for the graph run.\n\t* @internal\n\t*/\n\ttriggerToNodes = {};\n\t/**\n\t* Constructor for Pregel - meant for internal use only.\n\t*\n\t* @internal\n\t*/\n\tconstructor(fields) {\n\t\tsuper(fields);\n\t\tlet { streamMode } = fields;\n\t\tif (streamMode != null && !Array.isArray(streamMode)) streamMode = [streamMode];\n\t\tthis.nodes = fields.nodes;\n\t\tthis.channels = fields.channels;\n\t\tif (TASKS in this.channels && \"lc_graph_name\" in this.channels[TASKS] && this.channels[TASKS].lc_graph_name !== \"Topic\") throw new Error(`Channel '${TASKS}' is reserved and cannot be used in the graph.`);\n\t\telse this.channels[TASKS] = new Topic({ accumulate: false });\n\t\tthis.autoValidate = fields.autoValidate ?? this.autoValidate;\n\t\tthis.streamMode = streamMode ?? this.streamMode;\n\t\tthis.inputChannels = fields.inputChannels;\n\t\tthis.outputChannels = fields.outputChannels;\n\t\tthis.streamChannels = fields.streamChannels ?? this.streamChannels;\n\t\tthis.interruptAfter = fields.interruptAfter;\n\t\tthis.interruptBefore = fields.interruptBefore;\n\t\tthis.stepTimeout = fields.stepTimeout ?? this.stepTimeout;\n\t\tthis.debug = fields.debug ?? this.debug;\n\t\tthis.checkpointer = fields.checkpointer;\n\t\tthis.retryPolicy = fields.retryPolicy;\n\t\tthis.config = fields.config;\n\t\tthis.store = fields.store;\n\t\tthis.cache = fields.cache;\n\t\tthis.name = fields.name;\n\t\tthis.triggerToNodes = fields.triggerToNodes ?? this.triggerToNodes;\n\t\tthis.userInterrupt = fields.userInterrupt;\n\t\tif (this.autoValidate) this.validate();\n\t}\n\t/**\n\t* Creates a new instance of the Pregel graph with updated configuration.\n\t* This method follows the immutable pattern - instead of modifying the current instance,\n\t* it returns a new instance with the merged configuration.\n\t*\n\t* @example\n\t* ```typescript\n\t* // Create a new instance with debug enabled\n\t* const debugGraph = graph.withConfig({ debug: true });\n\t*\n\t* // Create a new instance with a specific thread ID\n\t* const threadGraph = graph.withConfig({\n\t*   configurable: { thread_id: \"123\" }\n\t* });\n\t* ```\n\t*\n\t* @param config - The configuration to merge with the current configuration\n\t* @returns A new Pregel instance with the merged configuration\n\t*/\n\twithConfig(config) {\n\t\tconst mergedConfig = mergeConfigs(this.config, config);\n\t\treturn new this.constructor({\n\t\t\t...this,\n\t\t\tconfig: mergedConfig\n\t\t});\n\t}\n\t/**\n\t* Validates the graph structure to ensure it is well-formed.\n\t* Checks for:\n\t* - No orphaned nodes\n\t* - Valid input/output channel configurations\n\t* - Valid interrupt configurations\n\t*\n\t* @returns this - The Pregel instance for method chaining\n\t* @throws {GraphValidationError} If the graph structure is invalid\n\t*/\n\tvalidate() {\n\t\tvalidateGraph({\n\t\t\tnodes: this.nodes,\n\t\t\tchannels: this.channels,\n\t\t\toutputChannels: this.outputChannels,\n\t\t\tinputChannels: this.inputChannels,\n\t\t\tstreamChannels: this.streamChannels,\n\t\t\tinterruptAfterNodes: this.interruptAfter,\n\t\t\tinterruptBeforeNodes: this.interruptBefore\n\t\t});\n\t\tfor (const [name, node] of Object.entries(this.nodes)) for (const trigger of node.triggers) {\n\t\t\tthis.triggerToNodes[trigger] ??= [];\n\t\t\tthis.triggerToNodes[trigger].push(name);\n\t\t}\n\t\treturn this;\n\t}\n\t/**\n\t* Gets a list of all channels that should be streamed.\n\t* If streamChannels is specified, returns those channels.\n\t* Otherwise, returns all channels in the graph.\n\t*\n\t* @returns Array of channel keys to stream\n\t*/\n\tget streamChannelsList() {\n\t\tif (Array.isArray(this.streamChannels)) return this.streamChannels;\n\t\telse if (this.streamChannels) return [this.streamChannels];\n\t\telse return Object.keys(this.channels);\n\t}\n\t/**\n\t* Gets the channels to stream in their original format.\n\t* If streamChannels is specified, returns it as-is (either single key or array).\n\t* Otherwise, returns all channels in the graph as an array.\n\t*\n\t* @returns Channel keys to stream, either as a single key or array\n\t*/\n\tget streamChannelsAsIs() {\n\t\tif (this.streamChannels) return this.streamChannels;\n\t\telse return Object.keys(this.channels);\n\t}\n\t/**\n\t* Gets a drawable representation of the graph structure.\n\t* This is an async version of getGraph() and is the preferred method to use.\n\t*\n\t* @param config - Configuration for generating the graph visualization\n\t* @returns A representation of the graph that can be visualized\n\t*/\n\tasync getGraphAsync(config) {\n\t\treturn this.getGraph(config);\n\t}\n\t/**\n\t* Gets all subgraphs within this graph.\n\t* A subgraph is a Pregel instance that is nested within a node of this graph.\n\t*\n\t* @deprecated Use getSubgraphsAsync instead. The async method will become the default in the next minor release.\n\t* @param namespace - Optional namespace to filter subgraphs\n\t* @param recurse - Whether to recursively get subgraphs of subgraphs\n\t* @returns Generator yielding tuples of [name, subgraph]\n\t*/\n\t*getSubgraphs(namespace, recurse) {\n\t\tfor (const [name, node] of Object.entries(this.nodes)) {\n\t\t\tif (namespace !== void 0) {\n\t\t\t\tif (!namespace.startsWith(name)) continue;\n\t\t\t}\n\t\t\tconst candidates = node.subgraphs?.length ? node.subgraphs : [node.bound];\n\t\t\tfor (const candidate of candidates) {\n\t\t\t\tconst graph = findSubgraphPregel(candidate);\n\t\t\t\tif (graph !== void 0) {\n\t\t\t\t\tif (name === namespace) {\n\t\t\t\t\t\tyield [name, graph];\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tif (namespace === void 0) yield [name, graph];\n\t\t\t\t\tif (recurse) {\n\t\t\t\t\t\tlet newNamespace = namespace;\n\t\t\t\t\t\tif (namespace !== void 0) newNamespace = namespace.slice(name.length + 1);\n\t\t\t\t\t\tfor (const [subgraphName, subgraph] of graph.getSubgraphs(newNamespace, recurse)) yield [`${name}${CHECKPOINT_NAMESPACE_SEPARATOR}${subgraphName}`, subgraph];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t/**\n\t* Gets all subgraphs within this graph asynchronously.\n\t* A subgraph is a Pregel instance that is nested within a node of this graph.\n\t*\n\t* @param namespace - Optional namespace to filter subgraphs\n\t* @param recurse - Whether to recursively get subgraphs of subgraphs\n\t* @returns AsyncGenerator yielding tuples of [name, subgraph]\n\t*/\n\tasync *getSubgraphsAsync(namespace, recurse) {\n\t\tyield* this.getSubgraphs(namespace, recurse);\n\t}\n\t/**\n\t* Prepares a state snapshot from saved checkpoint data.\n\t* This is an internal method used by getState and getStateHistory.\n\t*\n\t* @param config - Configuration for preparing the snapshot\n\t* @param saved - Optional saved checkpoint data\n\t* @param subgraphCheckpointer - Optional checkpointer for subgraphs\n\t* @param applyPendingWrites - Whether to apply pending writes to tasks and then to channels\n\t* @returns A snapshot of the graph state\n\t* @internal\n\t*/\n\tasync _prepareStateSnapshot({ config, saved, subgraphCheckpointer, applyPendingWrites = false }) {\n\t\tif (saved === void 0) return {\n\t\t\tvalues: {},\n\t\t\tnext: [],\n\t\t\tconfig,\n\t\t\ttasks: []\n\t\t};\n\t\tconst channels = emptyChannels(this.channels, saved.checkpoint);\n\t\tif (saved.pendingWrites?.length) {\n\t\t\tconst nullWrites = saved.pendingWrites.filter(([taskId, _]) => taskId === NULL_TASK_ID).map(([_, channel, value]) => [String(channel), value]);\n\t\t\tif (nullWrites.length > 0) _applyWrites(saved.checkpoint, channels, [{\n\t\t\t\tname: INPUT,\n\t\t\t\twrites: nullWrites,\n\t\t\t\ttriggers: []\n\t\t\t}], void 0, this.triggerToNodes);\n\t\t}\n\t\tconst nextTasks = Object.values(_prepareNextTasks(saved.checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, {\n\t\t\tstep: (saved.metadata?.step ?? -1) + 1,\n\t\t\tstore: this.store\n\t\t}));\n\t\tconst subgraphs = await gatherIterator(this.getSubgraphsAsync());\n\t\tconst parentNamespace = saved.config.configurable?.checkpoint_ns ?? \"\";\n\t\tconst taskStates = {};\n\t\tfor (const task of nextTasks) {\n\t\t\tconst matchingSubgraph = subgraphs.find(([name]) => name === task.name);\n\t\t\tif (!matchingSubgraph) continue;\n\t\t\tlet taskNs = `${String(task.name)}${CHECKPOINT_NAMESPACE_END}${task.id}`;\n\t\t\tif (parentNamespace) taskNs = `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${taskNs}`;\n\t\t\tif (subgraphCheckpointer === void 0) {\n\t\t\t\tconst config$1 = { configurable: {\n\t\t\t\t\tthread_id: saved.config.configurable?.thread_id,\n\t\t\t\t\tcheckpoint_ns: taskNs\n\t\t\t\t} };\n\t\t\t\ttaskStates[task.id] = config$1;\n\t\t\t} else {\n\t\t\t\tconst subgraphConfig = { configurable: {\n\t\t\t\t\t[CONFIG_KEY_CHECKPOINTER]: subgraphCheckpointer,\n\t\t\t\t\tthread_id: saved.config.configurable?.thread_id,\n\t\t\t\t\tcheckpoint_ns: taskNs\n\t\t\t\t} };\n\t\t\t\tconst pregel = matchingSubgraph[1];\n\t\t\t\ttaskStates[task.id] = await pregel.getState(subgraphConfig, { subgraphs: true });\n\t\t\t}\n\t\t}\n\t\tif (applyPendingWrites && saved.pendingWrites?.length) {\n\t\t\tconst nextTaskById = Object.fromEntries(nextTasks.map((task) => [task.id, task]));\n\t\t\tfor (const [taskId, channel, value] of saved.pendingWrites) {\n\t\t\t\tif ([\n\t\t\t\t\tERROR,\n\t\t\t\t\tINTERRUPT,\n\t\t\t\t\tSCHEDULED\n\t\t\t\t].includes(channel)) continue;\n\t\t\t\tif (!(taskId in nextTaskById)) continue;\n\t\t\t\tnextTaskById[taskId].writes.push([String(channel), value]);\n\t\t\t}\n\t\t\tconst tasksWithWrites$1 = nextTasks.filter((task) => task.writes.length > 0);\n\t\t\tif (tasksWithWrites$1.length > 0) _applyWrites(saved.checkpoint, channels, tasksWithWrites$1, void 0, this.triggerToNodes);\n\t\t}\n\t\tlet metadata = saved?.metadata;\n\t\tif (metadata && saved?.config?.configurable?.thread_id) metadata = {\n\t\t\t...metadata,\n\t\t\tthread_id: saved.config.configurable.thread_id\n\t\t};\n\t\tconst nextList = nextTasks.filter((task) => task.writes.length === 0).map((task) => task.name);\n\t\treturn {\n\t\t\tvalues: readChannels(channels, this.streamChannelsAsIs),\n\t\t\tnext: nextList,\n\t\t\ttasks: tasksWithWrites(nextTasks, saved?.pendingWrites ?? [], taskStates, this.streamChannelsAsIs),\n\t\t\tmetadata,\n\t\t\tconfig: patchCheckpointMap(saved.config, saved.metadata),\n\t\t\tcreatedAt: saved.checkpoint.ts,\n\t\t\tparentConfig: saved.parentConfig\n\t\t};\n\t}\n\t/**\n\t* Gets the current state of the graph.\n\t* Requires a checkpointer to be configured.\n\t*\n\t* @param config - Configuration for retrieving the state\n\t* @param options - Additional options\n\t* @returns A snapshot of the current graph state\n\t* @throws {GraphValueError} If no checkpointer is configured\n\t*/\n\tasync getState(config, options) {\n\t\tconst checkpointer = config.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;\n\t\tif (!checkpointer) throw new GraphValueError(\"No checkpointer set\", { lc_error_code: \"MISSING_CHECKPOINTER\" });\n\t\tconst checkpointNamespace = config.configurable?.checkpoint_ns ?? \"\";\n\t\tif (checkpointNamespace !== \"\" && config.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {\n\t\t\tconst recastNamespace = recastCheckpointNamespace(checkpointNamespace);\n\t\t\tfor await (const [name, subgraph] of this.getSubgraphsAsync(recastNamespace, true)) if (name === recastNamespace) return await subgraph.getState(patchConfigurable(config, { [CONFIG_KEY_CHECKPOINTER]: checkpointer }), { subgraphs: options?.subgraphs });\n\t\t\tthrow new Error(`Subgraph with namespace \"${recastNamespace}\" not found.`);\n\t\t}\n\t\tconst mergedConfig = mergeConfigs(this.config, config);\n\t\tconst saved = await checkpointer.getTuple(config);\n\t\tconst snapshot = await this._prepareStateSnapshot({\n\t\t\tconfig: mergedConfig,\n\t\t\tsaved,\n\t\t\tsubgraphCheckpointer: options?.subgraphs ? checkpointer : void 0,\n\t\t\tapplyPendingWrites: !config.configurable?.checkpoint_id\n\t\t});\n\t\treturn snapshot;\n\t}\n\t/**\n\t* Gets the history of graph states.\n\t* Requires a checkpointer to be configured.\n\t* Useful for:\n\t* - Debugging execution history\n\t* - Implementing time travel\n\t* - Analyzing graph behavior\n\t*\n\t* @param config - Configuration for retrieving the history\n\t* @param options - Options for filtering the history\n\t* @returns An async iterator of state snapshots\n\t* @throws {Error} If no checkpointer is configured\n\t*/\n\tasync *getStateHistory(config, options) {\n\t\tconst checkpointer = config.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;\n\t\tif (!checkpointer) throw new GraphValueError(\"No checkpointer set\", { lc_error_code: \"MISSING_CHECKPOINTER\" });\n\t\tconst checkpointNamespace = config.configurable?.checkpoint_ns ?? \"\";\n\t\tif (checkpointNamespace !== \"\" && config.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {\n\t\t\tconst recastNamespace = recastCheckpointNamespace(checkpointNamespace);\n\t\t\tfor await (const [name, pregel] of this.getSubgraphsAsync(recastNamespace, true)) if (name === recastNamespace) {\n\t\t\t\tyield* pregel.getStateHistory(patchConfigurable(config, { [CONFIG_KEY_CHECKPOINTER]: checkpointer }), options);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tthrow new Error(`Subgraph with namespace \"${recastNamespace}\" not found.`);\n\t\t}\n\t\tconst mergedConfig = mergeConfigs(this.config, config, { configurable: { checkpoint_ns: checkpointNamespace } });\n\t\tfor await (const checkpointTuple of checkpointer.list(mergedConfig, options)) yield this._prepareStateSnapshot({\n\t\t\tconfig: checkpointTuple.config,\n\t\t\tsaved: checkpointTuple\n\t\t});\n\t}\n\t/**\n\t* Apply updates to the graph state in bulk.\n\t* Requires a checkpointer to be configured.\n\t*\n\t* This method is useful for recreating a thread\n\t* from a list of updates, especially if a checkpoint\n\t* is created as a result of multiple tasks.\n\t*\n\t* @internal The API might change in the future.\n\t*\n\t* @param startConfig - Configuration for the update\n\t* @param updates - The list of updates to apply to graph state\n\t* @returns Updated configuration\n\t* @throws {GraphValueError} If no checkpointer is configured\n\t* @throws {InvalidUpdateError} If the update cannot be attributed to a node or an update can be only applied in sequence.\n\t*/\n\tasync bulkUpdateState(startConfig, supersteps) {\n\t\tconst checkpointer = startConfig.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;\n\t\tif (!checkpointer) throw new GraphValueError(\"No checkpointer set\", { lc_error_code: \"MISSING_CHECKPOINTER\" });\n\t\tif (supersteps.length === 0) throw new Error(\"No supersteps provided\");\n\t\tif (supersteps.some((s) => s.updates.length === 0)) throw new Error(\"No updates provided\");\n\t\tconst checkpointNamespace = startConfig.configurable?.checkpoint_ns ?? \"\";\n\t\tif (checkpointNamespace !== \"\" && startConfig.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {\n\t\t\tconst recastNamespace = recastCheckpointNamespace(checkpointNamespace);\n\t\t\tfor await (const [, pregel] of this.getSubgraphsAsync(recastNamespace, true)) return await pregel.bulkUpdateState(patchConfigurable(startConfig, { [CONFIG_KEY_CHECKPOINTER]: checkpointer }), supersteps);\n\t\t\tthrow new Error(`Subgraph \"${recastNamespace}\" not found`);\n\t\t}\n\t\tconst updateSuperStep = async (inputConfig, updates) => {\n\t\t\tconst config = this.config ? mergeConfigs(this.config, inputConfig) : inputConfig;\n\t\t\tconst saved = await checkpointer.getTuple(config);\n\t\t\tconst checkpoint = saved !== void 0 ? copyCheckpoint(saved.checkpoint) : emptyCheckpoint();\n\t\t\tconst checkpointPreviousVersions = { ...saved?.checkpoint.channel_versions };\n\t\t\tconst step = saved?.metadata?.step ?? -1;\n\t\t\tlet checkpointConfig = patchConfigurable(config, { checkpoint_ns: config.configurable?.checkpoint_ns ?? \"\" });\n\t\t\tlet checkpointMetadata = config.metadata ?? {};\n\t\t\tif (saved?.config.configurable) {\n\t\t\t\tcheckpointConfig = patchConfigurable(config, saved.config.configurable);\n\t\t\t\tcheckpointMetadata = {\n\t\t\t\t\t...saved.metadata,\n\t\t\t\t\t...checkpointMetadata\n\t\t\t\t};\n\t\t\t}\n\t\t\tconst { values, asNode } = updates[0];\n\t\t\tif (values == null && asNode === void 0) {\n\t\t\t\tif (updates.length > 1) throw new InvalidUpdateError(`Cannot create empty checkpoint with multiple updates`);\n\t\t\t\tconst nextConfig$1 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, void 0, step), {\n\t\t\t\t\tsource: \"update\",\n\t\t\t\t\tstep: step + 1,\n\t\t\t\t\tparents: saved?.metadata?.parents ?? {}\n\t\t\t\t}, {});\n\t\t\t\treturn patchCheckpointMap(nextConfig$1, saved ? saved.metadata : void 0);\n\t\t\t}\n\t\t\tconst channels = emptyChannels(this.channels, checkpoint);\n\t\t\tif (values === null && asNode === END) {\n\t\t\t\tif (updates.length > 1) throw new InvalidUpdateError(`Cannot apply multiple updates when clearing state`);\n\t\t\t\tif (saved) {\n\t\t\t\t\tconst nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites || [], this.nodes, channels, saved.config, true, {\n\t\t\t\t\t\tstep: (saved.metadata?.step ?? -1) + 1,\n\t\t\t\t\t\tcheckpointer,\n\t\t\t\t\t\tstore: this.store\n\t\t\t\t\t});\n\t\t\t\t\tconst nullWrites = (saved.pendingWrites || []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));\n\t\t\t\t\tif (nullWrites.length > 0) _applyWrites(checkpoint, channels, [{\n\t\t\t\t\t\tname: INPUT,\n\t\t\t\t\t\twrites: nullWrites,\n\t\t\t\t\t\ttriggers: []\n\t\t\t\t\t}], checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);\n\t\t\t\t\tfor (const [taskId, k, v] of saved.pendingWrites || []) {\n\t\t\t\t\t\tif ([\n\t\t\t\t\t\t\tERROR,\n\t\t\t\t\t\t\tINTERRUPT,\n\t\t\t\t\t\t\tSCHEDULED\n\t\t\t\t\t\t].includes(k)) continue;\n\t\t\t\t\t\tif (!(taskId in nextTasks)) continue;\n\t\t\t\t\t\tnextTasks[taskId].writes.push([k, v]);\n\t\t\t\t\t}\n\t\t\t\t\t_applyWrites(checkpoint, channels, Object.values(nextTasks), checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);\n\t\t\t\t}\n\t\t\t\tconst nextConfig$1 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, step), {\n\t\t\t\t\t...checkpointMetadata,\n\t\t\t\t\tsource: \"update\",\n\t\t\t\t\tstep: step + 1,\n\t\t\t\t\tparents: saved?.metadata?.parents ?? {}\n\t\t\t\t}, getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions));\n\t\t\t\treturn patchCheckpointMap(nextConfig$1, saved ? saved.metadata : void 0);\n\t\t\t}\n\t\t\tif (asNode === COPY) {\n\t\t\t\tif (updates.length > 1) throw new InvalidUpdateError(`Cannot copy checkpoint with multiple updates`);\n\t\t\t\tif (saved == null) throw new InvalidUpdateError(`Cannot copy a non-existent checkpoint`);\n\t\t\t\tconst isCopyWithUpdates = (values$1) => {\n\t\t\t\t\tif (!Array.isArray(values$1)) return false;\n\t\t\t\t\tif (values$1.length === 0) return false;\n\t\t\t\t\treturn values$1.every((v) => Array.isArray(v) && v.length === 2);\n\t\t\t\t};\n\t\t\t\tconst nextCheckpoint = createCheckpoint(checkpoint, void 0, step);\n\t\t\t\tconst nextConfig$1 = await checkpointer.put(saved.parentConfig ?? patchConfigurable(saved.config, { checkpoint_id: void 0 }), nextCheckpoint, {\n\t\t\t\t\tsource: \"fork\",\n\t\t\t\t\tstep: step + 1,\n\t\t\t\t\tparents: saved.metadata?.parents ?? {}\n\t\t\t\t}, {});\n\t\t\t\tif (isCopyWithUpdates(values)) {\n\t\t\t\t\tconst nextTasks = _prepareNextTasks(nextCheckpoint, saved.pendingWrites, this.nodes, channels, nextConfig$1, false, { step: step + 2 });\n\t\t\t\t\tconst tasksGroupBy = Object.values(nextTasks).reduce((acc, { name, id }) => {\n\t\t\t\t\t\tacc[name] ??= [];\n\t\t\t\t\t\tacc[name].push({ id });\n\t\t\t\t\t\treturn acc;\n\t\t\t\t\t}, {});\n\t\t\t\t\tconst userGroupBy = values.reduce((acc, item) => {\n\t\t\t\t\t\tconst [values$1, asNode$1] = item;\n\t\t\t\t\t\tacc[asNode$1] ??= [];\n\t\t\t\t\t\tconst targetIdx = acc[asNode$1].length;\n\t\t\t\t\t\tconst taskId = tasksGroupBy[asNode$1]?.[targetIdx]?.id;\n\t\t\t\t\t\tacc[asNode$1].push({\n\t\t\t\t\t\t\tvalues: values$1,\n\t\t\t\t\t\t\tasNode: asNode$1,\n\t\t\t\t\t\t\ttaskId\n\t\t\t\t\t\t});\n\t\t\t\t\t\treturn acc;\n\t\t\t\t\t}, {});\n\t\t\t\t\treturn updateSuperStep(patchCheckpointMap(nextConfig$1, saved.metadata), Object.values(userGroupBy).flat());\n\t\t\t\t}\n\t\t\t\treturn patchCheckpointMap(nextConfig$1, saved.metadata);\n\t\t\t}\n\t\t\tif (asNode === INPUT) {\n\t\t\t\tif (updates.length > 1) throw new InvalidUpdateError(`Cannot apply multiple updates when updating as input`);\n\t\t\t\tconst inputWrites = await gatherIterator(mapInput(this.inputChannels, values));\n\t\t\t\tif (inputWrites.length === 0) throw new InvalidUpdateError(`Received no input writes for ${JSON.stringify(this.inputChannels, null, 2)}`);\n\t\t\t\t_applyWrites(checkpoint, channels, [{\n\t\t\t\t\tname: INPUT,\n\t\t\t\t\twrites: inputWrites,\n\t\t\t\t\ttriggers: []\n\t\t\t\t}], checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);\n\t\t\t\tconst nextStep = saved?.metadata?.step != null ? saved.metadata.step + 1 : -1;\n\t\t\t\tconst nextConfig$1 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, nextStep), {\n\t\t\t\t\tsource: \"input\",\n\t\t\t\t\tstep: nextStep,\n\t\t\t\t\tparents: saved?.metadata?.parents ?? {}\n\t\t\t\t}, getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions));\n\t\t\t\tawait checkpointer.putWrites(nextConfig$1, inputWrites, uuid5(INPUT, checkpoint.id));\n\t\t\t\treturn patchCheckpointMap(nextConfig$1, saved ? saved.metadata : void 0);\n\t\t\t}\n\t\t\tif (config.configurable?.checkpoint_id === void 0 && saved?.pendingWrites !== void 0 && saved.pendingWrites.length > 0) {\n\t\t\t\tconst nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, {\n\t\t\t\t\tstore: this.store,\n\t\t\t\t\tcheckpointer: this.checkpointer,\n\t\t\t\t\tstep: (saved.metadata?.step ?? -1) + 1\n\t\t\t\t});\n\t\t\t\tconst nullWrites = (saved.pendingWrites ?? []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));\n\t\t\t\tif (nullWrites.length > 0) _applyWrites(saved.checkpoint, channels, [{\n\t\t\t\t\tname: INPUT,\n\t\t\t\t\twrites: nullWrites,\n\t\t\t\t\ttriggers: []\n\t\t\t\t}], void 0, this.triggerToNodes);\n\t\t\t\tfor (const [tid, k, v] of saved.pendingWrites) {\n\t\t\t\t\tif ([\n\t\t\t\t\t\tERROR,\n\t\t\t\t\t\tINTERRUPT,\n\t\t\t\t\t\tSCHEDULED\n\t\t\t\t\t].includes(k) || nextTasks[tid] === void 0) continue;\n\t\t\t\t\tnextTasks[tid].writes.push([k, v]);\n\t\t\t\t}\n\t\t\t\tconst tasks$1 = Object.values(nextTasks).filter((task) => {\n\t\t\t\t\treturn task.writes.length > 0;\n\t\t\t\t});\n\t\t\t\tif (tasks$1.length > 0) _applyWrites(checkpoint, channels, tasks$1, void 0, this.triggerToNodes);\n\t\t\t}\n\t\t\tconst nonNullVersion = Object.values(checkpoint.versions_seen).map((seenVersions) => {\n\t\t\t\treturn Object.values(seenVersions);\n\t\t\t}).flat().find((v) => !!v);\n\t\t\tconst validUpdates = [];\n\t\t\tif (updates.length === 1) {\n\t\t\t\tlet { values: values$1, asNode: asNode$1, taskId } = updates[0];\n\t\t\t\tif (asNode$1 === void 0 && Object.keys(this.nodes).length === 1) [asNode$1] = Object.keys(this.nodes);\n\t\t\t\telse if (asNode$1 === void 0 && nonNullVersion === void 0) {\n\t\t\t\t\tif (typeof this.inputChannels === \"string\" && this.nodes[this.inputChannels] !== void 0) asNode$1 = this.inputChannels;\n\t\t\t\t} else if (asNode$1 === void 0) {\n\t\t\t\t\tconst lastSeenByNode = Object.entries(checkpoint.versions_seen).map(([n, seen]) => {\n\t\t\t\t\t\treturn Object.values(seen).map((v) => {\n\t\t\t\t\t\t\treturn [v, n];\n\t\t\t\t\t\t});\n\t\t\t\t\t}).flat().filter(([_, v]) => v !== INTERRUPT).sort(([aNumber], [bNumber]) => compareChannelVersions(aNumber, bNumber));\n\t\t\t\t\tif (lastSeenByNode) {\n\t\t\t\t\t\tif (lastSeenByNode.length === 1) asNode$1 = lastSeenByNode[0][1];\n\t\t\t\t\t\telse if (lastSeenByNode[lastSeenByNode.length - 1][0] !== lastSeenByNode[lastSeenByNode.length - 2][0]) asNode$1 = lastSeenByNode[lastSeenByNode.length - 1][1];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (asNode$1 === void 0) throw new InvalidUpdateError(`Ambiguous update, specify \"asNode\"`);\n\t\t\t\tvalidUpdates.push({\n\t\t\t\t\tvalues: values$1,\n\t\t\t\t\tasNode: asNode$1,\n\t\t\t\t\ttaskId\n\t\t\t\t});\n\t\t\t} else for (const { asNode: asNode$1, values: values$1, taskId } of updates) {\n\t\t\t\tif (asNode$1 == null) throw new InvalidUpdateError(`\"asNode\" is required when applying multiple updates`);\n\t\t\t\tvalidUpdates.push({\n\t\t\t\t\tvalues: values$1,\n\t\t\t\t\tasNode: asNode$1,\n\t\t\t\t\ttaskId\n\t\t\t\t});\n\t\t\t}\n\t\t\tconst tasks = [];\n\t\t\tfor (const { asNode: asNode$1, values: values$1, taskId } of validUpdates) {\n\t\t\t\tif (this.nodes[asNode$1] === void 0) throw new InvalidUpdateError(`Node \"${asNode$1.toString()}\" does not exist`);\n\t\t\t\tconst writers = this.nodes[asNode$1].getWriters();\n\t\t\t\tif (!writers.length) throw new InvalidUpdateError(`No writers found for node \"${asNode$1.toString()}\"`);\n\t\t\t\ttasks.push({\n\t\t\t\t\tname: asNode$1,\n\t\t\t\t\tinput: values$1,\n\t\t\t\t\tproc: writers.length > 1 ? RunnableSequence.from(writers, { omitSequenceTags: true }) : writers[0],\n\t\t\t\t\twrites: [],\n\t\t\t\t\ttriggers: [INTERRUPT],\n\t\t\t\t\tid: taskId ?? uuid5(INTERRUPT, checkpoint.id),\n\t\t\t\t\twriters: []\n\t\t\t\t});\n\t\t\t}\n\t\t\tfor (const task of tasks) await task.proc.invoke(task.input, patchConfig({\n\t\t\t\t...config,\n\t\t\t\tstore: config?.store ?? this.store\n\t\t\t}, {\n\t\t\t\trunName: config.runName ?? `${this.getName()}UpdateState`,\n\t\t\t\tconfigurable: {\n\t\t\t\t\t[CONFIG_KEY_SEND]: (items) => task.writes.push(...items),\n\t\t\t\t\t[CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, task, select_, fresh_)\n\t\t\t\t}\n\t\t\t}));\n\t\t\tfor (const task of tasks) {\n\t\t\t\tconst channelWrites = task.writes.filter((w) => w[0] !== PUSH);\n\t\t\t\tif (saved !== void 0 && channelWrites.length > 0) await checkpointer.putWrites(checkpointConfig, channelWrites, task.id);\n\t\t\t}\n\t\t\t_applyWrites(checkpoint, channels, tasks, checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);\n\t\t\tconst newVersions = getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions);\n\t\t\tconst nextConfig = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, step + 1), {\n\t\t\t\tsource: \"update\",\n\t\t\t\tstep: step + 1,\n\t\t\t\tparents: saved?.metadata?.parents ?? {}\n\t\t\t}, newVersions);\n\t\t\tfor (const task of tasks) {\n\t\t\t\tconst pushWrites = task.writes.filter((w) => w[0] === PUSH);\n\t\t\t\tif (pushWrites.length > 0) await checkpointer.putWrites(nextConfig, pushWrites, task.id);\n\t\t\t}\n\t\t\treturn patchCheckpointMap(nextConfig, saved ? saved.metadata : void 0);\n\t\t};\n\t\tlet currentConfig = startConfig;\n\t\tfor (const { updates } of supersteps) currentConfig = await updateSuperStep(currentConfig, updates);\n\t\treturn currentConfig;\n\t}\n\t/**\n\t* Updates the state of the graph with new values.\n\t* Requires a checkpointer to be configured.\n\t*\n\t* This method can be used for:\n\t* - Implementing human-in-the-loop workflows\n\t* - Modifying graph state during breakpoints\n\t* - Integrating external inputs into the graph\n\t*\n\t* @param inputConfig - Configuration for the update\n\t* @param values - The values to update the state with\n\t* @param asNode - Optional node name to attribute the update to\n\t* @returns Updated configuration\n\t* @throws {GraphValueError} If no checkpointer is configured\n\t* @throws {InvalidUpdateError} If the update cannot be attributed to a node\n\t*/\n\tasync updateState(inputConfig, values, asNode) {\n\t\treturn this.bulkUpdateState(inputConfig, [{ updates: [{\n\t\t\tvalues,\n\t\t\tasNode\n\t\t}] }]);\n\t}\n\t/**\n\t* Gets the default values for various graph configuration options.\n\t* This is an internal method used to process and normalize configuration options.\n\t*\n\t* @param config - The input configuration options\n\t* @returns A tuple containing normalized values for:\n\t* - debug mode\n\t* - stream modes\n\t* - input keys\n\t* - output keys\n\t* - remaining config\n\t* - interrupt before nodes\n\t* - interrupt after nodes\n\t* - checkpointer\n\t* - store\n\t* - whether stream mode is single\n\t* - node cache\n\t* - whether checkpoint during is enabled\n\t* @internal\n\t*/\n\t_defaults(config) {\n\t\tconst { debug, streamMode, inputKeys, outputKeys, interruptAfter, interruptBefore,...rest } = config;\n\t\tlet streamModeSingle = true;\n\t\tconst defaultDebug = debug !== void 0 ? debug : this.debug;\n\t\tlet defaultOutputKeys = outputKeys;\n\t\tif (defaultOutputKeys === void 0) defaultOutputKeys = this.streamChannelsAsIs;\n\t\telse validateKeys(defaultOutputKeys, this.channels);\n\t\tlet defaultInputKeys = inputKeys;\n\t\tif (defaultInputKeys === void 0) defaultInputKeys = this.inputChannels;\n\t\telse validateKeys(defaultInputKeys, this.channels);\n\t\tconst defaultInterruptBefore = interruptBefore ?? this.interruptBefore ?? [];\n\t\tconst defaultInterruptAfter = interruptAfter ?? this.interruptAfter ?? [];\n\t\tlet defaultStreamMode;\n\t\tif (streamMode !== void 0) {\n\t\t\tdefaultStreamMode = Array.isArray(streamMode) ? streamMode : [streamMode];\n\t\t\tstreamModeSingle = typeof streamMode === \"string\";\n\t\t} else {\n\t\t\tif (config.configurable?.[CONFIG_KEY_TASK_ID] !== void 0) defaultStreamMode = [\"values\"];\n\t\t\telse defaultStreamMode = this.streamMode;\n\t\t\tstreamModeSingle = true;\n\t\t}\n\t\tlet defaultCheckpointer;\n\t\tif (this.checkpointer === false) defaultCheckpointer = void 0;\n\t\telse if (config !== void 0 && config.configurable?.[CONFIG_KEY_CHECKPOINTER] !== void 0) defaultCheckpointer = config.configurable[CONFIG_KEY_CHECKPOINTER];\n\t\telse if (this.checkpointer === true) throw new Error(\"checkpointer: true cannot be used for root graphs.\");\n\t\telse defaultCheckpointer = this.checkpointer;\n\t\tconst defaultStore = config.store ?? this.store;\n\t\tconst defaultCache = config.cache ?? this.cache;\n\t\tif (config.durability != null && config.checkpointDuring != null) throw new Error(\"Cannot use both `durability` and `checkpointDuring` at the same time.\");\n\t\tconst checkpointDuringDurability = (() => {\n\t\t\tif (config.checkpointDuring == null) return void 0;\n\t\t\tif (config.checkpointDuring === false) return \"exit\";\n\t\t\treturn \"async\";\n\t\t})();\n\t\tconst defaultDurability = config.durability ?? checkpointDuringDurability ?? config?.configurable?.[CONFIG_KEY_DURABILITY] ?? \"async\";\n\t\treturn [\n\t\t\tdefaultDebug,\n\t\t\tdefaultStreamMode,\n\t\t\tdefaultInputKeys,\n\t\t\tdefaultOutputKeys,\n\t\t\trest,\n\t\t\tdefaultInterruptBefore,\n\t\t\tdefaultInterruptAfter,\n\t\t\tdefaultCheckpointer,\n\t\t\tdefaultStore,\n\t\t\tstreamModeSingle,\n\t\t\tdefaultCache,\n\t\t\tdefaultDurability\n\t\t];\n\t}\n\t/**\n\t* Streams the execution of the graph, emitting state updates as they occur.\n\t* This is the primary method for observing graph execution in real-time.\n\t*\n\t* Stream modes:\n\t* - \"values\": Emits complete state after each step\n\t* - \"updates\": Emits only state changes after each step\n\t* - \"debug\": Emits detailed debug information\n\t* - \"messages\": Emits messages from within nodes\n\t* - \"custom\": Emits custom events from within nodes\n\t* - \"checkpoints\": Emits checkpoints from within nodes\n\t* - \"tasks\": Emits tasks from within nodes\n\t*\n\t* @param input - The input to start graph execution with\n\t* @param options - Configuration options for streaming\n\t* @returns An async iterable stream of graph state updates\n\t*/\n\tasync stream(input, options) {\n\t\tconst abortController = new AbortController();\n\t\tconst config = {\n\t\t\trecursionLimit: this.config?.recursionLimit,\n\t\t\t...options,\n\t\t\tsignal: combineAbortSignals(options?.signal, abortController.signal).signal\n\t\t};\n\t\tconst stream = await super.stream(input, config);\n\t\treturn new IterableReadableStreamWithAbortSignal(options?.encoding === \"text/event-stream\" ? toEventStream(stream) : stream, abortController);\n\t}\n\tstreamEvents(input, options, streamOptions) {\n\t\tconst abortController = new AbortController();\n\t\tconst config = {\n\t\t\trecursionLimit: this.config?.recursionLimit,\n\t\t\t...options,\n\t\t\tcallbacks: combineCallbacks(this.config?.callbacks, options?.callbacks),\n\t\t\tsignal: combineAbortSignals(options?.signal, abortController.signal).signal\n\t\t};\n\t\treturn new IterableReadableStreamWithAbortSignal(super.streamEvents(input, config, streamOptions), abortController);\n\t}\n\t/**\n\t* Validates the input for the graph.\n\t* @param input - The input to validate\n\t* @returns The validated input\n\t* @internal\n\t*/\n\tasync _validateInput(input) {\n\t\treturn input;\n\t}\n\t/**\n\t* Validates the context options for the graph.\n\t* @param context - The context options to validate\n\t* @returns The validated context options\n\t* @internal\n\t*/\n\tasync _validateContext(context) {\n\t\treturn context;\n\t}\n\t/**\n\t* Internal iterator used by stream() to generate state updates.\n\t* This method handles the core logic of graph execution and streaming.\n\t*\n\t* @param input - The input to start graph execution with\n\t* @param options - Configuration options for streaming\n\t* @returns AsyncGenerator yielding state updates\n\t* @internal\n\t*/\n\tasync *_streamIterator(input, options) {\n\t\tconst streamEncoding = \"version\" in (options ?? {}) ? void 0 : options?.encoding ?? void 0;\n\t\tconst streamSubgraphs = options?.subgraphs;\n\t\tconst inputConfig = ensureLangGraphConfig(this.config, options);\n\t\tif (inputConfig.recursionLimit === void 0 || inputConfig.recursionLimit < 1) throw new Error(`Passed \"recursionLimit\" must be at least 1.`);\n\t\tif (this.checkpointer !== void 0 && this.checkpointer !== false && inputConfig.configurable === void 0) throw new Error(`Checkpointer requires one or more of the following \"configurable\" keys: \"thread_id\", \"checkpoint_ns\", \"checkpoint_id\"`);\n\t\tconst validInput = await this._validateInput(input);\n\t\tconst { runId,...restConfig } = inputConfig;\n\t\tconst [debug, streamMode, , outputKeys, config, interruptBefore, interruptAfter, checkpointer, store, streamModeSingle, cache, durability] = this._defaults(restConfig);\n\t\tif (typeof config.context !== \"undefined\") config.context = await this._validateContext(config.context);\n\t\telse config.configurable = await this._validateContext(config.configurable);\n\t\tconst stream = new IterableReadableWritableStream({ modes: new Set(streamMode) });\n\t\tif (this.checkpointer === true) {\n\t\t\tconfig.configurable ??= {};\n\t\t\tconst ns = config.configurable[CONFIG_KEY_CHECKPOINT_NS] ?? \"\";\n\t\t\tconfig.configurable[CONFIG_KEY_CHECKPOINT_NS] = ns.split(CHECKPOINT_NAMESPACE_SEPARATOR).map((part) => part.split(CHECKPOINT_NAMESPACE_END)[0]).join(CHECKPOINT_NAMESPACE_SEPARATOR);\n\t\t}\n\t\tif (streamMode.includes(\"messages\")) {\n\t\t\tconst messageStreamer = new StreamMessagesHandler((chunk) => stream.push(chunk));\n\t\t\tconst { callbacks } = config;\n\t\t\tif (callbacks === void 0) config.callbacks = [messageStreamer];\n\t\t\telse if (Array.isArray(callbacks)) config.callbacks = callbacks.concat(messageStreamer);\n\t\t\telse {\n\t\t\t\tconst copiedCallbacks = callbacks.copy();\n\t\t\t\tcopiedCallbacks.addHandler(messageStreamer, true);\n\t\t\t\tconfig.callbacks = copiedCallbacks;\n\t\t\t}\n\t\t}\n\t\tconfig.writer ??= (chunk) => {\n\t\t\tif (!streamMode.includes(\"custom\")) return;\n\t\t\tconst ns = (getConfig()?.configurable?.[CONFIG_KEY_CHECKPOINT_NS])?.split(CHECKPOINT_NAMESPACE_SEPARATOR).slice(0, -1);\n\t\t\tstream.push([\n\t\t\t\tns ?? [],\n\t\t\t\t\"custom\",\n\t\t\t\tchunk\n\t\t\t]);\n\t\t};\n\t\tconfig.interrupt ??= this.userInterrupt ?? interrupt;\n\t\tconst callbackManager = await getCallbackManagerForConfig(config);\n\t\tconst runManager = await callbackManager?.handleChainStart(this.toJSON(), _coerceToDict(input, \"input\"), runId, void 0, void 0, void 0, config?.runName ?? this.getName());\n\t\tconst channelSpecs = getOnlyChannels(this.channels);\n\t\tlet loop;\n\t\tlet loopError;\n\t\t/**\n\t\t* The PregelLoop will yield events from concurrent tasks as soon as they are\n\t\t* generated. Each task can push multiple events onto the stream in any order.\n\t\t*\n\t\t* We use a separate background method and stream here in order to yield events\n\t\t* from the loop to the main stream and therefore back to the user as soon as\n\t\t* they are available.\n\t\t*/\n\t\tconst createAndRunLoop = async () => {\n\t\t\ttry {\n\t\t\t\tloop = await PregelLoop.initialize({\n\t\t\t\t\tinput: validInput,\n\t\t\t\t\tconfig,\n\t\t\t\t\tcheckpointer,\n\t\t\t\t\tnodes: this.nodes,\n\t\t\t\t\tchannelSpecs,\n\t\t\t\t\toutputKeys,\n\t\t\t\t\tstreamKeys: this.streamChannelsAsIs,\n\t\t\t\t\tstore,\n\t\t\t\t\tcache,\n\t\t\t\t\tstream,\n\t\t\t\t\tinterruptAfter,\n\t\t\t\t\tinterruptBefore,\n\t\t\t\t\tmanager: runManager,\n\t\t\t\t\tdebug: this.debug,\n\t\t\t\t\ttriggerToNodes: this.triggerToNodes,\n\t\t\t\t\tdurability\n\t\t\t\t});\n\t\t\t\tconst runner = new PregelRunner({\n\t\t\t\t\tloop,\n\t\t\t\t\tnodeFinished: config.configurable?.[CONFIG_KEY_NODE_FINISHED]\n\t\t\t\t});\n\t\t\t\tif (options?.subgraphs) loop.config.configurable = {\n\t\t\t\t\t...loop.config.configurable,\n\t\t\t\t\t[CONFIG_KEY_STREAM]: loop.stream\n\t\t\t\t};\n\t\t\t\tawait this._runLoop({\n\t\t\t\t\tloop,\n\t\t\t\t\trunner,\n\t\t\t\t\tdebug,\n\t\t\t\t\tconfig\n\t\t\t\t});\n\t\t\t\tif (durability === \"sync\") await Promise.all(loop?.checkpointerPromises ?? []);\n\t\t\t} catch (e) {\n\t\t\t\tloopError = e;\n\t\t\t} finally {\n\t\t\t\ttry {\n\t\t\t\t\tif (loop) {\n\t\t\t\t\t\tawait loop.store?.stop();\n\t\t\t\t\t\tawait loop.cache?.stop();\n\t\t\t\t\t}\n\t\t\t\t\tawait Promise.all(loop?.checkpointerPromises ?? []);\n\t\t\t\t} catch (e) {\n\t\t\t\t\tloopError = loopError ?? e;\n\t\t\t\t}\n\t\t\t\tif (loopError) stream.error(loopError);\n\t\t\t\telse stream.close();\n\t\t\t}\n\t\t};\n\t\tconst runLoopPromise = createAndRunLoop();\n\t\ttry {\n\t\t\tfor await (const chunk of stream) {\n\t\t\t\tif (chunk === void 0) throw new Error(\"Data structure error.\");\n\t\t\t\tconst [namespace, mode, payload] = chunk;\n\t\t\t\tif (streamMode.includes(mode)) {\n\t\t\t\t\tif (streamEncoding === \"text/event-stream\") {\n\t\t\t\t\t\tif (streamSubgraphs) yield [\n\t\t\t\t\t\t\tnamespace,\n\t\t\t\t\t\t\tmode,\n\t\t\t\t\t\t\tpayload\n\t\t\t\t\t\t];\n\t\t\t\t\t\telse yield [\n\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\tmode,\n\t\t\t\t\t\t\tpayload\n\t\t\t\t\t\t];\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (streamSubgraphs && !streamModeSingle) yield [\n\t\t\t\t\t\tnamespace,\n\t\t\t\t\t\tmode,\n\t\t\t\t\t\tpayload\n\t\t\t\t\t];\n\t\t\t\t\telse if (!streamModeSingle) yield [mode, payload];\n\t\t\t\t\telse if (streamSubgraphs) yield [namespace, payload];\n\t\t\t\t\telse yield payload;\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tawait runManager?.handleChainError(loopError);\n\t\t\tthrow e;\n\t\t} finally {\n\t\t\tawait runLoopPromise;\n\t\t}\n\t\tawait runManager?.handleChainEnd(loop?.output ?? {}, runId, void 0, void 0, void 0);\n\t}\n\t/**\n\t* Run the graph with a single input and config.\n\t* @param input The input to the graph.\n\t* @param options The configuration to use for the run.\n\t*/\n\tasync invoke(input, options) {\n\t\tconst streamMode = options?.streamMode ?? \"values\";\n\t\tconst config = {\n\t\t\t...options,\n\t\t\toutputKeys: options?.outputKeys ?? this.outputChannels,\n\t\t\tstreamMode,\n\t\t\tencoding: void 0\n\t\t};\n\t\tconst chunks = [];\n\t\tconst stream = await this.stream(input, config);\n\t\tconst interruptChunks = [];\n\t\tlet latest;\n\t\tfor await (const chunk of stream) if (streamMode === \"values\") if (isInterrupted(chunk)) interruptChunks.push(chunk[INTERRUPT]);\n\t\telse latest = chunk;\n\t\telse chunks.push(chunk);\n\t\tif (streamMode === \"values\") {\n\t\t\tif (interruptChunks.length > 0) {\n\t\t\t\tconst interrupts = interruptChunks.flat(1);\n\t\t\t\tif (latest == null) return { [INTERRUPT]: interrupts };\n\t\t\t\tif (typeof latest === \"object\") return {\n\t\t\t\t\t...latest,\n\t\t\t\t\t[INTERRUPT]: interrupts\n\t\t\t\t};\n\t\t\t}\n\t\t\treturn latest;\n\t\t}\n\t\treturn chunks;\n\t}\n\tasync _runLoop(params) {\n\t\tconst { loop, runner, debug, config } = params;\n\t\tlet tickError;\n\t\ttry {\n\t\t\twhile (await loop.tick({ inputKeys: this.inputChannels })) {\n\t\t\t\tfor (const { task } of await loop._matchCachedWrites()) loop._outputWrites(task.id, task.writes, true);\n\t\t\t\tif (debug) printStepCheckpoint(loop.checkpointMetadata.step, loop.channels, this.streamChannelsList);\n\t\t\t\tif (debug) printStepTasks(loop.step, Object.values(loop.tasks));\n\t\t\t\tawait runner.tick({\n\t\t\t\t\ttimeout: this.stepTimeout,\n\t\t\t\t\tretryPolicy: this.retryPolicy,\n\t\t\t\t\tonStepWrite: (step, writes) => {\n\t\t\t\t\t\tif (debug) printStepWrites(step, writes, this.streamChannelsList);\n\t\t\t\t\t},\n\t\t\t\t\tmaxConcurrency: config.maxConcurrency,\n\t\t\t\t\tsignal: config.signal\n\t\t\t\t});\n\t\t\t}\n\t\t\tif (loop.status === \"out_of_steps\") throw new GraphRecursionError([\n\t\t\t\t`Recursion limit of ${config.recursionLimit} reached`,\n\t\t\t\t\"without hitting a stop condition. You can increase the\",\n\t\t\t\t`limit by setting the \"recursionLimit\" config key.`\n\t\t\t].join(\" \"), { lc_error_code: \"GRAPH_RECURSION_LIMIT\" });\n\t\t} catch (e) {\n\t\t\ttickError = e;\n\t\t\tconst suppress = await loop.finishAndHandleError(tickError);\n\t\t\tif (!suppress) throw e;\n\t\t} finally {\n\t\t\tif (tickError === void 0) await loop.finishAndHandleError();\n\t\t}\n\t}\n\tasync clearCache() {\n\t\tawait this.cache?.clear([]);\n\t}\n};\n\n//#endregion\nexport { Channel, Pregel };\n//# sourceMappingURL=index.js.map","import { EmptyChannelError, InvalidUpdateError } from \"../errors.js\";\nimport { BaseChannel } from \"./base.js\";\n\n//#region src/channels/ephemeral_value.ts\n/**\n* Stores the value received in the step immediately preceding, clears after.\n*/\nvar EphemeralValue = class EphemeralValue extends BaseChannel {\n\tlc_graph_name = \"EphemeralValue\";\n\tguard;\n\tvalue = [];\n\tconstructor(guard = true) {\n\t\tsuper();\n\t\tthis.guard = guard;\n\t}\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new EphemeralValue(this.guard);\n\t\tif (typeof checkpoint !== \"undefined\") empty.value = [checkpoint];\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tif (values.length === 0) {\n\t\t\tconst updated = this.value.length > 0;\n\t\t\tthis.value = [];\n\t\t\treturn updated;\n\t\t}\n\t\tif (values.length !== 1 && this.guard) throw new InvalidUpdateError(\"EphemeralValue can only receive one value per step.\");\n\t\tthis.value = [values[values.length - 1]];\n\t\treturn true;\n\t}\n\tget() {\n\t\tif (this.value.length === 0) throw new EmptyChannelError();\n\t\treturn this.value[0];\n\t}\n\tcheckpoint() {\n\t\tif (this.value.length === 0) throw new EmptyChannelError();\n\t\treturn this.value[0];\n\t}\n\tisAvailable() {\n\t\treturn this.value.length !== 0;\n\t}\n};\n\n//#endregion\nexport { EphemeralValue };\n//# sourceMappingURL=ephemeral_value.js.map","import * as core from \"../core/index.js\";\nimport { $ZodError } from \"../core/index.js\";\nconst initializer = (inst, issues) => {\n    $ZodError.init(inst, issues);\n    inst.name = \"ZodError\";\n    Object.defineProperties(inst, {\n        format: {\n            value: (mapper) => core.formatError(inst, mapper),\n            // enumerable: false,\n        },\n        flatten: {\n            value: (mapper) => core.flattenError(inst, mapper),\n            // enumerable: false,\n        },\n        addIssue: {\n            value: (issue) => inst.issues.push(issue),\n            // enumerable: false,\n        },\n        addIssues: {\n            value: (issues) => inst.issues.push(...issues),\n            // enumerable: false,\n        },\n        isEmpty: {\n            get() {\n                return inst.issues.length === 0;\n            },\n            // enumerable: false,\n        },\n    });\n    // Object.defineProperty(inst, \"isEmpty\", {\n    //   get() {\n    //     return inst.issues.length === 0;\n    //   },\n    // });\n};\nexport const ZodError = core.$constructor(\"ZodError\", initializer);\nexport const ZodRealError = core.$constructor(\"ZodError\", initializer, {\n    Parent: Error,\n});\n// /** @deprecated Use `z.core.$ZodErrorMapCtx` instead. */\n// export type ErrorMapCtx = core.$ZodErrorMapCtx;\n","import * as core from \"../core/index.js\";\nimport { ZodRealError } from \"./errors.js\";\nexport const parse = /* @__PURE__ */ core._parse(ZodRealError);\nexport const parseAsync = /* @__PURE__ */ core._parseAsync(ZodRealError);\nexport const safeParse = /* @__PURE__ */ core._safeParse(ZodRealError);\nexport const safeParseAsync = /* @__PURE__ */ core._safeParseAsync(ZodRealError);\n","import * as core from \"../core/index.js\";\nimport { util } from \"../core/index.js\";\nimport * as checks from \"./checks.js\";\nimport * as iso from \"./iso.js\";\nimport * as parse from \"./parse.js\";\nexport const ZodType = /*@__PURE__*/ core.$constructor(\"ZodType\", (inst, def) => {\n    core.$ZodType.init(inst, def);\n    inst.def = def;\n    Object.defineProperty(inst, \"_def\", { value: def });\n    // base methods\n    inst.check = (...checks) => {\n        return inst.clone({\n            ...def,\n            checks: [\n                ...(def.checks ?? []),\n                ...checks.map((ch) => typeof ch === \"function\" ? { _zod: { check: ch, def: { check: \"custom\" }, onattach: [] } } : ch),\n            ],\n        }\n        // { parent: true }\n        );\n    };\n    inst.clone = (def, params) => core.clone(inst, def, params);\n    inst.brand = () => inst;\n    inst.register = ((reg, meta) => {\n        reg.add(inst, meta);\n        return inst;\n    });\n    // parsing\n    inst.parse = (data, params) => parse.parse(inst, data, params, { callee: inst.parse });\n    inst.safeParse = (data, params) => parse.safeParse(inst, data, params);\n    inst.parseAsync = async (data, params) => parse.parseAsync(inst, data, params, { callee: inst.parseAsync });\n    inst.safeParseAsync = async (data, params) => parse.safeParseAsync(inst, data, params);\n    inst.spa = inst.safeParseAsync;\n    // refinements\n    inst.refine = (check, params) => inst.check(refine(check, params));\n    inst.superRefine = (refinement) => inst.check(superRefine(refinement));\n    inst.overwrite = (fn) => inst.check(checks.overwrite(fn));\n    // wrappers\n    inst.optional = () => optional(inst);\n    inst.nullable = () => nullable(inst);\n    inst.nullish = () => optional(nullable(inst));\n    inst.nonoptional = (params) => nonoptional(inst, params);\n    inst.array = () => array(inst);\n    inst.or = (arg) => union([inst, arg]);\n    inst.and = (arg) => intersection(inst, arg);\n    inst.transform = (tx) => pipe(inst, transform(tx));\n    inst.default = (def) => _default(inst, def);\n    inst.prefault = (def) => prefault(inst, def);\n    // inst.coalesce = (def, params) => coalesce(inst, def, params);\n    inst.catch = (params) => _catch(inst, params);\n    inst.pipe = (target) => pipe(inst, target);\n    inst.readonly = () => readonly(inst);\n    // meta\n    inst.describe = (description) => {\n        const cl = inst.clone();\n        core.globalRegistry.add(cl, { description });\n        return cl;\n    };\n    Object.defineProperty(inst, \"description\", {\n        get() {\n            return core.globalRegistry.get(inst)?.description;\n        },\n        configurable: true,\n    });\n    inst.meta = (...args) => {\n        if (args.length === 0) {\n            return core.globalRegistry.get(inst);\n        }\n        const cl = inst.clone();\n        core.globalRegistry.add(cl, args[0]);\n        return cl;\n    };\n    // helpers\n    inst.isOptional = () => inst.safeParse(undefined).success;\n    inst.isNullable = () => inst.safeParse(null).success;\n    return inst;\n});\n/** @internal */\nexport const _ZodString = /*@__PURE__*/ core.$constructor(\"_ZodString\", (inst, def) => {\n    core.$ZodString.init(inst, def);\n    ZodType.init(inst, def);\n    const bag = inst._zod.bag;\n    inst.format = bag.format ?? null;\n    inst.minLength = bag.minimum ?? null;\n    inst.maxLength = bag.maximum ?? null;\n    // validations\n    inst.regex = (...args) => inst.check(checks.regex(...args));\n    inst.includes = (...args) => inst.check(checks.includes(...args));\n    inst.startsWith = (...args) => inst.check(checks.startsWith(...args));\n    inst.endsWith = (...args) => inst.check(checks.endsWith(...args));\n    inst.min = (...args) => inst.check(checks.minLength(...args));\n    inst.max = (...args) => inst.check(checks.maxLength(...args));\n    inst.length = (...args) => inst.check(checks.length(...args));\n    inst.nonempty = (...args) => inst.check(checks.minLength(1, ...args));\n    inst.lowercase = (params) => inst.check(checks.lowercase(params));\n    inst.uppercase = (params) => inst.check(checks.uppercase(params));\n    // transforms\n    inst.trim = () => inst.check(checks.trim());\n    inst.normalize = (...args) => inst.check(checks.normalize(...args));\n    inst.toLowerCase = () => inst.check(checks.toLowerCase());\n    inst.toUpperCase = () => inst.check(checks.toUpperCase());\n});\nexport const ZodString = /*@__PURE__*/ core.$constructor(\"ZodString\", (inst, def) => {\n    core.$ZodString.init(inst, def);\n    _ZodString.init(inst, def);\n    inst.email = (params) => inst.check(core._email(ZodEmail, params));\n    inst.url = (params) => inst.check(core._url(ZodURL, params));\n    inst.jwt = (params) => inst.check(core._jwt(ZodJWT, params));\n    inst.emoji = (params) => inst.check(core._emoji(ZodEmoji, params));\n    inst.guid = (params) => inst.check(core._guid(ZodGUID, params));\n    inst.uuid = (params) => inst.check(core._uuid(ZodUUID, params));\n    inst.uuidv4 = (params) => inst.check(core._uuidv4(ZodUUID, params));\n    inst.uuidv6 = (params) => inst.check(core._uuidv6(ZodUUID, params));\n    inst.uuidv7 = (params) => inst.check(core._uuidv7(ZodUUID, params));\n    inst.nanoid = (params) => inst.check(core._nanoid(ZodNanoID, params));\n    inst.guid = (params) => inst.check(core._guid(ZodGUID, params));\n    inst.cuid = (params) => inst.check(core._cuid(ZodCUID, params));\n    inst.cuid2 = (params) => inst.check(core._cuid2(ZodCUID2, params));\n    inst.ulid = (params) => inst.check(core._ulid(ZodULID, params));\n    inst.base64 = (params) => inst.check(core._base64(ZodBase64, params));\n    inst.base64url = (params) => inst.check(core._base64url(ZodBase64URL, params));\n    inst.xid = (params) => inst.check(core._xid(ZodXID, params));\n    inst.ksuid = (params) => inst.check(core._ksuid(ZodKSUID, params));\n    inst.ipv4 = (params) => inst.check(core._ipv4(ZodIPv4, params));\n    inst.ipv6 = (params) => inst.check(core._ipv6(ZodIPv6, params));\n    inst.cidrv4 = (params) => inst.check(core._cidrv4(ZodCIDRv4, params));\n    inst.cidrv6 = (params) => inst.check(core._cidrv6(ZodCIDRv6, params));\n    inst.e164 = (params) => inst.check(core._e164(ZodE164, params));\n    // iso\n    inst.datetime = (params) => inst.check(iso.datetime(params));\n    inst.date = (params) => inst.check(iso.date(params));\n    inst.time = (params) => inst.check(iso.time(params));\n    inst.duration = (params) => inst.check(iso.duration(params));\n});\nexport function string(params) {\n    return core._string(ZodString, params);\n}\nexport const ZodStringFormat = /*@__PURE__*/ core.$constructor(\"ZodStringFormat\", (inst, def) => {\n    core.$ZodStringFormat.init(inst, def);\n    _ZodString.init(inst, def);\n});\nexport const ZodEmail = /*@__PURE__*/ core.$constructor(\"ZodEmail\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodEmail.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function email(params) {\n    return core._email(ZodEmail, params);\n}\nexport const ZodGUID = /*@__PURE__*/ core.$constructor(\"ZodGUID\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodGUID.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function guid(params) {\n    return core._guid(ZodGUID, params);\n}\nexport const ZodUUID = /*@__PURE__*/ core.$constructor(\"ZodUUID\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodUUID.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function uuid(params) {\n    return core._uuid(ZodUUID, params);\n}\nexport function uuidv4(params) {\n    return core._uuidv4(ZodUUID, params);\n}\n// ZodUUIDv6\nexport function uuidv6(params) {\n    return core._uuidv6(ZodUUID, params);\n}\n// ZodUUIDv7\nexport function uuidv7(params) {\n    return core._uuidv7(ZodUUID, params);\n}\nexport const ZodURL = /*@__PURE__*/ core.$constructor(\"ZodURL\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodURL.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function url(params) {\n    return core._url(ZodURL, params);\n}\nexport const ZodEmoji = /*@__PURE__*/ core.$constructor(\"ZodEmoji\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodEmoji.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function emoji(params) {\n    return core._emoji(ZodEmoji, params);\n}\nexport const ZodNanoID = /*@__PURE__*/ core.$constructor(\"ZodNanoID\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodNanoID.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function nanoid(params) {\n    return core._nanoid(ZodNanoID, params);\n}\nexport const ZodCUID = /*@__PURE__*/ core.$constructor(\"ZodCUID\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodCUID.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function cuid(params) {\n    return core._cuid(ZodCUID, params);\n}\nexport const ZodCUID2 = /*@__PURE__*/ core.$constructor(\"ZodCUID2\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodCUID2.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function cuid2(params) {\n    return core._cuid2(ZodCUID2, params);\n}\nexport const ZodULID = /*@__PURE__*/ core.$constructor(\"ZodULID\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodULID.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function ulid(params) {\n    return core._ulid(ZodULID, params);\n}\nexport const ZodXID = /*@__PURE__*/ core.$constructor(\"ZodXID\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodXID.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function xid(params) {\n    return core._xid(ZodXID, params);\n}\nexport const ZodKSUID = /*@__PURE__*/ core.$constructor(\"ZodKSUID\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodKSUID.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function ksuid(params) {\n    return core._ksuid(ZodKSUID, params);\n}\nexport const ZodIPv4 = /*@__PURE__*/ core.$constructor(\"ZodIPv4\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodIPv4.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function ipv4(params) {\n    return core._ipv4(ZodIPv4, params);\n}\nexport const ZodIPv6 = /*@__PURE__*/ core.$constructor(\"ZodIPv6\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodIPv6.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function ipv6(params) {\n    return core._ipv6(ZodIPv6, params);\n}\nexport const ZodCIDRv4 = /*@__PURE__*/ core.$constructor(\"ZodCIDRv4\", (inst, def) => {\n    core.$ZodCIDRv4.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function cidrv4(params) {\n    return core._cidrv4(ZodCIDRv4, params);\n}\nexport const ZodCIDRv6 = /*@__PURE__*/ core.$constructor(\"ZodCIDRv6\", (inst, def) => {\n    core.$ZodCIDRv6.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function cidrv6(params) {\n    return core._cidrv6(ZodCIDRv6, params);\n}\nexport const ZodBase64 = /*@__PURE__*/ core.$constructor(\"ZodBase64\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodBase64.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function base64(params) {\n    return core._base64(ZodBase64, params);\n}\nexport const ZodBase64URL = /*@__PURE__*/ core.$constructor(\"ZodBase64URL\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodBase64URL.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function base64url(params) {\n    return core._base64url(ZodBase64URL, params);\n}\nexport const ZodE164 = /*@__PURE__*/ core.$constructor(\"ZodE164\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodE164.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function e164(params) {\n    return core._e164(ZodE164, params);\n}\nexport const ZodJWT = /*@__PURE__*/ core.$constructor(\"ZodJWT\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodJWT.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function jwt(params) {\n    return core._jwt(ZodJWT, params);\n}\nexport const ZodCustomStringFormat = /*@__PURE__*/ core.$constructor(\"ZodCustomStringFormat\", (inst, def) => {\n    // ZodStringFormat.init(inst, def);\n    core.$ZodCustomStringFormat.init(inst, def);\n    ZodStringFormat.init(inst, def);\n});\nexport function stringFormat(format, fnOrRegex, _params = {}) {\n    return core._stringFormat(ZodCustomStringFormat, format, fnOrRegex, _params);\n}\nexport const ZodNumber = /*@__PURE__*/ core.$constructor(\"ZodNumber\", (inst, def) => {\n    core.$ZodNumber.init(inst, def);\n    ZodType.init(inst, def);\n    inst.gt = (value, params) => inst.check(checks.gt(value, params));\n    inst.gte = (value, params) => inst.check(checks.gte(value, params));\n    inst.min = (value, params) => inst.check(checks.gte(value, params));\n    inst.lt = (value, params) => inst.check(checks.lt(value, params));\n    inst.lte = (value, params) => inst.check(checks.lte(value, params));\n    inst.max = (value, params) => inst.check(checks.lte(value, params));\n    inst.int = (params) => inst.check(int(params));\n    inst.safe = (params) => inst.check(int(params));\n    inst.positive = (params) => inst.check(checks.gt(0, params));\n    inst.nonnegative = (params) => inst.check(checks.gte(0, params));\n    inst.negative = (params) => inst.check(checks.lt(0, params));\n    inst.nonpositive = (params) => inst.check(checks.lte(0, params));\n    inst.multipleOf = (value, params) => inst.check(checks.multipleOf(value, params));\n    inst.step = (value, params) => inst.check(checks.multipleOf(value, params));\n    // inst.finite = (params) => inst.check(core.finite(params));\n    inst.finite = () => inst;\n    const bag = inst._zod.bag;\n    inst.minValue =\n        Math.max(bag.minimum ?? Number.NEGATIVE_INFINITY, bag.exclusiveMinimum ?? Number.NEGATIVE_INFINITY) ?? null;\n    inst.maxValue =\n        Math.min(bag.maximum ?? Number.POSITIVE_INFINITY, bag.exclusiveMaximum ?? Number.POSITIVE_INFINITY) ?? null;\n    inst.isInt = (bag.format ?? \"\").includes(\"int\") || Number.isSafeInteger(bag.multipleOf ?? 0.5);\n    inst.isFinite = true;\n    inst.format = bag.format ?? null;\n});\nexport function number(params) {\n    return core._number(ZodNumber, params);\n}\nexport const ZodNumberFormat = /*@__PURE__*/ core.$constructor(\"ZodNumberFormat\", (inst, def) => {\n    core.$ZodNumberFormat.init(inst, def);\n    ZodNumber.init(inst, def);\n});\nexport function int(params) {\n    return core._int(ZodNumberFormat, params);\n}\nexport function float32(params) {\n    return core._float32(ZodNumberFormat, params);\n}\nexport function float64(params) {\n    return core._float64(ZodNumberFormat, params);\n}\nexport function int32(params) {\n    return core._int32(ZodNumberFormat, params);\n}\nexport function uint32(params) {\n    return core._uint32(ZodNumberFormat, params);\n}\nexport const ZodBoolean = /*@__PURE__*/ core.$constructor(\"ZodBoolean\", (inst, def) => {\n    core.$ZodBoolean.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function boolean(params) {\n    return core._boolean(ZodBoolean, params);\n}\nexport const ZodBigInt = /*@__PURE__*/ core.$constructor(\"ZodBigInt\", (inst, def) => {\n    core.$ZodBigInt.init(inst, def);\n    ZodType.init(inst, def);\n    inst.gte = (value, params) => inst.check(checks.gte(value, params));\n    inst.min = (value, params) => inst.check(checks.gte(value, params));\n    inst.gt = (value, params) => inst.check(checks.gt(value, params));\n    inst.gte = (value, params) => inst.check(checks.gte(value, params));\n    inst.min = (value, params) => inst.check(checks.gte(value, params));\n    inst.lt = (value, params) => inst.check(checks.lt(value, params));\n    inst.lte = (value, params) => inst.check(checks.lte(value, params));\n    inst.max = (value, params) => inst.check(checks.lte(value, params));\n    inst.positive = (params) => inst.check(checks.gt(BigInt(0), params));\n    inst.negative = (params) => inst.check(checks.lt(BigInt(0), params));\n    inst.nonpositive = (params) => inst.check(checks.lte(BigInt(0), params));\n    inst.nonnegative = (params) => inst.check(checks.gte(BigInt(0), params));\n    inst.multipleOf = (value, params) => inst.check(checks.multipleOf(value, params));\n    const bag = inst._zod.bag;\n    inst.minValue = bag.minimum ?? null;\n    inst.maxValue = bag.maximum ?? null;\n    inst.format = bag.format ?? null;\n});\nexport function bigint(params) {\n    return core._bigint(ZodBigInt, params);\n}\nexport const ZodBigIntFormat = /*@__PURE__*/ core.$constructor(\"ZodBigIntFormat\", (inst, def) => {\n    core.$ZodBigIntFormat.init(inst, def);\n    ZodBigInt.init(inst, def);\n});\n// int64\nexport function int64(params) {\n    return core._int64(ZodBigIntFormat, params);\n}\n// uint64\nexport function uint64(params) {\n    return core._uint64(ZodBigIntFormat, params);\n}\nexport const ZodSymbol = /*@__PURE__*/ core.$constructor(\"ZodSymbol\", (inst, def) => {\n    core.$ZodSymbol.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function symbol(params) {\n    return core._symbol(ZodSymbol, params);\n}\nexport const ZodUndefined = /*@__PURE__*/ core.$constructor(\"ZodUndefined\", (inst, def) => {\n    core.$ZodUndefined.init(inst, def);\n    ZodType.init(inst, def);\n});\nfunction _undefined(params) {\n    return core._undefined(ZodUndefined, params);\n}\nexport { _undefined as undefined };\nexport const ZodNull = /*@__PURE__*/ core.$constructor(\"ZodNull\", (inst, def) => {\n    core.$ZodNull.init(inst, def);\n    ZodType.init(inst, def);\n});\nfunction _null(params) {\n    return core._null(ZodNull, params);\n}\nexport { _null as null };\nexport const ZodAny = /*@__PURE__*/ core.$constructor(\"ZodAny\", (inst, def) => {\n    core.$ZodAny.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function any() {\n    return core._any(ZodAny);\n}\nexport const ZodUnknown = /*@__PURE__*/ core.$constructor(\"ZodUnknown\", (inst, def) => {\n    core.$ZodUnknown.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function unknown() {\n    return core._unknown(ZodUnknown);\n}\nexport const ZodNever = /*@__PURE__*/ core.$constructor(\"ZodNever\", (inst, def) => {\n    core.$ZodNever.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function never(params) {\n    return core._never(ZodNever, params);\n}\nexport const ZodVoid = /*@__PURE__*/ core.$constructor(\"ZodVoid\", (inst, def) => {\n    core.$ZodVoid.init(inst, def);\n    ZodType.init(inst, def);\n});\nfunction _void(params) {\n    return core._void(ZodVoid, params);\n}\nexport { _void as void };\nexport const ZodDate = /*@__PURE__*/ core.$constructor(\"ZodDate\", (inst, def) => {\n    core.$ZodDate.init(inst, def);\n    ZodType.init(inst, def);\n    inst.min = (value, params) => inst.check(checks.gte(value, params));\n    inst.max = (value, params) => inst.check(checks.lte(value, params));\n    const c = inst._zod.bag;\n    inst.minDate = c.minimum ? new Date(c.minimum) : null;\n    inst.maxDate = c.maximum ? new Date(c.maximum) : null;\n});\nexport function date(params) {\n    return core._date(ZodDate, params);\n}\nexport const ZodArray = /*@__PURE__*/ core.$constructor(\"ZodArray\", (inst, def) => {\n    core.$ZodArray.init(inst, def);\n    ZodType.init(inst, def);\n    inst.element = def.element;\n    inst.min = (minLength, params) => inst.check(checks.minLength(minLength, params));\n    inst.nonempty = (params) => inst.check(checks.minLength(1, params));\n    inst.max = (maxLength, params) => inst.check(checks.maxLength(maxLength, params));\n    inst.length = (len, params) => inst.check(checks.length(len, params));\n    inst.unwrap = () => inst.element;\n});\nexport function array(element, params) {\n    return core._array(ZodArray, element, params);\n}\n// .keyof\nexport function keyof(schema) {\n    const shape = schema._zod.def.shape;\n    return literal(Object.keys(shape));\n}\nexport const ZodObject = /*@__PURE__*/ core.$constructor(\"ZodObject\", (inst, def) => {\n    core.$ZodObject.init(inst, def);\n    ZodType.init(inst, def);\n    util.defineLazy(inst, \"shape\", () => def.shape);\n    inst.keyof = () => _enum(Object.keys(inst._zod.def.shape));\n    inst.catchall = (catchall) => inst.clone({ ...inst._zod.def, catchall: catchall });\n    inst.passthrough = () => inst.clone({ ...inst._zod.def, catchall: unknown() });\n    // inst.nonstrict = () => inst.clone({ ...inst._zod.def, catchall: api.unknown() });\n    inst.loose = () => inst.clone({ ...inst._zod.def, catchall: unknown() });\n    inst.strict = () => inst.clone({ ...inst._zod.def, catchall: never() });\n    inst.strip = () => inst.clone({ ...inst._zod.def, catchall: undefined });\n    inst.extend = (incoming) => {\n        return util.extend(inst, incoming);\n    };\n    inst.merge = (other) => util.merge(inst, other);\n    inst.pick = (mask) => util.pick(inst, mask);\n    inst.omit = (mask) => util.omit(inst, mask);\n    inst.partial = (...args) => util.partial(ZodOptional, inst, args[0]);\n    inst.required = (...args) => util.required(ZodNonOptional, inst, args[0]);\n});\nexport function object(shape, params) {\n    const def = {\n        type: \"object\",\n        get shape() {\n            util.assignProp(this, \"shape\", { ...shape });\n            return this.shape;\n        },\n        ...util.normalizeParams(params),\n    };\n    return new ZodObject(def);\n}\n// strictObject\nexport function strictObject(shape, params) {\n    return new ZodObject({\n        type: \"object\",\n        get shape() {\n            util.assignProp(this, \"shape\", { ...shape });\n            return this.shape;\n        },\n        catchall: never(),\n        ...util.normalizeParams(params),\n    });\n}\n// looseObject\nexport function looseObject(shape, params) {\n    return new ZodObject({\n        type: \"object\",\n        get shape() {\n            util.assignProp(this, \"shape\", { ...shape });\n            return this.shape;\n        },\n        catchall: unknown(),\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodUnion = /*@__PURE__*/ core.$constructor(\"ZodUnion\", (inst, def) => {\n    core.$ZodUnion.init(inst, def);\n    ZodType.init(inst, def);\n    inst.options = def.options;\n});\nexport function union(options, params) {\n    return new ZodUnion({\n        type: \"union\",\n        options: options,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodDiscriminatedUnion = /*@__PURE__*/ core.$constructor(\"ZodDiscriminatedUnion\", (inst, def) => {\n    ZodUnion.init(inst, def);\n    core.$ZodDiscriminatedUnion.init(inst, def);\n});\nexport function discriminatedUnion(discriminator, options, params) {\n    // const [options, params] = args;\n    return new ZodDiscriminatedUnion({\n        type: \"union\",\n        options,\n        discriminator,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodIntersection = /*@__PURE__*/ core.$constructor(\"ZodIntersection\", (inst, def) => {\n    core.$ZodIntersection.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function intersection(left, right) {\n    return new ZodIntersection({\n        type: \"intersection\",\n        left: left,\n        right: right,\n    });\n}\nexport const ZodTuple = /*@__PURE__*/ core.$constructor(\"ZodTuple\", (inst, def) => {\n    core.$ZodTuple.init(inst, def);\n    ZodType.init(inst, def);\n    inst.rest = (rest) => inst.clone({\n        ...inst._zod.def,\n        rest: rest,\n    });\n});\nexport function tuple(items, _paramsOrRest, _params) {\n    const hasRest = _paramsOrRest instanceof core.$ZodType;\n    const params = hasRest ? _params : _paramsOrRest;\n    const rest = hasRest ? _paramsOrRest : null;\n    return new ZodTuple({\n        type: \"tuple\",\n        items: items,\n        rest,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodRecord = /*@__PURE__*/ core.$constructor(\"ZodRecord\", (inst, def) => {\n    core.$ZodRecord.init(inst, def);\n    ZodType.init(inst, def);\n    inst.keyType = def.keyType;\n    inst.valueType = def.valueType;\n});\nexport function record(keyType, valueType, params) {\n    return new ZodRecord({\n        type: \"record\",\n        keyType,\n        valueType: valueType,\n        ...util.normalizeParams(params),\n    });\n}\n// type alksjf = core.output<core.$ZodRecordKey>;\nexport function partialRecord(keyType, valueType, params) {\n    return new ZodRecord({\n        type: \"record\",\n        keyType: union([keyType, never()]),\n        valueType: valueType,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodMap = /*@__PURE__*/ core.$constructor(\"ZodMap\", (inst, def) => {\n    core.$ZodMap.init(inst, def);\n    ZodType.init(inst, def);\n    inst.keyType = def.keyType;\n    inst.valueType = def.valueType;\n});\nexport function map(keyType, valueType, params) {\n    return new ZodMap({\n        type: \"map\",\n        keyType: keyType,\n        valueType: valueType,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodSet = /*@__PURE__*/ core.$constructor(\"ZodSet\", (inst, def) => {\n    core.$ZodSet.init(inst, def);\n    ZodType.init(inst, def);\n    inst.min = (...args) => inst.check(core._minSize(...args));\n    inst.nonempty = (params) => inst.check(core._minSize(1, params));\n    inst.max = (...args) => inst.check(core._maxSize(...args));\n    inst.size = (...args) => inst.check(core._size(...args));\n});\nexport function set(valueType, params) {\n    return new ZodSet({\n        type: \"set\",\n        valueType: valueType,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodEnum = /*@__PURE__*/ core.$constructor(\"ZodEnum\", (inst, def) => {\n    core.$ZodEnum.init(inst, def);\n    ZodType.init(inst, def);\n    inst.enum = def.entries;\n    inst.options = Object.values(def.entries);\n    const keys = new Set(Object.keys(def.entries));\n    inst.extract = (values, params) => {\n        const newEntries = {};\n        for (const value of values) {\n            if (keys.has(value)) {\n                newEntries[value] = def.entries[value];\n            }\n            else\n                throw new Error(`Key ${value} not found in enum`);\n        }\n        return new ZodEnum({\n            ...def,\n            checks: [],\n            ...util.normalizeParams(params),\n            entries: newEntries,\n        });\n    };\n    inst.exclude = (values, params) => {\n        const newEntries = { ...def.entries };\n        for (const value of values) {\n            if (keys.has(value)) {\n                delete newEntries[value];\n            }\n            else\n                throw new Error(`Key ${value} not found in enum`);\n        }\n        return new ZodEnum({\n            ...def,\n            checks: [],\n            ...util.normalizeParams(params),\n            entries: newEntries,\n        });\n    };\n});\nfunction _enum(values, params) {\n    const entries = Array.isArray(values) ? Object.fromEntries(values.map((v) => [v, v])) : values;\n    return new ZodEnum({\n        type: \"enum\",\n        entries,\n        ...util.normalizeParams(params),\n    });\n}\nexport { _enum as enum };\n/** @deprecated This API has been merged into `z.enum()`. Use `z.enum()` instead.\n *\n * ```ts\n * enum Colors { red, green, blue }\n * z.enum(Colors);\n * ```\n */\nexport function nativeEnum(entries, params) {\n    return new ZodEnum({\n        type: \"enum\",\n        entries,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodLiteral = /*@__PURE__*/ core.$constructor(\"ZodLiteral\", (inst, def) => {\n    core.$ZodLiteral.init(inst, def);\n    ZodType.init(inst, def);\n    inst.values = new Set(def.values);\n    Object.defineProperty(inst, \"value\", {\n        get() {\n            if (def.values.length > 1) {\n                throw new Error(\"This schema contains multiple valid literal values. Use `.values` instead.\");\n            }\n            return def.values[0];\n        },\n    });\n});\nexport function literal(value, params) {\n    return new ZodLiteral({\n        type: \"literal\",\n        values: Array.isArray(value) ? value : [value],\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodFile = /*@__PURE__*/ core.$constructor(\"ZodFile\", (inst, def) => {\n    core.$ZodFile.init(inst, def);\n    ZodType.init(inst, def);\n    inst.min = (size, params) => inst.check(core._minSize(size, params));\n    inst.max = (size, params) => inst.check(core._maxSize(size, params));\n    inst.mime = (types, params) => inst.check(core._mime(Array.isArray(types) ? types : [types], params));\n});\nexport function file(params) {\n    return core._file(ZodFile, params);\n}\nexport const ZodTransform = /*@__PURE__*/ core.$constructor(\"ZodTransform\", (inst, def) => {\n    core.$ZodTransform.init(inst, def);\n    ZodType.init(inst, def);\n    inst._zod.parse = (payload, _ctx) => {\n        payload.addIssue = (issue) => {\n            if (typeof issue === \"string\") {\n                payload.issues.push(util.issue(issue, payload.value, def));\n            }\n            else {\n                // for Zod 3 backwards compatibility\n                const _issue = issue;\n                if (_issue.fatal)\n                    _issue.continue = false;\n                _issue.code ?? (_issue.code = \"custom\");\n                _issue.input ?? (_issue.input = payload.value);\n                _issue.inst ?? (_issue.inst = inst);\n                _issue.continue ?? (_issue.continue = true);\n                payload.issues.push(util.issue(_issue));\n            }\n        };\n        const output = def.transform(payload.value, payload);\n        if (output instanceof Promise) {\n            return output.then((output) => {\n                payload.value = output;\n                return payload;\n            });\n        }\n        payload.value = output;\n        return payload;\n    };\n});\nexport function transform(fn) {\n    return new ZodTransform({\n        type: \"transform\",\n        transform: fn,\n    });\n}\nexport const ZodOptional = /*@__PURE__*/ core.$constructor(\"ZodOptional\", (inst, def) => {\n    core.$ZodOptional.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n});\nexport function optional(innerType) {\n    return new ZodOptional({\n        type: \"optional\",\n        innerType: innerType,\n    });\n}\nexport const ZodNullable = /*@__PURE__*/ core.$constructor(\"ZodNullable\", (inst, def) => {\n    core.$ZodNullable.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n});\nexport function nullable(innerType) {\n    return new ZodNullable({\n        type: \"nullable\",\n        innerType: innerType,\n    });\n}\n// nullish\nexport function nullish(innerType) {\n    return optional(nullable(innerType));\n}\nexport const ZodDefault = /*@__PURE__*/ core.$constructor(\"ZodDefault\", (inst, def) => {\n    core.$ZodDefault.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n    inst.removeDefault = inst.unwrap;\n});\nexport function _default(innerType, defaultValue) {\n    return new ZodDefault({\n        type: \"default\",\n        innerType: innerType,\n        get defaultValue() {\n            return typeof defaultValue === \"function\" ? defaultValue() : defaultValue;\n        },\n    });\n}\nexport const ZodPrefault = /*@__PURE__*/ core.$constructor(\"ZodPrefault\", (inst, def) => {\n    core.$ZodPrefault.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n});\nexport function prefault(innerType, defaultValue) {\n    return new ZodPrefault({\n        type: \"prefault\",\n        innerType: innerType,\n        get defaultValue() {\n            return typeof defaultValue === \"function\" ? defaultValue() : defaultValue;\n        },\n    });\n}\nexport const ZodNonOptional = /*@__PURE__*/ core.$constructor(\"ZodNonOptional\", (inst, def) => {\n    core.$ZodNonOptional.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n});\nexport function nonoptional(innerType, params) {\n    return new ZodNonOptional({\n        type: \"nonoptional\",\n        innerType: innerType,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodSuccess = /*@__PURE__*/ core.$constructor(\"ZodSuccess\", (inst, def) => {\n    core.$ZodSuccess.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n});\nexport function success(innerType) {\n    return new ZodSuccess({\n        type: \"success\",\n        innerType: innerType,\n    });\n}\nexport const ZodCatch = /*@__PURE__*/ core.$constructor(\"ZodCatch\", (inst, def) => {\n    core.$ZodCatch.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n    inst.removeCatch = inst.unwrap;\n});\nfunction _catch(innerType, catchValue) {\n    return new ZodCatch({\n        type: \"catch\",\n        innerType: innerType,\n        catchValue: (typeof catchValue === \"function\" ? catchValue : () => catchValue),\n    });\n}\nexport { _catch as catch };\nexport const ZodNaN = /*@__PURE__*/ core.$constructor(\"ZodNaN\", (inst, def) => {\n    core.$ZodNaN.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function nan(params) {\n    return core._nan(ZodNaN, params);\n}\nexport const ZodPipe = /*@__PURE__*/ core.$constructor(\"ZodPipe\", (inst, def) => {\n    core.$ZodPipe.init(inst, def);\n    ZodType.init(inst, def);\n    inst.in = def.in;\n    inst.out = def.out;\n});\nexport function pipe(in_, out) {\n    return new ZodPipe({\n        type: \"pipe\",\n        in: in_,\n        out: out,\n        // ...util.normalizeParams(params),\n    });\n}\nexport const ZodReadonly = /*@__PURE__*/ core.$constructor(\"ZodReadonly\", (inst, def) => {\n    core.$ZodReadonly.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function readonly(innerType) {\n    return new ZodReadonly({\n        type: \"readonly\",\n        innerType: innerType,\n    });\n}\nexport const ZodTemplateLiteral = /*@__PURE__*/ core.$constructor(\"ZodTemplateLiteral\", (inst, def) => {\n    core.$ZodTemplateLiteral.init(inst, def);\n    ZodType.init(inst, def);\n});\nexport function templateLiteral(parts, params) {\n    return new ZodTemplateLiteral({\n        type: \"template_literal\",\n        parts,\n        ...util.normalizeParams(params),\n    });\n}\nexport const ZodLazy = /*@__PURE__*/ core.$constructor(\"ZodLazy\", (inst, def) => {\n    core.$ZodLazy.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.getter();\n});\nexport function lazy(getter) {\n    return new ZodLazy({\n        type: \"lazy\",\n        getter: getter,\n    });\n}\nexport const ZodPromise = /*@__PURE__*/ core.$constructor(\"ZodPromise\", (inst, def) => {\n    core.$ZodPromise.init(inst, def);\n    ZodType.init(inst, def);\n    inst.unwrap = () => inst._zod.def.innerType;\n});\nexport function promise(innerType) {\n    return new ZodPromise({\n        type: \"promise\",\n        innerType: innerType,\n    });\n}\nexport const ZodCustom = /*@__PURE__*/ core.$constructor(\"ZodCustom\", (inst, def) => {\n    core.$ZodCustom.init(inst, def);\n    ZodType.init(inst, def);\n});\n// custom checks\nexport function check(fn) {\n    const ch = new core.$ZodCheck({\n        check: \"custom\",\n        // ...util.normalizeParams(params),\n    });\n    ch._zod.check = fn;\n    return ch;\n}\nexport function custom(fn, _params) {\n    return core._custom(ZodCustom, fn ?? (() => true), _params);\n}\nexport function refine(fn, _params = {}) {\n    return core._refine(ZodCustom, fn, _params);\n}\n// superRefine\nexport function superRefine(fn) {\n    const ch = check((payload) => {\n        payload.addIssue = (issue) => {\n            if (typeof issue === \"string\") {\n                payload.issues.push(util.issue(issue, payload.value, ch._zod.def));\n            }\n            else {\n                // for Zod 3 backwards compatibility\n                const _issue = issue;\n                if (_issue.fatal)\n                    _issue.continue = false;\n                _issue.code ?? (_issue.code = \"custom\");\n                _issue.input ?? (_issue.input = payload.value);\n                _issue.inst ?? (_issue.inst = ch);\n                _issue.continue ?? (_issue.continue = !ch._zod.def.abort);\n                payload.issues.push(util.issue(_issue));\n            }\n        };\n        return fn(payload.value, payload);\n    });\n    return ch;\n}\nfunction _instanceof(cls, params = {\n    error: `Input not instance of ${cls.name}`,\n}) {\n    const inst = new ZodCustom({\n        type: \"custom\",\n        check: \"custom\",\n        fn: (data) => data instanceof cls,\n        abort: true,\n        ...util.normalizeParams(params),\n    });\n    inst._zod.bag.Class = cls;\n    return inst;\n}\nexport { _instanceof as instanceof };\n// stringbool\nexport const stringbool = (...args) => core._stringbool({\n    Pipe: ZodPipe,\n    Boolean: ZodBoolean,\n    String: ZodString,\n    Transform: ZodTransform,\n}, ...args);\nexport function json(params) {\n    const jsonSchema = lazy(() => {\n        return union([string(params), number(), boolean(), _null(), array(jsonSchema), record(string(), jsonSchema)]);\n    });\n    return jsonSchema;\n}\n// preprocess\n// /** @deprecated Use `z.pipe()` and `z.transform()` instead. */\nexport function preprocess(fn, schema) {\n    return pipe(transform(fn), schema);\n}\n","import uuid from './dist/index.js';\nexport const v1 = uuid.v1;\nexport const v1ToV6 = uuid.v1ToV6;\nexport const v3 = uuid.v3;\nexport const v4 = uuid.v4;\nexport const v5 = uuid.v5;\nexport const v6 = uuid.v6;\nexport const v6ToV1 = uuid.v6ToV1;\nexport const v7 = uuid.v7;\nexport const NIL = uuid.NIL;\nexport const MAX = uuid.MAX;\nexport const version = uuid.version;\nexport const validate = uuid.validate;\nexport const stringify = uuid.stringify;\nexport const parse = uuid.parse;\n","import { InvalidUpdateError, NodeInterrupt, UnreachableNodeError } from \"../errors.js\";\nimport { CHECKPOINT_NAMESPACE_END, CHECKPOINT_NAMESPACE_SEPARATOR, END, START, TAG_HIDDEN, _isSend } from \"../constants.js\";\nimport { RunnableCallable, gatherIterator, gatherIteratorSync } from \"../utils.js\";\nimport { ChannelWrite, PASSTHROUGH } from \"../pregel/write.js\";\nimport { PregelNode } from \"../pregel/read.js\";\nimport { isPregelLike } from \"../pregel/utils/subgraph.js\";\nimport { Channel, Pregel } from \"../pregel/index.js\";\nimport { EphemeralValue } from \"../channels/ephemeral_value.js\";\nimport { Runnable, _coerceToRunnable } from \"@langchain/core/runnables\";\nimport { Graph } from \"@langchain/core/runnables/graph\";\nimport { z } from \"zod/v4\";\nimport { validate } from \"uuid\";\n\n//#region src/graph/graph.ts\nvar Branch = class {\n\tpath;\n\tends;\n\tconstructor(options) {\n\t\tif (Runnable.isRunnable(options.path)) this.path = options.path;\n\t\telse this.path = _coerceToRunnable(options.path).withConfig({ runName: `Branch` });\n\t\tthis.ends = Array.isArray(options.pathMap) ? options.pathMap.reduce((acc, n) => {\n\t\t\tacc[n] = n;\n\t\t\treturn acc;\n\t\t}, {}) : options.pathMap;\n\t}\n\trun(writer, reader) {\n\t\treturn ChannelWrite.registerWriter(new RunnableCallable({\n\t\t\tname: \"<branch_run>\",\n\t\t\ttrace: false,\n\t\t\tfunc: async (input, config) => {\n\t\t\t\ttry {\n\t\t\t\t\treturn await this._route(input, config, writer, reader);\n\t\t\t\t} catch (e) {\n\t\t\t\t\tif (e.name === NodeInterrupt.unminifiable_name) console.warn(\"[WARN]: 'NodeInterrupt' thrown in conditional edge. This is likely a bug in your graph implementation.\\nNodeInterrupt should only be thrown inside a node, not in edge conditions.\");\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}));\n\t}\n\tasync _route(input, config, writer, reader) {\n\t\tlet result = await this.path.invoke(reader ? reader(config) : input, config);\n\t\tif (!Array.isArray(result)) result = [result];\n\t\tlet destinations;\n\t\tif (this.ends) destinations = result.map((r) => _isSend(r) ? r : this.ends[r]);\n\t\telse destinations = result;\n\t\tif (destinations.some((dest) => !dest)) throw new Error(\"Branch condition returned unknown or null destination\");\n\t\tif (destinations.filter(_isSend).some((packet) => packet.node === END)) throw new InvalidUpdateError(\"Cannot send a packet to the END node\");\n\t\tconst writeResult = await writer(destinations, config);\n\t\treturn writeResult ?? input;\n\t}\n};\nvar Graph$1 = class {\n\tnodes;\n\tedges;\n\tbranches;\n\tentryPoint;\n\tcompiled = false;\n\tconstructor() {\n\t\tthis.nodes = {};\n\t\tthis.edges = /* @__PURE__ */ new Set();\n\t\tthis.branches = {};\n\t}\n\twarnIfCompiled(message) {\n\t\tif (this.compiled) console.warn(message);\n\t}\n\tget allEdges() {\n\t\treturn this.edges;\n\t}\n\taddNode(...args) {\n\t\tfunction isMutlipleNodes(args$1) {\n\t\t\treturn args$1.length >= 1 && typeof args$1[0] !== \"string\";\n\t\t}\n\t\tconst nodes = isMutlipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]) : [[\n\t\t\targs[0],\n\t\t\targs[1],\n\t\t\targs[2]\n\t\t]];\n\t\tif (nodes.length === 0) throw new Error(\"No nodes provided in `addNode`\");\n\t\tfor (const [key, action, options] of nodes) {\n\t\t\tfor (const reservedChar of [CHECKPOINT_NAMESPACE_SEPARATOR, CHECKPOINT_NAMESPACE_END]) if (key.includes(reservedChar)) throw new Error(`\"${reservedChar}\" is a reserved character and is not allowed in node names.`);\n\t\t\tthis.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);\n\t\t\tif (key in this.nodes) throw new Error(`Node \\`${key}\\` already present.`);\n\t\t\tif (key === END) throw new Error(`Node \\`${key}\\` is reserved.`);\n\t\t\tconst runnable = _coerceToRunnable(action);\n\t\t\tthis.nodes[key] = {\n\t\t\t\trunnable,\n\t\t\t\tmetadata: options?.metadata,\n\t\t\t\tsubgraphs: isPregelLike(runnable) ? [runnable] : options?.subgraphs,\n\t\t\t\tends: options?.ends\n\t\t\t};\n\t\t}\n\t\treturn this;\n\t}\n\taddEdge(startKey, endKey) {\n\t\tthis.warnIfCompiled(`Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.`);\n\t\tif (startKey === END) throw new Error(\"END cannot be a start node\");\n\t\tif (endKey === START) throw new Error(\"START cannot be an end node\");\n\t\tif (Array.from(this.edges).some(([start]) => start === startKey) && !(\"channels\" in this)) throw new Error(`Already found path for ${startKey}. For multiple edges, use StateGraph.`);\n\t\tthis.edges.add([startKey, endKey]);\n\t\treturn this;\n\t}\n\taddConditionalEdges(source, path, pathMap) {\n\t\tconst options = typeof source === \"object\" ? source : {\n\t\t\tsource,\n\t\t\tpath,\n\t\t\tpathMap\n\t\t};\n\t\tthis.warnIfCompiled(\"Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\");\n\t\tif (!Runnable.isRunnable(options.path)) {\n\t\t\tconst pathDisplayValues = Array.isArray(options.pathMap) ? options.pathMap.join(\",\") : Object.keys(options.pathMap ?? {}).join(\",\");\n\t\t\toptions.path = _coerceToRunnable(options.path).withConfig({ runName: `Branch<${options.source}${pathDisplayValues !== \"\" ? `,${pathDisplayValues}` : \"\"}>`.slice(0, 63) });\n\t\t}\n\t\tconst name = options.path.getName() === \"RunnableLambda\" ? \"condition\" : options.path.getName();\n\t\tif (this.branches[options.source] && this.branches[options.source][name]) throw new Error(`Condition \\`${name}\\` already present for node \\`${source}\\``);\n\t\tthis.branches[options.source] ??= {};\n\t\tthis.branches[options.source][name] = new Branch(options);\n\t\treturn this;\n\t}\n\t/**\n\t* @deprecated use `addEdge(START, key)` instead\n\t*/\n\tsetEntryPoint(key) {\n\t\tthis.warnIfCompiled(\"Setting the entry point of a graph that has already been compiled. This will not be reflected in the compiled graph.\");\n\t\treturn this.addEdge(START, key);\n\t}\n\t/**\n\t* @deprecated use `addEdge(key, END)` instead\n\t*/\n\tsetFinishPoint(key) {\n\t\tthis.warnIfCompiled(\"Setting a finish point of a graph that has already been compiled. This will not be reflected in the compiled graph.\");\n\t\treturn this.addEdge(key, END);\n\t}\n\tcompile({ checkpointer, interruptBefore, interruptAfter, name } = {}) {\n\t\tthis.validate([...Array.isArray(interruptBefore) ? interruptBefore : [], ...Array.isArray(interruptAfter) ? interruptAfter : []]);\n\t\tconst compiled = new CompiledGraph({\n\t\t\tbuilder: this,\n\t\t\tcheckpointer,\n\t\t\tinterruptAfter,\n\t\t\tinterruptBefore,\n\t\t\tautoValidate: false,\n\t\t\tnodes: {},\n\t\t\tchannels: {\n\t\t\t\t[START]: new EphemeralValue(),\n\t\t\t\t[END]: new EphemeralValue()\n\t\t\t},\n\t\t\tinputChannels: START,\n\t\t\toutputChannels: END,\n\t\t\tstreamChannels: [],\n\t\t\tstreamMode: \"values\",\n\t\t\tname\n\t\t});\n\t\tfor (const [key, node] of Object.entries(this.nodes)) compiled.attachNode(key, node);\n\t\tfor (const [start, end] of this.edges) compiled.attachEdge(start, end);\n\t\tfor (const [start, branches] of Object.entries(this.branches)) for (const [name$1, branch] of Object.entries(branches)) compiled.attachBranch(start, name$1, branch);\n\t\treturn compiled.validate();\n\t}\n\tvalidate(interrupt) {\n\t\tconst allSources = new Set([...this.allEdges].map(([src, _]) => src));\n\t\tfor (const [start] of Object.entries(this.branches)) allSources.add(start);\n\t\tfor (const source of allSources) if (source !== START && !(source in this.nodes)) throw new Error(`Found edge starting at unknown node \\`${source}\\``);\n\t\tconst allTargets = new Set([...this.allEdges].map(([_, target]) => target));\n\t\tfor (const [start, branches] of Object.entries(this.branches)) for (const branch of Object.values(branches)) if (branch.ends != null) for (const end of Object.values(branch.ends)) allTargets.add(end);\n\t\telse {\n\t\t\tallTargets.add(END);\n\t\t\tfor (const node of Object.keys(this.nodes)) if (node !== start) allTargets.add(node);\n\t\t}\n\t\tfor (const node of Object.values(this.nodes)) for (const target of node.ends ?? []) allTargets.add(target);\n\t\tfor (const node of Object.keys(this.nodes)) if (!allTargets.has(node)) throw new UnreachableNodeError([\n\t\t\t`Node \\`${node}\\` is not reachable.`,\n\t\t\t\"\",\n\t\t\t\"If you are returning Command objects from your node,\",\n\t\t\t\"make sure you are passing names of potential destination nodes as an \\\"ends\\\" array\",\n\t\t\t\"into \\\".addNode(..., { ends: [\\\"node1\\\", \\\"node2\\\"] })\\\".\"\n\t\t].join(\"\\n\"), { lc_error_code: \"UNREACHABLE_NODE\" });\n\t\tfor (const target of allTargets) if (target !== END && !(target in this.nodes)) throw new Error(`Found edge ending at unknown node \\`${target}\\``);\n\t\tif (interrupt) {\n\t\t\tfor (const node of interrupt) if (!(node in this.nodes)) throw new Error(`Interrupt node \\`${node}\\` is not present`);\n\t\t}\n\t\tthis.compiled = true;\n\t}\n};\nvar CompiledGraph = class extends Pregel {\n\tbuilder;\n\tconstructor({ builder,...rest }) {\n\t\tsuper(rest);\n\t\tthis.builder = builder;\n\t}\n\tattachNode(key, node) {\n\t\tthis.channels[key] = new EphemeralValue();\n\t\tthis.nodes[key] = new PregelNode({\n\t\t\tchannels: [],\n\t\t\ttriggers: [],\n\t\t\tmetadata: node.metadata,\n\t\t\tsubgraphs: node.subgraphs,\n\t\t\tends: node.ends\n\t\t}).pipe(node.runnable).pipe(new ChannelWrite([{\n\t\t\tchannel: key,\n\t\t\tvalue: PASSTHROUGH\n\t\t}], [TAG_HIDDEN]));\n\t\tthis.streamChannels.push(key);\n\t}\n\tattachEdge(start, end) {\n\t\tif (end === END) {\n\t\t\tif (start === START) throw new Error(\"Cannot have an edge from START to END\");\n\t\t\tthis.nodes[start].writers.push(new ChannelWrite([{\n\t\t\t\tchannel: END,\n\t\t\t\tvalue: PASSTHROUGH\n\t\t\t}], [TAG_HIDDEN]));\n\t\t} else {\n\t\t\tthis.nodes[end].triggers.push(start);\n\t\t\tthis.nodes[end].channels.push(start);\n\t\t}\n\t}\n\tattachBranch(start, name, branch) {\n\t\tif (start === START && !this.nodes[START]) this.nodes[START] = Channel.subscribeTo(START, { tags: [TAG_HIDDEN] });\n\t\tthis.nodes[start].pipe(branch.run((dests) => {\n\t\t\tconst writes = dests.map((dest) => {\n\t\t\t\tif (_isSend(dest)) return dest;\n\t\t\t\treturn {\n\t\t\t\t\tchannel: dest === END ? END : `branch:${start}:${name}:${dest}`,\n\t\t\t\t\tvalue: PASSTHROUGH\n\t\t\t\t};\n\t\t\t});\n\t\t\treturn new ChannelWrite(writes, [TAG_HIDDEN]);\n\t\t}));\n\t\tconst ends = branch.ends ? Object.values(branch.ends) : Object.keys(this.nodes);\n\t\tfor (const end of ends) if (end !== END) {\n\t\t\tconst channelName = `branch:${start}:${name}:${end}`;\n\t\t\tthis.channels[channelName] = new EphemeralValue();\n\t\t\tthis.nodes[end].triggers.push(channelName);\n\t\t\tthis.nodes[end].channels.push(channelName);\n\t\t}\n\t}\n\t/**\n\t* Returns a drawable representation of the computation graph.\n\t*/\n\tasync getGraphAsync(config) {\n\t\tconst xray = config?.xray;\n\t\tconst graph = new Graph();\n\t\tconst startNodes = { [START]: graph.addNode({ schema: z.any() }, START) };\n\t\tconst endNodes = {};\n\t\tlet subgraphs = {};\n\t\tif (xray) subgraphs = Object.fromEntries((await gatherIterator(this.getSubgraphsAsync())).filter((x) => isCompiledGraph(x[1])));\n\t\tfunction addEdge(start, end, label, conditional = false) {\n\t\t\tif (end === END && endNodes[END] === void 0) endNodes[END] = graph.addNode({ schema: z.any() }, END);\n\t\t\tif (startNodes[start] === void 0) return;\n\t\t\tif (endNodes[end] === void 0) throw new Error(`End node ${end} not found!`);\n\t\t\treturn graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);\n\t\t}\n\t\tfor (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {\n\t\t\tconst displayKey = _escapeMermaidKeywords(key);\n\t\t\tconst node = nodeSpec.runnable;\n\t\t\tconst metadata = nodeSpec.metadata ?? {};\n\t\t\tif (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) metadata.__interrupt = \"before,after\";\n\t\t\telse if (this.interruptBefore?.includes(key)) metadata.__interrupt = \"before\";\n\t\t\telse if (this.interruptAfter?.includes(key)) metadata.__interrupt = \"after\";\n\t\t\tif (xray) {\n\t\t\t\tconst newXrayValue = typeof xray === \"number\" ? xray - 1 : xray;\n\t\t\t\tconst drawableSubgraph = subgraphs[key] !== void 0 ? await subgraphs[key].getGraphAsync({\n\t\t\t\t\t...config,\n\t\t\t\t\txray: newXrayValue\n\t\t\t\t}) : node.getGraph(config);\n\t\t\t\tdrawableSubgraph.trimFirstNode();\n\t\t\t\tdrawableSubgraph.trimLastNode();\n\t\t\t\tif (Object.keys(drawableSubgraph.nodes).length > 1) {\n\t\t\t\t\tconst [e, s] = graph.extend(drawableSubgraph, displayKey);\n\t\t\t\t\tif (e === void 0) throw new Error(`Could not extend subgraph \"${key}\" due to missing entrypoint.`);\n\t\t\t\t\tfunction _isRunnableInterface(thing) {\n\t\t\t\t\t\treturn thing ? thing.lc_runnable : false;\n\t\t\t\t\t}\n\t\t\t\t\tfunction _nodeDataStr(id, data) {\n\t\t\t\t\t\tif (id !== void 0 && !validate(id)) return id;\n\t\t\t\t\t\telse if (_isRunnableInterface(data)) try {\n\t\t\t\t\t\t\tlet dataStr = data.getName();\n\t\t\t\t\t\t\tdataStr = dataStr.startsWith(\"Runnable\") ? dataStr.slice(8) : dataStr;\n\t\t\t\t\t\t\treturn dataStr;\n\t\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\t\treturn data.getName();\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse return data.name ?? \"UnknownSchema\";\n\t\t\t\t\t}\n\t\t\t\t\tif (s !== void 0) startNodes[displayKey] = {\n\t\t\t\t\t\tname: _nodeDataStr(s.id, s.data),\n\t\t\t\t\t\t...s\n\t\t\t\t\t};\n\t\t\t\t\tendNodes[displayKey] = {\n\t\t\t\t\t\tname: _nodeDataStr(e.id, e.data),\n\t\t\t\t\t\t...e\n\t\t\t\t\t};\n\t\t\t\t} else {\n\t\t\t\t\tconst newNode = graph.addNode(node, displayKey, metadata);\n\t\t\t\t\tstartNodes[displayKey] = newNode;\n\t\t\t\t\tendNodes[displayKey] = newNode;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst newNode = graph.addNode(node, displayKey, metadata);\n\t\t\t\tstartNodes[displayKey] = newNode;\n\t\t\t\tendNodes[displayKey] = newNode;\n\t\t\t}\n\t\t}\n\t\tconst sortedEdges = [...this.builder.allEdges].sort(([a], [b]) => {\n\t\t\tif (a < b) return -1;\n\t\t\telse if (b > a) return 1;\n\t\t\telse return 0;\n\t\t});\n\t\tfor (const [start, end] of sortedEdges) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));\n\t\tfor (const [start, branches] of Object.entries(this.builder.branches)) {\n\t\t\tconst defaultEnds = {\n\t\t\t\t...Object.fromEntries(Object.keys(this.builder.nodes).filter((k) => k !== start).map((k) => [_escapeMermaidKeywords(k), _escapeMermaidKeywords(k)])),\n\t\t\t\t[END]: END\n\t\t\t};\n\t\t\tfor (const branch of Object.values(branches)) {\n\t\t\t\tlet ends;\n\t\t\t\tif (branch.ends !== void 0) ends = branch.ends;\n\t\t\t\telse ends = defaultEnds;\n\t\t\t\tfor (const [label, end] of Object.entries(ends)) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);\n\t\t\t}\n\t\t}\n\t\tfor (const [key, node] of Object.entries(this.builder.nodes)) if (node.ends !== void 0) for (const end of node.ends) addEdge(_escapeMermaidKeywords(key), _escapeMermaidKeywords(end), void 0, true);\n\t\treturn graph;\n\t}\n\t/**\n\t* Returns a drawable representation of the computation graph.\n\t*\n\t* @deprecated Use getGraphAsync instead. The async method will be the default in the next minor core release.\n\t*/\n\tgetGraph(config) {\n\t\tconst xray = config?.xray;\n\t\tconst graph = new Graph();\n\t\tconst startNodes = { [START]: graph.addNode({ schema: z.any() }, START) };\n\t\tconst endNodes = {};\n\t\tlet subgraphs = {};\n\t\tif (xray) subgraphs = Object.fromEntries(gatherIteratorSync(this.getSubgraphs()).filter((x) => isCompiledGraph(x[1])));\n\t\tfunction addEdge(start, end, label, conditional = false) {\n\t\t\tif (end === END && endNodes[END] === void 0) endNodes[END] = graph.addNode({ schema: z.any() }, END);\n\t\t\treturn graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);\n\t\t}\n\t\tfor (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {\n\t\t\tconst displayKey = _escapeMermaidKeywords(key);\n\t\t\tconst node = nodeSpec.runnable;\n\t\t\tconst metadata = nodeSpec.metadata ?? {};\n\t\t\tif (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) metadata.__interrupt = \"before,after\";\n\t\t\telse if (this.interruptBefore?.includes(key)) metadata.__interrupt = \"before\";\n\t\t\telse if (this.interruptAfter?.includes(key)) metadata.__interrupt = \"after\";\n\t\t\tif (xray) {\n\t\t\t\tconst newXrayValue = typeof xray === \"number\" ? xray - 1 : xray;\n\t\t\t\tconst drawableSubgraph = subgraphs[key] !== void 0 ? subgraphs[key].getGraph({\n\t\t\t\t\t...config,\n\t\t\t\t\txray: newXrayValue\n\t\t\t\t}) : node.getGraph(config);\n\t\t\t\tdrawableSubgraph.trimFirstNode();\n\t\t\t\tdrawableSubgraph.trimLastNode();\n\t\t\t\tif (Object.keys(drawableSubgraph.nodes).length > 1) {\n\t\t\t\t\tconst [e, s] = graph.extend(drawableSubgraph, displayKey);\n\t\t\t\t\tif (e === void 0) throw new Error(`Could not extend subgraph \"${key}\" due to missing entrypoint.`);\n\t\t\t\t\tfunction _isRunnableInterface(thing) {\n\t\t\t\t\t\treturn thing ? thing.lc_runnable : false;\n\t\t\t\t\t}\n\t\t\t\t\tfunction _nodeDataStr(id, data) {\n\t\t\t\t\t\tif (id !== void 0 && !validate(id)) return id;\n\t\t\t\t\t\telse if (_isRunnableInterface(data)) try {\n\t\t\t\t\t\t\tlet dataStr = data.getName();\n\t\t\t\t\t\t\tdataStr = dataStr.startsWith(\"Runnable\") ? dataStr.slice(8) : dataStr;\n\t\t\t\t\t\t\treturn dataStr;\n\t\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\t\treturn data.getName();\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse return data.name ?? \"UnknownSchema\";\n\t\t\t\t\t}\n\t\t\t\t\tif (s !== void 0) startNodes[displayKey] = {\n\t\t\t\t\t\tname: _nodeDataStr(s.id, s.data),\n\t\t\t\t\t\t...s\n\t\t\t\t\t};\n\t\t\t\t\tendNodes[displayKey] = {\n\t\t\t\t\t\tname: _nodeDataStr(e.id, e.data),\n\t\t\t\t\t\t...e\n\t\t\t\t\t};\n\t\t\t\t} else {\n\t\t\t\t\tconst newNode = graph.addNode(node, displayKey, metadata);\n\t\t\t\t\tstartNodes[displayKey] = newNode;\n\t\t\t\t\tendNodes[displayKey] = newNode;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst newNode = graph.addNode(node, displayKey, metadata);\n\t\t\t\tstartNodes[displayKey] = newNode;\n\t\t\t\tendNodes[displayKey] = newNode;\n\t\t\t}\n\t\t}\n\t\tconst sortedEdges = [...this.builder.allEdges].sort(([a], [b]) => {\n\t\t\tif (a < b) return -1;\n\t\t\telse if (b > a) return 1;\n\t\t\telse return 0;\n\t\t});\n\t\tfor (const [start, end] of sortedEdges) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));\n\t\tfor (const [start, branches] of Object.entries(this.builder.branches)) {\n\t\t\tconst defaultEnds = {\n\t\t\t\t...Object.fromEntries(Object.keys(this.builder.nodes).filter((k) => k !== start).map((k) => [_escapeMermaidKeywords(k), _escapeMermaidKeywords(k)])),\n\t\t\t\t[END]: END\n\t\t\t};\n\t\t\tfor (const branch of Object.values(branches)) {\n\t\t\t\tlet ends;\n\t\t\t\tif (branch.ends !== void 0) ends = branch.ends;\n\t\t\t\telse ends = defaultEnds;\n\t\t\t\tfor (const [label, end] of Object.entries(ends)) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);\n\t\t\t}\n\t\t}\n\t\treturn graph;\n\t}\n};\nfunction isCompiledGraph(x) {\n\treturn typeof x.attachNode === \"function\" && typeof x.attachEdge === \"function\";\n}\nfunction _escapeMermaidKeywords(key) {\n\tif (key === \"subgraph\") return `\"${key}\"`;\n\treturn key;\n}\n\n//#endregion\nexport { Branch, CompiledGraph, Graph$1 as Graph };\n//# sourceMappingURL=graph.js.map","import { EmptyChannelError, InvalidUpdateError } from \"../errors.js\";\nimport { BaseChannel } from \"./base.js\";\n\n//#region src/channels/named_barrier_value.ts\nconst areSetsEqual = (a, b) => a.size === b.size && [...a].every((value) => b.has(value));\n/**\n* A channel that waits until all named values are received before making the value available.\n*\n* This ensures that if node N and node M both write to channel C, the value of C will not be updated\n* until N and M have completed updating.\n*/\nvar NamedBarrierValue = class NamedBarrierValue extends BaseChannel {\n\tlc_graph_name = \"NamedBarrierValue\";\n\tnames;\n\tseen;\n\tconstructor(names) {\n\t\tsuper();\n\t\tthis.names = names;\n\t\tthis.seen = /* @__PURE__ */ new Set();\n\t}\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new NamedBarrierValue(this.names);\n\t\tif (typeof checkpoint !== \"undefined\") empty.seen = new Set(checkpoint);\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tlet updated = false;\n\t\tfor (const nodeName of values) if (this.names.has(nodeName)) {\n\t\t\tif (!this.seen.has(nodeName)) {\n\t\t\t\tthis.seen.add(nodeName);\n\t\t\t\tupdated = true;\n\t\t\t}\n\t\t} else throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);\n\t\treturn updated;\n\t}\n\tget() {\n\t\tif (!areSetsEqual(this.names, this.seen)) throw new EmptyChannelError();\n\t\treturn void 0;\n\t}\n\tcheckpoint() {\n\t\treturn [...this.seen];\n\t}\n\tconsume() {\n\t\tif (this.seen && this.names && areSetsEqual(this.seen, this.names)) {\n\t\t\tthis.seen = /* @__PURE__ */ new Set();\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tisAvailable() {\n\t\treturn !!this.names && areSetsEqual(this.names, this.seen);\n\t}\n};\n/**\n* A channel that waits until all named values are received before making the value ready to be made available.\n* It is only made available after finish() is called.\n* @internal\n*/\nvar NamedBarrierValueAfterFinish = class NamedBarrierValueAfterFinish extends BaseChannel {\n\tlc_graph_name = \"NamedBarrierValueAfterFinish\";\n\tnames;\n\tseen;\n\tfinished;\n\tconstructor(names) {\n\t\tsuper();\n\t\tthis.names = names;\n\t\tthis.seen = /* @__PURE__ */ new Set();\n\t\tthis.finished = false;\n\t}\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new NamedBarrierValueAfterFinish(this.names);\n\t\tif (typeof checkpoint !== \"undefined\") {\n\t\t\tconst [seen, finished] = checkpoint;\n\t\t\tempty.seen = new Set(seen);\n\t\t\tempty.finished = finished;\n\t\t}\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tlet updated = false;\n\t\tfor (const nodeName of values) if (this.names.has(nodeName) && !this.seen.has(nodeName)) {\n\t\t\tthis.seen.add(nodeName);\n\t\t\tupdated = true;\n\t\t} else if (!this.names.has(nodeName)) throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);\n\t\treturn updated;\n\t}\n\tget() {\n\t\tif (!this.finished || !areSetsEqual(this.names, this.seen)) throw new EmptyChannelError();\n\t\treturn void 0;\n\t}\n\tcheckpoint() {\n\t\treturn [[...this.seen], this.finished];\n\t}\n\tconsume() {\n\t\tif (this.finished && this.seen && this.names && areSetsEqual(this.seen, this.names)) {\n\t\t\tthis.seen = /* @__PURE__ */ new Set();\n\t\t\tthis.finished = false;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tfinish() {\n\t\tif (!this.finished && !!this.names && areSetsEqual(this.names, this.seen)) {\n\t\t\tthis.finished = true;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tisAvailable() {\n\t\treturn this.finished && !!this.names && areSetsEqual(this.names, this.seen);\n\t}\n};\n\n//#endregion\nexport { NamedBarrierValue, NamedBarrierValueAfterFinish, areSetsEqual };\n//# sourceMappingURL=named_barrier_value.js.map","import { BinaryOperatorAggregate } from \"../../channels/binop.js\";\nimport { LastValue } from \"../../channels/last_value.js\";\nimport { extendInteropZodObject, getInteropZodDefaultGetter, getInteropZodObjectShape, getSchemaDescription, interopZodObjectPartial, isZodSchemaV3 } from \"@langchain/core/utils/types\";\n\n//#region src/graph/zod/meta.ts\nconst META_EXTRAS_DESCRIPTION_PREFIX = \"lg:\";\n/**\n* A registry for storing and managing metadata associated with schemas.\n* This class provides methods to get, extend, remove, and check metadata for a given schema.\n*/\nvar SchemaMetaRegistry = class {\n\t/**\n\t* Internal map storing schema metadata.\n\t* @internal\n\t*/\n\t_map = /* @__PURE__ */ new WeakMap();\n\t/**\n\t* Cache for extended schfemas.\n\t* @internal\n\t*/\n\t_extensionCache = /* @__PURE__ */ new Map();\n\t/**\n\t* Retrieves the metadata associated with a given schema.\n\t* @template TValue The value type of the schema.\n\t* @template TUpdate The update type of the schema (defaults to TValue).\n\t* @param schema The schema to retrieve metadata for.\n\t* @returns The associated SchemaMeta, or undefined if not present.\n\t*/\n\tget(schema) {\n\t\treturn this._map.get(schema);\n\t}\n\t/**\n\t* Extends or sets the metadata for a given schema.\n\t* @template TValue The value type of the schema.\n\t* @template TUpdate The update type of the schema (defaults to TValue).\n\t* @param schema The schema to extend metadata for.\n\t* @param predicate A function that receives the existing metadata (or undefined) and returns the new metadata.\n\t*/\n\textend(schema, predicate) {\n\t\tconst existingMeta = this.get(schema);\n\t\tthis._map.set(schema, predicate(existingMeta));\n\t}\n\t/**\n\t* Removes the metadata associated with a given schema.\n\t* @param schema The schema to remove metadata for.\n\t* @returns The SchemaMetaRegistry instance (for chaining).\n\t*/\n\tremove(schema) {\n\t\tthis._map.delete(schema);\n\t\treturn this;\n\t}\n\t/**\n\t* Checks if metadata exists for a given schema.\n\t* @param schema The schema to check.\n\t* @returns True if metadata exists, false otherwise.\n\t*/\n\thas(schema) {\n\t\treturn this._map.has(schema);\n\t}\n\t/**\n\t* Returns a mapping of channel instances for each property in the schema\n\t* using the associated metadata in the registry.\n\t*\n\t* This is used to create the `channels` object that's passed to the `Graph` constructor.\n\t*\n\t* @template T The shape of the schema.\n\t* @param schema The schema to extract channels from.\n\t* @returns A mapping from property names to channel instances.\n\t*/\n\tgetChannelsForSchema(schema) {\n\t\tconst channels = {};\n\t\tconst shape = getInteropZodObjectShape(schema);\n\t\tfor (const [key, channelSchema] of Object.entries(shape)) {\n\t\t\tconst meta = this.get(channelSchema);\n\t\t\tif (meta?.reducer) channels[key] = new BinaryOperatorAggregate(meta.reducer.fn, meta.default);\n\t\t\telse channels[key] = new LastValue();\n\t\t}\n\t\treturn channels;\n\t}\n\t/**\n\t* Returns a modified schema that introspectively looks at all keys of the provided\n\t* object schema, and applies the augmentations based on meta provided with those keys\n\t* in the registry and the selectors provided in the `effects` parameter.\n\t*\n\t* This assumes that the passed in schema is the \"root\" schema object for a graph where\n\t* the keys of the schema are the channels of the graph. Because we need to represent\n\t* the input of a graph in a couple of different ways, the `effects` parameter allows\n\t* us to apply those augmentations based on pre determined conditions.\n\t*\n\t* @param schema The root schema object to extend.\n\t* @param effects The effects that are being applied.\n\t* @returns The extended schema.\n\t*/\n\tgetExtendedChannelSchemas(schema, effects) {\n\t\tif (Object.keys(effects).length === 0) return schema;\n\t\tconst cacheKey = Object.entries(effects).filter(([, v]) => v === true).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => `${k}:${v}`).join(\"|\");\n\t\tconst cache = this._extensionCache.get(cacheKey) ?? /* @__PURE__ */ new WeakMap();\n\t\tif (cache.has(schema)) return cache.get(schema);\n\t\tlet modifiedSchema = schema;\n\t\tif (effects.withReducerSchema || effects.withJsonSchemaExtrasAsDescription) {\n\t\t\tconst newShapeEntries = Object.entries(getInteropZodObjectShape(schema)).map(([key, schema$1]) => {\n\t\t\t\tconst meta = this.get(schema$1);\n\t\t\t\tlet outputSchema = effects.withReducerSchema ? meta?.reducer?.schema ?? schema$1 : schema$1;\n\t\t\t\tif (effects.withJsonSchemaExtrasAsDescription && meta?.jsonSchemaExtra) {\n\t\t\t\t\tconst description = getSchemaDescription(outputSchema) ?? getSchemaDescription(schema$1);\n\t\t\t\t\tconst strExtras = JSON.stringify({\n\t\t\t\t\t\t...meta.jsonSchemaExtra,\n\t\t\t\t\t\tdescription\n\t\t\t\t\t});\n\t\t\t\t\toutputSchema = outputSchema.describe(`${META_EXTRAS_DESCRIPTION_PREFIX}${strExtras}`);\n\t\t\t\t}\n\t\t\t\treturn [key, outputSchema];\n\t\t\t});\n\t\t\tmodifiedSchema = extendInteropZodObject(schema, Object.fromEntries(newShapeEntries));\n\t\t\tif (isZodSchemaV3(modifiedSchema)) modifiedSchema._def.unknownKeys = \"strip\";\n\t\t}\n\t\tif (effects.asPartial) modifiedSchema = interopZodObjectPartial(modifiedSchema);\n\t\tcache.set(schema, modifiedSchema);\n\t\tthis._extensionCache.set(cacheKey, cache);\n\t\treturn modifiedSchema;\n\t}\n};\nconst schemaMetaRegistry = new SchemaMetaRegistry();\nfunction withLangGraph(schema, meta) {\n\tif (meta.reducer && !meta.default) {\n\t\tconst defaultValueGetter = getInteropZodDefaultGetter(schema);\n\t\tif (defaultValueGetter != null) meta.default = defaultValueGetter;\n\t}\n\tif (meta.reducer) {\n\t\tconst schemaWithReducer = Object.assign(schema, { lg_reducer_schema: meta.reducer?.schema ?? schema });\n\t\tschemaMetaRegistry.extend(schemaWithReducer, () => meta);\n\t\treturn schemaWithReducer;\n\t} else {\n\t\tschemaMetaRegistry.extend(schema, () => meta);\n\t\treturn schema;\n\t}\n}\n\n//#endregion\nexport { META_EXTRAS_DESCRIPTION_PREFIX, SchemaMetaRegistry, schemaMetaRegistry, withLangGraph };\n//# sourceMappingURL=meta.js.map","import { InvalidUpdateError, ParentCommand } from \"../errors.js\";\nimport { isBaseChannel } from \"../channels/base.js\";\nimport { LastValueAfterFinish } from \"../channels/last_value.js\";\nimport { getChannel } from \"./annotation.js\";\nimport { CHECKPOINT_NAMESPACE_END, CHECKPOINT_NAMESPACE_SEPARATOR, Command, END, SELF, START, TAG_HIDDEN, _isSend, isCommand, isInterrupted } from \"../constants.js\";\nimport { RunnableCallable } from \"../utils.js\";\nimport { ChannelWrite, PASSTHROUGH } from \"../pregel/write.js\";\nimport { ChannelRead, PregelNode } from \"../pregel/read.js\";\nimport { isPregelLike } from \"../pregel/utils/subgraph.js\";\nimport { EphemeralValue } from \"../channels/ephemeral_value.js\";\nimport { Branch, CompiledGraph, Graph } from \"./graph.js\";\nimport { NamedBarrierValue, NamedBarrierValueAfterFinish } from \"../channels/named_barrier_value.js\";\nimport { schemaMetaRegistry } from \"./zod/meta.js\";\nimport { Runnable, _coerceToRunnable } from \"@langchain/core/runnables\";\nimport { interopParse, interopZodObjectPartial, isInteropZodObject } from \"@langchain/core/utils/types\";\n\n//#region src/graph/state.ts\nconst ROOT = \"__root__\";\nconst PartialStateSchema = Symbol.for(\"langgraph.state.partial\");\n/**\n* A graph whose nodes communicate by reading and writing to a shared state.\n* Each node takes a defined `State` as input and returns a `Partial<State>`.\n*\n* Each state key can optionally be annotated with a reducer function that\n* will be used to aggregate the values of that key received from multiple nodes.\n* The signature of a reducer function is (left: Value, right: UpdateValue) => Value.\n*\n* See {@link Annotation} for more on defining state.\n*\n* After adding nodes and edges to your graph, you must call `.compile()` on it before\n* you can use it.\n*\n* @example\n* ```ts\n* import {\n*   type BaseMessage,\n*   AIMessage,\n*   HumanMessage,\n* } from \"@langchain/core/messages\";\n* import { StateGraph, Annotation } from \"@langchain/langgraph\";\n*\n* // Define a state with a single key named \"messages\" that will\n* // combine a returned BaseMessage or arrays of BaseMessages\n* const StateAnnotation = Annotation.Root({\n*   sentiment: Annotation<string>,\n*   messages: Annotation<BaseMessage[]>({\n*     reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {\n*       if (Array.isArray(right)) {\n*         return left.concat(right);\n*       }\n*       return left.concat([right]);\n*     },\n*     default: () => [],\n*   }),\n* });\n*\n* const graphBuilder = new StateGraph(StateAnnotation);\n*\n* // A node in the graph that returns an object with a \"messages\" key\n* // will update the state by combining the existing value with the returned one.\n* const myNode = (state: typeof StateAnnotation.State) => {\n*   return {\n*     messages: [new AIMessage(\"Some new response\")],\n*     sentiment: \"positive\",\n*   };\n* };\n*\n* const graph = graphBuilder\n*   .addNode(\"myNode\", myNode)\n*   .addEdge(\"__start__\", \"myNode\")\n*   .addEdge(\"myNode\", \"__end__\")\n*   .compile();\n*\n* await graph.invoke({ messages: [new HumanMessage(\"how are you?\")] });\n*\n* // {\n* //   messages: [HumanMessage(\"how are you?\"), AIMessage(\"Some new response\")],\n* //   sentiment: \"positive\",\n* // }\n* ```\n*/\nvar StateGraph = class extends Graph {\n\tchannels = {};\n\twaitingEdges = /* @__PURE__ */ new Set();\n\t/** @internal */\n\t_schemaDefinition;\n\t/** @internal */\n\t_schemaRuntimeDefinition;\n\t/** @internal */\n\t_inputDefinition;\n\t/** @internal */\n\t_inputRuntimeDefinition;\n\t/** @internal */\n\t_outputDefinition;\n\t/** @internal */\n\t_outputRuntimeDefinition;\n\t/**\n\t* Map schemas to managed values\n\t* @internal\n\t*/\n\t_schemaDefinitions = /* @__PURE__ */ new Map();\n\t/** @internal */\n\t_metaRegistry = schemaMetaRegistry;\n\t/** @internal Used only for typing. */\n\t_configSchema;\n\t/** @internal */\n\t_configRuntimeSchema;\n\t/** @internal */\n\t_interrupt;\n\t/** @internal */\n\t_writer;\n\tconstructor(fields, contextSchema) {\n\t\tsuper();\n\t\tif (isZodStateGraphArgsWithStateSchema(fields)) {\n\t\t\tconst stateDef = this._metaRegistry.getChannelsForSchema(fields.state);\n\t\t\tconst inputDef = fields.input != null ? this._metaRegistry.getChannelsForSchema(fields.input) : stateDef;\n\t\t\tconst outputDef = fields.output != null ? this._metaRegistry.getChannelsForSchema(fields.output) : stateDef;\n\t\t\tthis._schemaDefinition = stateDef;\n\t\t\tthis._schemaRuntimeDefinition = fields.state;\n\t\t\tthis._inputDefinition = inputDef;\n\t\t\tthis._inputRuntimeDefinition = fields.input ?? PartialStateSchema;\n\t\t\tthis._outputDefinition = outputDef;\n\t\t\tthis._outputRuntimeDefinition = fields.output ?? fields.state;\n\t\t} else if (isInteropZodObject(fields)) {\n\t\t\tconst stateDef = this._metaRegistry.getChannelsForSchema(fields);\n\t\t\tthis._schemaDefinition = stateDef;\n\t\t\tthis._schemaRuntimeDefinition = fields;\n\t\t\tthis._inputDefinition = stateDef;\n\t\t\tthis._inputRuntimeDefinition = PartialStateSchema;\n\t\t\tthis._outputDefinition = stateDef;\n\t\t\tthis._outputRuntimeDefinition = fields;\n\t\t} else if (isStateGraphArgsWithInputOutputSchemas(fields)) {\n\t\t\tthis._schemaDefinition = fields.input.spec;\n\t\t\tthis._inputDefinition = fields.input.spec;\n\t\t\tthis._outputDefinition = fields.output.spec;\n\t\t} else if (isStateGraphArgsWithStateSchema(fields)) {\n\t\t\tthis._schemaDefinition = fields.stateSchema.spec;\n\t\t\tthis._inputDefinition = fields.input?.spec ?? this._schemaDefinition;\n\t\t\tthis._outputDefinition = fields.output?.spec ?? this._schemaDefinition;\n\t\t} else if (isStateDefinition(fields) || isAnnotationRoot(fields)) {\n\t\t\tconst spec = isAnnotationRoot(fields) ? fields.spec : fields;\n\t\t\tthis._schemaDefinition = spec;\n\t\t} else if (isStateGraphArgs(fields)) {\n\t\t\tconst spec = _getChannels(fields.channels);\n\t\t\tthis._schemaDefinition = spec;\n\t\t} else throw new Error(\"Invalid StateGraph input. Make sure to pass a valid Annotation.Root or Zod schema.\");\n\t\tthis._inputDefinition ??= this._schemaDefinition;\n\t\tthis._outputDefinition ??= this._schemaDefinition;\n\t\tthis._addSchema(this._schemaDefinition);\n\t\tthis._addSchema(this._inputDefinition);\n\t\tthis._addSchema(this._outputDefinition);\n\t\tfunction isOptions(options) {\n\t\t\treturn typeof options === \"object\" && options != null && !(\"spec\" in options) && !isInteropZodObject(options);\n\t\t}\n\t\tif (isOptions(contextSchema)) {\n\t\t\tif (isInteropZodObject(contextSchema.context)) this._configRuntimeSchema = contextSchema.context;\n\t\t\tthis._interrupt = contextSchema.interrupt;\n\t\t\tthis._writer = contextSchema.writer;\n\t\t} else if (isInteropZodObject(contextSchema)) this._configRuntimeSchema = contextSchema;\n\t}\n\tget allEdges() {\n\t\treturn new Set([...this.edges, ...Array.from(this.waitingEdges).flatMap(([starts, end]) => starts.map((start) => [start, end]))]);\n\t}\n\t_addSchema(stateDefinition) {\n\t\tif (this._schemaDefinitions.has(stateDefinition)) return;\n\t\tthis._schemaDefinitions.set(stateDefinition, stateDefinition);\n\t\tfor (const [key, val] of Object.entries(stateDefinition)) {\n\t\t\tlet channel;\n\t\t\tif (typeof val === \"function\") channel = val();\n\t\t\telse channel = val;\n\t\t\tif (this.channels[key] !== void 0) {\n\t\t\t\tif (this.channels[key] !== channel) {\n\t\t\t\t\tif (channel.lc_graph_name !== \"LastValue\") throw new Error(`Channel \"${key}\" already exists with a different type.`);\n\t\t\t\t}\n\t\t\t} else this.channels[key] = channel;\n\t\t}\n\t}\n\taddNode(...args) {\n\t\tfunction isMultipleNodes(args$1) {\n\t\t\treturn args$1.length >= 1 && typeof args$1[0] !== \"string\";\n\t\t}\n\t\tconst nodes = isMultipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]).map(([key, action]) => [key, action]) : [[\n\t\t\targs[0],\n\t\t\targs[1],\n\t\t\targs[2]\n\t\t]];\n\t\tif (nodes.length === 0) throw new Error(\"No nodes provided in `addNode`\");\n\t\tfor (const [key, action, options] of nodes) {\n\t\t\tif (key in this.channels) throw new Error(`${key} is already being used as a state attribute (a.k.a. a channel), cannot also be used as a node name.`);\n\t\t\tfor (const reservedChar of [CHECKPOINT_NAMESPACE_SEPARATOR, CHECKPOINT_NAMESPACE_END]) if (key.includes(reservedChar)) throw new Error(`\"${reservedChar}\" is a reserved character and is not allowed in node names.`);\n\t\t\tthis.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);\n\t\t\tif (key in this.nodes) throw new Error(`Node \\`${key}\\` already present.`);\n\t\t\tif (key === END || key === START) throw new Error(`Node \\`${key}\\` is reserved.`);\n\t\t\tlet inputSpec = this._schemaDefinition;\n\t\t\tif (options?.input !== void 0) {\n\t\t\t\tif (isInteropZodObject(options.input)) inputSpec = this._metaRegistry.getChannelsForSchema(options.input);\n\t\t\t\telse if (options.input.spec !== void 0) inputSpec = options.input.spec;\n\t\t\t}\n\t\t\tif (inputSpec !== void 0) this._addSchema(inputSpec);\n\t\t\tlet runnable;\n\t\t\tif (Runnable.isRunnable(action)) runnable = action;\n\t\t\telse if (typeof action === \"function\") runnable = new RunnableCallable({\n\t\t\t\tfunc: action,\n\t\t\t\tname: key,\n\t\t\t\ttrace: false\n\t\t\t});\n\t\t\telse runnable = _coerceToRunnable(action);\n\t\t\tlet cachePolicy = options?.cachePolicy;\n\t\t\tif (typeof cachePolicy === \"boolean\") cachePolicy = cachePolicy ? {} : void 0;\n\t\t\tconst nodeSpec = {\n\t\t\t\trunnable,\n\t\t\t\tretryPolicy: options?.retryPolicy,\n\t\t\t\tcachePolicy,\n\t\t\t\tmetadata: options?.metadata,\n\t\t\t\tinput: inputSpec ?? this._schemaDefinition,\n\t\t\t\tsubgraphs: isPregelLike(runnable) ? [runnable] : options?.subgraphs,\n\t\t\t\tends: options?.ends,\n\t\t\t\tdefer: options?.defer\n\t\t\t};\n\t\t\tthis.nodes[key] = nodeSpec;\n\t\t}\n\t\treturn this;\n\t}\n\taddEdge(startKey, endKey) {\n\t\tif (typeof startKey === \"string\") return super.addEdge(startKey, endKey);\n\t\tif (this.compiled) console.warn(\"Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\");\n\t\tfor (const start of startKey) {\n\t\t\tif (start === END) throw new Error(\"END cannot be a start node\");\n\t\t\tif (!Object.keys(this.nodes).some((node) => node === start)) throw new Error(`Need to add a node named \"${start}\" first`);\n\t\t}\n\t\tif (endKey === END) throw new Error(\"END cannot be an end node\");\n\t\tif (!Object.keys(this.nodes).some((node) => node === endKey)) throw new Error(`Need to add a node named \"${endKey}\" first`);\n\t\tthis.waitingEdges.add([startKey, endKey]);\n\t\treturn this;\n\t}\n\taddSequence(nodes) {\n\t\tconst parsedNodes = Array.isArray(nodes) ? nodes : Object.entries(nodes);\n\t\tif (parsedNodes.length === 0) throw new Error(\"Sequence requires at least one node.\");\n\t\tlet previousNode;\n\t\tfor (const [key, action, options] of parsedNodes) {\n\t\t\tif (key in this.nodes) throw new Error(`Node names must be unique: node with the name \"${key}\" already exists.`);\n\t\t\tconst validKey = key;\n\t\t\tthis.addNode(validKey, action, options);\n\t\t\tif (previousNode != null) this.addEdge(previousNode, validKey);\n\t\t\tpreviousNode = validKey;\n\t\t}\n\t\treturn this;\n\t}\n\tcompile({ checkpointer, store, cache, interruptBefore, interruptAfter, name, description } = {}) {\n\t\tthis.validate([...Array.isArray(interruptBefore) ? interruptBefore : [], ...Array.isArray(interruptAfter) ? interruptAfter : []]);\n\t\tconst outputKeys = Object.keys(this._schemaDefinitions.get(this._outputDefinition));\n\t\tconst outputChannels = outputKeys.length === 1 && outputKeys[0] === ROOT ? ROOT : outputKeys;\n\t\tconst streamKeys = Object.keys(this.channels);\n\t\tconst streamChannels = streamKeys.length === 1 && streamKeys[0] === ROOT ? ROOT : streamKeys;\n\t\tconst userInterrupt = this._interrupt;\n\t\tconst compiled = new CompiledStateGraph({\n\t\t\tbuilder: this,\n\t\t\tcheckpointer,\n\t\t\tinterruptAfter,\n\t\t\tinterruptBefore,\n\t\t\tautoValidate: false,\n\t\t\tnodes: {},\n\t\t\tchannels: {\n\t\t\t\t...this.channels,\n\t\t\t\t[START]: new EphemeralValue()\n\t\t\t},\n\t\t\tinputChannels: START,\n\t\t\toutputChannels,\n\t\t\tstreamChannels,\n\t\t\tstreamMode: \"updates\",\n\t\t\tstore,\n\t\t\tcache,\n\t\t\tname,\n\t\t\tdescription,\n\t\t\tuserInterrupt\n\t\t});\n\t\tcompiled.attachNode(START);\n\t\tfor (const [key, node] of Object.entries(this.nodes)) compiled.attachNode(key, node);\n\t\tcompiled.attachBranch(START, SELF, _getControlBranch(), { withReader: false });\n\t\tfor (const [key] of Object.entries(this.nodes)) compiled.attachBranch(key, SELF, _getControlBranch(), { withReader: false });\n\t\tfor (const [start, end] of this.edges) compiled.attachEdge(start, end);\n\t\tfor (const [starts, end] of this.waitingEdges) compiled.attachEdge(starts, end);\n\t\tfor (const [start, branches] of Object.entries(this.branches)) for (const [name$1, branch] of Object.entries(branches)) compiled.attachBranch(start, name$1, branch);\n\t\treturn compiled.validate();\n\t}\n};\nfunction _getChannels(schema) {\n\tconst channels = {};\n\tfor (const [name, val] of Object.entries(schema)) if (name === ROOT) channels[name] = getChannel(val);\n\telse channels[name] = getChannel(val);\n\treturn channels;\n}\n/**\n* Final result from building and compiling a {@link StateGraph}.\n* Should not be instantiated directly, only using the StateGraph `.compile()`\n* instance method.\n*/\nvar CompiledStateGraph = class extends CompiledGraph {\n\t/**\n\t* The description of the compiled graph.\n\t* This is used by the supervisor agent to describe the handoff to the agent.\n\t*/\n\tdescription;\n\t/** @internal */\n\t_metaRegistry = schemaMetaRegistry;\n\tconstructor({ description,...rest }) {\n\t\tsuper(rest);\n\t\tthis.description = description;\n\t}\n\tattachNode(key, node) {\n\t\tlet outputKeys;\n\t\tif (key === START) outputKeys = Object.entries(this.builder._schemaDefinitions.get(this.builder._inputDefinition)).map(([k]) => k);\n\t\telse outputKeys = Object.keys(this.builder.channels);\n\t\tfunction _getRoot(input) {\n\t\t\tif (isCommand(input)) {\n\t\t\t\tif (input.graph === Command.PARENT) return null;\n\t\t\t\treturn input._updateAsTuples();\n\t\t\t} else if (Array.isArray(input) && input.length > 0 && input.some((i) => isCommand(i))) {\n\t\t\t\tconst updates = [];\n\t\t\t\tfor (const i of input) if (isCommand(i)) {\n\t\t\t\t\tif (i.graph === Command.PARENT) continue;\n\t\t\t\t\tupdates.push(...i._updateAsTuples());\n\t\t\t\t} else updates.push([ROOT, i]);\n\t\t\t\treturn updates;\n\t\t\t} else if (input != null) return [[ROOT, input]];\n\t\t\treturn null;\n\t\t}\n\t\tconst nodeKey = key;\n\t\tfunction _getUpdates(input) {\n\t\t\tif (!input) return null;\n\t\t\telse if (isCommand(input)) {\n\t\t\t\tif (input.graph === Command.PARENT) return null;\n\t\t\t\treturn input._updateAsTuples().filter(([k]) => outputKeys.includes(k));\n\t\t\t} else if (Array.isArray(input) && input.length > 0 && input.some(isCommand)) {\n\t\t\t\tconst updates = [];\n\t\t\t\tfor (const item of input) if (isCommand(item)) {\n\t\t\t\t\tif (item.graph === Command.PARENT) continue;\n\t\t\t\t\tupdates.push(...item._updateAsTuples().filter(([k]) => outputKeys.includes(k)));\n\t\t\t\t} else {\n\t\t\t\t\tconst itemUpdates = _getUpdates(item);\n\t\t\t\t\tif (itemUpdates) updates.push(...itemUpdates ?? []);\n\t\t\t\t}\n\t\t\t\treturn updates;\n\t\t\t} else if (typeof input === \"object\" && !Array.isArray(input)) return Object.entries(input).filter(([k]) => outputKeys.includes(k));\n\t\t\telse {\n\t\t\t\tconst typeofInput = Array.isArray(input) ? \"array\" : typeof input;\n\t\t\t\tthrow new InvalidUpdateError(`Expected node \"${nodeKey.toString()}\" to return an object or an array containing at least one Command object, received ${typeofInput}`, { lc_error_code: \"INVALID_GRAPH_NODE_RETURN_VALUE\" });\n\t\t\t}\n\t\t}\n\t\tconst stateWriteEntries = [{\n\t\t\tvalue: PASSTHROUGH,\n\t\t\tmapper: new RunnableCallable({\n\t\t\t\tfunc: outputKeys.length && outputKeys[0] === ROOT ? _getRoot : _getUpdates,\n\t\t\t\ttrace: false,\n\t\t\t\trecurse: false\n\t\t\t})\n\t\t}];\n\t\tif (key === START) this.nodes[key] = new PregelNode({\n\t\t\ttags: [TAG_HIDDEN],\n\t\t\ttriggers: [START],\n\t\t\tchannels: [START],\n\t\t\twriters: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])]\n\t\t});\n\t\telse {\n\t\t\tconst inputDefinition = node?.input ?? this.builder._schemaDefinition;\n\t\t\tconst inputValues = Object.fromEntries(Object.keys(this.builder._schemaDefinitions.get(inputDefinition)).map((k) => [k, k]));\n\t\t\tconst isSingleInput = Object.keys(inputValues).length === 1 && ROOT in inputValues;\n\t\t\tconst branchChannel = `branch:to:${key}`;\n\t\t\tthis.channels[branchChannel] = node?.defer ? new LastValueAfterFinish() : new EphemeralValue(false);\n\t\t\tthis.nodes[key] = new PregelNode({\n\t\t\t\ttriggers: [branchChannel],\n\t\t\t\tchannels: isSingleInput ? Object.keys(inputValues) : inputValues,\n\t\t\t\twriters: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])],\n\t\t\t\tmapper: isSingleInput ? void 0 : (input) => {\n\t\t\t\t\treturn Object.fromEntries(Object.entries(input).filter(([k]) => k in inputValues));\n\t\t\t\t},\n\t\t\t\tbound: node?.runnable,\n\t\t\t\tmetadata: node?.metadata,\n\t\t\t\tretryPolicy: node?.retryPolicy,\n\t\t\t\tcachePolicy: node?.cachePolicy,\n\t\t\t\tsubgraphs: node?.subgraphs,\n\t\t\t\tends: node?.ends\n\t\t\t});\n\t\t}\n\t}\n\tattachEdge(starts, end) {\n\t\tif (end === END) return;\n\t\tif (typeof starts === \"string\") this.nodes[starts].writers.push(new ChannelWrite([{\n\t\t\tchannel: `branch:to:${end}`,\n\t\t\tvalue: null\n\t\t}], [TAG_HIDDEN]));\n\t\telse if (Array.isArray(starts)) {\n\t\t\tconst channelName = `join:${starts.join(\"+\")}:${end}`;\n\t\t\tthis.channels[channelName] = this.builder.nodes[end].defer ? new NamedBarrierValueAfterFinish(new Set(starts)) : new NamedBarrierValue(new Set(starts));\n\t\t\tthis.nodes[end].triggers.push(channelName);\n\t\t\tfor (const start of starts) this.nodes[start].writers.push(new ChannelWrite([{\n\t\t\t\tchannel: channelName,\n\t\t\t\tvalue: start\n\t\t\t}], [TAG_HIDDEN]));\n\t\t}\n\t}\n\tattachBranch(start, _, branch, options = { withReader: true }) {\n\t\tconst branchWriter = async (packets, config) => {\n\t\t\tconst filteredPackets = packets.filter((p) => p !== END);\n\t\t\tif (!filteredPackets.length) return;\n\t\t\tconst writes = filteredPackets.map((p) => {\n\t\t\t\tif (_isSend(p)) return p;\n\t\t\t\treturn {\n\t\t\t\t\tchannel: p === END ? p : `branch:to:${p}`,\n\t\t\t\t\tvalue: start\n\t\t\t\t};\n\t\t\t});\n\t\t\tawait ChannelWrite.doWrite({\n\t\t\t\t...config,\n\t\t\t\ttags: (config.tags ?? []).concat([TAG_HIDDEN])\n\t\t\t}, writes);\n\t\t};\n\t\tthis.nodes[start].writers.push(branch.run(branchWriter, options.withReader ? (config) => ChannelRead.doRead(config, this.streamChannels ?? this.outputChannels, true) : void 0));\n\t}\n\tasync _validateInput(input) {\n\t\tif (input == null) return input;\n\t\tconst schema = (() => {\n\t\t\tconst input$1 = this.builder._inputRuntimeDefinition;\n\t\t\tconst schema$1 = this.builder._schemaRuntimeDefinition;\n\t\t\tconst apply = (schema$2) => {\n\t\t\t\tif (schema$2 == null) return void 0;\n\t\t\t\treturn this._metaRegistry.getExtendedChannelSchemas(schema$2, { withReducerSchema: true });\n\t\t\t};\n\t\t\tif (isInteropZodObject(input$1)) return apply(input$1);\n\t\t\tif (input$1 === PartialStateSchema) return interopZodObjectPartial(apply(schema$1));\n\t\t\treturn void 0;\n\t\t})();\n\t\tif (isCommand(input)) {\n\t\t\tconst parsedInput = input;\n\t\t\tif (input.update && schema != null) parsedInput.update = interopParse(schema, input.update);\n\t\t\treturn parsedInput;\n\t\t}\n\t\tif (schema != null) return interopParse(schema, input);\n\t\treturn input;\n\t}\n\tisInterrupted(input) {\n\t\treturn isInterrupted(input);\n\t}\n\tasync _validateContext(config) {\n\t\tconst configSchema = this.builder._configRuntimeSchema;\n\t\tif (isInteropZodObject(configSchema)) interopParse(configSchema, config);\n\t\treturn config;\n\t}\n};\nfunction isStateDefinition(obj) {\n\treturn typeof obj === \"object\" && obj !== null && !Array.isArray(obj) && Object.keys(obj).length > 0 && Object.values(obj).every((v) => typeof v === \"function\" || isBaseChannel(v));\n}\nfunction isAnnotationRoot(obj) {\n\treturn typeof obj === \"object\" && obj !== null && \"lc_graph_name\" in obj && obj.lc_graph_name === \"AnnotationRoot\";\n}\nfunction isStateGraphArgs(obj) {\n\treturn typeof obj === \"object\" && obj !== null && obj.channels !== void 0;\n}\nfunction isStateGraphArgsWithStateSchema(obj) {\n\treturn typeof obj === \"object\" && obj !== null && obj.stateSchema !== void 0;\n}\nfunction isStateGraphArgsWithInputOutputSchemas(obj) {\n\treturn typeof obj === \"object\" && obj !== null && obj.stateSchema === void 0 && obj.input !== void 0 && obj.output !== void 0;\n}\nfunction isZodStateGraphArgsWithStateSchema(value) {\n\tif (typeof value !== \"object\" || value == null) return false;\n\tif (!(\"state\" in value) || !isInteropZodObject(value.state)) return false;\n\tif (\"input\" in value && !isInteropZodObject(value.input)) return false;\n\tif (\"output\" in value && !isInteropZodObject(value.output)) return false;\n\treturn true;\n}\nfunction _controlBranch(value) {\n\tif (_isSend(value)) return [value];\n\tconst commands = [];\n\tif (isCommand(value)) commands.push(value);\n\telse if (Array.isArray(value)) commands.push(...value.filter(isCommand));\n\tconst destinations = [];\n\tfor (const command of commands) {\n\t\tif (command.graph === Command.PARENT) throw new ParentCommand(command);\n\t\tif (_isSend(command.goto)) destinations.push(command.goto);\n\t\telse if (typeof command.goto === \"string\") destinations.push(command.goto);\n\t\telse if (Array.isArray(command.goto)) destinations.push(...command.goto);\n\t}\n\treturn destinations;\n}\nfunction _getControlBranch() {\n\tconst CONTROL_BRANCH_PATH = new RunnableCallable({\n\t\tfunc: _controlBranch,\n\t\ttags: [TAG_HIDDEN],\n\t\ttrace: false,\n\t\trecurse: false,\n\t\tname: \"<control_branch>\"\n\t});\n\treturn new Branch({ path: CONTROL_BRANCH_PATH });\n}\n\n//#endregion\nexport { CompiledStateGraph, StateGraph };\n//# sourceMappingURL=state.js.map","import { ensureLangGraphConfig } from \"../pregel/utils/config.js\";\nimport { StateGraph } from \"./state.js\";\nimport { v4 } from \"uuid\";\nimport { coerceMessageLikeToMessage } from \"@langchain/core/messages\";\n\n//#region src/graph/message.ts\nconst REMOVE_ALL_MESSAGES = \"__remove_all__\";\n/**\n* Prebuilt reducer that combines returned messages.\n* Can handle standard messages and special modifiers like {@link RemoveMessage}\n* instances.\n*/\nfunction messagesStateReducer(left, right) {\n\tconst leftArray = Array.isArray(left) ? left : [left];\n\tconst rightArray = Array.isArray(right) ? right : [right];\n\tconst leftMessages = leftArray.map(coerceMessageLikeToMessage);\n\tconst rightMessages = rightArray.map(coerceMessageLikeToMessage);\n\tfor (const m of leftMessages) if (m.id === null || m.id === void 0) {\n\t\tm.id = v4();\n\t\tm.lc_kwargs.id = m.id;\n\t}\n\tlet removeAllIdx;\n\tfor (let i = 0; i < rightMessages.length; i += 1) {\n\t\tconst m = rightMessages[i];\n\t\tif (m.id === null || m.id === void 0) {\n\t\t\tm.id = v4();\n\t\t\tm.lc_kwargs.id = m.id;\n\t\t}\n\t\tif (m.getType() === \"remove\" && m.id === REMOVE_ALL_MESSAGES) removeAllIdx = i;\n\t}\n\tif (removeAllIdx != null) return rightMessages.slice(removeAllIdx + 1);\n\tconst merged = [...leftMessages];\n\tconst mergedById = new Map(merged.map((m, i) => [m.id, i]));\n\tconst idsToRemove = /* @__PURE__ */ new Set();\n\tfor (const m of rightMessages) {\n\t\tconst existingIdx = mergedById.get(m.id);\n\t\tif (existingIdx !== void 0) if (m.getType() === \"remove\") idsToRemove.add(m.id);\n\t\telse {\n\t\t\tidsToRemove.delete(m.id);\n\t\t\tmerged[existingIdx] = m;\n\t\t}\n\t\telse {\n\t\t\tif (m.getType() === \"remove\") throw new Error(`Attempting to delete a message with an ID that doesn't exist ('${m.id}')`);\n\t\t\tmergedById.set(m.id, merged.length);\n\t\t\tmerged.push(m);\n\t\t}\n\t}\n\treturn merged.filter((m) => !idsToRemove.has(m.id));\n}\n/** @ignore */\nvar MessageGraph = class extends StateGraph {\n\tconstructor() {\n\t\tsuper({ channels: { __root__: {\n\t\t\treducer: messagesStateReducer,\n\t\t\tdefault: () => []\n\t\t} } });\n\t}\n};\n/**\n* Manually push a message to a message stream.\n*\n* This is useful when you need to push a manually created message before the node\n* has finished executing.\n*\n* When a message is pushed, it will be automatically persisted to the state after the node has finished executing.\n* To disable persisting, set `options.stateKey` to `null`.\n*\n* @param message The message to push. The message must have an ID set, otherwise an error will be thrown.\n* @param options RunnableConfig / Runtime coming from node context.\n*/\nfunction pushMessage(message, options) {\n\tconst { stateKey: userStateKey,...userConfig } = options ?? {};\n\tconst config = ensureLangGraphConfig(userConfig);\n\tlet stateKey = userStateKey ?? \"messages\";\n\tif (userStateKey === null) stateKey = void 0;\n\tconst validMessage = coerceMessageLikeToMessage(message);\n\tif (!validMessage.id) throw new Error(\"Message ID is required.\");\n\tconst callbacks = (() => {\n\t\tif (Array.isArray(config.callbacks)) return config.callbacks;\n\t\tif (typeof config.callbacks !== \"undefined\") return config.callbacks.handlers;\n\t\treturn [];\n\t})();\n\tconst messagesHandler = callbacks.find((cb) => \"name\" in cb && cb.name === \"StreamMessagesHandler\");\n\tif (messagesHandler) {\n\t\tconst metadata = config.metadata ?? {};\n\t\tconst namespace = (metadata.langgraph_checkpoint_ns ?? \"\").split(\"|\");\n\t\tmessagesHandler._emit([namespace, metadata], validMessage, void 0, false);\n\t}\n\tif (stateKey) config.configurable?.__pregel_send?.([[stateKey, validMessage]]);\n\treturn validMessage;\n}\n\n//#endregion\nexport { MessageGraph, REMOVE_ALL_MESSAGES, messagesStateReducer, pushMessage };\n//# sourceMappingURL=message.js.map","import { LastValue } from \"../channels/last_value.js\";\nimport { CONFIG_KEY_PREVIOUS_STATE, END, PREVIOUS, START, TAG_HIDDEN } from \"../constants.js\";\nimport { RunnableCallable, isAsyncGeneratorFunction, isGeneratorFunction } from \"../utils.js\";\nimport { ChannelWrite, PASSTHROUGH } from \"../pregel/write.js\";\nimport { PregelNode } from \"../pregel/read.js\";\nimport { call, getRunnableForEntrypoint } from \"../pregel/call.js\";\nimport { Pregel } from \"../pregel/index.js\";\nimport { EphemeralValue } from \"../channels/ephemeral_value.js\";\nimport { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\n\n//#region src/func/index.ts\n/**\n* Define a LangGraph task using the `task` function.\n*\n* Tasks can only be called from within an {@link entrypoint} or from within a StateGraph.\n* A task can be called like a regular function with the following differences:\n*\n* - When a checkpointer is enabled, the function inputs and outputs must be serializable.\n* - The wrapped function can only be called from within an entrypoint or StateGraph.\n* - Calling the function produces a promise. This makes it easy to parallelize tasks.\n*\n* @typeParam ArgsT - The type of arguments the task function accepts\n* @typeParam OutputT - The type of value the task function returns\n* @param optionsOrName - Either an {@link TaskOptions} object, or a string for the name of the task\n* @param func - The function that executes this task\n* @returns A proxy function that accepts the same arguments as the original and always returns the result as a Promise\n*\n* @example basic example\n* ```typescript\n* const addOne = task(\"add\", async (a: number) => a + 1);\n*\n* const workflow = entrypoint(\"example\", async (numbers: number[]) => {\n*   const promises = numbers.map(n => addOne(n));\n*   const results = await Promise.all(promises);\n*   return results;\n* });\n*\n* // Call the entrypoint\n* await workflow.invoke([1, 2, 3]); // Returns [2, 3, 4]\n* ```\n*\n* @example using a retry policy\n* ```typescript\n* const addOne = task({\n*     name: \"add\",\n*     retry: { maxAttempts: 3 }\n*   },\n*   async (a: number) => a + 1\n* );\n*\n* const workflow = entrypoint(\"example\", async (numbers: number[]) => {\n*   const promises = numbers.map(n => addOne(n));\n*   const results = await Promise.all(promises);\n*   return results;\n* });\n* ```\n* @category Functional API\n*/\nfunction task(optionsOrName, func) {\n\tconst options = typeof optionsOrName === \"string\" ? {\n\t\tname: optionsOrName,\n\t\tretry: void 0,\n\t\tcachePolicy: void 0\n\t} : optionsOrName;\n\tconst { name, retry } = options;\n\tif (isAsyncGeneratorFunction(func) || isGeneratorFunction(func)) throw new Error(\"Generators are disallowed as tasks. For streaming responses, use config.write.\");\n\tconst cachePolicy = options.cachePolicy ?? (\"cache\" in options ? options.cache : void 0);\n\tlet cache;\n\tif (typeof cachePolicy === \"boolean\") cache = cachePolicy ? {} : void 0;\n\telse cache = cachePolicy;\n\treturn (...args) => {\n\t\treturn call({\n\t\t\tfunc,\n\t\t\tname,\n\t\t\tretry,\n\t\t\tcache\n\t\t}, ...args);\n\t};\n}\n/**\n* Define a LangGraph workflow using the `entrypoint` function.\n*\n* ### Function signature\n*\n* The wrapped function must accept at most **two parameters**. The first parameter\n* is the input to the function. The second (optional) parameter is a\n* {@link LangGraphRunnableConfig} object. If you wish to pass multiple parameters to\n* the function, you can pass them as an object.\n*\n* ### Helper functions\n*\n* #### Streaming\n* To write data to the \"custom\" stream, use the {@link getWriter} function, or the\n* {@link LangGraphRunnableConfig.writer} property.\n*\n* #### State management\n* The {@link getPreviousState} function can be used to access the previous state\n* that was returned from the last invocation of the entrypoint on the same thread id.\n*\n* If you wish to save state other than the return value, you can use the\n* {@link entrypoint.final} function.\n*\n* @typeParam InputT - The type of input the entrypoint accepts\n* @typeParam OutputT - The type of output the entrypoint produces\n* @param optionsOrName - Either an {@link EntrypointOptions} object, or a string for the name of the entrypoint\n* @param func - The function that executes this entrypoint\n* @returns A {@link Pregel} instance that can be run to execute the workflow\n*\n* @example Using entrypoint and tasks\n* ```typescript\n* import { task, entrypoint } from \"@langchain/langgraph\";\n* import { MemorySaver } from \"@langchain/langgraph-checkpoint\";\n* import { interrupt, Command } from \"@langchain/langgraph\";\n*\n* const composeEssay = task(\"compose\", async (topic: string) => {\n*   await new Promise(r => setTimeout(r, 1000)); // Simulate slow operation\n*   return `An essay about ${topic}`;\n* });\n*\n* const reviewWorkflow = entrypoint({\n*   name: \"review\",\n*   checkpointer: new MemorySaver()\n* }, async (topic: string) => {\n*   const essay = await composeEssay(topic);\n*   const humanReview = await interrupt({\n*     question: \"Please provide a review\",\n*     essay\n*   });\n*   return {\n*     essay,\n*     review: humanReview\n*   };\n* });\n*\n* // Example configuration for the workflow\n* const config = {\n*   configurable: {\n*     thread_id: \"some_thread\"\n*   }\n* };\n*\n* // Topic for the essay\n* const topic = \"cats\";\n*\n* // Stream the workflow to generate the essay and await human review\n* for await (const result of reviewWorkflow.stream(topic, config)) {\n*   console.log(result);\n* }\n*\n* // Example human review provided after the interrupt\n* const humanReview = \"This essay is great.\";\n*\n* // Resume the workflow with the provided human review\n* for await (const result of reviewWorkflow.stream(new Command({ resume: humanReview }), config)) {\n*   console.log(result);\n* }\n* ```\n*\n* @example Accessing the previous return value\n* ```typescript\n* import { entrypoint, getPreviousState } from \"@langchain/langgraph\";\n* import { MemorySaver } from \"@langchain/langgraph-checkpoint\";\n*\n* const accumulator = entrypoint({\n*   name: \"accumulator\",\n*   checkpointer: new MemorySaver()\n* }, async (input: string) => {\n*   const previous = getPreviousState<number>();\n*   return previous !== undefined ? `${previous } ${input}` : input;\n* });\n*\n* const config = {\n*   configurable: {\n*     thread_id: \"some_thread\"\n*   }\n* };\n* await accumulator.invoke(\"hello\", config); // returns \"hello\"\n* await accumulator.invoke(\"world\", config); // returns \"hello world\"\n* ```\n*\n* @example Using entrypoint.final to save a value\n* ```typescript\n* import { entrypoint, getPreviousState } from \"@langchain/langgraph\";\n* import { MemorySaver } from \"@langchain/langgraph-checkpoint\";\n*\n* const myWorkflow = entrypoint({\n*   name: \"accumulator\",\n*   checkpointer: new MemorySaver()\n* }, async (num: number) => {\n*   const previous = getPreviousState<number>();\n*\n*   // This will return the previous value to the caller, saving\n*   // 2 * num to the checkpoint, which will be used in the next invocation\n*   // for the `previous` parameter.\n*   return entrypoint.final({\n*     value: previous ?? 0,\n*     save: 2 * num\n*   });\n* });\n*\n* const config = {\n*   configurable: {\n*     thread_id: \"some_thread\"\n*   }\n* };\n*\n* await myWorkflow.invoke(3, config); // 0 (previous was undefined)\n* await myWorkflow.invoke(1, config); // 6 (previous was 3 * 2 from the previous invocation)\n* ```\n* @category Functional API\n*/\nconst entrypoint = function entrypoint$1(optionsOrName, func) {\n\tconst { name, checkpointer, store, cache } = typeof optionsOrName === \"string\" ? {\n\t\tname: optionsOrName,\n\t\tcheckpointer: void 0,\n\t\tstore: void 0\n\t} : optionsOrName;\n\tif (isAsyncGeneratorFunction(func) || isGeneratorFunction(func)) throw new Error(\"Generators are disallowed as entrypoints. For streaming responses, use config.write.\");\n\tconst streamMode = \"updates\";\n\tconst bound = getRunnableForEntrypoint(name, func);\n\tfunction isEntrypointFinal(value) {\n\t\treturn typeof value === \"object\" && value !== null && \"__lg_type\" in value && value.__lg_type === \"__pregel_final\";\n\t}\n\tconst pluckReturnValue = new RunnableCallable({\n\t\tname: \"pluckReturnValue\",\n\t\tfunc: (value) => {\n\t\t\treturn isEntrypointFinal(value) ? value.value : value;\n\t\t}\n\t});\n\tconst pluckSaveValue = new RunnableCallable({\n\t\tname: \"pluckSaveValue\",\n\t\tfunc: (value) => {\n\t\t\treturn isEntrypointFinal(value) ? value.save : value;\n\t\t}\n\t});\n\tconst entrypointNode = new PregelNode({\n\t\tbound,\n\t\ttriggers: [START],\n\t\tchannels: [START],\n\t\twriters: [new ChannelWrite([{\n\t\t\tchannel: END,\n\t\t\tvalue: PASSTHROUGH,\n\t\t\tmapper: pluckReturnValue\n\t\t}, {\n\t\t\tchannel: PREVIOUS,\n\t\t\tvalue: PASSTHROUGH,\n\t\t\tmapper: pluckSaveValue\n\t\t}], [TAG_HIDDEN])]\n\t});\n\treturn new Pregel({\n\t\tname,\n\t\tcheckpointer,\n\t\tnodes: { [name]: entrypointNode },\n\t\tchannels: {\n\t\t\t[START]: new EphemeralValue(),\n\t\t\t[END]: new LastValue(),\n\t\t\t[PREVIOUS]: new LastValue()\n\t\t},\n\t\tinputChannels: START,\n\t\toutputChannels: END,\n\t\tstreamChannels: END,\n\t\tstreamMode,\n\t\tstore,\n\t\tcache\n\t});\n};\nentrypoint.final = function final({ value, save }) {\n\treturn {\n\t\tvalue,\n\t\tsave,\n\t\t__lg_type: \"__pregel_final\"\n\t};\n};\n/**\n* A helper utility function for use with the functional API that returns the previous\n* state from the checkpoint from the last invocation of the current thread.\n*\n* This function allows workflows to access state that was saved in previous runs\n* using {@link entrypoint.final}.\n*\n* @typeParam StateT - The type of the state that was previously saved\n* @returns The previous saved state from the last invocation of the current thread\n*\n* @example\n* ```typescript\n* const previousState = getPreviousState<{ counter: number }>();\n* const newCount = (previousState?.counter ?? 0) + 1;\n* ```\n* @category Functional API\n*/\nfunction getPreviousState() {\n\tconst config = AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\treturn config.configurable?.[CONFIG_KEY_PREVIOUS_STATE];\n}\n\n//#endregion\nexport { entrypoint, getPreviousState, task };\n//# sourceMappingURL=index.js.map","import { Annotation } from \"./annotation.js\";\nimport { withLangGraph } from \"./zod/meta.js\";\nimport { messagesStateReducer } from \"./message.js\";\nimport { z } from \"zod/v3\";\n\n//#region src/graph/messages_annotation.ts\n/**\n* Prebuilt state annotation that combines returned messages.\n* Can handle standard messages and special modifiers like {@link RemoveMessage}\n* instances.\n*\n* Specifically, importing and using the prebuilt MessagesAnnotation like this:\n*\n* @example\n* ```ts\n* import { MessagesAnnotation, StateGraph } from \"@langchain/langgraph\";\n*\n* const graph = new StateGraph(MessagesAnnotation)\n*   .addNode(...)\n*   ...\n* ```\n*\n* Is equivalent to initializing your state manually like this:\n*\n* @example\n* ```ts\n* import { BaseMessage } from \"@langchain/core/messages\";\n* import { Annotation, StateGraph, messagesStateReducer } from \"@langchain/langgraph\";\n*\n* export const StateAnnotation = Annotation.Root({\n*   messages: Annotation<BaseMessage[]>({\n*     reducer: messagesStateReducer,\n*     default: () => [],\n*   }),\n* });\n*\n* const graph = new StateGraph(StateAnnotation)\n*   .addNode(...)\n*   ...\n* ```\n*/\nconst MessagesAnnotation = Annotation.Root({ messages: Annotation({\n\treducer: messagesStateReducer,\n\tdefault: () => []\n}) });\n/**\n* Prebuilt schema meta for Zod state definition.\n*\n* @example\n* ```ts\n* import { z } from \"zod/v4-mini\";\n* import { MessagesZodState, StateGraph } from \"@langchain/langgraph\";\n*\n* const AgentState = z.object({\n*   messages: z.custom<BaseMessage[]>().register(registry, MessagesZodMeta),\n* });\n* ```\n*/\nconst MessagesZodMeta = {\n\treducer: { fn: messagesStateReducer },\n\tjsonSchemaExtra: { langgraph_type: \"messages\" },\n\tdefault: () => []\n};\n/**\n* Prebuilt state object that uses Zod to combine returned messages.\n* This utility is synonymous with the `MessagesAnnotation` annotation,\n* but uses Zod as the way to express messages state.\n*\n* You can use import and use this prebuilt schema like this:\n*\n* @example\n* ```ts\n* import { MessagesZodState, StateGraph } from \"@langchain/langgraph\";\n*\n* const graph = new StateGraph(MessagesZodState)\n*   .addNode(...)\n*   ...\n* ```\n*\n* Which is equivalent to initializing the schema object manually like this:\n*\n* @example\n* ```ts\n* import { z } from \"zod\";\n* import type { BaseMessage, BaseMessageLike } from \"@langchain/core/messages\";\n* import { StateGraph, messagesStateReducer } from \"@langchain/langgraph\";\n* import \"@langchain/langgraph/zod\";\n*\n* const AgentState = z.object({\n*   messages: z\n*     .custom<BaseMessage[]>()\n*     .default(() => [])\n*     .langgraph.reducer(\n*        messagesStateReducer,\n*        z.custom<BaseMessageLike | BaseMessageLike[]>()\n*     ),\n* });\n* const graph = new StateGraph(AgentState)\n*   .addNode(...)\n*   ...\n* ```\n*/\nconst MessagesZodState = z.object({ messages: withLangGraph(z.custom(), MessagesZodMeta) });\n\n//#endregion\nexport { MessagesAnnotation, MessagesZodMeta, MessagesZodState };\n//# sourceMappingURL=messages_annotation.js.map","import { Annotation, AnnotationRoot } from \"./annotation.js\";\nimport { CommandInstance } from \"../constants.js\";\nimport { Graph } from \"./graph.js\";\nimport { CompiledStateGraph, StateGraph } from \"./state.js\";\nimport { MessageGraph, REMOVE_ALL_MESSAGES, messagesStateReducer, pushMessage } from \"./message.js\";\n\nexport {  };","import { EmptyChannelError } from \"../errors.js\";\nimport { BaseChannel } from \"./base.js\";\n\n//#region src/channels/any_value.ts\n/**\n* Stores the last value received, assumes that if multiple values are received, they are all equal.\n*\n* Note: Unlike 'LastValue' if multiple nodes write to this channel in a single step, the values\n* will be continuously overwritten.\n*/\nvar AnyValue = class AnyValue extends BaseChannel {\n\tlc_graph_name = \"AnyValue\";\n\tvalue = [];\n\tconstructor() {\n\t\tsuper();\n\t}\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new AnyValue();\n\t\tif (typeof checkpoint !== \"undefined\") empty.value = [checkpoint];\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tif (values.length === 0) {\n\t\t\tconst updated = this.value.length > 0;\n\t\t\tthis.value = [];\n\t\t\treturn updated;\n\t\t}\n\t\tthis.value = [values[values.length - 1]];\n\t\treturn false;\n\t}\n\tget() {\n\t\tif (this.value.length === 0) throw new EmptyChannelError();\n\t\treturn this.value[0];\n\t}\n\tcheckpoint() {\n\t\tif (this.value.length === 0) throw new EmptyChannelError();\n\t\treturn this.value[0];\n\t}\n\tisAvailable() {\n\t\treturn this.value.length !== 0;\n\t}\n};\n\n//#endregion\nexport { AnyValue };\n//# sourceMappingURL=any_value.js.map","import { EmptyChannelError, InvalidUpdateError } from \"../errors.js\";\nimport { BaseChannel } from \"./base.js\";\nimport { areSetsEqual } from \"./named_barrier_value.js\";\n\n//#region src/channels/dynamic_barrier_value.ts\nfunction isWaitForNames(v) {\n\treturn v.__names !== void 0;\n}\n/**\n* A channel that switches between two states\n*\n* - in the \"priming\" state it can't be read from.\n*     - if it receives a WaitForNames update, it switches to the \"waiting\" state.\n* - in the \"waiting\" state it collects named values until all are received.\n*     - once all named values are received, it can be read once, and it switches\n*       back to the \"priming\" state.\n*/\nvar DynamicBarrierValue = class DynamicBarrierValue extends BaseChannel {\n\tlc_graph_name = \"DynamicBarrierValue\";\n\tnames;\n\tseen;\n\tconstructor() {\n\t\tsuper();\n\t\tthis.names = void 0;\n\t\tthis.seen = /* @__PURE__ */ new Set();\n\t}\n\tfromCheckpoint(checkpoint) {\n\t\tconst empty = new DynamicBarrierValue();\n\t\tif (typeof checkpoint !== \"undefined\") {\n\t\t\tempty.names = new Set(checkpoint[0]);\n\t\t\tempty.seen = new Set(checkpoint[1]);\n\t\t}\n\t\treturn empty;\n\t}\n\tupdate(values) {\n\t\tconst waitForNames = values.filter(isWaitForNames);\n\t\tif (waitForNames.length > 0) {\n\t\t\tif (waitForNames.length > 1) throw new InvalidUpdateError(\"Received multiple WaitForNames updates in the same step.\");\n\t\t\tthis.names = new Set(waitForNames[0].__names);\n\t\t\treturn true;\n\t\t} else if (this.names !== void 0) {\n\t\t\tlet updated = false;\n\t\t\tfor (const value of values) {\n\t\t\t\tif (isWaitForNames(value)) throw new Error(\"Assertion Error: Received unexpected WaitForNames instance.\");\n\t\t\t\tif (this.names.has(value) && !this.seen.has(value)) {\n\t\t\t\t\tthis.seen.add(value);\n\t\t\t\t\tupdated = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn updated;\n\t\t}\n\t\treturn false;\n\t}\n\tconsume() {\n\t\tif (this.seen && this.names && areSetsEqual(this.seen, this.names)) {\n\t\t\tthis.seen = /* @__PURE__ */ new Set();\n\t\t\tthis.names = void 0;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tget() {\n\t\tif (!this.names || !areSetsEqual(this.names, this.seen)) throw new EmptyChannelError();\n\t\treturn void 0;\n\t}\n\tcheckpoint() {\n\t\treturn [this.names ? [...this.names] : void 0, [...this.seen]];\n\t}\n\tisAvailable() {\n\t\treturn !!this.names && areSetsEqual(this.names, this.seen);\n\t}\n};\n\n//#endregion\nexport { DynamicBarrierValue };\n//# sourceMappingURL=dynamic_barrier_value.js.map","import { BaseChannel, createCheckpoint, emptyChannels } from \"./base.js\";\nimport { BinaryOperatorAggregate } from \"./binop.js\";\nimport { LastValue, LastValueAfterFinish } from \"./last_value.js\";\nimport { Topic } from \"./topic.js\";\nimport { EphemeralValue } from \"./ephemeral_value.js\";\nimport { NamedBarrierValue, NamedBarrierValueAfterFinish } from \"./named_barrier_value.js\";\nimport { AnyValue } from \"./any_value.js\";\nimport { DynamicBarrierValue } from \"./dynamic_barrier_value.js\";\n\nexport { AnyValue, BaseChannel, BinaryOperatorAggregate, DynamicBarrierValue, EphemeralValue, LastValue, LastValueAfterFinish, NamedBarrierValue, NamedBarrierValueAfterFinish, Topic, createCheckpoint, emptyChannels as empty };","import { BaseLangGraphError, EmptyChannelError, EmptyInputError, GraphBubbleUp, GraphInterrupt, GraphRecursionError, GraphValueError, InvalidUpdateError, MultipleSubgraphsError, NodeInterrupt, ParentCommand, RemoteException, UnreachableNodeError, getSubgraphsSeenSet, isGraphBubbleUp, isGraphInterrupt, isParentCommand } from \"./errors.js\";\nimport { BaseChannel } from \"./channels/base.js\";\nimport { BinaryOperatorAggregate } from \"./channels/binop.js\";\nimport { Annotation } from \"./graph/annotation.js\";\nimport { Command, END, INTERRUPT, START, Send, isCommand, isInterrupted } from \"./constants.js\";\nimport { Graph } from \"./graph/graph.js\";\nimport { CompiledStateGraph, StateGraph } from \"./graph/state.js\";\nimport { MessageGraph, REMOVE_ALL_MESSAGES, messagesStateReducer } from \"./graph/message.js\";\nimport \"./graph/index.js\";\nimport \"./channels/index.js\";\nimport { entrypoint, task } from \"./func/index.js\";\nimport { MessagesAnnotation, MessagesZodMeta, MessagesZodState } from \"./graph/messages_annotation.js\";\nimport { AsyncBatchedStore, BaseCheckpointSaver, BaseStore, InMemoryStore, MemorySaver, copyCheckpoint, emptyCheckpoint } from \"@langchain/langgraph-checkpoint\";\n\nexport { Annotation, AsyncBatchedStore, BaseChannel, BaseCheckpointSaver, BaseLangGraphError, BaseStore, BinaryOperatorAggregate, Command, CompiledStateGraph, END, EmptyChannelError, EmptyInputError, Graph, GraphBubbleUp, GraphInterrupt, GraphRecursionError, GraphValueError, INTERRUPT, InMemoryStore, InvalidUpdateError, MemorySaver, MessageGraph, MessagesAnnotation, MessagesZodMeta, MessagesZodState, MultipleSubgraphsError, NodeInterrupt, ParentCommand, REMOVE_ALL_MESSAGES, RemoteException, START, Send, StateGraph, UnreachableNodeError, messagesStateReducer as addMessages, copyCheckpoint, emptyCheckpoint, entrypoint, getSubgraphsSeenSet, isCommand, isGraphBubbleUp, isGraphInterrupt, isInterrupted, isParentCommand, messagesStateReducer, task };","import { AsyncLocalStorageProviderSingleton } from \"@langchain/core/singletons\";\n\n//#region src/writer.ts\nfunction writer(chunk) {\n\tconst config = AsyncLocalStorageProviderSingleton.getRunnableConfig();\n\tif (!config) throw new Error(\"Called interrupt() outside the context of a graph.\");\n\tconst conf = config.configurable;\n\tif (!conf) throw new Error(\"No configurable found in config\");\n\treturn conf.writer?.(chunk);\n}\n\n//#endregion\nexport { writer };\n//# sourceMappingURL=writer.js.map","import { initializeAsyncLocalStorageSingleton } from \"./setup/async_local_storage.js\";\nimport { BaseLangGraphError, EmptyChannelError, EmptyInputError, GraphBubbleUp, GraphInterrupt, GraphRecursionError, GraphValueError, InvalidUpdateError, MultipleSubgraphsError, NodeInterrupt, ParentCommand, RemoteException, UnreachableNodeError, getSubgraphsSeenSet, isGraphBubbleUp, isGraphInterrupt, isParentCommand } from \"./errors.js\";\nimport { BaseChannel } from \"./channels/base.js\";\nimport { BinaryOperatorAggregate } from \"./channels/binop.js\";\nimport { Annotation } from \"./graph/annotation.js\";\nimport { Command, END, INTERRUPT, START, Send, isCommand, isInterrupted } from \"./constants.js\";\nimport { getConfig, getCurrentTaskInput, getStore, getWriter } from \"./pregel/utils/config.js\";\nimport { interrupt } from \"./interrupt.js\";\nimport { Graph } from \"./graph/graph.js\";\nimport { CompiledStateGraph, StateGraph } from \"./graph/state.js\";\nimport { MessageGraph, REMOVE_ALL_MESSAGES, messagesStateReducer, pushMessage } from \"./graph/message.js\";\nimport { entrypoint, getPreviousState, task } from \"./func/index.js\";\nimport { MessagesAnnotation, MessagesZodMeta, MessagesZodState } from \"./graph/messages_annotation.js\";\nimport { AsyncBatchedStore, BaseCheckpointSaver, BaseStore, InMemoryStore, MemorySaver, copyCheckpoint, emptyCheckpoint } from \"./web.js\";\nimport { writer } from \"./writer.js\";\n\n//#region src/index.ts\ninitializeAsyncLocalStorageSingleton();\n\n//#endregion\nexport { Annotation, AsyncBatchedStore, BaseChannel, BaseCheckpointSaver, BaseLangGraphError, BaseStore, BinaryOperatorAggregate, Command, CompiledStateGraph, END, EmptyChannelError, EmptyInputError, Graph, GraphBubbleUp, GraphInterrupt, GraphRecursionError, GraphValueError, INTERRUPT, InMemoryStore, InvalidUpdateError, MemorySaver, MessageGraph, MessagesAnnotation, MessagesZodMeta, MessagesZodState, MultipleSubgraphsError, NodeInterrupt, ParentCommand, REMOVE_ALL_MESSAGES, RemoteException, START, Send, StateGraph, UnreachableNodeError, messagesStateReducer as addMessages, copyCheckpoint, emptyCheckpoint, entrypoint, getConfig, getCurrentTaskInput, getPreviousState, getStore, getSubgraphsSeenSet, getWriter, interrupt, isCommand, isGraphBubbleUp, isGraphInterrupt, isInterrupted, isParentCommand, messagesStateReducer, pushMessage, task, writer };\n//# sourceMappingURL=index.js.map","import { interopSafeParseAsync } from \"@langchain/core/utils/types\";\nimport { BaseLLMOutputParser, OutputParserException } from \"@langchain/core/output_parsers\";\n\n//#region src/output_parsers.ts\nvar AnthropicToolsOutputParser = class extends BaseLLMOutputParser {\n\tstatic lc_name() {\n\t\treturn \"AnthropicToolsOutputParser\";\n\t}\n\tlc_namespace = [\n\t\t\"langchain\",\n\t\t\"anthropic\",\n\t\t\"output_parsers\"\n\t];\n\treturnId = false;\n\t/** The type of tool calls to return. */\n\tkeyName;\n\t/** Whether to return only the first tool call. */\n\treturnSingle = false;\n\tzodSchema;\n\tconstructor(params) {\n\t\tsuper(params);\n\t\tthis.keyName = params.keyName;\n\t\tthis.returnSingle = params.returnSingle ?? this.returnSingle;\n\t\tthis.zodSchema = params.zodSchema;\n\t}\n\tasync _validateResult(result) {\n\t\tlet parsedResult = result;\n\t\tif (typeof result === \"string\") try {\n\t\t\tparsedResult = JSON.parse(result);\n\t\t} catch (e) {\n\t\t\tthrow new OutputParserException(`Failed to parse. Text: \"${JSON.stringify(result, null, 2)}\". Error: ${JSON.stringify(e.message)}`, result);\n\t\t}\n\t\telse parsedResult = result;\n\t\tif (this.zodSchema === void 0) return parsedResult;\n\t\tconst zodParsedResult = await interopSafeParseAsync(this.zodSchema, parsedResult);\n\t\tif (zodParsedResult.success) return zodParsedResult.data;\n\t\telse throw new OutputParserException(`Failed to parse. Text: \"${JSON.stringify(result, null, 2)}\". Error: ${JSON.stringify(zodParsedResult.error.issues)}`, JSON.stringify(parsedResult, null, 2));\n\t}\n\tasync parseResult(generations) {\n\t\tconst tools = generations.flatMap((generation) => {\n\t\t\tconst { message } = generation;\n\t\t\tif (!Array.isArray(message.content)) return [];\n\t\t\tconst tool$1 = extractToolCalls(message.content)[0];\n\t\t\treturn tool$1;\n\t\t});\n\t\tif (tools[0] === void 0) throw new Error(\"No parseable tool calls provided to AnthropicToolsOutputParser.\");\n\t\tconst [tool] = tools;\n\t\tconst validatedResult = await this._validateResult(tool.args);\n\t\treturn validatedResult;\n\t}\n};\nfunction extractToolCalls(content) {\n\tconst toolCalls = [];\n\tfor (const block of content) if (block.type === \"tool_use\") toolCalls.push({\n\t\tname: block.name,\n\t\targs: block.input,\n\t\tid: block.id,\n\t\ttype: \"tool_call\"\n\t});\n\treturn toolCalls;\n}\n\n//#endregion\nexport { AnthropicToolsOutputParser, extractToolCalls };\n//# sourceMappingURL=output_parsers.js.map","//#region src/utils/tools.ts\nfunction handleToolChoice(toolChoice) {\n\tif (!toolChoice) return void 0;\n\telse if (toolChoice === \"any\") return { type: \"any\" };\n\telse if (toolChoice === \"auto\") return { type: \"auto\" };\n\telse if (toolChoice === \"none\") return { type: \"none\" };\n\telse if (typeof toolChoice === \"string\") return {\n\t\ttype: \"tool\",\n\t\tname: toolChoice\n\t};\n\telse return toolChoice;\n}\n\n//#endregion\nexport { handleToolChoice };\n//# sourceMappingURL=tools.js.map","import { parseBase64DataUrl } from \"@langchain/core/messages\";\n\n//#region src/utils/content.ts\nfunction _isAnthropicThinkingBlock(block) {\n\treturn typeof block === \"object\" && block !== null && \"type\" in block && block.type === \"thinking\";\n}\nfunction _isAnthropicRedactedThinkingBlock(block) {\n\treturn typeof block === \"object\" && block !== null && \"type\" in block && block.type === \"redacted_thinking\";\n}\nfunction _isAnthropicSearchResultBlock(block) {\n\treturn typeof block === \"object\" && block !== null && \"type\" in block && block.type === \"search_result\";\n}\nfunction _isAnthropicImageBlockParam(block) {\n\tif (typeof block !== \"object\" || block == null) return false;\n\tif (!(\"type\" in block) || block.type !== \"image\") return false;\n\tif (!(\"source\" in block) || typeof block.source !== \"object\" || block.source == null) return false;\n\tif (!(\"type\" in block.source)) return false;\n\tif (block.source.type === \"base64\") {\n\t\tif (!(\"media_type\" in block.source)) return false;\n\t\tif (typeof block.source.media_type !== \"string\") return false;\n\t\tif (!(\"data\" in block.source)) return false;\n\t\tif (typeof block.source.data !== \"string\") return false;\n\t\treturn true;\n\t}\n\tif (block.source.type === \"url\") {\n\t\tif (!(\"url\" in block.source)) return false;\n\t\tif (typeof block.source.url !== \"string\") return false;\n\t\treturn true;\n\t}\n\treturn false;\n}\nconst standardContentBlockConverter = {\n\tproviderName: \"anthropic\",\n\tfromStandardTextBlock(block) {\n\t\treturn {\n\t\t\ttype: \"text\",\n\t\t\ttext: block.text,\n\t\t\t...\"citations\" in (block.metadata ?? {}) ? { citations: block.metadata.citations } : {},\n\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {}\n\t\t};\n\t},\n\tfromStandardImageBlock(block) {\n\t\tif (block.source_type === \"url\") {\n\t\t\tconst data = parseBase64DataUrl({\n\t\t\t\tdataUrl: block.url,\n\t\t\t\tasTypedArray: false\n\t\t\t});\n\t\t\tif (data) return {\n\t\t\t\ttype: \"image\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"base64\",\n\t\t\t\t\tdata: data.data,\n\t\t\t\t\tmedia_type: data.mime_type\n\t\t\t\t},\n\t\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {}\n\t\t\t};\n\t\t\telse return {\n\t\t\t\ttype: \"image\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"url\",\n\t\t\t\t\turl: block.url\n\t\t\t\t},\n\t\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {}\n\t\t\t};\n\t\t} else if (block.source_type === \"base64\") return {\n\t\t\ttype: \"image\",\n\t\t\tsource: {\n\t\t\t\ttype: \"base64\",\n\t\t\t\tdata: block.data,\n\t\t\t\tmedia_type: block.mime_type ?? \"\"\n\t\t\t},\n\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {}\n\t\t};\n\t\telse throw new Error(`Unsupported image source type: ${block.source_type}`);\n\t},\n\tfromStandardFileBlock(block) {\n\t\tconst mime_type = (block.mime_type ?? \"\").split(\";\")[0];\n\t\tif (block.source_type === \"url\") {\n\t\t\tif (mime_type === \"application/pdf\" || mime_type === \"\") return {\n\t\t\t\ttype: \"document\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"url\",\n\t\t\t\t\turl: block.url\n\t\t\t\t},\n\t\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {},\n\t\t\t\t...\"citations\" in (block.metadata ?? {}) ? { citations: block.metadata.citations } : {},\n\t\t\t\t...\"context\" in (block.metadata ?? {}) ? { context: block.metadata.context } : {},\n\t\t\t\t...\"title\" in (block.metadata ?? {}) ? { title: block.metadata.title } : {}\n\t\t\t};\n\t\t\tthrow new Error(`Unsupported file mime type for file url source: ${block.mime_type}`);\n\t\t} else if (block.source_type === \"text\") if (mime_type === \"text/plain\" || mime_type === \"\") return {\n\t\t\ttype: \"document\",\n\t\t\tsource: {\n\t\t\t\ttype: \"text\",\n\t\t\t\tdata: block.text,\n\t\t\t\tmedia_type: block.mime_type ?? \"\"\n\t\t\t},\n\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {},\n\t\t\t...\"citations\" in (block.metadata ?? {}) ? { citations: block.metadata.citations } : {},\n\t\t\t...\"context\" in (block.metadata ?? {}) ? { context: block.metadata.context } : {},\n\t\t\t...\"title\" in (block.metadata ?? {}) ? { title: block.metadata.title } : {}\n\t\t};\n\t\telse throw new Error(`Unsupported file mime type for file text source: ${block.mime_type}`);\n\t\telse if (block.source_type === \"base64\") if (mime_type === \"application/pdf\" || mime_type === \"\") return {\n\t\t\ttype: \"document\",\n\t\t\tsource: {\n\t\t\t\ttype: \"base64\",\n\t\t\t\tdata: block.data,\n\t\t\t\tmedia_type: \"application/pdf\"\n\t\t\t},\n\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {},\n\t\t\t...\"citations\" in (block.metadata ?? {}) ? { citations: block.metadata.citations } : {},\n\t\t\t...\"context\" in (block.metadata ?? {}) ? { context: block.metadata.context } : {},\n\t\t\t...\"title\" in (block.metadata ?? {}) ? { title: block.metadata.title } : {}\n\t\t};\n\t\telse if ([\n\t\t\t\"image/jpeg\",\n\t\t\t\"image/png\",\n\t\t\t\"image/gif\",\n\t\t\t\"image/webp\"\n\t\t].includes(mime_type)) return {\n\t\t\ttype: \"document\",\n\t\t\tsource: {\n\t\t\t\ttype: \"content\",\n\t\t\t\tcontent: [{\n\t\t\t\t\ttype: \"image\",\n\t\t\t\t\tsource: {\n\t\t\t\t\t\ttype: \"base64\",\n\t\t\t\t\t\tdata: block.data,\n\t\t\t\t\t\tmedia_type: mime_type\n\t\t\t\t\t}\n\t\t\t\t}]\n\t\t\t},\n\t\t\t...\"cache_control\" in (block.metadata ?? {}) ? { cache_control: block.metadata.cache_control } : {},\n\t\t\t...\"citations\" in (block.metadata ?? {}) ? { citations: block.metadata.citations } : {},\n\t\t\t...\"context\" in (block.metadata ?? {}) ? { context: block.metadata.context } : {},\n\t\t\t...\"title\" in (block.metadata ?? {}) ? { title: block.metadata.title } : {}\n\t\t};\n\t\telse throw new Error(`Unsupported file mime type for file base64 source: ${block.mime_type}`);\n\t\telse throw new Error(`Unsupported file source type: ${block.source_type}`);\n\t}\n};\n\n//#endregion\nexport { _isAnthropicImageBlockParam, _isAnthropicRedactedThinkingBlock, _isAnthropicSearchResultBlock, _isAnthropicThinkingBlock, standardContentBlockConverter };\n//# sourceMappingURL=content.js.map","//#region src/utils/index.ts\nconst iife = (fn) => fn();\n\n//#endregion\nexport { iife };\n//# sourceMappingURL=index.js.map","import { iife } from \"./index.js\";\n\n//#region src/utils/standard.ts\nfunction _isStandardAnnotation(annotation) {\n\treturn typeof annotation === \"object\" && annotation !== null && \"type\" in annotation && annotation.type === \"citation\";\n}\nfunction _formatStandardCitations(annotations) {\n\tfunction* iterateAnnotations() {\n\t\tfor (const annotation of annotations) if (_isStandardAnnotation(annotation)) {\n\t\t\tif (annotation.source === \"char\") yield {\n\t\t\t\ttype: \"char_location\",\n\t\t\t\tfile_id: annotation.url ?? \"\",\n\t\t\t\tstart_char_index: annotation.startIndex ?? 0,\n\t\t\t\tend_char_index: annotation.endIndex ?? 0,\n\t\t\t\tdocument_title: annotation.title ?? null,\n\t\t\t\tdocument_index: 0,\n\t\t\t\tcited_text: annotation.citedText ?? \"\"\n\t\t\t};\n\t\t\telse if (annotation.source === \"page\") yield {\n\t\t\t\ttype: \"page_location\",\n\t\t\t\tfile_id: annotation.url ?? \"\",\n\t\t\t\tstart_page_number: annotation.startIndex ?? 0,\n\t\t\t\tend_page_number: annotation.endIndex ?? 0,\n\t\t\t\tdocument_title: annotation.title ?? null,\n\t\t\t\tdocument_index: 0,\n\t\t\t\tcited_text: annotation.citedText ?? \"\"\n\t\t\t};\n\t\t\telse if (annotation.source === \"block\") yield {\n\t\t\t\ttype: \"content_block_location\",\n\t\t\t\tfile_id: annotation.url ?? \"\",\n\t\t\t\tstart_block_index: annotation.startIndex ?? 0,\n\t\t\t\tend_block_index: annotation.endIndex ?? 0,\n\t\t\t\tdocument_title: annotation.title ?? null,\n\t\t\t\tdocument_index: 0,\n\t\t\t\tcited_text: annotation.citedText ?? \"\"\n\t\t\t};\n\t\t\telse if (annotation.source === \"url\") yield {\n\t\t\t\ttype: \"web_search_result_location\",\n\t\t\t\turl: annotation.url ?? \"\",\n\t\t\t\ttitle: annotation.title ?? null,\n\t\t\t\tencrypted_index: String(annotation.startIndex ?? 0),\n\t\t\t\tcited_text: annotation.citedText ?? \"\"\n\t\t\t};\n\t\t\telse if (annotation.source === \"search\") yield {\n\t\t\t\ttype: \"search_result_location\",\n\t\t\t\ttitle: annotation.title ?? null,\n\t\t\t\tstart_block_index: annotation.startIndex ?? 0,\n\t\t\t\tend_block_index: annotation.endIndex ?? 0,\n\t\t\t\tsearch_result_index: 0,\n\t\t\t\tsource: annotation.source ?? \"\",\n\t\t\t\tcited_text: annotation.citedText ?? \"\"\n\t\t\t};\n\t\t}\n\t}\n\treturn Array.from(iterateAnnotations());\n}\nfunction _formatBase64Data(data) {\n\tif (typeof data === \"string\") return data;\n\telse return _encodeUint8Array(data);\n}\nfunction _encodeUint8Array(data) {\n\tconst output = [];\n\tfor (let i = 0, { length } = data; i < length; i++) output.push(String.fromCharCode(data[i]));\n\treturn btoa(output.join(\"\"));\n}\nfunction _normalizeMimeType(mimeType) {\n\treturn (mimeType ?? \"\").split(\";\")[0].toLowerCase();\n}\nfunction _extractMetadataValue(metadata, key) {\n\tif (metadata !== void 0 && metadata !== null && typeof metadata === \"object\" && key in metadata) return metadata[key];\n\treturn void 0;\n}\nfunction _applyDocumentMetadata(block, metadata) {\n\tconst cacheControl = _extractMetadataValue(metadata, \"cache_control\");\n\tif (cacheControl !== void 0) block.cache_control = cacheControl;\n\tconst citations = _extractMetadataValue(metadata, \"citations\");\n\tif (citations !== void 0) block.citations = citations;\n\tconst context = _extractMetadataValue(metadata, \"context\");\n\tif (context !== void 0) block.context = context;\n\tconst title = _extractMetadataValue(metadata, \"title\");\n\tif (title !== void 0) block.title = title;\n\treturn block;\n}\nfunction _applyImageMetadata(block, metadata) {\n\tconst cacheControl = _extractMetadataValue(metadata, \"cache_control\");\n\tif (cacheControl !== void 0) block.cache_control = cacheControl;\n\treturn block;\n}\nfunction _hasAllowedImageMimeType(mimeType) {\n\tconst ALLOWED_IMAGE_MIME_TYPES = new Set([\n\t\t\"image/jpeg\",\n\t\t\"image/png\",\n\t\t\"image/gif\",\n\t\t\"image/webp\"\n\t]);\n\treturn ALLOWED_IMAGE_MIME_TYPES.has(mimeType);\n}\nfunction _formatStandardContent(message) {\n\tconst result = [];\n\tconst responseMetadata = message.response_metadata;\n\tconst isAnthropicMessage = \"model_provider\" in responseMetadata && responseMetadata?.model_provider === \"anthropic\";\n\tfor (const block of message.contentBlocks) if (block.type === \"text\") if (block.annotations) result.push({\n\t\ttype: \"text\",\n\t\ttext: block.text,\n\t\tcitations: _formatStandardCitations(block.annotations)\n\t});\n\telse result.push({\n\t\ttype: \"text\",\n\t\ttext: block.text\n\t});\n\telse if (block.type === \"tool_call\") result.push({\n\t\ttype: \"tool_use\",\n\t\tid: block.id ?? \"\",\n\t\tname: block.name,\n\t\tinput: block.args\n\t});\n\telse if (block.type === \"tool_call_chunk\") {\n\t\tconst input = iife(() => {\n\t\t\tif (typeof block.args !== \"string\") return block.args;\n\t\t\ttry {\n\t\t\t\treturn JSON.parse(block.args);\n\t\t\t} catch {\n\t\t\t\treturn {};\n\t\t\t}\n\t\t});\n\t\tresult.push({\n\t\t\ttype: \"tool_use\",\n\t\t\tid: block.id ?? \"\",\n\t\t\tname: block.name ?? \"\",\n\t\t\tinput\n\t\t});\n\t} else if (block.type === \"reasoning\" && isAnthropicMessage) result.push({\n\t\ttype: \"thinking\",\n\t\tthinking: block.reasoning,\n\t\tsignature: String(block.signature)\n\t});\n\telse if (block.type === \"server_tool_call\" && isAnthropicMessage) {\n\t\tif (block.name === \"web_search\") result.push({\n\t\t\ttype: \"server_tool_use\",\n\t\t\tname: block.name,\n\t\t\tid: block.id ?? \"\",\n\t\t\tinput: block.args\n\t\t});\n\t\telse if (block.name === \"code_execution\") result.push({\n\t\t\ttype: \"server_tool_use\",\n\t\t\tname: block.name,\n\t\t\tid: block.id ?? \"\",\n\t\t\tinput: block.args\n\t\t});\n\t} else if (block.type === \"server_tool_call_result\" && isAnthropicMessage) {\n\t\tif (block.name === \"web_search\" && Array.isArray(block.output.urls)) {\n\t\t\tconst content = block.output.urls.map((url) => ({\n\t\t\t\ttype: \"web_search_result\",\n\t\t\t\ttitle: \"\",\n\t\t\t\tencrypted_content: \"\",\n\t\t\t\turl\n\t\t\t}));\n\t\t\tresult.push({\n\t\t\t\ttype: \"web_search_tool_result\",\n\t\t\t\ttool_use_id: block.toolCallId ?? \"\",\n\t\t\t\tcontent\n\t\t\t});\n\t\t} else if (block.name === \"code_execution\") result.push({\n\t\t\ttype: \"code_execution_tool_result\",\n\t\t\ttool_use_id: block.toolCallId ?? \"\",\n\t\t\tcontent: block.output\n\t\t});\n\t\telse if (block.name === \"mcp_tool_result\") result.push({\n\t\t\ttype: \"mcp_tool_result\",\n\t\t\ttool_use_id: block.toolCallId ?? \"\",\n\t\t\tcontent: block.output\n\t\t});\n\t} else if (block.type === \"audio\") throw new Error(\"Anthropic does not support audio content blocks.\");\n\telse if (block.type === \"file\") {\n\t\tconst metadata = block.metadata;\n\t\tif (block.fileId) {\n\t\t\tresult.push(_applyDocumentMetadata({\n\t\t\t\ttype: \"document\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"file\",\n\t\t\t\t\tfile_id: block.fileId\n\t\t\t\t}\n\t\t\t}, metadata));\n\t\t\tcontinue;\n\t\t}\n\t\tif (block.url) {\n\t\t\tconst mimeType = _normalizeMimeType(block.mimeType);\n\t\t\tif (mimeType === \"application/pdf\" || mimeType === \"\") {\n\t\t\t\tresult.push(_applyDocumentMetadata({\n\t\t\t\t\ttype: \"document\",\n\t\t\t\t\tsource: {\n\t\t\t\t\t\ttype: \"url\",\n\t\t\t\t\t\turl: block.url\n\t\t\t\t\t}\n\t\t\t\t}, metadata));\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (block.data) {\n\t\t\tconst mimeType = _normalizeMimeType(block.mimeType);\n\t\t\tif (mimeType === \"\" || mimeType === \"application/pdf\") result.push(_applyDocumentMetadata({\n\t\t\t\ttype: \"document\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"base64\",\n\t\t\t\t\tdata: _formatBase64Data(block.data),\n\t\t\t\t\tmedia_type: \"application/pdf\"\n\t\t\t\t}\n\t\t\t}, metadata));\n\t\t\telse if (mimeType === \"text/plain\") result.push(_applyDocumentMetadata({\n\t\t\t\ttype: \"document\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"text\",\n\t\t\t\t\tdata: _formatBase64Data(block.data),\n\t\t\t\t\tmedia_type: \"text/plain\"\n\t\t\t\t}\n\t\t\t}, metadata));\n\t\t\telse if (_hasAllowedImageMimeType(mimeType)) result.push(_applyDocumentMetadata({\n\t\t\t\ttype: \"document\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"content\",\n\t\t\t\t\tcontent: [{\n\t\t\t\t\t\ttype: \"image\",\n\t\t\t\t\t\tsource: {\n\t\t\t\t\t\t\ttype: \"base64\",\n\t\t\t\t\t\t\tdata: _formatBase64Data(block.data),\n\t\t\t\t\t\t\tmedia_type: mimeType\n\t\t\t\t\t\t}\n\t\t\t\t\t}]\n\t\t\t\t}\n\t\t\t}, metadata));\n\t\t\telse throw new Error(`Unsupported file mime type for Anthropic base64 source: ${mimeType}`);\n\t\t\tcontinue;\n\t\t}\n\t\tthrow new Error(\"File content block must include a fileId, url, or data property.\");\n\t} else if (block.type === \"image\") {\n\t\tconst metadata = block.metadata;\n\t\tif (block.fileId) {\n\t\t\tresult.push(_applyImageMetadata({\n\t\t\t\ttype: \"image\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"file\",\n\t\t\t\t\tfile_id: block.fileId\n\t\t\t\t}\n\t\t\t}, metadata));\n\t\t\tcontinue;\n\t\t}\n\t\tif (block.url) {\n\t\t\tresult.push(_applyImageMetadata({\n\t\t\t\ttype: \"image\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"url\",\n\t\t\t\t\turl: block.url\n\t\t\t\t}\n\t\t\t}, metadata));\n\t\t\tcontinue;\n\t\t}\n\t\tif (block.data) {\n\t\t\tconst mimeType = _normalizeMimeType(block.mimeType) || \"image/png\";\n\t\t\tif (_hasAllowedImageMimeType(mimeType)) result.push(_applyImageMetadata({\n\t\t\t\ttype: \"image\",\n\t\t\t\tsource: {\n\t\t\t\t\ttype: \"base64\",\n\t\t\t\t\tdata: _formatBase64Data(block.data),\n\t\t\t\t\tmedia_type: mimeType\n\t\t\t\t}\n\t\t\t}, metadata));\n\t\t\tcontinue;\n\t\t}\n\t\tthrow new Error(\"Image content block must include a fileId, url, or data property.\");\n\t} else if (block.type === \"video\") {} else if (block.type === \"text-plain\") {\n\t\tif (block.data) result.push(_applyDocumentMetadata({\n\t\t\ttype: \"document\",\n\t\t\tsource: {\n\t\t\t\ttype: \"text\",\n\t\t\t\tdata: _formatBase64Data(block.data),\n\t\t\t\tmedia_type: \"text/plain\"\n\t\t\t}\n\t\t}, block.metadata));\n\t} else if (block.type === \"non_standard\" && isAnthropicMessage) result.push(block.value);\n\treturn result;\n}\n\n//#endregion\nexport { _formatStandardContent };\n//# sourceMappingURL=standard.js.map","import { _isAnthropicImageBlockParam, _isAnthropicRedactedThinkingBlock, _isAnthropicSearchResultBlock, _isAnthropicThinkingBlock, standardContentBlockConverter } from \"./content.js\";\nimport { _formatStandardContent } from \"./standard.js\";\nimport { HumanMessage, convertToProviderContentBlock, isAIMessage, isDataContentBlock, parseBase64DataUrl } from \"@langchain/core/messages\";\n\n//#region src/utils/message_inputs.ts\nfunction _formatImage(imageUrl) {\n\tconst parsed = parseBase64DataUrl({ dataUrl: imageUrl });\n\tif (parsed) return {\n\t\ttype: \"base64\",\n\t\tmedia_type: parsed.mime_type,\n\t\tdata: parsed.data\n\t};\n\tlet parsedUrl;\n\ttry {\n\t\tparsedUrl = new URL(imageUrl);\n\t} catch {\n\t\tthrow new Error([\n\t\t\t`Malformed image URL: ${JSON.stringify(imageUrl)}. Content blocks of type 'image_url' must be a valid http, https, or base64-encoded data URL.`,\n\t\t\t\"Example: data:image/png;base64,/9j/4AAQSk...\",\n\t\t\t\"Example: https://example.com/image.jpg\"\n\t\t].join(\"\\n\\n\"));\n\t}\n\tif (parsedUrl.protocol === \"http:\" || parsedUrl.protocol === \"https:\") return {\n\t\ttype: \"url\",\n\t\turl: imageUrl\n\t};\n\tthrow new Error([\n\t\t`Invalid image URL protocol: ${JSON.stringify(parsedUrl.protocol)}. Anthropic only supports images as http, https, or base64-encoded data URLs on 'image_url' content blocks.`,\n\t\t\"Example: data:image/png;base64,/9j/4AAQSk...\",\n\t\t\"Example: https://example.com/image.jpg\"\n\t].join(\"\\n\\n\"));\n}\nfunction _ensureMessageContents(messages) {\n\tconst updatedMsgs = [];\n\tfor (const message of messages) if (message._getType() === \"tool\") if (typeof message.content === \"string\") {\n\t\tconst previousMessage = updatedMsgs[updatedMsgs.length - 1];\n\t\tif (previousMessage?._getType() === \"human\" && Array.isArray(previousMessage.content) && \"type\" in previousMessage.content[0] && previousMessage.content[0].type === \"tool_result\") previousMessage.content.push({\n\t\t\ttype: \"tool_result\",\n\t\t\tcontent: message.content,\n\t\t\ttool_use_id: message.tool_call_id\n\t\t});\n\t\telse updatedMsgs.push(new HumanMessage({ content: [{\n\t\t\ttype: \"tool_result\",\n\t\t\tcontent: message.content,\n\t\t\ttool_use_id: message.tool_call_id\n\t\t}] }));\n\t} else updatedMsgs.push(new HumanMessage({ content: [{\n\t\ttype: \"tool_result\",\n\t\t...message.content != null ? { content: _formatContent(message) } : {},\n\t\ttool_use_id: message.tool_call_id\n\t}] }));\n\telse updatedMsgs.push(message);\n\treturn updatedMsgs;\n}\nfunction _convertLangChainToolCallToAnthropic(toolCall) {\n\tif (toolCall.id === void 0) throw new Error(`Anthropic requires all tool calls to have an \"id\".`);\n\treturn {\n\t\ttype: \"tool_use\",\n\t\tid: toolCall.id,\n\t\tname: toolCall.name,\n\t\tinput: toolCall.args\n\t};\n}\nfunction* _formatContentBlocks(content) {\n\tconst toolTypes = [\n\t\t\"bash_code_execution_tool_result\",\n\t\t\"input_json_delta\",\n\t\t\"server_tool_use\",\n\t\t\"text_editor_code_execution_tool_result\",\n\t\t\"tool_result\",\n\t\t\"tool_use\",\n\t\t\"web_search_result\",\n\t\t\"web_search_tool_result\"\n\t];\n\tconst textTypes = [\"text\", \"text_delta\"];\n\tfor (const contentPart of content) {\n\t\tif (isDataContentBlock(contentPart)) yield convertToProviderContentBlock(contentPart, standardContentBlockConverter);\n\t\tconst cacheControl = \"cache_control\" in contentPart ? contentPart.cache_control : void 0;\n\t\tif (contentPart.type === \"image_url\") {\n\t\t\tlet source;\n\t\t\tif (typeof contentPart.image_url === \"string\") source = _formatImage(contentPart.image_url);\n\t\t\telse if (typeof contentPart.image_url === \"object\" && contentPart.image_url !== null && \"url\" in contentPart.image_url && typeof contentPart.image_url.url === \"string\") source = _formatImage(contentPart.image_url.url);\n\t\t\tif (source) yield {\n\t\t\t\ttype: \"image\",\n\t\t\t\tsource,\n\t\t\t\t...cacheControl ? { cache_control: cacheControl } : {}\n\t\t\t};\n\t\t} else if (_isAnthropicImageBlockParam(contentPart)) return contentPart;\n\t\telse if (contentPart.type === \"document\") yield {\n\t\t\t...contentPart,\n\t\t\t...cacheControl ? { cache_control: cacheControl } : {}\n\t\t};\n\t\telse if (_isAnthropicThinkingBlock(contentPart)) {\n\t\t\tconst block = {\n\t\t\t\ttype: \"thinking\",\n\t\t\t\tthinking: contentPart.thinking,\n\t\t\t\tsignature: contentPart.signature,\n\t\t\t\t...cacheControl ? { cache_control: cacheControl } : {}\n\t\t\t};\n\t\t\tyield block;\n\t\t} else if (_isAnthropicRedactedThinkingBlock(contentPart)) {\n\t\t\tconst block = {\n\t\t\t\ttype: \"redacted_thinking\",\n\t\t\t\tdata: contentPart.data,\n\t\t\t\t...cacheControl ? { cache_control: cacheControl } : {}\n\t\t\t};\n\t\t\tyield block;\n\t\t} else if (_isAnthropicSearchResultBlock(contentPart)) {\n\t\t\tconst block = {\n\t\t\t\ttype: \"search_result\",\n\t\t\t\ttitle: contentPart.title,\n\t\t\t\tsource: contentPart.source,\n\t\t\t\t...\"cache_control\" in contentPart && contentPart.cache_control ? { cache_control: contentPart.cache_control } : {},\n\t\t\t\t...\"citations\" in contentPart && contentPart.citations ? { citations: contentPart.citations } : {},\n\t\t\t\tcontent: contentPart.content\n\t\t\t};\n\t\t\tyield block;\n\t\t} else if (textTypes.find((t) => t === contentPart.type) && \"text\" in contentPart) yield {\n\t\t\ttype: \"text\",\n\t\t\ttext: contentPart.text,\n\t\t\t...cacheControl ? { cache_control: cacheControl } : {},\n\t\t\t...\"citations\" in contentPart && contentPart.citations ? { citations: contentPart.citations } : {}\n\t\t};\n\t\telse if (toolTypes.find((t) => t === contentPart.type)) {\n\t\t\tconst contentPartCopy = { ...contentPart };\n\t\t\tif (\"index\" in contentPartCopy) delete contentPartCopy.index;\n\t\t\tif (contentPartCopy.type === \"input_json_delta\") contentPartCopy.type = \"tool_use\";\n\t\t\tif (\"input\" in contentPartCopy) {\n\t\t\t\tif (typeof contentPartCopy.input === \"string\") try {\n\t\t\t\t\tcontentPartCopy.input = JSON.parse(contentPartCopy.input);\n\t\t\t\t} catch {\n\t\t\t\t\tcontentPartCopy.input = {};\n\t\t\t\t}\n\t\t\t}\n\t\t\tyield {\n\t\t\t\t...contentPartCopy,\n\t\t\t\t...cacheControl ? { cache_control: cacheControl } : {}\n\t\t\t};\n\t\t} else if (contentPart.type === \"container_upload\") yield {\n\t\t\t...contentPart,\n\t\t\t...cacheControl ? { cache_control: cacheControl } : {}\n\t\t};\n\t}\n}\nfunction _formatContent(message) {\n\tconst { content } = message;\n\tif (typeof content === \"string\") return content;\n\telse return Array.from(_formatContentBlocks(content));\n}\n/**\n* Formats messages as a prompt for the model.\n* Used in LangSmith, export is important here.\n* @param messages The base messages to format as a prompt.\n* @returns The formatted prompt.\n*/\nfunction _convertMessagesToAnthropicPayload(messages) {\n\tconst mergedMessages = _ensureMessageContents(messages);\n\tlet system;\n\tif (mergedMessages.length > 0 && mergedMessages[0]._getType() === \"system\") system = messages[0].content;\n\tconst conversationMessages = system !== void 0 ? mergedMessages.slice(1) : mergedMessages;\n\tconst formattedMessages = conversationMessages.map((message) => {\n\t\tlet role;\n\t\tif (message._getType() === \"human\") role = \"user\";\n\t\telse if (message._getType() === \"ai\") role = \"assistant\";\n\t\telse if (message._getType() === \"tool\") role = \"user\";\n\t\telse if (message._getType() === \"system\") throw new Error(\"System messages are only permitted as the first passed message.\");\n\t\telse throw new Error(`Message type \"${message.type}\" is not supported.`);\n\t\tif (isAIMessage(message) && message.response_metadata?.output_version === \"v1\") return {\n\t\t\trole,\n\t\t\tcontent: _formatStandardContent(message)\n\t\t};\n\t\tif (isAIMessage(message) && !!message.tool_calls?.length) if (typeof message.content === \"string\") if (message.content === \"\") return {\n\t\t\trole,\n\t\t\tcontent: message.tool_calls.map(_convertLangChainToolCallToAnthropic)\n\t\t};\n\t\telse return {\n\t\t\trole,\n\t\t\tcontent: [{\n\t\t\t\ttype: \"text\",\n\t\t\t\ttext: message.content\n\t\t\t}, ...message.tool_calls.map(_convertLangChainToolCallToAnthropic)]\n\t\t};\n\t\telse {\n\t\t\tconst { content } = message;\n\t\t\tconst hasMismatchedToolCalls = !message.tool_calls.every((toolCall) => content.find((contentPart) => (contentPart.type === \"tool_use\" || contentPart.type === \"input_json_delta\" || contentPart.type === \"server_tool_use\") && contentPart.id === toolCall.id));\n\t\t\tif (hasMismatchedToolCalls) console.warn(`The \"tool_calls\" field on a message is only respected if content is a string.`);\n\t\t\treturn {\n\t\t\t\trole,\n\t\t\t\tcontent: _formatContent(message)\n\t\t\t};\n\t\t}\n\t\telse return {\n\t\t\trole,\n\t\t\tcontent: _formatContent(message)\n\t\t};\n\t});\n\treturn {\n\t\tmessages: mergeMessages(formattedMessages),\n\t\tsystem\n\t};\n}\nfunction mergeMessages(messages) {\n\tif (!messages || messages.length <= 1) return messages;\n\tconst result = [];\n\tlet currentMessage = messages[0];\n\tconst normalizeContent = (content) => {\n\t\tif (typeof content === \"string\") return [{\n\t\t\ttype: \"text\",\n\t\t\ttext: content\n\t\t}];\n\t\treturn content;\n\t};\n\tconst isToolResultMessage = (msg) => {\n\t\tif (msg.role !== \"user\") return false;\n\t\tif (typeof msg.content === \"string\") return false;\n\t\treturn Array.isArray(msg.content) && msg.content.every((item) => item.type === \"tool_result\");\n\t};\n\tfor (let i = 1; i < messages.length; i += 1) {\n\t\tconst nextMessage = messages[i];\n\t\tif (isToolResultMessage(currentMessage) && isToolResultMessage(nextMessage)) currentMessage = {\n\t\t\t...currentMessage,\n\t\t\tcontent: [...normalizeContent(currentMessage.content), ...normalizeContent(nextMessage.content)]\n\t\t};\n\t\telse {\n\t\t\tresult.push(currentMessage);\n\t\t\tcurrentMessage = nextMessage;\n\t\t}\n\t}\n\tresult.push(currentMessage);\n\treturn result;\n}\n\n//#endregion\nexport { _convertMessagesToAnthropicPayload };\n//# sourceMappingURL=message_inputs.js.map","import { extractToolCalls } from \"../output_parsers.js\";\nimport { AIMessage, AIMessageChunk } from \"@langchain/core/messages\";\n\n//#region src/utils/message_outputs.ts\nfunction _makeMessageChunkFromAnthropicEvent(data, fields) {\n\tconst response_metadata = { model_provider: \"anthropic\" };\n\tif (data.type === \"message_start\") {\n\t\tconst { content, usage,...additionalKwargs } = data.message;\n\t\tconst filteredAdditionalKwargs = {};\n\t\tfor (const [key, value] of Object.entries(additionalKwargs)) if (value !== void 0 && value !== null) filteredAdditionalKwargs[key] = value;\n\t\tconst { input_tokens, output_tokens,...rest } = usage ?? {};\n\t\tconst usageMetadata = {\n\t\t\tinput_tokens,\n\t\t\toutput_tokens,\n\t\t\ttotal_tokens: input_tokens + output_tokens,\n\t\t\tinput_token_details: {\n\t\t\t\tcache_creation: rest.cache_creation_input_tokens,\n\t\t\t\tcache_read: rest.cache_read_input_tokens\n\t\t\t}\n\t\t};\n\t\treturn { chunk: new AIMessageChunk({\n\t\t\tcontent: fields.coerceContentToString ? \"\" : [],\n\t\t\tadditional_kwargs: filteredAdditionalKwargs,\n\t\t\tusage_metadata: fields.streamUsage ? usageMetadata : void 0,\n\t\t\tresponse_metadata: {\n\t\t\t\t...response_metadata,\n\t\t\t\tusage: { ...rest }\n\t\t\t},\n\t\t\tid: data.message.id\n\t\t}) };\n\t} else if (data.type === \"message_delta\") {\n\t\tconst usageMetadata = {\n\t\t\tinput_tokens: 0,\n\t\t\toutput_tokens: data.usage.output_tokens,\n\t\t\ttotal_tokens: data.usage.output_tokens,\n\t\t\tinput_token_details: {\n\t\t\t\tcache_creation: data.usage.cache_creation_input_tokens,\n\t\t\t\tcache_read: data.usage.cache_read_input_tokens\n\t\t\t}\n\t\t};\n\t\tconst responseMetadata = \"context_management\" in data.delta ? { context_management: data.delta.context_management } : void 0;\n\t\treturn { chunk: new AIMessageChunk({\n\t\t\tcontent: fields.coerceContentToString ? \"\" : [],\n\t\t\tresponse_metadata: responseMetadata,\n\t\t\tadditional_kwargs: { ...data.delta },\n\t\t\tusage_metadata: fields.streamUsage ? usageMetadata : void 0\n\t\t}) };\n\t} else if (data.type === \"content_block_start\" && [\n\t\t\"tool_use\",\n\t\t\"document\",\n\t\t\"server_tool_use\",\n\t\t\"web_search_tool_result\"\n\t].includes(data.content_block.type)) {\n\t\tconst contentBlock = data.content_block;\n\t\tlet toolCallChunks;\n\t\tif (contentBlock.type === \"tool_use\") toolCallChunks = [{\n\t\t\tid: contentBlock.id,\n\t\t\tindex: data.index,\n\t\t\tname: contentBlock.name,\n\t\t\targs: \"\"\n\t\t}];\n\t\telse toolCallChunks = [];\n\t\treturn { chunk: new AIMessageChunk({\n\t\t\tcontent: fields.coerceContentToString ? \"\" : [{\n\t\t\t\tindex: data.index,\n\t\t\t\t...data.content_block,\n\t\t\t\tinput: contentBlock.type === \"server_tool_use\" || contentBlock.type === \"tool_use\" ? \"\" : void 0\n\t\t\t}],\n\t\t\tresponse_metadata,\n\t\t\tadditional_kwargs: {},\n\t\t\ttool_call_chunks: toolCallChunks\n\t\t}) };\n\t} else if (data.type === \"content_block_delta\" && [\n\t\t\"text_delta\",\n\t\t\"citations_delta\",\n\t\t\"thinking_delta\",\n\t\t\"signature_delta\"\n\t].includes(data.delta.type)) if (fields.coerceContentToString && \"text\" in data.delta) return { chunk: new AIMessageChunk({ content: data.delta.text }) };\n\telse {\n\t\tconst contentBlock = data.delta;\n\t\tif (\"citation\" in contentBlock) {\n\t\t\tcontentBlock.citations = [contentBlock.citation];\n\t\t\tdelete contentBlock.citation;\n\t\t}\n\t\tif (contentBlock.type === \"thinking_delta\" || contentBlock.type === \"signature_delta\") return { chunk: new AIMessageChunk({\n\t\t\tcontent: [{\n\t\t\t\tindex: data.index,\n\t\t\t\t...contentBlock,\n\t\t\t\ttype: \"thinking\"\n\t\t\t}],\n\t\t\tresponse_metadata\n\t\t}) };\n\t\treturn { chunk: new AIMessageChunk({\n\t\t\tcontent: [{\n\t\t\t\tindex: data.index,\n\t\t\t\t...contentBlock,\n\t\t\t\ttype: \"text\"\n\t\t\t}],\n\t\t\tresponse_metadata\n\t\t}) };\n\t}\n\telse if (data.type === \"content_block_delta\" && data.delta.type === \"input_json_delta\") return { chunk: new AIMessageChunk({\n\t\tcontent: fields.coerceContentToString ? \"\" : [{\n\t\t\tindex: data.index,\n\t\t\tinput: data.delta.partial_json,\n\t\t\ttype: data.delta.type\n\t\t}],\n\t\tresponse_metadata,\n\t\tadditional_kwargs: {},\n\t\ttool_call_chunks: [{\n\t\t\tindex: data.index,\n\t\t\targs: data.delta.partial_json\n\t\t}]\n\t}) };\n\telse if (data.type === \"content_block_start\" && data.content_block.type === \"text\") {\n\t\tconst content = data.content_block?.text;\n\t\tif (content !== void 0) return { chunk: new AIMessageChunk({\n\t\t\tcontent: fields.coerceContentToString ? content : [{\n\t\t\t\tindex: data.index,\n\t\t\t\t...data.content_block\n\t\t\t}],\n\t\t\tresponse_metadata,\n\t\t\tadditional_kwargs: {}\n\t\t}) };\n\t} else if (data.type === \"content_block_start\" && data.content_block.type === \"redacted_thinking\") return { chunk: new AIMessageChunk({\n\t\tcontent: fields.coerceContentToString ? \"\" : [{\n\t\t\tindex: data.index,\n\t\t\t...data.content_block\n\t\t}],\n\t\tresponse_metadata\n\t}) };\n\telse if (data.type === \"content_block_start\" && data.content_block.type === \"thinking\") {\n\t\tconst content = data.content_block.thinking;\n\t\treturn { chunk: new AIMessageChunk({\n\t\t\tcontent: fields.coerceContentToString ? content : [{\n\t\t\t\tindex: data.index,\n\t\t\t\t...data.content_block\n\t\t\t}],\n\t\t\tresponse_metadata\n\t\t}) };\n\t}\n\treturn null;\n}\nfunction anthropicResponseToChatMessages(messages, additionalKwargs) {\n\tconst response_metadata = {\n\t\t...additionalKwargs,\n\t\tmodel_provider: \"anthropic\"\n\t};\n\tconst usage = additionalKwargs.usage;\n\tconst usageMetadata = usage != null ? {\n\t\tinput_tokens: usage.input_tokens ?? 0,\n\t\toutput_tokens: usage.output_tokens ?? 0,\n\t\ttotal_tokens: (usage.input_tokens ?? 0) + (usage.output_tokens ?? 0),\n\t\tinput_token_details: {\n\t\t\tcache_creation: usage.cache_creation_input_tokens,\n\t\t\tcache_read: usage.cache_read_input_tokens\n\t\t}\n\t} : void 0;\n\tif (messages.length === 1 && messages[0].type === \"text\") return [{\n\t\ttext: messages[0].text,\n\t\tmessage: new AIMessage({\n\t\t\tcontent: messages[0].text,\n\t\t\tadditional_kwargs: additionalKwargs,\n\t\t\tusage_metadata: usageMetadata,\n\t\t\tresponse_metadata,\n\t\t\tid: additionalKwargs.id\n\t\t})\n\t}];\n\telse {\n\t\tconst toolCalls = extractToolCalls(messages);\n\t\tconst generations = [{\n\t\t\ttext: \"\",\n\t\t\tmessage: new AIMessage({\n\t\t\t\tcontent: messages,\n\t\t\t\tadditional_kwargs: additionalKwargs,\n\t\t\t\ttool_calls: toolCalls,\n\t\t\t\tusage_metadata: usageMetadata,\n\t\t\t\tresponse_metadata,\n\t\t\t\tid: additionalKwargs.id\n\t\t\t})\n\t\t}];\n\t\treturn generations;\n\t}\n}\n\n//#endregion\nexport { _makeMessageChunkFromAnthropicEvent, anthropicResponseToChatMessages };\n//# sourceMappingURL=message_outputs.js.map","//#region src/utils/errors.ts\nfunction addLangChainErrorFields(error, lc_error_code) {\n\terror.lc_error_code = lc_error_code;\n\terror.message = `${error.message}\\n\\nTroubleshooting URL: https://js.langchain.com/docs/troubleshooting/errors/${lc_error_code}/\\n`;\n\treturn error;\n}\nfunction wrapAnthropicClientError(e) {\n\tlet error;\n\tif (e.status === 400 && e.message.includes(\"tool\")) error = addLangChainErrorFields(e, \"INVALID_TOOL_RESULTS\");\n\telse if (e.status === 401) error = addLangChainErrorFields(e, \"MODEL_AUTHENTICATION\");\n\telse if (e.status === 404) error = addLangChainErrorFields(e, \"MODEL_NOT_FOUND\");\n\telse if (e.status === 429) error = addLangChainErrorFields(e, \"MODEL_RATE_LIMIT\");\n\telse error = e;\n\treturn error;\n}\n\n//#endregion\nexport { wrapAnthropicClientError };\n//# sourceMappingURL=errors.js.map","function __classPrivateFieldSet(receiver, state, value, kind, f) {\n    if (kind === \"m\")\n        throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f)\n        throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver))\n        throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return kind === \"a\" ? f.call(receiver, value) : f ? (f.value = value) : state.set(receiver, value), value;\n}\nfunction __classPrivateFieldGet(receiver, state, kind, f) {\n    if (kind === \"a\" && !f)\n        throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver))\n        throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\nexport { __classPrivateFieldSet, __classPrivateFieldGet };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n/**\n * https://stackoverflow.com/a/2117523\n */\nexport let uuid4 = function () {\n    const { crypto } = globalThis;\n    if (crypto?.randomUUID) {\n        uuid4 = crypto.randomUUID.bind(crypto);\n        return crypto.randomUUID();\n    }\n    const u8 = new Uint8Array(1);\n    const randomByte = crypto ? () => crypto.getRandomValues(u8)[0] : () => (Math.random() * 0xff) & 0xff;\n    return '10000000-1000-4000-8000-100000000000'.replace(/[018]/g, (c) => (+c ^ (randomByte() & (15 >> (+c / 4)))).toString(16));\n};\n//# sourceMappingURL=uuid.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nexport function isAbortError(err) {\n    return (typeof err === 'object' &&\n        err !== null &&\n        // Spec-compliant fetch implementations\n        (('name' in err && err.name === 'AbortError') ||\n            // Expo fetch\n            ('message' in err && String(err.message).includes('FetchRequestCanceledException'))));\n}\nexport const castToError = (err) => {\n    if (err instanceof Error)\n        return err;\n    if (typeof err === 'object' && err !== null) {\n        try {\n            if (Object.prototype.toString.call(err) === '[object Error]') {\n                // @ts-ignore - not all envs have native support for cause yet\n                const error = new Error(err.message, err.cause ? { cause: err.cause } : {});\n                if (err.stack)\n                    error.stack = err.stack;\n                // @ts-ignore - not all envs have native support for cause yet\n                if (err.cause && !error.cause)\n                    error.cause = err.cause;\n                if (err.name)\n                    error.name = err.name;\n                return error;\n            }\n        }\n        catch { }\n        try {\n            return new Error(JSON.stringify(err));\n        }\n        catch { }\n    }\n    return new Error(err);\n};\n//# sourceMappingURL=errors.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { castToError } from \"../internal/errors.mjs\";\nexport class AnthropicError extends Error {\n}\nexport class APIError extends AnthropicError {\n    constructor(status, error, message, headers) {\n        super(`${APIError.makeMessage(status, error, message)}`);\n        this.status = status;\n        this.headers = headers;\n        this.requestID = headers?.get('request-id');\n        this.error = error;\n    }\n    static makeMessage(status, error, message) {\n        const msg = error?.message ?\n            typeof error.message === 'string' ?\n                error.message\n                : JSON.stringify(error.message)\n            : error ? JSON.stringify(error)\n                : message;\n        if (status && msg) {\n            return `${status} ${msg}`;\n        }\n        if (status) {\n            return `${status} status code (no body)`;\n        }\n        if (msg) {\n            return msg;\n        }\n        return '(no status code or body)';\n    }\n    static generate(status, errorResponse, message, headers) {\n        if (!status || !headers) {\n            return new APIConnectionError({ message, cause: castToError(errorResponse) });\n        }\n        const error = errorResponse;\n        if (status === 400) {\n            return new BadRequestError(status, error, message, headers);\n        }\n        if (status === 401) {\n            return new AuthenticationError(status, error, message, headers);\n        }\n        if (status === 403) {\n            return new PermissionDeniedError(status, error, message, headers);\n        }\n        if (status === 404) {\n            return new NotFoundError(status, error, message, headers);\n        }\n        if (status === 409) {\n            return new ConflictError(status, error, message, headers);\n        }\n        if (status === 422) {\n            return new UnprocessableEntityError(status, error, message, headers);\n        }\n        if (status === 429) {\n            return new RateLimitError(status, error, message, headers);\n        }\n        if (status >= 500) {\n            return new InternalServerError(status, error, message, headers);\n        }\n        return new APIError(status, error, message, headers);\n    }\n}\nexport class APIUserAbortError extends APIError {\n    constructor({ message } = {}) {\n        super(undefined, undefined, message || 'Request was aborted.', undefined);\n    }\n}\nexport class APIConnectionError extends APIError {\n    constructor({ message, cause }) {\n        super(undefined, undefined, message || 'Connection error.', undefined);\n        // in some environments the 'cause' property is already declared\n        // @ts-ignore\n        if (cause)\n            this.cause = cause;\n    }\n}\nexport class APIConnectionTimeoutError extends APIConnectionError {\n    constructor({ message } = {}) {\n        super({ message: message ?? 'Request timed out.' });\n    }\n}\nexport class BadRequestError extends APIError {\n}\nexport class AuthenticationError extends APIError {\n}\nexport class PermissionDeniedError extends APIError {\n}\nexport class NotFoundError extends APIError {\n}\nexport class ConflictError extends APIError {\n}\nexport class UnprocessableEntityError extends APIError {\n}\nexport class RateLimitError extends APIError {\n}\nexport class InternalServerError extends APIError {\n}\n//# sourceMappingURL=error.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { AnthropicError } from \"../../core/error.mjs\";\n// https://url.spec.whatwg.org/#url-scheme-string\nconst startsWithSchemeRegexp = /^[a-z][a-z0-9+.-]*:/i;\nexport const isAbsoluteURL = (url) => {\n    return startsWithSchemeRegexp.test(url);\n};\nexport let isArray = (val) => ((isArray = Array.isArray), isArray(val));\nexport let isReadonlyArray = isArray;\n/** Returns an object if the given value isn't an object, otherwise returns as-is */\nexport function maybeObj(x) {\n    if (typeof x !== 'object') {\n        return {};\n    }\n    return x ?? {};\n}\n// https://stackoverflow.com/a/34491287\nexport function isEmptyObj(obj) {\n    if (!obj)\n        return true;\n    for (const _k in obj)\n        return false;\n    return true;\n}\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nexport function hasOwn(obj, key) {\n    return Object.prototype.hasOwnProperty.call(obj, key);\n}\nexport function isObj(obj) {\n    return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\nexport const ensurePresent = (value) => {\n    if (value == null) {\n        throw new AnthropicError(`Expected a value to be given but received ${value} instead.`);\n    }\n    return value;\n};\nexport const validatePositiveInteger = (name, n) => {\n    if (typeof n !== 'number' || !Number.isInteger(n)) {\n        throw new AnthropicError(`${name} must be an integer`);\n    }\n    if (n < 0) {\n        throw new AnthropicError(`${name} must be a positive integer`);\n    }\n    return n;\n};\nexport const coerceInteger = (value) => {\n    if (typeof value === 'number')\n        return Math.round(value);\n    if (typeof value === 'string')\n        return parseInt(value, 10);\n    throw new AnthropicError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\nexport const coerceFloat = (value) => {\n    if (typeof value === 'number')\n        return value;\n    if (typeof value === 'string')\n        return parseFloat(value);\n    throw new AnthropicError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\nexport const coerceBoolean = (value) => {\n    if (typeof value === 'boolean')\n        return value;\n    if (typeof value === 'string')\n        return value === 'true';\n    return Boolean(value);\n};\nexport const maybeCoerceInteger = (value) => {\n    if (value == null) {\n        return undefined;\n    }\n    return coerceInteger(value);\n};\nexport const maybeCoerceFloat = (value) => {\n    if (value == null) {\n        return undefined;\n    }\n    return coerceFloat(value);\n};\nexport const maybeCoerceBoolean = (value) => {\n    if (value == null) {\n        return undefined;\n    }\n    return coerceBoolean(value);\n};\nexport const safeJSON = (text) => {\n    try {\n        return JSON.parse(text);\n    }\n    catch (err) {\n        return undefined;\n    }\n};\n//# sourceMappingURL=values.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nexport const sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));\n//# sourceMappingURL=sleep.mjs.map","export const VERSION = '0.65.0'; // x-release-please-version\n//# sourceMappingURL=version.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { VERSION } from \"../version.mjs\";\nexport const isRunningInBrowser = () => {\n    return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n        // @ts-ignore\n        typeof window.document !== 'undefined' &&\n        // @ts-ignore\n        typeof navigator !== 'undefined');\n};\n/**\n * Note this does not detect 'browser'; for that, use getBrowserInfo().\n */\nfunction getDetectedPlatform() {\n    if (typeof Deno !== 'undefined' && Deno.build != null) {\n        return 'deno';\n    }\n    if (typeof EdgeRuntime !== 'undefined') {\n        return 'edge';\n    }\n    if (Object.prototype.toString.call(typeof globalThis.process !== 'undefined' ? globalThis.process : 0) === '[object process]') {\n        return 'node';\n    }\n    return 'unknown';\n}\nconst getPlatformProperties = () => {\n    const detectedPlatform = getDetectedPlatform();\n    if (detectedPlatform === 'deno') {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': VERSION,\n            'X-Stainless-OS': normalizePlatform(Deno.build.os),\n            'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n            'X-Stainless-Runtime': 'deno',\n            'X-Stainless-Runtime-Version': typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n        };\n    }\n    if (typeof EdgeRuntime !== 'undefined') {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': VERSION,\n            'X-Stainless-OS': 'Unknown',\n            'X-Stainless-Arch': `other:${EdgeRuntime}`,\n            'X-Stainless-Runtime': 'edge',\n            'X-Stainless-Runtime-Version': globalThis.process.version,\n        };\n    }\n    // Check if Node.js\n    if (detectedPlatform === 'node') {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': VERSION,\n            'X-Stainless-OS': normalizePlatform(globalThis.process.platform ?? 'unknown'),\n            'X-Stainless-Arch': normalizeArch(globalThis.process.arch ?? 'unknown'),\n            'X-Stainless-Runtime': 'node',\n            'X-Stainless-Runtime-Version': globalThis.process.version ?? 'unknown',\n        };\n    }\n    const browserInfo = getBrowserInfo();\n    if (browserInfo) {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': VERSION,\n            'X-Stainless-OS': 'Unknown',\n            'X-Stainless-Arch': 'unknown',\n            'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n            'X-Stainless-Runtime-Version': browserInfo.version,\n        };\n    }\n    // TODO add support for Cloudflare workers, etc.\n    return {\n        'X-Stainless-Lang': 'js',\n        'X-Stainless-Package-Version': VERSION,\n        'X-Stainless-OS': 'Unknown',\n        'X-Stainless-Arch': 'unknown',\n        'X-Stainless-Runtime': 'unknown',\n        'X-Stainless-Runtime-Version': 'unknown',\n    };\n};\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo() {\n    if (typeof navigator === 'undefined' || !navigator) {\n        return null;\n    }\n    // NOTE: The order matters here!\n    const browserPatterns = [\n        { key: 'edge', pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'ie', pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'ie', pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'chrome', pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'firefox', pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'safari', pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n    ];\n    // Find the FIRST matching browser\n    for (const { key, pattern } of browserPatterns) {\n        const match = pattern.exec(navigator.userAgent);\n        if (match) {\n            const major = match[1] || 0;\n            const minor = match[2] || 0;\n            const patch = match[3] || 0;\n            return { browser: key, version: `${major}.${minor}.${patch}` };\n        }\n    }\n    return null;\n}\nconst normalizeArch = (arch) => {\n    // Node docs:\n    // - https://nodejs.org/api/process.html#processarch\n    // Deno docs:\n    // - https://doc.deno.land/deno/stable/~/Deno.build\n    if (arch === 'x32')\n        return 'x32';\n    if (arch === 'x86_64' || arch === 'x64')\n        return 'x64';\n    if (arch === 'arm')\n        return 'arm';\n    if (arch === 'aarch64' || arch === 'arm64')\n        return 'arm64';\n    if (arch)\n        return `other:${arch}`;\n    return 'unknown';\n};\nconst normalizePlatform = (platform) => {\n    // Node platforms:\n    // - https://nodejs.org/api/process.html#processplatform\n    // Deno platforms:\n    // - https://doc.deno.land/deno/stable/~/Deno.build\n    // - https://github.com/denoland/deno/issues/14799\n    platform = platform.toLowerCase();\n    // NOTE: this iOS check is untested and may not work\n    // Node does not work natively on IOS, there is a fork at\n    // https://github.com/nodejs-mobile/nodejs-mobile\n    // however it is unknown at the time of writing how to detect if it is running\n    if (platform.includes('ios'))\n        return 'iOS';\n    if (platform === 'android')\n        return 'Android';\n    if (platform === 'darwin')\n        return 'MacOS';\n    if (platform === 'win32')\n        return 'Windows';\n    if (platform === 'freebsd')\n        return 'FreeBSD';\n    if (platform === 'openbsd')\n        return 'OpenBSD';\n    if (platform === 'linux')\n        return 'Linux';\n    if (platform)\n        return `Other:${platform}`;\n    return 'Unknown';\n};\nlet _platformHeaders;\nexport const getPlatformHeaders = () => {\n    return (_platformHeaders ?? (_platformHeaders = getPlatformProperties()));\n};\n//# sourceMappingURL=detect-platform.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nexport function getDefaultFetch() {\n    if (typeof fetch !== 'undefined') {\n        return fetch;\n    }\n    throw new Error('`fetch` is not defined as a global; Either pass `fetch` to the client, `new Anthropic({ fetch })` or polyfill the global, `globalThis.fetch = fetch`');\n}\nexport function makeReadableStream(...args) {\n    const ReadableStream = globalThis.ReadableStream;\n    if (typeof ReadableStream === 'undefined') {\n        // Note: All of the platforms / runtimes we officially support already define\n        // `ReadableStream` as a global, so this should only ever be hit on unsupported runtimes.\n        throw new Error('`ReadableStream` is not defined as a global; You will need to polyfill it, `globalThis.ReadableStream = ReadableStream`');\n    }\n    return new ReadableStream(...args);\n}\nexport function ReadableStreamFrom(iterable) {\n    let iter = Symbol.asyncIterator in iterable ? iterable[Symbol.asyncIterator]() : iterable[Symbol.iterator]();\n    return makeReadableStream({\n        start() { },\n        async pull(controller) {\n            const { done, value } = await iter.next();\n            if (done) {\n                controller.close();\n            }\n            else {\n                controller.enqueue(value);\n            }\n        },\n        async cancel() {\n            await iter.return?.();\n        },\n    });\n}\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function ReadableStreamToAsyncIterable(stream) {\n    if (stream[Symbol.asyncIterator])\n        return stream;\n    const reader = stream.getReader();\n    return {\n        async next() {\n            try {\n                const result = await reader.read();\n                if (result?.done)\n                    reader.releaseLock(); // release lock when stream becomes closed\n                return result;\n            }\n            catch (e) {\n                reader.releaseLock(); // release lock when stream becomes errored\n                throw e;\n            }\n        },\n        async return() {\n            const cancelPromise = reader.cancel();\n            reader.releaseLock();\n            await cancelPromise;\n            return { done: true, value: undefined };\n        },\n        [Symbol.asyncIterator]() {\n            return this;\n        },\n    };\n}\n/**\n * Cancels a ReadableStream we don't need to consume.\n * See https://undici.nodejs.org/#/?id=garbage-collection\n */\nexport async function CancelReadableStream(stream) {\n    if (stream === null || typeof stream !== 'object')\n        return;\n    if (stream[Symbol.asyncIterator]) {\n        await stream[Symbol.asyncIterator]().return?.();\n        return;\n    }\n    const reader = stream.getReader();\n    const cancelPromise = reader.cancel();\n    reader.releaseLock();\n    await cancelPromise;\n}\n//# sourceMappingURL=shims.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nexport const FallbackEncoder = ({ headers, body }) => {\n    return {\n        bodyHeaders: {\n            'content-type': 'application/json',\n        },\n        body: JSON.stringify(body),\n    };\n};\n//# sourceMappingURL=request-options.mjs.map","export function concatBytes(buffers) {\n    let length = 0;\n    for (const buffer of buffers) {\n        length += buffer.length;\n    }\n    const output = new Uint8Array(length);\n    let index = 0;\n    for (const buffer of buffers) {\n        output.set(buffer, index);\n        index += buffer.length;\n    }\n    return output;\n}\nlet encodeUTF8_;\nexport function encodeUTF8(str) {\n    let encoder;\n    return (encodeUTF8_ ??\n        ((encoder = new globalThis.TextEncoder()), (encodeUTF8_ = encoder.encode.bind(encoder))))(str);\n}\nlet decodeUTF8_;\nexport function decodeUTF8(bytes) {\n    let decoder;\n    return (decodeUTF8_ ??\n        ((decoder = new globalThis.TextDecoder()), (decodeUTF8_ = decoder.decode.bind(decoder))))(bytes);\n}\n//# sourceMappingURL=bytes.mjs.map","var _LineDecoder_buffer, _LineDecoder_carriageReturnIndex;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"../tslib.mjs\";\nimport { concatBytes, decodeUTF8, encodeUTF8 } from \"../utils/bytes.mjs\";\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nexport class LineDecoder {\n    constructor() {\n        _LineDecoder_buffer.set(this, void 0);\n        _LineDecoder_carriageReturnIndex.set(this, void 0);\n        __classPrivateFieldSet(this, _LineDecoder_buffer, new Uint8Array(), \"f\");\n        __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, \"f\");\n    }\n    decode(chunk) {\n        if (chunk == null) {\n            return [];\n        }\n        const binaryChunk = chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n            : typeof chunk === 'string' ? encodeUTF8(chunk)\n                : chunk;\n        __classPrivateFieldSet(this, _LineDecoder_buffer, concatBytes([__classPrivateFieldGet(this, _LineDecoder_buffer, \"f\"), binaryChunk]), \"f\");\n        const lines = [];\n        let patternIndex;\n        while ((patternIndex = findNewlineIndex(__classPrivateFieldGet(this, _LineDecoder_buffer, \"f\"), __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\"))) != null) {\n            if (patternIndex.carriage && __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") == null) {\n                // skip until we either get a corresponding `\\n`, a new `\\r` or nothing\n                __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, patternIndex.index, \"f\");\n                continue;\n            }\n            // we got double \\r or \\rtext\\n\n            if (__classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") != null &&\n                (patternIndex.index !== __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") + 1 || patternIndex.carriage)) {\n                lines.push(decodeUTF8(__classPrivateFieldGet(this, _LineDecoder_buffer, \"f\").subarray(0, __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") - 1)));\n                __classPrivateFieldSet(this, _LineDecoder_buffer, __classPrivateFieldGet(this, _LineDecoder_buffer, \"f\").subarray(__classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\")), \"f\");\n                __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, \"f\");\n                continue;\n            }\n            const endIndex = __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") !== null ? patternIndex.preceding - 1 : patternIndex.preceding;\n            const line = decodeUTF8(__classPrivateFieldGet(this, _LineDecoder_buffer, \"f\").subarray(0, endIndex));\n            lines.push(line);\n            __classPrivateFieldSet(this, _LineDecoder_buffer, __classPrivateFieldGet(this, _LineDecoder_buffer, \"f\").subarray(patternIndex.index), \"f\");\n            __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, \"f\");\n        }\n        return lines;\n    }\n    flush() {\n        if (!__classPrivateFieldGet(this, _LineDecoder_buffer, \"f\").length) {\n            return [];\n        }\n        return this.decode('\\n');\n    }\n}\n_LineDecoder_buffer = new WeakMap(), _LineDecoder_carriageReturnIndex = new WeakMap();\n// prettier-ignore\nLineDecoder.NEWLINE_CHARS = new Set(['\\n', '\\r']);\nLineDecoder.NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n/**\n * This function searches the buffer for the end patterns, (\\r or \\n)\n * and returns an object with the index preceding the matched newline and the\n * index after the newline char. `null` is returned if no new line is found.\n *\n * ```ts\n * findNewLineIndex('abc\\ndef') -> { preceding: 2, index: 3 }\n * ```\n */\nfunction findNewlineIndex(buffer, startIndex) {\n    const newline = 0x0a; // \\n\n    const carriage = 0x0d; // \\r\n    for (let i = startIndex ?? 0; i < buffer.length; i++) {\n        if (buffer[i] === newline) {\n            return { preceding: i, index: i + 1, carriage: false };\n        }\n        if (buffer[i] === carriage) {\n            return { preceding: i, index: i + 1, carriage: true };\n        }\n    }\n    return null;\n}\nexport function findDoubleNewlineIndex(buffer) {\n    // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n    // and returns the index right after the first occurrence of any pattern,\n    // or -1 if none of the patterns are found.\n    const newline = 0x0a; // \\n\n    const carriage = 0x0d; // \\r\n    for (let i = 0; i < buffer.length - 1; i++) {\n        if (buffer[i] === newline && buffer[i + 1] === newline) {\n            // \\n\\n\n            return i + 2;\n        }\n        if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n            // \\r\\r\n            return i + 2;\n        }\n        if (buffer[i] === carriage &&\n            buffer[i + 1] === newline &&\n            i + 3 < buffer.length &&\n            buffer[i + 2] === carriage &&\n            buffer[i + 3] === newline) {\n            // \\r\\n\\r\\n\n            return i + 4;\n        }\n    }\n    return -1;\n}\n//# sourceMappingURL=line.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { hasOwn } from \"./values.mjs\";\nconst levelNumbers = {\n    off: 0,\n    error: 200,\n    warn: 300,\n    info: 400,\n    debug: 500,\n};\nexport const parseLogLevel = (maybeLevel, sourceName, client) => {\n    if (!maybeLevel) {\n        return undefined;\n    }\n    if (hasOwn(levelNumbers, maybeLevel)) {\n        return maybeLevel;\n    }\n    loggerFor(client).warn(`${sourceName} was set to ${JSON.stringify(maybeLevel)}, expected one of ${JSON.stringify(Object.keys(levelNumbers))}`);\n    return undefined;\n};\nfunction noop() { }\nfunction makeLogFn(fnLevel, logger, logLevel) {\n    if (!logger || levelNumbers[fnLevel] > levelNumbers[logLevel]) {\n        return noop;\n    }\n    else {\n        // Don't wrap logger functions, we want the stacktrace intact!\n        return logger[fnLevel].bind(logger);\n    }\n}\nconst noopLogger = {\n    error: noop,\n    warn: noop,\n    info: noop,\n    debug: noop,\n};\nlet cachedLoggers = /* @__PURE__ */ new WeakMap();\nexport function loggerFor(client) {\n    const logger = client.logger;\n    const logLevel = client.logLevel ?? 'off';\n    if (!logger) {\n        return noopLogger;\n    }\n    const cachedLogger = cachedLoggers.get(logger);\n    if (cachedLogger && cachedLogger[0] === logLevel) {\n        return cachedLogger[1];\n    }\n    const levelLogger = {\n        error: makeLogFn('error', logger, logLevel),\n        warn: makeLogFn('warn', logger, logLevel),\n        info: makeLogFn('info', logger, logLevel),\n        debug: makeLogFn('debug', logger, logLevel),\n    };\n    cachedLoggers.set(logger, [logLevel, levelLogger]);\n    return levelLogger;\n}\nexport const formatRequestDetails = (details) => {\n    if (details.options) {\n        details.options = { ...details.options };\n        delete details.options['headers']; // redundant + leaks internals\n    }\n    if (details.headers) {\n        details.headers = Object.fromEntries((details.headers instanceof Headers ? [...details.headers] : Object.entries(details.headers)).map(([name, value]) => [\n            name,\n            (name.toLowerCase() === 'x-api-key' ||\n                name.toLowerCase() === 'authorization' ||\n                name.toLowerCase() === 'cookie' ||\n                name.toLowerCase() === 'set-cookie') ?\n                '***'\n                : value,\n        ]));\n    }\n    if ('retryOfRequestLogID' in details) {\n        if (details.retryOfRequestLogID) {\n            details.retryOf = details.retryOfRequestLogID;\n        }\n        delete details.retryOfRequestLogID;\n    }\n    return details;\n};\n//# sourceMappingURL=log.mjs.map","var _Stream_client;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"../internal/tslib.mjs\";\nimport { AnthropicError } from \"./error.mjs\";\nimport { makeReadableStream } from \"../internal/shims.mjs\";\nimport { findDoubleNewlineIndex, LineDecoder } from \"../internal/decoders/line.mjs\";\nimport { ReadableStreamToAsyncIterable } from \"../internal/shims.mjs\";\nimport { isAbortError } from \"../internal/errors.mjs\";\nimport { safeJSON } from \"../internal/utils/values.mjs\";\nimport { encodeUTF8 } from \"../internal/utils/bytes.mjs\";\nimport { loggerFor } from \"../internal/utils/log.mjs\";\nimport { APIError } from \"./error.mjs\";\nexport class Stream {\n    constructor(iterator, controller, client) {\n        this.iterator = iterator;\n        _Stream_client.set(this, void 0);\n        this.controller = controller;\n        __classPrivateFieldSet(this, _Stream_client, client, \"f\");\n    }\n    static fromSSEResponse(response, controller, client) {\n        let consumed = false;\n        const logger = client ? loggerFor(client) : console;\n        async function* iterator() {\n            if (consumed) {\n                throw new AnthropicError('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n            }\n            consumed = true;\n            let done = false;\n            try {\n                for await (const sse of _iterSSEMessages(response, controller)) {\n                    if (sse.event === 'completion') {\n                        try {\n                            yield JSON.parse(sse.data);\n                        }\n                        catch (e) {\n                            logger.error(`Could not parse message into JSON:`, sse.data);\n                            logger.error(`From chunk:`, sse.raw);\n                            throw e;\n                        }\n                    }\n                    if (sse.event === 'message_start' ||\n                        sse.event === 'message_delta' ||\n                        sse.event === 'message_stop' ||\n                        sse.event === 'content_block_start' ||\n                        sse.event === 'content_block_delta' ||\n                        sse.event === 'content_block_stop') {\n                        try {\n                            yield JSON.parse(sse.data);\n                        }\n                        catch (e) {\n                            logger.error(`Could not parse message into JSON:`, sse.data);\n                            logger.error(`From chunk:`, sse.raw);\n                            throw e;\n                        }\n                    }\n                    if (sse.event === 'ping') {\n                        continue;\n                    }\n                    if (sse.event === 'error') {\n                        throw new APIError(undefined, safeJSON(sse.data) ?? sse.data, undefined, response.headers);\n                    }\n                }\n                done = true;\n            }\n            catch (e) {\n                // If the user calls `stream.controller.abort()`, we should exit without throwing.\n                if (isAbortError(e))\n                    return;\n                throw e;\n            }\n            finally {\n                // If the user `break`s, abort the ongoing request.\n                if (!done)\n                    controller.abort();\n            }\n        }\n        return new Stream(iterator, controller, client);\n    }\n    /**\n     * Generates a Stream from a newline-separated ReadableStream\n     * where each item is a JSON value.\n     */\n    static fromReadableStream(readableStream, controller, client) {\n        let consumed = false;\n        async function* iterLines() {\n            const lineDecoder = new LineDecoder();\n            const iter = ReadableStreamToAsyncIterable(readableStream);\n            for await (const chunk of iter) {\n                for (const line of lineDecoder.decode(chunk)) {\n                    yield line;\n                }\n            }\n            for (const line of lineDecoder.flush()) {\n                yield line;\n            }\n        }\n        async function* iterator() {\n            if (consumed) {\n                throw new AnthropicError('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n            }\n            consumed = true;\n            let done = false;\n            try {\n                for await (const line of iterLines()) {\n                    if (done)\n                        continue;\n                    if (line)\n                        yield JSON.parse(line);\n                }\n                done = true;\n            }\n            catch (e) {\n                // If the user calls `stream.controller.abort()`, we should exit without throwing.\n                if (isAbortError(e))\n                    return;\n                throw e;\n            }\n            finally {\n                // If the user `break`s, abort the ongoing request.\n                if (!done)\n                    controller.abort();\n            }\n        }\n        return new Stream(iterator, controller, client);\n    }\n    [(_Stream_client = new WeakMap(), Symbol.asyncIterator)]() {\n        return this.iterator();\n    }\n    /**\n     * Splits the stream into two streams which can be\n     * independently read from at different speeds.\n     */\n    tee() {\n        const left = [];\n        const right = [];\n        const iterator = this.iterator();\n        const teeIterator = (queue) => {\n            return {\n                next: () => {\n                    if (queue.length === 0) {\n                        const result = iterator.next();\n                        left.push(result);\n                        right.push(result);\n                    }\n                    return queue.shift();\n                },\n            };\n        };\n        return [\n            new Stream(() => teeIterator(left), this.controller, __classPrivateFieldGet(this, _Stream_client, \"f\")),\n            new Stream(() => teeIterator(right), this.controller, __classPrivateFieldGet(this, _Stream_client, \"f\")),\n        ];\n    }\n    /**\n     * Converts this stream to a newline-separated ReadableStream of\n     * JSON stringified values in the stream\n     * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n     */\n    toReadableStream() {\n        const self = this;\n        let iter;\n        return makeReadableStream({\n            async start() {\n                iter = self[Symbol.asyncIterator]();\n            },\n            async pull(ctrl) {\n                try {\n                    const { value, done } = await iter.next();\n                    if (done)\n                        return ctrl.close();\n                    const bytes = encodeUTF8(JSON.stringify(value) + '\\n');\n                    ctrl.enqueue(bytes);\n                }\n                catch (err) {\n                    ctrl.error(err);\n                }\n            },\n            async cancel() {\n                await iter.return?.();\n            },\n        });\n    }\n}\nexport async function* _iterSSEMessages(response, controller) {\n    if (!response.body) {\n        controller.abort();\n        if (typeof globalThis.navigator !== 'undefined' &&\n            globalThis.navigator.product === 'ReactNative') {\n            throw new AnthropicError(`The default react-native fetch implementation does not support streaming. Please use expo/fetch: https://docs.expo.dev/versions/latest/sdk/expo/#expofetch-api`);\n        }\n        throw new AnthropicError(`Attempted to iterate over a response with no body`);\n    }\n    const sseDecoder = new SSEDecoder();\n    const lineDecoder = new LineDecoder();\n    const iter = ReadableStreamToAsyncIterable(response.body);\n    for await (const sseChunk of iterSSEChunks(iter)) {\n        for (const line of lineDecoder.decode(sseChunk)) {\n            const sse = sseDecoder.decode(line);\n            if (sse)\n                yield sse;\n        }\n    }\n    for (const line of lineDecoder.flush()) {\n        const sse = sseDecoder.decode(line);\n        if (sse)\n            yield sse;\n    }\n}\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator) {\n    let data = new Uint8Array();\n    for await (const chunk of iterator) {\n        if (chunk == null) {\n            continue;\n        }\n        const binaryChunk = chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n            : typeof chunk === 'string' ? encodeUTF8(chunk)\n                : chunk;\n        let newData = new Uint8Array(data.length + binaryChunk.length);\n        newData.set(data);\n        newData.set(binaryChunk, data.length);\n        data = newData;\n        let patternIndex;\n        while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n            yield data.slice(0, patternIndex);\n            data = data.slice(patternIndex);\n        }\n    }\n    if (data.length > 0) {\n        yield data;\n    }\n}\nclass SSEDecoder {\n    constructor() {\n        this.event = null;\n        this.data = [];\n        this.chunks = [];\n    }\n    decode(line) {\n        if (line.endsWith('\\r')) {\n            line = line.substring(0, line.length - 1);\n        }\n        if (!line) {\n            // empty line and we didn't previously encounter any messages\n            if (!this.event && !this.data.length)\n                return null;\n            const sse = {\n                event: this.event,\n                data: this.data.join('\\n'),\n                raw: this.chunks,\n            };\n            this.event = null;\n            this.data = [];\n            this.chunks = [];\n            return sse;\n        }\n        this.chunks.push(line);\n        if (line.startsWith(':')) {\n            return null;\n        }\n        let [fieldname, _, value] = partition(line, ':');\n        if (value.startsWith(' ')) {\n            value = value.substring(1);\n        }\n        if (fieldname === 'event') {\n            this.event = value;\n        }\n        else if (fieldname === 'data') {\n            this.data.push(value);\n        }\n        return null;\n    }\n}\nfunction partition(str, delimiter) {\n    const index = str.indexOf(delimiter);\n    if (index !== -1) {\n        return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n    }\n    return [str, '', ''];\n}\n//# sourceMappingURL=streaming.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { Stream } from \"../core/streaming.mjs\";\nimport { formatRequestDetails, loggerFor } from \"./utils/log.mjs\";\nexport async function defaultParseResponse(client, props) {\n    const { response, requestLogID, retryOfRequestLogID, startTime } = props;\n    const body = await (async () => {\n        if (props.options.stream) {\n            loggerFor(client).debug('response', response.status, response.url, response.headers, response.body);\n            // Note: there is an invariant here that isn't represented in the type system\n            // that if you set `stream: true` the response type must also be `Stream<T>`\n            if (props.options.__streamClass) {\n                return props.options.__streamClass.fromSSEResponse(response, props.controller);\n            }\n            return Stream.fromSSEResponse(response, props.controller);\n        }\n        // fetch refuses to read the body when the status code is 204.\n        if (response.status === 204) {\n            return null;\n        }\n        if (props.options.__binaryResponse) {\n            return response;\n        }\n        const contentType = response.headers.get('content-type');\n        const mediaType = contentType?.split(';')[0]?.trim();\n        const isJSON = mediaType?.includes('application/json') || mediaType?.endsWith('+json');\n        if (isJSON) {\n            const json = await response.json();\n            return addRequestID(json, response);\n        }\n        const text = await response.text();\n        return text;\n    })();\n    loggerFor(client).debug(`[${requestLogID}] response parsed`, formatRequestDetails({\n        retryOfRequestLogID,\n        url: response.url,\n        status: response.status,\n        body,\n        durationMs: Date.now() - startTime,\n    }));\n    return body;\n}\nexport function addRequestID(value, response) {\n    if (!value || typeof value !== 'object' || Array.isArray(value)) {\n        return value;\n    }\n    return Object.defineProperty(value, '_request_id', {\n        value: response.headers.get('request-id'),\n        enumerable: false,\n    });\n}\n//# sourceMappingURL=parse.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nvar _APIPromise_client;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"../internal/tslib.mjs\";\nimport { defaultParseResponse, addRequestID, } from \"../internal/parse.mjs\";\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nexport class APIPromise extends Promise {\n    constructor(client, responsePromise, parseResponse = defaultParseResponse) {\n        super((resolve) => {\n            // this is maybe a bit weird but this has to be a no-op to not implicitly\n            // parse the response body; instead .then, .catch, .finally are overridden\n            // to parse the response\n            resolve(null);\n        });\n        this.responsePromise = responsePromise;\n        this.parseResponse = parseResponse;\n        _APIPromise_client.set(this, void 0);\n        __classPrivateFieldSet(this, _APIPromise_client, client, \"f\");\n    }\n    _thenUnwrap(transform) {\n        return new APIPromise(__classPrivateFieldGet(this, _APIPromise_client, \"f\"), this.responsePromise, async (client, props) => addRequestID(transform(await this.parseResponse(client, props), props), props.response));\n    }\n    /**\n     * Gets the raw `Response` instance instead of parsing the response\n     * data.\n     *\n     * If you want to parse the response body but still get the `Response`\n     * instance, you can use {@link withResponse()}.\n     *\n     *  Getting the wrong TypeScript type for `Response`?\n     * Try setting `\"moduleResolution\": \"NodeNext\"` or add `\"lib\": [\"DOM\"]`\n     * to your `tsconfig.json`.\n     */\n    asResponse() {\n        return this.responsePromise.then((p) => p.response);\n    }\n    /**\n     * Gets the parsed response data, the raw `Response` instance and the ID of the request,\n     * returned via the `request-id` header which is useful for debugging requests and resporting\n     * issues to Anthropic.\n     *\n     * If you just want to get the raw `Response` instance without parsing it,\n     * you can use {@link asResponse()}.\n     *\n     *  Getting the wrong TypeScript type for `Response`?\n     * Try setting `\"moduleResolution\": \"NodeNext\"` or add `\"lib\": [\"DOM\"]`\n     * to your `tsconfig.json`.\n     */\n    async withResponse() {\n        const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n        return { data, response, request_id: response.headers.get('request-id') };\n    }\n    parse() {\n        if (!this.parsedPromise) {\n            this.parsedPromise = this.responsePromise.then((data) => this.parseResponse(__classPrivateFieldGet(this, _APIPromise_client, \"f\"), data));\n        }\n        return this.parsedPromise;\n    }\n    then(onfulfilled, onrejected) {\n        return this.parse().then(onfulfilled, onrejected);\n    }\n    catch(onrejected) {\n        return this.parse().catch(onrejected);\n    }\n    finally(onfinally) {\n        return this.parse().finally(onfinally);\n    }\n}\n_APIPromise_client = new WeakMap();\n//# sourceMappingURL=api-promise.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nvar _AbstractPage_client;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"../internal/tslib.mjs\";\nimport { AnthropicError } from \"./error.mjs\";\nimport { defaultParseResponse } from \"../internal/parse.mjs\";\nimport { APIPromise } from \"./api-promise.mjs\";\nimport { maybeObj } from \"../internal/utils/values.mjs\";\nexport class AbstractPage {\n    constructor(client, response, body, options) {\n        _AbstractPage_client.set(this, void 0);\n        __classPrivateFieldSet(this, _AbstractPage_client, client, \"f\");\n        this.options = options;\n        this.response = response;\n        this.body = body;\n    }\n    hasNextPage() {\n        const items = this.getPaginatedItems();\n        if (!items.length)\n            return false;\n        return this.nextPageRequestOptions() != null;\n    }\n    async getNextPage() {\n        const nextOptions = this.nextPageRequestOptions();\n        if (!nextOptions) {\n            throw new AnthropicError('No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.');\n        }\n        return await __classPrivateFieldGet(this, _AbstractPage_client, \"f\").requestAPIList(this.constructor, nextOptions);\n    }\n    async *iterPages() {\n        let page = this;\n        yield page;\n        while (page.hasNextPage()) {\n            page = await page.getNextPage();\n            yield page;\n        }\n    }\n    async *[(_AbstractPage_client = new WeakMap(), Symbol.asyncIterator)]() {\n        for await (const page of this.iterPages()) {\n            for (const item of page.getPaginatedItems()) {\n                yield item;\n            }\n        }\n    }\n}\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nexport class PagePromise extends APIPromise {\n    constructor(client, request, Page) {\n        super(client, request, async (client, props) => new Page(client, props.response, await defaultParseResponse(client, props), props.options));\n    }\n    /**\n     * Allow auto-paginating iteration on an unawaited list call, eg:\n     *\n     *    for await (const item of client.items.list()) {\n     *      console.log(item)\n     *    }\n     */\n    async *[Symbol.asyncIterator]() {\n        const page = await this;\n        for await (const item of page) {\n            yield item;\n        }\n    }\n}\nexport class Page extends AbstractPage {\n    constructor(client, response, body, options) {\n        super(client, response, body, options);\n        this.data = body.data || [];\n        this.has_more = body.has_more || false;\n        this.first_id = body.first_id || null;\n        this.last_id = body.last_id || null;\n    }\n    getPaginatedItems() {\n        return this.data ?? [];\n    }\n    hasNextPage() {\n        if (this.has_more === false) {\n            return false;\n        }\n        return super.hasNextPage();\n    }\n    nextPageRequestOptions() {\n        if (this.options.query?.['before_id']) {\n            // in reverse\n            const first_id = this.first_id;\n            if (!first_id) {\n                return null;\n            }\n            return {\n                ...this.options,\n                query: {\n                    ...maybeObj(this.options.query),\n                    before_id: first_id,\n                },\n            };\n        }\n        const cursor = this.last_id;\n        if (!cursor) {\n            return null;\n        }\n        return {\n            ...this.options,\n            query: {\n                ...maybeObj(this.options.query),\n                after_id: cursor,\n            },\n        };\n    }\n}\n//# sourceMappingURL=pagination.mjs.map","import { ReadableStreamFrom } from \"./shims.mjs\";\nexport const checkFileSupport = () => {\n    if (typeof File === 'undefined') {\n        const { process } = globalThis;\n        const isOldNode = typeof process?.versions?.node === 'string' && parseInt(process.versions.node.split('.')) < 20;\n        throw new Error('`File` is not defined as a global, which is required for file uploads.' +\n            (isOldNode ?\n                \" Update to Node 20 LTS or newer, or set `globalThis.File` to `import('node:buffer').File`.\"\n                : ''));\n    }\n};\n/**\n * Construct a `File` instance. This is used to ensure a helpful error is thrown\n * for environments that don't define a global `File` yet.\n */\nexport function makeFile(fileBits, fileName, options) {\n    checkFileSupport();\n    return new File(fileBits, fileName ?? 'unknown_file', options);\n}\nexport function getName(value) {\n    return (((typeof value === 'object' &&\n        value !== null &&\n        (('name' in value && value.name && String(value.name)) ||\n            ('url' in value && value.url && String(value.url)) ||\n            ('filename' in value && value.filename && String(value.filename)) ||\n            ('path' in value && value.path && String(value.path)))) ||\n        '')\n        .split(/[\\\\/]/)\n        .pop() || undefined);\n}\nexport const isAsyncIterable = (value) => value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nexport const maybeMultipartFormRequestOptions = async (opts, fetch) => {\n    if (!hasUploadableValue(opts.body))\n        return opts;\n    return { ...opts, body: await createForm(opts.body, fetch) };\n};\nexport const multipartFormRequestOptions = async (opts, fetch) => {\n    return { ...opts, body: await createForm(opts.body, fetch) };\n};\nconst supportsFormDataMap = /* @__PURE__ */ new WeakMap();\n/**\n * node-fetch doesn't support the global FormData object in recent node versions. Instead of sending\n * properly-encoded form data, it just stringifies the object, resulting in a request body of \"[object FormData]\".\n * This function detects if the fetch function provided supports the global FormData object to avoid\n * confusing error messages later on.\n */\nfunction supportsFormData(fetchObject) {\n    const fetch = typeof fetchObject === 'function' ? fetchObject : fetchObject.fetch;\n    const cached = supportsFormDataMap.get(fetch);\n    if (cached)\n        return cached;\n    const promise = (async () => {\n        try {\n            const FetchResponse = ('Response' in fetch ?\n                fetch.Response\n                : (await fetch('data:,')).constructor);\n            const data = new FormData();\n            if (data.toString() === (await new FetchResponse(data).text())) {\n                return false;\n            }\n            return true;\n        }\n        catch {\n            // avoid false negatives\n            return true;\n        }\n    })();\n    supportsFormDataMap.set(fetch, promise);\n    return promise;\n}\nexport const createForm = async (body, fetch) => {\n    if (!(await supportsFormData(fetch))) {\n        throw new TypeError('The provided fetch function does not support file uploads with the current global FormData class.');\n    }\n    const form = new FormData();\n    await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n    return form;\n};\n// We check for Blob not File because Bun.File doesn't inherit from File,\n// but they both inherit from Blob and have a `name` property at runtime.\nconst isNamedBlob = (value) => value instanceof Blob && 'name' in value;\nconst isUploadable = (value) => typeof value === 'object' &&\n    value !== null &&\n    (value instanceof Response || isAsyncIterable(value) || isNamedBlob(value));\nconst hasUploadableValue = (value) => {\n    if (isUploadable(value))\n        return true;\n    if (Array.isArray(value))\n        return value.some(hasUploadableValue);\n    if (value && typeof value === 'object') {\n        for (const k in value) {\n            if (hasUploadableValue(value[k]))\n                return true;\n        }\n    }\n    return false;\n};\nconst addFormValue = async (form, key, value) => {\n    if (value === undefined)\n        return;\n    if (value == null) {\n        throw new TypeError(`Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`);\n    }\n    // TODO: make nested formats configurable\n    if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n        form.append(key, String(value));\n    }\n    else if (value instanceof Response) {\n        let options = {};\n        const contentType = value.headers.get('Content-Type');\n        if (contentType) {\n            options = { type: contentType };\n        }\n        form.append(key, makeFile([await value.blob()], getName(value), options));\n    }\n    else if (isAsyncIterable(value)) {\n        form.append(key, makeFile([await new Response(ReadableStreamFrom(value)).blob()], getName(value)));\n    }\n    else if (isNamedBlob(value)) {\n        form.append(key, makeFile([value], getName(value), { type: value.type }));\n    }\n    else if (Array.isArray(value)) {\n        await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n    }\n    else if (typeof value === 'object') {\n        await Promise.all(Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)));\n    }\n    else {\n        throw new TypeError(`Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`);\n    }\n};\n//# sourceMappingURL=uploads.mjs.map","import { getName, makeFile, isAsyncIterable } from \"./uploads.mjs\";\nimport { checkFileSupport } from \"./uploads.mjs\";\n/**\n * This check adds the arrayBuffer() method type because it is available and used at runtime\n */\nconst isBlobLike = (value) => value != null &&\n    typeof value === 'object' &&\n    typeof value.size === 'number' &&\n    typeof value.type === 'string' &&\n    typeof value.text === 'function' &&\n    typeof value.slice === 'function' &&\n    typeof value.arrayBuffer === 'function';\n/**\n * This check adds the arrayBuffer() method type because it is available and used at runtime\n */\nconst isFileLike = (value) => value != null &&\n    typeof value === 'object' &&\n    typeof value.name === 'string' &&\n    typeof value.lastModified === 'number' &&\n    isBlobLike(value);\nconst isResponseLike = (value) => value != null &&\n    typeof value === 'object' &&\n    typeof value.url === 'string' &&\n    typeof value.blob === 'function';\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file.  Can be an {@link Uploadable}, {@link BlobLikePart}, or {@link AsyncIterable} of {@link BlobLikePart}s\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nexport async function toFile(value, name, options) {\n    checkFileSupport();\n    // If it's a promise, resolve it.\n    value = await value;\n    name || (name = getName(value));\n    // If we've been given a `File` we don't need to do anything if the name / options\n    // have not been customised.\n    if (isFileLike(value)) {\n        if (value instanceof File && name == null && options == null) {\n            return value;\n        }\n        return makeFile([await value.arrayBuffer()], name ?? value.name, {\n            type: value.type,\n            lastModified: value.lastModified,\n            ...options,\n        });\n    }\n    if (isResponseLike(value)) {\n        const blob = await value.blob();\n        name || (name = new URL(value.url).pathname.split(/[\\\\/]/).pop());\n        return makeFile(await getBytes(blob), name, options);\n    }\n    const parts = await getBytes(value);\n    if (!options?.type) {\n        const type = parts.find((part) => typeof part === 'object' && 'type' in part && part.type);\n        if (typeof type === 'string') {\n            options = { ...options, type };\n        }\n    }\n    return makeFile(parts, name, options);\n}\nasync function getBytes(value) {\n    let parts = [];\n    if (typeof value === 'string' ||\n        ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n        value instanceof ArrayBuffer) {\n        parts.push(value);\n    }\n    else if (isBlobLike(value)) {\n        parts.push(value instanceof Blob ? value : await value.arrayBuffer());\n    }\n    else if (isAsyncIterable(value) // includes Readable, ReadableStream, etc.\n    ) {\n        for await (const chunk of value) {\n            parts.push(...(await getBytes(chunk))); // TODO, consider validating?\n        }\n    }\n    else {\n        const constructor = value?.constructor?.name;\n        throw new Error(`Unexpected data type: ${typeof value}${constructor ? `; constructor: ${constructor}` : ''}${propsForError(value)}`);\n    }\n    return parts;\n}\nfunction propsForError(value) {\n    if (typeof value !== 'object' || value === null)\n        return '';\n    const props = Object.getOwnPropertyNames(value);\n    return `; props: [${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\n//# sourceMappingURL=to-file.mjs.map","export { toFile } from \"../internal/to-file.mjs\";\n//# sourceMappingURL=uploads.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nexport class APIResource {\n    constructor(client) {\n        this._client = client;\n    }\n}\n//# sourceMappingURL=resource.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { isReadonlyArray } from \"./utils/values.mjs\";\nconst brand_privateNullableHeaders = Symbol.for('brand.privateNullableHeaders');\nfunction* iterateHeaders(headers) {\n    if (!headers)\n        return;\n    if (brand_privateNullableHeaders in headers) {\n        const { values, nulls } = headers;\n        yield* values.entries();\n        for (const name of nulls) {\n            yield [name, null];\n        }\n        return;\n    }\n    let shouldClear = false;\n    let iter;\n    if (headers instanceof Headers) {\n        iter = headers.entries();\n    }\n    else if (isReadonlyArray(headers)) {\n        iter = headers;\n    }\n    else {\n        shouldClear = true;\n        iter = Object.entries(headers ?? {});\n    }\n    for (let row of iter) {\n        const name = row[0];\n        if (typeof name !== 'string')\n            throw new TypeError('expected header name to be a string');\n        const values = isReadonlyArray(row[1]) ? row[1] : [row[1]];\n        let didClear = false;\n        for (const value of values) {\n            if (value === undefined)\n                continue;\n            // Objects keys always overwrite older headers, they never append.\n            // Yield a null to clear the header before adding the new values.\n            if (shouldClear && !didClear) {\n                didClear = true;\n                yield [name, null];\n            }\n            yield [name, value];\n        }\n    }\n}\nexport const buildHeaders = (newHeaders) => {\n    const targetHeaders = new Headers();\n    const nullHeaders = new Set();\n    for (const headers of newHeaders) {\n        const seenHeaders = new Set();\n        for (const [name, value] of iterateHeaders(headers)) {\n            const lowerName = name.toLowerCase();\n            if (!seenHeaders.has(lowerName)) {\n                targetHeaders.delete(name);\n                seenHeaders.add(lowerName);\n            }\n            if (value === null) {\n                targetHeaders.delete(name);\n                nullHeaders.add(lowerName);\n            }\n            else {\n                targetHeaders.append(name, value);\n                nullHeaders.delete(lowerName);\n            }\n        }\n    }\n    return { [brand_privateNullableHeaders]: true, values: targetHeaders, nulls: nullHeaders };\n};\nexport const isEmptyHeaders = (headers) => {\n    for (const _ of iterateHeaders(headers))\n        return false;\n    return true;\n};\n//# sourceMappingURL=headers.mjs.map","import { AnthropicError } from \"../../core/error.mjs\";\n/**\n * Percent-encode everything that isn't safe to have in a path without encoding safe chars.\n *\n * Taken from https://datatracker.ietf.org/doc/html/rfc3986#section-3.3:\n * > unreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n * > sub-delims  = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\" / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n * > pchar       = unreserved / pct-encoded / sub-delims / \":\" / \"@\"\n */\nexport function encodeURIPath(str) {\n    return str.replace(/[^A-Za-z0-9\\-._~!$&'()*+,;=:@]+/g, encodeURIComponent);\n}\nconst EMPTY = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.create(null));\nexport const createPathTagFunction = (pathEncoder = encodeURIPath) => function path(statics, ...params) {\n    // If there are no params, no processing is needed.\n    if (statics.length === 1)\n        return statics[0];\n    let postPath = false;\n    const invalidSegments = [];\n    const path = statics.reduce((previousValue, currentValue, index) => {\n        if (/[?#]/.test(currentValue)) {\n            postPath = true;\n        }\n        const value = params[index];\n        let encoded = (postPath ? encodeURIComponent : pathEncoder)('' + value);\n        if (index !== params.length &&\n            (value == null ||\n                (typeof value === 'object' &&\n                    // handle values from other realms\n                    value.toString ===\n                        Object.getPrototypeOf(Object.getPrototypeOf(value.hasOwnProperty ?? EMPTY) ?? EMPTY)\n                            ?.toString))) {\n            encoded = value + '';\n            invalidSegments.push({\n                start: previousValue.length + currentValue.length,\n                length: encoded.length,\n                error: `Value of type ${Object.prototype.toString\n                    .call(value)\n                    .slice(8, -1)} is not a valid path parameter`,\n            });\n        }\n        return previousValue + currentValue + (index === params.length ? '' : encoded);\n    }, '');\n    const pathOnly = path.split(/[?#]/, 1)[0];\n    const invalidSegmentPattern = /(?<=^|\\/)(?:\\.|%2e){1,2}(?=\\/|$)/gi;\n    let match;\n    // Find all invalid segments\n    while ((match = invalidSegmentPattern.exec(pathOnly)) !== null) {\n        invalidSegments.push({\n            start: match.index,\n            length: match[0].length,\n            error: `Value \"${match[0]}\" can\\'t be safely passed as a path parameter`,\n        });\n    }\n    invalidSegments.sort((a, b) => a.start - b.start);\n    if (invalidSegments.length > 0) {\n        let lastEnd = 0;\n        const underline = invalidSegments.reduce((acc, segment) => {\n            const spaces = ' '.repeat(segment.start - lastEnd);\n            const arrows = '^'.repeat(segment.length);\n            lastEnd = segment.start + segment.length;\n            return acc + spaces + arrows;\n        }, '');\n        throw new AnthropicError(`Path parameters result in path with invalid segments:\\n${invalidSegments\n            .map((e) => e.error)\n            .join('\\n')}\\n${path}\\n${underline}`);\n    }\n    return path;\n};\n/**\n * URI-encodes path params and ensures no unsafe /./ or /../ path segments are introduced.\n */\nexport const path = /* @__PURE__ */ createPathTagFunction(encodeURIPath);\n//# sourceMappingURL=path.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../core/resource.mjs\";\nimport { Page } from \"../../core/pagination.mjs\";\nimport { buildHeaders } from \"../../internal/headers.mjs\";\nimport { multipartFormRequestOptions } from \"../../internal/uploads.mjs\";\nimport { path } from \"../../internal/utils/path.mjs\";\nexport class Files extends APIResource {\n    /**\n     * List Files\n     *\n     * @example\n     * ```ts\n     * // Automatically fetches more pages as needed.\n     * for await (const fileMetadata of client.beta.files.list()) {\n     *   // ...\n     * }\n     * ```\n     */\n    list(params = {}, options) {\n        const { betas, ...query } = params ?? {};\n        return this._client.getAPIList('/v1/files', (Page), {\n            query,\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'files-api-2025-04-14'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * Delete File\n     *\n     * @example\n     * ```ts\n     * const deletedFile = await client.beta.files.delete(\n     *   'file_id',\n     * );\n     * ```\n     */\n    delete(fileID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.delete(path `/v1/files/${fileID}`, {\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'files-api-2025-04-14'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * Download File\n     *\n     * @example\n     * ```ts\n     * const response = await client.beta.files.download(\n     *   'file_id',\n     * );\n     *\n     * const content = await response.blob();\n     * console.log(content);\n     * ```\n     */\n    download(fileID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.get(path `/v1/files/${fileID}/content`, {\n            ...options,\n            headers: buildHeaders([\n                {\n                    'anthropic-beta': [...(betas ?? []), 'files-api-2025-04-14'].toString(),\n                    Accept: 'application/binary',\n                },\n                options?.headers,\n            ]),\n            __binaryResponse: true,\n        });\n    }\n    /**\n     * Get File Metadata\n     *\n     * @example\n     * ```ts\n     * const fileMetadata =\n     *   await client.beta.files.retrieveMetadata('file_id');\n     * ```\n     */\n    retrieveMetadata(fileID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.get(path `/v1/files/${fileID}`, {\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'files-api-2025-04-14'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * Upload File\n     *\n     * @example\n     * ```ts\n     * const fileMetadata = await client.beta.files.upload({\n     *   file: fs.createReadStream('path/to/file'),\n     * });\n     * ```\n     */\n    upload(params, options) {\n        const { betas, ...body } = params;\n        return this._client.post('/v1/files', multipartFormRequestOptions({\n            body,\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'files-api-2025-04-14'].toString() },\n                options?.headers,\n            ]),\n        }, this._client));\n    }\n}\n//# sourceMappingURL=files.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../core/resource.mjs\";\nimport { Page } from \"../../core/pagination.mjs\";\nimport { buildHeaders } from \"../../internal/headers.mjs\";\nimport { path } from \"../../internal/utils/path.mjs\";\nexport class Models extends APIResource {\n    /**\n     * Get a specific model.\n     *\n     * The Models API response can be used to determine information about a specific\n     * model or resolve a model alias to a model ID.\n     *\n     * @example\n     * ```ts\n     * const betaModelInfo = await client.beta.models.retrieve(\n     *   'model_id',\n     * );\n     * ```\n     */\n    retrieve(modelID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.get(path `/v1/models/${modelID}?beta=true`, {\n            ...options,\n            headers: buildHeaders([\n                { ...(betas?.toString() != null ? { 'anthropic-beta': betas?.toString() } : undefined) },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * List available models.\n     *\n     * The Models API response can be used to determine which models are available for\n     * use in the API. More recently released models are listed first.\n     *\n     * @example\n     * ```ts\n     * // Automatically fetches more pages as needed.\n     * for await (const betaModelInfo of client.beta.models.list()) {\n     *   // ...\n     * }\n     * ```\n     */\n    list(params = {}, options) {\n        const { betas, ...query } = params ?? {};\n        return this._client.getAPIList('/v1/models?beta=true', (Page), {\n            query,\n            ...options,\n            headers: buildHeaders([\n                { ...(betas?.toString() != null ? { 'anthropic-beta': betas?.toString() } : undefined) },\n                options?.headers,\n            ]),\n        });\n    }\n}\n//# sourceMappingURL=models.mjs.map","import { AnthropicError } from \"../../core/error.mjs\";\nimport { ReadableStreamToAsyncIterable } from \"../shims.mjs\";\nimport { LineDecoder } from \"./line.mjs\";\nexport class JSONLDecoder {\n    constructor(iterator, controller) {\n        this.iterator = iterator;\n        this.controller = controller;\n    }\n    async *decoder() {\n        const lineDecoder = new LineDecoder();\n        for await (const chunk of this.iterator) {\n            for (const line of lineDecoder.decode(chunk)) {\n                yield JSON.parse(line);\n            }\n        }\n        for (const line of lineDecoder.flush()) {\n            yield JSON.parse(line);\n        }\n    }\n    [Symbol.asyncIterator]() {\n        return this.decoder();\n    }\n    static fromResponse(response, controller) {\n        if (!response.body) {\n            controller.abort();\n            if (typeof globalThis.navigator !== 'undefined' &&\n                globalThis.navigator.product === 'ReactNative') {\n                throw new AnthropicError(`The default react-native fetch implementation does not support streaming. Please use expo/fetch: https://docs.expo.dev/versions/latest/sdk/expo/#expofetch-api`);\n            }\n            throw new AnthropicError(`Attempted to iterate over a response with no body`);\n        }\n        return new JSONLDecoder(ReadableStreamToAsyncIterable(response.body), controller);\n    }\n}\n//# sourceMappingURL=jsonl.mjs.map","export * from \"./core/error.mjs\";\n//# sourceMappingURL=error.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../../core/resource.mjs\";\nimport { Page } from \"../../../core/pagination.mjs\";\nimport { buildHeaders } from \"../../../internal/headers.mjs\";\nimport { JSONLDecoder } from \"../../../internal/decoders/jsonl.mjs\";\nimport { AnthropicError } from \"../../../error.mjs\";\nimport { path } from \"../../../internal/utils/path.mjs\";\nexport class Batches extends APIResource {\n    /**\n     * Send a batch of Message creation requests.\n     *\n     * The Message Batches API can be used to process multiple Messages API requests at\n     * once. Once a Message Batch is created, it begins processing immediately. Batches\n     * can take up to 24 hours to complete.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const betaMessageBatch =\n     *   await client.beta.messages.batches.create({\n     *     requests: [\n     *       {\n     *         custom_id: 'my-custom-id-1',\n     *         params: {\n     *           max_tokens: 1024,\n     *           messages: [\n     *             { content: 'Hello, world', role: 'user' },\n     *           ],\n     *           model: 'claude-sonnet-4-5-20250929',\n     *         },\n     *       },\n     *     ],\n     *   });\n     * ```\n     */\n    create(params, options) {\n        const { betas, ...body } = params;\n        return this._client.post('/v1/messages/batches?beta=true', {\n            body,\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'message-batches-2024-09-24'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * This endpoint is idempotent and can be used to poll for Message Batch\n     * completion. To access the results of a Message Batch, make a request to the\n     * `results_url` field in the response.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const betaMessageBatch =\n     *   await client.beta.messages.batches.retrieve(\n     *     'message_batch_id',\n     *   );\n     * ```\n     */\n    retrieve(messageBatchID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.get(path `/v1/messages/batches/${messageBatchID}?beta=true`, {\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'message-batches-2024-09-24'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * List all Message Batches within a Workspace. Most recently created batches are\n     * returned first.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * // Automatically fetches more pages as needed.\n     * for await (const betaMessageBatch of client.beta.messages.batches.list()) {\n     *   // ...\n     * }\n     * ```\n     */\n    list(params = {}, options) {\n        const { betas, ...query } = params ?? {};\n        return this._client.getAPIList('/v1/messages/batches?beta=true', (Page), {\n            query,\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'message-batches-2024-09-24'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * Delete a Message Batch.\n     *\n     * Message Batches can only be deleted once they've finished processing. If you'd\n     * like to delete an in-progress batch, you must first cancel it.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const betaDeletedMessageBatch =\n     *   await client.beta.messages.batches.delete(\n     *     'message_batch_id',\n     *   );\n     * ```\n     */\n    delete(messageBatchID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.delete(path `/v1/messages/batches/${messageBatchID}?beta=true`, {\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'message-batches-2024-09-24'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * Batches may be canceled any time before processing ends. Once cancellation is\n     * initiated, the batch enters a `canceling` state, at which time the system may\n     * complete any in-progress, non-interruptible requests before finalizing\n     * cancellation.\n     *\n     * The number of canceled requests is specified in `request_counts`. To determine\n     * which requests were canceled, check the individual results within the batch.\n     * Note that cancellation may not result in any canceled requests if they were\n     * non-interruptible.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const betaMessageBatch =\n     *   await client.beta.messages.batches.cancel(\n     *     'message_batch_id',\n     *   );\n     * ```\n     */\n    cancel(messageBatchID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.post(path `/v1/messages/batches/${messageBatchID}/cancel?beta=true`, {\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'message-batches-2024-09-24'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * Streams the results of a Message Batch as a `.jsonl` file.\n     *\n     * Each line in the file is a JSON object containing the result of a single request\n     * in the Message Batch. Results are not guaranteed to be in the same order as\n     * requests. Use the `custom_id` field to match results to requests.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const betaMessageBatchIndividualResponse =\n     *   await client.beta.messages.batches.results(\n     *     'message_batch_id',\n     *   );\n     * ```\n     */\n    async results(messageBatchID, params = {}, options) {\n        const batch = await this.retrieve(messageBatchID);\n        if (!batch.results_url) {\n            throw new AnthropicError(`No batch \\`results_url\\`; Has it finished processing? ${batch.processing_status} - ${batch.id}`);\n        }\n        const { betas } = params ?? {};\n        return this._client\n            .get(batch.results_url, {\n            ...options,\n            headers: buildHeaders([\n                {\n                    'anthropic-beta': [...(betas ?? []), 'message-batches-2024-09-24'].toString(),\n                    Accept: 'application/binary',\n                },\n                options?.headers,\n            ]),\n            stream: true,\n            __binaryResponse: true,\n        })\n            ._thenUnwrap((_, props) => JSONLDecoder.fromResponse(props.response, props.controller));\n    }\n}\n//# sourceMappingURL=batches.mjs.map","export * from \"./core/streaming.mjs\";\n//# sourceMappingURL=streaming.mjs.map","const tokenize = (input) => {\n    let current = 0;\n    let tokens = [];\n    while (current < input.length) {\n        let char = input[current];\n        if (char === '\\\\') {\n            current++;\n            continue;\n        }\n        if (char === '{') {\n            tokens.push({\n                type: 'brace',\n                value: '{',\n            });\n            current++;\n            continue;\n        }\n        if (char === '}') {\n            tokens.push({\n                type: 'brace',\n                value: '}',\n            });\n            current++;\n            continue;\n        }\n        if (char === '[') {\n            tokens.push({\n                type: 'paren',\n                value: '[',\n            });\n            current++;\n            continue;\n        }\n        if (char === ']') {\n            tokens.push({\n                type: 'paren',\n                value: ']',\n            });\n            current++;\n            continue;\n        }\n        if (char === ':') {\n            tokens.push({\n                type: 'separator',\n                value: ':',\n            });\n            current++;\n            continue;\n        }\n        if (char === ',') {\n            tokens.push({\n                type: 'delimiter',\n                value: ',',\n            });\n            current++;\n            continue;\n        }\n        if (char === '\"') {\n            let value = '';\n            let danglingQuote = false;\n            char = input[++current];\n            while (char !== '\"') {\n                if (current === input.length) {\n                    danglingQuote = true;\n                    break;\n                }\n                if (char === '\\\\') {\n                    current++;\n                    if (current === input.length) {\n                        danglingQuote = true;\n                        break;\n                    }\n                    value += char + input[current];\n                    char = input[++current];\n                }\n                else {\n                    value += char;\n                    char = input[++current];\n                }\n            }\n            char = input[++current];\n            if (!danglingQuote) {\n                tokens.push({\n                    type: 'string',\n                    value,\n                });\n            }\n            continue;\n        }\n        let WHITESPACE = /\\s/;\n        if (char && WHITESPACE.test(char)) {\n            current++;\n            continue;\n        }\n        let NUMBERS = /[0-9]/;\n        if ((char && NUMBERS.test(char)) || char === '-' || char === '.') {\n            let value = '';\n            if (char === '-') {\n                value += char;\n                char = input[++current];\n            }\n            while ((char && NUMBERS.test(char)) || char === '.') {\n                value += char;\n                char = input[++current];\n            }\n            tokens.push({\n                type: 'number',\n                value,\n            });\n            continue;\n        }\n        let LETTERS = /[a-z]/i;\n        if (char && LETTERS.test(char)) {\n            let value = '';\n            while (char && LETTERS.test(char)) {\n                if (current === input.length) {\n                    break;\n                }\n                value += char;\n                char = input[++current];\n            }\n            if (value == 'true' || value == 'false' || value === 'null') {\n                tokens.push({\n                    type: 'name',\n                    value,\n                });\n            }\n            else {\n                // unknown token, e.g. `nul` which isn't quite `null`\n                current++;\n                continue;\n            }\n            continue;\n        }\n        current++;\n    }\n    return tokens;\n}, strip = (tokens) => {\n    if (tokens.length === 0) {\n        return tokens;\n    }\n    let lastToken = tokens[tokens.length - 1];\n    switch (lastToken.type) {\n        case 'separator':\n            tokens = tokens.slice(0, tokens.length - 1);\n            return strip(tokens);\n            break;\n        case 'number':\n            let lastCharacterOfLastToken = lastToken.value[lastToken.value.length - 1];\n            if (lastCharacterOfLastToken === '.' || lastCharacterOfLastToken === '-') {\n                tokens = tokens.slice(0, tokens.length - 1);\n                return strip(tokens);\n            }\n        case 'string':\n            let tokenBeforeTheLastToken = tokens[tokens.length - 2];\n            if (tokenBeforeTheLastToken?.type === 'delimiter') {\n                tokens = tokens.slice(0, tokens.length - 1);\n                return strip(tokens);\n            }\n            else if (tokenBeforeTheLastToken?.type === 'brace' && tokenBeforeTheLastToken.value === '{') {\n                tokens = tokens.slice(0, tokens.length - 1);\n                return strip(tokens);\n            }\n            break;\n        case 'delimiter':\n            tokens = tokens.slice(0, tokens.length - 1);\n            return strip(tokens);\n            break;\n    }\n    return tokens;\n}, unstrip = (tokens) => {\n    let tail = [];\n    tokens.map((token) => {\n        if (token.type === 'brace') {\n            if (token.value === '{') {\n                tail.push('}');\n            }\n            else {\n                tail.splice(tail.lastIndexOf('}'), 1);\n            }\n        }\n        if (token.type === 'paren') {\n            if (token.value === '[') {\n                tail.push(']');\n            }\n            else {\n                tail.splice(tail.lastIndexOf(']'), 1);\n            }\n        }\n    });\n    if (tail.length > 0) {\n        tail.reverse().map((item) => {\n            if (item === '}') {\n                tokens.push({\n                    type: 'brace',\n                    value: '}',\n                });\n            }\n            else if (item === ']') {\n                tokens.push({\n                    type: 'paren',\n                    value: ']',\n                });\n            }\n        });\n    }\n    return tokens;\n}, generate = (tokens) => {\n    let output = '';\n    tokens.map((token) => {\n        switch (token.type) {\n            case 'string':\n                output += '\"' + token.value + '\"';\n                break;\n            default:\n                output += token.value;\n                break;\n        }\n    });\n    return output;\n}, partialParse = (input) => JSON.parse(generate(unstrip(strip(tokenize(input)))));\nexport { partialParse };\n//# sourceMappingURL=parser.mjs.map","var _BetaMessageStream_instances, _BetaMessageStream_currentMessageSnapshot, _BetaMessageStream_connectedPromise, _BetaMessageStream_resolveConnectedPromise, _BetaMessageStream_rejectConnectedPromise, _BetaMessageStream_endPromise, _BetaMessageStream_resolveEndPromise, _BetaMessageStream_rejectEndPromise, _BetaMessageStream_listeners, _BetaMessageStream_ended, _BetaMessageStream_errored, _BetaMessageStream_aborted, _BetaMessageStream_catchingPromiseCreated, _BetaMessageStream_response, _BetaMessageStream_request_id, _BetaMessageStream_getFinalMessage, _BetaMessageStream_getFinalText, _BetaMessageStream_handleError, _BetaMessageStream_beginRequest, _BetaMessageStream_addStreamEvent, _BetaMessageStream_endRequest, _BetaMessageStream_accumulateMessage;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"../internal/tslib.mjs\";\nimport { isAbortError } from \"../internal/errors.mjs\";\nimport { AnthropicError, APIUserAbortError } from \"../error.mjs\";\nimport { Stream } from \"../streaming.mjs\";\nimport { partialParse } from \"../_vendor/partial-json-parser/parser.mjs\";\nconst JSON_BUF_PROPERTY = '__json_buf';\nfunction tracksToolInput(content) {\n    return content.type === 'tool_use' || content.type === 'server_tool_use' || content.type === 'mcp_tool_use';\n}\nexport class BetaMessageStream {\n    constructor() {\n        _BetaMessageStream_instances.add(this);\n        this.messages = [];\n        this.receivedMessages = [];\n        _BetaMessageStream_currentMessageSnapshot.set(this, void 0);\n        this.controller = new AbortController();\n        _BetaMessageStream_connectedPromise.set(this, void 0);\n        _BetaMessageStream_resolveConnectedPromise.set(this, () => { });\n        _BetaMessageStream_rejectConnectedPromise.set(this, () => { });\n        _BetaMessageStream_endPromise.set(this, void 0);\n        _BetaMessageStream_resolveEndPromise.set(this, () => { });\n        _BetaMessageStream_rejectEndPromise.set(this, () => { });\n        _BetaMessageStream_listeners.set(this, {});\n        _BetaMessageStream_ended.set(this, false);\n        _BetaMessageStream_errored.set(this, false);\n        _BetaMessageStream_aborted.set(this, false);\n        _BetaMessageStream_catchingPromiseCreated.set(this, false);\n        _BetaMessageStream_response.set(this, void 0);\n        _BetaMessageStream_request_id.set(this, void 0);\n        _BetaMessageStream_handleError.set(this, (error) => {\n            __classPrivateFieldSet(this, _BetaMessageStream_errored, true, \"f\");\n            if (isAbortError(error)) {\n                error = new APIUserAbortError();\n            }\n            if (error instanceof APIUserAbortError) {\n                __classPrivateFieldSet(this, _BetaMessageStream_aborted, true, \"f\");\n                return this._emit('abort', error);\n            }\n            if (error instanceof AnthropicError) {\n                return this._emit('error', error);\n            }\n            if (error instanceof Error) {\n                const anthropicError = new AnthropicError(error.message);\n                // @ts-ignore\n                anthropicError.cause = error;\n                return this._emit('error', anthropicError);\n            }\n            return this._emit('error', new AnthropicError(String(error)));\n        });\n        __classPrivateFieldSet(this, _BetaMessageStream_connectedPromise, new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _BetaMessageStream_resolveConnectedPromise, resolve, \"f\");\n            __classPrivateFieldSet(this, _BetaMessageStream_rejectConnectedPromise, reject, \"f\");\n        }), \"f\");\n        __classPrivateFieldSet(this, _BetaMessageStream_endPromise, new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _BetaMessageStream_resolveEndPromise, resolve, \"f\");\n            __classPrivateFieldSet(this, _BetaMessageStream_rejectEndPromise, reject, \"f\");\n        }), \"f\");\n        // Don't let these promises cause unhandled rejection errors.\n        // we will manually cause an unhandled rejection error later\n        // if the user hasn't registered any error listener or called\n        // any promise-returning method.\n        __classPrivateFieldGet(this, _BetaMessageStream_connectedPromise, \"f\").catch(() => { });\n        __classPrivateFieldGet(this, _BetaMessageStream_endPromise, \"f\").catch(() => { });\n    }\n    get response() {\n        return __classPrivateFieldGet(this, _BetaMessageStream_response, \"f\");\n    }\n    get request_id() {\n        return __classPrivateFieldGet(this, _BetaMessageStream_request_id, \"f\");\n    }\n    /**\n     * Returns the `MessageStream` data, the raw `Response` instance and the ID of the request,\n     * returned vie the `request-id` header which is useful for debugging requests and resporting\n     * issues to Anthropic.\n     *\n     * This is the same as the `APIPromise.withResponse()` method.\n     *\n     * This method will raise an error if you created the stream using `MessageStream.fromReadableStream`\n     * as no `Response` is available.\n     */\n    async withResponse() {\n        const response = await __classPrivateFieldGet(this, _BetaMessageStream_connectedPromise, \"f\");\n        if (!response) {\n            throw new Error('Could not resolve a `Response` object');\n        }\n        return {\n            data: this,\n            response,\n            request_id: response.headers.get('request-id'),\n        };\n    }\n    /**\n     * Intended for use on the frontend, consuming a stream produced with\n     * `.toReadableStream()` on the backend.\n     *\n     * Note that messages sent to the model do not appear in `.on('message')`\n     * in this context.\n     */\n    static fromReadableStream(stream) {\n        const runner = new BetaMessageStream();\n        runner._run(() => runner._fromReadableStream(stream));\n        return runner;\n    }\n    static createMessage(messages, params, options) {\n        const runner = new BetaMessageStream();\n        for (const message of params.messages) {\n            runner._addMessageParam(message);\n        }\n        runner._run(() => runner._createMessage(messages, { ...params, stream: true }, { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } }));\n        return runner;\n    }\n    _run(executor) {\n        executor().then(() => {\n            this._emitFinal();\n            this._emit('end');\n        }, __classPrivateFieldGet(this, _BetaMessageStream_handleError, \"f\"));\n    }\n    _addMessageParam(message) {\n        this.messages.push(message);\n    }\n    _addMessage(message, emit = true) {\n        this.receivedMessages.push(message);\n        if (emit) {\n            this._emit('message', message);\n        }\n    }\n    async _createMessage(messages, params, options) {\n        const signal = options?.signal;\n        let abortHandler;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            abortHandler = this.controller.abort.bind(this.controller);\n            signal.addEventListener('abort', abortHandler);\n        }\n        try {\n            __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_beginRequest).call(this);\n            const { response, data: stream } = await messages\n                .create({ ...params, stream: true }, { ...options, signal: this.controller.signal })\n                .withResponse();\n            this._connected(response);\n            for await (const event of stream) {\n                __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_addStreamEvent).call(this, event);\n            }\n            if (stream.controller.signal?.aborted) {\n                throw new APIUserAbortError();\n            }\n            __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_endRequest).call(this);\n        }\n        finally {\n            if (signal && abortHandler) {\n                signal.removeEventListener('abort', abortHandler);\n            }\n        }\n    }\n    _connected(response) {\n        if (this.ended)\n            return;\n        __classPrivateFieldSet(this, _BetaMessageStream_response, response, \"f\");\n        __classPrivateFieldSet(this, _BetaMessageStream_request_id, response?.headers.get('request-id'), \"f\");\n        __classPrivateFieldGet(this, _BetaMessageStream_resolveConnectedPromise, \"f\").call(this, response);\n        this._emit('connect');\n    }\n    get ended() {\n        return __classPrivateFieldGet(this, _BetaMessageStream_ended, \"f\");\n    }\n    get errored() {\n        return __classPrivateFieldGet(this, _BetaMessageStream_errored, \"f\");\n    }\n    get aborted() {\n        return __classPrivateFieldGet(this, _BetaMessageStream_aborted, \"f\");\n    }\n    abort() {\n        this.controller.abort();\n    }\n    /**\n     * Adds the listener function to the end of the listeners array for the event.\n     * No checks are made to see if the listener has already been added. Multiple calls passing\n     * the same combination of event and listener will result in the listener being added, and\n     * called, multiple times.\n     * @returns this MessageStream, so that calls can be chained\n     */\n    on(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _BetaMessageStream_listeners, \"f\")[event] || (__classPrivateFieldGet(this, _BetaMessageStream_listeners, \"f\")[event] = []);\n        listeners.push({ listener });\n        return this;\n    }\n    /**\n     * Removes the specified listener from the listener array for the event.\n     * off() will remove, at most, one instance of a listener from the listener array. If any single\n     * listener has been added multiple times to the listener array for the specified event, then\n     * off() must be called multiple times to remove each instance.\n     * @returns this MessageStream, so that calls can be chained\n     */\n    off(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _BetaMessageStream_listeners, \"f\")[event];\n        if (!listeners)\n            return this;\n        const index = listeners.findIndex((l) => l.listener === listener);\n        if (index >= 0)\n            listeners.splice(index, 1);\n        return this;\n    }\n    /**\n     * Adds a one-time listener function for the event. The next time the event is triggered,\n     * this listener is removed and then invoked.\n     * @returns this MessageStream, so that calls can be chained\n     */\n    once(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _BetaMessageStream_listeners, \"f\")[event] || (__classPrivateFieldGet(this, _BetaMessageStream_listeners, \"f\")[event] = []);\n        listeners.push({ listener, once: true });\n        return this;\n    }\n    /**\n     * This is similar to `.once()`, but returns a Promise that resolves the next time\n     * the event is triggered, instead of calling a listener callback.\n     * @returns a Promise that resolves the next time given event is triggered,\n     * or rejects if an error is emitted.  (If you request the 'error' event,\n     * returns a promise that resolves with the error).\n     *\n     * Example:\n     *\n     *   const message = await stream.emitted('message') // rejects if the stream errors\n     */\n    emitted(event) {\n        return new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _BetaMessageStream_catchingPromiseCreated, true, \"f\");\n            if (event !== 'error')\n                this.once('error', reject);\n            this.once(event, resolve);\n        });\n    }\n    async done() {\n        __classPrivateFieldSet(this, _BetaMessageStream_catchingPromiseCreated, true, \"f\");\n        await __classPrivateFieldGet(this, _BetaMessageStream_endPromise, \"f\");\n    }\n    get currentMessage() {\n        return __classPrivateFieldGet(this, _BetaMessageStream_currentMessageSnapshot, \"f\");\n    }\n    /**\n     * @returns a promise that resolves with the the final assistant Message response,\n     * or rejects if an error occurred or the stream ended prematurely without producing a Message.\n     */\n    async finalMessage() {\n        await this.done();\n        return __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_getFinalMessage).call(this);\n    }\n    /**\n     * @returns a promise that resolves with the the final assistant Message's text response, concatenated\n     * together if there are more than one text blocks.\n     * Rejects if an error occurred or the stream ended prematurely without producing a Message.\n     */\n    async finalText() {\n        await this.done();\n        return __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_getFinalText).call(this);\n    }\n    _emit(event, ...args) {\n        // make sure we don't emit any MessageStreamEvents after end\n        if (__classPrivateFieldGet(this, _BetaMessageStream_ended, \"f\"))\n            return;\n        if (event === 'end') {\n            __classPrivateFieldSet(this, _BetaMessageStream_ended, true, \"f\");\n            __classPrivateFieldGet(this, _BetaMessageStream_resolveEndPromise, \"f\").call(this);\n        }\n        const listeners = __classPrivateFieldGet(this, _BetaMessageStream_listeners, \"f\")[event];\n        if (listeners) {\n            __classPrivateFieldGet(this, _BetaMessageStream_listeners, \"f\")[event] = listeners.filter((l) => !l.once);\n            listeners.forEach(({ listener }) => listener(...args));\n        }\n        if (event === 'abort') {\n            const error = args[0];\n            if (!__classPrivateFieldGet(this, _BetaMessageStream_catchingPromiseCreated, \"f\") && !listeners?.length) {\n                Promise.reject(error);\n            }\n            __classPrivateFieldGet(this, _BetaMessageStream_rejectConnectedPromise, \"f\").call(this, error);\n            __classPrivateFieldGet(this, _BetaMessageStream_rejectEndPromise, \"f\").call(this, error);\n            this._emit('end');\n            return;\n        }\n        if (event === 'error') {\n            // NOTE: _emit('error', error) should only be called from #handleError().\n            const error = args[0];\n            if (!__classPrivateFieldGet(this, _BetaMessageStream_catchingPromiseCreated, \"f\") && !listeners?.length) {\n                // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n                // If you are seeing stack traces here, make sure to handle errors via either:\n                // - runner.on('error', () => ...)\n                // - await runner.done()\n                // - await runner.final...()\n                // - etc.\n                Promise.reject(error);\n            }\n            __classPrivateFieldGet(this, _BetaMessageStream_rejectConnectedPromise, \"f\").call(this, error);\n            __classPrivateFieldGet(this, _BetaMessageStream_rejectEndPromise, \"f\").call(this, error);\n            this._emit('end');\n        }\n    }\n    _emitFinal() {\n        const finalMessage = this.receivedMessages.at(-1);\n        if (finalMessage) {\n            this._emit('finalMessage', __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_getFinalMessage).call(this));\n        }\n    }\n    async _fromReadableStream(readableStream, options) {\n        const signal = options?.signal;\n        let abortHandler;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            abortHandler = this.controller.abort.bind(this.controller);\n            signal.addEventListener('abort', abortHandler);\n        }\n        try {\n            __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_beginRequest).call(this);\n            this._connected(null);\n            const stream = Stream.fromReadableStream(readableStream, this.controller);\n            for await (const event of stream) {\n                __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_addStreamEvent).call(this, event);\n            }\n            if (stream.controller.signal?.aborted) {\n                throw new APIUserAbortError();\n            }\n            __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_endRequest).call(this);\n        }\n        finally {\n            if (signal && abortHandler) {\n                signal.removeEventListener('abort', abortHandler);\n            }\n        }\n    }\n    [(_BetaMessageStream_currentMessageSnapshot = new WeakMap(), _BetaMessageStream_connectedPromise = new WeakMap(), _BetaMessageStream_resolveConnectedPromise = new WeakMap(), _BetaMessageStream_rejectConnectedPromise = new WeakMap(), _BetaMessageStream_endPromise = new WeakMap(), _BetaMessageStream_resolveEndPromise = new WeakMap(), _BetaMessageStream_rejectEndPromise = new WeakMap(), _BetaMessageStream_listeners = new WeakMap(), _BetaMessageStream_ended = new WeakMap(), _BetaMessageStream_errored = new WeakMap(), _BetaMessageStream_aborted = new WeakMap(), _BetaMessageStream_catchingPromiseCreated = new WeakMap(), _BetaMessageStream_response = new WeakMap(), _BetaMessageStream_request_id = new WeakMap(), _BetaMessageStream_handleError = new WeakMap(), _BetaMessageStream_instances = new WeakSet(), _BetaMessageStream_getFinalMessage = function _BetaMessageStream_getFinalMessage() {\n        if (this.receivedMessages.length === 0) {\n            throw new AnthropicError('stream ended without producing a Message with role=assistant');\n        }\n        return this.receivedMessages.at(-1);\n    }, _BetaMessageStream_getFinalText = function _BetaMessageStream_getFinalText() {\n        if (this.receivedMessages.length === 0) {\n            throw new AnthropicError('stream ended without producing a Message with role=assistant');\n        }\n        const textBlocks = this.receivedMessages\n            .at(-1)\n            .content.filter((block) => block.type === 'text')\n            .map((block) => block.text);\n        if (textBlocks.length === 0) {\n            throw new AnthropicError('stream ended without producing a content block with type=text');\n        }\n        return textBlocks.join(' ');\n    }, _BetaMessageStream_beginRequest = function _BetaMessageStream_beginRequest() {\n        if (this.ended)\n            return;\n        __classPrivateFieldSet(this, _BetaMessageStream_currentMessageSnapshot, undefined, \"f\");\n    }, _BetaMessageStream_addStreamEvent = function _BetaMessageStream_addStreamEvent(event) {\n        if (this.ended)\n            return;\n        const messageSnapshot = __classPrivateFieldGet(this, _BetaMessageStream_instances, \"m\", _BetaMessageStream_accumulateMessage).call(this, event);\n        this._emit('streamEvent', event, messageSnapshot);\n        switch (event.type) {\n            case 'content_block_delta': {\n                const content = messageSnapshot.content.at(-1);\n                switch (event.delta.type) {\n                    case 'text_delta': {\n                        if (content.type === 'text') {\n                            this._emit('text', event.delta.text, content.text || '');\n                        }\n                        break;\n                    }\n                    case 'citations_delta': {\n                        if (content.type === 'text') {\n                            this._emit('citation', event.delta.citation, content.citations ?? []);\n                        }\n                        break;\n                    }\n                    case 'input_json_delta': {\n                        if (tracksToolInput(content) && content.input) {\n                            this._emit('inputJson', event.delta.partial_json, content.input);\n                        }\n                        break;\n                    }\n                    case 'thinking_delta': {\n                        if (content.type === 'thinking') {\n                            this._emit('thinking', event.delta.thinking, content.thinking);\n                        }\n                        break;\n                    }\n                    case 'signature_delta': {\n                        if (content.type === 'thinking') {\n                            this._emit('signature', content.signature);\n                        }\n                        break;\n                    }\n                    default:\n                        checkNever(event.delta);\n                }\n                break;\n            }\n            case 'message_stop': {\n                this._addMessageParam(messageSnapshot);\n                this._addMessage(messageSnapshot, true);\n                break;\n            }\n            case 'content_block_stop': {\n                this._emit('contentBlock', messageSnapshot.content.at(-1));\n                break;\n            }\n            case 'message_start': {\n                __classPrivateFieldSet(this, _BetaMessageStream_currentMessageSnapshot, messageSnapshot, \"f\");\n                break;\n            }\n            case 'content_block_start':\n            case 'message_delta':\n                break;\n        }\n    }, _BetaMessageStream_endRequest = function _BetaMessageStream_endRequest() {\n        if (this.ended) {\n            throw new AnthropicError(`stream has ended, this shouldn't happen`);\n        }\n        const snapshot = __classPrivateFieldGet(this, _BetaMessageStream_currentMessageSnapshot, \"f\");\n        if (!snapshot) {\n            throw new AnthropicError(`request ended without sending any chunks`);\n        }\n        __classPrivateFieldSet(this, _BetaMessageStream_currentMessageSnapshot, undefined, \"f\");\n        return snapshot;\n    }, _BetaMessageStream_accumulateMessage = function _BetaMessageStream_accumulateMessage(event) {\n        let snapshot = __classPrivateFieldGet(this, _BetaMessageStream_currentMessageSnapshot, \"f\");\n        if (event.type === 'message_start') {\n            if (snapshot) {\n                throw new AnthropicError(`Unexpected event order, got ${event.type} before receiving \"message_stop\"`);\n            }\n            return event.message;\n        }\n        if (!snapshot) {\n            throw new AnthropicError(`Unexpected event order, got ${event.type} before \"message_start\"`);\n        }\n        switch (event.type) {\n            case 'message_stop':\n                return snapshot;\n            case 'message_delta':\n                snapshot.container = event.delta.container;\n                snapshot.stop_reason = event.delta.stop_reason;\n                snapshot.stop_sequence = event.delta.stop_sequence;\n                snapshot.usage.output_tokens = event.usage.output_tokens;\n                snapshot.context_management = event.context_management;\n                if (event.usage.input_tokens != null) {\n                    snapshot.usage.input_tokens = event.usage.input_tokens;\n                }\n                if (event.usage.cache_creation_input_tokens != null) {\n                    snapshot.usage.cache_creation_input_tokens = event.usage.cache_creation_input_tokens;\n                }\n                if (event.usage.cache_read_input_tokens != null) {\n                    snapshot.usage.cache_read_input_tokens = event.usage.cache_read_input_tokens;\n                }\n                if (event.usage.server_tool_use != null) {\n                    snapshot.usage.server_tool_use = event.usage.server_tool_use;\n                }\n                return snapshot;\n            case 'content_block_start':\n                snapshot.content.push(event.content_block);\n                return snapshot;\n            case 'content_block_delta': {\n                const snapshotContent = snapshot.content.at(event.index);\n                switch (event.delta.type) {\n                    case 'text_delta': {\n                        if (snapshotContent?.type === 'text') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                text: (snapshotContent.text || '') + event.delta.text,\n                            };\n                        }\n                        break;\n                    }\n                    case 'citations_delta': {\n                        if (snapshotContent?.type === 'text') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                citations: [...(snapshotContent.citations ?? []), event.delta.citation],\n                            };\n                        }\n                        break;\n                    }\n                    case 'input_json_delta': {\n                        if (snapshotContent && tracksToolInput(snapshotContent)) {\n                            // we need to keep track of the raw JSON string as well so that we can\n                            // re-parse it for each delta, for now we just store it as an untyped\n                            // non-enumerable property on the snapshot\n                            let jsonBuf = snapshotContent[JSON_BUF_PROPERTY] || '';\n                            jsonBuf += event.delta.partial_json;\n                            const newContent = { ...snapshotContent };\n                            Object.defineProperty(newContent, JSON_BUF_PROPERTY, {\n                                value: jsonBuf,\n                                enumerable: false,\n                                writable: true,\n                            });\n                            if (jsonBuf) {\n                                try {\n                                    newContent.input = partialParse(jsonBuf);\n                                }\n                                catch (err) {\n                                    const error = new AnthropicError(`Unable to parse tool parameter JSON from model. Please retry your request or adjust your prompt. Error: ${err}. JSON: ${jsonBuf}`);\n                                    __classPrivateFieldGet(this, _BetaMessageStream_handleError, \"f\").call(this, error);\n                                }\n                            }\n                            snapshot.content[event.index] = newContent;\n                        }\n                        break;\n                    }\n                    case 'thinking_delta': {\n                        if (snapshotContent?.type === 'thinking') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                thinking: snapshotContent.thinking + event.delta.thinking,\n                            };\n                        }\n                        break;\n                    }\n                    case 'signature_delta': {\n                        if (snapshotContent?.type === 'thinking') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                signature: event.delta.signature,\n                            };\n                        }\n                        break;\n                    }\n                    default:\n                        checkNever(event.delta);\n                }\n                return snapshot;\n            }\n            case 'content_block_stop':\n                return snapshot;\n        }\n    }, Symbol.asyncIterator)]() {\n        const pushQueue = [];\n        const readQueue = [];\n        let done = false;\n        this.on('streamEvent', (event) => {\n            const reader = readQueue.shift();\n            if (reader) {\n                reader.resolve(event);\n            }\n            else {\n                pushQueue.push(event);\n            }\n        });\n        this.on('end', () => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.resolve(undefined);\n            }\n            readQueue.length = 0;\n        });\n        this.on('abort', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        this.on('error', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        return {\n            next: async () => {\n                if (!pushQueue.length) {\n                    if (done) {\n                        return { value: undefined, done: true };\n                    }\n                    return new Promise((resolve, reject) => readQueue.push({ resolve, reject })).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n                }\n                const chunk = pushQueue.shift();\n                return { value: chunk, done: false };\n            },\n            return: async () => {\n                this.abort();\n                return { value: undefined, done: true };\n            },\n        };\n    }\n    toReadableStream() {\n        const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n        return stream.toReadableStream();\n    }\n}\n// used to ensure exhaustive case matching without throwing a runtime error\nfunction checkNever(x) { }\n//# sourceMappingURL=BetaMessageStream.mjs.map","// File containing shared constants\n/**\n * Model-specific timeout constraints for non-streaming requests\n */\nexport const MODEL_NONSTREAMING_TOKENS = {\n    'claude-opus-4-20250514': 8192,\n    'claude-opus-4-0': 8192,\n    'claude-4-opus-20250514': 8192,\n    'anthropic.claude-opus-4-20250514-v1:0': 8192,\n    'claude-opus-4@20250514': 8192,\n    'claude-opus-4-1-20250805': 8192,\n    'anthropic.claude-opus-4-1-20250805-v1:0': 8192,\n    'claude-opus-4-1@20250805': 8192,\n};\n//# sourceMappingURL=constants.mjs.map","var _BetaToolRunner_instances, _BetaToolRunner_consumed, _BetaToolRunner_mutated, _BetaToolRunner_state, _BetaToolRunner_options, _BetaToolRunner_message, _BetaToolRunner_toolResponse, _BetaToolRunner_completion, _BetaToolRunner_iterationCount, _BetaToolRunner_generateToolResponse;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"../../internal/tslib.mjs\";\nimport { AnthropicError } from \"../../core/error.mjs\";\nimport { buildHeaders } from \"../../internal/headers.mjs\";\n/**\n * Just Promise.withResolvers(), which is not available in all environments.\n */\nfunction promiseWithResolvers() {\n    let resolve;\n    let reject;\n    const promise = new Promise((res, rej) => {\n        resolve = res;\n        reject = rej;\n    });\n    return { promise, resolve: resolve, reject: reject };\n}\n/**\n * A ToolRunner handles the automatic conversation loop between the assistant and tools.\n *\n * A ToolRunner is an async iterable that yields either BetaMessage or BetaMessageStream objects\n * depending on the streaming configuration.\n */\nexport class BetaToolRunner {\n    constructor(client, params, options) {\n        _BetaToolRunner_instances.add(this);\n        this.client = client;\n        /** Whether the async iterator has been consumed */\n        _BetaToolRunner_consumed.set(this, false);\n        /** Whether parameters have been mutated since the last API call */\n        _BetaToolRunner_mutated.set(this, false);\n        /** Current state containing the request parameters */\n        _BetaToolRunner_state.set(this, void 0);\n        _BetaToolRunner_options.set(this, void 0);\n        /** Promise for the last message received from the assistant */\n        _BetaToolRunner_message.set(this, void 0);\n        /** Cached tool response to avoid redundant executions */\n        _BetaToolRunner_toolResponse.set(this, void 0);\n        /** Promise resolvers for waiting on completion */\n        _BetaToolRunner_completion.set(this, void 0);\n        /** Number of iterations (API requests) made so far */\n        _BetaToolRunner_iterationCount.set(this, 0);\n        __classPrivateFieldSet(this, _BetaToolRunner_state, {\n            params: {\n                // You can't clone the entire params since there are functions as handlers.\n                // You also don't really need to clone params.messages, but it probably will prevent a foot gun\n                // somewhere.\n                ...params,\n                messages: structuredClone(params.messages),\n            },\n        }, \"f\");\n        __classPrivateFieldSet(this, _BetaToolRunner_options, {\n            ...options,\n            headers: buildHeaders([{ 'x-stainless-helper': 'BetaToolRunner' }, options?.headers]),\n        }, \"f\");\n        __classPrivateFieldSet(this, _BetaToolRunner_completion, promiseWithResolvers(), \"f\");\n    }\n    async *[(_BetaToolRunner_consumed = new WeakMap(), _BetaToolRunner_mutated = new WeakMap(), _BetaToolRunner_state = new WeakMap(), _BetaToolRunner_options = new WeakMap(), _BetaToolRunner_message = new WeakMap(), _BetaToolRunner_toolResponse = new WeakMap(), _BetaToolRunner_completion = new WeakMap(), _BetaToolRunner_iterationCount = new WeakMap(), _BetaToolRunner_instances = new WeakSet(), Symbol.asyncIterator)]() {\n        var _a;\n        if (__classPrivateFieldGet(this, _BetaToolRunner_consumed, \"f\")) {\n            throw new AnthropicError('Cannot iterate over a consumed stream');\n        }\n        __classPrivateFieldSet(this, _BetaToolRunner_consumed, true, \"f\");\n        __classPrivateFieldSet(this, _BetaToolRunner_mutated, true, \"f\");\n        __classPrivateFieldSet(this, _BetaToolRunner_toolResponse, undefined, \"f\");\n        try {\n            while (true) {\n                let stream;\n                try {\n                    if (__classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params.max_iterations &&\n                        __classPrivateFieldGet(this, _BetaToolRunner_iterationCount, \"f\") >= __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params.max_iterations) {\n                        break;\n                    }\n                    __classPrivateFieldSet(this, _BetaToolRunner_mutated, false, \"f\");\n                    __classPrivateFieldSet(this, _BetaToolRunner_message, undefined, \"f\");\n                    __classPrivateFieldSet(this, _BetaToolRunner_toolResponse, undefined, \"f\");\n                    __classPrivateFieldSet(this, _BetaToolRunner_iterationCount, (_a = __classPrivateFieldGet(this, _BetaToolRunner_iterationCount, \"f\"), _a++, _a), \"f\");\n                    const { max_iterations, ...params } = __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params;\n                    if (params.stream) {\n                        stream = this.client.beta.messages.stream({ ...params }, __classPrivateFieldGet(this, _BetaToolRunner_options, \"f\"));\n                        __classPrivateFieldSet(this, _BetaToolRunner_message, stream.finalMessage(), \"f\");\n                        yield stream;\n                    }\n                    else {\n                        __classPrivateFieldSet(this, _BetaToolRunner_message, this.client.beta.messages.create({ ...params, stream: false }, __classPrivateFieldGet(this, _BetaToolRunner_options, \"f\")), \"f\");\n                        yield __classPrivateFieldGet(this, _BetaToolRunner_message, \"f\");\n                    }\n                    if (!__classPrivateFieldGet(this, _BetaToolRunner_mutated, \"f\")) {\n                        const { role, content } = await __classPrivateFieldGet(this, _BetaToolRunner_message, \"f\");\n                        __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params.messages.push({ role, content });\n                    }\n                    const toolMessage = await __classPrivateFieldGet(this, _BetaToolRunner_instances, \"m\", _BetaToolRunner_generateToolResponse).call(this, __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params.messages.at(-1));\n                    if (toolMessage) {\n                        __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params.messages.push(toolMessage);\n                    }\n                    if (!toolMessage && !__classPrivateFieldGet(this, _BetaToolRunner_mutated, \"f\")) {\n                        break;\n                    }\n                }\n                finally {\n                    if (stream) {\n                        stream.abort();\n                    }\n                }\n            }\n            if (!__classPrivateFieldGet(this, _BetaToolRunner_message, \"f\")) {\n                throw new AnthropicError('ToolRunner concluded without a message from the server');\n            }\n            __classPrivateFieldGet(this, _BetaToolRunner_completion, \"f\").resolve(await __classPrivateFieldGet(this, _BetaToolRunner_message, \"f\"));\n        }\n        catch (error) {\n            __classPrivateFieldSet(this, _BetaToolRunner_consumed, false, \"f\");\n            // Silence unhandled promise errors\n            __classPrivateFieldGet(this, _BetaToolRunner_completion, \"f\").promise.catch(() => { });\n            __classPrivateFieldGet(this, _BetaToolRunner_completion, \"f\").reject(error);\n            __classPrivateFieldSet(this, _BetaToolRunner_completion, promiseWithResolvers(), \"f\");\n            throw error;\n        }\n    }\n    setMessagesParams(paramsOrMutator) {\n        if (typeof paramsOrMutator === 'function') {\n            __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params = paramsOrMutator(__classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params);\n        }\n        else {\n            __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params = paramsOrMutator;\n        }\n        __classPrivateFieldSet(this, _BetaToolRunner_mutated, true, \"f\");\n        // Invalidate cached tool response since parameters changed\n        __classPrivateFieldSet(this, _BetaToolRunner_toolResponse, undefined, \"f\");\n    }\n    /**\n     * Get the tool response for the last message from the assistant.\n     * Avoids redundant tool executions by caching results.\n     *\n     * @returns A promise that resolves to a BetaMessageParam containing tool results, or null if no tools need to be executed\n     *\n     * @example\n     * const toolResponse = await runner.generateToolResponse();\n     * if (toolResponse) {\n     *   console.log('Tool results:', toolResponse.content);\n     * }\n     */\n    async generateToolResponse() {\n        const message = (await __classPrivateFieldGet(this, _BetaToolRunner_message, \"f\")) ?? this.params.messages.at(-1);\n        if (!message) {\n            return null;\n        }\n        return __classPrivateFieldGet(this, _BetaToolRunner_instances, \"m\", _BetaToolRunner_generateToolResponse).call(this, message);\n    }\n    /**\n     * Wait for the async iterator to complete. This works even if the async iterator hasn't yet started, and\n     * will wait for an instance to start and go to completion.\n     *\n     * @returns A promise that resolves to the final BetaMessage when the iterator completes\n     *\n     * @example\n     * // Start consuming the iterator\n     * for await (const message of runner) {\n     *   console.log('Message:', message.content);\n     * }\n     *\n     * // Meanwhile, wait for completion from another part of the code\n     * const finalMessage = await runner.done();\n     * console.log('Final response:', finalMessage.content);\n     */\n    done() {\n        return __classPrivateFieldGet(this, _BetaToolRunner_completion, \"f\").promise;\n    }\n    /**\n     * Returns a promise indicating that the stream is done. Unlike .done(), this will eagerly read the stream:\n     * * If the iterator has not been consumed, consume the entire iterator and return the final message from the\n     * assistant.\n     * * If the iterator has been consumed, waits for it to complete and returns the final message.\n     *\n     * @returns A promise that resolves to the final BetaMessage from the conversation\n     * @throws {AnthropicError} If no messages were processed during the conversation\n     *\n     * @example\n     * const finalMessage = await runner.runUntilDone();\n     * console.log('Final response:', finalMessage.content);\n     */\n    async runUntilDone() {\n        // If not yet consumed, start consuming and wait for completion\n        if (!__classPrivateFieldGet(this, _BetaToolRunner_consumed, \"f\")) {\n            for await (const _ of this) {\n                // Iterator naturally populates this.#message\n            }\n        }\n        // If consumed but not completed, wait for completion\n        return this.done();\n    }\n    /**\n     * Get the current parameters being used by the ToolRunner.\n     *\n     * @returns A readonly view of the current ToolRunnerParams\n     *\n     * @example\n     * const currentParams = runner.params;\n     * console.log('Current model:', currentParams.model);\n     * console.log('Message count:', currentParams.messages.length);\n     */\n    get params() {\n        return __classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params;\n    }\n    /**\n     * Add one or more messages to the conversation history.\n     *\n     * @param messages - One or more BetaMessageParam objects to add to the conversation\n     *\n     * @example\n     * runner.pushMessages(\n     *   { role: 'user', content: 'Also, what about the weather in NYC?' }\n     * );\n     *\n     * @example\n     * // Adding multiple messages\n     * runner.pushMessages(\n     *   { role: 'user', content: 'What about NYC?' },\n     *   { role: 'user', content: 'And Boston?' }\n     * );\n     */\n    pushMessages(...messages) {\n        this.setMessagesParams((params) => ({\n            ...params,\n            messages: [...params.messages, ...messages],\n        }));\n    }\n    /**\n     * Makes the ToolRunner directly awaitable, equivalent to calling .runUntilDone()\n     * This allows using `await runner` instead of `await runner.runUntilDone()`\n     */\n    then(onfulfilled, onrejected) {\n        return this.runUntilDone().then(onfulfilled, onrejected);\n    }\n}\n_BetaToolRunner_generateToolResponse = async function _BetaToolRunner_generateToolResponse(lastMessage) {\n    if (__classPrivateFieldGet(this, _BetaToolRunner_toolResponse, \"f\") !== undefined) {\n        return __classPrivateFieldGet(this, _BetaToolRunner_toolResponse, \"f\");\n    }\n    __classPrivateFieldSet(this, _BetaToolRunner_toolResponse, generateToolResponse(__classPrivateFieldGet(this, _BetaToolRunner_state, \"f\").params, lastMessage), \"f\");\n    return __classPrivateFieldGet(this, _BetaToolRunner_toolResponse, \"f\");\n};\nasync function generateToolResponse(params, lastMessage = params.messages.at(-1)) {\n    // Only process if the last message is from the assistant and has tool use blocks\n    if (!lastMessage ||\n        lastMessage.role !== 'assistant' ||\n        !lastMessage.content ||\n        typeof lastMessage.content === 'string') {\n        return null;\n    }\n    const toolUseBlocks = lastMessage.content.filter((content) => content.type === 'tool_use');\n    if (toolUseBlocks.length === 0) {\n        return null;\n    }\n    const toolResults = await Promise.all(toolUseBlocks.map(async (toolUse) => {\n        const tool = params.tools.find((t) => t.name === toolUse.name);\n        if (!tool || !('run' in tool)) {\n            return {\n                type: 'tool_result',\n                tool_use_id: toolUse.id,\n                content: `Error: Tool '${toolUse.name}' not found`,\n                is_error: true,\n            };\n        }\n        try {\n            let input = toolUse.input;\n            if ('parse' in tool && tool.parse) {\n                input = tool.parse(input);\n            }\n            const result = await tool.run(input);\n            return {\n                type: 'tool_result',\n                tool_use_id: toolUse.id,\n                content: result,\n            };\n        }\n        catch (error) {\n            return {\n                type: 'tool_result',\n                tool_use_id: toolUse.id,\n                content: `Error: ${error instanceof Error ? error.message : String(error)}`,\n                is_error: true,\n            };\n        }\n    }));\n    return {\n        role: 'user',\n        content: toolResults,\n    };\n}\n//# sourceMappingURL=BetaToolRunner.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../../core/resource.mjs\";\nimport * as BatchesAPI from \"./batches.mjs\";\nimport { Batches, } from \"./batches.mjs\";\nimport { buildHeaders } from \"../../../internal/headers.mjs\";\nimport { BetaMessageStream } from \"../../../lib/BetaMessageStream.mjs\";\nimport { MODEL_NONSTREAMING_TOKENS } from \"../../../internal/constants.mjs\";\nimport { BetaToolRunner, } from \"../../../lib/tools/BetaToolRunner.mjs\";\nconst DEPRECATED_MODELS = {\n    'claude-1.3': 'November 6th, 2024',\n    'claude-1.3-100k': 'November 6th, 2024',\n    'claude-instant-1.1': 'November 6th, 2024',\n    'claude-instant-1.1-100k': 'November 6th, 2024',\n    'claude-instant-1.2': 'November 6th, 2024',\n    'claude-3-sonnet-20240229': 'July 21st, 2025',\n    'claude-3-opus-20240229': 'January 5th, 2026',\n    'claude-2.1': 'July 21st, 2025',\n    'claude-2.0': 'July 21st, 2025',\n    'claude-3-5-sonnet-20241022': 'October 22, 2025',\n    'claude-3-5-sonnet-20240620': 'October 22, 2025',\n};\nexport class Messages extends APIResource {\n    constructor() {\n        super(...arguments);\n        this.batches = new BatchesAPI.Batches(this._client);\n    }\n    create(params, options) {\n        const { betas, ...body } = params;\n        if (body.model in DEPRECATED_MODELS) {\n            console.warn(`The model '${body.model}' is deprecated and will reach end-of-life on ${DEPRECATED_MODELS[body.model]}\\nPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.`);\n        }\n        let timeout = this._client._options.timeout;\n        if (!body.stream && timeout == null) {\n            const maxNonstreamingTokens = MODEL_NONSTREAMING_TOKENS[body.model] ?? undefined;\n            timeout = this._client.calculateNonstreamingTimeout(body.max_tokens, maxNonstreamingTokens);\n        }\n        return this._client.post('/v1/messages?beta=true', {\n            body,\n            timeout: timeout ?? 600000,\n            ...options,\n            headers: buildHeaders([\n                { ...(betas?.toString() != null ? { 'anthropic-beta': betas?.toString() } : undefined) },\n                options?.headers,\n            ]),\n            stream: params.stream ?? false,\n        });\n    }\n    /**\n     * Create a Message stream\n     */\n    stream(body, options) {\n        return BetaMessageStream.createMessage(this, body, options);\n    }\n    /**\n     * Count the number of tokens in a Message.\n     *\n     * The Token Count API can be used to count the number of tokens in a Message,\n     * including tools, images, and documents, without creating it.\n     *\n     * Learn more about token counting in our\n     * [user guide](/en/docs/build-with-claude/token-counting)\n     *\n     * @example\n     * ```ts\n     * const betaMessageTokensCount =\n     *   await client.beta.messages.countTokens({\n     *     messages: [{ content: 'string', role: 'user' }],\n     *     model: 'claude-3-7-sonnet-latest',\n     *   });\n     * ```\n     */\n    countTokens(params, options) {\n        const { betas, ...body } = params;\n        return this._client.post('/v1/messages/count_tokens?beta=true', {\n            body,\n            ...options,\n            headers: buildHeaders([\n                { 'anthropic-beta': [...(betas ?? []), 'token-counting-2024-11-01'].toString() },\n                options?.headers,\n            ]),\n        });\n    }\n    toolRunner(body, options) {\n        return new BetaToolRunner(this._client, body, options);\n    }\n}\nexport { BetaToolRunner } from \"../../../lib/tools/BetaToolRunner.mjs\";\nMessages.Batches = Batches;\nMessages.BetaToolRunner = BetaToolRunner;\n//# sourceMappingURL=messages.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../core/resource.mjs\";\nimport * as FilesAPI from \"./files.mjs\";\nimport { Files, } from \"./files.mjs\";\nimport * as ModelsAPI from \"./models.mjs\";\nimport { Models } from \"./models.mjs\";\nimport * as MessagesAPI from \"./messages/messages.mjs\";\nimport { Messages, } from \"./messages/messages.mjs\";\nexport class Beta extends APIResource {\n    constructor() {\n        super(...arguments);\n        this.models = new ModelsAPI.Models(this._client);\n        this.messages = new MessagesAPI.Messages(this._client);\n        this.files = new FilesAPI.Files(this._client);\n    }\n}\nBeta.Models = Models;\nBeta.Messages = Messages;\nBeta.Files = Files;\n//# sourceMappingURL=beta.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../core/resource.mjs\";\nimport { buildHeaders } from \"../internal/headers.mjs\";\nexport class Completions extends APIResource {\n    create(params, options) {\n        const { betas, ...body } = params;\n        return this._client.post('/v1/complete', {\n            body,\n            timeout: this._client._options.timeout ?? 600000,\n            ...options,\n            headers: buildHeaders([\n                { ...(betas?.toString() != null ? { 'anthropic-beta': betas?.toString() } : undefined) },\n                options?.headers,\n            ]),\n            stream: params.stream ?? false,\n        });\n    }\n}\n//# sourceMappingURL=completions.mjs.map","var _MessageStream_instances, _MessageStream_currentMessageSnapshot, _MessageStream_connectedPromise, _MessageStream_resolveConnectedPromise, _MessageStream_rejectConnectedPromise, _MessageStream_endPromise, _MessageStream_resolveEndPromise, _MessageStream_rejectEndPromise, _MessageStream_listeners, _MessageStream_ended, _MessageStream_errored, _MessageStream_aborted, _MessageStream_catchingPromiseCreated, _MessageStream_response, _MessageStream_request_id, _MessageStream_getFinalMessage, _MessageStream_getFinalText, _MessageStream_handleError, _MessageStream_beginRequest, _MessageStream_addStreamEvent, _MessageStream_endRequest, _MessageStream_accumulateMessage;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"../internal/tslib.mjs\";\nimport { isAbortError } from \"../internal/errors.mjs\";\nimport { AnthropicError, APIUserAbortError } from \"../error.mjs\";\nimport { Stream } from \"../streaming.mjs\";\nimport { partialParse } from \"../_vendor/partial-json-parser/parser.mjs\";\nconst JSON_BUF_PROPERTY = '__json_buf';\nfunction tracksToolInput(content) {\n    return content.type === 'tool_use' || content.type === 'server_tool_use';\n}\nexport class MessageStream {\n    constructor() {\n        _MessageStream_instances.add(this);\n        this.messages = [];\n        this.receivedMessages = [];\n        _MessageStream_currentMessageSnapshot.set(this, void 0);\n        this.controller = new AbortController();\n        _MessageStream_connectedPromise.set(this, void 0);\n        _MessageStream_resolveConnectedPromise.set(this, () => { });\n        _MessageStream_rejectConnectedPromise.set(this, () => { });\n        _MessageStream_endPromise.set(this, void 0);\n        _MessageStream_resolveEndPromise.set(this, () => { });\n        _MessageStream_rejectEndPromise.set(this, () => { });\n        _MessageStream_listeners.set(this, {});\n        _MessageStream_ended.set(this, false);\n        _MessageStream_errored.set(this, false);\n        _MessageStream_aborted.set(this, false);\n        _MessageStream_catchingPromiseCreated.set(this, false);\n        _MessageStream_response.set(this, void 0);\n        _MessageStream_request_id.set(this, void 0);\n        _MessageStream_handleError.set(this, (error) => {\n            __classPrivateFieldSet(this, _MessageStream_errored, true, \"f\");\n            if (isAbortError(error)) {\n                error = new APIUserAbortError();\n            }\n            if (error instanceof APIUserAbortError) {\n                __classPrivateFieldSet(this, _MessageStream_aborted, true, \"f\");\n                return this._emit('abort', error);\n            }\n            if (error instanceof AnthropicError) {\n                return this._emit('error', error);\n            }\n            if (error instanceof Error) {\n                const anthropicError = new AnthropicError(error.message);\n                // @ts-ignore\n                anthropicError.cause = error;\n                return this._emit('error', anthropicError);\n            }\n            return this._emit('error', new AnthropicError(String(error)));\n        });\n        __classPrivateFieldSet(this, _MessageStream_connectedPromise, new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _MessageStream_resolveConnectedPromise, resolve, \"f\");\n            __classPrivateFieldSet(this, _MessageStream_rejectConnectedPromise, reject, \"f\");\n        }), \"f\");\n        __classPrivateFieldSet(this, _MessageStream_endPromise, new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _MessageStream_resolveEndPromise, resolve, \"f\");\n            __classPrivateFieldSet(this, _MessageStream_rejectEndPromise, reject, \"f\");\n        }), \"f\");\n        // Don't let these promises cause unhandled rejection errors.\n        // we will manually cause an unhandled rejection error later\n        // if the user hasn't registered any error listener or called\n        // any promise-returning method.\n        __classPrivateFieldGet(this, _MessageStream_connectedPromise, \"f\").catch(() => { });\n        __classPrivateFieldGet(this, _MessageStream_endPromise, \"f\").catch(() => { });\n    }\n    get response() {\n        return __classPrivateFieldGet(this, _MessageStream_response, \"f\");\n    }\n    get request_id() {\n        return __classPrivateFieldGet(this, _MessageStream_request_id, \"f\");\n    }\n    /**\n     * Returns the `MessageStream` data, the raw `Response` instance and the ID of the request,\n     * returned vie the `request-id` header which is useful for debugging requests and resporting\n     * issues to Anthropic.\n     *\n     * This is the same as the `APIPromise.withResponse()` method.\n     *\n     * This method will raise an error if you created the stream using `MessageStream.fromReadableStream`\n     * as no `Response` is available.\n     */\n    async withResponse() {\n        const response = await __classPrivateFieldGet(this, _MessageStream_connectedPromise, \"f\");\n        if (!response) {\n            throw new Error('Could not resolve a `Response` object');\n        }\n        return {\n            data: this,\n            response,\n            request_id: response.headers.get('request-id'),\n        };\n    }\n    /**\n     * Intended for use on the frontend, consuming a stream produced with\n     * `.toReadableStream()` on the backend.\n     *\n     * Note that messages sent to the model do not appear in `.on('message')`\n     * in this context.\n     */\n    static fromReadableStream(stream) {\n        const runner = new MessageStream();\n        runner._run(() => runner._fromReadableStream(stream));\n        return runner;\n    }\n    static createMessage(messages, params, options) {\n        const runner = new MessageStream();\n        for (const message of params.messages) {\n            runner._addMessageParam(message);\n        }\n        runner._run(() => runner._createMessage(messages, { ...params, stream: true }, { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } }));\n        return runner;\n    }\n    _run(executor) {\n        executor().then(() => {\n            this._emitFinal();\n            this._emit('end');\n        }, __classPrivateFieldGet(this, _MessageStream_handleError, \"f\"));\n    }\n    _addMessageParam(message) {\n        this.messages.push(message);\n    }\n    _addMessage(message, emit = true) {\n        this.receivedMessages.push(message);\n        if (emit) {\n            this._emit('message', message);\n        }\n    }\n    async _createMessage(messages, params, options) {\n        const signal = options?.signal;\n        let abortHandler;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            abortHandler = this.controller.abort.bind(this.controller);\n            signal.addEventListener('abort', abortHandler);\n        }\n        try {\n            __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_beginRequest).call(this);\n            const { response, data: stream } = await messages\n                .create({ ...params, stream: true }, { ...options, signal: this.controller.signal })\n                .withResponse();\n            this._connected(response);\n            for await (const event of stream) {\n                __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_addStreamEvent).call(this, event);\n            }\n            if (stream.controller.signal?.aborted) {\n                throw new APIUserAbortError();\n            }\n            __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_endRequest).call(this);\n        }\n        finally {\n            if (signal && abortHandler) {\n                signal.removeEventListener('abort', abortHandler);\n            }\n        }\n    }\n    _connected(response) {\n        if (this.ended)\n            return;\n        __classPrivateFieldSet(this, _MessageStream_response, response, \"f\");\n        __classPrivateFieldSet(this, _MessageStream_request_id, response?.headers.get('request-id'), \"f\");\n        __classPrivateFieldGet(this, _MessageStream_resolveConnectedPromise, \"f\").call(this, response);\n        this._emit('connect');\n    }\n    get ended() {\n        return __classPrivateFieldGet(this, _MessageStream_ended, \"f\");\n    }\n    get errored() {\n        return __classPrivateFieldGet(this, _MessageStream_errored, \"f\");\n    }\n    get aborted() {\n        return __classPrivateFieldGet(this, _MessageStream_aborted, \"f\");\n    }\n    abort() {\n        this.controller.abort();\n    }\n    /**\n     * Adds the listener function to the end of the listeners array for the event.\n     * No checks are made to see if the listener has already been added. Multiple calls passing\n     * the same combination of event and listener will result in the listener being added, and\n     * called, multiple times.\n     * @returns this MessageStream, so that calls can be chained\n     */\n    on(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _MessageStream_listeners, \"f\")[event] || (__classPrivateFieldGet(this, _MessageStream_listeners, \"f\")[event] = []);\n        listeners.push({ listener });\n        return this;\n    }\n    /**\n     * Removes the specified listener from the listener array for the event.\n     * off() will remove, at most, one instance of a listener from the listener array. If any single\n     * listener has been added multiple times to the listener array for the specified event, then\n     * off() must be called multiple times to remove each instance.\n     * @returns this MessageStream, so that calls can be chained\n     */\n    off(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _MessageStream_listeners, \"f\")[event];\n        if (!listeners)\n            return this;\n        const index = listeners.findIndex((l) => l.listener === listener);\n        if (index >= 0)\n            listeners.splice(index, 1);\n        return this;\n    }\n    /**\n     * Adds a one-time listener function for the event. The next time the event is triggered,\n     * this listener is removed and then invoked.\n     * @returns this MessageStream, so that calls can be chained\n     */\n    once(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _MessageStream_listeners, \"f\")[event] || (__classPrivateFieldGet(this, _MessageStream_listeners, \"f\")[event] = []);\n        listeners.push({ listener, once: true });\n        return this;\n    }\n    /**\n     * This is similar to `.once()`, but returns a Promise that resolves the next time\n     * the event is triggered, instead of calling a listener callback.\n     * @returns a Promise that resolves the next time given event is triggered,\n     * or rejects if an error is emitted.  (If you request the 'error' event,\n     * returns a promise that resolves with the error).\n     *\n     * Example:\n     *\n     *   const message = await stream.emitted('message') // rejects if the stream errors\n     */\n    emitted(event) {\n        return new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _MessageStream_catchingPromiseCreated, true, \"f\");\n            if (event !== 'error')\n                this.once('error', reject);\n            this.once(event, resolve);\n        });\n    }\n    async done() {\n        __classPrivateFieldSet(this, _MessageStream_catchingPromiseCreated, true, \"f\");\n        await __classPrivateFieldGet(this, _MessageStream_endPromise, \"f\");\n    }\n    get currentMessage() {\n        return __classPrivateFieldGet(this, _MessageStream_currentMessageSnapshot, \"f\");\n    }\n    /**\n     * @returns a promise that resolves with the the final assistant Message response,\n     * or rejects if an error occurred or the stream ended prematurely without producing a Message.\n     */\n    async finalMessage() {\n        await this.done();\n        return __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_getFinalMessage).call(this);\n    }\n    /**\n     * @returns a promise that resolves with the the final assistant Message's text response, concatenated\n     * together if there are more than one text blocks.\n     * Rejects if an error occurred or the stream ended prematurely without producing a Message.\n     */\n    async finalText() {\n        await this.done();\n        return __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_getFinalText).call(this);\n    }\n    _emit(event, ...args) {\n        // make sure we don't emit any MessageStreamEvents after end\n        if (__classPrivateFieldGet(this, _MessageStream_ended, \"f\"))\n            return;\n        if (event === 'end') {\n            __classPrivateFieldSet(this, _MessageStream_ended, true, \"f\");\n            __classPrivateFieldGet(this, _MessageStream_resolveEndPromise, \"f\").call(this);\n        }\n        const listeners = __classPrivateFieldGet(this, _MessageStream_listeners, \"f\")[event];\n        if (listeners) {\n            __classPrivateFieldGet(this, _MessageStream_listeners, \"f\")[event] = listeners.filter((l) => !l.once);\n            listeners.forEach(({ listener }) => listener(...args));\n        }\n        if (event === 'abort') {\n            const error = args[0];\n            if (!__classPrivateFieldGet(this, _MessageStream_catchingPromiseCreated, \"f\") && !listeners?.length) {\n                Promise.reject(error);\n            }\n            __classPrivateFieldGet(this, _MessageStream_rejectConnectedPromise, \"f\").call(this, error);\n            __classPrivateFieldGet(this, _MessageStream_rejectEndPromise, \"f\").call(this, error);\n            this._emit('end');\n            return;\n        }\n        if (event === 'error') {\n            // NOTE: _emit('error', error) should only be called from #handleError().\n            const error = args[0];\n            if (!__classPrivateFieldGet(this, _MessageStream_catchingPromiseCreated, \"f\") && !listeners?.length) {\n                // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n                // If you are seeing stack traces here, make sure to handle errors via either:\n                // - runner.on('error', () => ...)\n                // - await runner.done()\n                // - await runner.final...()\n                // - etc.\n                Promise.reject(error);\n            }\n            __classPrivateFieldGet(this, _MessageStream_rejectConnectedPromise, \"f\").call(this, error);\n            __classPrivateFieldGet(this, _MessageStream_rejectEndPromise, \"f\").call(this, error);\n            this._emit('end');\n        }\n    }\n    _emitFinal() {\n        const finalMessage = this.receivedMessages.at(-1);\n        if (finalMessage) {\n            this._emit('finalMessage', __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_getFinalMessage).call(this));\n        }\n    }\n    async _fromReadableStream(readableStream, options) {\n        const signal = options?.signal;\n        let abortHandler;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            abortHandler = this.controller.abort.bind(this.controller);\n            signal.addEventListener('abort', abortHandler);\n        }\n        try {\n            __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_beginRequest).call(this);\n            this._connected(null);\n            const stream = Stream.fromReadableStream(readableStream, this.controller);\n            for await (const event of stream) {\n                __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_addStreamEvent).call(this, event);\n            }\n            if (stream.controller.signal?.aborted) {\n                throw new APIUserAbortError();\n            }\n            __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_endRequest).call(this);\n        }\n        finally {\n            if (signal && abortHandler) {\n                signal.removeEventListener('abort', abortHandler);\n            }\n        }\n    }\n    [(_MessageStream_currentMessageSnapshot = new WeakMap(), _MessageStream_connectedPromise = new WeakMap(), _MessageStream_resolveConnectedPromise = new WeakMap(), _MessageStream_rejectConnectedPromise = new WeakMap(), _MessageStream_endPromise = new WeakMap(), _MessageStream_resolveEndPromise = new WeakMap(), _MessageStream_rejectEndPromise = new WeakMap(), _MessageStream_listeners = new WeakMap(), _MessageStream_ended = new WeakMap(), _MessageStream_errored = new WeakMap(), _MessageStream_aborted = new WeakMap(), _MessageStream_catchingPromiseCreated = new WeakMap(), _MessageStream_response = new WeakMap(), _MessageStream_request_id = new WeakMap(), _MessageStream_handleError = new WeakMap(), _MessageStream_instances = new WeakSet(), _MessageStream_getFinalMessage = function _MessageStream_getFinalMessage() {\n        if (this.receivedMessages.length === 0) {\n            throw new AnthropicError('stream ended without producing a Message with role=assistant');\n        }\n        return this.receivedMessages.at(-1);\n    }, _MessageStream_getFinalText = function _MessageStream_getFinalText() {\n        if (this.receivedMessages.length === 0) {\n            throw new AnthropicError('stream ended without producing a Message with role=assistant');\n        }\n        const textBlocks = this.receivedMessages\n            .at(-1)\n            .content.filter((block) => block.type === 'text')\n            .map((block) => block.text);\n        if (textBlocks.length === 0) {\n            throw new AnthropicError('stream ended without producing a content block with type=text');\n        }\n        return textBlocks.join(' ');\n    }, _MessageStream_beginRequest = function _MessageStream_beginRequest() {\n        if (this.ended)\n            return;\n        __classPrivateFieldSet(this, _MessageStream_currentMessageSnapshot, undefined, \"f\");\n    }, _MessageStream_addStreamEvent = function _MessageStream_addStreamEvent(event) {\n        if (this.ended)\n            return;\n        const messageSnapshot = __classPrivateFieldGet(this, _MessageStream_instances, \"m\", _MessageStream_accumulateMessage).call(this, event);\n        this._emit('streamEvent', event, messageSnapshot);\n        switch (event.type) {\n            case 'content_block_delta': {\n                const content = messageSnapshot.content.at(-1);\n                switch (event.delta.type) {\n                    case 'text_delta': {\n                        if (content.type === 'text') {\n                            this._emit('text', event.delta.text, content.text || '');\n                        }\n                        break;\n                    }\n                    case 'citations_delta': {\n                        if (content.type === 'text') {\n                            this._emit('citation', event.delta.citation, content.citations ?? []);\n                        }\n                        break;\n                    }\n                    case 'input_json_delta': {\n                        if (tracksToolInput(content) && content.input) {\n                            this._emit('inputJson', event.delta.partial_json, content.input);\n                        }\n                        break;\n                    }\n                    case 'thinking_delta': {\n                        if (content.type === 'thinking') {\n                            this._emit('thinking', event.delta.thinking, content.thinking);\n                        }\n                        break;\n                    }\n                    case 'signature_delta': {\n                        if (content.type === 'thinking') {\n                            this._emit('signature', content.signature);\n                        }\n                        break;\n                    }\n                    default:\n                        checkNever(event.delta);\n                }\n                break;\n            }\n            case 'message_stop': {\n                this._addMessageParam(messageSnapshot);\n                this._addMessage(messageSnapshot, true);\n                break;\n            }\n            case 'content_block_stop': {\n                this._emit('contentBlock', messageSnapshot.content.at(-1));\n                break;\n            }\n            case 'message_start': {\n                __classPrivateFieldSet(this, _MessageStream_currentMessageSnapshot, messageSnapshot, \"f\");\n                break;\n            }\n            case 'content_block_start':\n            case 'message_delta':\n                break;\n        }\n    }, _MessageStream_endRequest = function _MessageStream_endRequest() {\n        if (this.ended) {\n            throw new AnthropicError(`stream has ended, this shouldn't happen`);\n        }\n        const snapshot = __classPrivateFieldGet(this, _MessageStream_currentMessageSnapshot, \"f\");\n        if (!snapshot) {\n            throw new AnthropicError(`request ended without sending any chunks`);\n        }\n        __classPrivateFieldSet(this, _MessageStream_currentMessageSnapshot, undefined, \"f\");\n        return snapshot;\n    }, _MessageStream_accumulateMessage = function _MessageStream_accumulateMessage(event) {\n        let snapshot = __classPrivateFieldGet(this, _MessageStream_currentMessageSnapshot, \"f\");\n        if (event.type === 'message_start') {\n            if (snapshot) {\n                throw new AnthropicError(`Unexpected event order, got ${event.type} before receiving \"message_stop\"`);\n            }\n            return event.message;\n        }\n        if (!snapshot) {\n            throw new AnthropicError(`Unexpected event order, got ${event.type} before \"message_start\"`);\n        }\n        switch (event.type) {\n            case 'message_stop':\n                return snapshot;\n            case 'message_delta':\n                snapshot.stop_reason = event.delta.stop_reason;\n                snapshot.stop_sequence = event.delta.stop_sequence;\n                snapshot.usage.output_tokens = event.usage.output_tokens;\n                // Update other usage fields if they exist in the event\n                if (event.usage.input_tokens != null) {\n                    snapshot.usage.input_tokens = event.usage.input_tokens;\n                }\n                if (event.usage.cache_creation_input_tokens != null) {\n                    snapshot.usage.cache_creation_input_tokens = event.usage.cache_creation_input_tokens;\n                }\n                if (event.usage.cache_read_input_tokens != null) {\n                    snapshot.usage.cache_read_input_tokens = event.usage.cache_read_input_tokens;\n                }\n                if (event.usage.server_tool_use != null) {\n                    snapshot.usage.server_tool_use = event.usage.server_tool_use;\n                }\n                return snapshot;\n            case 'content_block_start':\n                snapshot.content.push({ ...event.content_block });\n                return snapshot;\n            case 'content_block_delta': {\n                const snapshotContent = snapshot.content.at(event.index);\n                switch (event.delta.type) {\n                    case 'text_delta': {\n                        if (snapshotContent?.type === 'text') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                text: (snapshotContent.text || '') + event.delta.text,\n                            };\n                        }\n                        break;\n                    }\n                    case 'citations_delta': {\n                        if (snapshotContent?.type === 'text') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                citations: [...(snapshotContent.citations ?? []), event.delta.citation],\n                            };\n                        }\n                        break;\n                    }\n                    case 'input_json_delta': {\n                        if (snapshotContent && tracksToolInput(snapshotContent)) {\n                            // we need to keep track of the raw JSON string as well so that we can\n                            // re-parse it for each delta, for now we just store it as an untyped\n                            // non-enumerable property on the snapshot\n                            let jsonBuf = snapshotContent[JSON_BUF_PROPERTY] || '';\n                            jsonBuf += event.delta.partial_json;\n                            const newContent = { ...snapshotContent };\n                            Object.defineProperty(newContent, JSON_BUF_PROPERTY, {\n                                value: jsonBuf,\n                                enumerable: false,\n                                writable: true,\n                            });\n                            if (jsonBuf) {\n                                newContent.input = partialParse(jsonBuf);\n                            }\n                            snapshot.content[event.index] = newContent;\n                        }\n                        break;\n                    }\n                    case 'thinking_delta': {\n                        if (snapshotContent?.type === 'thinking') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                thinking: snapshotContent.thinking + event.delta.thinking,\n                            };\n                        }\n                        break;\n                    }\n                    case 'signature_delta': {\n                        if (snapshotContent?.type === 'thinking') {\n                            snapshot.content[event.index] = {\n                                ...snapshotContent,\n                                signature: event.delta.signature,\n                            };\n                        }\n                        break;\n                    }\n                    default:\n                        checkNever(event.delta);\n                }\n                return snapshot;\n            }\n            case 'content_block_stop':\n                return snapshot;\n        }\n    }, Symbol.asyncIterator)]() {\n        const pushQueue = [];\n        const readQueue = [];\n        let done = false;\n        this.on('streamEvent', (event) => {\n            const reader = readQueue.shift();\n            if (reader) {\n                reader.resolve(event);\n            }\n            else {\n                pushQueue.push(event);\n            }\n        });\n        this.on('end', () => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.resolve(undefined);\n            }\n            readQueue.length = 0;\n        });\n        this.on('abort', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        this.on('error', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        return {\n            next: async () => {\n                if (!pushQueue.length) {\n                    if (done) {\n                        return { value: undefined, done: true };\n                    }\n                    return new Promise((resolve, reject) => readQueue.push({ resolve, reject })).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n                }\n                const chunk = pushQueue.shift();\n                return { value: chunk, done: false };\n            },\n            return: async () => {\n                this.abort();\n                return { value: undefined, done: true };\n            },\n        };\n    }\n    toReadableStream() {\n        const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n        return stream.toReadableStream();\n    }\n}\n// used to ensure exhaustive case matching without throwing a runtime error\nfunction checkNever(x) { }\n//# sourceMappingURL=MessageStream.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../core/resource.mjs\";\nimport { Page } from \"../../core/pagination.mjs\";\nimport { buildHeaders } from \"../../internal/headers.mjs\";\nimport { JSONLDecoder } from \"../../internal/decoders/jsonl.mjs\";\nimport { AnthropicError } from \"../../error.mjs\";\nimport { path } from \"../../internal/utils/path.mjs\";\nexport class Batches extends APIResource {\n    /**\n     * Send a batch of Message creation requests.\n     *\n     * The Message Batches API can be used to process multiple Messages API requests at\n     * once. Once a Message Batch is created, it begins processing immediately. Batches\n     * can take up to 24 hours to complete.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const messageBatch = await client.messages.batches.create({\n     *   requests: [\n     *     {\n     *       custom_id: 'my-custom-id-1',\n     *       params: {\n     *         max_tokens: 1024,\n     *         messages: [\n     *           { content: 'Hello, world', role: 'user' },\n     *         ],\n     *         model: 'claude-sonnet-4-5-20250929',\n     *       },\n     *     },\n     *   ],\n     * });\n     * ```\n     */\n    create(body, options) {\n        return this._client.post('/v1/messages/batches', { body, ...options });\n    }\n    /**\n     * This endpoint is idempotent and can be used to poll for Message Batch\n     * completion. To access the results of a Message Batch, make a request to the\n     * `results_url` field in the response.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const messageBatch = await client.messages.batches.retrieve(\n     *   'message_batch_id',\n     * );\n     * ```\n     */\n    retrieve(messageBatchID, options) {\n        return this._client.get(path `/v1/messages/batches/${messageBatchID}`, options);\n    }\n    /**\n     * List all Message Batches within a Workspace. Most recently created batches are\n     * returned first.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * // Automatically fetches more pages as needed.\n     * for await (const messageBatch of client.messages.batches.list()) {\n     *   // ...\n     * }\n     * ```\n     */\n    list(query = {}, options) {\n        return this._client.getAPIList('/v1/messages/batches', (Page), { query, ...options });\n    }\n    /**\n     * Delete a Message Batch.\n     *\n     * Message Batches can only be deleted once they've finished processing. If you'd\n     * like to delete an in-progress batch, you must first cancel it.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const deletedMessageBatch =\n     *   await client.messages.batches.delete('message_batch_id');\n     * ```\n     */\n    delete(messageBatchID, options) {\n        return this._client.delete(path `/v1/messages/batches/${messageBatchID}`, options);\n    }\n    /**\n     * Batches may be canceled any time before processing ends. Once cancellation is\n     * initiated, the batch enters a `canceling` state, at which time the system may\n     * complete any in-progress, non-interruptible requests before finalizing\n     * cancellation.\n     *\n     * The number of canceled requests is specified in `request_counts`. To determine\n     * which requests were canceled, check the individual results within the batch.\n     * Note that cancellation may not result in any canceled requests if they were\n     * non-interruptible.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const messageBatch = await client.messages.batches.cancel(\n     *   'message_batch_id',\n     * );\n     * ```\n     */\n    cancel(messageBatchID, options) {\n        return this._client.post(path `/v1/messages/batches/${messageBatchID}/cancel`, options);\n    }\n    /**\n     * Streams the results of a Message Batch as a `.jsonl` file.\n     *\n     * Each line in the file is a JSON object containing the result of a single request\n     * in the Message Batch. Results are not guaranteed to be in the same order as\n     * requests. Use the `custom_id` field to match results to requests.\n     *\n     * Learn more about the Message Batches API in our\n     * [user guide](/en/docs/build-with-claude/batch-processing)\n     *\n     * @example\n     * ```ts\n     * const messageBatchIndividualResponse =\n     *   await client.messages.batches.results('message_batch_id');\n     * ```\n     */\n    async results(messageBatchID, options) {\n        const batch = await this.retrieve(messageBatchID);\n        if (!batch.results_url) {\n            throw new AnthropicError(`No batch \\`results_url\\`; Has it finished processing? ${batch.processing_status} - ${batch.id}`);\n        }\n        return this._client\n            .get(batch.results_url, {\n            ...options,\n            headers: buildHeaders([{ Accept: 'application/binary' }, options?.headers]),\n            stream: true,\n            __binaryResponse: true,\n        })\n            ._thenUnwrap((_, props) => JSONLDecoder.fromResponse(props.response, props.controller));\n    }\n}\n//# sourceMappingURL=batches.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../core/resource.mjs\";\nimport { MessageStream } from \"../../lib/MessageStream.mjs\";\nimport * as BatchesAPI from \"./batches.mjs\";\nimport { Batches, } from \"./batches.mjs\";\nimport { MODEL_NONSTREAMING_TOKENS } from \"../../internal/constants.mjs\";\nexport class Messages extends APIResource {\n    constructor() {\n        super(...arguments);\n        this.batches = new BatchesAPI.Batches(this._client);\n    }\n    create(body, options) {\n        if (body.model in DEPRECATED_MODELS) {\n            console.warn(`The model '${body.model}' is deprecated and will reach end-of-life on ${DEPRECATED_MODELS[body.model]}\\nPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.`);\n        }\n        let timeout = this._client._options.timeout;\n        if (!body.stream && timeout == null) {\n            const maxNonstreamingTokens = MODEL_NONSTREAMING_TOKENS[body.model] ?? undefined;\n            timeout = this._client.calculateNonstreamingTimeout(body.max_tokens, maxNonstreamingTokens);\n        }\n        return this._client.post('/v1/messages', {\n            body,\n            timeout: timeout ?? 600000,\n            ...options,\n            stream: body.stream ?? false,\n        });\n    }\n    /**\n     * Create a Message stream\n     */\n    stream(body, options) {\n        return MessageStream.createMessage(this, body, options);\n    }\n    /**\n     * Count the number of tokens in a Message.\n     *\n     * The Token Count API can be used to count the number of tokens in a Message,\n     * including tools, images, and documents, without creating it.\n     *\n     * Learn more about token counting in our\n     * [user guide](/en/docs/build-with-claude/token-counting)\n     *\n     * @example\n     * ```ts\n     * const messageTokensCount =\n     *   await client.messages.countTokens({\n     *     messages: [{ content: 'string', role: 'user' }],\n     *     model: 'claude-3-7-sonnet-latest',\n     *   });\n     * ```\n     */\n    countTokens(body, options) {\n        return this._client.post('/v1/messages/count_tokens', { body, ...options });\n    }\n}\nconst DEPRECATED_MODELS = {\n    'claude-1.3': 'November 6th, 2024',\n    'claude-1.3-100k': 'November 6th, 2024',\n    'claude-instant-1.1': 'November 6th, 2024',\n    'claude-instant-1.1-100k': 'November 6th, 2024',\n    'claude-instant-1.2': 'November 6th, 2024',\n    'claude-3-sonnet-20240229': 'July 21st, 2025',\n    'claude-3-opus-20240229': 'January 5th, 2026',\n    'claude-2.1': 'July 21st, 2025',\n    'claude-2.0': 'July 21st, 2025',\n    'claude-3-5-sonnet-20241022': 'October 22, 2025',\n    'claude-3-5-sonnet-20240620': 'October 22, 2025',\n};\nMessages.Batches = Batches;\n//# sourceMappingURL=messages.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../core/resource.mjs\";\nimport { Page } from \"../core/pagination.mjs\";\nimport { buildHeaders } from \"../internal/headers.mjs\";\nimport { path } from \"../internal/utils/path.mjs\";\nexport class Models extends APIResource {\n    /**\n     * Get a specific model.\n     *\n     * The Models API response can be used to determine information about a specific\n     * model or resolve a model alias to a model ID.\n     */\n    retrieve(modelID, params = {}, options) {\n        const { betas } = params ?? {};\n        return this._client.get(path `/v1/models/${modelID}`, {\n            ...options,\n            headers: buildHeaders([\n                { ...(betas?.toString() != null ? { 'anthropic-beta': betas?.toString() } : undefined) },\n                options?.headers,\n            ]),\n        });\n    }\n    /**\n     * List available models.\n     *\n     * The Models API response can be used to determine which models are available for\n     * use in the API. More recently released models are listed first.\n     */\n    list(params = {}, options) {\n        const { betas, ...query } = params ?? {};\n        return this._client.getAPIList('/v1/models', (Page), {\n            query,\n            ...options,\n            headers: buildHeaders([\n                { ...(betas?.toString() != null ? { 'anthropic-beta': betas?.toString() } : undefined) },\n                options?.headers,\n            ]),\n        });\n    }\n}\n//# sourceMappingURL=models.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nexport * from \"./shared.mjs\";\nexport { Beta, } from \"./beta/beta.mjs\";\nexport { Completions, } from \"./completions.mjs\";\nexport { Messages, } from \"./messages/messages.mjs\";\nexport { Models, } from \"./models.mjs\";\n//# sourceMappingURL=index.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nexport const readEnv = (env) => {\n    if (typeof globalThis.process !== 'undefined') {\n        return globalThis.process.env?.[env]?.trim() ?? undefined;\n    }\n    if (typeof globalThis.Deno !== 'undefined') {\n        return globalThis.Deno.env?.get?.(env)?.trim();\n    }\n    return undefined;\n};\n//# sourceMappingURL=env.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nvar _BaseAnthropic_instances, _a, _BaseAnthropic_encoder, _BaseAnthropic_baseURLOverridden;\nimport { __classPrivateFieldGet, __classPrivateFieldSet } from \"./internal/tslib.mjs\";\nimport { uuid4 } from \"./internal/utils/uuid.mjs\";\nimport { validatePositiveInteger, isAbsoluteURL, safeJSON } from \"./internal/utils/values.mjs\";\nimport { sleep } from \"./internal/utils/sleep.mjs\";\nimport { castToError, isAbortError } from \"./internal/errors.mjs\";\nimport { getPlatformHeaders } from \"./internal/detect-platform.mjs\";\nimport * as Shims from \"./internal/shims.mjs\";\nimport * as Opts from \"./internal/request-options.mjs\";\nimport { VERSION } from \"./version.mjs\";\nimport * as Errors from \"./core/error.mjs\";\nimport * as Pagination from \"./core/pagination.mjs\";\nimport * as Uploads from \"./core/uploads.mjs\";\nimport * as API from \"./resources/index.mjs\";\nimport { APIPromise } from \"./core/api-promise.mjs\";\nimport { Completions, } from \"./resources/completions.mjs\";\nimport { Models } from \"./resources/models.mjs\";\nimport { Beta, } from \"./resources/beta/beta.mjs\";\nimport { Messages, } from \"./resources/messages/messages.mjs\";\nimport { isRunningInBrowser } from \"./internal/detect-platform.mjs\";\nimport { buildHeaders } from \"./internal/headers.mjs\";\nimport { readEnv } from \"./internal/utils/env.mjs\";\nimport { formatRequestDetails, loggerFor, parseLogLevel, } from \"./internal/utils/log.mjs\";\nimport { isEmptyObj } from \"./internal/utils/values.mjs\";\nexport const HUMAN_PROMPT = '\\\\n\\\\nHuman:';\nexport const AI_PROMPT = '\\\\n\\\\nAssistant:';\n/**\n * Base class for Anthropic API clients.\n */\nexport class BaseAnthropic {\n    /**\n     * API Client for interfacing with the Anthropic API.\n     *\n     * @param {string | null | undefined} [opts.apiKey=process.env['ANTHROPIC_API_KEY'] ?? null]\n     * @param {string | null | undefined} [opts.authToken=process.env['ANTHROPIC_AUTH_TOKEN'] ?? null]\n     * @param {string} [opts.baseURL=process.env['ANTHROPIC_BASE_URL'] ?? https://api.anthropic.com] - Override the default base URL for the API.\n     * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n     * @param {MergedRequestInit} [opts.fetchOptions] - Additional `RequestInit` options to be passed to `fetch` calls.\n     * @param {Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n     * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n     * @param {HeadersLike} opts.defaultHeaders - Default headers to include with every request to the API.\n     * @param {Record<string, string | undefined>} opts.defaultQuery - Default query parameters to include with every request to the API.\n     * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n     */\n    constructor({ baseURL = readEnv('ANTHROPIC_BASE_URL'), apiKey = readEnv('ANTHROPIC_API_KEY') ?? null, authToken = readEnv('ANTHROPIC_AUTH_TOKEN') ?? null, ...opts } = {}) {\n        _BaseAnthropic_instances.add(this);\n        _BaseAnthropic_encoder.set(this, void 0);\n        const options = {\n            apiKey,\n            authToken,\n            ...opts,\n            baseURL: baseURL || `https://api.anthropic.com`,\n        };\n        if (!options.dangerouslyAllowBrowser && isRunningInBrowser()) {\n            throw new Errors.AnthropicError(\"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew Anthropic({ apiKey, dangerouslyAllowBrowser: true });\\n\");\n        }\n        this.baseURL = options.baseURL;\n        this.timeout = options.timeout ?? _a.DEFAULT_TIMEOUT /* 10 minutes */;\n        this.logger = options.logger ?? console;\n        const defaultLogLevel = 'warn';\n        // Set default logLevel early so that we can log a warning in parseLogLevel.\n        this.logLevel = defaultLogLevel;\n        this.logLevel =\n            parseLogLevel(options.logLevel, 'ClientOptions.logLevel', this) ??\n                parseLogLevel(readEnv('ANTHROPIC_LOG'), \"process.env['ANTHROPIC_LOG']\", this) ??\n                defaultLogLevel;\n        this.fetchOptions = options.fetchOptions;\n        this.maxRetries = options.maxRetries ?? 2;\n        this.fetch = options.fetch ?? Shims.getDefaultFetch();\n        __classPrivateFieldSet(this, _BaseAnthropic_encoder, Opts.FallbackEncoder, \"f\");\n        this._options = options;\n        this.apiKey = apiKey;\n        this.authToken = authToken;\n    }\n    /**\n     * Create a new client instance re-using the same options given to the current client with optional overriding.\n     */\n    withOptions(options) {\n        const client = new this.constructor({\n            ...this._options,\n            baseURL: this.baseURL,\n            maxRetries: this.maxRetries,\n            timeout: this.timeout,\n            logger: this.logger,\n            logLevel: this.logLevel,\n            fetch: this.fetch,\n            fetchOptions: this.fetchOptions,\n            apiKey: this.apiKey,\n            authToken: this.authToken,\n            ...options,\n        });\n        return client;\n    }\n    defaultQuery() {\n        return this._options.defaultQuery;\n    }\n    validateHeaders({ values, nulls }) {\n        if (this.apiKey && values.get('x-api-key')) {\n            return;\n        }\n        if (nulls.has('x-api-key')) {\n            return;\n        }\n        if (this.authToken && values.get('authorization')) {\n            return;\n        }\n        if (nulls.has('authorization')) {\n            return;\n        }\n        throw new Error('Could not resolve authentication method. Expected either apiKey or authToken to be set. Or for one of the \"X-Api-Key\" or \"Authorization\" headers to be explicitly omitted');\n    }\n    async authHeaders(opts) {\n        return buildHeaders([await this.apiKeyAuth(opts), await this.bearerAuth(opts)]);\n    }\n    async apiKeyAuth(opts) {\n        if (this.apiKey == null) {\n            return undefined;\n        }\n        return buildHeaders([{ 'X-Api-Key': this.apiKey }]);\n    }\n    async bearerAuth(opts) {\n        if (this.authToken == null) {\n            return undefined;\n        }\n        return buildHeaders([{ Authorization: `Bearer ${this.authToken}` }]);\n    }\n    /**\n     * Basic re-implementation of `qs.stringify` for primitive types.\n     */\n    stringifyQuery(query) {\n        return Object.entries(query)\n            .filter(([_, value]) => typeof value !== 'undefined')\n            .map(([key, value]) => {\n            if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n                return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;\n            }\n            if (value === null) {\n                return `${encodeURIComponent(key)}=`;\n            }\n            throw new Errors.AnthropicError(`Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`);\n        })\n            .join('&');\n    }\n    getUserAgent() {\n        return `${this.constructor.name}/JS ${VERSION}`;\n    }\n    defaultIdempotencyKey() {\n        return `stainless-node-retry-${uuid4()}`;\n    }\n    makeStatusError(status, error, message, headers) {\n        return Errors.APIError.generate(status, error, message, headers);\n    }\n    buildURL(path, query, defaultBaseURL) {\n        const baseURL = (!__classPrivateFieldGet(this, _BaseAnthropic_instances, \"m\", _BaseAnthropic_baseURLOverridden).call(this) && defaultBaseURL) || this.baseURL;\n        const url = isAbsoluteURL(path) ?\n            new URL(path)\n            : new URL(baseURL + (baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n        const defaultQuery = this.defaultQuery();\n        if (!isEmptyObj(defaultQuery)) {\n            query = { ...defaultQuery, ...query };\n        }\n        if (typeof query === 'object' && query && !Array.isArray(query)) {\n            url.search = this.stringifyQuery(query);\n        }\n        return url.toString();\n    }\n    _calculateNonstreamingTimeout(maxTokens) {\n        const defaultTimeout = 10 * 60;\n        const expectedTimeout = (60 * 60 * maxTokens) / 128000;\n        if (expectedTimeout > defaultTimeout) {\n            throw new Errors.AnthropicError('Streaming is required for operations that may take longer than 10 minutes. ' +\n                'See https://github.com/anthropics/anthropic-sdk-typescript#streaming-responses for more details');\n        }\n        return defaultTimeout * 1000;\n    }\n    /**\n     * Used as a callback for mutating the given `FinalRequestOptions` object.\n     */\n    async prepareOptions(options) { }\n    /**\n     * Used as a callback for mutating the given `RequestInit` object.\n     *\n     * This is useful for cases where you want to add certain headers based off of\n     * the request properties, e.g. `method` or `url`.\n     */\n    async prepareRequest(request, { url, options }) { }\n    get(path, opts) {\n        return this.methodRequest('get', path, opts);\n    }\n    post(path, opts) {\n        return this.methodRequest('post', path, opts);\n    }\n    patch(path, opts) {\n        return this.methodRequest('patch', path, opts);\n    }\n    put(path, opts) {\n        return this.methodRequest('put', path, opts);\n    }\n    delete(path, opts) {\n        return this.methodRequest('delete', path, opts);\n    }\n    methodRequest(method, path, opts) {\n        return this.request(Promise.resolve(opts).then((opts) => {\n            return { method, path, ...opts };\n        }));\n    }\n    request(options, remainingRetries = null) {\n        return new APIPromise(this, this.makeRequest(options, remainingRetries, undefined));\n    }\n    async makeRequest(optionsInput, retriesRemaining, retryOfRequestLogID) {\n        const options = await optionsInput;\n        const maxRetries = options.maxRetries ?? this.maxRetries;\n        if (retriesRemaining == null) {\n            retriesRemaining = maxRetries;\n        }\n        await this.prepareOptions(options);\n        const { req, url, timeout } = await this.buildRequest(options, {\n            retryCount: maxRetries - retriesRemaining,\n        });\n        await this.prepareRequest(req, { url, options });\n        /** Not an API request ID, just for correlating local log entries. */\n        const requestLogID = 'log_' + ((Math.random() * (1 << 24)) | 0).toString(16).padStart(6, '0');\n        const retryLogStr = retryOfRequestLogID === undefined ? '' : `, retryOf: ${retryOfRequestLogID}`;\n        const startTime = Date.now();\n        loggerFor(this).debug(`[${requestLogID}] sending request`, formatRequestDetails({\n            retryOfRequestLogID,\n            method: options.method,\n            url,\n            options,\n            headers: req.headers,\n        }));\n        if (options.signal?.aborted) {\n            throw new Errors.APIUserAbortError();\n        }\n        const controller = new AbortController();\n        const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n        const headersTime = Date.now();\n        if (response instanceof globalThis.Error) {\n            const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n            if (options.signal?.aborted) {\n                throw new Errors.APIUserAbortError();\n            }\n            // detect native connection timeout errors\n            // deno throws \"TypeError: error sending request for url (https://example/): client error (Connect): tcp connect error: Operation timed out (os error 60): Operation timed out (os error 60)\"\n            // undici throws \"TypeError: fetch failed\" with cause \"ConnectTimeoutError: Connect Timeout Error (attempted address: example:443, timeout: 1ms)\"\n            // others do not provide enough information to distinguish timeouts from other connection errors\n            const isTimeout = isAbortError(response) ||\n                /timed? ?out/i.test(String(response) + ('cause' in response ? String(response.cause) : ''));\n            if (retriesRemaining) {\n                loggerFor(this).info(`[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} - ${retryMessage}`);\n                loggerFor(this).debug(`[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} (${retryMessage})`, formatRequestDetails({\n                    retryOfRequestLogID,\n                    url,\n                    durationMs: headersTime - startTime,\n                    message: response.message,\n                }));\n                return this.retryRequest(options, retriesRemaining, retryOfRequestLogID ?? requestLogID);\n            }\n            loggerFor(this).info(`[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} - error; no more retries left`);\n            loggerFor(this).debug(`[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} (error; no more retries left)`, formatRequestDetails({\n                retryOfRequestLogID,\n                url,\n                durationMs: headersTime - startTime,\n                message: response.message,\n            }));\n            if (isTimeout) {\n                throw new Errors.APIConnectionTimeoutError();\n            }\n            throw new Errors.APIConnectionError({ cause: response });\n        }\n        const specialHeaders = [...response.headers.entries()]\n            .filter(([name]) => name === 'request-id')\n            .map(([name, value]) => ', ' + name + ': ' + JSON.stringify(value))\n            .join('');\n        const responseInfo = `[${requestLogID}${retryLogStr}${specialHeaders}] ${req.method} ${url} ${response.ok ? 'succeeded' : 'failed'} with status ${response.status} in ${headersTime - startTime}ms`;\n        if (!response.ok) {\n            const shouldRetry = await this.shouldRetry(response);\n            if (retriesRemaining && shouldRetry) {\n                const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n                // We don't need the body of this response.\n                await Shims.CancelReadableStream(response.body);\n                loggerFor(this).info(`${responseInfo} - ${retryMessage}`);\n                loggerFor(this).debug(`[${requestLogID}] response error (${retryMessage})`, formatRequestDetails({\n                    retryOfRequestLogID,\n                    url: response.url,\n                    status: response.status,\n                    headers: response.headers,\n                    durationMs: headersTime - startTime,\n                }));\n                return this.retryRequest(options, retriesRemaining, retryOfRequestLogID ?? requestLogID, response.headers);\n            }\n            const retryMessage = shouldRetry ? `error; no more retries left` : `error; not retryable`;\n            loggerFor(this).info(`${responseInfo} - ${retryMessage}`);\n            const errText = await response.text().catch((err) => castToError(err).message);\n            const errJSON = safeJSON(errText);\n            const errMessage = errJSON ? undefined : errText;\n            loggerFor(this).debug(`[${requestLogID}] response error (${retryMessage})`, formatRequestDetails({\n                retryOfRequestLogID,\n                url: response.url,\n                status: response.status,\n                headers: response.headers,\n                message: errMessage,\n                durationMs: Date.now() - startTime,\n            }));\n            const err = this.makeStatusError(response.status, errJSON, errMessage, response.headers);\n            throw err;\n        }\n        loggerFor(this).info(responseInfo);\n        loggerFor(this).debug(`[${requestLogID}] response start`, formatRequestDetails({\n            retryOfRequestLogID,\n            url: response.url,\n            status: response.status,\n            headers: response.headers,\n            durationMs: headersTime - startTime,\n        }));\n        return { response, options, controller, requestLogID, retryOfRequestLogID, startTime };\n    }\n    getAPIList(path, Page, opts) {\n        return this.requestAPIList(Page, { method: 'get', path, ...opts });\n    }\n    requestAPIList(Page, options) {\n        const request = this.makeRequest(options, null, undefined);\n        return new Pagination.PagePromise(this, request, Page);\n    }\n    async fetchWithTimeout(url, init, ms, controller) {\n        const { signal, method, ...options } = init || {};\n        if (signal)\n            signal.addEventListener('abort', () => controller.abort());\n        const timeout = setTimeout(() => controller.abort(), ms);\n        const isReadableBody = (globalThis.ReadableStream && options.body instanceof globalThis.ReadableStream) ||\n            (typeof options.body === 'object' && options.body !== null && Symbol.asyncIterator in options.body);\n        const fetchOptions = {\n            signal: controller.signal,\n            ...(isReadableBody ? { duplex: 'half' } : {}),\n            method: 'GET',\n            ...options,\n        };\n        if (method) {\n            // Custom methods like 'patch' need to be uppercased\n            // See https://github.com/nodejs/undici/issues/2294\n            fetchOptions.method = method.toUpperCase();\n        }\n        try {\n            // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n            return await this.fetch.call(undefined, url, fetchOptions);\n        }\n        finally {\n            clearTimeout(timeout);\n        }\n    }\n    async shouldRetry(response) {\n        // Note this is not a standard header.\n        const shouldRetryHeader = response.headers.get('x-should-retry');\n        // If the server explicitly says whether or not to retry, obey.\n        if (shouldRetryHeader === 'true')\n            return true;\n        if (shouldRetryHeader === 'false')\n            return false;\n        // Retry on request timeouts.\n        if (response.status === 408)\n            return true;\n        // Retry on lock timeouts.\n        if (response.status === 409)\n            return true;\n        // Retry on rate limits.\n        if (response.status === 429)\n            return true;\n        // Retry internal errors.\n        if (response.status >= 500)\n            return true;\n        return false;\n    }\n    async retryRequest(options, retriesRemaining, requestLogID, responseHeaders) {\n        let timeoutMillis;\n        // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n        const retryAfterMillisHeader = responseHeaders?.get('retry-after-ms');\n        if (retryAfterMillisHeader) {\n            const timeoutMs = parseFloat(retryAfterMillisHeader);\n            if (!Number.isNaN(timeoutMs)) {\n                timeoutMillis = timeoutMs;\n            }\n        }\n        // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n        const retryAfterHeader = responseHeaders?.get('retry-after');\n        if (retryAfterHeader && !timeoutMillis) {\n            const timeoutSeconds = parseFloat(retryAfterHeader);\n            if (!Number.isNaN(timeoutSeconds)) {\n                timeoutMillis = timeoutSeconds * 1000;\n            }\n            else {\n                timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n            }\n        }\n        // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n        // just do what it says, but otherwise calculate a default\n        if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n            const maxRetries = options.maxRetries ?? this.maxRetries;\n            timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n        }\n        await sleep(timeoutMillis);\n        return this.makeRequest(options, retriesRemaining - 1, requestLogID);\n    }\n    calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries) {\n        const initialRetryDelay = 0.5;\n        const maxRetryDelay = 8.0;\n        const numRetries = maxRetries - retriesRemaining;\n        // Apply exponential backoff, but not more than the max.\n        const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n        // Apply some jitter, take up to at most 25 percent of the retry time.\n        const jitter = 1 - Math.random() * 0.25;\n        return sleepSeconds * jitter * 1000;\n    }\n    calculateNonstreamingTimeout(maxTokens, maxNonstreamingTokens) {\n        const maxTime = 60 * 60 * 1000; // 60 minutes\n        const defaultTime = 60 * 10 * 1000; // 10 minutes\n        const expectedTime = (maxTime * maxTokens) / 128000;\n        if (expectedTime > defaultTime || (maxNonstreamingTokens != null && maxTokens > maxNonstreamingTokens)) {\n            throw new Errors.AnthropicError('Streaming is required for operations that may take longer than 10 minutes. See https://github.com/anthropics/anthropic-sdk-typescript#long-requests for more details');\n        }\n        return defaultTime;\n    }\n    async buildRequest(inputOptions, { retryCount = 0 } = {}) {\n        const options = { ...inputOptions };\n        const { method, path, query, defaultBaseURL } = options;\n        const url = this.buildURL(path, query, defaultBaseURL);\n        if ('timeout' in options)\n            validatePositiveInteger('timeout', options.timeout);\n        options.timeout = options.timeout ?? this.timeout;\n        const { bodyHeaders, body } = this.buildBody({ options });\n        const reqHeaders = await this.buildHeaders({ options: inputOptions, method, bodyHeaders, retryCount });\n        const req = {\n            method,\n            headers: reqHeaders,\n            ...(options.signal && { signal: options.signal }),\n            ...(globalThis.ReadableStream &&\n                body instanceof globalThis.ReadableStream && { duplex: 'half' }),\n            ...(body && { body }),\n            ...(this.fetchOptions ?? {}),\n            ...(options.fetchOptions ?? {}),\n        };\n        return { req, url, timeout: options.timeout };\n    }\n    async buildHeaders({ options, method, bodyHeaders, retryCount, }) {\n        let idempotencyHeaders = {};\n        if (this.idempotencyHeader && method !== 'get') {\n            if (!options.idempotencyKey)\n                options.idempotencyKey = this.defaultIdempotencyKey();\n            idempotencyHeaders[this.idempotencyHeader] = options.idempotencyKey;\n        }\n        const headers = buildHeaders([\n            idempotencyHeaders,\n            {\n                Accept: 'application/json',\n                'User-Agent': this.getUserAgent(),\n                'X-Stainless-Retry-Count': String(retryCount),\n                ...(options.timeout ? { 'X-Stainless-Timeout': String(Math.trunc(options.timeout / 1000)) } : {}),\n                ...getPlatformHeaders(),\n                ...(this._options.dangerouslyAllowBrowser ?\n                    { 'anthropic-dangerous-direct-browser-access': 'true' }\n                    : undefined),\n                'anthropic-version': '2023-06-01',\n            },\n            await this.authHeaders(options),\n            this._options.defaultHeaders,\n            bodyHeaders,\n            options.headers,\n        ]);\n        this.validateHeaders(headers);\n        return headers.values;\n    }\n    buildBody({ options: { body, headers: rawHeaders } }) {\n        if (!body) {\n            return { bodyHeaders: undefined, body: undefined };\n        }\n        const headers = buildHeaders([rawHeaders]);\n        if (\n        // Pass raw type verbatim\n        ArrayBuffer.isView(body) ||\n            body instanceof ArrayBuffer ||\n            body instanceof DataView ||\n            (typeof body === 'string' &&\n                // Preserve legacy string encoding behavior for now\n                headers.values.has('content-type')) ||\n            // `Blob` is superset of `File`\n            (globalThis.Blob && body instanceof globalThis.Blob) ||\n            // `FormData` -> `multipart/form-data`\n            body instanceof FormData ||\n            // `URLSearchParams` -> `application/x-www-form-urlencoded`\n            body instanceof URLSearchParams ||\n            // Send chunked stream (each chunk has own `length`)\n            (globalThis.ReadableStream && body instanceof globalThis.ReadableStream)) {\n            return { bodyHeaders: undefined, body: body };\n        }\n        else if (typeof body === 'object' &&\n            (Symbol.asyncIterator in body ||\n                (Symbol.iterator in body && 'next' in body && typeof body.next === 'function'))) {\n            return { bodyHeaders: undefined, body: Shims.ReadableStreamFrom(body) };\n        }\n        else {\n            return __classPrivateFieldGet(this, _BaseAnthropic_encoder, \"f\").call(this, { body, headers });\n        }\n    }\n}\n_a = BaseAnthropic, _BaseAnthropic_encoder = new WeakMap(), _BaseAnthropic_instances = new WeakSet(), _BaseAnthropic_baseURLOverridden = function _BaseAnthropic_baseURLOverridden() {\n    return this.baseURL !== 'https://api.anthropic.com';\n};\nBaseAnthropic.Anthropic = _a;\nBaseAnthropic.HUMAN_PROMPT = HUMAN_PROMPT;\nBaseAnthropic.AI_PROMPT = AI_PROMPT;\nBaseAnthropic.DEFAULT_TIMEOUT = 600000; // 10 minutes\nBaseAnthropic.AnthropicError = Errors.AnthropicError;\nBaseAnthropic.APIError = Errors.APIError;\nBaseAnthropic.APIConnectionError = Errors.APIConnectionError;\nBaseAnthropic.APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\nBaseAnthropic.APIUserAbortError = Errors.APIUserAbortError;\nBaseAnthropic.NotFoundError = Errors.NotFoundError;\nBaseAnthropic.ConflictError = Errors.ConflictError;\nBaseAnthropic.RateLimitError = Errors.RateLimitError;\nBaseAnthropic.BadRequestError = Errors.BadRequestError;\nBaseAnthropic.AuthenticationError = Errors.AuthenticationError;\nBaseAnthropic.InternalServerError = Errors.InternalServerError;\nBaseAnthropic.PermissionDeniedError = Errors.PermissionDeniedError;\nBaseAnthropic.UnprocessableEntityError = Errors.UnprocessableEntityError;\nBaseAnthropic.toFile = Uploads.toFile;\n/**\n * API Client for interfacing with the Anthropic API.\n */\nexport class Anthropic extends BaseAnthropic {\n    constructor() {\n        super(...arguments);\n        this.completions = new API.Completions(this);\n        this.messages = new API.Messages(this);\n        this.models = new API.Models(this);\n        this.beta = new API.Beta(this);\n    }\n}\nAnthropic.Completions = Completions;\nAnthropic.Messages = Messages;\nAnthropic.Models = Models;\nAnthropic.Beta = Beta;\n//# sourceMappingURL=client.mjs.map","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nexport { Anthropic as default } from \"./client.mjs\";\nexport { toFile } from \"./core/uploads.mjs\";\nexport { APIPromise } from \"./core/api-promise.mjs\";\nexport { BaseAnthropic, Anthropic, HUMAN_PROMPT, AI_PROMPT } from \"./client.mjs\";\nexport { PagePromise } from \"./core/pagination.mjs\";\nexport { AnthropicError, APIError, APIConnectionError, APIConnectionTimeoutError, APIUserAbortError, NotFoundError, ConflictError, RateLimitError, BadRequestError, AuthenticationError, InternalServerError, PermissionDeniedError, UnprocessableEntityError, } from \"./core/error.mjs\";\n//# sourceMappingURL=index.mjs.map","import { AnthropicToolsOutputParser } from \"./output_parsers.js\";\nimport { handleToolChoice } from \"./utils/tools.js\";\nimport { _convertMessagesToAnthropicPayload } from \"./utils/message_inputs.js\";\nimport { _makeMessageChunkFromAnthropicEvent, anthropicResponseToChatMessages } from \"./utils/message_outputs.js\";\nimport { wrapAnthropicClientError } from \"./utils/errors.js\";\nimport { Anthropic as Anthropic$1 } from \"@anthropic-ai/sdk\";\nimport { AIMessageChunk } from \"@langchain/core/messages\";\nimport { ChatGenerationChunk } from \"@langchain/core/outputs\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { BaseChatModel } from \"@langchain/core/language_models/chat_models\";\nimport { isOpenAITool } from \"@langchain/core/language_models/base\";\nimport { toJsonSchema } from \"@langchain/core/utils/json_schema\";\nimport { RunnablePassthrough, RunnableSequence } from \"@langchain/core/runnables\";\nimport { isInteropZodSchema } from \"@langchain/core/utils/types\";\nimport { isLangChainTool } from \"@langchain/core/utils/function_calling\";\n\n//#region src/chat_models.ts\nconst MODEL_DEFAULT_MAX_OUTPUT_TOKENS = {\n\t\"claude-opus-4-1\": 8192,\n\t\"claude-opus-4\": 8192,\n\t\"claude-sonnet-4\": 8192,\n\t\"claude-sonnet-3-7-sonnet\": 8192,\n\t\"claude-3-5-sonnet\": 4096,\n\t\"claude-3-5-haiku\": 4096,\n\t\"claude-3-haiku\": 2048\n};\nconst FALLBACK_MAX_OUTPUT_TOKENS = 2048;\nfunction defaultMaxOutputTokensForModel(model) {\n\tif (!model) return FALLBACK_MAX_OUTPUT_TOKENS;\n\tconst maxTokens = Object.entries(MODEL_DEFAULT_MAX_OUTPUT_TOKENS).find(([key]) => model.startsWith(key))?.[1];\n\treturn maxTokens ?? FALLBACK_MAX_OUTPUT_TOKENS;\n}\nfunction _toolsInParams(params) {\n\treturn !!(params.tools && params.tools.length > 0);\n}\nfunction _documentsInParams(params) {\n\tfor (const message of params.messages ?? []) {\n\t\tif (typeof message.content === \"string\") continue;\n\t\tfor (const block of message.content ?? []) if (typeof block === \"object\" && block != null && block.type === \"document\" && typeof block.citations === \"object\" && block.citations?.enabled) return true;\n\t}\n\treturn false;\n}\nfunction _thinkingInParams(params) {\n\treturn !!(params.thinking && params.thinking.type === \"enabled\");\n}\nfunction isAnthropicTool(tool) {\n\treturn \"input_schema\" in tool;\n}\nfunction isBuiltinTool(tool) {\n\tconst builtInToolPrefixes = [\n\t\t\"text_editor_\",\n\t\t\"computer_\",\n\t\t\"bash_\",\n\t\t\"web_search_\",\n\t\t\"web_fetch_\",\n\t\t\"str_replace_editor_\",\n\t\t\"str_replace_based_edit_tool_\",\n\t\t\"code_execution_\",\n\t\t\"memory_\"\n\t];\n\treturn typeof tool === \"object\" && tool !== null && \"type\" in tool && \"name\" in tool && typeof tool.type === \"string\" && builtInToolPrefixes.some((prefix) => typeof tool.type === \"string\" && tool.type.startsWith(prefix));\n}\nfunction extractToken(chunk) {\n\tif (typeof chunk.content === \"string\") return chunk.content;\n\telse if (Array.isArray(chunk.content) && chunk.content.length >= 1 && \"input\" in chunk.content[0]) return typeof chunk.content[0].input === \"string\" ? chunk.content[0].input : JSON.stringify(chunk.content[0].input);\n\telse if (Array.isArray(chunk.content) && chunk.content.length >= 1 && \"text\" in chunk.content[0] && typeof chunk.content[0].text === \"string\") return chunk.content[0].text;\n\treturn void 0;\n}\n/**\n* Anthropic chat model integration.\n*\n* Setup:\n* Install `@langchain/anthropic` and set an environment variable named `ANTHROPIC_API_KEY`.\n*\n* ```bash\n* npm install @langchain/anthropic\n* export ANTHROPIC_API_KEY=\"your-api-key\"\n* ```\n*\n* ## [Constructor args](https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html#constructor)\n*\n* ## [Runtime args](https://api.js.langchain.com/interfaces/langchain_anthropic.ChatAnthropicCallOptions.html)\n*\n* Runtime args can be passed as the second argument to any of the base runnable methods `.invoke`. `.stream`, `.batch`, etc.\n* They can also be passed via `.bind`, or the second arg in `.bindTools`, like shown in the examples below:\n*\n* ```typescript\n* // When calling `.bind`, call options should be passed via the first argument\n* const llmWithArgsBound = llm.bindTools([...]).withConfig({\n*   stop: [\"\\n\"],\n* });\n*\n* // When calling `.bindTools`, call options should be passed via the second argument\n* const llmWithTools = llm.bindTools(\n*   [...],\n*   {\n*     tool_choice: \"auto\",\n*   }\n* );\n* ```\n*\n* ## Examples\n*\n* <details open>\n* <summary><strong>Instantiate</strong></summary>\n*\n* ```typescript\n* import { ChatAnthropic } from '@langchain/anthropic';\n*\n* const llm = new ChatAnthropic({\n*   model: \"claude-sonnet-4-5-20250929\",\n*   temperature: 0,\n*   maxTokens: undefined,\n*   maxRetries: 2,\n*   // apiKey: \"...\",\n*   // baseUrl: \"...\",\n*   // other params...\n* });\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Invoking</strong></summary>\n*\n* ```typescript\n* const input = `Translate \"I love programming\" into French.`;\n*\n* // Models also accept a list of chat messages or a formatted prompt\n* const result = await llm.invoke(input);\n* console.log(result);\n* ```\n*\n* ```txt\n* AIMessage {\n*   \"id\": \"msg_01QDpd78JUHpRP6bRRNyzbW3\",\n*   \"content\": \"Here's the translation to French:\\n\\nJ'adore la programmation.\",\n*   \"response_metadata\": {\n*     \"id\": \"msg_01QDpd78JUHpRP6bRRNyzbW3\",\n*     \"model\": \"claude-sonnet-4-5-20250929\",\n*     \"stop_reason\": \"end_turn\",\n*     \"stop_sequence\": null,\n*     \"usage\": {\n*       \"input_tokens\": 25,\n*       \"output_tokens\": 19\n*     },\n*     \"type\": \"message\",\n*     \"role\": \"assistant\"\n*   },\n*   \"usage_metadata\": {\n*     \"input_tokens\": 25,\n*     \"output_tokens\": 19,\n*     \"total_tokens\": 44\n*   }\n* }\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Streaming Chunks</strong></summary>\n*\n* ```typescript\n* for await (const chunk of await llm.stream(input)) {\n*   console.log(chunk);\n* }\n* ```\n*\n* ```txt\n* AIMessageChunk {\n*   \"id\": \"msg_01N8MwoYxiKo9w4chE4gXUs4\",\n*   \"content\": \"\",\n*   \"additional_kwargs\": {\n*     \"id\": \"msg_01N8MwoYxiKo9w4chE4gXUs4\",\n*     \"type\": \"message\",\n*     \"role\": \"assistant\",\n*     \"model\": \"claude-sonnet-4-5-20250929\"\n*   },\n*   \"usage_metadata\": {\n*     \"input_tokens\": 25,\n*     \"output_tokens\": 1,\n*     \"total_tokens\": 26\n*   }\n* }\n* AIMessageChunk {\n*   \"content\": \"\",\n* }\n* AIMessageChunk {\n*   \"content\": \"Here\",\n* }\n* AIMessageChunk {\n*   \"content\": \"'s\",\n* }\n* AIMessageChunk {\n*   \"content\": \" the translation to\",\n* }\n* AIMessageChunk {\n*   \"content\": \" French:\\n\\nJ\",\n* }\n* AIMessageChunk {\n*   \"content\": \"'adore la programmation\",\n* }\n* AIMessageChunk {\n*   \"content\": \".\",\n* }\n* AIMessageChunk {\n*   \"content\": \"\",\n*   \"additional_kwargs\": {\n*     \"stop_reason\": \"end_turn\",\n*     \"stop_sequence\": null\n*   },\n*   \"usage_metadata\": {\n*     \"input_tokens\": 0,\n*     \"output_tokens\": 19,\n*     \"total_tokens\": 19\n*   }\n* }\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Aggregate Streamed Chunks</strong></summary>\n*\n* ```typescript\n* import { AIMessageChunk } from '@langchain/core/messages';\n* import { concat } from '@langchain/core/utils/stream';\n*\n* const stream = await llm.stream(input);\n* let full: AIMessageChunk | undefined;\n* for await (const chunk of stream) {\n*   full = !full ? chunk : concat(full, chunk);\n* }\n* console.log(full);\n* ```\n*\n* ```txt\n* AIMessageChunk {\n*   \"id\": \"msg_01SBTb5zSGXfjUc7yQ8EKEEA\",\n*   \"content\": \"Here's the translation to French:\\n\\nJ'adore la programmation.\",\n*   \"additional_kwargs\": {\n*     \"id\": \"msg_01SBTb5zSGXfjUc7yQ8EKEEA\",\n*     \"type\": \"message\",\n*     \"role\": \"assistant\",\n*     \"model\": \"claude-sonnet-4-5-20250929\",\n*     \"stop_reason\": \"end_turn\",\n*     \"stop_sequence\": null\n*   },\n*   \"usage_metadata\": {\n*     \"input_tokens\": 25,\n*     \"output_tokens\": 20,\n*     \"total_tokens\": 45\n*   }\n* }\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Bind tools</strong></summary>\n*\n* ```typescript\n* import { z } from 'zod';\n*\n* const GetWeather = {\n*   name: \"GetWeather\",\n*   description: \"Get the current weather in a given location\",\n*   schema: z.object({\n*     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n*   }),\n* }\n*\n* const GetPopulation = {\n*   name: \"GetPopulation\",\n*   description: \"Get the current population in a given location\",\n*   schema: z.object({\n*     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n*   }),\n* }\n*\n* const llmWithTools = llm.bindTools([GetWeather, GetPopulation]);\n* const aiMsg = await llmWithTools.invoke(\n*   \"Which city is hotter today and which is bigger: LA or NY?\"\n* );\n* console.log(aiMsg.tool_calls);\n* ```\n*\n* ```txt\n* [\n*   {\n*     name: 'GetWeather',\n*     args: { location: 'Los Angeles, CA' },\n*     id: 'toolu_01WjW3Dann6BPJVtLhovdBD5',\n*     type: 'tool_call'\n*   },\n*   {\n*     name: 'GetWeather',\n*     args: { location: 'New York, NY' },\n*     id: 'toolu_01G6wfJgqi5zRmJomsmkyZXe',\n*     type: 'tool_call'\n*   },\n*   {\n*     name: 'GetPopulation',\n*     args: { location: 'Los Angeles, CA' },\n*     id: 'toolu_0165qYWBA2VFyUst5RA18zew',\n*     type: 'tool_call'\n*   },\n*   {\n*     name: 'GetPopulation',\n*     args: { location: 'New York, NY' },\n*     id: 'toolu_01PGNyP33vxr13tGqr7i3rDo',\n*     type: 'tool_call'\n*   }\n* ]\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Structured Output</strong></summary>\n*\n* ```typescript\n* import { z } from 'zod';\n*\n* const Joke = z.object({\n*   setup: z.string().describe(\"The setup of the joke\"),\n*   punchline: z.string().describe(\"The punchline to the joke\"),\n*   rating: z.number().optional().describe(\"How funny the joke is, from 1 to 10\")\n* }).describe('Joke to tell user.');\n*\n* const structuredLlm = llm.withStructuredOutput(Joke, { name: \"Joke\" });\n* const jokeResult = await structuredLlm.invoke(\"Tell me a joke about cats\");\n* console.log(jokeResult);\n* ```\n*\n* ```txt\n* {\n*   setup: \"Why don't cats play poker in the jungle?\",\n*   punchline: 'Too many cheetahs!',\n*   rating: 7\n* }\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Multimodal</strong></summary>\n*\n* ```typescript\n* import { HumanMessage } from '@langchain/core/messages';\n*\n* const imageUrl = \"https://example.com/image.jpg\";\n* const imageData = await fetch(imageUrl).then(res => res.arrayBuffer());\n* const base64Image = Buffer.from(imageData).toString('base64');\n*\n* const message = new HumanMessage({\n*   content: [\n*     { type: \"text\", text: \"describe the weather in this image\" },\n*     {\n*       type: \"image_url\",\n*       image_url: { url: `data:image/jpeg;base64,${base64Image}` },\n*     },\n*   ]\n* });\n*\n* const imageDescriptionAiMsg = await llm.invoke([message]);\n* console.log(imageDescriptionAiMsg.content);\n* ```\n*\n* ```txt\n* The weather in this image appears to be beautiful and clear. The sky is a vibrant blue with scattered white clouds, suggesting a sunny and pleasant day. The clouds are wispy and light, indicating calm conditions without any signs of storms or heavy weather. The bright green grass on the rolling hills looks lush and well-watered, which could mean recent rainfall or good growing conditions. Overall, the scene depicts a perfect spring or early summer day with mild temperatures, plenty of sunshine, and gentle breezes - ideal weather for enjoying the outdoors or for plant growth.\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Usage Metadata</strong></summary>\n*\n* ```typescript\n* const aiMsgForMetadata = await llm.invoke(input);\n* console.log(aiMsgForMetadata.usage_metadata);\n* ```\n*\n* ```txt\n* { input_tokens: 25, output_tokens: 19, total_tokens: 44 }\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Stream Usage Metadata</strong></summary>\n*\n* ```typescript\n* const streamForMetadata = await llm.stream(\n*   input,\n*   {\n*     streamUsage: true\n*   }\n* );\n* let fullForMetadata: AIMessageChunk | undefined;\n* for await (const chunk of streamForMetadata) {\n*   fullForMetadata = !fullForMetadata ? chunk : concat(fullForMetadata, chunk);\n* }\n* console.log(fullForMetadata?.usage_metadata);\n* ```\n*\n* ```txt\n* { input_tokens: 25, output_tokens: 20, total_tokens: 45 }\n* ```\n* </details>\n*\n* <br />\n*\n* <details>\n* <summary><strong>Response Metadata</strong></summary>\n*\n* ```typescript\n* const aiMsgForResponseMetadata = await llm.invoke(input);\n* console.log(aiMsgForResponseMetadata.response_metadata);\n* ```\n*\n* ```txt\n* {\n*   id: 'msg_01STxeQxJmp4sCSpioD6vK3L',\n*   model: 'claude-sonnet-4-5-20250929',\n*   stop_reason: 'end_turn',\n*   stop_sequence: null,\n*   usage: { input_tokens: 25, output_tokens: 19 },\n*   type: 'message',\n*   role: 'assistant'\n* }\n* ```\n* </details>\n*\n* <br />\n*/\nvar ChatAnthropicMessages = class extends BaseChatModel {\n\tstatic lc_name() {\n\t\treturn \"ChatAnthropic\";\n\t}\n\tget lc_secrets() {\n\t\treturn {\n\t\t\tanthropicApiKey: \"ANTHROPIC_API_KEY\",\n\t\t\tapiKey: \"ANTHROPIC_API_KEY\"\n\t\t};\n\t}\n\tget lc_aliases() {\n\t\treturn { modelName: \"model\" };\n\t}\n\tlc_serializable = true;\n\tanthropicApiKey;\n\tapiKey;\n\tapiUrl;\n\ttemperature;\n\ttopK;\n\ttopP;\n\tmaxTokens;\n\tmodelName = \"claude-3-5-sonnet-latest\";\n\tmodel = \"claude-3-5-sonnet-latest\";\n\tinvocationKwargs;\n\tstopSequences;\n\tstreaming = false;\n\tclientOptions;\n\tthinking = { type: \"disabled\" };\n\tcontextManagement;\n\tbatchClient;\n\tstreamingClient;\n\tstreamUsage = true;\n\t/**\n\t* Optional method that returns an initialized underlying Anthropic client.\n\t* Useful for accessing Anthropic models hosted on other cloud services\n\t* such as Google Vertex.\n\t*/\n\tcreateClient;\n\tconstructor(fields) {\n\t\tsuper(fields ?? {});\n\t\tthis.anthropicApiKey = fields?.apiKey ?? fields?.anthropicApiKey ?? getEnvironmentVariable(\"ANTHROPIC_API_KEY\");\n\t\tif (!this.anthropicApiKey && !fields?.createClient) throw new Error(\"Anthropic API key not found\");\n\t\tthis.clientOptions = fields?.clientOptions ?? {};\n\t\t/** Keep anthropicApiKey for backwards compatibility */\n\t\tthis.apiKey = this.anthropicApiKey;\n\t\tthis.apiUrl = fields?.anthropicApiUrl;\n\t\t/** Keep modelName for backwards compatibility */\n\t\tthis.modelName = fields?.model ?? fields?.modelName ?? this.model;\n\t\tthis.model = this.modelName;\n\t\tthis.invocationKwargs = fields?.invocationKwargs ?? {};\n\t\tthis.topP = fields?.topP ?? this.topP;\n\t\tthis.temperature = fields?.temperature ?? this.temperature;\n\t\tthis.topK = fields?.topK ?? this.topK;\n\t\tthis.maxTokens = fields?.maxTokens ?? defaultMaxOutputTokensForModel(this.model);\n\t\tthis.stopSequences = fields?.stopSequences ?? this.stopSequences;\n\t\tthis.streaming = fields?.streaming ?? false;\n\t\tthis.streamUsage = fields?.streamUsage ?? this.streamUsage;\n\t\tthis.thinking = fields?.thinking ?? this.thinking;\n\t\tthis.contextManagement = fields?.contextManagement ?? this.contextManagement;\n\t\tthis.createClient = fields?.createClient ?? ((options) => new Anthropic$1(options));\n\t}\n\tgetLsParams(options) {\n\t\tconst params = this.invocationParams(options);\n\t\treturn {\n\t\t\tls_provider: \"anthropic\",\n\t\t\tls_model_name: this.model,\n\t\t\tls_model_type: \"chat\",\n\t\t\tls_temperature: params.temperature ?? void 0,\n\t\t\tls_max_tokens: params.max_tokens ?? void 0,\n\t\t\tls_stop: options.stop\n\t\t};\n\t}\n\t/**\n\t* Formats LangChain StructuredTools to AnthropicTools.\n\t*\n\t* @param {ChatAnthropicCallOptions[\"tools\"]} tools The tools to format\n\t* @returns {AnthropicTool[] | undefined} The formatted tools, or undefined if none are passed.\n\t*/\n\tformatStructuredToolToAnthropic(tools) {\n\t\tif (!tools || !tools.length) return void 0;\n\t\treturn tools.map((tool) => {\n\t\t\tif (isBuiltinTool(tool)) return tool;\n\t\t\tif (isAnthropicTool(tool)) return tool;\n\t\t\tif (isOpenAITool(tool)) return {\n\t\t\t\tname: tool.function.name,\n\t\t\t\tdescription: tool.function.description,\n\t\t\t\tinput_schema: tool.function.parameters\n\t\t\t};\n\t\t\tif (isLangChainTool(tool)) return {\n\t\t\t\tname: tool.name,\n\t\t\t\tdescription: tool.description,\n\t\t\t\tinput_schema: isInteropZodSchema(tool.schema) ? toJsonSchema(tool.schema) : tool.schema\n\t\t\t};\n\t\t\tthrow new Error(`Unknown tool type passed to ChatAnthropic: ${JSON.stringify(tool, null, 2)}`);\n\t\t});\n\t}\n\tbindTools(tools, kwargs) {\n\t\treturn this.withConfig({\n\t\t\ttools: this.formatStructuredToolToAnthropic(tools),\n\t\t\t...kwargs\n\t\t});\n\t}\n\t/**\n\t* Get the parameters used to invoke the model\n\t*/\n\tinvocationParams(options) {\n\t\tconst tool_choice = handleToolChoice(options?.tool_choice);\n\t\tif (this.thinking.type === \"enabled\") {\n\t\t\tif (this.topP !== void 0 && this.topK !== -1) throw new Error(\"topK is not supported when thinking is enabled\");\n\t\t\tif (this.temperature !== void 0 && this.temperature !== 1) throw new Error(\"temperature is not supported when thinking is enabled\");\n\t\t\treturn {\n\t\t\t\tmodel: this.model,\n\t\t\t\tstop_sequences: options?.stop ?? this.stopSequences,\n\t\t\t\tstream: this.streaming,\n\t\t\t\tmax_tokens: this.maxTokens,\n\t\t\t\ttools: this.formatStructuredToolToAnthropic(options?.tools),\n\t\t\t\ttool_choice,\n\t\t\t\tthinking: this.thinking,\n\t\t\t\tcontext_management: this.contextManagement,\n\t\t\t\t...this.invocationKwargs,\n\t\t\t\tcontainer: options?.container\n\t\t\t};\n\t\t}\n\t\treturn {\n\t\t\tmodel: this.model,\n\t\t\ttemperature: this.temperature,\n\t\t\ttop_k: this.topK,\n\t\t\ttop_p: this.topP,\n\t\t\tstop_sequences: options?.stop ?? this.stopSequences,\n\t\t\tstream: this.streaming,\n\t\t\tmax_tokens: this.maxTokens,\n\t\t\ttools: this.formatStructuredToolToAnthropic(options?.tools),\n\t\t\ttool_choice,\n\t\t\tthinking: this.thinking,\n\t\t\tcontext_management: this.contextManagement,\n\t\t\t...this.invocationKwargs,\n\t\t\tcontainer: options?.container\n\t\t};\n\t}\n\t/** @ignore */\n\t_identifyingParams() {\n\t\treturn {\n\t\t\tmodel_name: this.model,\n\t\t\t...this.invocationParams()\n\t\t};\n\t}\n\t/**\n\t* Get the identifying parameters for the model\n\t*/\n\tidentifyingParams() {\n\t\treturn {\n\t\t\tmodel_name: this.model,\n\t\t\t...this.invocationParams()\n\t\t};\n\t}\n\tasync *_streamResponseChunks(messages, options, runManager) {\n\t\tconst params = this.invocationParams(options);\n\t\tconst formattedMessages = _convertMessagesToAnthropicPayload(messages);\n\t\tconst payload = {\n\t\t\t...params,\n\t\t\t...formattedMessages,\n\t\t\tstream: true\n\t\t};\n\t\tconst coerceContentToString = !_toolsInParams(payload) && !_documentsInParams(payload) && !_thinkingInParams(payload);\n\t\tconst stream = await this.createStreamWithRetry(payload, { headers: options.headers });\n\t\tfor await (const data of stream) {\n\t\t\tif (options.signal?.aborted) {\n\t\t\t\tstream.controller.abort();\n\t\t\t\tthrow new Error(\"AbortError: User aborted the request.\");\n\t\t\t}\n\t\t\tconst shouldStreamUsage = this.streamUsage ?? options.streamUsage;\n\t\t\tconst result = _makeMessageChunkFromAnthropicEvent(data, {\n\t\t\t\tstreamUsage: shouldStreamUsage,\n\t\t\t\tcoerceContentToString\n\t\t\t});\n\t\t\tif (!result) continue;\n\t\t\tconst { chunk } = result;\n\t\t\tconst token = extractToken(chunk);\n\t\t\tconst generationChunk = new ChatGenerationChunk({\n\t\t\t\tmessage: new AIMessageChunk({\n\t\t\t\t\tcontent: chunk.content,\n\t\t\t\t\tadditional_kwargs: chunk.additional_kwargs,\n\t\t\t\t\ttool_call_chunks: chunk.tool_call_chunks,\n\t\t\t\t\tusage_metadata: shouldStreamUsage ? chunk.usage_metadata : void 0,\n\t\t\t\t\tresponse_metadata: chunk.response_metadata,\n\t\t\t\t\tid: chunk.id\n\t\t\t\t}),\n\t\t\t\ttext: token ?? \"\"\n\t\t\t});\n\t\t\tyield generationChunk;\n\t\t\tawait runManager?.handleLLMNewToken(token ?? \"\", void 0, void 0, void 0, void 0, { chunk: generationChunk });\n\t\t}\n\t}\n\t/** @ignore */\n\tasync _generateNonStreaming(messages, params, requestOptions) {\n\t\tconst response = await this.completionWithRetry({\n\t\t\t...params,\n\t\t\tstream: false,\n\t\t\t..._convertMessagesToAnthropicPayload(messages)\n\t\t}, requestOptions);\n\t\tconst { content,...additionalKwargs } = response;\n\t\tconst generations = anthropicResponseToChatMessages(content, additionalKwargs);\n\t\tconst { role: _role, type: _type,...rest } = additionalKwargs;\n\t\treturn {\n\t\t\tgenerations,\n\t\t\tllmOutput: rest\n\t\t};\n\t}\n\t/** @ignore */\n\tasync _generate(messages, options, runManager) {\n\t\tif (this.stopSequences && options.stop) throw new Error(`\"stopSequence\" parameter found in input and default params`);\n\t\tconst params = this.invocationParams(options);\n\t\tif (params.stream) {\n\t\t\tlet finalChunk;\n\t\t\tconst stream = this._streamResponseChunks(messages, options, runManager);\n\t\t\tfor await (const chunk of stream) if (finalChunk === void 0) finalChunk = chunk;\n\t\t\telse finalChunk = finalChunk.concat(chunk);\n\t\t\tif (finalChunk === void 0) throw new Error(\"No chunks returned from Anthropic API.\");\n\t\t\treturn { generations: [{\n\t\t\t\ttext: finalChunk.text,\n\t\t\t\tmessage: finalChunk.message\n\t\t\t}] };\n\t\t} else return this._generateNonStreaming(messages, params, {\n\t\t\tsignal: options.signal,\n\t\t\theaders: options.headers\n\t\t});\n\t}\n\t/**\n\t* Creates a streaming request with retry.\n\t* @param request The parameters for creating a completion.\n\t* @param options\n\t* @returns A streaming request.\n\t*/\n\tasync createStreamWithRetry(request, options) {\n\t\tif (!this.streamingClient) {\n\t\t\tconst options_ = this.apiUrl ? { baseURL: this.apiUrl } : void 0;\n\t\t\tthis.streamingClient = this.createClient({\n\t\t\t\tdangerouslyAllowBrowser: true,\n\t\t\t\t...this.clientOptions,\n\t\t\t\t...options_,\n\t\t\t\tapiKey: this.apiKey,\n\t\t\t\tmaxRetries: 0\n\t\t\t});\n\t\t}\n\t\tconst makeCompletionRequest = async () => {\n\t\t\ttry {\n\t\t\t\treturn await this.streamingClient.messages.create({\n\t\t\t\t\t...request,\n\t\t\t\t\t...this.invocationKwargs,\n\t\t\t\t\tstream: true\n\t\t\t\t}, options);\n\t\t\t} catch (e) {\n\t\t\t\tconst error = wrapAnthropicClientError(e);\n\t\t\t\tthrow error;\n\t\t\t}\n\t\t};\n\t\treturn this.caller.call(makeCompletionRequest);\n\t}\n\t/** @ignore */\n\tasync completionWithRetry(request, options) {\n\t\tif (!this.batchClient) {\n\t\t\tconst options$1 = this.apiUrl ? { baseURL: this.apiUrl } : void 0;\n\t\t\tthis.batchClient = this.createClient({\n\t\t\t\tdangerouslyAllowBrowser: true,\n\t\t\t\t...this.clientOptions,\n\t\t\t\t...options$1,\n\t\t\t\tapiKey: this.apiKey,\n\t\t\t\tmaxRetries: 0\n\t\t\t});\n\t\t}\n\t\tconst makeCompletionRequest = async () => {\n\t\t\ttry {\n\t\t\t\treturn await this.batchClient.messages.create({\n\t\t\t\t\t...request,\n\t\t\t\t\t...this.invocationKwargs\n\t\t\t\t}, options);\n\t\t\t} catch (e) {\n\t\t\t\tconst error = wrapAnthropicClientError(e);\n\t\t\t\tthrow error;\n\t\t\t}\n\t\t};\n\t\treturn this.caller.callWithOptions({ signal: options.signal ?? void 0 }, makeCompletionRequest);\n\t}\n\t_llmType() {\n\t\treturn \"anthropic\";\n\t}\n\twithStructuredOutput(outputSchema, config) {\n\t\tconst schema = outputSchema;\n\t\tconst name = config?.name;\n\t\tconst method = config?.method;\n\t\tconst includeRaw = config?.includeRaw;\n\t\tif (method === \"jsonMode\") throw new Error(`Anthropic only supports \"functionCalling\" as a method.`);\n\t\tlet functionName = name ?? \"extract\";\n\t\tlet outputParser;\n\t\tlet tools;\n\t\tif (isInteropZodSchema(schema)) {\n\t\t\tconst jsonSchema = toJsonSchema(schema);\n\t\t\ttools = [{\n\t\t\t\tname: functionName,\n\t\t\t\tdescription: jsonSchema.description ?? \"A function available to call.\",\n\t\t\t\tinput_schema: jsonSchema\n\t\t\t}];\n\t\t\toutputParser = new AnthropicToolsOutputParser({\n\t\t\t\treturnSingle: true,\n\t\t\t\tkeyName: functionName,\n\t\t\t\tzodSchema: schema\n\t\t\t});\n\t\t} else {\n\t\t\tlet anthropicTools;\n\t\t\tif (typeof schema.name === \"string\" && typeof schema.description === \"string\" && typeof schema.input_schema === \"object\" && schema.input_schema != null) {\n\t\t\t\tanthropicTools = schema;\n\t\t\t\tfunctionName = schema.name;\n\t\t\t} else anthropicTools = {\n\t\t\t\tname: functionName,\n\t\t\t\tdescription: schema.description ?? \"\",\n\t\t\t\tinput_schema: schema\n\t\t\t};\n\t\t\ttools = [anthropicTools];\n\t\t\toutputParser = new AnthropicToolsOutputParser({\n\t\t\t\treturnSingle: true,\n\t\t\t\tkeyName: functionName\n\t\t\t});\n\t\t}\n\t\tlet llm;\n\t\tif (this.thinking?.type === \"enabled\") {\n\t\t\tconst thinkingAdmonition = \"Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\";\n\t\t\tconsole.warn(thinkingAdmonition);\n\t\t\tllm = this.withConfig({\n\t\t\t\toutputVersion: \"v0\",\n\t\t\t\ttools,\n\t\t\t\tls_structured_output_format: {\n\t\t\t\t\tkwargs: { method: \"functionCalling\" },\n\t\t\t\t\tschema: toJsonSchema(schema)\n\t\t\t\t}\n\t\t\t});\n\t\t\tconst raiseIfNoToolCalls = (message) => {\n\t\t\t\tif (!message.tool_calls || message.tool_calls.length === 0) throw new Error(thinkingAdmonition);\n\t\t\t\treturn message;\n\t\t\t};\n\t\t\tllm = llm.pipe(raiseIfNoToolCalls);\n\t\t} else llm = this.withConfig({\n\t\t\toutputVersion: \"v0\",\n\t\t\ttools,\n\t\t\ttool_choice: {\n\t\t\t\ttype: \"tool\",\n\t\t\t\tname: functionName\n\t\t\t},\n\t\t\tls_structured_output_format: {\n\t\t\t\tkwargs: { method: \"functionCalling\" },\n\t\t\t\tschema: toJsonSchema(schema)\n\t\t\t}\n\t\t});\n\t\tif (!includeRaw) return llm.pipe(outputParser).withConfig({ runName: \"ChatAnthropicStructuredOutput\" });\n\t\tconst parserAssign = RunnablePassthrough.assign({ parsed: (input, config$1) => outputParser.invoke(input.raw, config$1) });\n\t\tconst parserNone = RunnablePassthrough.assign({ parsed: () => null });\n\t\tconst parsedWithFallback = parserAssign.withFallbacks({ fallbacks: [parserNone] });\n\t\treturn RunnableSequence.from([{ raw: llm }, parsedWithFallback]).withConfig({ runName: \"StructuredOutputRunnable\" });\n\t}\n};\nvar ChatAnthropic = class extends ChatAnthropicMessages {};\n\n//#endregion\nexport { ChatAnthropic, ChatAnthropicMessages };\n//# sourceMappingURL=chat_models.js.map","import { _convertMessagesToAnthropicPayload } from \"./message_inputs.js\";\n\n//#region src/utils/prompts.ts\n/**\n* Convert a formatted LangChain prompt (e.g. pulled from the hub) into\n* a format expected by Anthropic's JS SDK.\n*\n* Requires the \"@langchain/anthropic\" package to be installed in addition\n* to the Anthropic SDK.\n*\n* @example\n* ```ts\n* import { convertPromptToAnthropic } from \"langsmith/utils/hub/anthropic\";\n* import { pull } from \"langchain/hub\";\n*\n* import Anthropic from '@anthropic-ai/sdk';\n*\n* const prompt = await pull(\"jacob/joke-generator\");\n* const formattedPrompt = await prompt.invoke({\n*   topic: \"cats\",\n* });\n*\n* const { system, messages } = convertPromptToAnthropic(formattedPrompt);\n*\n* const anthropicClient = new Anthropic({\n*   apiKey: 'your_api_key',\n* });\n*\n* const anthropicResponse = await anthropicClient.messages.create({\n*   model: \"claude-sonnet-4-5-20250929\",\n*   max_tokens: 1024,\n*   stream: false,\n*   system,\n*   messages,\n* });\n* ```\n* @param formattedPrompt\n* @returns A partial Anthropic payload.\n*/\nfunction convertPromptToAnthropic(formattedPrompt) {\n\tconst messages = formattedPrompt.toChatMessages();\n\tconst anthropicBody = _convertMessagesToAnthropicPayload(messages);\n\tif (anthropicBody.messages === void 0) anthropicBody.messages = [];\n\treturn anthropicBody;\n}\n\n//#endregion\nexport { convertPromptToAnthropic };\n//# sourceMappingURL=prompts.js.map","import { ChatAnthropic, ChatAnthropicMessages } from \"./chat_models.js\";\nimport { convertPromptToAnthropic } from \"./utils/prompts.js\";\n\nexport { ChatAnthropic, ChatAnthropicMessages, convertPromptToAnthropic };","/**\n * PR Analysis Tools for LangChain Agent\n * These tools are used by the agent to analyze different aspects of PR changes\n */\n\nimport { DynamicStructuredTool } from '@langchain/core/tools';\nimport { z } from 'zod';\nimport { DiffFile } from '../types/agent.types.js';\n\n/**\n * Parse git diff into structured file changes\n */\nexport function parseDiff(diff: string): DiffFile[] {\n  const files: DiffFile[] = [];\n  const lines = diff.split('\\n');\n  let currentFile: Partial<DiffFile> | null = null;\n  let currentDiff: string[] = [];\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i];\n\n    // New file detected\n    if (line.startsWith('diff --git')) {\n      // Save previous file\n      if (currentFile) {\n        files.push({\n          ...currentFile,\n          diff: currentDiff.join('\\n'),\n        } as DiffFile);\n      }\n\n      // Parse file path\n      const match = line.match(/^diff --git a\\/(.+?) b\\/(.+?)$/);\n      if (match) {\n        const filePath = match[2] !== '/dev/null' ? match[2] : match[1];\n        currentFile = {\n          path: filePath,\n          additions: 0,\n          deletions: 0,\n          language: detectLanguage(filePath),\n        };\n        currentDiff = [line];\n      }\n    } else if (line.startsWith('new file') && currentFile) {\n      currentFile.status = 'A';\n      currentDiff.push(line);\n    } else if (line.startsWith('deleted file') && currentFile) {\n      currentFile.status = 'D';\n      currentDiff.push(line);\n    } else if (line.startsWith('rename from') && currentFile) {\n      currentFile.status = 'R';\n      const oldPath = line.replace('rename from ', '').trim();\n      currentFile.oldPath = oldPath;\n      currentDiff.push(line);\n    } else if (line.startsWith('+') && !line.startsWith('+++') && currentFile) {\n      currentFile.additions = (currentFile.additions || 0) + 1;\n      currentDiff.push(line);\n    } else if (line.startsWith('-') && !line.startsWith('---') && currentFile) {\n      currentFile.deletions = (currentFile.deletions || 0) + 1;\n      currentDiff.push(line);\n    } else if (currentFile) {\n      currentDiff.push(line);\n    }\n  }\n\n  // Save last file\n  if (currentFile) {\n    files.push({\n      ...currentFile,\n      diff: currentDiff.join('\\n'),\n    } as DiffFile);\n  }\n\n  return files;\n}\n\n/**\n * Detect programming language from file extension\n */\nfunction detectLanguage(filePath: string): string {\n  const ext = filePath.split('.').pop()?.toLowerCase();\n  const languageMap: Record<string, string> = {\n    ts: 'typescript',\n    tsx: 'typescript',\n    js: 'javascript',\n    jsx: 'javascript',\n    py: 'python',\n    java: 'java',\n    go: 'go',\n    rs: 'rust',\n    rb: 'ruby',\n    php: 'php',\n    cs: 'csharp',\n    cpp: 'cpp',\n    c: 'c',\n    swift: 'swift',\n    kt: 'kotlin',\n    yaml: 'yaml',\n    yml: 'yaml',\n    json: 'json',\n    md: 'markdown',\n  };\n  return languageMap[ext || ''] || 'unknown';\n}\n\n/**\n * Create file analyzer tool\n */\nexport function createFileAnalyzerTool() {\n  return new DynamicStructuredTool({\n    name: 'analyze_file',\n    description: 'Analyze a specific file from the diff to identify risks, complexity, and provide recommendations',\n    schema: z.object({\n      filePath: z.string().describe('Path of the file to analyze'),\n      diffContent: z.string().describe('The diff content for this file'),\n    }),\n    func: async ({ filePath, diffContent }) => {\n      // Parse the diff to extract changes\n      const additions = (diffContent.match(/^\\+[^+]/gm) || []).length;\n      const deletions = (diffContent.match(/^-[^-]/gm) || []).length;\n      const totalChanges = additions + deletions;\n\n      // Basic complexity scoring\n      let complexity = 1;\n      if (totalChanges > 100) complexity = 4;\n      else if (totalChanges > 50) complexity = 3;\n      else if (totalChanges > 20) complexity = 2;\n\n      // Detect potential risks\n      const risks: string[] = [];\n      \n      // Check for security-related patterns\n      if (/eval\\(|exec\\(|system\\(/i.test(diffContent)) {\n        risks.push('Potentially dangerous function calls detected (eval, exec, system)');\n      }\n      if (/password|secret|api[_-]?key|token/i.test(diffContent) && /['\"]/i.test(diffContent)) {\n        risks.push('Possible hardcoded credentials or secrets');\n      }\n      if (/TODO|FIXME|XXX|HACK/i.test(diffContent)) {\n        risks.push('Contains TODO/FIXME comments indicating incomplete work');\n      }\n      if (totalChanges > 200) {\n        risks.push('Very large change set - difficult to review thoroughly');\n      }\n\n      // Check for error handling\n      const hasTryCatch = /try\\s*{|catch\\s*\\(/i.test(diffContent);\n      const hasThrow = /throw\\s+/i.test(diffContent);\n      if (hasThrow && !hasTryCatch) {\n        risks.push('Throws errors without apparent error handling');\n      }\n\n      return JSON.stringify({\n        path: filePath,\n        additions,\n        deletions,\n        complexity,\n        risks,\n        language: detectLanguage(filePath),\n      });\n    },\n  });\n}\n\n/**\n * Create risk detector tool\n */\nexport function createRiskDetectorTool() {\n  return new DynamicStructuredTool({\n    name: 'detect_risks',\n    description: 'Detect security, quality, and breaking change risks in the PR',\n    schema: z.object({\n      diff: z.string().describe('The full diff to analyze for risks'),\n      context: z.string().optional().describe('Additional context about the changes'),\n    }),\n    func: async ({ diff, context }) => {\n      const risks: Array<{ type: string; severity: string; description: string }> = [];\n\n      // Security risks\n      if (/sql.*=.*\\+|SQL.*=.*\\+/i.test(diff)) {\n        risks.push({\n          type: 'security',\n          severity: 'high',\n          description: 'Potential SQL injection - string concatenation in SQL queries',\n        });\n      }\n\n      if (/innerHTML|dangerouslySetInnerHTML/i.test(diff)) {\n        risks.push({\n          type: 'security',\n          severity: 'medium',\n          description: 'XSS risk - using innerHTML or dangerouslySetInnerHTML',\n        });\n      }\n\n      // Breaking changes\n      if (/export\\s+(interface|type|class|function)\\s+\\w+/i.test(diff) && /-.*export/i.test(diff)) {\n        risks.push({\n          type: 'breaking',\n          severity: 'high',\n          description: 'Potential breaking change - modified or removed export',\n        });\n      }\n\n      // Code quality\n      if ((diff.match(/console\\.log/g) || []).length > 3) {\n        risks.push({\n          type: 'quality',\n          severity: 'low',\n          description: 'Multiple console.log statements - consider using proper logging',\n        });\n      }\n\n      // Performance\n      if (/for.*for|while.*while/i.test(diff) && /O\\(n\\^2\\)/i.test(diff)) {\n        risks.push({\n          type: 'performance',\n          severity: 'medium',\n          description: 'Nested loops detected - potential O(n) complexity',\n        });\n      }\n\n      return JSON.stringify({\n        riskCount: risks.length,\n        risks,\n        context: context || 'No additional context provided',\n      });\n    },\n  });\n}\n\n/**\n * Create complexity scorer tool\n */\nexport function createComplexityScorerTool() {\n  return new DynamicStructuredTool({\n    name: 'score_complexity',\n    description: 'Calculate overall complexity score for the PR (1-5 scale)',\n    schema: z.object({\n      filesAnalyzed: z.array(z.any()).describe('Array of analyzed files'),\n      totalChanges: z.number().describe('Total lines changed'),\n    }),\n    func: async ({ filesAnalyzed, totalChanges }) => {\n      let score = 1;\n      \n      // Factor 1: Total changes\n      if (totalChanges > 500) score = Math.max(score, 5);\n      else if (totalChanges > 300) score = Math.max(score, 4);\n      else if (totalChanges > 150) score = Math.max(score, 3);\n      else if (totalChanges > 50) score = Math.max(score, 2);\n\n      // Factor 2: Number of files\n      const fileCount = filesAnalyzed.length;\n      if (fileCount > 20) score = Math.max(score, 5);\n      else if (fileCount > 10) score = Math.max(score, 4);\n      else if (fileCount > 5) score = Math.max(score, 3);\n\n      // Factor 3: File complexity average\n      const avgFileComplexity = filesAnalyzed.reduce((sum: number, f: any) => sum + (f.complexity || 1), 0) / Math.max(fileCount, 1);\n      if (avgFileComplexity >= 4) score = Math.max(score, 5);\n      else if (avgFileComplexity >= 3) score = Math.max(score, 4);\n\n      return JSON.stringify({\n        overallComplexity: Math.min(score, 5),\n        factors: {\n          totalChanges,\n          fileCount,\n          avgFileComplexity: avgFileComplexity.toFixed(1),\n        },\n        recommendation: score >= 4\n          ? 'High complexity - consider breaking into smaller PRs'\n          : score >= 3\n            ? 'Moderate complexity - ensure thorough testing'\n            : 'Low complexity - straightforward changes',\n      });\n    },\n  });\n}\n\n/**\n * Create summary generator tool\n */\nexport function createSummaryGeneratorTool() {\n  return new DynamicStructuredTool({\n    name: 'generate_summary',\n    description: 'Generate a concise summary of PR changes',\n    schema: z.object({\n      files: z.array(z.any()).describe('Array of changed files'),\n      title: z.string().optional().describe('PR title'),\n    }),\n    func: async ({ files, title }) => {\n      const filesByType: Record<string, number> = {};\n      let totalAdditions = 0;\n      let totalDeletions = 0;\n\n      files.forEach((file: any) => {\n        const lang = file.language || 'other';\n        filesByType[lang] = (filesByType[lang] || 0) + 1;\n        totalAdditions += file.additions || 0;\n        totalDeletions += file.deletions || 0;\n      });\n\n      const mainLanguage = Object.entries(filesByType).sort((a, b) => b[1] - a[1])[0]?.[0] || 'unknown';\n\n      return JSON.stringify({\n        title: title || 'Untitled PR',\n        fileCount: files.length,\n        totalAdditions,\n        totalDeletions,\n        netChange: totalAdditions - totalDeletions,\n        mainLanguage,\n        filesByType,\n        summary: `Changes ${files.length} file(s) with ${totalAdditions} additions and ${totalDeletions} deletions. Primary language: ${mainLanguage}.`,\n      });\n    },\n  });\n}\n\n/**\n * Create code suggestion tool for fixing issues based on reviewer comments\n */\nexport function createCodeSuggestionTool() {\n  return new DynamicStructuredTool({\n    name: 'suggest_code_fix',\n    description: 'Generate a code fix suggestion based on a reviewer comment and the associated code snippet',\n    schema: z.object({\n      reviewerComment: z.string().describe('The reviewer\\'s comment describing the issue'),\n      codeSnippet: z.string().describe('The original code snippet to be fixed'),\n      filePath: z.string().describe('Path of the file containing the code'),\n      prTitle: z.string().optional().describe('PR title for context'),\n      prContext: z.string().optional().describe('Additional PR context (repo, branch, etc.)'),\n    }),\n    func: async ({ reviewerComment, codeSnippet, filePath, prTitle, prContext }) => {\n      // Build the fix prompt\n      const prompt = `You are an expert software engineer and code-fixer. You will take a reviewer comment and the associated code snippet and produce the corrected code snippet only.\n\nContext:\n${prContext || '(no additional context)'}\n- PR Title: ${prTitle || '(unknown)'}\n- File: ${filePath}\n\nReviewer comment:\n${reviewerComment.trim()}\n\nOriginal code snippet:\n\\`\\`\\`\n${codeSnippet}\n\\`\\`\\`\n\nTask:\n1) Apply the reviewer's requested changes to the provided code snippet.\n2) Output rules (MUST follow exactly):\n   - Return only the corrected code snippet (no explanations, no markdown fences, no extra text).\n   - If only a few lines changed you may return only the updated lines, but prefer returning the full corrected snippet when structural/context changes are required.\n   - Preserve original code style and indentation.\n   - If no changes are needed, reply with exactly: NO CHANGE\n   - Do not include filenames, metadata, or commentary.\n\nProduce the corrected code now.`;\n\n      return JSON.stringify({\n        filePath,\n        originalCode: codeSnippet,\n        reviewerComment,\n        prompt,\n        status: 'ready',\n        message: 'Code suggestion prompt prepared. The agent will use this to generate the fix.',\n      });\n    },\n  });\n}\n\n","/**\n * Base PR Agent Workflow using LangGraph\n * Follows architecture-doc-generator patterns with self-refinement\n */\n\nimport { StateGraph, Annotation, END } from '@langchain/langgraph';\nimport { MemorySaver } from '@langchain/langgraph';\nimport { ChatAnthropic } from '@langchain/anthropic';\nimport { AgentContext, AgentResult, FileAnalysis, AgentExecutionOptions } from '../types/agent.types.js';\nimport {\n  parseDiff,\n  createFileAnalyzerTool,\n  createRiskDetectorTool,\n  createComplexityScorerTool,\n  createSummaryGeneratorTool,\n} from '../tools/pr-analysis-tools.js';\n\n/**\n * Agent workflow state\n */\nexport const PRAgentState = Annotation.Root({\n  // Input context\n  context: Annotation<AgentContext>({\n    reducer: (_, update) => update,\n  }),\n\n  // Current iteration\n  iteration: Annotation<number>({\n    reducer: (_, update) => update,\n    default: () => 0,\n  }),\n\n  // File analyses\n  fileAnalyses: Annotation<Map<string, FileAnalysis>>({\n    reducer: (_, update) => update,\n    default: () => new Map(),\n  }),\n\n  // Current analysis state\n  currentSummary: Annotation<string>({\n    reducer: (_, update) => update,\n    default: () => '',\n  }),\n\n  currentRisks: Annotation<string[]>({\n    reducer: (_, update) => update,\n    default: () => [],\n  }),\n\n  currentComplexity: Annotation<number>({\n    reducer: (_, update) => update,\n    default: () => 1,\n  }),\n\n  // Quality metrics\n  clarityScore: Annotation<number>({\n    reducer: (_, update) => update,\n    default: () => 0,\n  }),\n\n  missingInformation: Annotation<string[]>({\n    reducer: (_, update) => update,\n    default: () => [],\n  }),\n\n  // Recommendations\n  recommendations: Annotation<string[]>({\n    reducer: (_, update) => update,\n    default: () => [],\n  }),\n\n  // Insights and reasoning\n  insights: Annotation<string[]>({\n    reducer: (current, update) => [...current, ...update],\n    default: () => [],\n  }),\n\n  reasoning: Annotation<string[]>({\n    reducer: (current, update) => [...current, ...update],\n    default: () => [],\n  }),\n\n  // Token tracking\n  totalInputTokens: Annotation<number>({\n    reducer: (current, update) => current + update,\n    default: () => 0,\n  }),\n\n  totalOutputTokens: Annotation<number>({\n    reducer: (current, update) => current + update,\n    default: () => 0,\n  }),\n});\n\n/**\n * Configuration for PR agent workflow\n */\nexport interface PRAgentWorkflowConfig {\n  maxIterations: number;\n  clarityThreshold: number;\n  skipSelfRefinement?: boolean;\n}\n\n/**\n * Base class for PR agents with self-refinement workflow\n */\nexport abstract class BasePRAgentWorkflow {\n  protected model: ChatAnthropic;\n  protected workflow: ReturnType<typeof this.buildWorkflow>;\n  protected checkpointer = new MemorySaver();\n  protected tools: any[];\n\n  constructor(apiKey: string, modelName: string = 'claude-sonnet-4-5-20250929') {\n    this.model = new ChatAnthropic({\n      apiKey,\n      modelName,\n      temperature: 0.2,\n      maxTokens: 4000, // Increased for detailed summaries\n    });\n\n    // Initialize tools\n    this.tools = [\n      createFileAnalyzerTool(),\n      createRiskDetectorTool(),\n      createComplexityScorerTool(),\n      createSummaryGeneratorTool(),\n    ];\n\n    this.workflow = this.buildWorkflow();\n  }\n\n  /**\n   * Build the PR analysis workflow\n   */\n  private buildWorkflow() {\n    const graph = new StateGraph(PRAgentState);\n\n    // Define nodes\n    graph.addNode('analyzeFiles', this.analyzeFilesNode.bind(this));\n    graph.addNode('detectRisks', this.detectRisksNode.bind(this));\n    graph.addNode('calculateComplexity', this.calculateComplexityNode.bind(this));\n    graph.addNode('generateSummary', this.generateSummaryNode.bind(this));\n    graph.addNode('evaluateQuality', this.evaluateQualityNode.bind(this));\n    graph.addNode('refineAnalysis', this.refineAnalysisNode.bind(this));\n    graph.addNode('finalize', this.finalizeNode.bind(this));\n\n    // Set entry point\n    const entryPoint = 'analyzeFiles' as '__start__';\n    graph.setEntryPoint(entryPoint);\n\n    // Build workflow graph\n    graph.addEdge(entryPoint, 'detectRisks' as '__start__');\n    graph.addEdge('detectRisks' as '__start__', 'calculateComplexity' as '__start__');\n    graph.addEdge('calculateComplexity' as '__start__', 'generateSummary' as '__start__');\n    graph.addEdge('generateSummary' as '__start__', 'evaluateQuality' as '__start__');\n\n    // Conditional: refine or finalize\n    graph.addConditionalEdges('evaluateQuality' as '__start__', this.shouldRefine.bind(this), {\n      refine: 'refineAnalysis' as '__start__',\n      finalize: 'finalize' as '__start__',\n    });\n\n    // After refinement, evaluate again\n    graph.addEdge('refineAnalysis' as '__start__', 'evaluateQuality' as '__start__');\n\n    // End after finalization\n    graph.addEdge('finalize' as '__start__', END);\n\n    return graph.compile({ checkpointer: this.checkpointer });\n  }\n\n  /**\n   * Execute the agent workflow\n   */\n  async execute(context: AgentContext, options?: AgentExecutionOptions): Promise<AgentResult> {\n    const startTime = Date.now();\n\n    // Fast path: skip self-refinement\n    if (options?.skipSelfRefinement) {\n      return this.executeFastPath(context, startTime);\n    }\n\n    const config: PRAgentWorkflowConfig = {\n      maxIterations: 3,\n      clarityThreshold: 80,\n      skipSelfRefinement: false,\n    };\n\n    const initialState = {\n      context,\n      iteration: 0,\n      fileAnalyses: new Map(),\n      currentSummary: '',\n      currentRisks: [],\n      currentComplexity: 1,\n      clarityScore: 0,\n      missingInformation: [],\n      recommendations: [],\n      insights: [],\n      reasoning: [],\n      totalInputTokens: 0,\n      totalOutputTokens: 0,\n    };\n\n    const workflowConfig = {\n      configurable: {\n        thread_id: `pr-agent-${Date.now()}`,\n        maxIterations: config.maxIterations,\n        clarityThreshold: config.clarityThreshold,\n      },\n      recursionLimit: 50,\n    };\n\n    let finalState = initialState;\n    let totalInputTokens = 0;\n    let totalOutputTokens = 0;\n\n    // Execute workflow - stream returns state updates\n    try {\n      for await (const state of await this.workflow.stream(initialState, workflowConfig as any)) {\n        // Get the last node's state\n        const nodeNames = Object.keys(state);\n        if (nodeNames.length > 0) {\n          const lastNodeName = nodeNames[nodeNames.length - 1];\n          finalState = (state as any)[lastNodeName] || finalState;\n\n          // Extract token counts if present\n          const stateAny = finalState as any;\n          if (stateAny.totalInputTokens !== undefined) {\n            totalInputTokens = stateAny.totalInputTokens;\n          }\n          if (stateAny.totalOutputTokens !== undefined) {\n            totalOutputTokens = stateAny.totalOutputTokens;\n          }\n        }\n      }\n    } catch (error) {\n      console.error('Workflow execution error:', error);\n      throw error;\n    }\n\n    const executionTime = Date.now() - startTime;\n\n    return {\n      summary: finalState.currentSummary,\n      fileAnalyses: finalState.fileAnalyses,\n      overallComplexity: finalState.currentComplexity,\n      overallRisks: finalState.currentRisks,\n      recommendations: finalState.recommendations,\n      insights: finalState.insights,\n      reasoning: finalState.reasoning,\n      provider: 'anthropic',\n      model: this.model.modelName,\n      totalTokensUsed: totalInputTokens + totalOutputTokens,\n      executionTime,\n      mode: context.mode,\n    };\n  }\n\n  /**\n   * Fast path execution - skip refinement\n   */\n  private async executeFastPath(context: AgentContext, startTime: number): Promise<AgentResult> {\n    const files = parseDiff(context.diff);\n    const fileAnalyses = new Map<string, FileAnalysis>();\n\n    // Analyze each file\n    for (const file of files.slice(0, 20)) { // Limit to 20 files\n      const analysis: FileAnalysis = {\n        path: file.path,\n        summary: `Modified ${file.additions} lines, deleted ${file.deletions} lines`,\n        risks: [],\n        complexity: Math.min(5, Math.floor((file.additions + file.deletions) / 50) + 1),\n        changes: {\n          additions: file.additions,\n          deletions: file.deletions,\n        },\n        recommendations: [],\n      };\n\n      fileAnalyses.set(file.path, analysis);\n    }\n\n    // Calculate overall complexity\n    const complexities = Array.from(fileAnalyses.values()).map(f => f.complexity);\n    const overallComplexity = complexities.length > 0\n      ? Math.round(complexities.reduce((a, b) => a + b, 0) / complexities.length)\n      : 1;\n\n    const executionTime = Date.now() - startTime;\n\n    return {\n      summary: `Analyzed ${files.length} files with ${files.reduce((sum, f) => sum + f.additions, 0)} additions and ${files.reduce((sum, f) => sum + f.deletions, 0)} deletions`,\n      fileAnalyses,\n      overallComplexity,\n      overallRisks: [],\n      recommendations: ['Fast path analysis - run with --agent for detailed analysis'],\n      insights: [],\n      reasoning: ['Fast path: Self-refinement skipped for speed'],\n      provider: 'anthropic',\n      model: this.model.modelName,\n      totalTokensUsed: 0,\n      executionTime,\n      mode: context.mode,\n    };\n  }\n\n  // Workflow nodes\n\n  private async analyzeFilesNode(state: typeof PRAgentState.State) {\n    const { context } = state;\n    const files = parseDiff(context.diff);\n    \n    console.log(` Analyzing ${files.length} files...`);\n\n    const fileAnalyses = new Map<string, FileAnalysis>();\n\n    // Analyze files in batches for detailed insights\n    const filesToAnalyze = files.slice(0, 15); // Limit to 15 files for detailed analysis\n    const importantFiles = filesToAnalyze.filter(f => \n      f.additions + f.deletions > 20 || // Significant changes\n      f.path.includes('config') || \n      f.path.includes('schema') ||\n      f.path.includes('migration') ||\n      f.path.includes('test')\n    ).slice(0, 5); // Top 5 important files\n\n    // Get detailed analysis for important files\n    if (importantFiles.length > 0) {\n      try {\n        const fileDetailsPrompt = `Analyze these important files from a pull request. For each file, provide a brief but insightful description of what changed and why it matters.\n\nFiles:\n${importantFiles.map(f => `\nFile: ${f.path}\nStatus: ${f.status || 'modified'}\nChanges: +${f.additions} -${f.deletions}\nDiff preview:\n\\`\\`\\`\n${f.diff.substring(0, 500)}\n\\`\\`\\`\n`).join('\\n---\\n')}\n\nRespond with a JSON object mapping file paths to analysis objects:\n{\n  \"path/to/file\": {\n    \"summary\": \"Brief description of changes\",\n    \"risks\": [\"risk1\", \"risk2\"],\n    \"complexity\": 1-5,\n    \"recommendations\": [\"rec1\", \"rec2\"]\n  }\n}`;\n\n        const response = await this.model.invoke(fileDetailsPrompt);\n        const content = response.content as string;\n        \n        // Track tokens\n        const usage = (response.response_metadata as any)?.usage;\n        const inputTokens = usage?.input_tokens || 0;\n        const outputTokens = usage?.output_tokens || 0;\n\n        // Parse detailed file analyses\n        try {\n          const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n          if (jsonMatch) {\n            const detailedAnalyses = JSON.parse(jsonMatch[0]);\n            \n            // Apply detailed analysis to file analyses\n            for (const file of importantFiles) {\n              const detail = detailedAnalyses[file.path];\n              if (detail) {\n                fileAnalyses.set(file.path, {\n                  path: file.path,\n                  summary: detail.summary || `${file.status || 'M'}: +${file.additions} -${file.deletions}`,\n                  risks: Array.isArray(detail.risks) ? detail.risks : [],\n                  complexity: detail.complexity || Math.min(5, Math.floor((file.additions + file.deletions) / 50) + 1),\n                  changes: {\n                    additions: file.additions,\n                    deletions: file.deletions,\n                  },\n                  recommendations: Array.isArray(detail.recommendations) ? detail.recommendations : [],\n                });\n              }\n            }\n          }\n        } catch (parseError) {\n          console.warn('Failed to parse file analysis JSON, using basic analysis');\n        }\n\n        // Update state with token tracking\n        state = {\n          ...state,\n          totalInputTokens: (state.totalInputTokens || 0) + inputTokens,\n          totalOutputTokens: (state.totalOutputTokens || 0) + outputTokens,\n        };\n      } catch (error) {\n        console.warn('Error in detailed file analysis, falling back to basic:', error);\n      }\n    }\n\n    // Add basic analysis for remaining files\n    for (const file of filesToAnalyze) {\n      if (!fileAnalyses.has(file.path)) {\n        const analysis: FileAnalysis = {\n          path: file.path,\n          summary: `${file.status || 'M'}: +${file.additions} -${file.deletions}`,\n          risks: [],\n          complexity: Math.min(5, Math.floor((file.additions + file.deletions) / 50) + 1),\n          changes: {\n            additions: file.additions,\n            deletions: file.deletions,\n          },\n          recommendations: [],\n        };\n\n        fileAnalyses.set(file.path, analysis);\n      }\n    }\n\n    return {\n      ...state,\n      fileAnalyses,\n      insights: [`Analyzed ${files.length} files (${importantFiles.length} in detail)`],\n    };\n  }\n\n  private async detectRisksNode(state: typeof PRAgentState.State) {\n    const { context, fileAnalyses } = state;\n    \n    console.log('  Detecting risks...');\n\n    // Build context for risk analysis\n    const fileList = Array.from(fileAnalyses.entries())\n      .slice(0, 15)\n      .map(([path, analysis]) => \n        `${path} (+${analysis.changes.additions} -${analysis.changes.deletions})`\n      )\n      .join('\\n');\n\n    // Get a sample of the diff for risk analysis (limit size)\n    const diffSample = context.diff.substring(0, 8000); // First 8KB for context\n\n    const riskPrompt = `You are a security and code quality expert analyzing a pull request for potential risks.\n\nAnalyze the following changes and identify SPECIFIC risks in these categories:\n1. **Security Risks**: Exposed credentials, insecure patterns, authentication/authorization issues\n2. **Breaking Changes**: API changes, database schema changes, removed functionality\n3. **Performance Concerns**: Inefficient algorithms, memory leaks, N+1 queries\n4. **Code Quality**: Complex logic, missing error handling, lack of tests\n5. **Operational Risks**: Configuration changes, deployment concerns, dependency updates\n\nPR Title: ${context.title || 'No title provided'}\n\nFiles changed:\n${fileList}\n\nDiff sample:\n\\`\\`\\`\n${diffSample}\n\\`\\`\\`\n\nProvide a JSON array of specific risks found. Each risk should be a clear, actionable statement.\nFormat: [\"risk 1\", \"risk 2\", ...]\n\nOnly include risks that are actually present. If no significant risks, return an empty array [].`;\n\n    try {\n      const response = await this.model.invoke(riskPrompt);\n      const content = response.content as string;\n      \n      // Track tokens\n      const usage = (response.response_metadata as any)?.usage;\n      const inputTokens = usage?.input_tokens || 0;\n      const outputTokens = usage?.output_tokens || 0;\n\n      // Parse JSON response\n      let risks: string[] = [];\n      try {\n        // Extract JSON from markdown code blocks if present\n        const jsonMatch = content.match(/\\[[\\s\\S]*\\]/);\n        if (jsonMatch) {\n          risks = JSON.parse(jsonMatch[0]);\n        }\n      } catch (parseError) {\n        console.warn('Failed to parse risk JSON, extracting manually');\n        // Fallback: extract bullet points\n        const lines = content.split('\\n');\n        risks = lines\n          .filter(line => line.trim().startsWith('-') || line.trim().startsWith(''))\n          .map(line => line.replace(/^[-]\\s*/, '').trim())\n          .filter(line => line.length > 0);\n      }\n\n      // Add basic pattern-based checks\n      const patternRisks: string[] = [];\n      if (context.diff.includes('password') || context.diff.includes('secret') || context.diff.includes('api_key')) {\n        patternRisks.push('Potential credentials or sensitive data in code changes');\n      }\n      if (fileAnalyses.size > 20) {\n        patternRisks.push(`Large change set (${fileAnalyses.size} files) - may be difficult to review thoroughly`);\n      }\n      if (context.diff.includes('DROP TABLE') || context.diff.includes('ALTER TABLE')) {\n        patternRisks.push('Database schema changes detected - requires careful migration planning');\n      }\n\n      // Merge risks, avoiding duplicates\n      const allRisks = [...new Set([...risks, ...patternRisks])];\n\n      return {\n        ...state,\n        currentRisks: allRisks,\n        insights: [`Identified ${allRisks.length} potential risks`],\n        totalInputTokens: (state.totalInputTokens || 0) + inputTokens,\n        totalOutputTokens: (state.totalOutputTokens || 0) + outputTokens,\n      };\n    } catch (error) {\n      console.error('Error in risk detection:', error);\n      \n      // Fallback to basic pattern matching\n      const basicRisks: string[] = [];\n      if (context.diff.includes('password') || context.diff.includes('secret')) {\n        basicRisks.push('Potential credentials in diff');\n      }\n      if (fileAnalyses.size > 15) {\n        basicRisks.push('Large change set - difficult to review');\n      }\n\n      return {\n        ...state,\n        currentRisks: basicRisks,\n        insights: [`Identified ${basicRisks.length} potential risks (basic analysis)`],\n      };\n    }\n  }\n\n  private async calculateComplexityNode(state: typeof PRAgentState.State) {\n    const { fileAnalyses } = state;\n    \n    console.log(' Calculating complexity...');\n\n    const complexities = Array.from(fileAnalyses.values()).map(f => f.complexity);\n    const avgComplexity = complexities.length > 0\n      ? complexities.reduce((a, b) => a + b, 0) / complexities.length\n      : 1;\n\n    return {\n      ...state,\n      currentComplexity: Math.round(avgComplexity),\n    };\n  }\n\n  private async generateSummaryNode(state: typeof PRAgentState.State) {\n    const { context, fileAnalyses, currentRisks, currentComplexity } = state;\n    \n    console.log(' Generating detailed summary...');\n\n    const totalFiles = fileAnalyses.size;\n    const totalAdditions = Array.from(fileAnalyses.values()).reduce((sum, f) => sum + f.changes.additions, 0);\n    const totalDeletions = Array.from(fileAnalyses.values()).reduce((sum, f) => sum + f.changes.deletions, 0);\n\n    // Build file list with changes\n    const fileList = Array.from(fileAnalyses.entries())\n      .slice(0, 20)\n      .map(([path, analysis]) => \n        `- ${path}: +${analysis.changes.additions} -${analysis.changes.deletions} (complexity: ${analysis.complexity}/5)`\n      )\n      .join('\\n');\n\n    // Create comprehensive prompt for LLM\n    const summaryPrompt = `You are analyzing a pull request. Provide a DETAILED and COMPREHENSIVE summary that covers:\n\n1. **Overall Purpose**: What is this PR trying to accomplish? What problem does it solve?\n2. **Key Changes**: What are the main changes being made? Group related changes together.\n3. **Impact Analysis**: What parts of the system are affected? What are the implications?\n4. **Technical Details**: Mention important technical aspects (new dependencies, API changes, data model changes, etc.)\n5. **Patterns Observed**: Any design patterns, refactoring, or architectural changes?\n\nPR Title: ${context.title || 'No title provided'}\n\nStatistics:\n- Files changed: ${totalFiles}\n- Lines added: ${totalAdditions}\n- Lines deleted: ${totalDeletions}\n- Overall complexity: ${currentComplexity}/5\n- Risks identified: ${currentRisks.length}\n\nFiles changed:\n${fileList}\n\n${currentRisks.length > 0 ? `\\nRisks detected:\\n${currentRisks.map(r => `- ${r}`).join('\\n')}` : ''}\n\nProvide a detailed, well-structured summary (3-5 paragraphs) that would help a reviewer understand the scope and purpose of this PR.`;\n\n    try {\n      const response = await this.model.invoke(summaryPrompt);\n      const detailedSummary = response.content as string;\n\n      // Track token usage\n      const usage = (response.response_metadata as any)?.usage;\n      const inputTokens = usage?.input_tokens || 0;\n      const outputTokens = usage?.output_tokens || 0;\n\n      return {\n        ...state,\n        currentSummary: detailedSummary,\n        totalInputTokens: inputTokens,\n        totalOutputTokens: outputTokens,\n      };\n    } catch (error) {\n      console.error('Error generating summary:', error);\n      // Fallback to basic summary\n      const fallbackSummary = `PR Analysis Summary:\n- Files changed: ${totalFiles}\n- Additions: ${totalAdditions}\n- Deletions: ${totalDeletions}\n- Overall complexity: ${currentComplexity}/5\n- Risks identified: ${currentRisks.length}\n\n${context.title ? `Title: ${context.title}` : ''}`;\n\n      return {\n        ...state,\n        currentSummary: fallbackSummary,\n      };\n    }\n  }\n\n  private async evaluateQualityNode(state: typeof PRAgentState.State) {\n    const { iteration } = state;\n    \n    console.log(` Evaluating quality (iteration ${iteration + 1})...`);\n\n    // Simple quality check\n    const clarityScore = 85; // Placeholder\n\n    return {\n      ...state,\n      clarityScore,\n      iteration: iteration + 1,\n    };\n  }\n\n  private async refineAnalysisNode(state: typeof PRAgentState.State) {\n    const { currentSummary, currentRisks, fileAnalyses, context } = state;\n    \n    console.log(' Refining analysis...');\n\n    // Generate comprehensive recommendations\n    const refinementPrompt = `Based on this PR analysis, provide specific, actionable recommendations for the developer and reviewers.\n\nPR Summary:\n${currentSummary}\n\nRisks Identified:\n${currentRisks.map(r => `- ${r}`).join('\\n')}\n\nFiles Changed: ${fileAnalyses.size}\n\nConsider:\n1. Code organization and structure improvements\n2. Testing recommendations\n3. Documentation needs\n4. Performance optimizations\n5. Security enhancements\n6. Review process suggestions\n\nProvide a JSON array of 3-5 specific, actionable recommendations:\n[\"recommendation 1\", \"recommendation 2\", ...]`;\n\n    try {\n      const response = await this.model.invoke(refinementPrompt);\n      const content = response.content as string;\n      \n      // Track tokens\n      const usage = (response.response_metadata as any)?.usage;\n      const inputTokens = usage?.input_tokens || 0;\n      const outputTokens = usage?.output_tokens || 0;\n\n      // Parse recommendations\n      let recommendations: string[] = [];\n      try {\n        const jsonMatch = content.match(/\\[[\\s\\S]*\\]/);\n        if (jsonMatch) {\n          recommendations = JSON.parse(jsonMatch[0]);\n        }\n      } catch (parseError) {\n        // Fallback: extract bullet points\n        const lines = content.split('\\n');\n        recommendations = lines\n          .filter(line => line.trim().startsWith('-') || line.trim().startsWith('') || /^\\d+\\./.test(line.trim()))\n          .map(line => line.replace(/^[-]\\s*/, '').replace(/^\\d+\\.\\s*/, '').trim())\n          .filter(line => line.length > 0)\n          .slice(0, 5);\n      }\n\n      // Add default recommendations if none found\n      if (recommendations.length === 0) {\n        recommendations = [\n          'Ensure comprehensive test coverage for new functionality',\n          'Update relevant documentation',\n          'Consider performance implications of changes',\n        ];\n      }\n\n      return {\n        ...state,\n        recommendations,\n        totalInputTokens: (state.totalInputTokens || 0) + inputTokens,\n        totalOutputTokens: (state.totalOutputTokens || 0) + outputTokens,\n      };\n    } catch (error) {\n      console.error('Error refining analysis:', error);\n      return {\n        ...state,\n        recommendations: [\n          'Review changes carefully for potential side effects',\n          'Ensure test coverage is adequate',\n          'Update documentation as needed',\n        ],\n      };\n    }\n  }\n\n  private async finalizeNode(state: typeof PRAgentState.State) {\n    console.log(' Finalizing analysis...');\n    \n    return state;\n  }\n\n  private shouldRefine(state: typeof PRAgentState.State): string {\n    // Use defaults if config not accessible\n    const maxIterations = 3;\n    const clarityThreshold = 80;\n\n    if (state.iteration >= maxIterations) {\n      console.log(`  Stopping: Max iterations (${maxIterations}) reached`);\n      return 'finalize';\n    }\n\n    if (state.clarityScore >= clarityThreshold) {\n      console.log(` Stopping: Clarity threshold (${clarityThreshold}) achieved`);\n      return 'finalize';\n    }\n\n    console.log(` Continuing: Iteration ${state.iteration}, clarity ${state.clarityScore}`);\n    return 'refine';\n  }\n}\n\n","/**\n * PR Analyzer Agent\n * LangChain-based agent for intelligent PR analysis\n */\n\nimport { BasePRAgentWorkflow } from './base-pr-agent-workflow.js';\nimport { AgentContext, AgentResult, AgentMetadata, AnalysisMode } from '../types/agent.types.js';\nimport { parseDiff } from '../tools/pr-analysis-tools.js';\n\n/**\n * PR Analysis Agent using LangChain and LangGraph\n */\nexport class PRAnalyzerAgent extends BasePRAgentWorkflow {\n  constructor(apiKey: string, modelName: string = 'claude-sonnet-4-5-20250929') {\n    super(apiKey, modelName);\n  }\n\n  /**\n   * Get agent metadata\n   */\n  getMetadata(): AgentMetadata {\n    return {\n      name: 'pr-analyzer',\n      version: '1.0.0',\n      description: 'AI-powered pull request analyzer using LangChain agent workflow',\n      capabilities: [\n        'file-level analysis',\n        'risk detection',\n        'complexity scoring',\n        'intelligent recommendations',\n        'self-refinement workflow',\n      ],\n    };\n  }\n\n  /**\n   * Analyze a PR with full agent workflow\n   */\n  async analyze(\n    diff: string,\n    title?: string,\n    mode?: AnalysisMode,\n  ): Promise<AgentResult> {\n    // Parse diff into files\n    const files = parseDiff(diff);\n\n    // Create context\n    const context: AgentContext = {\n      diff,\n      title,\n      files,\n      tokenBudget: 100000,\n      maxCost: 5.0,\n      mode: mode || { summary: true, risks: true, complexity: true },\n    };\n\n    // Execute workflow\n    const result = await this.execute(context, {\n      skipSelfRefinement: files.length < 5 || diff.length < 10000, // Skip for small PRs\n    });\n\n    return result;\n  }\n\n  /**\n   * Quick analysis without refinement\n   */\n  async quickAnalyze(diff: string, title?: string): Promise<AgentResult> {\n    const files = parseDiff(diff);\n\n    const context: AgentContext = {\n      diff,\n      title,\n      files,\n      tokenBudget: 50000,\n      maxCost: 2.0,\n      mode: { summary: true, risks: true, complexity: true },\n    };\n\n    return this.execute(context, {\n      skipSelfRefinement: true,\n    });\n  }\n\n  /**\n   * Analyze specific files only\n   */\n  async analyzeFiles(diff: string, filePaths: string[]): Promise<AgentResult> {\n    const allFiles = parseDiff(diff);\n    const files = allFiles.filter(f => filePaths.includes(f.path));\n\n    const context: AgentContext = {\n      diff,\n      files,\n      tokenBudget: 50000,\n      maxCost: 2.0,\n      mode: { summary: true, risks: true, complexity: true },\n    };\n\n    return this.execute(context, {\n      skipSelfRefinement: true,\n    });\n  }\n\n  /**\n   * Check if agent can execute with given context\n   */\n  async canExecute(context: AgentContext): Promise<boolean> {\n    return context.files.length > 0 && context.diff.length > 0;\n  }\n\n  /**\n   * Estimate tokens for this analysis\n   */\n  async estimateTokens(context: AgentContext): Promise<number> {\n    const baseTokens = 2000;\n    const diffTokens = Math.ceil(context.diff.length / 4); // ~4 chars per token\n    const filesTokens = context.files.length * 100;\n    \n    return baseTokens + diffTokens + filesTokens;\n  }\n}\n\n/**\n * Factory function to create PR analyzer agent\n */\nexport function createPRAnalyzerAgent(apiKey: string, modelName?: string): PRAnalyzerAgent {\n  return new PRAnalyzerAgent(apiKey, modelName);\n}\n\n","import * as core from '@actions/core';\nimport * as github from '@actions/github';\nimport { PRAnalyzerAgent } from './agents/pr-analyzer-agent.js';\n\nasync function run() {\n  try {\n    const apiKey = process.env.ANTHROPIC_API_KEY;\n    const ghToken = process.env.GITHUB_TOKEN;\n\n    if (!apiKey) {\n      core.setFailed('ANTHROPIC_API_KEY environment variable is required');\n      return;\n    }\n\n    if (!ghToken) {\n      core.setFailed('GITHUB_TOKEN environment variable is required');\n      return;\n    }\n\n    const { context } = github;\n    const { pull_request: pr, repository } = context.payload;\n\n    if (!pr) {\n      core.setFailed('This action can only be run on pull request events');\n      return;\n    }\n\n    core.info(`Analyzing PR #${pr.number} in ${repository?.full_name}`);\n\n    // Get PR diffs\n    const diff = await getPRDiffs(context, ghToken);\n\n    if (!diff) {\n      core.warning('No changes found in the pull request');\n      return;\n    }\n    \n    core.info(`Diff size: ${diff.length} characters`);\n    \n    if (!repository) {\n      core.setFailed('Repository information not available');\n      return;\n    }\n\n    // Use LangChain PRAnalyzerAgent\n    core.info('Running LangChain agent analysis...');\n    const agent = new PRAnalyzerAgent(apiKey, 'claude-sonnet-4-5-20250929');\n\n    // Analyze with the LangChain agent\n    core.info('Parsing diff and analyzing...');\n    const result = await agent.analyze(diff, pr.title);\n    \n    core.info(`Analysis complete: ${result.fileAnalyses.size} files analyzed`);\n\n    // Format the summary\n    let summary = '';\n    \n    if (result.summary) {\n      summary += `### Summary\\n${result.summary}\\n\\n`;\n    }\n    \n    if (result.overallRisks.length > 0) {\n      summary += `### Potential Risks\\n`;\n      result.overallRisks.forEach((risk: string) => {\n        summary += `- ${risk}\\n`;\n      });\n      summary += '\\n';\n    } else {\n      summary += `### Potential Risks\\nNone\\n\\n`;\n    }\n    \n    summary += `### Complexity: ${result.overallComplexity}/5\\n`;\n    \n    if (result.recommendations && result.recommendations.length > 0) {\n      summary += `\\n### Recommendations\\n`;\n      result.recommendations.forEach((rec: string) => {\n        summary += `- ${rec}\\n`;\n      });\n    }\n\n    // Post comment\n    await postComment(pr.number, summary, repository, ghToken);\n\n    core.info('Analysis complete!');\n\n  } catch (error) {\n    core.setFailed(`Action failed with error: ${error}`);\n  }\n}\n\nasync function getPRDiffs(context: any, ghToken: string): Promise<string> {\n  try {\n    const { pull_request: pr, repository } = context.payload;\n\n    const octokit = github.getOctokit(ghToken);\n\n    const { data: files } = await octokit.rest.pulls.listFiles({\n      owner: repository.owner.login,\n      repo: repository.name,\n      pull_number: pr.number\n    });\n\n    // Format as proper git diff that parseDiff expects\n    return files.map((f: any) => {\n      const status = f.status === 'added' ? 'new file mode 100644' : \n                     f.status === 'removed' ? 'deleted file mode 100644' : '';\n      const patch = f.patch || '';\n      \n      return `diff --git a/${f.filename} b/${f.filename}\n${status ? status + '\\n' : ''}--- ${f.status === 'added' ? '/dev/null' : 'a/' + f.filename}\n+++ ${f.status === 'removed' ? '/dev/null' : 'b/' + f.filename}\n${patch}`;\n    }).join('\\n');\n  } catch (error) {\n    core.error('Error fetching PR diff:');\n    core.error(String(error));\n    throw new Error('Failed to fetch PR diff');\n  }\n}\n\nasync function postComment(prNumber: number, summary: string, repository: any, ghToken: string) {\n  try {\n    const octokit = github.getOctokit(ghToken);\n\n    await octokit.rest.issues.createComment({\n      owner: repository.owner.login,\n      repo: repository.name,\n      issue_number: prNumber,\n      body: `##  AI Analysis (PR Agent by TechDebtGPT)\\n\\n${summary}`\n    });\n  } catch (error) {\n    core.error('Error posting comment:');\n    core.error(String(error));\n    throw new Error('Failed to post comment');\n  }\n}\n\nrun();\n"],"names":[],"sourceRoot":""}